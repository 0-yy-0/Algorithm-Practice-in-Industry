[
    {
        "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository\n  Mining Study",
        "url": "http://arxiv.org/abs/2305.11164v1",
        "pub_date": "2023-05-18",
        "summary": "The rise of machine learning (ML) systems has exacerbated their carbon\nfootprint due to increased capabilities and model sizes. However, there is\nscarce knowledge on how the carbon footprint of ML models is actually measured,\nreported, and evaluated. In light of this, the paper aims to analyze the\nmeasurement of the carbon footprint of 1,417 ML models and associated datasets\non Hugging Face, which is the most popular repository for pretrained ML models.\nThe goal is to provide insights and recommendations on how to report and\noptimize the carbon efficiency of ML models. The study includes the first\nrepository mining study on the Hugging Face Hub API on carbon emissions. This\nstudy seeks to answer two research questions: (1) how do ML model creators\nmeasure and report carbon emissions on Hugging Face Hub?, and (2) what aspects\nimpact the carbon emissions of training ML models? The study yielded several\nkey findings. These include a decreasing proportion of carbon\nemissions-reporting models, a slight decrease in reported carbon footprint on\nHugging Face over the past 2 years, and a continued dominance of NLP as the\nmain application domain. Furthermore, the study uncovers correlations between\ncarbon emissions and various attributes such as model size, dataset size, and\nML application domains. These results highlight the need for software\nmeasurements to improve energy reporting practices and promote carbon-efficient\nmodel development within the Hugging Face community. In response to this issue,\ntwo classifications are proposed: one for categorizing models based on their\ncarbon emission reporting practices and another for their carbon efficiency.\nThe aim of these classification proposals is to foster transparency and\nsustainable model development within the ML community.",
        "translated": "机器学习(ML)系统的兴起加剧了它们的碳足印，原因是功能和模型尺寸的增加。然而，对于机器学习模型的碳足印实际上是如何测量、报告和评估的，我们知之甚少。有鉴于此，本文旨在分析“拥抱脸”上对1417个机器学习模型及相关数据集的碳足印测量结果。“拥抱脸”是最受欢迎的预训机器学习模型库。目标是就如何报告和优化机器学习模型的碳效率提供见解和建议。这项研究包括第一个关于碳排放的拥抱面中心 API 的知识库挖掘研究。这项研究试图回答两个研究问题: (1)机器学习模型的创建者如何测量和报告拥抱面部中心的碳排放量？以及(2)哪些方面影响训练机器学习模型的碳排放量？这项研究产生了几个关键的发现。其中包括碳排放报告模型的比例下降，过去两年“拥抱脸”上的报告碳足印略有下降，以及自然语言处理作为主要应用领域的持续主导地位。此外，该研究还揭示了碳排放与模型大小、数据集大小和机器学习应用领域等各种属性之间的相关性。这些结果突出了软件测量的必要性，以改善能源报告做法，并促进在拥抱面社区的碳效率模型开发。针对这一问题，提出了两种分类: 一种是根据其碳排放报告做法对模型进行分类，另一种是根据其碳效率进行分类。这些分类建议的目的是在 ML 社区内促进透明度和可持续的模型开发。"
    },
    {
        "title": "TOME: A Two-stage Approach for Model-based Retrieval",
        "url": "http://arxiv.org/abs/2305.11161v1",
        "pub_date": "2023-05-18",
        "summary": "Recently, model-based retrieval has emerged as a new paradigm in text\nretrieval that discards the index in the traditional retrieval model and\ninstead memorizes the candidate corpora using model parameters. This design\nemploys a sequence-to-sequence paradigm to generate document identifiers, which\nenables the complete capture of the relevance between queries and documents and\nsimplifies the classic indexretrieval-rerank pipeline. Despite its attractive\nqualities, there remain several major challenges in model-based retrieval,\nincluding the discrepancy between pre-training and fine-tuning, and the\ndiscrepancy between training and inference. To deal with the above challenges,\nwe propose a novel two-stage model-based retrieval approach called TOME, which\nmakes two major technical contributions, including the utilization of tokenized\nURLs as identifiers and the design of a two-stage generation architecture. We\nalso propose a number of training strategies to deal with the training\ndifficulty as the corpus size increases. Extensive experiments and analysis on\nMS MARCO and Natural Questions demonstrate the effectiveness of our proposed\napproach, and we investigate the scaling laws of TOME by examining various\ninfluencing factors.",
        "translated": "近年来，基于模型的检索已经成为文本检索的一种新范式，它抛弃了传统检索模型中的索引，而是利用模型参数记忆候选语料库。该设计采用序列到序列的方法生成文档标识符，能够完全捕获查询和文档之间的相关性，简化了经典的索引检索-重排序流水线。尽管基于模型的检索具有吸引人的优点，但仍然存在一些主要的挑战，包括预训练和微调之间的差异，以及训练和推理之间的差异。为了应对上述挑战，我们提出了一种新的基于两阶段模型的检索方法，称为 TOME，它做出了两个主要的技术贡献，包括使用标记化 URL 作为标识符和设计一个两阶段生成体系结构。随着语料库规模的增大，我们提出了一些训练策略来解决训练难度。大量的实验和分析 MS MARCO 和自然问题证明了我们提出的方法的有效性，我们研究了 TOME 的缩放规律通过检查各种影响因素。"
    },
    {
        "title": "Preference or Intent? Double Disentangled Collaborative Filtering",
        "url": "http://arxiv.org/abs/2305.11084v1",
        "pub_date": "2023-05-18",
        "summary": "People usually have different intents for choosing items, while their\npreferences under the same intent may also different. In traditional\ncollaborative filtering approaches, both intent and preference factors are\nusually entangled in the modeling process, which significantly limits the\nrobustness and interpretability of recommendation performances. For example,\nthe low-rating items are always treated as negative feedback while they\nactually could provide positive information about user intent. To this end, in\nthis paper, we propose a two-fold representation learning approach, namely\nDouble Disentangled Collaborative Filtering (DDCF), for personalized\nrecommendations. The first-level disentanglement is for separating the\ninfluence factors of intent and preference, while the second-level\ndisentanglement is performed to build independent sparse preference\nrepresentations under individual intent with limited computational complexity.\nSpecifically, we employ two variational autoencoder networks, intent\nrecognition network and preference decomposition network, to learn the intent\nand preference factors, respectively. In this way, the low-rating items will be\ntreated as positive samples for modeling intents while the negative samples for\nmodeling preferences. Finally, extensive experiments on three real-world\ndatasets and four evaluation metrics clearly validate the effectiveness and the\ninterpretability of DDCF.",
        "translated": "人们通常有不同的意图选择项目，而他们的偏好下，相同的意图也可能有所不同。在传统的协同过滤建模方法中，意图和偏好因素通常会在建模过程中纠缠在一起，这极大地限制了推荐性能的稳健性和可解释性。例如，低等级的项目总是被视为负面反馈，而实际上它们可以提供关于用户意图的正面信息。为此，在本文中，我们提出了一种双重表征学习方法，即双重分离协同过滤(DDCF) ，用于个性化推荐。第一级解缠是为了分离意图和偏好的影响因素，而第二级解缠是为了在计算复杂度有限的个体意图下构建独立的稀疏偏好表示。具体来说，我们使用两个变分自动编码器网络，意图识别网络和偏好分解网络，分别学习意图和偏好因素。这样，低等级的项目将被视为建模意图的正面样本，而负面样本将被视为建模偏好。最后，在三个实际数据集和四个评价指标上进行了广泛的实验，验证了 DDCF 的有效性和可解释性。"
    },
    {
        "title": "AMR4NLI: Interpretable and robust NLI measures from semantic graphs",
        "url": "http://arxiv.org/abs/2306.00936v1",
        "pub_date": "2023-06-01",
        "summary": "The task of natural language inference (NLI) asks whether a given premise\n(expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human\nratings of entailment, but the meaning relationships driving these ratings are\nnot formalized. Can the underlying sentence pair relationships be made more\nexplicit in an interpretable yet robust fashion? We compare semantic structures\nto represent premise and hypothesis, including sets of contextualized\nembeddings and semantic graphs (Abstract Meaning Representations), and measure\nwhether the hypothesis is a semantic substructure of the premise, utilizing\ninterpretable metrics. Our evaluation on three English benchmarks finds value\nin both contextualized embeddings and semantic graphs; moreover, they provide\ncomplementary signals, and can be leveraged together in a hybrid model.",
        "translated": "自然语言推理的任务是询问一个给定的前提(用自然语言表示)是否包含一个给定的自然语言假设。NLI 基准包含人工赋值评级，但是驱动这些评级的意义关系并没有形式化。潜在的句子对关系是否可以以一种可解释的、强有力的方式更明确地表达出来？我们比较了表示前提和假设的语义结构，包括语境化嵌入和语义图集(抽象意义表示) ，并利用可解释的度量衡量假设是否是前提的语义子结构。我们对三个英语基准测试的评估发现了上下文嵌入和语义图的价值; 此外，它们提供了互补的信号，并且可以在混合模型中一起使用。"
    },
    {
        "title": "ACLM: A Selective-Denoising based Generative Data Augmentation Approach\n  for Low-Resource Complex NER",
        "url": "http://arxiv.org/abs/2306.00928v1",
        "pub_date": "2023-06-01",
        "summary": "Complex Named Entity Recognition (NER) is the task of detecting\nlinguistically complex named entities in low-context text. In this paper, we\npresent ACLM Attention-map aware keyword selection for Conditional Language\nModel fine-tuning), a novel data augmentation approach based on conditional\ngeneration to address the data scarcity problem in low-resource complex NER.\nACLM alleviates the context-entity mismatch issue, a problem existing NER data\naugmentation techniques suffer from and often generates incoherent\naugmentations by placing complex named entities in the wrong context. ACLM\nbuilds on BART and is optimized on a novel text reconstruction or denoising\ntask - we use selective masking (aided by attention maps) to retain the named\nentities and certain keywords in the input sentence that provide contextually\nrelevant additional knowledge or hints about the named entities. Compared with\nother data augmentation strategies, ACLM can generate more diverse and coherent\naugmentations preserving the true word sense of complex entities in the\nsentence. We demonstrate the effectiveness of ACLM both qualitatively and\nquantitatively on monolingual, cross-lingual, and multilingual complex NER\nacross various low-resource settings. ACLM outperforms all our neural baselines\nby a significant margin (1%-36%). In addition, we demonstrate the application\nof ACLM to other domains that suffer from data scarcity (e.g., biomedical). In\npractice, ACLM generates more effective and factual augmentations for these\ndomains than prior methods. Code: https://github.com/Sreyan88/ACLM",
        "translated": "复杂命名实体识别(NER)是在低语境文本中检测语言复杂命名实体的任务。针对低资源复杂 NER 中的数据稀缺问题，提出了一种基于条件生成的数据增强方法—— ACLM 注意图感知的条件语言模型关键词选择方法。ACLM 缓解了上下文-实体不匹配问题，这是现有的 NER 数据增强技术所面临的问题，并且通常通过将复杂的命名实体放置在错误的上下文中而产生不一致的增强。ACLM 建立在 BART 的基础上，针对一个新的文本重建或去噪任务进行优化——我们使用选择性掩蔽(通过注意力地图辅助)来保留输入句中的命名实体和某些关键字，这些关键字提供了与上下文相关的附加知识或关于命名实体的提示。与其他数据增强策略相比，ACLM 能够产生更多样化和连贯的增强，保持句子中复杂实体的真实词义。我们证明了 ACLM 在定性和定量上对不同低资源环境下的单语言、跨语言和多语言复杂 NER 的有效性。ACLM 比我们所有的神经基线都要好得多(1% -36%)。此外，我们还展示了 ACLM 在其他数据稀缺领域(如生物医学)的应用。在实践中，ACLM 为这些领域产生了比以前的方法更有效和实际的增强。密码:  https://github.com/sreyan88/aclm"
    },
    {
        "title": "SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in\n  Graph Neural Networks",
        "url": "http://arxiv.org/abs/2306.00899v1",
        "pub_date": "2023-06-01",
        "summary": "Graph Neural Networks (GNNs) have demonstrated promising outcomes across\nvarious tasks, including node classification and link prediction. Despite their\nremarkable success in various high-impact applications, we have identified\nthree common pitfalls in message passing for link prediction. Particularly, in\nprevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges\n(i.e., the edges being predicted) consistently exist as message passing edges\nin the graph during training. Consequently, this results in overfitting and\ndistribution shift, both of which adversely impact the generalizability to test\nthe target edges. Additionally, during test time, the failure to exclude the\ntest target edges leads to implicit test leakage caused by neighborhood\naggregation. In this paper, we analyze these three pitfalls and investigate the\nimpact of including or excluding target edges on the performance of nodes with\nvarying degrees during training and test phases. Our theoretical and empirical\nanalysis demonstrates that low-degree nodes are more susceptible to these\npitfalls. These pitfalls can have detrimental consequences when GNNs are\nimplemented in production systems. To systematically address these pitfalls, we\npropose SpotTarget, an effective and efficient GNN training framework. During\ntraining, SpotTarget leverages our insight regarding low-degree nodes and\nexcludes train target edges connected to at least one low-degree node. During\ntest time, it emulates real-world scenarios of GNN usage in production and\nexcludes all test target edges. Our experiments conducted on diverse real-world\ndatasets, demonstrate that SpotTarget significantly enhances GNNs, achieving up\nto a 15x increase in accuracy in sparse graphs. Furthermore, SpotTarget\nconsistently and dramatically improves the performance for low-degree nodes in\ndense graphs.",
        "translated": "图形神经网络(GNN)在各种任务中，包括节点分类和链路预测，都取得了很好的效果。尽管它们在各种高影响力的应用程序中取得了显著的成功，但是我们已经确定了链接预测中消息传递的三个常见缺陷。特别是，在流行的 GNN 框架(例如，DGL 和 PyTorch-Geometer)中，目标边(例如，被预测的边)在训练期间始终作为图中的消息传递边存在。因此，这会导致过拟合和分布偏移，这两者都会对测试目标边缘的通用性产生不利影响。此外，在测试时间内，未能排除测试目标边缘会导致由邻域聚合引起的隐式测试泄漏。在本文中，我们分析了这三个陷阱，并研究了在训练和测试阶段包含或排除目标边对不同程度的节点性能的影响。我们的理论和实证分析表明，低度节点更容易受到这些陷阱的影响。当 GNN 在生产系统中实现时，这些缺陷可能会产生有害的后果。为了系统地解决这些缺陷，我们提出了 SpotTarget，一个高效的 GNN 训练框架。在训练过程中，SpotTarget 利用我们对低度节点的洞察力，排除了连接到至少一个低度节点的训练目标边缘。在测试期间，它模拟生产中 GNN 使用的真实场景，并排除所有测试目标边缘。我们在不同的真实世界数据集上进行的实验表明，SpotTarget 显著地增强了 GNN，在稀疏图中实现了高达15倍的精度提高。此外，SpotTarget 持续而显著地改善了稠密图中低度节点的性能。"
    },
    {
        "title": "Topic-Guided Sampling For Data-Efficient Multi-Domain Stance Detection",
        "url": "http://arxiv.org/abs/2306.00765v1",
        "pub_date": "2023-06-01",
        "summary": "Stance Detection is concerned with identifying the attitudes expressed by an\nauthor towards a target of interest. This task spans a variety of domains\nranging from social media opinion identification to detecting the stance for a\nlegal claim. However, the framing of the task varies within these domains, in\nterms of the data collection protocol, the label dictionary and the number of\navailable annotations. Furthermore, these stance annotations are significantly\nimbalanced on a per-topic and inter-topic basis. These make multi-domain stance\ndetection a challenging task, requiring standardization and domain adaptation.\nTo overcome this challenge, we propose $\\textbf{T}$opic $\\textbf{E}$fficient\n$\\textbf{St}$anc$\\textbf{E}$ $\\textbf{D}$etection (TESTED), consisting of a\ntopic-guided diversity sampling technique and a contrastive objective that is\nused for fine-tuning a stance classifier. We evaluate the method on an existing\nbenchmark of $16$ datasets with in-domain, i.e. all topics seen and\nout-of-domain, i.e. unseen topics, experiments. The results show that our\nmethod outperforms the state-of-the-art with an average of $3.5$ F1 points\nincrease in-domain, and is more generalizable with an averaged increase of\n$10.2$ F1 on out-of-domain evaluation while using $\\leq10\\%$ of the training\ndata. We show that our sampling technique mitigates both inter- and per-topic\nclass imbalances. Finally, our analysis demonstrates that the contrastive\nlearning objective allows the model a more pronounced segmentation of samples\nwith varying labels.",
        "translated": "姿势检测是指识别作者对于感兴趣的目标所表达的态度。这项任务涉及从社交媒体舆论识别到检测法律诉求立场等多个领域。然而，在这些领域内，任务的框架在数据收集协议、标签字典和可用注释的数量方面有所不同。此外，这些立场注释在每个主题和主题间的基础上显著不平衡。这使得多域姿态检测成为一项具有挑战性的任务，需要标准化和域自适应。为了克服这个挑战，我们提出了 $textbf { T } $opic $textbf { E } $ffical$textbf { St } $anc $textbf { E } $textbf { D } $etection (TESTED) ，包括一个主题引导的多样性采样技术和一个用于微调立场分类器的对比目标。我们评估的方法，在一个现有的基准 $16 $数据集与域内，即所有主题看到和域外，即看不到的主题，实验。结果表明，我们的方法优于国家的最新技术，平均 $3.5 $F1点在域内增加，更具普遍性，平均增加 $10.2 $F1在域外评估，同时使用 $leq10% $的训练数据。我们展示了我们的抽样技术缓解了主题间和主题间的类不平衡。最后，我们的分析表明，对比学习的目标允许模型更明显的样本分割与不同的标签。"
    },
    {
        "title": "End-to-End Document Classification and Key Information Extraction using\n  Assignment Optimization",
        "url": "http://arxiv.org/abs/2306.00750v1",
        "pub_date": "2023-06-01",
        "summary": "We propose end-to-end document classification and key information extraction\n(KIE) for automating document processing in forms. Through accurate document\nclassification we harness known information from templates to enhance KIE from\nforms. We use text and layout encoding with a cosine similarity measure to\nclassify visually-similar documents. We then demonstrate a novel application of\nmixed integer programming by using assignment optimization to extract key\ninformation from documents. Our approach is validated on an in-house dataset of\nnoisy scanned forms. The best performing document classification approach\nachieved 0.97 f1 score. A mean f1 score of 0.94 for the KIE task suggests there\nis significant potential in applying optimization techniques. Abation results\nshow that the method relies on document preprocessing techniques to mitigate\nType II errors and achieve optimal performance.",
        "translated": "我们建议采用端到端文档分类及信息抽取，以自动处理表格内的文件。通过准确的文档分类，我们利用模板中的已知信息来增强表单中的知识工具教育。我们使用文本和布局编码，并采用余弦距离度量方法对视觉上相似的文档进行分类。然后我们展示了一个新的混合整数规划的应用，通过使用分配优化从文档中提取关键信息。我们的方法是在一个有噪声的扫描表单的内部数据集上进行验证的。表现最好的文档分类得分为0.97 f1。KIE 任务的平均 f1得分为0.94，表明应用优化技术有很大的潜力。消减结果表明，该方法依赖于文档预处理技术，以减轻 II 类错误，并取得最佳性能。"
    },
    {
        "title": "TopEx: Topic-based Explanations for Model Comparison",
        "url": "http://arxiv.org/abs/2306.00976v1",
        "pub_date": "2023-06-01",
        "summary": "Meaningfully comparing language models is challenging with current\nexplanation methods. Current explanations are overwhelming for humans due to\nlarge vocabularies or incomparable across models. We present TopEx, an\nexplanation method that enables a level playing field for comparing language\nmodels via model-agnostic topics. We demonstrate how TopEx can identify\nsimilarities and differences between DistilRoBERTa and GPT-2 on a variety of\nNLP tasks.",
        "translated": "对语言模型进行有意义的比较对于当前的解释方法来说是一个挑战。目前的解释对人类来说是压倒性的，因为词汇量很大，或者在不同的模型中是无法比较的。我们提出了 TopEx，一种解释方法，使一个公平的竞争环境比较语言模型通过模型不可知的主题。我们演示了 TopEx 如何在各种 NLP 任务中识别 DistilRoBERTa 和 GPT-2之间的相似点和不同点。"
    },
    {
        "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and\n  Acceleration",
        "url": "http://arxiv.org/abs/2306.00978v1",
        "pub_date": "2023-06-01",
        "summary": "Large language models (LLMs) have shown excellent performance on various\ntasks, but the astronomical model size raises the hardware barrier for serving\n(memory size) and slows down token generation (memory bandwidth). In this\npaper, we propose Activation-aware Weight Quantization (AWQ), a\nhardware-friendly approach for LLM low-bit weight-only quantization. Our method\nis based on the observation that weights are not equally important: protecting\nonly 1% of salient weights can greatly reduce quantization error. We then\npropose to search for the optimal per-channel scaling that protects the salient\nweights by observing the activation, not weights. AWQ does not rely on any\nbackpropagation or reconstruction, so it can well preserve LLMs' generalization\nability on different domains and modalities, without overfitting to the\ncalibration set; it also does not rely on any data layout reordering,\nmaintaining the hardware efficiency. AWQ outperforms existing work on various\nlanguage modeling, common sense QA, and domain-specific benchmarks. Thanks to\nbetter generalization, it achieves excellent quantization performance for\ninstruction-tuned LMs and, for the first time, multi-modal LMs. We also\nimplement efficient tensor core kernels with reorder-free online dequantization\nto accelerate AWQ, achieving a 1.45x speedup over GPTQ and is 1.85x faster than\nthe cuBLAS FP16 implementation. Our method provides a turn-key solution to\ncompress LLMs to 3/4 bits for efficient deployment.",
        "translated": "大型语言模型(LLM)在各种任务中表现出了优异的性能，但是庞大的模型大小增加了服务的硬件障碍(内存大小) ，并减慢了令牌生成(内存带宽)。本文提出了一种基于激活感知的权重量化(AWQ)方法，用于 LLM 低比特权重量化。我们的方法是基于这样的观察: 重量并不同等重要，只保护显著重量的1% 就可以大大减少量化噪声。然后我们建议通过观察激活而不是权值来寻找保护显著权值的最佳通道尺度。AWQ 不依赖任何反向传播或重构，因此它可以很好地保持 LLM 在不同领域和模式下的泛化能力，而不会过度适应校准集; 它也不依赖任何数据布局重排序，保持硬件效率。AWQ 在各种语言建模、常识性 QA 和特定领域基准测试方面的表现优于现有的工作。由于更好的泛化，它实现了优良的量化性能的指令调谐 LM 和第一次，多模态 LM。我们还实现了高效的张量核心，无需重新排序的在线去量化来加速 AWQ，比 GPTQ 提高了1.45倍的速度，比 cuBLAS FP16实现快了1.85倍。我们的方法提供了一个交钥匙解决方案，可以将 LLM 压缩到3/4位，从而实现高效部署。"
    },
    {
        "title": "EEL: Efficiently Encoding Lattices for Reranking",
        "url": "http://arxiv.org/abs/2306.00947v1",
        "pub_date": "2023-06-01",
        "summary": "Standard decoding approaches for conditional text generation tasks typically\nsearch for an output hypothesis with high model probability, but this may not\nyield the best hypothesis according to human judgments of quality. Reranking to\noptimize for \"downstream\" metrics can better optimize for quality, but many\nmetrics of interest are computed with pre-trained language models, which are\nslow to apply to large numbers of hypotheses. We explore an approach for\nreranking hypotheses by using Transformers to efficiently encode lattices of\ngenerated outputs, a method we call EEL. With a single Transformer pass over\nthe entire lattice, we can approximately compute a contextualized\nrepresentation of each token as if it were only part of a single hypothesis in\nisolation. We combine this approach with a new class of token-factored\nrerankers (TFRs) that allow for efficient extraction of high reranker-scoring\nhypotheses from the lattice. Empirically, our approach incurs minimal\ndegradation error compared to the exponentially slower approach of encoding\neach hypothesis individually. When applying EEL with TFRs across three text\ngeneration tasks, our results show both substantial speedup compared to naive\nreranking and often better performance on downstream metrics than comparable\napproaches.",
        "translated": "条件文本生成任务的标准解码方法通常搜索具有高模型概率的输出假设，但这可能不会根据人类对质量的判断产生最佳假设。重新排序以优化“下游”指标可以更好地优化质量，但许多感兴趣的指标是使用预先训练的语言模型计算的，这些模型适用于大量假设的速度很慢。我们探索了一种重新排序假设的方法，通过使用变形金刚有效地编码生成的输出格子，一种方法，我们称之为 EEL。通过一个单变压器遍历整个格子，我们可以近似地计算每个标记的上下文化表示，就好像它只是孤立的单个假设的一部分一样。我们结合这种方法与一类新的令牌因子重排序(TFR) ，允许有效地提取高重排序得分假设从格。根据经验，我们的方法产生最小的退化误差相比，指数较慢的方法编码每个假设单独。在跨三个文本生成任务应用带 TFR 的 EEL 时，我们的结果显示，与初始重新排序相比，EEL 的速度大幅提高，而且下游指标的性能通常比可比方法更好。"
    },
    {
        "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
        "url": "http://arxiv.org/abs/2306.00946v1",
        "pub_date": "2023-06-01",
        "summary": "Why do large language models sometimes output factual inaccuracies and\nexhibit erroneous reasoning? The brittleness of these models, particularly when\nexecuting long chains of reasoning, currently seems to be an inevitable price\nto pay for their advanced capabilities of coherently synthesizing knowledge,\npragmatics, and abstract thought. Towards making sense of this fundamentally\nunsolved problem, this work identifies and analyzes the phenomenon of attention\nglitches, in which the Transformer architecture's inductive biases\nintermittently fail to capture robust reasoning. To isolate the issue, we\nintroduce flip-flop language modeling (FFLM), a parametric family of synthetic\nbenchmarks designed to probe the extrapolative behavior of neural language\nmodels. This simple generative task requires a model to copy binary symbols\nover long-range dependencies, ignoring the tokens in between. We find that\nTransformer FFLMs suffer from a long tail of sporadic reasoning errors, some of\nwhich we can eliminate using various regularization techniques. Our preliminary\nmechanistic analyses show why the remaining errors may be very difficult to\ndiagnose and resolve. We hypothesize that attention glitches account for (some\nof) the closed-domain hallucinations in natural LLMs.",
        "translated": "为什么大型语言模型有时会输出不准确的事实，并表现出错误的推理？这些模型的脆弱性，特别是在执行长链推理时，目前似乎是为其连贯综合知识、语用学和抽象思维的先进能力付出的不可避免的代价。为了理解这个根本上未解决的问题，本文识别并分析了注意小故障现象，其中变压器结构的感应偏差间歇性地不能捕获鲁棒性推理。为了隔离这个问题，我们引入了触发器语言建模(FFLM) ，这是一个参数化的合成基准，旨在探索神经语言模型的外推行为。这个简单的生成任务需要一个模型在远程依赖关系上复制二进制符号，忽略中间的标记。我们发现变压器 FFLM 存在很多零星的推理错误，我们可以使用各种正则化技术来消除其中的一些错误。我们的初步机理分析表明，为什么剩余的误差可能非常难以诊断和解决。我们假设在自然的 LLM 中，注意力失调可以解释(部分)闭域幻觉。"
    }
]