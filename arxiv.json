[
    {
        "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository\n  Mining Study",
        "url": "http://arxiv.org/abs/2305.11164v1",
        "pub_date": "2023-05-18",
        "summary": "The rise of machine learning (ML) systems has exacerbated their carbon\nfootprint due to increased capabilities and model sizes. However, there is\nscarce knowledge on how the carbon footprint of ML models is actually measured,\nreported, and evaluated. In light of this, the paper aims to analyze the\nmeasurement of the carbon footprint of 1,417 ML models and associated datasets\non Hugging Face, which is the most popular repository for pretrained ML models.\nThe goal is to provide insights and recommendations on how to report and\noptimize the carbon efficiency of ML models. The study includes the first\nrepository mining study on the Hugging Face Hub API on carbon emissions. This\nstudy seeks to answer two research questions: (1) how do ML model creators\nmeasure and report carbon emissions on Hugging Face Hub?, and (2) what aspects\nimpact the carbon emissions of training ML models? The study yielded several\nkey findings. These include a decreasing proportion of carbon\nemissions-reporting models, a slight decrease in reported carbon footprint on\nHugging Face over the past 2 years, and a continued dominance of NLP as the\nmain application domain. Furthermore, the study uncovers correlations between\ncarbon emissions and various attributes such as model size, dataset size, and\nML application domains. These results highlight the need for software\nmeasurements to improve energy reporting practices and promote carbon-efficient\nmodel development within the Hugging Face community. In response to this issue,\ntwo classifications are proposed: one for categorizing models based on their\ncarbon emission reporting practices and another for their carbon efficiency.\nThe aim of these classification proposals is to foster transparency and\nsustainable model development within the ML community.",
        "translated": "机器学习(ML)系统的兴起加剧了它们的碳足印，原因是功能和模型尺寸的增加。然而，对于机器学习模型的碳足印实际上是如何测量、报告和评估的，我们知之甚少。有鉴于此，本文旨在分析“拥抱脸”上对1417个机器学习模型及相关数据集的碳足印测量结果。“拥抱脸”是最受欢迎的预训机器学习模型库。目标是就如何报告和优化机器学习模型的碳效率提供见解和建议。这项研究包括第一个关于碳排放的拥抱面中心 API 的知识库挖掘研究。这项研究试图回答两个研究问题: (1)机器学习模型的创建者如何测量和报告拥抱面部中心的碳排放量？以及(2)哪些方面影响训练机器学习模型的碳排放量？这项研究产生了几个关键的发现。其中包括碳排放报告模型的比例下降，过去两年“拥抱脸”上的报告碳足印略有下降，以及自然语言处理作为主要应用领域的持续主导地位。此外，该研究还揭示了碳排放与模型大小、数据集大小和机器学习应用领域等各种属性之间的相关性。这些结果突出了软件测量的必要性，以改善能源报告做法，并促进在拥抱面社区的碳效率模型开发。针对这一问题，提出了两种分类: 一种是根据其碳排放报告做法对模型进行分类，另一种是根据其碳效率进行分类。这些分类建议的目的是在 ML 社区内促进透明度和可持续的模型开发。"
    },
    {
        "title": "TOME: A Two-stage Approach for Model-based Retrieval",
        "url": "http://arxiv.org/abs/2305.11161v1",
        "pub_date": "2023-05-18",
        "summary": "Recently, model-based retrieval has emerged as a new paradigm in text\nretrieval that discards the index in the traditional retrieval model and\ninstead memorizes the candidate corpora using model parameters. This design\nemploys a sequence-to-sequence paradigm to generate document identifiers, which\nenables the complete capture of the relevance between queries and documents and\nsimplifies the classic indexretrieval-rerank pipeline. Despite its attractive\nqualities, there remain several major challenges in model-based retrieval,\nincluding the discrepancy between pre-training and fine-tuning, and the\ndiscrepancy between training and inference. To deal with the above challenges,\nwe propose a novel two-stage model-based retrieval approach called TOME, which\nmakes two major technical contributions, including the utilization of tokenized\nURLs as identifiers and the design of a two-stage generation architecture. We\nalso propose a number of training strategies to deal with the training\ndifficulty as the corpus size increases. Extensive experiments and analysis on\nMS MARCO and Natural Questions demonstrate the effectiveness of our proposed\napproach, and we investigate the scaling laws of TOME by examining various\ninfluencing factors.",
        "translated": "近年来，基于模型的检索已经成为文本检索的一种新范式，它抛弃了传统检索模型中的索引，而是利用模型参数记忆候选语料库。该设计采用序列到序列的方法生成文档标识符，能够完全捕获查询和文档之间的相关性，简化了经典的索引检索-重排序流水线。尽管基于模型的检索具有吸引人的优点，但仍然存在一些主要的挑战，包括预训练和微调之间的差异，以及训练和推理之间的差异。为了应对上述挑战，我们提出了一种新的基于两阶段模型的检索方法，称为 TOME，它做出了两个主要的技术贡献，包括使用标记化 URL 作为标识符和设计一个两阶段生成体系结构。随着语料库规模的增大，我们提出了一些训练策略来解决训练难度。大量的实验和分析 MS MARCO 和自然问题证明了我们提出的方法的有效性，我们研究了 TOME 的缩放规律通过检查各种影响因素。"
    },
    {
        "title": "Preference or Intent? Double Disentangled Collaborative Filtering",
        "url": "http://arxiv.org/abs/2305.11084v1",
        "pub_date": "2023-05-18",
        "summary": "People usually have different intents for choosing items, while their\npreferences under the same intent may also different. In traditional\ncollaborative filtering approaches, both intent and preference factors are\nusually entangled in the modeling process, which significantly limits the\nrobustness and interpretability of recommendation performances. For example,\nthe low-rating items are always treated as negative feedback while they\nactually could provide positive information about user intent. To this end, in\nthis paper, we propose a two-fold representation learning approach, namely\nDouble Disentangled Collaborative Filtering (DDCF), for personalized\nrecommendations. The first-level disentanglement is for separating the\ninfluence factors of intent and preference, while the second-level\ndisentanglement is performed to build independent sparse preference\nrepresentations under individual intent with limited computational complexity.\nSpecifically, we employ two variational autoencoder networks, intent\nrecognition network and preference decomposition network, to learn the intent\nand preference factors, respectively. In this way, the low-rating items will be\ntreated as positive samples for modeling intents while the negative samples for\nmodeling preferences. Finally, extensive experiments on three real-world\ndatasets and four evaluation metrics clearly validate the effectiveness and the\ninterpretability of DDCF.",
        "translated": "人们通常有不同的意图选择项目，而他们的偏好下，相同的意图也可能有所不同。在传统的协同过滤建模方法中，意图和偏好因素通常会在建模过程中纠缠在一起，这极大地限制了推荐性能的稳健性和可解释性。例如，低等级的项目总是被视为负面反馈，而实际上它们可以提供关于用户意图的正面信息。为此，在本文中，我们提出了一种双重表征学习方法，即双重分离协同过滤(DDCF) ，用于个性化推荐。第一级解缠是为了分离意图和偏好的影响因素，而第二级解缠是为了在计算复杂度有限的个体意图下构建独立的稀疏偏好表示。具体来说，我们使用两个变分自动编码器网络，意图识别网络和偏好分解网络，分别学习意图和偏好因素。这样，低等级的项目将被视为建模意图的正面样本，而负面样本将被视为建模偏好。最后，在三个实际数据集和四个评价指标上进行了广泛的实验，验证了 DDCF 的有效性和可解释性。"
    },
    {
        "title": "AMR4NLI: Interpretable and robust NLI measures from semantic graphs",
        "url": "http://arxiv.org/abs/2306.00936v1",
        "pub_date": "2023-06-01",
        "summary": "The task of natural language inference (NLI) asks whether a given premise\n(expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human\nratings of entailment, but the meaning relationships driving these ratings are\nnot formalized. Can the underlying sentence pair relationships be made more\nexplicit in an interpretable yet robust fashion? We compare semantic structures\nto represent premise and hypothesis, including sets of contextualized\nembeddings and semantic graphs (Abstract Meaning Representations), and measure\nwhether the hypothesis is a semantic substructure of the premise, utilizing\ninterpretable metrics. Our evaluation on three English benchmarks finds value\nin both contextualized embeddings and semantic graphs; moreover, they provide\ncomplementary signals, and can be leveraged together in a hybrid model.",
        "translated": "自然语言推理的任务是询问一个给定的前提(用自然语言表示)是否包含一个给定的自然语言假设。NLI 基准包含人工赋值评级，但是驱动这些评级的意义关系并没有形式化。潜在的句子对关系是否可以以一种可解释的、强有力的方式更明确地表达出来？我们比较了表示前提和假设的语义结构，包括语境化嵌入和语义图集(抽象意义表示) ，并利用可解释的度量衡量假设是否是前提的语义子结构。我们对三个英语基准测试的评估发现了上下文嵌入和语义图的价值; 此外，它们提供了互补的信号，并且可以在混合模型中一起使用。"
    },
    {
        "title": "ACLM: A Selective-Denoising based Generative Data Augmentation Approach\n  for Low-Resource Complex NER",
        "url": "http://arxiv.org/abs/2306.00928v1",
        "pub_date": "2023-06-01",
        "summary": "Complex Named Entity Recognition (NER) is the task of detecting\nlinguistically complex named entities in low-context text. In this paper, we\npresent ACLM Attention-map aware keyword selection for Conditional Language\nModel fine-tuning), a novel data augmentation approach based on conditional\ngeneration to address the data scarcity problem in low-resource complex NER.\nACLM alleviates the context-entity mismatch issue, a problem existing NER data\naugmentation techniques suffer from and often generates incoherent\naugmentations by placing complex named entities in the wrong context. ACLM\nbuilds on BART and is optimized on a novel text reconstruction or denoising\ntask - we use selective masking (aided by attention maps) to retain the named\nentities and certain keywords in the input sentence that provide contextually\nrelevant additional knowledge or hints about the named entities. Compared with\nother data augmentation strategies, ACLM can generate more diverse and coherent\naugmentations preserving the true word sense of complex entities in the\nsentence. We demonstrate the effectiveness of ACLM both qualitatively and\nquantitatively on monolingual, cross-lingual, and multilingual complex NER\nacross various low-resource settings. ACLM outperforms all our neural baselines\nby a significant margin (1%-36%). In addition, we demonstrate the application\nof ACLM to other domains that suffer from data scarcity (e.g., biomedical). In\npractice, ACLM generates more effective and factual augmentations for these\ndomains than prior methods. Code: https://github.com/Sreyan88/ACLM",
        "translated": "复杂命名实体识别(NER)是在低语境文本中检测语言复杂命名实体的任务。针对低资源复杂 NER 中的数据稀缺问题，提出了一种基于条件生成的数据增强方法—— ACLM 注意图感知的条件语言模型关键词选择方法。ACLM 缓解了上下文-实体不匹配问题，这是现有的 NER 数据增强技术所面临的问题，并且通常通过将复杂的命名实体放置在错误的上下文中而产生不一致的增强。ACLM 建立在 BART 的基础上，针对一个新的文本重建或去噪任务进行优化——我们使用选择性掩蔽(通过注意力地图辅助)来保留输入句中的命名实体和某些关键字，这些关键字提供了与上下文相关的附加知识或关于命名实体的提示。与其他数据增强策略相比，ACLM 能够产生更多样化和连贯的增强，保持句子中复杂实体的真实词义。我们证明了 ACLM 在定性和定量上对不同低资源环境下的单语言、跨语言和多语言复杂 NER 的有效性。ACLM 比我们所有的神经基线都要好得多(1% -36%)。此外，我们还展示了 ACLM 在其他数据稀缺领域(如生物医学)的应用。在实践中，ACLM 为这些领域产生了比以前的方法更有效和实际的增强。密码:  https://github.com/sreyan88/aclm"
    },
    {
        "title": "SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in\n  Graph Neural Networks",
        "url": "http://arxiv.org/abs/2306.00899v1",
        "pub_date": "2023-06-01",
        "summary": "Graph Neural Networks (GNNs) have demonstrated promising outcomes across\nvarious tasks, including node classification and link prediction. Despite their\nremarkable success in various high-impact applications, we have identified\nthree common pitfalls in message passing for link prediction. Particularly, in\nprevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges\n(i.e., the edges being predicted) consistently exist as message passing edges\nin the graph during training. Consequently, this results in overfitting and\ndistribution shift, both of which adversely impact the generalizability to test\nthe target edges. Additionally, during test time, the failure to exclude the\ntest target edges leads to implicit test leakage caused by neighborhood\naggregation. In this paper, we analyze these three pitfalls and investigate the\nimpact of including or excluding target edges on the performance of nodes with\nvarying degrees during training and test phases. Our theoretical and empirical\nanalysis demonstrates that low-degree nodes are more susceptible to these\npitfalls. These pitfalls can have detrimental consequences when GNNs are\nimplemented in production systems. To systematically address these pitfalls, we\npropose SpotTarget, an effective and efficient GNN training framework. During\ntraining, SpotTarget leverages our insight regarding low-degree nodes and\nexcludes train target edges connected to at least one low-degree node. During\ntest time, it emulates real-world scenarios of GNN usage in production and\nexcludes all test target edges. Our experiments conducted on diverse real-world\ndatasets, demonstrate that SpotTarget significantly enhances GNNs, achieving up\nto a 15x increase in accuracy in sparse graphs. Furthermore, SpotTarget\nconsistently and dramatically improves the performance for low-degree nodes in\ndense graphs.",
        "translated": "图形神经网络(GNN)在各种任务中，包括节点分类和链路预测，都取得了很好的效果。尽管它们在各种高影响力的应用程序中取得了显著的成功，但是我们已经确定了链接预测中消息传递的三个常见缺陷。特别是，在流行的 GNN 框架(例如，DGL 和 PyTorch-Geometer)中，目标边(例如，被预测的边)在训练期间始终作为图中的消息传递边存在。因此，这会导致过拟合和分布偏移，这两者都会对测试目标边缘的通用性产生不利影响。此外，在测试时间内，未能排除测试目标边缘会导致由邻域聚合引起的隐式测试泄漏。在本文中，我们分析了这三个陷阱，并研究了在训练和测试阶段包含或排除目标边对不同程度的节点性能的影响。我们的理论和实证分析表明，低度节点更容易受到这些陷阱的影响。当 GNN 在生产系统中实现时，这些缺陷可能会产生有害的后果。为了系统地解决这些缺陷，我们提出了 SpotTarget，一个高效的 GNN 训练框架。在训练过程中，SpotTarget 利用我们对低度节点的洞察力，排除了连接到至少一个低度节点的训练目标边缘。在测试期间，它模拟生产中 GNN 使用的真实场景，并排除所有测试目标边缘。我们在不同的真实世界数据集上进行的实验表明，SpotTarget 显著地增强了 GNN，在稀疏图中实现了高达15倍的精度提高。此外，SpotTarget 持续而显著地改善了稠密图中低度节点的性能。"
    },
    {
        "title": "Topic-Guided Sampling For Data-Efficient Multi-Domain Stance Detection",
        "url": "http://arxiv.org/abs/2306.00765v1",
        "pub_date": "2023-06-01",
        "summary": "Stance Detection is concerned with identifying the attitudes expressed by an\nauthor towards a target of interest. This task spans a variety of domains\nranging from social media opinion identification to detecting the stance for a\nlegal claim. However, the framing of the task varies within these domains, in\nterms of the data collection protocol, the label dictionary and the number of\navailable annotations. Furthermore, these stance annotations are significantly\nimbalanced on a per-topic and inter-topic basis. These make multi-domain stance\ndetection a challenging task, requiring standardization and domain adaptation.\nTo overcome this challenge, we propose $\\textbf{T}$opic $\\textbf{E}$fficient\n$\\textbf{St}$anc$\\textbf{E}$ $\\textbf{D}$etection (TESTED), consisting of a\ntopic-guided diversity sampling technique and a contrastive objective that is\nused for fine-tuning a stance classifier. We evaluate the method on an existing\nbenchmark of $16$ datasets with in-domain, i.e. all topics seen and\nout-of-domain, i.e. unseen topics, experiments. The results show that our\nmethod outperforms the state-of-the-art with an average of $3.5$ F1 points\nincrease in-domain, and is more generalizable with an averaged increase of\n$10.2$ F1 on out-of-domain evaluation while using $\\leq10\\%$ of the training\ndata. We show that our sampling technique mitigates both inter- and per-topic\nclass imbalances. Finally, our analysis demonstrates that the contrastive\nlearning objective allows the model a more pronounced segmentation of samples\nwith varying labels.",
        "translated": "姿势检测是指识别作者对于感兴趣的目标所表达的态度。这项任务涉及从社交媒体舆论识别到检测法律诉求立场等多个领域。然而，在这些领域内，任务的框架在数据收集协议、标签字典和可用注释的数量方面有所不同。此外，这些立场注释在每个主题和主题间的基础上显著不平衡。这使得多域姿态检测成为一项具有挑战性的任务，需要标准化和域自适应。为了克服这个挑战，我们提出了 $textbf { T } $opic $textbf { E } $ffical$textbf { St } $anc $textbf { E } $textbf { D } $etection (TESTED) ，包括一个主题引导的多样性采样技术和一个用于微调立场分类器的对比目标。我们评估的方法，在一个现有的基准 $16 $数据集与域内，即所有主题看到和域外，即看不到的主题，实验。结果表明，我们的方法优于国家的最新技术，平均 $3.5 $F1点在域内增加，更具普遍性，平均增加 $10.2 $F1在域外评估，同时使用 $leq10% $的训练数据。我们展示了我们的抽样技术缓解了主题间和主题间的类不平衡。最后，我们的分析表明，对比学习的目标允许模型更明显的样本分割与不同的标签。"
    },
    {
        "title": "End-to-End Document Classification and Key Information Extraction using\n  Assignment Optimization",
        "url": "http://arxiv.org/abs/2306.00750v1",
        "pub_date": "2023-06-01",
        "summary": "We propose end-to-end document classification and key information extraction\n(KIE) for automating document processing in forms. Through accurate document\nclassification we harness known information from templates to enhance KIE from\nforms. We use text and layout encoding with a cosine similarity measure to\nclassify visually-similar documents. We then demonstrate a novel application of\nmixed integer programming by using assignment optimization to extract key\ninformation from documents. Our approach is validated on an in-house dataset of\nnoisy scanned forms. The best performing document classification approach\nachieved 0.97 f1 score. A mean f1 score of 0.94 for the KIE task suggests there\nis significant potential in applying optimization techniques. Abation results\nshow that the method relies on document preprocessing techniques to mitigate\nType II errors and achieve optimal performance.",
        "translated": "我们建议采用端到端文档分类及信息抽取，以自动处理表格内的文件。通过准确的文档分类，我们利用模板中的已知信息来增强表单中的知识工具教育。我们使用文本和布局编码，并采用余弦距离度量方法对视觉上相似的文档进行分类。然后我们展示了一个新的混合整数规划的应用，通过使用分配优化从文档中提取关键信息。我们的方法是在一个有噪声的扫描表单的内部数据集上进行验证的。表现最好的文档分类得分为0.97 f1。KIE 任务的平均 f1得分为0.94，表明应用优化技术有很大的潜力。消减结果表明，该方法依赖于文档预处理技术，以减轻 II 类错误，并取得最佳性能。"
    },
    {
        "title": "TopEx: Topic-based Explanations for Model Comparison",
        "url": "http://arxiv.org/abs/2306.00976v1",
        "pub_date": "2023-06-01",
        "summary": "Meaningfully comparing language models is challenging with current\nexplanation methods. Current explanations are overwhelming for humans due to\nlarge vocabularies or incomparable across models. We present TopEx, an\nexplanation method that enables a level playing field for comparing language\nmodels via model-agnostic topics. We demonstrate how TopEx can identify\nsimilarities and differences between DistilRoBERTa and GPT-2 on a variety of\nNLP tasks.",
        "translated": "对语言模型进行有意义的比较对于当前的解释方法来说是一个挑战。目前的解释对人类来说是压倒性的，因为词汇量很大，或者在不同的模型中是无法比较的。我们提出了 TopEx，一种解释方法，使一个公平的竞争环境比较语言模型通过模型不可知的主题。我们演示了 TopEx 如何在各种 NLP 任务中识别 DistilRoBERTa 和 GPT-2之间的相似点和不同点。"
    },
    {
        "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and\n  Acceleration",
        "url": "http://arxiv.org/abs/2306.00978v1",
        "pub_date": "2023-06-01",
        "summary": "Large language models (LLMs) have shown excellent performance on various\ntasks, but the astronomical model size raises the hardware barrier for serving\n(memory size) and slows down token generation (memory bandwidth). In this\npaper, we propose Activation-aware Weight Quantization (AWQ), a\nhardware-friendly approach for LLM low-bit weight-only quantization. Our method\nis based on the observation that weights are not equally important: protecting\nonly 1% of salient weights can greatly reduce quantization error. We then\npropose to search for the optimal per-channel scaling that protects the salient\nweights by observing the activation, not weights. AWQ does not rely on any\nbackpropagation or reconstruction, so it can well preserve LLMs' generalization\nability on different domains and modalities, without overfitting to the\ncalibration set; it also does not rely on any data layout reordering,\nmaintaining the hardware efficiency. AWQ outperforms existing work on various\nlanguage modeling, common sense QA, and domain-specific benchmarks. Thanks to\nbetter generalization, it achieves excellent quantization performance for\ninstruction-tuned LMs and, for the first time, multi-modal LMs. We also\nimplement efficient tensor core kernels with reorder-free online dequantization\nto accelerate AWQ, achieving a 1.45x speedup over GPTQ and is 1.85x faster than\nthe cuBLAS FP16 implementation. Our method provides a turn-key solution to\ncompress LLMs to 3/4 bits for efficient deployment.",
        "translated": "大型语言模型(LLM)在各种任务中表现出了优异的性能，但是庞大的模型大小增加了服务的硬件障碍(内存大小) ，并减慢了令牌生成(内存带宽)。本文提出了一种基于激活感知的权重量化(AWQ)方法，用于 LLM 低比特权重量化。我们的方法是基于这样的观察: 重量并不同等重要，只保护显著重量的1% 就可以大大减少量化噪声。然后我们建议通过观察激活而不是权值来寻找保护显著权值的最佳通道尺度。AWQ 不依赖任何反向传播或重构，因此它可以很好地保持 LLM 在不同领域和模式下的泛化能力，而不会过度适应校准集; 它也不依赖任何数据布局重排序，保持硬件效率。AWQ 在各种语言建模、常识性 QA 和特定领域基准测试方面的表现优于现有的工作。由于更好的泛化，它实现了优良的量化性能的指令调谐 LM 和第一次，多模态 LM。我们还实现了高效的张量核心，无需重新排序的在线去量化来加速 AWQ，比 GPTQ 提高了1.45倍的速度，比 cuBLAS FP16实现快了1.85倍。我们的方法提供了一个交钥匙解决方案，可以将 LLM 压缩到3/4位，从而实现高效部署。"
    },
    {
        "title": "EEL: Efficiently Encoding Lattices for Reranking",
        "url": "http://arxiv.org/abs/2306.00947v1",
        "pub_date": "2023-06-01",
        "summary": "Standard decoding approaches for conditional text generation tasks typically\nsearch for an output hypothesis with high model probability, but this may not\nyield the best hypothesis according to human judgments of quality. Reranking to\noptimize for \"downstream\" metrics can better optimize for quality, but many\nmetrics of interest are computed with pre-trained language models, which are\nslow to apply to large numbers of hypotheses. We explore an approach for\nreranking hypotheses by using Transformers to efficiently encode lattices of\ngenerated outputs, a method we call EEL. With a single Transformer pass over\nthe entire lattice, we can approximately compute a contextualized\nrepresentation of each token as if it were only part of a single hypothesis in\nisolation. We combine this approach with a new class of token-factored\nrerankers (TFRs) that allow for efficient extraction of high reranker-scoring\nhypotheses from the lattice. Empirically, our approach incurs minimal\ndegradation error compared to the exponentially slower approach of encoding\neach hypothesis individually. When applying EEL with TFRs across three text\ngeneration tasks, our results show both substantial speedup compared to naive\nreranking and often better performance on downstream metrics than comparable\napproaches.",
        "translated": "条件文本生成任务的标准解码方法通常搜索具有高模型概率的输出假设，但这可能不会根据人类对质量的判断产生最佳假设。重新排序以优化“下游”指标可以更好地优化质量，但许多感兴趣的指标是使用预先训练的语言模型计算的，这些模型适用于大量假设的速度很慢。我们探索了一种重新排序假设的方法，通过使用变形金刚有效地编码生成的输出格子，一种方法，我们称之为 EEL。通过一个单变压器遍历整个格子，我们可以近似地计算每个标记的上下文化表示，就好像它只是孤立的单个假设的一部分一样。我们结合这种方法与一类新的令牌因子重排序(TFR) ，允许有效地提取高重排序得分假设从格。根据经验，我们的方法产生最小的退化误差相比，指数较慢的方法编码每个假设单独。在跨三个文本生成任务应用带 TFR 的 EEL 时，我们的结果显示，与初始重新排序相比，EEL 的速度大幅提高，而且下游指标的性能通常比可比方法更好。"
    },
    {
        "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
        "url": "http://arxiv.org/abs/2306.00946v1",
        "pub_date": "2023-06-01",
        "summary": "Why do large language models sometimes output factual inaccuracies and\nexhibit erroneous reasoning? The brittleness of these models, particularly when\nexecuting long chains of reasoning, currently seems to be an inevitable price\nto pay for their advanced capabilities of coherently synthesizing knowledge,\npragmatics, and abstract thought. Towards making sense of this fundamentally\nunsolved problem, this work identifies and analyzes the phenomenon of attention\nglitches, in which the Transformer architecture's inductive biases\nintermittently fail to capture robust reasoning. To isolate the issue, we\nintroduce flip-flop language modeling (FFLM), a parametric family of synthetic\nbenchmarks designed to probe the extrapolative behavior of neural language\nmodels. This simple generative task requires a model to copy binary symbols\nover long-range dependencies, ignoring the tokens in between. We find that\nTransformer FFLMs suffer from a long tail of sporadic reasoning errors, some of\nwhich we can eliminate using various regularization techniques. Our preliminary\nmechanistic analyses show why the remaining errors may be very difficult to\ndiagnose and resolve. We hypothesize that attention glitches account for (some\nof) the closed-domain hallucinations in natural LLMs.",
        "translated": "为什么大型语言模型有时会输出不准确的事实，并表现出错误的推理？这些模型的脆弱性，特别是在执行长链推理时，目前似乎是为其连贯综合知识、语用学和抽象思维的先进能力付出的不可避免的代价。为了理解这个根本上未解决的问题，本文识别并分析了注意小故障现象，其中变压器结构的感应偏差间歇性地不能捕获鲁棒性推理。为了隔离这个问题，我们引入了触发器语言建模(FFLM) ，这是一个参数化的合成基准，旨在探索神经语言模型的外推行为。这个简单的生成任务需要一个模型在远程依赖关系上复制二进制符号，忽略中间的标记。我们发现变压器 FFLM 存在很多零星的推理错误，我们可以使用各种正则化技术来消除其中的一些错误。我们的初步机理分析表明，为什么剩余的误差可能非常难以诊断和解决。我们假设在自然的 LLM 中，注意力失调可以解释(部分)闭域幻觉。"
    },
    {
        "title": "\"Let's not Quote out of Context\": Unified Vision-Language Pretraining\n  for Context Assisted Image Captioning",
        "url": "http://arxiv.org/abs/2306.00931v1",
        "pub_date": "2023-06-01",
        "summary": "Well-formed context aware image captions and tags in enterprise content such\nas marketing material are critical to ensure their brand presence and content\nrecall. Manual creation and updates to ensure the same is non trivial given the\nscale and the tedium towards this task. We propose a new unified\nVision-Language (VL) model based on the One For All (OFA) model, with a focus\non context-assisted image captioning where the caption is generated based on\nboth the image and its context. Our approach aims to overcome the\ncontext-independent (image and text are treated independently) nature of the\nexisting approaches. We exploit context by pretraining our model with datasets\nof three tasks: news image captioning where the news article is the context,\ncontextual visual entailment, and keyword extraction from the context. The\nsecond pretraining task is a new VL task, and we construct and release two\ndatasets for the task with 1.1M and 2.2K data instances. Our system achieves\nstate-of-the-art results with an improvement of up to 8.34 CIDEr score on the\nbenchmark news image captioning datasets. To the best of our knowledge, ours is\nthe first effort at incorporating contextual information in pretraining the\nmodels for the VL tasks.",
        "translated": "在企业内容(如营销材料)中形成良好的上下文感知图像标题和标签对于确保其品牌存在和内容召回至关重要。手工创建和更新，以确保相同的是不平凡的规模和乏味的这项任务。我们提出了一个新的统一的视觉语言(VL)模型的基础上的一个为所有(OFA)模型，重点是上下文辅助图像字幕生成的标题是基于图像和它的上下文。我们的方法旨在克服现有方法的上下文无关性(图像和文本是独立处理的)。我们利用上下文预训练我们的模型与三个任务的数据集: 新闻图像字幕，其中的新闻文章是上下文，上下文视觉暗示，和关键字提取从上下文。第二个预训练任务是一个新的 VL 任务，我们用1.1 M 和2.2 K 的数据实例构造并发布了两个任务数据集。我们的系统取得了最先进的成果，在基准的新闻图像字幕数据集上提高了高达8.34 CIDEr 得分。据我们所知，我们是第一次尝试将上下文信息合并到 VL 任务的模型预训练中。"
    },
    {
        "title": "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play\n  Multi-Character Belief Tracker",
        "url": "http://arxiv.org/abs/2306.00924v1",
        "pub_date": "2023-06-01",
        "summary": "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\nstates of other people$\\unicode{x2014}$is a key element of our social\nintelligence. Yet, despite their ever more impressive performance, large-scale\nneural language models still lack basic theory of mind capabilities\nout-of-the-box. We posit that simply scaling up models will not imbue them with\ntheory of mind due to the inherently symbolic and implicit nature of the\nphenomenon, and instead investigate an alternative: can we design a\ndecoding-time algorithm that enhances theory of mind of off-the-shelf neural\nlanguage models without explicit supervision? We present SymbolicToM, a\nplug-and-play approach to reason about the belief states of multiple characters\nin reading comprehension tasks via explicit symbolic representation. More\nconcretely, our approach tracks each entity's beliefs, their estimation of\nother entities' beliefs, and higher-order levels of reasoning, all through\ngraphical representations, allowing for more precise and interpretable\nreasoning than previous approaches. Empirical results on the well-known ToMi\nbenchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\noff-the-shelf neural networks' theory of mind in a zero-shot setting while\nshowing robust out-of-distribution performance compared to supervised\nbaselines. Our work also reveals spurious patterns in existing theory of mind\nbenchmarks, emphasizing the importance of out-of-distribution evaluation and\nmethods that do not overfit a particular dataset.",
        "translated": "心理理论对他人心理状态进行推理的能力是我们社会智力的一个关键因素。然而，尽管大规模神经语言模型的表现越来越令人印象深刻，它们仍然缺乏开箱即用的思维能力的基本理论。我们假定，由于这种现象固有的象征性和隐含性，简单地扩大模型不会给它们灌输心智理论，而是研究另一种选择: 我们能否设计一种解码时间算法，在没有明确监督的情况下增强现成神经语言模型的心智理论？我们展示了 SymbolicToM，一种即插即用的方法，通过显式的符号表示来推断阅读理解任务中多个角色的信念状态。更具体地说，我们的方法跟踪每个实体的信念，他们对其他实体信念的估计，以及更高层次的推理，所有这些都通过图形表示，允许比以前的方法更精确和可解释的推理。著名的 ToMi 基准测试(Le et al。 ，2019)的实验结果表明，SymbolicToM 显著增强了现成的神经网络的心智理论，在零拍设置，同时显示出稳健的分布外性能相比，监督基线。我们的工作还揭示了现有心智基准理论中的虚假模式，强调了分布外评估的重要性，以及不适合特定数据集的方法。"
    },
    {
        "title": "T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image\n  Generation",
        "url": "http://arxiv.org/abs/2306.00905v1",
        "pub_date": "2023-06-01",
        "summary": "Warning: This paper contains several contents that may be toxic, harmful, or\noffensive.\n  In the last few years, text-to-image generative models have gained remarkable\nsuccess in generating images with unprecedented quality accompanied by a\nbreakthrough of inference speed. Despite their rapid progress, human biases\nthat manifest in the training examples, particularly with regard to common\nstereotypical biases, like gender and skin tone, still have been found in these\ngenerative models. In this work, we seek to measure more complex human biases\nexist in the task of text-to-image generations. Inspired by the well-known\nImplicit Association Test (IAT) from social psychology, we propose a novel\nText-to-Image Association Test (T2IAT) framework that quantifies the implicit\nstereotypes between concepts and valence, and those in the images. We replicate\nthe previously documented bias tests on generative models, including morally\nneutral tests on flowers and insects as well as demographic stereotypical tests\non diverse social attributes. The results of these experiments demonstrate the\npresence of complex stereotypical behaviors in image generations.",
        "translated": "警告: 本文件含有多种内容，可能是有毒的，有害的，或攻击性。在过去的几年中，文本到图像的生成模型在生成具有前所未有质量的图像方面取得了显著的成功，同时推理速度也有了突破。尽管进展迅速，但在这些生成模型中仍然发现了在训练实例中表现出来的人为偏见，特别是在性别和肤色等常见的陈规定型偏见方面。在这项工作中，我们试图测量更复杂的人类偏见存在于文本到图像的生成任务。受到来自社会心理学的著名隐含尺度(IAT)的启发，我们提出了一个新颖的文本-图像关联测试(t2IAT)框架，它量化了概念和效价之间以及图像中的内隐刻板印象。我们在生殖模型上重复之前记录的偏见测试，包括对花和昆虫的道德中立测试，以及对不同社会属性的人口统计学刻板印象测试。实验结果表明，在图像生成过程中存在复杂的刻板印象行为。"
    },
    {
        "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for\n  Biomedicine in One Day",
        "url": "http://arxiv.org/abs/2306.00890v1",
        "pub_date": "2023-06-01",
        "summary": "Conversational generative AI has demonstrated remarkable promise for\nempowering biomedical practitioners, but current investigations focus on\nunimodal text. Multimodal conversational AI has seen rapid progress by\nleveraging billions of image-text pairs from the public web, but such\ngeneral-domain vision-language models still lack sophistication in\nunderstanding and conversing about biomedical images. In this paper, we propose\na cost-efficient approach for training a vision-language conversational\nassistant that can answer open-ended research questions of biomedical images.\nThe key idea is to leverage a large-scale, broad-coverage biomedical\nfigure-caption dataset extracted from PubMed Central, use GPT-4 to\nself-instruct open-ended instruction-following data from the captions, and then\nfine-tune a large general-domain vision-language model using a novel curriculum\nlearning method. Specifically, the model first learns to align biomedical\nvocabulary using the figure-caption pairs as is, then learns to master\nopen-ended conversational semantics using GPT-4 generated instruction-following\ndata, broadly mimicking how a layperson gradually acquires biomedical\nknowledge. This enables us to train a Large Language and Vision Assistant for\nBioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med\nexhibits excellent multimodal conversational capability and can follow\nopen-ended instruction to assist with inquiries about a biomedical image. On\nthree standard biomedical visual question answering datasets, LLaVA-Med\noutperforms previous supervised state-of-the-art on certain metrics. To\nfacilitate biomedical multimodal research, we will release our\ninstruction-following data and the LLaVA-Med model.",
        "translated": "对话生成 AI 已经显示了赋予生物医学从业人员显着的前景，但目前的研究侧重于单一模式的文本。通过利用来自公共网络的数十亿个图像-文本对，多模式会话人工智能已经取得了迅速的进展，但是这种通用领域的视觉-语言模型在理解和对生物医学图像进行会话方面仍然缺乏先进性。本文针对生物医学图像的开放式研究问题，提出了一种具有成本效益的视觉语言会话助手培训方法。其关键思想是利用从 PubMed Central 提取的大规模、广泛覆盖的生物医学图形标题数据集，使用 GPT-4自我指导开放式教学——跟随标题中的数据，然后使用新的课程学习方法微调大型通用领域视觉语言模型。具体而言，该模型首先学习使用图标-标题对来校准生物医学词汇，然后学习使用 GPT-4生成的指令跟踪数据来掌握开放式会话语义，广泛地模仿外行如何逐渐获得生物医学知识。这使得我们能够在不到15个小时的时间内培训一个大型语言和视觉生物医学助手(LLaVA-Med)(有8个 A100s)。LLaVA-Med 具有优秀的多通道会话能力，可以遵循开放式指导，以协助有关生物医学图像的查询。在三个标准的生物医学视觉问答数据集上，LLaVA-Med 在某些指标上优于先前监督的最先进水平。为了促进生物医学多模式研究，我们将发布我们的指令跟踪数据和 LLaVA-Med 模型。"
    },
    {
        "title": "Fresh Content Needs More Attention: Multi-funnel Fresh Content\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.01720v1",
        "pub_date": "2023-06-02",
        "summary": "Recommendation system serves as a conduit connecting users to an incredibly\nlarge, diverse and ever growing collection of contents. In practice, missing\ninformation on fresh (and tail) contents needs to be filled in order for them\nto be exposed and discovered by their audience. We here share our success\nstories in building a dedicated fresh content recommendation stack on a large\ncommercial platform. To nominate fresh contents, we built a multi-funnel\nnomination system that combines (i) a two-tower model with strong\ngeneralization power for coverage, and (ii) a sequence model with near\nreal-time update on user feedback for relevance. The multi-funnel setup\neffectively balances between coverage and relevance. An in-depth study uncovers\nthe relationship between user activity level and their proximity toward fresh\ncontents, which further motivates a contextual multi-funnel setup. Nominated\nfresh candidates are then scored and ranked by systems considering prediction\nuncertainty to further bootstrap content with less exposure. We evaluate the\nbenefits of the dedicated fresh content recommendation stack, and the\nmulti-funnel nomination system in particular, through user corpus co-diverted\nlive experiments. We conduct multiple rounds of live experiments on a\ncommercial platform serving billion of users demonstrating efficacy of our\nproposed methods.",
        "translated": "推荐系统作为一个渠道，连接用户到一个令人难以置信的庞大，多样化和不断增长的内容集合。在实践中，需要填补关于新鲜(和尾部)内容的缺失信息，以便它们被观众暴露和发现。我们在这里分享我们在一个大型商业平台上建立一个专门的新内容推荐堆栈的成功故事。为了提名新的内容，我们建立了一个多漏斗提名系统，该系统结合了(i)一个具有很强覆盖泛化能力的双塔模型和(ii)一个具有近实时更新用户反馈相关性的序列模型。多漏斗设置有效地平衡了覆盖率和相关性。深入的研究揭示了用户活动水平与其接近新鲜内容之间的关系，进一步激发了上下文多漏斗设置。提名的新鲜候选人，然后得分和排名的系统考虑预测不确定性，以进一步引导内容，较少的曝光。我们通过用户语料库共转向现场实验，评估了专用新鲜内容推荐堆栈的优点，尤其是多漏斗提名系统。我们在一个为数十亿用户服务的商业平台上进行多轮实验，证明我们提出的方法的有效性。"
    },
    {
        "title": "Pretrained Language Model based Web Search Ranking: From Relevance to\n  Satisfaction",
        "url": "http://arxiv.org/abs/2306.01599v1",
        "pub_date": "2023-06-02",
        "summary": "Search engine plays a crucial role in satisfying users' diverse information\nneeds. Recently, Pretrained Language Models (PLMs) based text ranking models\nhave achieved huge success in web search. However, many state-of-the-art text\nranking approaches only focus on core relevance while ignoring other dimensions\nthat contribute to user satisfaction, e.g., document quality, recency,\nauthority, etc. In this work, we focus on ranking user satisfaction rather than\nrelevance in web search, and propose a PLM-based framework, namely SAT-Ranker,\nwhich comprehensively models different dimensions of user satisfaction in a\nunified manner. In particular, we leverage the capacities of PLMs on both\ntextual and numerical inputs, and apply a multi-field input that modularizes\neach dimension of user satisfaction as an input field. Overall, SAT-Ranker is\nan effective, extensible, and data-centric framework that has huge potential\nfor industrial applications. On rigorous offline and online experiments,\nSAT-Ranker obtains remarkable gains on various evaluation sets targeting\ndifferent dimensions of user satisfaction. It is now fully deployed online to\nimprove the usability of our search engine.",
        "translated": "搜索引擎在满足用户多样化的信息需求方面起着至关重要的作用。近年来，基于预训练语言模型(PLM)的文本排序模型在网络搜索领域取得了巨大的成功。然而，许多最先进的文本排名方法只关注核心相关性，而忽略了有助于用户满意度的其他方面，如文档质量、最新性、权威性等。在这项工作中，我们的重点是排名用户满意度而不是相关性的网络搜索，并提出了一个基于 PLM 的框架，即 SAT-Ranker，它综合模型的不同维度的用户满意度在统一的方式。特别是，我们利用 PLM 在文本和数字输入方面的能力，并应用多领域的输入，将用户满意度的每个维度模块化，作为输入领域。总的来说，SAT-Ranker 是一个有效的、可扩展的、以数据为中心的框架，在工业应用方面具有巨大的潜力。在严格的离线和在线实验中，SAT-Ranker 在针对不同用户满意度维度的各种评价集上取得了显著的效果。它现在已经完全部署在网上，以提高我们的搜索引擎的可用性。"
    },
    {
        "title": "Influence Maximization with Fairness at Scale (Extended Version)",
        "url": "http://arxiv.org/abs/2306.01587v1",
        "pub_date": "2023-06-02",
        "summary": "In this paper, we revisit the problem of influence maximization with\nfairness, which aims to select k influential nodes to maximise the spread of\ninformation in a network, while ensuring that selected sensitive user\nattributes are fairly affected, i.e., are proportionally similar between the\noriginal network and the affected users. Recent studies on this problem focused\nonly on extremely small networks, hence the challenge remains on how to achieve\na scalable solution, applicable to networks with millions or billions of nodes.\nWe propose an approach that is based on learning node representations for fair\nspread from diffusion cascades, instead of the social connectivity s.t. we can\ndeal with very large graphs. We propose two data-driven approaches: (a)\nfairness-based participant sampling (FPS), and (b) fairness as context (FAC).\nSpread related user features, such as the probability of diffusing information\nto others, are derived from the historical information cascades, using a deep\nneural network. The extracted features are then used in selecting influencers\nthat maximize the influence spread, while being also fair with respect to the\nchosen sensitive attributes. In FPS, fairness and cascade length information\nare considered independently in the decision-making process, while FAC\nconsiders these information facets jointly and considers correlations between\nthem. The proposed algorithms are generic and represent the first policy-driven\nsolutions that can be applied to arbitrary sets of sensitive attributes at\nscale. We evaluate the performance of our solutions on a real-world public\ndataset (Sina Weibo) and on a hybrid real-synthethic dataset (Digg), which\nexhibit all the facets that we exploit, namely diffusion network, diffusion\ntraces, and user profiles. These experiments show that our methods outperform\nthe state-the-art solutions in terms of spread, fairness, and scalability.",
        "translated": "本文重新讨论了公平影响最大化问题，其目的是选择 k 个有影响的节点以使网络中的信息传播最大化，同时确保选择的敏感用户属性受到相当大的影响，即原始网络与受影响用户之间的比例相似。最近关于这个问题的研究只集中在极小的网络上，因此挑战仍然是如何实现一个可伸缩的解决方案，适用于拥有数百万或数十亿个节点的网络。我们提出了一种基于学习节点表示的扩散级联公平扩散方法，代替了社会连通性方法，我们可以处理非常大的图。我们提出两种数据驱动的方法: (a)基于公平的参与者抽样(FPS)和(b)作为上下文的公平(FAC)。传播相关的用户特征，如向他人传播信息的概率，是从历史信息级联，使用深度神经网络推导出来的。然后将提取的特征用于选择影响者，使影响扩散最大化，同时对所选择的敏感属性也是公平的。在 FPS 中，公平性和级联长度信息在决策过程中被独立地考虑，而 FAC 则联合考虑这些信息方面，并考虑它们之间的相关性。提出的算法是通用的，代表了第一个策略驱动的解决方案，可以应用于任意集的敏感属性在规模。我们在一个真实世界的公共数据集(新浪微博)和一个混合的真实合成数据集(Digg)上评估我们的解决方案的性能，这些数据集展示了我们利用的所有方面，即扩散网络、扩散轨迹和用户配置文件。这些实验表明，我们的方法在扩展性、公平性和可伸缩性方面优于最先进的解决方案。"
    },
    {
        "title": "Système de recommandations basé sur les contraintes pour les\n  simulations de gestion de crise",
        "url": "http://arxiv.org/abs/2306.01504v1",
        "pub_date": "2023-06-02",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking\n  Intent in Recommender Systems",
        "url": "http://arxiv.org/abs/2306.01476v1",
        "pub_date": "2023-06-02",
        "summary": "Recommending novel content, which expands user horizons by introducing them\nto new interests, has been shown to improve users' long-term experience on\nrecommendation platforms \\cite{chen2021values}. Users however are not\nconstantly looking to explore novel content. It is therefore crucial to\nunderstand their novelty-seeking intent and adjust the recommendation policy\naccordingly. Most existing literature models a user's propensity to choose\nnovel content or to prefer a more diverse set of recommendations at individual\ninteractions. Hierarchical structure, on the other hand, exists in a user's\nnovelty-seeking intent, which is manifested as a static and intrinsic user\npreference for seeking novelty along with a dynamic session-based propensity.\nTo this end, we propose a novel hierarchical reinforcement learning-based\nmethod to model the hierarchical user novelty-seeking intent, and to adapt the\nrecommendation policy accordingly based on the extracted user novelty-seeking\npropensity. We further incorporate diversity and novelty-related measurement in\nthe reward function of the hierarchical RL (HRL) agent to encourage user\nexploration \\cite{chen2021values}. We demonstrate the benefits of explicitly\nmodeling hierarchical user novelty-seeking intent in recommendations through\nextensive experiments on simulated and real-world datasets. In particular, we\ndemonstrate that the effectiveness of our proposed hierarchical RL-based method\nlies in its ability to capture such hierarchically-structured intent. As a\nresult, the proposed HRL model achieves superior performance on several public\ndatasets, compared with state-of-art baselines.",
        "translated": "推荐新颖的内容，通过引入新的兴趣拓展用户的视野，已经被证明可以改善用户在推荐平台上的长期体验。然而，用户并不总是寻找新奇的内容。因此，必须了解其寻求新颖性的意图，并相应调整建议政策。大多数现有的文献模拟了用户在个人交互中选择新颖内容或更喜欢多样化推荐的倾向。另一方面，层次结构存在于用户的猎奇意图中，表现为一种静态的、内在的用户猎奇偏好以及一种基于会话的动态倾向。为此，我们提出了一种新的基于层次强化学习的方法来建立层次用户查新意图模型，并根据提取出的用户查新意图相应地调整推荐策略。我们进一步将多样性和新颖性相关度量纳入层次 RL (HRL)代理的奖励功能，以鼓励用户探索引用{ Chen 2021value }。我们通过在模拟和真实世界数据集上的大量实验，展示了在推荐中明确建模分层用户猎奇意图的好处。特别地，我们证明了我们提出的基于层次 RL 的方法的有效性在于它能够捕获这种层次结构的意图。结果表明，所提出的 HRL 模型在多个公共数据集上取得了优于现有基线的性能。"
    },
    {
        "title": "Multilingual Conceptual Coverage in Text-to-Image Models",
        "url": "http://arxiv.org/abs/2306.01735v1",
        "pub_date": "2023-06-02",
        "summary": "We propose \"Conceptual Coverage Across Languages\" (CoCo-CroLa), a technique\nfor benchmarking the degree to which any generative text-to-image system\nprovides multilingual parity to its training language in terms of tangible\nnouns. For each model we can assess \"conceptual coverage\" of a given target\nlanguage relative to a source language by comparing the population of images\ngenerated for a series of tangible nouns in the source language to the\npopulation of images generated for each noun under translation in the target\nlanguage. This technique allows us to estimate how well-suited a model is to a\ntarget language as well as identify model-specific weaknesses, spurious\ncorrelations, and biases without a-priori assumptions. We demonstrate how it\ncan be used to benchmark T2I models in terms of multilinguality, and how\ndespite its simplicity it is a good proxy for impressive generalization.",
        "translated": "我们提出了“跨语言的概念覆盖”(CoCo-CroLa) ，一种基准测试的程度，任何生成性文本到图像系统提供多语言平等的训练语言在有形名词方面。对于每个模型，我们可以通过比较源语言中一系列有形名词生成的图像的总体与目标语言中翻译下的每个名词生成的图像的总体来评估给定目标语言相对于源语言的“概念覆盖”。这种技术使我们能够估计模型与目标语言的匹配程度，并且在没有先验假设的情况下识别特定于模型的弱点、虚假的相关性和偏差。我们展示了如何使用它来基准 T2I 模型的多语言性，以及如何尽管它的简单性，它是一个令人印象深刻的推广良好的代理。"
    },
    {
        "title": "DocFormerv2: Local Features for Document Understanding",
        "url": "http://arxiv.org/abs/2306.01733v1",
        "pub_date": "2023-06-02",
        "summary": "We propose DocFormerv2, a multi-modal transformer for Visual Document\nUnderstanding (VDU). The VDU domain entails understanding documents (beyond\nmere OCR predictions) e.g., extracting information from a form, VQA for\ndocuments and other tasks. VDU is challenging as it needs a model to make sense\nof multiple modalities (visual, language and spatial) to make a prediction. Our\napproach, termed DocFormerv2 is an encoder-decoder transformer which takes as\ninput - vision, language and spatial features. DocFormerv2 is pre-trained with\nunsupervised tasks employed asymmetrically i.e., two novel document tasks on\nencoder and one on the auto-regressive decoder. The unsupervised tasks have\nbeen carefully designed to ensure that the pre-training encourages\nlocal-feature alignment between multiple modalities. DocFormerv2 when evaluated\non nine datasets shows state-of-the-art performance over strong baselines e.g.\nTabFact (4.3%), InfoVQA (1.4%), FUNSD (1%). Furthermore, to show generalization\ncapabilities, on three VQA tasks involving scene-text, Doc- Formerv2\noutperforms previous comparably-sized models and even does better than much\nlarger models (such as GIT2, PaLi and Flamingo) on some tasks. Extensive\nablations show that due to its pre-training, DocFormerv2 understands multiple\nmodalities better than prior-art in VDU.",
        "translated": "我们提出 DocFormerv2，一个用于可视化文档理解(VDU)的多模式转换器。VDU 领域需要理解文档(超越单纯的 OCR 预测) ，例如，从表单中提取信息，文档的 VQA 和其他任务。VDU 是具有挑战性的，因为它需要一个模型来理解多种形式(视觉、语言和空间)来做出预测。我们的方法，称为 DocFormerv2是一个编码器-解码器转换器，它采取作为输入-视觉，语言和空间特征。DocFormerv2预先训练了非对称使用的非监督任务，即编码器上的两个新的文档任务和自动回归解码器上的一个任务。这些无监督的任务经过精心设计，以确保预先培训鼓励多种模式之间的局部特征对齐。对9个数据集进行评估后，DocFormerv2显示出超过强基线的最先进性能，例如 TabFact (4.3%) ，InfoVQA (1.4%) ，FUNSD (1%)。此外，为了显示泛化能力，在涉及场景文本的三个 VQA 任务中，Doc-Formerv2在一些任务中表现优于以前的同等大小的模型，甚至优于更大的模型(如 GIT2、 PaLi 和 Flamingo)。广泛的消融表明，由于其预先培训，DocFormerv2了解多种形式更好地比先前的技术在 VDU。"
    },
    {
        "title": "Improving Generalization in Task-oriented Dialogues with Workflows and\n  Action Plans",
        "url": "http://arxiv.org/abs/2306.01729v1",
        "pub_date": "2023-06-02",
        "summary": "Task-oriented dialogue is difficult in part because it involves understanding\nuser intent, collecting information from the user, executing API calls, and\ngenerating helpful and fluent responses. However, for complex tasks one must\nalso correctly do all of these things over multiple steps, and in a specific\norder. While large pre-trained language models can be fine-tuned end-to-end to\ncreate multi-step task-oriented dialogue agents that generate fluent text, our\nexperiments confirm that this approach alone cannot reliably perform new\nmulti-step tasks that are unseen during training. To address these limitations,\nwe augment the dialogue contexts given to \\textmd{text2text} transformers with\nknown \\textit{valid workflow names} and \\textit{action plans}. Action plans\nconsist of sequences of actions required to accomplish a task, and are encoded\nas simple sequences of keywords (e.g. verify-identity, pull-up-account,\nreset-password, etc.). We perform extensive experiments on the Action-Based\nConversations Dataset (ABCD) with T5-small, base and large models, and show\nthat such models: a) are able to more readily generalize to unseen workflows by\nfollowing the provided plan, and b) are able to generalize to executing unseen\nactions if they are provided in the plan. In contrast, models are unable to\nfully accomplish new multi-step tasks when they are not provided action plan\ninformation, even when given new valid workflow names.",
        "translated": "面向任务的对话之所以困难，部分原因在于它涉及到理解用户的意图、从用户那里收集信息、执行 API 调用以及生成有用而流畅的响应。然而，对于复杂的任务，人们还必须在多个步骤中以特定的顺序正确地完成所有这些事情。虽然大型预先训练的语言模型可以进行端到端的微调，以创建多步骤任务导向的对话代理，生成流畅的文本，我们的实验证实，这种方法本身不能可靠地执行新的多步骤任务，在培训期间看不到。为了解决这些限制，我们使用已知的 texttit {有效的工作流名称}和 texttit {操作计划}增加了为 textmd { text2text }转换器提供的对话上下文。行动计划由完成任务所需的一系列行动组成，并被编码为简单的关键字序列(例如验证身份、上拉帐户、重置密码等)。我们在基于行动的对话数据集(ABCD)上对 T5-小型、基础和大型模型进行了广泛的实验，并表明这样的模型: a)能够通过遵循提供的计划更容易地推广到不可见的工作流，b)能够推广到执行不可见的行动，如果它们在计划中提供。相比之下，模型不能完全完成新的多步骤任务，如果没有提供行动计划信息，即使给出了新的有效工作流名称。"
    },
    {
        "title": "Distilling Efficient Language-Specific Models for Cross-Lingual Transfer",
        "url": "http://arxiv.org/abs/2306.01709v1",
        "pub_date": "2023-06-02",
        "summary": "Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, are\nwidely used for cross-lingual transfer learning. While these are pretrained to\nrepresent hundreds of languages, end users of NLP systems are often interested\nonly in individual languages. For such purposes, the MMTs' language coverage\nmakes them unnecessarily expensive to deploy in terms of model size, inference\ntime, energy, and hardware cost. We thus propose to extract compressed,\nlanguage-specific models from MMTs which retain the capacity of the original\nMMTs for cross-lingual transfer. This is achieved by distilling the MMT\nbilingually, i.e., using data from only the source and target language of\ninterest. Specifically, we use a two-phase distillation approach, termed\nBiStil: (i) the first phase distils a general bilingual model from the MMT,\nwhile (ii) the second, task-specific phase sparsely fine-tunes the bilingual\n\"student\" model using a task-tuned variant of the original MMT as its\n\"teacher\". We evaluate this distillation technique in zero-shot cross-lingual\ntransfer across a number of standard cross-lingual benchmarks. The key results\nindicate that the distilled models exhibit minimal degradation in target\nlanguage performance relative to the base MMT despite being significantly\nsmaller and faster. Furthermore, we find that they outperform multilingually\ndistilled models such as DistilmBERT and MiniLMv2 while having a very modest\ntraining budget in comparison, even on a per-language basis. We also show that\nbilingual models distilled from MMTs greatly outperform bilingual models\ntrained from scratch. Our code and models are available at\nhttps://github.com/AlanAnsell/bistil.",
        "translated": "大规模多语言变换器(MMT) ，如 mBERT 和 XLM-R，被广泛用于跨语言迁移学习。虽然这些语言已经被预先训练成可以代表数百种语言，但是 NLP 系统的最终用户通常只对个别语言感兴趣。出于这样的目的，MMT 的语言覆盖率使得它们在模型大小、推理时间、能量和硬件成本方面的部署成本不必要地昂贵。因此，我们建议从 MMT 中提取压缩的、特定于语言的模型，这些模型保留了原始 MMT 的跨语言迁移能力。这是通过提取双语的 MMT 来实现的，也就是说，只使用感兴趣的源语言和目标语言的数据。具体而言，我们使用两阶段精馏方法，称为 BiStil: (i)第一阶段从 MMT 中提取一般的双语模型，而(ii)第二阶段，任务特定阶段使用原始 MMT 的任务调整变体作为其“老师”稀疏地微调双语“学生”模型。我们评估了这种蒸馏技术在零拍跨语言传输跨一些标准的跨语言基准。实验结果表明，相对于基本 MMT，提取出的模型尽管具有显著的更小和更快的性能，但是在目标语言性能方面表现出最小的退化。此外，我们发现它们的表现优于多语言蒸馏模型，如 DistilmBERT 和 MiniLMv2，同时具有非常有限的培训预算相比，即使在每种语言的基础上。我们还表明，从 MMT 中提炼出来的双语模型比从头开始训练的双语模型的表现要好得多。我们的代码和模型可在 https://github.com/alanansell/bistil 获得。"
    },
    {
        "title": "Resolving Interference When Merging Models",
        "url": "http://arxiv.org/abs/2306.01708v1",
        "pub_date": "2023-06-02",
        "summary": "Transfer learning - i.e., further fine-tuning a pre-trained model on a\ndownstream task - can confer significant advantages, including improved\ndownstream performance, faster convergence, and better sample efficiency. These\nadvantages have led to a proliferation of task-specific fine-tuned models,\nwhich typically can only perform a single task and do not benefit from one\nanother. Recently, model merging techniques have emerged as a solution to\ncombine multiple task-specific models into a single multitask model without\nperforming additional training. However, existing merging methods often ignore\nthe interference between parameters of different models, resulting in large\nperformance drops when merging multiple models. In this paper, we demonstrate\nthat prior merging techniques inadvertently lose valuable information due to\ntwo major sources of interference: (a) interference due to redundant parameter\nvalues and (b) disagreement on the sign of a given parameter's values across\nmodels. To address this, we propose our method, TrIm, Elect Sign &amp; Merge\n(TIES-Merging), which introduces three novel steps when merging models: (1)\nresetting parameters that only changed a small amount during fine-tuning, (2)\nresolving sign conflicts, and (3) merging only the parameters that are in\nalignment with the final agreed-upon sign. We find that TIES-Merging\noutperforms several existing methods in diverse settings covering a range of\nmodalities, domains, number of tasks, model sizes, architectures, and\nfine-tuning settings. We further analyze the impact of different types of\ninterference on model parameters, highlight the importance of resolving sign\ninterference. Our code is available at\nhttps://github.com/prateeky2806/ties-merging",
        "translated": "转移学习——即进一步微调下游任务的预先训练的模型——可以带来显著的优势，包括改善下游性能、加快收敛速度和提高采样效率。这些优势导致了特定于任务的微调模型的激增，这些模型通常只能执行单个任务，并且不能从彼此中受益。最近，模型合并技术已经成为一种解决方案，可以将多个任务特定的模型合并成一个单一的多任务模型，而不需要进行额外的训练。然而，现有的合并方法往往忽略了不同模型参数之间的干扰，导致合并多个模型时性能大幅度下降。在本文中，我们证明了先前的合并技术无意中失去了有价值的信息，由于两个主要的干扰来源: (a)由于冗余参数值的干扰和(b)在给定的参数值的符号不一致跨模型。为了解决这个问题，我们提出了我们的方法，TrIm，Elect Sign & Merge (TIES-Merging) ，它在合并模型时引入了三个新的步骤: (1)重置在微调过程中只改变了很少量的参数，(2)解决符号冲突，(3)只合并与最终达成一致的符号一致的参数。我们发现 TIES-Merging 在不同的设置中优于几种现有的方法，包括一系列模式、领域、任务数量、模型大小、架构和微调设置。进一步分析了不同类型的干扰对模型参数的影响，强调了解决符号干扰的重要性。我们的代码可以在 https://github.com/prateeky2806/ties-merging 找到"
    },
    {
        "title": "Learning Multi-step Reasoning from Arithmetic Task",
        "url": "http://arxiv.org/abs/2306.01707v1",
        "pub_date": "2023-06-02",
        "summary": "Mathematical reasoning is regarded as a necessary ability for Language Models\n(LMs). Recent works demonstrate large LMs' impressive performance in solving\nmath problems. The success is attributed to their Chain-of-Thought (CoT)\nreasoning abilities, i.e., the ability to decompose complex questions into\nstep-by-step reasoning chains, but such ability seems only to emerge from\nmodels with abundant parameters. This work investigates how to incorporate\nrelatively small LMs with the capabilities of multi-step reasoning. We propose\nto inject such abilities by continually pre-training LMs on a synthetic dataset\nMsAT, which stands for Multi-step Arithmetic Task. Our experiments on four math\nword problem datasets show the effectiveness of the proposed method in\nenhancing LMs' math reasoning abilities.",
        "translated": "数学推理被认为是语言模型(LM)的必备能力。最近的作品展示了大型 LM 在解决数学问题方面令人印象深刻的表现。这一成功归功于他们的思维链(Chain-of-Thought，CoT)推理能力，即将复杂问题分解为逐步推理链的能力，但这种能力似乎只出现在参数丰富的模型中。本文研究如何将相对较小的线性规划模型与多步推理能力结合起来。我们建议通过在一个合成数据集 MsAT 上连续预训练 LM 来注入这种能力，MsAT 表示多步算术任务。我们在四个数学词汇问题数据集上的实验表明了该方法在提高 LM 数学推理能力方面的有效性。"
    },
    {
        "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model\n  Training",
        "url": "http://arxiv.org/abs/2306.01693v1",
        "pub_date": "2023-06-02",
        "summary": "Language models (LMs) often exhibit undesirable text generation behaviors,\nincluding generating false, toxic, or irrelevant outputs. Reinforcement\nlearning from human feedback (RLHF) - where human preference judgments on LM\noutputs are transformed into a learning signal - has recently shown promise in\naddressing these issues. However, such holistic feedback conveys limited\ninformation on long text outputs; it does not indicate which aspects of the\noutputs influenced user preference; e.g., which parts contain what type(s) of\nerrors. In this paper, we use fine-grained human feedback (e.g., which sentence\nis false, which sub-sentence is irrelevant) as an explicit training signal. We\nintroduce Fine-Grained RLHF, a framework that enables training and learning\nfrom reward functions that are fine-grained in two respects: (1) density,\nproviding a reward after every segment (e.g., a sentence) is generated; and (2)\nincorporating multiple reward models associated with different feedback types\n(e.g., factual incorrectness, irrelevance, and information incompleteness). We\nconduct experiments on detoxification and long-form question answering to\nillustrate how learning with such reward functions leads to improved\nperformance, supported by both automatic and human evaluation. Additionally, we\nshow that LM behaviors can be customized using different combinations of\nfine-grained reward models. We release all data, collected human feedback, and\ncodes at https://FineGrainedRLHF.github.io.",
        "translated": "语言模型(LM)经常表现出不良的文本生成行为，包括生成错误的、有毒的或不相关的输出。人类反馈的强化学习——人类对 LM 输出的偏好判断被转化为一个学习信号——最近在解决这些问题方面显示出了希望。然而，这样的整体反馈传达了关于长文本输出的有限信息; 它没有指出输出的哪些方面影响了用户的偏好; 例如，哪些部分包含哪些类型的错误。在本文中，我们使用细粒度的人反馈(例如，哪个句子是错误的，哪个子句是不相关的)作为显性训练信号。我们介绍了细粒度 RLHF，一个框架，使培训和学习奖励功能的细粒度在两个方面: (1)密度，提供奖励后，每个部分(例如，一个句子)生成; 和(2)结合多个奖励模型与不同的反馈类型(例如，事实不正确，不相关性和信息不完整)。我们进行了解毒实验和长形式的问题回答，以说明如何学习与这种奖励功能导致提高绩效，支持自动和人类的评价。此外，我们表明，LM 行为可以定制使用细粒度奖励模型的不同组合。我们发布所有数据，收集人类反馈，并在 https://finegrainedrlhf.github.io 代码。"
    },
    {
        "title": "DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control\n  for Empathetic Response Generation",
        "url": "http://arxiv.org/abs/2306.01657v1",
        "pub_date": "2023-06-02",
        "summary": "Empathy is a crucial factor in open-domain conversations, which naturally\nshows one's caring and understanding to others. Though several methods have\nbeen proposed to generate empathetic responses, existing works often lead to\nmonotonous empathy that refers to generic and safe expressions. In this paper,\nwe propose to use explicit control to guide the empathy expression and design a\nframework DiffusEmp based on conditional diffusion language model to unify the\nutilization of dialogue context and attribute-oriented control signals.\nSpecifically, communication mechanism, intent, and semantic frame are imported\nas multi-grained signals that control the empathy realization from coarse to\nfine levels. We then design a specific masking strategy to reflect the\nrelationship between multi-grained signals and response tokens, and integrate\nit into the diffusion model to influence the generative process. Experimental\nresults on a benchmark dataset EmpatheticDialogue show that our framework\noutperforms competitive baselines in terms of controllability, informativeness,\nand diversity without the loss of context-relatedness.",
        "translated": "移情是开放领域对话中的一个关键因素，它自然而然地表现出一个人对他人的关心和理解。虽然已经提出了一些方法来产生移情反应，现有的作品往往导致单调的移情，涉及通用和安全的表达。本文提出用显式控制来引导移情表达，并设计了一个基于条件扩散语言模型的扩散映射框架，统一了对话上下文和面向属性控制信号的利用。具体来说，引入交流机制、意图和语义框架作为多粒度信号，从粗到细控制移情实现。然后我们设计了一个特定的掩蔽策略来反映多粒度信号和响应标记之间的关系，并将其整合到扩散模型中以影响生成过程。在一个基准数据集 EmpatheticDialogue 上的实验结果表明，我们的框架在可控性、信息性和多样性方面优于竞争性基准，而且没有丧失上下文相关性。"
    },
    {
        "title": "Learning from Partially Annotated Data: Example-aware Creation of\n  Gap-filling Exercises for Language Learning",
        "url": "http://arxiv.org/abs/2306.01584v1",
        "pub_date": "2023-06-02",
        "summary": "Since performing exercises (including, e.g., practice tests) forms a crucial\ncomponent of learning, and creating such exercises requires non-trivial effort\nfrom the teacher. There is a great value in automatic exercise generation in\ndigital tools in education. In this paper, we particularly focus on automatic\ncreation of gapfilling exercises for language learning, specifically grammar\nexercises. Since providing any annotation in this domain requires human expert\neffort, we aim to avoid it entirely and explore the task of converting existing\ntexts into new gap-filling exercises, purely based on an example exercise,\nwithout explicit instruction or detailed annotation of the intended grammar\ntopics. We contribute (i) a novel neural network architecture specifically\ndesigned for aforementioned gap-filling exercise generation task, and (ii) a\nreal-world benchmark dataset for French grammar. We show that our model for\nthis French grammar gap-filling exercise generation outperforms a competitive\nbaseline classifier by 8% in F1 percentage points, achieving an average F1\nscore of 82%. Our model implementation and the dataset are made publicly\navailable to foster future research, thus offering a standardized evaluation\nand baseline solution of the proposed partially annotated data prediction task\nin grammar exercise creation.",
        "translated": "因为做练习(包括，例如，练习测试)是学习的重要组成部分，而创建这样的练习需要老师付出非凡的努力。数字化练习工具的自动生成在教育中具有重要的应用价值。在本文中，我们特别关注于语言学习中填空练习的自动生成，尤其是语法练习。由于在这个领域提供任何注释都需要人类专家的努力，我们的目标是完全避免它，并探索将现有文本转换为新的填补空白练习的任务，纯粹基于一个示例练习，没有明确的指示或预期的语法主题的详细注释。我们贡献了(i)一个新的神经网络架构，专门设计的上述缺口填补练习生成任务，和(ii)法语语法的现实世界基准数据集。我们表明，我们的模型为这个法语语法差距填补练习生成优于竞争性基线分类器8% 的 F1百分点，实现平均 F1得分为82% 。我们的模型实现和数据集是公开的，以促进未来的研究，从而提供了一个标准化的评价和基线解决方案的建议部分注释数据预测任务在语法练习创建。"
    },
    {
        "title": "EmoUS: Simulating User Emotions in Task-Oriented Dialogues",
        "url": "http://arxiv.org/abs/2306.01579v1",
        "pub_date": "2023-06-02",
        "summary": "Existing user simulators (USs) for task-oriented dialogue systems only model\nuser behaviour on semantic and natural language levels without considering the\nuser persona and emotions. Optimising dialogue systems with generic user\npolicies, which cannot model diverse user behaviour driven by different\nemotional states, may result in a high drop-off rate when deployed in the real\nworld. Thus, we present EmoUS, a user simulator that learns to simulate user\nemotions alongside user behaviour. EmoUS generates user emotions, semantic\nactions, and natural language responses based on the user goal, the dialogue\nhistory, and the user persona. By analysing what kind of system behaviour\nelicits what kind of user emotions, we show that EmoUS can be used as a probe\nto evaluate a variety of dialogue systems and in particular their effect on the\nuser's emotional state. Developing such methods is important in the age of\nlarge language model chat-bots and rising ethical concerns.",
        "translated": "现有的面向任务对话系统的用户模拟器(USs)只是在语义和自然语言层面上对用户行为进行建模，而没有考虑用户角色和情感。使用通用用户策略优化对话系统，不能模拟由不同情绪状态驱动的不同用户行为，在现实世界中部署时可能导致较高的下降率。因此，我们提出了 emoUS，一个用户模拟器，学习模拟用户的情绪以及用户的行为。基于用户目标、对话历史和用户角色，EmoUS 产生用户情绪、语义动作和自然语言反应。通过分析什么样的系统行为引发了什么样的用户情绪，我们表明，情绪美可以作为一个探测器来评估各种对话系统，特别是他们对用户的情绪状态的影响。在大型语言模型聊天机器人时代，开发这样的方法非常重要，同时也引起了越来越多的道德关注。"
    },
    {
        "title": "Learning Similarity among Users for Personalized Session-Based\n  Recommendation from hierarchical structure of User-Session-Item",
        "url": "http://arxiv.org/abs/2306.03040v1",
        "pub_date": "2023-06-05",
        "summary": "The task of the session-based recommendation is to predict the next\ninteraction of the user based on the anonymized user's behavior pattern. And\npersonalized version of this system is a promising research field due to its\navailability to deal with user information. However, there's a problem that the\nuser's preferences and historical sessions were not considered in the typical\nsession-based recommendation since it concentrates only on user-item\ninteraction. In addition, the existing personalized session-based\nrecommendation model has a limited capability in that it only considers the\npreference of the current user without considering those of similar users. It\nmeans there can be the loss of information included within the hierarchical\ndata structure of the user-session-item. To tackle with this problem, we\npropose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender).\nTo model global historical sessions of users, we propose UserGraph that has two\ntypes of nodes - ItemNode and UserNode. We then connect the nodes with three\ntypes of edges. The first type of edges connects ItemNode as chronological\norder, and the second connects ItemNode to UserNode, and the last connects\nUserNode to ItemNode. With these user embeddings, we propose additional\ncontrastive loss, that makes users with similar intention be close to each\nother in the vector space. we apply graph neural network on these UserGraph and\nupdate nodes. Experimental results on two real-world datasets demonstrate that\nour method outperforms some state-of-the-art approaches.",
        "translated": "基于会话的推荐的任务是根据匿名用户的行为模式预测用户的下一次交互。而个性化版本的系统由于能够有效地处理用户信息，是一个很有前途的研究领域。然而，有一个问题，在典型的基于会话的推荐中没有考虑用户的首选项和历史会话，因为它只关注用户项交互。此外，现有的基于个性化会话的推荐模型能力有限，因为它只考虑当前用户的偏好，而不考虑相似用户的偏好。这意味着用户会话项的分层数据结构中包含的信息可能会丢失。为了解决这一问题，我们提出了 USP-SBR (abbr。基于用户相似度的动态会话推荐程序)。为了对用户的全局历史会话进行建模，我们提出了具有两种类型节点的 UserGraph —— ItemNode 和 UserNode。然后我们用三种边连接节点。第一种边以时间顺序连接 ItemNode，第二种边将 ItemNode 连接到 UserNode，最后一种边将 UserNode 连接到 ItemNode。通过这些用户嵌入，我们提出了额外的对比损失，使得具有相似意图的用户在向量空间中更加接近。我们将图形神经网络应用于这些用户图和更新节点。在两个实际数据集上的实验结果表明，我们的方法优于一些最先进的方法。"
    },
    {
        "title": "Gen-IR @ SIGIR 2023: The First Workshop on Generative Information\n  Retrieval",
        "url": "http://arxiv.org/abs/2306.02887v1",
        "pub_date": "2023-06-05",
        "summary": "Generative information retrieval (IR) has experienced substantial growth\nacross multiple research communities (e.g., information retrieval, computer\nvision, natural language processing, and machine learning), and has been highly\nvisible in the popular press. Theoretical, empirical, and actual user-facing\nproducts have been released that retrieve documents (via generation) or\ndirectly generate answers given an input request. We would like to investigate\nwhether end-to-end generative models are just another trend or, as some claim,\na paradigm change for IR. This necessitates new metrics, theoretical grounding,\nevaluation methods, task definitions, models, user interfaces, etc. The goal of\nthis workshop (https://coda.io/@sigir/gen-ir) is to focus on previously\nexplored Generative IR techniques like document retrieval and direct Grounded\nAnswer Generation, while also offering a venue for the discussion and\nexploration of how Generative IR can be applied to new domains like\nrecommendation systems, summarization, etc. The format of the workshop is\ninteractive, including roundtable and keynote sessions and tends to avoid the\none-sided dialogue of a mini-conference.",
        "translated": "生成信息检索在多个研究领域(如信息检索、计算机视觉、自然语言处理和机器学习)都经历了实质性的增长，并且在大众媒体上非常明显。理论、经验和实际的面向用户的产品已经发布，检索文档(通过生成)或直接生成给定输入请求的答案。我们想要研究的是，端到端的生成模型是否只是另一种趋势，或者，正如一些人声称的，一个范式变化的 IR。这就需要新的指标、理论基础、评估方法、任务定义、模型、用户界面等。这个研讨会( https://coda.io/@sigir/gen-IR )的目标是专注于先前探索的生成性信息检索技术，如文献检索和直接接地的答案生成，同时也为讨论和探索生成性信息检索如何应用于新的领域，如推荐系统，摘要等提供了场所。讲习班的形式是互动的，包括圆桌会议和主旨会议，往往避免小型会议的单方面对话。"
    },
    {
        "title": "Benchmarking Middle-Trained Language Models for Neural Search",
        "url": "http://arxiv.org/abs/2306.02867v1",
        "pub_date": "2023-06-05",
        "summary": "Middle training methods aim to bridge the gap between the Masked Language\nModel (MLM) pre-training and the final finetuning for retrieval. Recent models\nsuch as CoCondenser, RetroMAE, and LexMAE argue that the MLM task is not\nsufficient enough to pre-train a transformer network for retrieval and hence\npropose various tasks to do so. Intrigued by those novel methods, we noticed\nthat all these models used different finetuning protocols, making it hard to\nassess the benefits of middle training. We propose in this paper a benchmark of\nCoCondenser, RetroMAE, and LexMAE, under the same finetuning conditions. We\ncompare both dense and sparse approaches under various finetuning protocols and\nmiddle training on different collections (MS MARCO, Wikipedia or Tripclick). We\nuse additional middle training baselines, such as a standard MLM finetuning on\nthe retrieval collection, optionally augmented by a CLS predicting the passage\nterm frequency. For the sparse approach, our study reveals that there is almost\nno statistical difference between those methods: the more effective the\nfinetuning procedure is, the less difference there is between those models. For\nthe dense approach, RetroMAE using MS MARCO as middle-training collection shows\nexcellent results in almost all the settings. Finally, we show that middle\ntraining on the retrieval collection, thus adapting the language model to it,\nis a critical factor. Overall, a better experimental setup should be adopted to\nevaluate middle training methods. Code available at\nhttps://github.com/naver/splade/tree/benchmarch-SIGIR23",
        "translated": "中间训练方法旨在弥补蒙版语言模型(MLM)预训练和检索的最终微调之间的差距。最近的一些模型，如 CoCondenser，RotMAE 和 LexMAE 认为传销任务不足以预先训练一个变压器网络进行检索，因此提出了各种各样的任务来这样做。被这些新奇的方法所吸引，我们注意到所有这些模型使用不同的微调协议，使得评估中间训练的好处变得困难。在本文中，我们提出了一个基准的协同凝聚器，反向 MAE 和 LexMAE，在相同的微调条件下。我们比较了在各种微调协议和不同集合(MS MARCO，Wikipedia 或 Tripclick)的中间培训下的密集和稀疏方法。我们使用额外的中间训练基线，例如在检索集合上的标准 MLM 微调，可选地通过预测通过项频率的 CLS 加强。对于稀疏方法，我们的研究表明，这些方法之间几乎没有统计上的差异: 微调过程越有效，这些模型之间的差异就越小。对于密集的方法，使用 MS MARCO 作为中间训练收集在几乎所有的设置中都显示出优异的结果。最后，我们表明，中间训练的检索集，从而使语言模型适应它，是一个关键因素。总的来说，应该采用更好的实验设置来评价中间训练方法。Https://github.com/naver/splade/tree/benchmarch-sigir23提供密码"
    },
    {
        "title": "CTRL: Connect Tabular and Language Model for CTR Prediction",
        "url": "http://arxiv.org/abs/2306.02841v1",
        "pub_date": "2023-06-05",
        "summary": "Traditional click-through rate (CTR) prediction models convert the tabular\ndata into one-hot vectors and leverage the collaborative relations among\nfeatures for inferring user's preference over items. This modeling paradigm\ndiscards the essential semantic information. Though some recent works like P5\nand M6-Rec have explored the potential of using Pre-trained Language Models\n(PLMs) to extract semantic signals for CTR prediction, they are computationally\nexpensive and suffer from low efficiency. Besides, the beneficial collaborative\nrelations are not considered, hindering the recommendation performance. To\nsolve these problems, in this paper, we propose a novel framework\n\\textbf{CTRL}, which is industrial friendly and model-agnostic with high\ntraining and inference efficiency. Specifically, the original tabular data is\nfirst converted into textual data. Both tabular data and converted textual data\nare regarded as two different modalities and are separately fed into the\ncollaborative CTR model and pre-trained language model. A cross-modal knowledge\nalignment procedure is performed to fine-grained align and integrate the\ncollaborative and semantic signals, and the lightweight collaborative model can\nbe deployed online for efficient serving after fine-tuned with supervised\nsignals. Experimental results on three public datasets show that CTRL\noutperforms the SOTA CTR models significantly. Moreover, we further verify its\neffectiveness on a large-scale industrial recommender system.",
        "translated": "传统的点进率预测模型将表格数据转换为一个热点向量，并利用特征之间的协同关系来推断用户对项目的偏好。这种建模范式抛弃了基本的语义信息。虽然最近的一些工作，如 P5和 M6-Rec 已经探索了使用预训练语言模型(PLM)提取语义信号进行 CTR 预测的潜力，但是它们的计算成本高，效率低。此外，没有考虑到有益的协作关系，阻碍了推荐绩效的提高。为了解决这些问题，本文提出了一种新的框架 textbf { CTRL } ，该框架具有良好的工业友好性和模型无关性，并且具有较高的训练和推理效率。具体来说，首先将原始表格数据转换为文本数据。将表格数据和转换后的文本数据视为两种不同的模式，分别输入协同 CTR 模型和预训练语言模型。通过跨模态知识对齐过程对协作信号和语义信号进行细粒度对齐和集成，并对监督信号进行细调后，可以在线部署轻量级协作模型，实现高效服务。在三个公共数据集上的实验结果表明，CTRL 模型的性能明显优于 SOTA CTR 模型。此外，我们进一步验证了该方法在大规模工业推荐系统上的有效性。"
    },
    {
        "title": "Path-Specific Counterfactual Fairness for Recommender Systems",
        "url": "http://arxiv.org/abs/2306.02615v1",
        "pub_date": "2023-06-05",
        "summary": "Recommender systems (RSs) have become an indispensable part of online\nplatforms. With the growing concerns of algorithmic fairness, RSs are not only\nexpected to deliver high-quality personalized content, but are also demanded\nnot to discriminate against users based on their demographic information.\nHowever, existing RSs could capture undesirable correlations between sensitive\nfeatures and observed user behaviors, leading to biased recommendations. Most\nfair RSs tackle this problem by completely blocking the influences of sensitive\nfeatures on recommendations. But since sensitive features may also affect user\ninterests in a fair manner (e.g., race on culture-based preferences),\nindiscriminately eliminating all the influences of sensitive features\ninevitably degenerate the recommendations quality and necessary diversities. To\naddress this challenge, we propose a path-specific fair RS (PSF-RS) for\nrecommendations. Specifically, we summarize all fair and unfair correlations\nbetween sensitive features and observed ratings into two latent proxy\nmediators, where the concept of path-specific bias (PS-Bias) is defined based\non path-specific counterfactual inference. Inspired by Pearl's minimal change\nprinciple, we address the PS-Bias by minimally transforming the biased factual\nworld into a hypothetically fair world, where a fair RS model can be learned\naccordingly by solving a constrained optimization problem. For the technical\npart, we propose a feasible implementation of PSF-RS, i.e., PSF-VAE, with\nweakly-supervised variational inference, which robustly infers the latent\nmediators such that unfairness can be mitigated while necessary recommendation\ndiversities can be maximally preserved simultaneously. Experiments conducted on\nsemi-simulated and real-world datasets demonstrate the effectiveness of PSF-RS.",
        "translated": "推荐系统已经成为在线平台不可或缺的一部分。随着对算法公平性的日益关注，RSS 不仅被期望提供高质量的个性化内容，而且被要求不因用户的人口统计信息而歧视用户。然而，现有的 RSS 可能捕获敏感特性和观察到的用户行为之间不希望看到的相关性，从而导致有偏见的推荐。大多数公平的 RSS 通过完全阻止敏感特性对建议的影响来解决这个问题。但是，由于敏感特性也可能以公平的方式影响用户的兴趣(例如，基于文化的偏好的种族) ，不加区分地消除敏感特性的所有影响必然会降低推荐的质量和必要的多样性。为了应对这一挑战，我们提出了一个路径特定的公平 RS (PSF-RS)的建议。具体而言，我们将敏感特征和观察评分之间的所有公平和不公平的相关性总结为两个潜在的代理中介，其中路径特异性偏倚(PS-Bias)的概念是基于路径特异性反事实推断定义的。受珀尔的最小改变原则的启发，我们通过最小化地将有偏见的现实世界转化为一个假设的公平世界，在这个假设的公平世界中，通过解决一个受限制的最佳化问题，可以相应地学习一个公平的遥感模型，从而解决偏差问题。在技术部分，我们提出了一种可行的 PSF-RS 的实现方法，即弱监督变分推理 PSF-VAE，它可以强有力地推断出潜在的中介因子，从而在最大限度地保留必要的推荐多样性的同时，减少不公平性。在半模拟和真实数据集上进行的实验证明了 PSF-RS 算法的有效性。"
    },
    {
        "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems",
        "url": "http://arxiv.org/abs/2306.03091v1",
        "pub_date": "2023-06-05",
        "summary": "Large Language Models (LLMs) have greatly advanced code auto-completion\nsystems, with a potential for substantial productivity enhancements for\ndevelopers. However, current benchmarks mainly focus on single-file tasks,\nleaving an assessment gap for more complex, real-world, multi-file programming\nscenarios. To fill this gap, we introduce RepoBench, a new benchmark\nspecifically designed for evaluating repository-level code auto-completion\nsystems. RepoBench consists of three interconnected evaluation tasks:\nRepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P\n(Pipeline). Each task respectively measures the system's ability to retrieve\nthe most relevant code snippets from other files as cross-file context, predict\nthe next line of code with cross-file and in-file context, and handle complex\ntasks that require a combination of both retrieval and next-line prediction.\nRepoBench aims to facilitate a more complete comparison of performance and\nencouraging continuous improvement in auto-completion systems. RepoBench is\npublicly available at https://github.com/Leolty/repobench.",
        "translated": "大型语言模型(Large Language Model，LLM)具有非常先进的代码自动完成系统，对于开发人员来说，这有可能大大提高生产力。然而，当前的基准测试主要集中在单文件任务上，对于更复杂的、真实的、多文件编程场景留下了评估空白。为了填补这个空白，我们引入了 RepoBench，这是一个专门为评估存储库级代码自动完成系统而设计的新基准。RepoBench 由三个相互连接的评估任务组成: RepoBench-R (检索)、 RepoBench-C (代码完成)和 RepoBench-P (管道)。每个任务分别测量系统从其他文件中检索最相关代码片段作为跨文件上下文的能力，用跨文件和文件内上下文预测下一行代码的能力，以及处理需要检索和下一行预测相结合的复杂任务的能力。RepoBench 旨在促进更全面的性能比较，并鼓励自动完成系统的持续改进。RepoBench 可在 https://github.com/leolty/RepoBench 公开使用。"
    },
    {
        "title": "Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For\n  Scoring and Providing Actionable Insights on Classroom Instruction",
        "url": "http://arxiv.org/abs/2306.03090v1",
        "pub_date": "2023-06-05",
        "summary": "Coaching, which involves classroom observation and expert feedback, is a\nwidespread and fundamental part of teacher training. However, the majority of\nteachers do not have access to consistent, high quality coaching due to limited\nresources and access to expertise. We explore whether generative AI could\nbecome a cost-effective complement to expert feedback by serving as an\nautomated teacher coach. In doing so, we propose three teacher coaching tasks\nfor generative AI: (A) scoring transcript segments based on classroom\nobservation instruments, (B) identifying highlights and missed opportunities\nfor good instructional strategies, and (C) providing actionable suggestions for\neliciting more student reasoning. We recruit expert math teachers to evaluate\nthe zero-shot performance of ChatGPT on each of these tasks for elementary math\nclassroom transcripts. Our results reveal that ChatGPT generates responses that\nare relevant to improving instruction, but they are often not novel or\ninsightful. For example, 82% of the model's suggestions point to places in the\ntranscript where the teacher is already implementing that suggestion. Our work\nhighlights the challenges of producing insightful, novel and truthful feedback\nfor teachers while paving the way for future research to address these\nobstacles and improve the capacity of generative AI to coach teachers.",
        "translated": "辅导，包括课堂观察和专家反馈，是教师培训的一个广泛而基本的组成部分。然而，由于资源和专业知识有限，大多数教师无法获得连贯、高质量的辅导。我们探讨生成式人工智能是否可以成为一个具有成本效益的专家反馈的补充，作为一个自动化的教师教练。在这样做时，我们提出了三个生成性人工智能的教师培训任务: (A)基于课堂观察工具评分成绩单片段，(B)识别优秀教学策略的亮点和错过的机会，以及(C)提供可行的建议，以引发更多的学生推理。我们招募数学专家教师来评估 ChatGPT 在小学数学课堂成绩单中每一项任务的“零打击”表现。我们的研究结果表明，ChatGPT 产生的反应与提高教学质量有关，但它们往往不是新颖或有见地的。例如，模型中82% 的建议指向成绩单中教师已经实施该建议的地方。我们的工作强调了为教师提供有见地、新颖和真实的反馈所面临的挑战，同时为未来的研究解决这些障碍和提高生成性人工智能指导教师的能力铺平了道路。"
    },
    {
        "title": "Sequential Monte Carlo Steering of Large Language Models using\n  Probabilistic Programs",
        "url": "http://arxiv.org/abs/2306.03081v1",
        "pub_date": "2023-06-05",
        "summary": "Even after fine-tuning and reinforcement learning, large language models\n(LLMs) can be difficult, if not impossible, to control reliably with prompts\nalone. We propose a new inference-time approach to enforcing syntactic and\nsemantic constraints on the outputs of LLMs, called sequential Monte Carlo\n(SMC) steering. The key idea is to specify language generation tasks as\nposterior inference problems in a class of discrete probabilistic sequence\nmodels, and replace standard decoding with sequential Monte Carlo inference.\nFor a computational cost similar to that of beam search, SMC can steer LLMs to\nsolve diverse tasks, including infilling, generation under syntactic\nconstraints, and prompt intersection. To facilitate experimentation with SMC\nsteering, we present a probabilistic programming library, LLaMPPL\n(https://github.com/probcomp/LLaMPPL), for concisely specifying new generation\ntasks as language model probabilistic programs, and automating steering of\nLLaMA-family Transformers.",
        "translated": "即使经过微调和强化学习，大型语言模型(LLM)也很难单靠提示符进行可靠控制。我们提出了一种新的推理时间方法，称为序贯蒙特卡罗(SMC)指导，以强制语法和语义约束的 LLM 的输出。其核心思想是在一类离散概率序列模型中将语言生成任务指定为后验推理问题，并用序贯蒙特卡罗推理代替标准译码。对于类似于波束搜索的计算代价，SMC 可以引导 LLM 解决不同的任务，包括填充、语法约束下的生成和快速交叉。为了方便 SMC 指导的实验，我们提出了一个概率编程库，LLaMPPL ( https://github.com/probcomp/LLaMPPL ) ，简明地指定新一代任务作为语言模型概率程序，并自动指导 LlaMA 家族变压器。"
    },
    {
        "title": "Machine Learning and Statistical Approaches to Measuring Similarity of\n  Political Parties",
        "url": "http://arxiv.org/abs/2306.03079v1",
        "pub_date": "2023-06-05",
        "summary": "Mapping political party systems to metric policy spaces is one of the major\nmethodological problems in political science. At present, in most political\nscience project this task is performed by domain experts relying on purely\nqualitative assessments, with all the attendant problems of subjectivity and\nlabor intensiveness. We consider how advances in natural language processing,\nincluding large transformer-based language models, can be applied to solve that\nissue. We apply a number of texts similarity measures to party political\nprograms, analyze how they correlate with each other, and -- in the absence of\na satisfactory benchmark -- evaluate them against other measures, including\nthose based on expert surveys, voting records, electoral patterns, and\ncandidate networks. Finally, we consider the prospects of relying on those\nmethods to correct, supplement, and eventually replace expert judgments.",
        "translated": "将政党系统映射到度量政策空间是政治学的主要方法论问题之一。目前，在大多数政治科学项目中，这项任务是由领域专家依靠纯粹的定性评估来完成的，伴随而来的问题包括主观性和劳动密集性。我们考虑如何应用自然语言处理的进步，包括基于大型转换器的语言模型，来解决这个问题。我们将大量的文本相似性度量方法应用于政党政治计划，分析它们之间的相互关系，并且——在缺乏令人满意的基准的情况下——根据其他度量方法对它们进行评估，包括那些基于专家调查、投票记录、选举模式和候选人网络的方法。最后，我们考虑依靠这些方法来纠正、补充并最终取代专家判断的前景。"
    },
    {
        "title": "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight\n  Compression",
        "url": "http://arxiv.org/abs/2306.03078v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advances in large language model (LLM) pretraining have led to\nhigh-quality LLMs with impressive abilities. By compressing such LLMs via\nquantization to 3-4 bits per parameter, they can fit into memory-limited\ndevices such as laptops and mobile phones, enabling personalized use. However,\nquantization down to 3-4 bits per parameter usually leads to moderate-to-high\naccuracy losses, especially for smaller models in the 1-10B parameter range,\nwhich are well-suited for edge deployments. To address this accuracy issue, we\nintroduce the Sparse-Quantized Representation (SpQR), a new compressed format\nand quantization technique which enables for the first time near-lossless\ncompression of LLMs across model scales, while reaching similar compression\nlevels to previous methods. SpQR works by identifying and isolating outlier\nweights, which cause particularly-large quantization errors, and storing them\nin higher precision, while compressing all other weights to 3-4 bits, and\nachieves relative accuracy losses of less than 1% in perplexity for\nhighly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B\nparameter LLM on a single 24 GB consumer GPU without any performance\ndegradation at 15% speedup thus making powerful LLMs available to consumer\nwithout any downsides. SpQR comes with efficient algorithms for both encoding\nweights into its format, as well as decoding them efficiently at runtime.\nSpecifically, we provide an efficient GPU inference algorithm for SpQR which\nyields faster inference than 16-bit baselines at similar accuracy, while\nenabling memory compression gains of more than 4x.",
        "translated": "大语言模型(LLM)预训练的最新进展导致了具有令人印象深刻的能力的高质量 LLM。通过量化将这种 LLM 压缩到每个参数3-4位，它们可以适用于内存有限的设备，如笔记本电脑和移动电话，从而实现个性化使用。然而，每个参数下降到3-4位的量化通常会导致中高精度的损失，特别是对于1-10B 参数范围内的较小模型，它们非常适合边缘部署。为了解决这个精度问题，我们引入了稀疏量化表示(SpQR) ，这是一种新的压缩格式和量化技术，它能够首次在模型尺度上对 LLM 进行近无损压缩，同时达到与以前的方法相似的压缩水平。SpQR 的工作原理是识别和隔离引起特别大量化误差的离群值权重，并以更高的精度存储它们，同时将所有其他权重压缩到3-4位，对于高精度 LLaMA 和 Falcon LLM，相对精度损失小于1% 。这使得在一个24GB 的消费者 GPU 上运行33B 参数 LLM 成为可能，而且在加速15% 的情况下性能没有任何下降，从而使得消费者可以在没有任何缺点的情况下使用功能强大的 LLM。SpQR 提供了有效的算法，既可以将权值编码成它的格式，也可以在运行时高效地解码它们。具体来说，我们为 SpQR 提供了一种高效的 GPU 推理算法，它在相似的精度下比16位基线产生更快的推理，同时使内存压缩增益超过4倍。"
    },
    {
        "title": "Interactive Editing for Text Summarization",
        "url": "http://arxiv.org/abs/2306.03067v1",
        "pub_date": "2023-06-05",
        "summary": "Summarizing lengthy documents is a common and essential task in our daily\nlives. Although recent advancements in neural summarization models can assist\nin crafting general-purpose summaries, human writers often have specific\nrequirements that call for a more customized approach. To address this need, we\nintroduce REVISE (Refinement and Editing via Iterative Summarization\nEnhancement), an innovative framework designed to facilitate iterative editing\nand refinement of draft summaries by human writers. Within our framework,\nwriters can effortlessly modify unsatisfactory segments at any location or\nlength and provide optional starting phrases -- our system will generate\ncoherent alternatives that seamlessly integrate with the existing summary. At\nits core, REVISE incorporates a modified fill-in-the-middle model with the\nencoder-decoder architecture while developing novel evaluation metrics tailored\nfor the summarization task. In essence, our framework empowers users to create\nhigh-quality, personalized summaries by effectively harnessing both human\nexpertise and AI capabilities, ultimately transforming the summarization\nprocess into a truly collaborative and adaptive experience.",
        "translated": "总结冗长的文件是我们日常生活中的一项共同而又必不可少的任务。虽然神经总结模型的最新进展可以帮助制作通用的总结，但人类作者往往有特定的需求，需要更加定制的方法。为了满足这一需求，我们引入了 REVISE (通过迭代摘要增强进行细化和编辑) ，这是一个创新的框架，旨在促进人类作者对摘要草稿的迭代编辑和细化。在我们的框架内，作者可以毫不费力地在任何位置或长度修改不满意的部分，并提供可选的起始短语——我们的系统将生成与现有摘要无缝集成的连贯备选方案。在其核心，REVISE 采用了修改的填充中间模型与编码器-解码器架构，同时开发新的评估指标定制的摘要任务。本质上，我们的框架通过有效利用人类专业知识和人工智能能力，使用户能够创建高质量的个性化摘要，最终将摘要过程转化为真正的协作和适应性体验。"
    },
    {
        "title": "Structured Voronoi Sampling",
        "url": "http://arxiv.org/abs/2306.03061v1",
        "pub_date": "2023-06-05",
        "summary": "Recently, there has been a growing interest in the development of\ngradient-based sampling algorithms for text generation, especially in the\ncontext of controlled generation. However, there exists a lack of theoretically\ngrounded and principled approaches for this task. In this paper, we take an\nimportant step toward building a principled approach for sampling from language\nmodels with gradient-based methods. We use discrete distributions given by\nlanguage models to define densities and develop an algorithm based on\nHamiltonian Monte Carlo to sample from them. We name our gradient-based\ntechnique Structured Voronoi Sampling (SVS). In an experimental setup where the\nreference distribution is known, we show that the empirical distribution of SVS\nsamples is closer to the reference distribution compared to alternative\nsampling schemes. Furthermore, in a controlled generation task, SVS is able to\ngenerate fluent and diverse samples while following the control targets\nsignificantly better than other methods.",
        "translated": "近年来，基于梯度的文本生成采样算法的研究越来越受到人们的关注，尤其是在控制生成的背景下。然而，这项工作缺乏理论基础和原则性的方法。在本文中，我们采取了一个重要的步骤，以建立一个原则性的方法从语言模型采样基于梯度的方法。我们使用语言模型给出的离散分布来定义密度，并开发一个基于 Hamiltonian Monte Carlo 的算法来取样。我们将基于梯度的技术命名为结构化 Voronoi 抽样(SVS)。在已知参考分布的实验装置中，我们发现 SVS 样本的经验分布比其他抽样方案更接近参考分布。此外，在控制生成任务中，SVS 能够生成流畅多样的样本，并且能够明显地更好地跟踪控制目标。"
    },
    {
        "title": "Analyzing Syntactic Generalization Capacity of Pre-trained Language\n  Models on Japanese Honorific Conversion",
        "url": "http://arxiv.org/abs/2306.03055v1",
        "pub_date": "2023-06-05",
        "summary": "Using Japanese honorifics is challenging because it requires not only\nknowledge of the grammatical rules but also contextual information, such as\nsocial relationships. It remains unclear whether pre-trained large language\nmodels (LLMs) can flexibly handle Japanese honorifics like humans. To analyze\nthis, we introduce an honorific conversion task that considers social\nrelationships among people mentioned in a conversation. We construct a Japanese\nhonorifics dataset from problem templates of various sentence structures to\ninvestigate the syntactic generalization capacity of GPT-3, one of the leading\nLLMs, on this task under two settings: fine-tuning and prompt learning. Our\nresults showed that the fine-tuned GPT-3 performed better in a context-aware\nhonorific conversion task than the prompt-based one. The fine-tuned model\ndemonstrated overall syntactic generalizability towards compound honorific\nsentences, except when tested with the data involving direct speech.",
        "translated": "使用敬称很有挑战性，因为它不仅需要语法规则的知识，还需要上下文信息，比如社会关系。目前还不清楚经过训练的大型语言模型(LLM)是否能像人类一样灵活地处理敬称。为了分析这一点，我们引入了一个敬语转换任务，考虑谈话中提到的人之间的社会关系。我们从不同句子结构的问题模板中构建了一个敬称数据集，在微调和及时学习两种设置下，研究了领先的语法模型之一 GPT-3的句法泛化能力。我们的研究结果表明，微调的 GPT-3在上下文感知的敬语转换任务中比基于提示的任务表现得更好。经过微调的模型显示了复合敬语句的整体句法泛化能力，除非使用直接引语的数据进行测试。"
    },
    {
        "title": "Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese\n  Medical Exam Dataset",
        "url": "http://arxiv.org/abs/2306.03030v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advancements in large language models (LLMs) have transformed the\nfield of question answering (QA). However, evaluating LLMs in the medical field\nis challenging due to the lack of standardized and comprehensive datasets. To\naddress this gap, we introduce CMExam, sourced from the Chinese National\nMedical Licensing Examination. CMExam consists of 60K+ multiple-choice\nquestions for standardized and objective evaluations, as well as solution\nexplanations for model reasoning evaluation in an open-ended manner. For\nin-depth analyses of LLMs, we invited medical professionals to label five\nadditional question-wise annotations, including disease groups, clinical\ndepartments, medical disciplines, areas of competency, and question difficulty\nlevels. Alongside the dataset, we further conducted thorough experiments with\nrepresentative LLMs and QA algorithms on CMExam. The results show that GPT-4\nhad the best accuracy of 61.5% and a weighted F1 score of 0.616. These results\nhighlight a great disparity when compared to human accuracy, which stood at\n71.6%. For explanation tasks, while LLMs could generate relevant reasoning and\ndemonstrate improved performance after finetuning, they fall short of a desired\nstandard, indicating ample room for improvement. To the best of our knowledge,\nCMExam is the first Chinese medical exam dataset to provide comprehensive\nmedical annotations. The experiments and findings of LLM evaluation also\nprovide valuable insights into the challenges and potential solutions in\ndeveloping Chinese medical QA systems and LLM evaluation pipelines. The dataset\nand relevant code are available at https://github.com/williamliujl/CMExam.",
        "translated": "大型语言模型(LLM)的最新进展已经改变了问答(QA)领域。然而，由于缺乏标准化和全面的数据集，评估 LLM 在医学领域是具有挑战性的。为了弥补这一差距，我们引入了来自中国国家医师执业资格考试的中国医师执业资格考试。CMExam 由60K + 多项选择题组成，用于标准化和客观的评估，以及开放式方式的模型推理评估的解决方案说明。对于 LLM 的深入分析，我们邀请医学专业人员标记另外五个明智的问题注释，包括疾病组，临床部门，医学学科，能力领域和问题难度水平。除了数据集，我们进一步在 CMExam 上进行了具有代表性的 LLM 和 QA 算法的全面实验。结果表明，GPT-4的最佳准确率为61.5% ，加权 F1得分为0.616。这些结果突出了一个巨大的差异，相比之下，人类的准确率为71.6% 。对于解释任务，虽然 LLM 可以生成相关的推理，并在微调后显示出改进的性能，但它们没有达到理想的标准，表明有足够的改进空间。据我们所知，中国医学考试是第一个提供全面医学注释的中国医学考试数据集。LLM 评价的实验和研究结果也为开发中国医疗质量保证体系和 LLM 评价管道提供了有价值的启示。数据集和相关代码可在 https://github.com/williamliujl/cmexam 查阅。"
    },
    {
        "title": "PokemonChat: Auditing ChatGPT for Pokémon Universe Knowledge",
        "url": "http://arxiv.org/abs/2306.03024v1",
        "pub_date": "2023-06-05",
        "summary": "The recently released ChatGPT model demonstrates unprecedented capabilities\nin zero-shot question-answering. In this work, we probe ChatGPT for its\nconversational understanding and introduce a conversational framework\n(protocol) that can be adopted in future studies. The Pok\\'emon universe serves\nas an ideal testing ground for auditing ChatGPT's reasoning capabilities due to\nits closed world assumption. After bringing ChatGPT's background knowledge (on\nthe Pok\\'emon universe) to light, we test its reasoning process when using\nthese concepts in battle scenarios. We then evaluate its ability to acquire new\nknowledge and include it in its reasoning process. Our ultimate goal is to\nassess ChatGPT's ability to generalize, combine features, and to acquire and\nreason over newly introduced knowledge from human feedback. We find that\nChatGPT has prior knowledge of the Pokemon universe, which can reason upon in\nbattle scenarios to a great extent, even when new information is introduced.\nThe model performs better with collaborative feedback and if there is an\ninitial phase of information retrieval, but also hallucinates occasionally and\nis susceptible to adversarial attacks.",
        "translated": "最近发布的 ChatGPT 模型展示了前所未有的零命中问题回答能力。在本文中，我们探讨了 ChatGPT 的会话理解，并介绍了一个可以在未来研究中采用的会话框架(协议)。由于其封闭的世界假设，宇宙上的 Pok’em 可以作为审核 ChatGPT 推理能力的理想试验场。在将 ChatGPT 的背景知识(关于宇宙中的 Pok’em)公之于众之后，我们在战斗场景中使用这些概念时测试它的推理过程。然后，我们评估它获取新知识的能力，并将其包括在推理过程中。我们的最终目标是评估 ChatGPT 的概括、结合特性的能力，以及从人类反馈中获取和推理新引入的知识的能力。我们发现 ChatGPT 拥有口袋妖怪世界的先验知识，即使在引入新信息的情况下，它也可以在很大程度上在战斗场景中进行推理。这种模式在协作反馈的情况下表现得更好，如果存在信息检索的初始阶段，但有时也会产生幻觉，容易受到敌对攻击。"
    },
    {
        "title": "On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based\n  Graph Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.03624v1",
        "pub_date": "2023-06-06",
        "summary": "Collaborative filtering (CF) is an important research direction in\nrecommender systems that aims to make recommendations given the information on\nuser-item interactions. Graph CF has attracted more and more attention in\nrecent years due to its effectiveness in leveraging high-order information in\nthe user-item bipartite graph for better recommendations. Specifically, recent\nstudies show the success of graph neural networks (GNN) for CF is attributed to\nits low-pass filtering effects. However, current researches lack a study of how\ndifferent signal components contributes to recommendations, and how to design\nstrategies to properly use them well. To this end, from the view of spectral\ntransformation, we analyze the important factors that a graph filter should\nconsider to achieve better performance. Based on the discoveries, we design\nJGCF, an efficient and effective method for CF based on Jacobi polynomial bases\nand frequency decomposition strategies. Extensive experiments on four widely\nused public datasets show the effectiveness and efficiency of the proposed\nmethods, which brings at most 27.06% performance gain on Alibaba-iFashion.\nBesides, the experimental results also show that JGCF is better at handling\nsparse datasets, which shows potential in making recommendations for cold-start\nusers.",
        "translated": "协同过滤(CF)是推荐系统的一个重要研究方向，其目的是根据用户项目交互的信息提供推荐。近年来，图形 CF 由于能够有效地利用用户项目二分图中的高阶信息来获得更好的建议而引起了越来越多的关注。具体来说，最近的研究表明，图神经网络(GNN)对 CF 的成功归功于其低通滤波效果。然而，目前的研究缺乏研究不同的信号成分如何有助于推荐，以及如何设计策略，以适当地使用它们。为此，本文从谱变换的角度出发，分析了图形滤波器要获得更好的性能所应考虑的重要因素。基于这些发现，我们设计了一种基于 Jacobi 多项式基和频率分解策略的高效率和有效的协同过滤方法。在四个广泛使用的公共数据集上进行了大量的实验，结果表明了该方法的有效性和高效性，在阿里巴巴-iFashion 平台上获得了最多27.06% 的性能提升。此外，实验结果还表明，JGCF 在处理稀疏数据集方面有较好的表现，可以为冷启动用户提供建议。"
    },
    {
        "title": "Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR\n  Prediction in Taobao",
        "url": "http://arxiv.org/abs/2306.03527v1",
        "pub_date": "2023-06-06",
        "summary": "Click-Through Rate (CTR) prediction serves as a fundamental component in\nonline advertising. A common practice is to train a CTR model on advertisement\n(ad) impressions with user feedback. Since ad impressions are purposely\nselected by the model itself, their distribution differs from the inference\ndistribution and thus exhibits sample selection bias (SSB) that affects model\nperformance. Existing studies on SSB mainly employ sample re-weighting\ntechniques which suffer from high variance and poor model calibration. Another\nline of work relies on costly uniform data that is inadequate to train\nindustrial models. Thus mitigating SSB in industrial models with a\nuniform-data-free framework is worth exploring. Fortunately, many platforms\ndisplay mixed results of organic items (i.e., recommendations) and sponsored\nitems (i.e., ads) to users, where impressions of ads and recommendations are\nselected by different systems but share the same user decision rationales.\nBased on the above characteristics, we propose to leverage recommendations\nsamples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After\nelaborating data augmentation, Rec4Ad learns disentangled representations with\nalignment and decorrelation modules for enhancement. When deployed in Taobao\ndisplay advertising system, Rec4Ad achieves substantial gains in key business\nmetrics, with a lift of up to +6.6\\% CTR and +2.9\\% RPM.",
        "translated": "点进率预测是在线广告的一个基本组成部分。一个常见的做法是训练广告(广告)印象与用户反馈的点击率模型。由于广告印象是由模型本身有目的地选择的，它们的分布不同于推断分布，因此表现出影响模型性能的样本选择偏差(SSB)。现有的 SSB 研究主要采用样本重权重技术，存在方差大、模型校正差等问题。另一项工作依赖于昂贵的统一数据，这些数据不足以培训工业模型。因此，在无统一数据框架的工业模型中减少 SSB 是值得探索的。幸运的是，许多平台向用户显示有机项目(即推荐)和赞助项目(即广告)的混合结果，其中广告和推荐的印象由不同的系统选择，但共享相同的用户决策理由。基于上述特点，我们建议利用推荐样本作为免费午餐，以减轻 SSB 的广告点击率模型(Rec4Ad)。在详细阐述了数据增强之后，Rec4Ad 学习了利用对齐和去相关模块进行增强的解纠缠表示。在淘宝展示广告系统中部署 Rec4Ad 后，Rec4Ad 在关键业务指标上取得了实质性进展，点击率和转速分别提高了6.6% 和2.9% 。"
    },
    {
        "title": "COPR: Consistency-Oriented Pre-Ranking for Online Advertising",
        "url": "http://arxiv.org/abs/2306.03516v1",
        "pub_date": "2023-06-06",
        "summary": "Cascading architecture has been widely adopted in large-scale advertising\nsystems to balance efficiency and effectiveness. In this architecture, the\npre-ranking model is expected to be a lightweight approximation of the ranking\nmodel, which handles more candidates with strict latency requirements. Due to\nthe gap in model capacity, the pre-ranking and ranking models usually generate\ninconsistent ranked results, thus hurting the overall system effectiveness. The\nparadigm of score alignment is proposed to regularize their raw scores to be\nconsistent. However, it suffers from inevitable alignment errors and error\namplification by bids when applied in online advertising. To this end, we\nintroduce a consistency-oriented pre-ranking framework for online advertising,\nwhich employs a chunk-based sampling module and a plug-and-play rank alignment\nmodule to explicitly optimize consistency of ECPM-ranked results. A $\\Delta\nNDCG$-based weighting mechanism is adopted to better distinguish the importance\nof inter-chunk samples in optimization. Both online and offline experiments\nhave validated the superiority of our framework. When deployed in Taobao\ndisplay advertising system, it achieves an improvement of up to +12.3\\% CTR and\n+5.6\\% RPM.",
        "translated": "为了平衡效率和效果，级联体系结构在大规模广告系统中得到了广泛的应用。在这种体系结构中，预排序模型被期望是排序模型的轻量级近似，它处理具有严格延迟要求的更多候选者。由于模型容量的差距，预排序模型和排序模型通常会产生不一致的排序结果，从而影响系统的整体有效性。提出了分数对齐的范式，以规范他们的原始分数是一致的。然而，在网络广告中应用时，不可避免地会出现一致性错误和出价放大错误。为此，我们引入了一个面向一致性的在线广告预排序框架，该框架采用了基于块的抽样模块和即插即用的排序对齐模块来显式优化 ECPM 排序结果的一致性。为了更好地区分块间样本在优化中的重要性，采用了基于 $Delta NDCG 的加权机制。这两个在线和离线实验都验证了我们框架的优越性。在淘宝展示广告系统中，点击率和转速分别提高了12.3% 和5.6% 。"
    },
    {
        "title": "Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search",
        "url": "http://arxiv.org/abs/2306.03411v1",
        "pub_date": "2023-06-06",
        "summary": "Customers interacting with product search engines are increasingly\nformulating information-seeking queries. Frequently Asked Question (FAQ)\nretrieval aims to retrieve common question-answer pairs for a user query with\nquestion intent. Integrating FAQ retrieval in product search can not only\nempower users to make more informed purchase decisions, but also enhance user\nretention through efficient post-purchase support. Determining when an FAQ\nentry can satisfy a user's information need within product search, without\ndisrupting their shopping experience, represents an important challenge. We\npropose an intent-aware FAQ retrieval system consisting of (1) an intent\nclassifier that predicts when a user's information need can be answered by an\nFAQ; (2) a reformulation model that rewrites a query into a natural question.\nOffline evaluation demonstrates that our approach improves Hit@1 by 13% on\nretrieving ground-truth FAQs, while reducing latency by 95% compared to\nbaseline systems. These improvements are further validated by real user\nfeedback, where 71% of displayed FAQs on top of product search results received\nexplicit positive user feedback. Overall, our findings show promising\ndirections for integrating FAQ retrieval into product search at scale.",
        "translated": "与产品搜索引擎互动的客户越来越多地提出信息搜索查询。常见问题(FAQ)检索的目的是为具有问题意图的用户查询检索常见的问题-答案对。将常见问题检索整合到产品搜索中，不仅可以使用户做出更明智的购买决策，而且可以通过有效的购买后支持来提高用户保留率。在不影响用户购物体验的情况下，确定 FAQ 条目何时能够满足用户在产品搜索中的信息需求，是一个重要的挑战。我们提出了一个意图感知的 FAQ 检索系统，包括(1)意图分类器，预测何时用户的信息需求可以由 FAQ 回答; (2)重写模型，将查询重写成一个自然的问题。脱机评估表明，与基线系统相比，我们的方法在检索地面真相 FAQ 时将 Hit@1提高了13% ，同时减少了95% 的延迟。这些改进通过真实的用户反馈得到了进一步的验证，在产品搜索结果之上显示的 FAQ 中有71% 得到了明确的积极的用户反馈。总的来说，我们的研究结果为将 FAQ 检索整合到大规模的产品搜索中提供了有希望的方向。"
    },
    {
        "title": "Computational Technologies for Fashion Recommendation: A Survey",
        "url": "http://arxiv.org/abs/2306.03395v1",
        "pub_date": "2023-06-06",
        "summary": "Fashion recommendation is a key research field in computational fashion\nresearch and has attracted considerable interest in the computer vision,\nmultimedia, and information retrieval communities in recent years. Due to the\ngreat demand for applications, various fashion recommendation tasks, such as\npersonalized fashion product recommendation, complementary (mix-and-match)\nrecommendation, and outfit recommendation, have been posed and explored in the\nliterature. The continuing research attention and advances impel us to look\nback and in-depth into the field for a better understanding. In this paper, we\ncomprehensively review recent research efforts on fashion recommendation from a\ntechnological perspective. We first introduce fashion recommendation at a macro\nlevel and analyse its characteristics and differences with general\nrecommendation tasks. We then clearly categorize different fashion\nrecommendation efforts into several sub-tasks and focus on each sub-task in\nterms of its problem formulation, research focus, state-of-the-art methods, and\nlimitations. We also summarize the datasets proposed in the literature for use\nin fashion recommendation studies to give readers a brief illustration.\nFinally, we discuss several promising directions for future research in this\nfield. Overall, this survey systematically reviews the development of fashion\nrecommendation research. It also discusses the current limitations and gaps\nbetween academic research and the real needs of the fashion industry. In the\nprocess, we offer a deep insight into how the fashion industry could benefit\nfrom fashion recommendation technologies. the computational technologies of\nfashion recommendation.",
        "translated": "时尚推荐是计算时尚研究中的一个关键研究领域，近年来在计算机视觉、多媒体和信息检索社区引起了相当大的兴趣。由于应用需求的巨大，各种时尚推荐任务，如个性化的时尚产品推荐，补充(混搭)推荐，服装推荐，已提出和探讨的文献。持续的研究关注和进步促使我们回顾和深入到这一领域，以便更好地理解。本文从技术角度综述了近年来时尚推荐的研究成果。本文首先从宏观层面介绍了时尚推荐，并分析了它与一般推荐任务的特点和区别。然后，我们清楚地将不同的时尚推荐工作分为几个子任务，并根据其问题形成、研究重点、最先进的方法和局限性关注每个子任务。我们还总结了文献中提出的用于时尚推荐研究的数据集，以便给读者一个简要的说明。最后，我们讨论了这一领域未来研究的几个有希望的方向。总的来说，本调查系统地回顾了时尚推荐研究的发展。文章还讨论了当前学术研究与时尚产业实际需求之间的局限性和差距。在这个过程中，我们提供了一个深入的洞察时尚产业如何可以受益于时尚推荐技术。时尚推荐的计算技术。"
    },
    {
        "title": "CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\n  Fine-Tuning and Multi-Task Learning with Label Descriptions",
        "url": "http://arxiv.org/abs/2306.03907v1",
        "pub_date": "2023-06-06",
        "summary": "The widespread popularity of social media has led to an increase in hateful,\nabusive, and sexist language, motivating methods for the automatic detection of\nsuch phenomena. The goal of the SemEval shared task \\textit{Towards Explainable\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\nC). In this paper, we present our submitted systems for all three subtasks,\nbased on a multi-task model that has been fine-tuned on a range of related\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\nimplement multi-task learning by formulating each task as binary pairwise text\nclassification, where the dataset and label descriptions are given along with\nthe input text. The results show clear improvements over a fine-tuned\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\% in subtask A\n(rank 13/84), 64.8\\% in subtask B (rank 19/69), and 44.9\\% in subtask C\n(26/63).",
        "translated": "社交媒体的广泛流行导致了仇恨、辱骂和性别歧视语言的增加，激发了自动检测此类现象的方法。SemEval 共享任务的目标是检测英语社交媒体帖子中的性别歧视(子任务 A) ，并将这些帖子分为四个粗粒度的性别歧视类别(子任务 B)和十一个细粒度的子类别(子任务 C)。在本文中，我们提出了针对所有三个子任务的提交系统，该系统基于一个多任务模型，在针对特定的 EDOS 子任务进行微调之前，该模型已经在一系列相关任务和数据集上进行了微调。我们通过将每个任务表示为二进制成对文本分类来实现多任务学习，其中数据集和标签描述与输入文本一起给出。结果显示，与作为基线的微调 DeBERTa-V3相比，明显改善，子任务 A (排名13/84)的分数为85.9% ，子任务 B (排名19/69)为64.8% ，子任务 C 为44.9% (26/63)。"
    },
    {
        "title": "Utterance Classification with Logical Neural Network: Explainable AI for\n  Mental Disorder Diagnosis",
        "url": "http://arxiv.org/abs/2306.03902v1",
        "pub_date": "2023-06-06",
        "summary": "In response to the global challenge of mental health problems, we proposes a\nLogical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis\nof mental disorders. Due to the lack of effective therapy coverage for mental\ndisorders, there is a need for an AI solution that can assist therapists with\nthe diagnosis. However, current Neural Network models lack explainability and\nmay not be trusted by therapists. The LNN is a Recurrent Neural Network\narchitecture that combines the learning capabilities of neural networks with\nthe reasoning capabilities of classical logic-based AI. The proposed system\nuses input predicates from clinical interviews to output a mental disorder\nclass, and different predicate pruning techniques are used to achieve\nscalability and higher scores. In addition, we provide an insight extraction\nmethod to aid therapists with their diagnosis. The proposed system addresses\nthe lack of explainability of current Neural Network models and provides a more\ntrustworthy solution for mental disorder diagnosis.",
        "translated": "针对心理健康问题的全球性挑战，我们提出了一种基于逻辑神经网络(LNN)的神经符号人工智能方法来诊断精神障碍。由于缺乏有效的治疗覆盖面的精神障碍，有一个人工智能解决方案的需要，可以帮助治疗师的诊断。然而，目前的神经网络模型缺乏可解释性，可能不被治疗师信任。神经网络是一种递归神经网络结构，它结合了神经网络的学习能力和经典的基于逻辑的人工智能的推理能力。该系统使用临床访谈中的输入谓词输出一个精神障碍类，并使用不同的谓词修剪技术来实现可扩展性和更高的分数。此外，我们提供了一个洞察力提取方法，以帮助治疗师与他们的诊断。该系统解决了目前神经网络模型的不可解释性问题，为精神疾病的诊断提供了一个更可靠的解决方案。"
    },
    {
        "title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
        "url": "http://arxiv.org/abs/2306.03901v2",
        "pub_date": "2023-06-06",
        "summary": "Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .",
        "translated": "具有内存的大型语言模型(LLM)在计算上是通用的。然而，主流 LLM 并没有充分利用记忆的优势，而且设计受到生物大脑的严重影响。传统的神经记忆机制由于其近似特性和容易累积错误，不能支持 LLM 模拟复杂的推理过程。本文从现代计算机体系结构中寻找启示，用符号存储器增强复杂多跳推理的 LLM。这样的符号内存框架实例化为一个 LLM 和一组 SQL 数据库，LLM 在其中生成 SQL 指令来操作 SQL 数据库。在需要复杂推理的合成数据集上，验证了所提出的记忆框架的有效性。有关计划的网页可于 https://chatdatabase.github.io/下载。"
    },
    {
        "title": "Causal interventions expose implicit situation models for commonsense\n  language understanding",
        "url": "http://arxiv.org/abs/2306.03882v2",
        "pub_date": "2023-06-06",
        "summary": "Accounts of human language processing have long appealed to implicit\n``situation models'' that enrich comprehension with relevant but unstated world\nknowledge. Here, we apply causal intervention techniques to recent transformer\nmodels to analyze performance on the Winograd Schema Challenge (WSC), where a\nsingle context cue shifts interpretation of an ambiguous pronoun. We identify a\nrelatively small circuit of attention heads that are responsible for\npropagating information from the context word that guides which of the\ncandidate noun phrases the pronoun ultimately attends to. We then compare how\nthis circuit behaves in a closely matched ``syntactic'' control where the\nsituation model is not strictly necessary. These analyses suggest distinct\npathways through which implicit situation models are constructed to guide\npronoun resolution.",
        "translated": "长期以来，人类语言处理的描述一直呼吁隐含的“情境模型”，用相关但未陈述的世界知识丰富理解。在这里，我们将因果干预技术应用到最近的转换器模型中，以分析 Winograd 模式挑战(WSC)的表现，其中一个单一的上下文提示转移了对一个模棱两可的代词的解释。我们识别出一个相对较小的注意力回路，它负责从上下文词中传播信息，指导代词最终注意哪个候选名词短语。然后我们比较这个电路在一个紧密匹配的“语法”控制中的表现，在这个控制中情境模型并不是严格必要的。这些分析揭示了指导代词消解的内隐情境模型构建的不同途径。"
    },
    {
        "title": "Deductive Verification of Chain-of-Thought Reasoning",
        "url": "http://arxiv.org/abs/2306.03872v2",
        "pub_date": "2023-06-06",
        "summary": "Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.",
        "translated": "大型语言模型(LLM)在执行各种推理任务时显著受益于思维链(CoT)的提示。虽然 CoT 允许模型产生更全面的推理过程，但它对中间推理步骤的强调可能无意中引入幻觉和累积错误，从而限制模型解决复杂推理任务的能力。我们受到人类如何小心谨慎地进行演绎逻辑推理过程来解决任务的启发，我们试图使语言模型能够执行明确而严格的演绎推理，并通过自我验证来确保其推理过程的可信度。然而，即使使用像 chatgPT 这样的高级模型，直接验证整个演绎推理过程的有效性也是具有挑战性的。鉴于此，我们建议将推理验证过程分解为一系列逐步的子过程，每个子过程只接收其必要的上下文和前提。为了方便这个过程，我们提出了自然程序，一种基于自然语言的演绎推理格式。我们的方法使模型能够产生精确的推理步骤，其中后续步骤更严格地基于先前的步骤。它还使语言模型能够按部就班地进行推理自我验证。通过将这个验证过程整合到每个演绎推理阶段，我们大大提高了生成推理步骤的严谨性和可信度。在这个过程中，我们还提高了复杂推理任务的正确答案。密码将在 https://github.com/lz1oceani/verify_cot 公布。"
    },
    {
        "title": "Correction of Errors in Preference Ratings from Automated Metrics for\n  Text Generation",
        "url": "http://arxiv.org/abs/2306.03866v1",
        "pub_date": "2023-06-06",
        "summary": "A major challenge in the field of Text Generation is evaluation: Human\nevaluations are cost-intensive, and automated metrics often display\nconsiderable disagreement with human judgments. In this paper, we propose a\nstatistical model of Text Generation evaluation that accounts for the\nerror-proneness of automated metrics when used to generate preference rankings\nbetween system outputs. We show that existing automated metrics are generally\nover-confident in assigning significant differences between systems in this\nsetting. However, our model enables an efficient combination of human and\nautomated ratings to remedy the error-proneness of the automated metrics. We\nshow that using this combination, we only require about 50% of the human\nannotations typically used in evaluations to arrive at robust and statistically\nsignificant results while yielding the same evaluation outcome as the pure\nhuman evaluation in 95% of cases. We showcase the benefits of approach for\nthree text generation tasks: dialogue systems, machine translation, and text\nsummarization.",
        "translated": "文本生成领域的一个主要挑战是评价: 人的评价是成本密集型的，自动化度量往往显示出与人的判断相当大的分歧。本文提出了一种文本生成评价的统计模型，该模型考虑了自动化度量在生成系统输出之间的偏好排序时的错误倾向性。我们表明，现有的自动化度量通常过于自信，以至于在这种设置中分配系统之间的显著差异。然而，我们的模型能够有效地结合人工评分和自动评分来纠正自动度量的错误倾向性。我们表明，使用这种组合，我们只需要通常用于评估的约50% 的人工注释来达到稳健和统计学显着的结果，同时在95% 的情况下产生与纯人类评估相同的评估结果。我们展示了这种方法在三个文本生成任务中的优点: 对话系统、机器翻译和文本摘要。"
    },
    {
        "title": "Iterative Translation Refinement with Large Language Models",
        "url": "http://arxiv.org/abs/2306.03856v1",
        "pub_date": "2023-06-06",
        "summary": "Large language models have shown surprising performances in understanding\ninstructions and performing natural language tasks. In this paper, we propose\niterative translation refinement to leverage the power of large language models\nfor more natural translation and post-editing. We show that by simply involving\na large language model in an iterative process, the output quality improves\nbeyond mere translation. Extensive test scenarios with GPT-3.5 reveal that\nalthough iterations reduce string-based metric scores, neural metrics indicate\ncomparable if not improved translation quality. Further, human evaluations\ndemonstrate that our method effectively reduces translationese compared to\ninitial GPT translations and even human references, especially for into-English\ndirections. Ablation studies underscore the importance of anchoring the\nrefinement process to the source input and a reasonable initial translation.",
        "translated": "大型语言模型在理解指令和执行自然语言任务方面表现出惊人的表现。在本文中，我们提出了迭代翻译细化，以利用大型语言模型的力量，更自然的翻译和后期编辑。我们表明，通过简单地在迭代过程中涉及一个大的语言模型，输出质量提高超过单纯的翻译。使用 GPT-3.5的大量测试场景显示，尽管迭代减少了基于字符串的度量得分，但神经度量表明，即使没有提高翻译质量，也可以进行比较。此外，人工评估表明，我们的方法有效地减少翻译相比，最初的 GPT 翻译，甚至人工参考，特别是进入英语方向。消融研究强调了将细化过程锚定在源输入和合理的初始翻译上的重要性。"
    },
    {
        "title": "From Key Points to Key Point Hierarchy: Structured and Expressive\n  Opinion Summarization",
        "url": "http://arxiv.org/abs/2306.03853v1",
        "pub_date": "2023-06-06",
        "summary": "Key Point Analysis (KPA) has been recently proposed for deriving fine-grained\ninsights from collections of textual comments. KPA extracts the main points in\nthe data as a list of concise sentences or phrases, termed key points, and\nquantifies their prevalence. While key points are more expressive than word\nclouds and key phrases, making sense of a long, flat list of key points, which\noften express related ideas in varying levels of granularity, may still be\nchallenging. To address this limitation of KPA, we introduce the task of\norganizing a given set of key points into a hierarchy, according to their\nspecificity. Such hierarchies may be viewed as a novel type of Textual\nEntailment Graph. We develop ThinkP, a high quality benchmark dataset of key\npoint hierarchies for business and product reviews, obtained by consolidating\nmultiple annotations. We compare different methods for predicting pairwise\nrelations between key points, and for inferring a hierarchy from these pairwise\npredictions. In particular, for the task of computing pairwise key point\nrelations, we achieve significant gains over existing strong baselines by\napplying directional distributional similarity methods to a novel\ndistributional representation of key points, and further boost performance via\nweak supervision.",
        "translated": "关键点分析(Key Point Analysis，KPA)最近被提议用于从文本注释集合中获得细粒度的见解。KPA 从数据中提取主要观点作为一个简洁的句子或短语列表，称为关键点，并量化其普遍性。虽然关键点比单词云和关键短语更能表达思想，但是要理解一个长长的、扁平的关键点列表可能仍然是一个挑战，因为这些关键点通常表达的是不同粒度级别的相关思想。为了解决 KPA 的这个局限性，我们引入了这样一个任务: 根据关键点的特殊性，将一组给定的关键点组织成一个层次结构。这种等级制度可以被视为一种新型的文字蕴涵图。我们开发 ThinkP，它是一个高质量的基准数据集，通过整合多个注释获得，用于业务和产品评论的关键点层次结构。我们比较了预测关键点之间成对关系的不同方法，以及从这些成对预测中推断层次结构的不同方法。特别是对于计算成对关键点关系的任务，我们通过将方向分布相似性方法应用于一种新的关键点分布表示，在现有的强基线上取得了显著的效果，并且通过弱监督进一步提高了性能。"
    },
    {
        "title": "LEACE: Perfect linear concept erasure in closed form",
        "url": "http://arxiv.org/abs/2306.03819v1",
        "pub_date": "2023-06-06",
        "summary": "Concept erasure aims to remove specified features from a representation. It\ncan be used to improve fairness (e.g. preventing a classifier from using gender\nor race) and interpretability (e.g. removing a concept to observe changes in\nmodel behavior). In this paper, we introduce LEAst-squares Concept Erasure\n(LEACE), a closed-form method which provably prevents all linear classifiers\nfrom detecting a concept while inflicting the least possible damage to the\nrepresentation. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate the usefulness of our method on two tasks:\nmeasuring the reliance of language models on part-of-speech information, and\nreducing gender bias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.",
        "translated": "概念擦除的目的是从表示中去除特定的特征。它可以用来提高公平性(例如防止分类器使用性别或种族)和可解释性(例如移除观察模型行为变化的概念)。本文介绍了最小二乘概念擦除(LEACE)方法，这是一种可证明的闭式方法，它可以防止所有的线性分类器检测到一个概念，同时对表示造成最小可能的损害。我们将 LEACE 应用到大型语言模型中，使用了一种称为“概念擦除”的新方法，这种方法可以从网络的每一层删除目标概念信息。我们证明了我们的方法在两个任务上的有用性: 测量语言模型对词性信息的依赖性，以及减少 BERT 嵌入中的性别偏见。密码可于 https://github.com/eleutherai/concept-erasure 索取。"
    },
    {
        "title": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.03799v1",
        "pub_date": "2023-06-06",
        "summary": "Prompt engineering is an essential technique for enhancing the abilities of\nlarge language models (LLMs) by providing explicit and specific instructions.\nIt enables LLMs to excel in various tasks, such as arithmetic reasoning,\nquestion answering, summarization, relation extraction, machine translation,\nand sentiment analysis. Researchers have been actively exploring different\nprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and\nIn-context learning. However, an unresolved problem arises from the fact that\ncurrent approaches lack a solid theoretical foundation for determining optimal\nprompts. To address this issue in prompt engineering, we propose a new and\neffective approach called Prompt Space. Our methodology utilizes text\nembeddings to obtain basis vectors by matrix decomposition, and then constructs\na space for representing all prompts. Prompt Space significantly outperforms\nstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,\nwithout the help of the CoT method and the prompt \"Let's think step by step\",\nPrompt Space shows superior performance over the few-shot method. Overall, our\napproach provides a robust and fundamental theoretical framework for selecting\nsimple and effective prompts. This advancement marks a significant step towards\nimproving prompt engineering for a wide variety of applications in LLMs.",
        "translated": "提示工程是通过提供明确和具体的指令来提高大型语言模型(LLM)能力的一种基本技术。它使 LLM 能够胜任各种任务，例如算术推理、问题回答、总结、关系提取、机器翻译和情感分析。研究人员一直在积极探索不同的快速工程策略，如思维链(CoT) ，零 CoT 和在上下文中学习。然而，一个未解决的问题出现在这样一个事实上，即目前的方法缺乏确定最佳提示的坚实的理论基础。为了在快速工程中解决这个问题，我们提出了一种新的和有效的方法称为快速空间。我们的方法利用文本嵌入通过矩阵分解获得基向量，然后构造一个空间来表示所有的提示。Prompt Space 在10个公共推理基准上明显优于最先进的提示范例。值得注意的是，没有 CoT 方法和提示“让我们一步一步地思考”的帮助，Prompt Space 显示出优于少数镜头方法的性能。总的来说，我们的方法为选择简单有效的提示提供了一个强大的基础理论框架。这一进展标志着在改进 LLM 中各种应用的快速工程方面迈出了重要的一步。"
    },
    {
        "title": "MarineVRS: Marine Video Retrieval System with Explainability via\n  Semantic Understanding",
        "url": "http://arxiv.org/abs/2306.04593v1",
        "pub_date": "2023-06-07",
        "summary": "Building a video retrieval system that is robust and reliable, especially for\nthe marine environment, is a challenging task due to several factors such as\ndealing with massive amounts of dense and repetitive data, occlusion,\nblurriness, low lighting conditions, and abstract queries. To address these\nchallenges, we present MarineVRS, a novel and flexible video retrieval system\ndesigned explicitly for the marine domain. MarineVRS integrates\nstate-of-the-art methods for visual and linguistic object representation to\nenable efficient and accurate search and analysis of vast volumes of underwater\nvideo data. In addition, unlike the conventional video retrieval system, which\nonly permits users to index a collection of images or videos and search using a\nfree-form natural language sentence, our retrieval system includes an\nadditional Explainability module that outputs the segmentation masks of the\nobjects that the input query referred to. This feature allows users to identify\nand isolate specific objects in the video footage, leading to more detailed\nanalysis and understanding of their behavior and movements. Finally, with its\nadaptability, explainability, accuracy, and scalability, MarineVRS is a\npowerful tool for marine researchers and scientists to efficiently and\naccurately process vast amounts of data and gain deeper insights into the\nbehavior and movements of marine species.",
        "translated": "建立一个健壮可靠的视频检索系统，特别是对于海洋环境来说，是一个具有挑战性的任务，因为有几个因素，如处理大量密集和重复的数据，遮挡，模糊，低照明条件和抽象查询。为了应对这些挑战，我们提出了 MarineVRS，一个新颖的和灵活的视频检索系统，明确地为海洋领域设计。MarineVRS 集成了最先进的视觉和语言对象表示方法，能够高效、准确地搜索和分析海量水下视频数据。此外，与传统的视频检索系统不同，传统的视频检索系统只允许用户索引一组图像或视频并使用自由格式的自然语言句子进行搜索，我们的检索系统包括一个额外的可解释性模块，该模块输出输入查询引用的对象的分割掩码。这个功能允许用户识别和隔离视频画面中的特定物体，从而对它们的行为和动作进行更详细的分析和理解。最后，凭借其适应性、可解释性、准确性和可扩展性，MarineVRS 是海洋研究人员和科学家有效和准确地处理大量数据并获得对海洋物种行为和运动的更深刻见解的强大工具。"
    },
    {
        "title": "Constraint-based recommender system for crisis management simulations",
        "url": "http://arxiv.org/abs/2306.04553v1",
        "pub_date": "2023-06-07",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Embracing Uncertainty: Adaptive Vague Preference Policy Learning for\n  Multi-round Conversational Recommendation",
        "url": "http://arxiv.org/abs/2306.04487v1",
        "pub_date": "2023-06-07",
        "summary": "Conversational recommendation systems (CRS) effectively address information\nasymmetry by dynamically eliciting user preferences through multi-turn\ninteractions. Existing CRS widely assumes that users have clear preferences.\nUnder this assumption, the agent will completely trust the user feedback and\ntreat the accepted or rejected signals as strong indicators to filter items and\nreduce the candidate space, which may lead to the problem of over-filtering.\nHowever, in reality, users' preferences are often vague and volatile, with\nuncertainty about their desires and changing decisions during interactions.\n  To address this issue, we introduce a novel scenario called Vague Preference\nMulti-round Conversational Recommendation (VPMCR), which considers users' vague\nand volatile preferences in CRS.VPMCR employs a soft estimation mechanism to\nassign a non-zero confidence score for all candidate items to be displayed,\nnaturally avoiding the over-filtering problem. In the VPMCR setting, we\nintroduce an solution called Adaptive Vague Preference Policy Learning (AVPPL),\nwhich consists of two main components: Uncertainty-aware Soft Estimation (USE)\nand Uncertainty-aware Policy Learning (UPL). USE estimates the uncertainty of\nusers' vague feedback and captures their dynamic preferences using a\nchoice-based preferences extraction module and a time-aware decaying strategy.\nUPL leverages the preference distribution estimated by USE to guide the\nconversation and adapt to changes in users' preferences to make recommendations\nor ask for attributes.\n  Our extensive experiments demonstrate the effectiveness of our method in the\nVPMCR scenario, highlighting its potential for practical applications and\nimproving the overall performance and applicability of CRS in real-world\nsettings, particularly for users with vague or dynamic preferences.",
        "translated": "会话推荐系统(CRS)通过多回合交互动态引出用户偏好，从而有效地解决信息不对称问题。现有的 CRS 普遍假设用户有明确的偏好。在这种假设下，代理完全信任用户的反馈，将接受或拒绝的信号作为强指标来过滤项目，减少候选空间，从而可能导致过滤问题。然而，在现实中，用户的偏好往往是模糊和不稳定的，他们的愿望和交互过程中改变决定的不确定性。为了解决这一问题，我们引入了一种新的场景——模糊偏好多轮会话推荐(VPMCR) ，该场景考虑了 CRS 中用户的模糊和不稳定偏好。 VPMCR 采用了一种软估计机制，为所有待显示的候选项赋予一个非零置信度分数，自然避免了过滤问题。在 VPCR 设置中，我们引入了一个称为自适应模糊偏好策略学习(AdaptiveVague Preferences Policy Learning，AVPPL)的解决方案，该解决方案由两个主要组件组成: 不确定感知软估计(UUSE)和不确定感知策略学习(UPL)。USE 利用基于选择的偏好提取模块和时间感知衰减策略估计用户模糊反馈的不确定性，并获取用户的动态偏好。UPL 利用 USE 估计的偏好分布来引导对话，并适应用户偏好的变化来提出建议或请求属性。我们的广泛实验证明了我们的方法在 VPCR 场景中的有效性，突出了其实际应用的潜力，并提高了 CRS 在现实世界环境中的总体性能和适用性，特别是对于具有模糊或动态偏好的用户。"
    },
    {
        "title": "RD-Suite: A Benchmark for Ranking Distillation",
        "url": "http://arxiv.org/abs/2306.04455v1",
        "pub_date": "2023-06-07",
        "summary": "The distillation of ranking models has become an important topic in both\nacademia and industry. In recent years, several advanced methods have been\nproposed to tackle this problem, often leveraging ranking information from\nteacher rankers that is absent in traditional classification settings. To date,\nthere is no well-established consensus on how to evaluate this class of models.\nMoreover, inconsistent benchmarking on a wide range of tasks and datasets make\nit difficult to assess or invigorate advances in this field. This paper first\nexamines representative prior arts on ranking distillation, and raises three\nquestions to be answered around methodology and reproducibility. To that end,\nwe propose a systematic and unified benchmark, Ranking Distillation Suite\n(RD-Suite), which is a suite of tasks with 4 large real-world datasets,\nencompassing two major modalities (textual and numeric) and two applications\n(standard distillation and distillation transfer). RD-Suite consists of\nbenchmark results that challenge some of the common wisdom in the field, and\nthe release of datasets with teacher scores and evaluation scripts for future\nresearch. RD-Suite paves the way towards better understanding of ranking\ndistillation, facilities more research in this direction, and presents new\nchallenges.",
        "translated": "排序模型的提取已经成为学术界和工业界的一个重要课题。近年来，一些先进的方法被提出来解决这个问题，往往利用排名信息从教师排名，这是缺乏在传统的分类设置。到目前为止，对于如何评估这类模型还没有确定的共识。此外，对广泛的任务和数据集不一致的基准设定使得难以评估或激励这一领域的进展。本文首先考察了有代表性的等级精馏现有技术，并围绕方法论和可重复性提出了三个需要回答的问题。为此，我们提出了一个系统和统一的基准，秩序蒸馏套件(RD-Suite) ，这是一套任务与4个大型真实世界数据集，包括两个主要模式(文本和数字)和两个应用程序(标准蒸馏和蒸馏转移)。RD-Suite 包括挑战该领域常识的基准测试结果，以及发布包含教师成绩和未来研究评估脚本的数据集。RD-Suite 为更好地理解分级蒸馏铺平了道路，设备在这个方向上进行了更多的研究，并提出了新的挑战。"
    },
    {
        "title": "Modeling Dual Period-Varying Preferences for Takeaway Recommendation",
        "url": "http://arxiv.org/abs/2306.04370v1",
        "pub_date": "2023-06-07",
        "summary": "Takeaway recommender systems, which aim to accurately provide stores that\noffer foods meeting users' interests, have served billions of users in our\ndaily life. Different from traditional recommendation, takeaway recommendation\nfaces two main challenges: (1) Dual Interaction-Aware Preference Modeling.\nTraditional recommendation commonly focuses on users' single preferences for\nitems while takeaway recommendation needs to comprehensively consider users'\ndual preferences for stores and foods. (2) Period-Varying Preference Modeling.\nConventional recommendation generally models continuous changes in users'\npreferences from a session-level or day-level perspective. However, in\npractical takeaway systems, users' preferences vary significantly during the\nmorning, noon, night, and late night periods of the day. To address these\nchallenges, we propose a Dual Period-Varying Preference modeling (DPVP) for\ntakeaway recommendation. Specifically, we design a dual interaction-aware\nmodule, aiming to capture users' dual preferences based on their interactions\nwith stores and foods. Moreover, to model various preferences in different time\nperiods of the day, we propose a time-based decomposition module as well as a\ntime-aware gating mechanism. Extensive offline and online experiments\ndemonstrate that our model outperforms state-of-the-art methods on real-world\ndatasets and it is capable of modeling the dual period-varying preferences.\nMoreover, our model has been deployed online on Meituan Takeaway platform,\nleading to an average improvement in GMV (Gross Merchandise Value) of 0.70%.",
        "translated": "外卖推荐系统，旨在准确地提供商店，提供符合用户兴趣的食品，已服务于数十亿用户在我们的日常生活。与传统的推荐不同，外卖推荐面临着两个主要挑战: (1)双交互感知偏好建模。传统的推荐方式通常侧重于用户对商品的单一偏好，而外卖推荐方式则需要全面考虑用户对商店和食品的双重偏好。(变周期偏好模型。传统的推荐通常从会话级或日级的角度模拟用户偏好的持续变化。然而，在实际的外卖系统中，用户的偏好在白天的早上、中午、晚上和深夜各不相同。为了应对这些挑战，我们提出了一个外卖推荐的双周期变化偏好模型(DPVP)。具体来说，我们设计了一个双交互感知模块，旨在根据用户与商店和食物的交互来捕捉他们的双重偏好。此外，为了模拟一天中不同时段的各种偏好，我们提出了一个基于时间的分解模块以及一个时间感知的门控机制。大量的离线和在线实验表明，我们的模型优于现实世界数据集的最先进的方法，它能够建模的双周期变化的偏好。此外，我们的模型已经在美团外卖平台上进行了在线部署，导致平均商品总值(GMV)提高了0.70% 。"
    },
    {
        "title": "ModuleFormer: Learning Modular Large Language Models From Uncurated Data",
        "url": "http://arxiv.org/abs/2306.04640v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have achieved remarkable results. But existing\nmodels are expensive to train and deploy, and it is also difficult to expand\ntheir knowledge beyond pre-training data without forgetting previous knowledge.\nThis paper proposes a new neural network architecture, ModuleFormer, that\nleverages modularity to improve the efficiency and flexibility of large\nlanguage models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).\nUnlike the previous SMoE-based modular language model [Gururangan et al.,\n2021], which requires domain-labeled data to learn domain-specific experts,\nModuleFormer can induce modularity from uncurated data with its new load\nbalancing and load concentration losses. ModuleFormer is a modular architecture\nthat includes two different types of modules, new stick-breaking attention\nheads, and feedforward experts. Different modules are sparsely activated\nconditions on the input token during training and inference. In our experiment,\nwe found that the modular architecture enables three important abilities for\nlarge pre-trained language models: 1) Efficiency, since ModuleFormer only\nactivates a subset of its modules for each input token, thus it could achieve\nthe same performance as dense LLMs with more than two times throughput; 2)\nExtendability, ModuleFormer is more immune to catastrophic forgetting than\ndense LLMs and can be easily extended with new modules to learn new knowledge\nthat is not included in the training data; 3) Specialisation, finetuning\nModuleFormer could specialize a subset of modules to the finetuning task, and\nthe task-unrelated modules could be easily pruned for a lightweight deployment.",
        "translated": "大语言模型(LLM)已经取得了显著的成果。但现有模型的培训和部署成本很高，而且很难在不忘记先前知识的情况下扩展其知识范围，超出培训前的数据。本文提出了一种新的神经网络结构——模块化网络结构，该结构利用模块化来提高大型语言模型的效率和灵活性。基于稀疏混合专家算法(SMoE)的模块形成器。与以前基于 SMoE 的模块化语言模型[ Gururangan et al。 ，2021]不同，其需要领域标记的数据来学习领域特定的专家，ModuleForm 可以通过其新的负载平衡和负载集中损失来诱导未经策划的数据的模块化。ModuleForm 是一个模块化架构，包括两种不同类型的模块、新的分散注意力的头部和前馈专家。在训练和推理过程中，不同的模块在输入令牌上是稀疏激活的条件。在我们的实验中，我们发现模块化架构为大型预先训练的语言模型提供了三个重要的能力: 1)效率，因为模块化程序只为每个输入令牌激活其模块的一个子集，因此它可以达到与密集 LLM 相同的性能，吞吐量超过两倍; 2)可扩展性，模块化程序比密集 LLM 更能免疫灾难性遗忘，并且可以很容易地用新模块进行扩展，以学习未包含在训练数据中的新知识; 3)专业化，微调的模块化程序可以为微调任务专门化模块的一个子集，并且与任务无关的模块可以很容易地为。"
    },
    {
        "title": "Transformers as Statisticians: Provable In-Context Learning with\n  In-Context Algorithm Selection",
        "url": "http://arxiv.org/abs/2306.04637v1",
        "pub_date": "2023-06-07",
        "summary": "Neural sequence models based on the transformer architecture have\ndemonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they\ncan perform new tasks when prompted with training and test examples, without\nany parameter update to the model. This work first provides a comprehensive\nstatistical theory for transformers to perform ICL. Concretely, we show that\ntransformers can implement a broad class of standard machine learning\nalgorithms in context, such as least squares, ridge regression, Lasso, learning\ngeneralized linear models, and gradient descent on two-layer neural networks,\nwith near-optimal predictive power on various in-context data distributions.\nUsing an efficient implementation of in-context gradient descent as the\nunderlying mechanism, our transformer constructions admit mild size bounds, and\ncan be learned with polynomially many pretraining sequences.\n  Building on these ``base'' ICL algorithms, intriguingly, we show that\ntransformers can implement more complex ICL procedures involving\n\\emph{in-context algorithm selection}, akin to what a statistician can do in\nreal life -- A \\emph{single} transformer can adaptively select different base\nICL algorithms -- or even perform qualitatively different tasks -- on different\ninput sequences, without any explicit prompting of the right algorithm or task.\nWe both establish this in theory by explicit constructions, and also observe\nthis phenomenon experimentally. In theory, we construct two general mechanisms\nfor algorithm selection with concrete examples: pre-ICL testing, and post-ICL\nvalidation. As an example, we use the post-ICL validation mechanism to\nconstruct a transformer that can perform nearly Bayes-optimal ICL on a\nchallenging task -- noisy linear models with mixed noise levels.\nExperimentally, we demonstrate the strong in-context algorithm selection\ncapabilities of standard transformer architectures.",
        "translated": "基于变压器结构的神经序列模型表现出了显著的移动{在上下文中学习}(ICL)能力，它们可以在训练和测试示例的提示下执行新的任务，而不需要对模型进行任何参数更新。这项工作首先为变压器执行 ICL 提供了一个全面的统计理论。具体来说，我们展示了变压器可以在上下文环境中实现一大类标准的机器学习算法，如最小二乘、岭回归、套索、学习广义线性模型，以及在两层神经网络上实现梯度下降法，对各种上下文数据分布具有近乎最优的预测能力。使用一个有效的实现在上下文中的梯度下降法作为底层机制，我们的变压器结构承认温和的大小界限，可以学习与多项式许多预训练序列。在这些“基本”ICL 算法的基础上，有趣的是，我们展示了变压器可以实现更复杂的 ICL 程序，包括 emph { in-context 算法选择} ，类似于统计学家在现实生活中可以做的——一个 emph { single }变压器可以自适应地选择不同的基本 ICL 算法——甚至可以执行定性上不同的任务——在不同的输入序列上，没有任何明确的正确算法或任务的提示。我们通过明确的结构在理论上建立了这种现象，并且通过实验观察了这种现象。在理论上，我们通过具体的实例构造了两种通用的算法选择机制: 前 ICL 测试和后 ICL 验证。作为一个例子，我们使用后 ICL 验证机制来构造一个变压器，可以执行接近贝叶斯最优的 ICL 在一个具有挑战性的任务-混合噪声水平的线性模型。实验表明，标准变压器结构具有很强的上下文算法选择能力。"
    },
    {
        "title": "On the Reliability of Watermarks for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04634v1",
        "pub_date": "2023-06-07",
        "summary": "Large language models (LLMs) are now deployed to everyday use and positioned\nto produce large quantities of text in the coming decade. Machine-generated\ntext may displace human-written text on the internet and has the potential to\nbe used for malicious purposes, such as spearphishing attacks and social media\nbots. Watermarking is a simple and effective strategy for mitigating such harms\nby enabling the detection and documentation of LLM-generated text. Yet, a\ncrucial question remains: How reliable is watermarking in realistic settings in\nthe wild? There, watermarked text might be mixed with other text sources,\nparaphrased by human writers or other language models, and used for\napplications in a broad number of domains, both social and technical. In this\npaper, we explore different detection schemes, quantify their power at\ndetecting watermarks, and determine how much machine-generated text needs to be\nobserved in each scenario to reliably detect the watermark. We especially\nhighlight our human study, where we investigate the reliability of watermarking\nwhen faced with human paraphrasing. We compare watermark-based detection to\nother detection strategies, finding overall that watermarking is a reliable\nsolution, especially because of its sample complexity - for all attacks we\nconsider, the watermark evidence compounds the more examples are given, and the\nwatermark is eventually detected.",
        "translated": "大型语言模型(LLM)现在被部署到日常使用中，并定位于在未来十年生成大量文本。机器生成的文本可能取代互联网上人写的文本，并有可能被用于恶意目的，如鱼叉式钓鱼攻击和社交媒体机器人。水印是一种简单而有效的策略，通过检测和记录 LLM 生成的文本来减轻这种危害。然而，一个关键的问题仍然存在: 在野外的现实环境中，水印的可靠性如何？在那里，水印文本可能与其他文本来源混合，由人类作家或其他语言模型转述，并用于广泛的领域中的应用，包括社会和技术。在本文中，我们探讨了不同的检测方案，量化它们在检测水印方面的能力，并确定在每个场景中需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调我们的人类研究，我们调查的可靠性水印时，面对人类释义。我们比较了基于水印的检测和其他检测策略，发现水印是一个可靠的解决方案，特别是因为它的样本复杂性-对于所有的攻击，我们考虑，水印证据复合越多的例子，并最终检测水印。"
    },
    {
        "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,\n  and LLMs Evaluations",
        "url": "http://arxiv.org/abs/2306.04618v1",
        "pub_date": "2023-06-07",
        "summary": "This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.",
        "translated": "本文重新审视了自然语言处理领域中分布外(OOD)鲁棒性的研究。我们发现在以往的研究中，分布移位设置通常缺乏足够的挑战，阻碍了面向对象的鲁棒性的准确评估。为了解决这些问题，我们提出了一个基准建设协议，以确保明确的差异和挑战性的分配转移。然后我们介绍了 BOSS，一个用于分布外鲁棒性评估的基准套件，包括5个任务和20个数据集。基于 BOSS 系统，我们对预训练语言模型进行了一系列的实验，用于分析和评估面向对象的鲁棒性。首先，对于普通的微调，我们研究分发内(ID)和 OOD 性能之间的关系。我们确定了三种典型的类型，揭示了内部学习机制，这可能有助于面向对象的鲁棒性预测，与 ID 数据集的进步相关。然后，我们对 BOSS 上的5种经典方法进行了评估，发现尽管它们在特定情况下显示出一些有效性，但与普通的微调相比，它们并没有提供显著的改进。此外，我们评估了5个具有不同适应范例的 LLM，发现当有足够的 ID 数据可用时，针对特定领域的微调模型在 ID 示例上的表现明显优于 LLM。但是，在面向对象的实例中，使用上下文内学习对 LLM 进行优先排序会产生更好的结果。我们发现，微调小型模型和 LLM 在有效处理下游任务方面都面临挑战。该代码在 url { https://github.com/lifan-yuan/ood_nlp }是公共的。"
    },
    {
        "title": "The Two Word Test: A Semantic Benchmark for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04610v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have shown remarkable abilities recently,\nincluding passing advanced professional exams and demanding benchmark tests.\nThis performance has led many to suggest that they are close to achieving\nhumanlike or 'true' understanding of language, and even Artificial General\nIntelligence (AGI). Here, we provide a new open-source benchmark that can\nassess semantic abilities of LLMs using two-word phrases using a task that can\nbe performed relatively easily by humans without advanced training. Combining\nmultiple words into a single concept is a fundamental aspect of human language\nand intelligence. The test requires meaningfulness judgments of 1768 noun-noun\ncombinations that have been rated as meaningful (e.g., baby boy) or not\nmeaningful (e.g., goat sky). by 150 human raters. We provide versions of the\ntask that probe meaningfulness ratings on a 0-4 scale as well as binary\njudgments. We conducted a series of experiments using the TWT on GPT-4,\nGPT-3.5, and Bard, with both versions. Results demonstrated that, compared to\nhumans, all models perform poorly at rating meaningfulness of these phrases.\nGPT-3.5 and Bard are also unable to make binary discriminations between\nsensible and nonsense phrases as making sense. GPT-4 makes a substantial\nimprovement in binary discrimination of combinatorial phrases but is still\nsignificantly worse than human performance. The TWT can be used to understand\nthe limitations and weaknesses of current LLMs, and potentially improve them.\nThe test also reminds us that caution is warranted in attributing 'true\nunderstanding' or AGI to LLMs. TWT is available at:\nhttps://github.com/NickRiccardi/two-word-test",
        "translated": "大型语言模型(LLM)最近显示出非凡的能力，包括通过高级专业考试和苛刻的基准测试。这种表现使得许多人认为他们已经接近达到类人或“真正”理解语言，甚至人工通用智能(AGI)。在这里，我们提供了一个新的开源基准，可以使用两个词的短语来评估 LLM 的语义能力，使用的任务可以相对容易地由人类执行，而不需要高级培训。将多个单词组合成一个单一的概念是人类语言和智力的一个基本方面。这个测试需要对1768个名词和名词的组合进行有意义的判断，这些组合被认为是有意义的(比如，男婴)或者没有意义的(比如，山羊天空)。被150个人类评估员评估。我们提供了任务的版本，探讨有意义的评级在0-4尺度以及二元判断。我们使用行波管在 GPT-4、 GPT-3.5和巴德上进行了一系列的实验，两个版本都有。结果表明，与人类相比，所有的模型在评价这些短语的意义方面表现不佳。GPT-3.5和巴德也不能把明智的和无意义的短语作为有意义的二元区分。GPT-4在组合短语的二进制识别方面有显著改善，但仍明显低于人类的识别水平。行波管可以用来了解现有 LLM 的局限性和弱点，并可能改进它们。该测试还提醒我们，在将“真正的理解”或 AGI 归因于 LLM 时，谨慎是必要的。TWT 可在以下 https://github.com/nickriccardi/two-word-test 购买:"
    },
    {
        "title": "Language Models Get a Gender Makeover: Mitigating Gender Bias with\n  Few-Shot Data Interventions",
        "url": "http://arxiv.org/abs/2306.04597v1",
        "pub_date": "2023-06-07",
        "summary": "Societal biases present in pre-trained large language models are a critical\nissue as these models have been shown to propagate biases in countless\ndownstream applications, rendering them unfair towards specific groups of\npeople. Since large-scale retraining of these models from scratch is both time\nand compute-expensive, a variety of approaches have been previously proposed\nthat de-bias a pre-trained model. While the majority of current\nstate-of-the-art debiasing methods focus on changes to the training regime, in\nthis paper, we propose data intervention strategies as a powerful yet simple\ntechnique to reduce gender bias in pre-trained models. Specifically, we\nempirically show that by fine-tuning a pre-trained model on only 10 de-biased\n(intervened) training examples, the tendency to favor any gender is\nsignificantly reduced. Since our proposed method only needs a few training\nexamples, our few-shot debiasing approach is highly feasible and practical.\nThrough extensive experimentation, we show that our debiasing technique\nperforms better than competitive state-of-the-art baselines with minimal loss\nin language modeling ability.",
        "translated": "预先训练的大型语言模型中存在的社会偏见是一个关键问题，因为这些模型已被证明在无数下游应用程序中传播偏见，使它们对特定人群不公平。由于从头开始对这些模型进行大规模的再训练既耗费时间又耗费计算机资源，因此先前已经提出了各种方法来消除预训练模型的偏差。虽然目前大多数最先进的消除偏见的方法集中在训练体制的变化，在本文中，我们提出的数据干预策略作为一个强大而简单的技术，以减少预训练模型中的性别偏见。具体来说，我们的经验表明，通过微调一个预先训练的模型，只有10个无偏见(干预)训练的例子，倾向于任何性别显着降低。由于本文提出的方法只需要少量训练样本，因此本文提出的小镜头消偏方法具有很高的可行性和实用性。通过大量的实验，我们发现我们的去偏技术在语言建模能力损失最小的情况下比竞争性的最先进的基线表现得更好。"
    },
    {
        "title": "Gender, names and other mysteries: Towards the ambiguous for\n  gender-inclusive translation",
        "url": "http://arxiv.org/abs/2306.04573v1",
        "pub_date": "2023-06-07",
        "summary": "The vast majority of work on gender in MT focuses on 'unambiguous' inputs,\nwhere gender markers in the source language are expected to be resolved in the\noutput. Conversely, this paper explores the widespread case where the source\nsentence lacks explicit gender markers, but the target sentence contains them\ndue to richer grammatical gender. We particularly focus on inputs containing\nperson names.\n  Investigating such sentence pairs casts a new light on research into MT\ngender bias and its mitigation. We find that many name-gender co-occurrences in\nMT data are not resolvable with 'unambiguous gender' in the source language,\nand that gender-ambiguous examples can make up a large proportion of training\nexamples. From this, we discuss potential steps toward gender-inclusive\ntranslation which accepts the ambiguity in both gender and translation.",
        "translated": "在机器翻译领域，绝大多数关于性别的工作集中在“明确的”输入上，源语言中的性别标记预计将在输出中得到解决。相反，本文探讨了普遍存在的一种情况，即原句缺乏明确的性别标记，但是由于性丰富，目标句包含了这些性别标记。我们特别关注包含人名的输入。对这类句子对的研究为 MT 性别偏见的研究及其缓解提供了新的视角。我们发现，在机器翻译数据中，许多名称-性别同时出现的情况不能用源语言中的“明确的性别”来解决，而且性别模糊的例子可以构成很大比例的训练例子。从这一点出发，我们讨论了实现性别包容性翻译的可能步骤，即接受性别歧义和翻译歧义。"
    },
    {
        "title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.04563v1",
        "pub_date": "2023-06-07",
        "summary": "Humor is a central aspect of human communication that has not been solved for\nartificial agents so far. Large language models (LLMs) are increasingly able to\ncapture implicit and contextual information. Especially, OpenAI's ChatGPT\nrecently gained immense public attention. The GPT3-based model almost seems to\ncommunicate on a human level and can even tell jokes. Humor is an essential\ncomponent of human communication. But is ChatGPT really funny? We put ChatGPT's\nsense of humor to the test. In a series of exploratory experiments around\njokes, i.e., generation, explanation, and detection, we seek to understand\nChatGPT's capability to grasp and reproduce human humor. Since the model itself\nis not accessible, we applied prompt-based experiments. Our empirical evidence\nindicates that jokes are not hard-coded but mostly also not newly generated by\nthe model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system\naccurately explains valid jokes but also comes up with fictional explanations\nfor invalid jokes. Joke-typical characteristics can mislead ChatGPT in the\nclassification of jokes. ChatGPT has not solved computational humor yet but it\ncan be a big leap toward \"funny\" machines.",
        "translated": "幽默是人类交流的一个核心方面，迄今为止人工智能还没有解决这个问题。大型语言模型(LLM)越来越能够捕获隐式信息和上下文信息。尤其是 OpenAI 的 ChatGPT 最近引起了公众的广泛关注。基于 GPT3的模型几乎可以在人类水平上交流，甚至可以讲笑话。幽默是人际交往的重要组成部分。但是聊天 GPT 真的有趣吗？我们测试了 ChatGPT 的幽默感。在一系列围绕笑话的探索性实验中，即生成、解释和发现，我们试图理解 ChatGPT 掌握和再现人类幽默的能力。由于模型本身不可访问，我们应用了基于提示的实验。我们的经验证明表明，笑话不是硬编码的，但大多数也不是模型新生成的。在1008个笑话中，超过90% 的笑话都是相同的25个。该系统准确地解释了有效的笑话，但同时也为无效的笑话提供了虚构的解释。笑话的典型特征会误导聊天 GPT 对笑话的分类。ChatGPT 还没有解决计算幽默问题，但是它可以向“有趣的”机器迈出一大步。"
    },
    {
        "title": "Multi-Task Training with In-Domain Language Models for Diagnostic\n  Reasoning",
        "url": "http://arxiv.org/abs/2306.04551v1",
        "pub_date": "2023-06-07",
        "summary": "Generative artificial intelligence (AI) is a promising direction for\naugmenting clinical diagnostic decision support and reducing diagnostic errors,\na leading contributor to medical errors. To further the development of clinical\nAI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a\ncomprehensive generative AI framework, comprised of six tasks representing key\ncomponents in clinical reasoning. We present a comparative analysis of\nin-domain versus out-of-domain language models as well as multi-task versus\nsingle task training with a focus on the problem summarization task in DR.BENCH\n(Gao et al., 2023). We demonstrate that a multi-task, clinically trained\nlanguage model outperforms its general domain counterpart by a large margin,\nestablishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.\nThis research underscores the value of domain-specific training for optimizing\nclinical diagnostic reasoning tasks.",
        "translated": "生成性人工智能(AI)是增强临床诊断决策支持和减少诊断错误的一个有前途的方向，是导致医疗错误的主要因素。为了进一步发展临床人工智能系统，将诊断推理基准(DR.BENCH)作为一个全面的生成性人工智能框架引入，该框架由代表临床推理关键组成部分的六个任务组成。我们提出了领域内与领域外语言模型以及多任务与单任务训练的比较分析，重点是 DR.BENCH 中的问题总结任务(Gao et al。 ，2023)。我们证明，一个多任务，临床训练的语言模型优于其一般领域的对应大幅度，建立一个新的最先进的表现，ROUGE-L 分数为28.55。本研究强调了领域特定训练对于优化临床诊断推理任务的价值。"
    },
    {
        "title": "Contrastive Bootstrapping for Label Refinement",
        "url": "http://arxiv.org/abs/2306.04544v1",
        "pub_date": "2023-06-07",
        "summary": "Traditional text classification typically categorizes texts into pre-defined\ncoarse-grained classes, from which the produced models cannot handle the\nreal-world scenario where finer categories emerge periodically for accurate\nservices. In this work, we investigate the setting where fine-grained\nclassification is done only using the annotation of coarse-grained categories\nand the coarse-to-fine mapping. We propose a lightweight contrastive\nclustering-based bootstrapping method to iteratively refine the labels of\npassages. During clustering, it pulls away negative passage-prototype pairs\nunder the guidance of the mapping from both global and local perspectives.\nExperiments on NYT and 20News show that our method outperforms the\nstate-of-the-art methods by a large margin.",
        "translated": "传统的文本分类通常将文本分类为预定义的粗粒度类，由此产生的模型无法处理现实场景，即定期出现更精细的类别以获得准确的服务。在这项工作中，我们研究的设置，细粒度分类是完成只使用粗粒度类别的注释和粗到细的映射。提出了一种基于轻量级对比聚类的自举算法来迭代细化文章标签。在聚类过程中，它在映射的指导下，从全局和局部两个角度抽取负的通道原型对。在《纽约时报》和《20世纪新闻》上的实验表明，我们的方法比最先进的方法有很大的优势。"
    },
    {
        "title": "Safe Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.05292v1",
        "pub_date": "2023-06-08",
        "summary": "Excellent tail performance is crucial for modern machine learning tasks, such\nas algorithmic fairness, class imbalance, and risk-sensitive decision making,\nas it ensures the effective handling of challenging samples within a dataset.\nTail performance is also a vital determinant of success for personalised\nrecommender systems to reduce the risk of losing users with low satisfaction.\nThis study introduces a \"safe\" collaborative filtering method that prioritises\nrecommendation quality for less-satisfied users rather than focusing on the\naverage performance. Our approach minimises the conditional value at risk\n(CVaR), which represents the average risk over the tails of users' loss. To\novercome computational challenges for web-scale recommender systems, we develop\na robust yet practical algorithm that extends the most scalable method,\nimplicit alternating least squares (iALS). Empirical evaluation on real-world\ndatasets demonstrates the excellent tail performance of our approach while\nmaintaining competitive computational efficiency.",
        "translated": "优秀的尾部性能对于现代机器学习任务至关重要，例如算法公平性、类不平衡性和风险敏感决策，因为它确保有效处理数据集中具有挑战性的样本。尾部性能也是个性化推荐系统成功的一个重要决定因素，可以降低用户满意度不高而流失的风险。这项研究引入了一种“安全”的协同过滤方法，优先考虑对不满意用户的推荐质量，而不是关注平均性能。我们的方法将条件风险值(CVaR)最小化，CVaR 代表用户损失尾部的平均风险。为了克服网络规模推荐系统的计算挑战，我们开发了一个强大而实用的算法，扩展了最可扩展的方法，隐式交替最小二乘(iALS)。对真实世界数据集的实证评估证明了该方法在保持竞争计算效率的同时具有优异的尾部性能。"
    },
    {
        "title": "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit",
        "url": "http://arxiv.org/abs/2306.05212v1",
        "pub_date": "2023-06-08",
        "summary": "Although Large Language Models (LLMs) have demonstrated extraordinary\ncapabilities in many domains, they still have a tendency to hallucinate and\ngenerate fictitious responses to user requests. This problem can be alleviated\nby augmenting LLMs with information retrieval (IR) systems (also known as\nretrieval-augmented LLMs). Applying this strategy, LLMs can generate more\nfactual texts in response to user input according to the relevant content\nretrieved by IR systems from external corpora as references. In addition, by\nincorporating external knowledge, retrieval-augmented LLMs can answer in-domain\nquestions that cannot be answered by solely relying on the world knowledge\nstored in parameters. To support research in this area and facilitate the\ndevelopment of retrieval-augmented LLM systems, we develop RETA-LLM, a\n{RET}reival-{A}ugmented LLM toolkit. In RETA-LLM, we create a complete pipeline\nto help researchers and users build their customized in-domain LLM-based\nsystems. Compared with previous retrieval-augmented LLM systems, RETA-LLM\nprovides more plug-and-play modules to support better interaction between IR\nsystems and LLMs, including {request rewriting, document retrieval, passage\nextraction, answer generation, and fact checking} modules. Our toolkit is\npublicly available at https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.",
        "translated": "尽管大型语言模型(LLM)已经在许多领域展示了非凡的能力，但是它们仍然有产生幻觉和对用户请求产生虚构响应的倾向。这个问题可以通过使用信息检索(IR)系统(也称为检索增强 LLM)来增强 LLM 来缓解。应用这种策略，LLM 可以根据 IR 系统从外部语料库中检索到的相关内容作为参考，根据用户的输入生成更多的事实性文本。此外，通过合并外部知识，检索增强 LLM 可以回答领域内的问题，而这些问题不能仅仅依赖于存储在参数中的世界知识来回答。为了支持这一领域的研究和促进检索增强 LLM 系统的发展，我们开发了 RETA-LLM，一个{ RET } reval-{ A }增强 LLM 工具包。在 RETA-LLM 中，我们创建了一个完整的管道来帮助研究人员和用户构建他们定制的基于领域 LLM 的系统。与以前的检索增强 LLM 系统相比，RETA-LLM 提供了更多的即插即用模块，以支持 IR 系统和 LLM 之间更好的交互，包括{请求重写、文献检索、段落提取、答案生成和事实检查}模块。我们的工具包可以在 https://github.com/ruc-gsai/yulan-ir/tree/main/reta-llm 上公开获得。"
    },
    {
        "title": "Controllable Multi-Objective Re-ranking with Policy Hypernetworks",
        "url": "http://arxiv.org/abs/2306.05118v1",
        "pub_date": "2023-06-08",
        "summary": "Multi-stage ranking pipelines have become widely used strategies in modern\nrecommender systems, where the final stage aims to return a ranked list of\nitems that balances a number of requirements such as user preference,\ndiversity, novelty etc. Linear scalarization is arguably the most widely used\ntechnique to merge multiple requirements into one optimization objective, by\nsumming up the requirements with certain preference weights. Existing\nfinal-stage ranking methods often adopt a static model where the preference\nweights are determined during offline training and kept unchanged during online\nserving. Whenever a modification of the preference weights is needed, the model\nhas to be re-trained, which is time and resources inefficient. Meanwhile, the\nmost appropriate weights may vary greatly for different groups of targeting\nusers or at different time periods (e.g., during holiday promotions). In this\npaper, we propose a framework called controllable multi-objective re-ranking\n(CMR) which incorporates a hypernetwork to generate parameters for a re-ranking\nmodel according to different preference weights. In this way, CMR is enabled to\nadapt the preference weights according to the environment changes in an online\nmanner, without retraining the models. Moreover, we classify practical\nbusiness-oriented tasks into four main categories and seamlessly incorporate\nthem in a new proposed re-ranking model based on an Actor-Evaluator framework,\nwhich serves as a reliable real-world testbed for CMR. Offline experiments\nbased on the dataset collected from Taobao App showed that CMR improved several\npopular re-ranking models by using them as underlying models. Online A/B tests\nalso demonstrated the effectiveness and trustworthiness of CMR.",
        "translated": "多阶段排名管道已经成为现代推荐系统中广泛使用的策略，最后阶段的目标是返回一个项目的排名列表，以平衡一些需求，如用户偏好，多样性，新颖性等。线性标量可以说是最广泛使用的技术合并多个需求到一个优化目标，通过总结需求与一定的偏好权重。现有的最后阶段排序方法通常采用静态模型，在离线训练期间确定偏好权重，在线服务期间保持不变。当需要修改偏好权重时，模型必须重新训练，这是时间和资源效率低下的。与此同时，最合适的权重可能会因不同的目标用户群体或在不同的时间段(例如，在假日促销期间)而有很大差异。本文提出了一种可控的多目标重排序(CMR)框架，该框架结合了一个超网络，根据不同的偏好权重为重排序模型生成参数。通过这种方式，CMR 能够根据环境变化在线调整偏好权重，而不需要重新训练模型。此外，我们将面向业务的实际任务分为四个主要类别，并将它们无缝地纳入一个新提出的重新排序模型，该模型基于一个演员-评估者框架，作为一个可靠的现实世界的 CMR 测试平台。基于从淘宝应用收集的数据集的离线实验表明，CMR 通过使用它们作为基础模型改进了几个流行的重新排名模型。在线 A/B 测试也证明了 CMR 的有效性和可信性。"
    },
    {
        "title": "Attention Weighted Mixture of Experts with Contrastive Learning for\n  Personalized Ranking in E-commerce",
        "url": "http://arxiv.org/abs/2306.05011v1",
        "pub_date": "2023-06-08",
        "summary": "Ranking model plays an essential role in e-commerce search and\nrecommendation. An effective ranking model should give a personalized ranking\nlist for each user according to the user preference. Existing algorithms\nusually extract a user representation vector from the user behavior sequence,\nthen feed the vector into a feed-forward network (FFN) together with other\nfeatures for feature interactions, and finally produce a personalized ranking\nscore. Despite tremendous progress in the past, there is still room for\nimprovement. Firstly, the personalized patterns of feature interactions for\ndifferent users are not explicitly modeled. Secondly, most of existing\nalgorithms have poor personalized ranking results for long-tail users with few\nhistorical behaviors due to the data sparsity. To overcome the two challenges,\nwe propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive\nlearning for personalized ranking. Firstly, AW-MoE leverages the MoE framework\nto capture personalized feature interactions for different users. To model the\nuser preference, the user behavior sequence is simultaneously fed into expert\nnetworks and the gate network. Within the gate network, one gate unit and one\nactivation unit are designed to adaptively learn the fine-grained activation\nvector for experts using an attention mechanism. Secondly, a random masking\nstrategy is applied to the user behavior sequence to simulate long-tail users,\nand an auxiliary contrastive loss is imposed to the output of the gate network\nto improve the model generalization for these users. This is validated by a\nhigher performance gain on the long-tail user test set. Experiment results on a\nJD real production dataset and a public dataset demonstrate the effectiveness\nof AW-MoE, which significantly outperforms state-of-art methods. Notably,\nAW-MoE has been successfully deployed in the JD e-commerce search engine, ...",
        "translated": "排名模型在电子商务搜索和推荐中起着至关重要的作用。一个有效的排名模型应该根据用户的偏好为每个用户提供一个个性化的排名列表。现有的算法通常从用户行为序列中提取用户表示向量，然后将该向量与其他特征一起反馈到前馈网络(FFN)中进行特征交互，最终产生个性化的排序得分。尽管过去取得了巨大的进步，但仍有改进的空间。首先，不同用户特征交互的个性化模式没有明确建模。其次，由于数据稀疏，现有算法对于长尾用户的个性化排序效果较差，历史行为较少。为了克服这两个挑战，我们提出了基于对比学习的专家注意加权混合排序方法(AW-MoE)。首先，AW-MoE 利用 MoE 框架为不同的用户捕获个性化的特征交互。为了建立用户偏好模型，将用户行为序列同时输入到专家网络和门网络中。在门网络中，设计了一个门单元和一个激活单元，利用注意机制为专家自适应地学习细粒度激活向量。其次，对用户行为序列采用随机掩蔽策略来模拟长尾用户，并对门网络的输出增加辅助对比度损失，以提高对长尾用户的模型泛化能力。这通过在长尾用户测试集上获得更高的性能增益来验证。在 JD 实际生产数据集和公开数据集上的实验结果证明了 AW-MoE 方法的有效性，其性能明显优于最先进的方法。值得注意的是，AW-MoE 已经成功地部署在 JD 电子商务搜索引擎，..。"
    },
    {
        "title": "Unified Embedding Based Personalized Retrieval in Etsy Search",
        "url": "http://arxiv.org/abs/2306.04833v1",
        "pub_date": "2023-06-07",
        "summary": "Embedding-based neural retrieval is a prevalent approach to address the\nsemantic gap problem which often arises in product search on tail queries. In\ncontrast, popular queries typically lack context and have a broad intent where\nadditional context from users historical interaction can be helpful. In this\npaper, we share our novel approach to address both: the semantic gap problem\nfollowed by an end to end trained model for personalized semantic retrieval. We\npropose learning a unified embedding model incorporating graph, transformer and\nterm-based embeddings end to end and share our design choices for optimal\ntradeoff between performance and efficiency. We share our learnings in feature\nengineering, hard negative sampling strategy, and application of transformer\nmodel, including a novel pre-training strategy and other tricks for improving\nsearch relevance and deploying such a model at industry scale. Our personalized\nretrieval model significantly improves the overall search experience, as\nmeasured by a 5.58% increase in search purchase rate and a 2.63% increase in\nsite-wide conversion rate, aggregated across multiple A/B tests - on live\ntraffic.",
        "translated": "基于嵌入式的神经检索是解决尾部查询产品搜索中经常出现的语义缺口问题的一种常用方法。相比之下，流行的查询通常缺乏上下文，并且具有广泛的意图，其中来自用户历史交互的额外上下文可能有所帮助。在本文中，我们分享了我们的新方法来解决这两个问题: 语义差距问题，然后是个性化语义检索的端到端训练模型。我们提出了一种结合图形、变换器和基于术语的嵌入端到端学习的统一嵌入模型，并共享我们的设计选择，以实现性能和效率之间的最优平衡。我们分享了我们在特征工程、硬负采样策略和变压器模型应用方面的经验，包括一种新的预训练策略和其他提高搜索相关性和在行业规模部署此类模型的技巧。我们的个性化检索模型显著改善了整体搜索体验，通过对实时流量进行多个 A/B 测试，搜索购买率增加了5.58% ，网站转换率增加了2.63% 。"
    },
    {
        "title": "MIMIC-IT: Multi-Modal In-Context Instruction Tuning",
        "url": "http://arxiv.org/abs/2306.05425v1",
        "pub_date": "2023-06-08",
        "summary": "High-quality instructions and responses are essential for the zero-shot\nperformance of large language models on interactive natural language tasks. For\ninteractive vision-language tasks involving intricate visual scenes, a large\nquantity of diverse and creative instruction-response pairs should be\nimperative to tune vision-language models (VLMs). Nevertheless, the current\navailability of vision-language instruction-response pairs in terms of\nquantity, diversity, and creativity remains limited, posing challenges to the\ngeneralization of interactive VLMs. Here we present MultI-Modal In-Context\nInstruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal\ninstruction-response pairs, with 2.2 million unique instructions derived from\nimages and videos. Each pair is accompanied by multi-modal in-context\ninformation, forming conversational contexts aimed at empowering VLMs in\nperception, reasoning, and planning. The instruction-response collection\nprocess, dubbed as Syphus, is scaled using an automatic annotation pipeline\nthat combines human expertise with GPT's capabilities. Using the MIMIC-IT\ndataset, we train a large VLM named Otter. Based on extensive evaluations\nconducted on vision-language benchmarks, it has been observed that Otter\ndemonstrates remarkable proficiency in multi-modal perception, reasoning, and\nin-context learning. Human evaluation reveals it effectively aligns with the\nuser's intentions. We release the MIMIC-IT dataset, instruction-response\ncollection pipeline, benchmarks, and the Otter model.",
        "translated": "高质量的指令和响应对于大型语言模型在交互式自然语言任务中的零点性能至关重要。对于涉及复杂视觉场景的交互式视觉语言任务，必须调优视觉语言模型(VLM)。然而，目前视觉-语言教学-反应对在数量、多样性和创造性方面的可用性仍然有限，对交互式 VLM 的普及提出了挑战。在这里，我们介绍了多模态上下文指令调优(MIMIC-IT) ，一个包含280万个多模态指令-响应对的数据集，其中有220万个来自图像和视频的独特指令。每一对都伴随着多模态的语境信息，形成旨在赋予 VLM 感知、推理和计划能力的会话语境。这个被称为 Syphus 的指令-响应收集过程使用一个自动注释管道进行扩展，该管道将人类的专业知识与 GPT 的功能结合在一起。使用 MIMIC-IT 数据集，我们训练了一个名为 Otter 的大型 VLM。基于对视觉语言基准的广泛评估，我们发现 Otter 在多模态知觉、推理和语境学习方面表现出显著的能力。人工评估显示它有效地与用户的意图保持一致。我们发布 MIMIC-IT 数据集、指令-响应收集管道、基准测试和 Otter 模型。"
    },
    {
        "title": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to\n  Pre-trained Language Models Memories",
        "url": "http://arxiv.org/abs/2306.05406v1",
        "pub_date": "2023-06-08",
        "summary": "Pre-trained language models (PLMs) demonstrate excellent abilities to\nunderstand texts in the generic domain while struggling in a specific domain.\nAlthough continued pre-training on a large domain-specific corpus is effective,\nit is costly to tune all the parameters on the domain. In this paper, we\ninvestigate whether we can adapt PLMs both effectively and efficiently by only\ntuning a few parameters. Specifically, we decouple the feed-forward networks\n(FFNs) of the Transformer architecture into two parts: the original pre-trained\nFFNs to maintain the old-domain knowledge and our novel domain-specific\nadapters to inject domain-specific knowledge in parallel. Then we adopt a\nmixture-of-adapters gate to fuse the knowledge from different domain adapters\ndynamically. Our proposed Mixture-of-Domain-Adapters (MixDA) employs a\ntwo-stage adapter-tuning strategy that leverages both unlabeled data and\nlabeled data to help the domain adaptation: i) domain-specific adapter on\nunlabeled data; followed by ii) the task-specific adapter on labeled data.\nMixDA can be seamlessly plugged into the pretraining-finetuning paradigm and\nour experiments demonstrate that MixDA achieves superior performance on\nin-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and\nknowledge-intensive tasks (KILT). Further analyses demonstrate the reliability,\nscalability, and efficiency of our method. The code is available at\nhttps://github.com/Amano-Aki/Mixture-of-Domain-Adapters.",
        "translated": "预训练语言模型(PLM)展示了在通用领域理解文本而在特定领域挣扎的卓越能力。尽管在特定于领域的大型语料库上进行持续的预训练是有效的，但是调优领域上的所有参数的成本是很高的。在本文中，我们研究是否可以适应 PLM 的有效性和有效性，只需调整几个参数。具体来说，我们将变压器结构的前馈网络(FFN)解耦为两部分: 原始的预先训练的 FFN 来维护旧的领域知识，以及我们新颖的领域特定适配器来并行注入领域特定的知识。然后采用混合适配器门来动态融合来自不同领域适配器的知识。我们提出的混合域适配器(MixDA)采用两阶段适配器调优策略，利用未标记数据和标记数据来帮助域适配: i)未标记数据上的域特定适配器; 随后 ii)标记数据上的任务特定适配器。MixDA 可以无缝地插入预训练-微调范式，我们的实验表明，MixDA 在域内任务(GLUE) ，域外任务(ChemProt，RCT，IMDB，Amazon)和知识密集型任务(KILT)上取得了优越的性能。进一步的分析证明了该方法的可靠性、可扩展性和有效性。密码可在 https://github.com/amano-aki/mixture-of-domain-adapters 查阅。"
    },
    {
        "title": "Modular Visual Question Answering via Code Generation",
        "url": "http://arxiv.org/abs/2306.05392v1",
        "pub_date": "2023-06-08",
        "summary": "We present a framework that formulates visual question answering as modular\ncode generation. In contrast to prior work on modular approaches to VQA, our\napproach requires no additional training and relies on pre-trained language\nmodels (LMs), visual models pre-trained on image-caption pairs, and fifty VQA\nexamples used for in-context learning. The generated Python programs invoke and\ncompose the outputs of the visual models using arithmetic and conditional\nlogic. Our approach improves accuracy on the COVR dataset by at least 3% and on\nthe GQA dataset by roughly 2% compared to the few-shot baseline that does not\nemploy code generation.",
        "translated": "我们提出了一个框架，制定可视化问题回答作为模块化代码生成。与之前关于 VQA 模块化方法的工作相比，我们的方法不需要额外的培训，并且依赖于预先训练的语言模型(LM) ，在图像-标题对上预先训练的可视化模型以及用于上下文学习的50个 VQA 示例。生成的 Python 程序使用算术和条件逻辑调用和组合可视化模型的输出。我们的方法在 COVR 数据集上提高了至少3% 的准确性，在 GQA 数据集上提高了大约2% 的准确性，相比之下，不使用代码生成的少镜头基线。"
    },
    {
        "title": "Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across\n  Age",
        "url": "http://arxiv.org/abs/2306.05387v1",
        "pub_date": "2023-06-08",
        "summary": "Emerging psychopathology studies are showing that patterns of changes in\nemotional state -- emotion dynamics -- are associated with overall well-being\nand mental health. More recently, there has been some work in tracking emotion\ndynamics through one's utterances, allowing for data to be collected on a\nlarger scale across time and people. However, several questions about how\nemotion dynamics change with age, especially in children, and when determined\nthrough children's writing, remain unanswered. In this work, we use both a\nlexicon and a machine learning based approach to quantify characteristics of\nemotion dynamics determined from poems written by children of various ages. We\nshow that both approaches point to similar trends: consistent increasing\nintensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and\ndominance) with age and a consistent decreasing valence with age. We also find\nincreasing emotional variability, rise rates (i.e., emotional reactivity), and\nrecovery rates (i.e., emotional regulation) with age. These results act as a\nuseful baselines for further research in how patterns of emotions expressed by\nchildren change with age, and their association with mental health.",
        "translated": "新兴的精神病理学研究表明，情绪状态的变化模式——情绪动力学——与整体幸福感和心理健康有关。最近，已经有一些工作通过一个人的话语跟踪情绪动态，允许跨越时间和人的更大规模的数据收集。然而，一些关于情绪动态如何随着年龄变化的问题，特别是在儿童中，以及当通过儿童的写作决定时，仍然没有答案。本研究采用词汇学习和机器学习相结合的方法，对不同年龄段儿童诗歌的情绪动力学特征进行量化研究。我们发现，这两种方法都指向相似的趋势: 随着年龄的增长，某些情绪(例如，愤怒、恐惧、喜悦、悲伤、觉醒和支配)的强度持续增加，而随着年龄的增长，情绪的效价持续下降。我们还发现，随着年龄的增长，情绪波动性、情绪反应性和恢复率都在增加。这些结果为进一步研究儿童表达的情绪模式如何随年龄变化及其与心理健康的关系提供了有用的基线。"
    },
    {
        "title": "The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher\n  Responses in Educational Dialogues",
        "url": "http://arxiv.org/abs/2306.05360v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents the ADAIO team's system entry in the Building Educational\nApplications (BEA) 2023 Shared Task on Generating AI Teacher Responses in\nEducational Dialogues. The task aims to assess the performance of\nstate-of-the-art generative models as AI teachers in producing suitable\nresponses within a student-teacher dialogue. Our system comprises evaluating\nvarious baseline models using OpenAI GPT-3 and designing diverse prompts to\nprompt the OpenAI models for teacher response generation. After the challenge,\nour system achieved second place by employing a few-shot prompt-based approach\nwith the OpenAI text-davinci-003 model. The results highlight the few-shot\nlearning capabilities of large-language models, particularly OpenAI's GPT-3, in\nthe role of AI teachers.",
        "translated": "本文介绍了 ADAIO 团队的系统条目在建筑教育应用(BEA)2023共同任务生成人工智能教师在教育对话中的反应。这项任务旨在评估最先进的生成模式作为人工智能教师在学生-教师对话中产生适当反应的表现。我们的系统包括使用 OpenAI GPT-3评估各种基线模型，并设计不同的提示以提示 OpenAI 模型用于教师反应生成。经过挑战，我们的系统取得了第二名，采用了几个镜头的提示为基础的方法与 OpenAI 文本达芬奇003模型。研究结果强调了大型语言模型(尤其是 OpenAI 的 GPT-3)在人工智能教师角色中的少量学习能力。"
    },
    {
        "title": "Advancing Italian Biomedical Information Extraction with Large Language\n  Models: Methodological Insights and Multicenter Practical Application",
        "url": "http://arxiv.org/abs/2306.05323v1",
        "pub_date": "2023-06-08",
        "summary": "The introduction of computerized medical records in hospitals has reduced\nburdensome operations like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting them from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation, using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Large Language Model for this task. Moreover, we conducted several\nexperiments with three external independent datasets to implement an effective\nmulticenter model, with overall F1-score 84.77%, Precision 83.16%, Recall\n86.44%. The lessons learned are: (i) the crucial role of a consistent\nannotation process and (ii) a fine-tuning strategy that combines classical\nmethods with a \"few-shot\" approach. This allowed us to establish methodological\nguidelines that pave the way for future implementations in this field and allow\nItalian hospitals to tap into important research opportunities.",
        "translated": "医院采用计算机化病历减少了手工书写和信息提取等繁重的操作。然而，包含在医疗记录中的数据仍然没有得到充分利用，主要是因为从非结构化的文本医疗记录中提取数据需要时间和精力。信息抽取是自然语言处理的一个子领域，通过使用自动文本挖掘管道，可以帮助临床医生克服这一限制。在这项工作中，我们创建了第一个意大利神经精神病命名实体识别数据集，PsyNIT，并使用它来开发这项任务的大型语言模型。此外，我们利用三个独立的外部数据集进行了多个实验，实现了一个有效的多中心模型，F1总分为84.77% ，精度为83.16% ，召回率为86.44% 。从中学到的经验教训是: (i)一致的注释过程的关键作用; (ii)将经典方法与“少量拍摄”方法相结合的微调策略。这使我们能够制定方法指南，为今后在这一领域的实施铺平道路，并使意大利医院能够利用重要的研究机会。"
    },
    {
        "title": "KIT's Multilingual Speech Translation System for IWSLT 2023",
        "url": "http://arxiv.org/abs/2306.05320v1",
        "pub_date": "2023-06-08",
        "summary": "Many existing speech translation benchmarks focus on native-English speech in\nhigh-quality recording conditions, which often do not match the conditions in\nreal-life use-cases. In this paper, we describe our speech translation system\nfor the multilingual track of IWSLT 2023, which focuses on the translation of\nscientific conference talks. The test condition features accented input speech\nand terminology-dense contents. The tasks requires translation into 10\nlanguages of varying amounts of resources. In absence of training data from the\ntarget domain, we use a retrieval-based approach (kNN-MT) for effective\nadaptation (+0.8 BLEU for speech translation). We also use adapters to easily\nintegrate incremental training data from data augmentation, and show that it\nmatches the performance of re-training. We observe that cascaded systems are\nmore easily adaptable towards specific target domains, due to their separate\nmodules. Our cascaded speech system substantially outperforms its end-to-end\ncounterpart on scientific talk translation, although their performance remains\nsimilar on TED talks.",
        "translated": "许多现有的语音翻译基准主要集中在高质量录音条件下的英语母语语音上，而这些语音翻译基准往往与现实生活中的语音翻译条件不匹配。本文介绍了我们为 IWSLT 2023多语种赛道开发的演讲翻译系统，该系统主要用于科学会议演讲的翻译。测试条件的特点是重音输入语音和术语密集的内容。这些任务需要翻译成10种不同数量资源的语言。在没有来自目标域的训练数据的情况下，我们使用基于检索的方法(kNN-MT)进行有效的自适应(语音翻译 + 0.8 BLEU)。我们还使用适配器方便地集成了来自数据增强的增量训练数据，并表明它与再训练的性能相匹配。我们观察到级联系统由于其独立的模块，更容易适应特定的目标域。我们的级联语音系统在科学演讲翻译方面大大优于其端到端的对应系统，尽管它们在 TED 演讲中的表现仍然相似。"
    },
    {
        "title": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
        "url": "http://arxiv.org/abs/2306.05317v1",
        "pub_date": "2023-06-08",
        "summary": "In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.",
        "translated": "在本文中，我们考虑的挑战，总结病人的医疗进展记录在有限的数据设置。对于2023年 BioNLP 研讨会上的问题列表摘要(共享任务1A) ，我们证明临床 T5对765个医疗诊所笔记进行微调优于其他提取，抽象和零拍基线，产生合理的医疗笔记摘要基线系统。此外，我们还介绍了分层总结模型集成(HESM) ，其由不同的微调临床 T5模型的令牌级集成组成，然后是最小贝叶斯风险(MBR)解码。我们的 HESM 方法导致了相当大的总结性能提升，并且当在坚持的挑战数据上进行评估时，ROUGE-L 达到了32.77，这是共享任务排行榜上表现最好的系统。"
    },
    {
        "title": "Are fairness metric scores enough to assess discrimination biases in\n  machine learning?",
        "url": "http://arxiv.org/abs/2306.05307v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents novel experiments shedding light on the shortcomings of\ncurrent metrics for assessing biases of gender discrimination made by machine\nlearning algorithms on textual data. We focus on the Bios dataset, and our\nlearning task is to predict the occupation of individuals, based on their\nbiography. Such prediction tasks are common in commercial Natural Language\nProcessing (NLP) applications such as automatic job recommendations. We address\nan important limitation of theoretical discussions dealing with group-wise\nfairness metrics: they focus on large datasets, although the norm in many\nindustrial NLP applications is to use small to reasonably large linguistic\ndatasets for which the main practical constraint is to get a good prediction\naccuracy. We then question how reliable are different popular measures of bias\nwhen the size of the training set is simply sufficient to learn reasonably\naccurate predictions. Our experiments sample the Bios dataset and learn more\nthan 200 models on different sample sizes. This allows us to statistically\nstudy our results and to confirm that common gender bias indices provide\ndiverging and sometimes unreliable results when applied to relatively small\ntraining and test samples. This highlights the crucial importance of variance\ncalculations for providing sound results in this field.",
        "translated": "本文介绍了一些新颖的实验，揭示了目前机器学习算法对文本数据进行性别歧视偏差评估的指标存在的缺陷。我们的重点是生物数据集，我们的学习任务是预测个人的职业，根据他们的传记。这种预测任务在商业自然语言处理(NLP)应用程序(如自动工作推荐)中很常见。我们解决了关于群体公平性度量的理论讨论的一个重要局限性: 它们集中在大数据集上，尽管在许多工业 NLP 应用中的规范是使用小到合理的大语言数据集，其主要的实际限制是获得良好的预测精度。然后我们质疑当训练集的大小仅仅足以学习合理准确的预测时，不同的流行的偏倚测量方法的可靠性。我们的实验样本的 Bios 数据集和学习超过200个不同样本大小的模型。这使我们能够统计研究我们的结果，并确认共同的性别偏见指数提供不同的，有时不可靠的结果时，适用于相对较小的训练和测试样本。这突出了方差计算对于在这一领域提供可靠结果的至关重要性。"
    },
    {
        "title": "ToolAlpaca: Generalized Tool Learning for Language Models with 3000\n  Simulated Cases",
        "url": "http://arxiv.org/abs/2306.05301v1",
        "pub_date": "2023-06-08",
        "summary": "Enabling large language models to effectively utilize real-world tools is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have primarily relied on either extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nhave utilized supervised learning to train limited types of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without specific tool-specific training.\nTo address this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a tool-use corpus and learn generalized\ntool-use abilities on compact language models with minimal human intervention.\nSpecifically, ToolAlpaca first collects a comprehensive dataset by building a\nmulti-agent simulation environment, which contains 3938 tool-use instances from\nmore than 400 real-world tool APIs spanning 50 distinct categories.\nSubsequently, the constructed corpus is employed to fine-tune compact language\nmodels, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B,\nrespectively. Finally, we evaluate the ability of these models to utilize\npreviously unseen tools without specific training. Experimental results\ndemonstrate that ToolAlpaca achieves effective generalized tool-use\ncapabilities comparable to those of extremely large language models like\nGPT-3.5. This validation supports the notion that learning generalized tool-use\nabilities is feasible for compact language models.",
        "translated": "使大型语言模型能够有效地利用现实世界中的工具对于实现内嵌智能是至关重要的。现有的工具学习方法主要依赖于极其庞大的语言模型，如 GPT-4，以零打击的方式获得广义的工具使用能力，或者利用监督式学习在紧凑模型上训练有限类型的工具。然而，小型语言模型是否能够在没有特定工具训练的情况下实现工具使用能力的普遍化仍然是个未知数。为了解决这个问题，本文介绍了 ToolAlpaca，这是一个新的框架，它可以自动生成一个工具使用语料库，并在最少人工干预的情况下学习紧凑语言模型上的广义工具使用能力。具体来说，ToolAlpaca 首先通过构建一个多代理仿真环境来收集一个全面的数据集，该环境包含来自400多个实际工具 API 的3938个工具使用实例，这些 API 跨越50个不同的类别。然后，利用构建的语料库对紧凑语言模型进行微调，得到两个模型，分别为 ToolAlpaca-7B 和 ToolAlpaca-13B。最后，我们评估这些模型在没有特定训练的情况下利用以前看不见的工具的能力。实验结果表明，ToolAlpaca 实现了有效的广义工具使用能力，可以与 GPT-3.5这样的超大型语言模型相媲美。这种验证支持这样一种观点，即学习广义的工具使用能力对于紧凑的语言模型是可行的。"
    },
    {
        "title": "How Can Recommender Systems Benefit from Large Language Models: A Survey",
        "url": "http://arxiv.org/abs/2306.05817v1",
        "pub_date": "2023-06-09",
        "summary": "Recommender systems (RS) play important roles to match users' information\nneeds for Internet applications. In natural language processing (NLP) domains,\nlarge language model (LLM) has shown astonishing emergent abilities (e.g.,\ninstruction following, reasoning), thus giving rise to the promising research\ndirection of adapting LLM to RS for performance enhancements and user\nexperience improvements. In this paper, we conduct a comprehensive survey on\nthis research direction from an application-oriented view. We first summarize\nexisting research works from two orthogonal perspectives: where and how to\nadapt LLM to RS. For the \"WHERE\" question, we discuss the roles that LLM could\nplay in different stages of the recommendation pipeline, i.e., feature\nengineering, feature encoder, scoring/ranking function, and pipeline\ncontroller. For the \"HOW\" question, we investigate the training and inference\nstrategies, resulting in two fine-grained taxonomy criteria, i.e., whether to\ntune LLMs or not, and whether to involve conventional recommendation model\n(CRM) for inference. Detailed analysis and general development trajectories are\nprovided for both questions, respectively. Then, we highlight key challenges in\nadapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and\nethics. Finally, we summarize the survey and discuss the future prospects. We\nalso actively maintain a GitHub repository for papers and other related\nresources in this rising direction:\n$\\href{https://github.com/CHIANGEL/Awesome-LLM-for-RecSys}{[GitHub\\;Link]}$.",
        "translated": "推荐系统(RS)在满足互联网应用的用户信息需求方面发挥着重要作用。在自然语言处理(NLP)领域，大语言模型(LLM)表现出惊人的涌现能力(如指令跟随、推理) ，从而引发了将 LLM 应用于 RS 以提高性能和改善用户体验的研究方向。本文从应用导向的角度对这一研究方向进行了全面综述。本文首先从两个正交的角度对现有的研究工作进行了总结: 在何处以及如何使 LLM 适应 RS。对于“ WHERE”问题，我们讨论 LLM 在推荐流水线的不同阶段可以扮演的角色，即特征工程、特征编码器、评分/排名函数和流水线控制器。对于“如何”问题，我们研究了训练和推理策略，产生了两个细粒度的分类标准，即是否调优 LLM，以及是否涉及传统的推荐模型(CRM)进行推理。对这两个问题分别提供了详细的分析和一般的开发轨迹。然后，从效率、有效性和道德三个方面，重点阐述了长期管理适应 RS 所面临的主要挑战。最后，对调查结果进行了总结，并对未来进行了展望。我们还积极地维护一个 gitHub 存储库，用于存放论文和其他相关资源，这是一个不断发展的方向: $href { https://GitHub.com/chiangel/awesome-llm-for-recsys }{[ gitHub; Link ]}} $。"
    },
    {
        "title": "Interactive Explanation with Varying Level of Details in an Explainable\n  Scientific Literature Recommender System",
        "url": "http://arxiv.org/abs/2306.05809v1",
        "pub_date": "2023-06-09",
        "summary": "Explainable recommender systems (RS) have traditionally followed a\none-size-fits-all approach, delivering the same explanation level of detail to\neach user, without considering their individual needs and goals. Further,\nexplanations in RS have so far been presented mostly in a static and\nnon-interactive manner. To fill these research gaps, we aim in this paper to\nadopt a user-centered, interactive explanation model that provides explanations\nwith different levels of detail and empowers users to interact with, control,\nand personalize the explanations based on their needs and preferences. We\nfollowed a user-centered approach to design interactive explanations with three\nlevels of detail (basic, intermediate, and advanced) and implemented them in\nthe transparent Recommendation and Interest Modeling Application (RIMA). We\nconducted a qualitative user study (N=14) to investigate the impact of\nproviding interactive explanations with varying level of details on the users'\nperception of the explainable RS. Our study showed qualitative evidence that\nfostering interaction and giving users control in deciding which explanation\nthey would like to see can meet the demands of users with different needs,\npreferences, and goals, and consequently can have positive effects on different\ncrucial aspects in explainable recommendation, including transparency, trust,\nsatisfaction, and user experience.",
        "translated": "可解释的推荐系统(RS)传统上遵循一种一刀切的方法，向每个用户提供相同的详细解释水平，而不考虑他们的个人需求和目标。此外，到目前为止，RS 中的解释大多是以静态和非交互的方式提出的。为了填补这些研究空白，本文的目标是采用一种以用户为中心的交互式解释模型，该模型提供不同层次的详细解释，并使用户能够根据自己的需求和偏好进行交互、控制和个性化解释。我们遵循以用户为中心的方法来设计具有三个细节层次(基础、中级和高级)的交互式解释，并在透明的推荐和兴趣建模应用程序(RIMA)中实现它们。我们进行了一项定性的用户研究(N = 14) ，以调查不同程度的细节提供交互式解释对用户感知可解释 RS 的影响。我们的研究显示，定性的证据表明，培养互动和让用户控制决定他们想要看到的解释可以满足不同需求，偏好和目标的用户的需求，因此可以对解释性推荐的不同关键方面产生积极的影响，包括透明度，信任，满意度和用户体验。"
    },
    {
        "title": "RankFormer: Listwise Learning-to-Rank Using Listwide Labels",
        "url": "http://arxiv.org/abs/2306.05808v1",
        "pub_date": "2023-06-09",
        "summary": "Web applications where users are presented with a limited selection of items\nhave long employed ranking models to put the most relevant results first. Any\nfeedback received from users is typically assumed to reflect a relative\njudgement on the utility of items, e.g. a user clicking on an item only implies\nit is better than items not clicked in the same ranked list. Hence, the\nobjectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.\n  Yet, by only viewing feedback as relative, we neglect the user's absolute\nfeedback on the list's overall quality, e.g. when no items in the selection are\nclicked. We thus reconsider the standard LTR paradigm and argue the benefits of\nlearning from this listwide signal. To this end, we propose the RankFormer as\nan architecture that, with a Transformer at its core, can jointly optimize a\nnovel listwide assessment objective and a traditional listwise LTR objective.\n  We simulate implicit feedback on public datasets and observe that the\nRankFormer succeeds in benefitting from listwide signals. Additionally, we\nconduct experiments in e-commerce on Amazon Search data and find the RankFormer\nto be superior to all baselines offline. An online experiment shows that\nknowledge distillation can be used to find immediate practical use for the\nRankFormer.",
        "translated": "在 Web 应用程序中，用户只能看到有限的条目，这种情况长期以来一直采用排名模型，将最相关的结果放在第一位。从用户收到的任何反馈通常被认为反映了对项目效用的相对判断，例如，用户点击一个项目只意味着它比没有在同一排名列表中点击的项目要好。因此，学习排名(Learning-to-Rank，LTR)中优化的目标往往是成对的或列表的。然而，由于只把反馈看作是相对的，我们忽略了用户对列表整体质量的绝对反馈，例如，当选择中没有项被点击的时候。因此，我们重新考虑标准的 LTR 范式，并讨论从这个列表范围的信号中学习的好处。为此，我们提出 RankForm 作为一种体系结构，其核心是一个 Transformer，可以联合优化一个新的列表范围评估目标和一个传统的列表式 LTR 目标。我们模拟公共数据集上的隐式反馈，并观察到 RankForm 成功地从列表宽信号中受益。此外，我们在亚马逊搜索数据上进行电子商务实验，发现排名前优于所有离线基线。一个在线实验表明，知识提取可以用来找到直接的实际应用的秩次前。"
    },
    {
        "title": "Customizing General-Purpose Foundation Models for Medical Report\n  Generation",
        "url": "http://arxiv.org/abs/2306.05642v1",
        "pub_date": "2023-06-09",
        "summary": "Medical caption prediction which can be regarded as a task of medical report\ngeneration (MRG), requires the automatic generation of coherent and accurate\ncaptions for the given medical images. However, the scarcity of labelled\nmedical image-report pairs presents great challenges in the development of deep\nand large-scale neural networks capable of harnessing the potential artificial\ngeneral intelligence power like large language models (LLMs). In this work, we\npropose customizing off-the-shelf general-purpose large-scale pre-trained\nmodels, i.e., foundation models (FMs), in computer vision and natural language\nprocessing with a specific focus on medical report generation. Specifically,\nfollowing BLIP-2, a state-of-the-art vision-language pre-training approach, we\nintroduce our encoder-decoder-based MRG model. This model utilizes a\nlightweight query Transformer to connect two FMs: the giant vision Transformer\nEVA-ViT-g and a bilingual LLM trained to align with human intentions (referred\nto as ChatGLM-6B). Furthermore, we conduct ablative experiments on the\ntrainable components of the model to identify the crucial factors for effective\ntransfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn\nmedical image representations, followed by parameter-efficient training of\nChatGLM-6B to capture the writing styles of medical reports, is essential for\nachieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and\nthe 2nd, respectively, out of 13 participating teams, based on the BERTScore\nand ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction\nTask competition.",
        "translated": "医学字幕预测是医学报告生成的一项重要任务，它要求为给定的医学图像自动生成连贯、准确的医学字幕。然而，标记的医学图像-报告对的稀缺性给深度和大规模神经网络的发展提出了巨大的挑战，这些神经网络能够利用潜在的人工通用智能能力，如大语言模型(LLM)。在这项工作中，我们建议定制现成的通用大规模预训练模型，即基础模型(FM) ，在计算机视觉和自然语言处理，特别是医疗报告生成的重点。具体来说，在 BLIP-2(一种最先进的视觉语言预训练方法)之后，我们介绍了基于编码器-解码器的 MRG 模型。该模型使用一个轻量级查询 Transformer 连接两个 FM: 巨大的愿景跑车 EVA-ViT-g 和一个双语 LLM，后者经过训练以符合人类意图(称为 ChatGLM-6B)。此外，我们还对模型的可训练部分进行了烧蚀实验，以确定有效迁移学习的关键因素。我们的研究结果表明，将 EVA-ViT-g 解冻以学习医学图像表示，然后对 ChatGLM-6B 进行参数有效的训练以捕获医学报告的写作风格，对于实现最佳结果至关重要。根据 BERTScore 和 ROUGE-1指标，在 ImageCLEFMedical Caption 2023字幕预测任务竞赛中，我们的最佳尝试(PCLmed Team)分别在13个参赛团队中获得第4名和第2名。"
    },
    {
        "title": "Bayesian Knowledge-driven Critiquing with Indirect Evidence",
        "url": "http://arxiv.org/abs/2306.05636v1",
        "pub_date": "2023-06-09",
        "summary": "Conversational recommender systems (CRS) enhance the expressivity and\npersonalization of recommendations through multiple turns of user-system\ninteraction. Critiquing is a well-known paradigm for CRS that allows users to\niteratively refine recommendations by providing feedback about attributes of\nrecommended items. While existing critiquing methodologies utilize direct\nattributes of items to address user requests such as 'I prefer Western movies',\nthe opportunity of incorporating richer contextual and side information about\nitems stored in Knowledge Graphs (KG) into the critiquing paradigm has been\noverlooked. Employing this substantial knowledge together with a\nwell-established reasoning methodology paves the way for critique-based\nrecommenders to allow for complex knowledge-based feedback (e.g., 'I like\nmovies featuring war side effects on veterans') which may arise in natural\nuser-system conversations. In this work, we aim to increase the flexibility of\ncritique-based recommendation by integrating KGs and propose a novel Bayesian\ninference framework that enables reasoning with relational knowledge-based\nfeedback. We study and formulate the framework considering a Gaussian\nlikelihood and evaluate it on two well-known recommendation datasets with KGs.\nOur evaluations demonstrate the effectiveness of our framework in leveraging\nindirect KG-based feedback (i.e., preferred relational properties of items\nrather than preferred items themselves), often improving personalized\nrecommendations over a one-shot recommender by more than 15%. This work enables\na new paradigm for using rich knowledge content and reasoning over indirect\nevidence as a mechanism for critiquing interactions with CRS.",
        "translated": "会话推荐系统(CRS)通过多轮用户系统交互增强推荐的表达能力和个性化。批评是 CRS 的一个众所周知的范例，它允许用户通过提供关于推荐项目属性的反馈来迭代地完善推荐。虽然现有的批评方法利用项目的直接属性来满足用户的要求，例如“我更喜欢西部电影”，但是将知识图表(KG)中存储的项目的更丰富的上下文和侧面信息纳入批评范式的机会被忽视了。使用这些实质性的知识和一个完善的推理方法为基于评论的推荐者铺平了道路，以允许复杂的基于知识的反馈(例如，“我喜欢有退伍军人战争副作用的电影”) ，这可能出现在自然的用户系统对话中。在这项工作中，我们的目标是通过整合幼稚园来增加基于批判的推荐的灵活性，并提出一个新的贝叶斯推断框架，使推理与关系知识为基础的反馈。我们研究并制定了考虑高斯似然的框架，并在两个著名的 KG 推荐数据集上进行了评估。我们的评估表明，我们的框架在利用间接的基于 KG 的反馈(即，项目的首选关系属性，而不是首选项本身)方面的有效性，通常比一次性推荐提高个性化推荐超过15% 。这项工作为使用丰富的知识内容和推理间接证据作为一种机制批判与 CRS 的相互作用提供了一个新的范例。"
    },
    {
        "title": "Leveraging Large Language Models for Scalable Vector Graphics-Driven\n  Image Understanding",
        "url": "http://arxiv.org/abs/2306.06094v1",
        "pub_date": "2023-06-09",
        "summary": "Recently, large language models (LLMs) have made significant advancements in\nnatural language understanding and generation. However, their potential in\ncomputer vision remains largely unexplored. In this paper, we introduce a new,\nexploratory approach that enables LLMs to process images using the Scalable\nVector Graphics (SVG) format. By leveraging the XML-based textual descriptions\nof SVG representations instead of raster images, we aim to bridge the gap\nbetween the visual and textual modalities, allowing LLMs to directly understand\nand manipulate images without the need for parameterized visual components. Our\nmethod facilitates simple image classification, generation, and in-context\nlearning using only LLM capabilities. We demonstrate the promise of our\napproach across discriminative and generative tasks, highlighting its (i)\nrobustness against distribution shift, (ii) substantial improvements achieved\nby tapping into the in-context learning abilities of LLMs, and (iii) image\nunderstanding and generation capabilities with human guidance. Our code, data,\nand models can be found here https://github.com/mu-cai/svg-llm.",
        "translated": "近年来，大型语言模型(LLM)在自然语言理解和生成方面取得了显著的进展。然而，它们在计算机视觉方面的潜力在很大程度上仍未得到开发。在这篇文章中，我们介绍了一种新的探索性的方法，使 LLM 能够使用可缩放向量图形(SVG)格式来处理图像。通过利用基于 XML 的 SVG 表示的文本描述而不是栅格图像，我们的目标是弥合视觉和文本模式之间的差距，允许 LLM 直接理解和操作图像，而不需要参数化的视觉组件。我们的方法有助于简单的图像分类，生成，并在上下文学习使用 LLM 的能力。我们展示了我们在歧视性和生成性任务中的方法的前景，强调了其(i)对分布转移的稳健性，(ii)通过利用 LLM 的上下文学习能力实现的实质性改进，以及(iii)图像理解和生成能力与人类指导。我们的代码、数据和模型可以在这里找到 https://github.com/mu-cai/svg-llm。"
    },
    {
        "title": "Developing Speech Processing Pipelines for Police Accountability",
        "url": "http://arxiv.org/abs/2306.06086v1",
        "pub_date": "2023-06-09",
        "summary": "Police body-worn cameras have the potential to improve accountability and\ntransparency in policing. Yet in practice, they result in millions of hours of\nfootage that is never reviewed. We investigate the potential of large\npre-trained speech models for facilitating reviews, focusing on ASR and officer\nspeech detection in footage from traffic stops. Our proposed pipeline includes\ntraining data alignment and filtering, fine-tuning with resource constraints,\nand combining officer speech detection with ASR for a fully automated approach.\nWe find that (1) fine-tuning strongly improves ASR performance on officer\nspeech (WER=12-13%), (2) ASR on officer speech is much more accurate than on\ncommunity member speech (WER=43.55-49.07%), (3) domain-specific tasks like\nofficer speech detection and diarization remain challenging. Our work offers\npractical applications for reviewing body camera footage and general guidance\nfor adapting pre-trained speech models to noisy multi-speaker domains.",
        "translated": "警察身上佩戴的摄像头有可能改善警务工作的问责制和透明度。然而在实践中，他们导致数百万小时的镜头，从来没有审查。我们调查的潜力，大型预先训练的语音模型，以促进审查，侧重于 ASR 和官员的语音检测镜头从交通停止。我们提出的流水线包括训练数据对齐和过滤，与资源约束的微调，并结合官员语音检测和 ASR 为一个完全自动化的方法。我们发现: (1)微调有力地提高了官员语音的 ASR 性能(WER = 12-13%) ，(2)官员语音的 ASR 比社区成员语音的 ASR 更准确(WER = 43.55-49.07%) ，(3)官员语音检测和数字化等领域特定任务仍然具有挑战性。我们的工作提供了实际应用，审查身体摄像机镜头和一般指导适应预先训练的语音模型噪声多扬声器领域。"
    },
    {
        "title": "Trapping LLM Hallucinations Using Tagged Context Prompts",
        "url": "http://arxiv.org/abs/2306.06085v1",
        "pub_date": "2023-06-09",
        "summary": "Recent advances in large language models (LLMs), such as ChatGPT, have led to\nhighly sophisticated conversation agents. However, these models suffer from\n\"hallucinations,\" where the model generates false or fabricated information.\nAddressing this challenge is crucial, particularly with AI-driven platforms\nbeing adopted across various sectors. In this paper, we propose a novel method\nto recognize and flag instances when LLMs perform outside their domain\nknowledge, and ensuring users receive accurate information.\n  We find that the use of context combined with embedded tags can successfully\ncombat hallucinations within generative language models. To do this, we\nbaseline hallucination frequency in no-context prompt-response pairs using\ngenerated URLs as easily-tested indicators of fabricated data. We observed a\nsignificant reduction in overall hallucination when context was supplied along\nwith question prompts for tested generative engines. Lastly, we evaluated how\nplacing tags within contexts impacted model responses and were able to\neliminate hallucinations in responses with 98.88% effectiveness.",
        "translated": "大型语言模型(LLM)的最新进展，如 ChatGPT，已经导致了高度复杂的会话代理。然而，这些模型遭受“幻觉”，即模型产生虚假或捏造的信息。应对这一挑战至关重要，特别是在各个部门都在采用人工智能驱动的平台的情况下。在本文中，我们提出了一种新的方法来识别和标记实例时，LLM 执行领域外的知识，并确保用户接收准确的信息。我们发现使用上下文结合嵌入式标签可以成功地战胜生成语言模型中的幻觉。为此，我们使用生成的 URL 作为编造数据的容易测试的指标，对无上下文提示-响应对中的幻觉频率进行基线测试。我们观察到整体幻觉的显着减少时，上下文提供的问题提示测试生成引擎。最后，我们评估了在上下文中放置标签是如何影响模型反应的，并且能够以98.88% 的有效率消除反应中的幻觉。"
    },
    {
        "title": "Mind2Web: Towards a Generalist Agent for the Web",
        "url": "http://arxiv.org/abs/2306.06070v1",
        "pub_date": "2023-06-09",
        "summary": "We introduce Mind2Web, the first dataset for developing and evaluating\ngeneralist agents for the web that can follow language instructions to complete\ncomplex tasks on any website. Existing datasets for web agents either use\nsimulated websites or only cover a limited set of websites and tasks, thus not\nsuitable for generalist web agents. With over 2,000 open-ended tasks collected\nfrom 137 websites spanning 31 domains and crowdsourced action sequences for the\ntasks, Mind2Web provides three necessary ingredients for building generalist\nweb agents: 1) diverse domains, websites, and tasks, 2) use of real-world\nwebsites instead of simulated and simplified ones, and 3) a broad spectrum of\nuser interaction patterns. Based on Mind2Web, we conduct an initial exploration\nof using large language models (LLMs) for building generalist web agents. While\nthe raw HTML of real-world websites are often too large to be fed to LLMs, we\nshow that first filtering it with a small LM significantly improves the\neffectiveness and efficiency of LLMs. Our solution demonstrates a decent level\nof performance, even on websites or entire domains the model has never seen\nbefore, but there is still a substantial room to improve towards truly\ngeneralizable agents. We open-source our dataset, model implementation, and\ntrained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further\nresearch on building a generalist agent for the web.",
        "translated": "我们介绍 Mind2Web，第一个用于开发和评估通用网络代理的数据集，这些代理可以按照语言指令在任何网站上完成复杂的任务。现有的 Web 代理数据集要么使用模拟网站，要么只覆盖有限的一组网站和任务，因此不适合于通用 Web 代理。Mind2Web 从31个领域的137个网站中收集了超过2000个开放式任务，并为这些任务提供了众包的动作序列。 Mind2Web 为构建通用网络代理提供了三个必要的组成部分: 1)不同的领域、网站和任务; 2)使用真实世界的网站而不是模拟和简化的网站; 3)广泛的用户交互模式。基于 Mind2Web，我们对使用大型语言模型(LLM)构建通用 Web 代理进行了初步探索。虽然现实世界中网站的原始 HTML 通常太大而无法提供给 LLM，但我们表明，首先使用小型 LM 对其进行过滤可以显著提高 LLM 的有效性和效率。我们的解决方案展示了一个不错的性能水平，甚至在模型从未见过的网站或整个域上，但是仍然有很大的空间来改进真正可推广的代理。我们开源我们的数据集，模型实现，和训练有素的模型( https://osu-nlp-group.github.io/mind2web ) ，以促进进一步的研究建立一个通用的代理网站。"
    },
    {
        "title": "Assisting Language Learners: Automated Trans-Lingual Definition\n  Generation via Contrastive Prompt Learning",
        "url": "http://arxiv.org/abs/2306.06058v1",
        "pub_date": "2023-06-09",
        "summary": "The standard definition generation task requires to automatically produce\nmono-lingual definitions (e.g., English definitions for English words), but\nignores that the generated definitions may also consist of unfamiliar words for\nlanguage learners. In this work, we propose a novel task of Trans-Lingual\nDefinition Generation (TLDG), which aims to generate definitions in another\nlanguage, i.e., the native speaker's language. Initially, we explore the\nunsupervised manner of this task and build up a simple implementation of\nfine-tuning the multi-lingual machine translation model. Then, we develop two\nnovel methods, Prompt Combination and Contrastive Prompt Learning, for further\nenhancing the quality of the generation. Our methods are evaluated against the\nbaseline Pipeline method in both rich- and low-resource settings, and we\nempirically establish its superiority in generating higher-quality\ntrans-lingual definitions.",
        "translated": "标准的定义生成任务要求自动生成单语言定义(例如，英语单词的英语定义) ，但是忽略了生成的定义也可能包含语言学习者不熟悉的单词。在这项工作中，我们提出了一个新颖的任务跨语言定义生成(TLDG) ，其目的是生成另一种语言的定义，即母语说话人的语言。最初，我们探讨了这项任务的无监督方式，并建立了一个简单的实现，微调多语种机器翻译模型。然后，为了进一步提高生成的质量，我们开发了两种新的方法，即即时组合和对比即时学习。在资源丰富和资源少的情况下，我们对比基线流水线方法对我们的方法进行了评估，并且我们经验性地建立了它在产生更高质量的跨语言定义方面的优势。"
    },
    {
        "title": "FinGPT: Open-Source Financial Large Language Models",
        "url": "http://arxiv.org/abs/2306.06031v1",
        "pub_date": "2023-06-09",
        "summary": "Large language models (LLMs) have shown the potential of revolutionizing\nnatural language processing tasks in diverse domains, sparking great interest\nin finance. Accessing high-quality financial data is the first challenge for\nfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken\nadvantage of their unique data accumulation, such privileged access calls for\nan open-source alternative to democratize Internet-scale financial data.\n  In this paper, we present an open-source large language model, FinGPT, for\nthe finance sector. Unlike proprietary models, FinGPT takes a data-centric\napproach, providing researchers and practitioners with accessible and\ntransparent resources to develop their FinLLMs. We highlight the importance of\nan automatic data curation pipeline and the lightweight low-rank adaptation\ntechnique in building FinGPT. Furthermore, we showcase several potential\napplications as stepping stones for users, such as robo-advising, algorithmic\ntrading, and low-code development. Through collaborative efforts within the\nopen-source AI4Finance community, FinGPT aims to stimulate innovation,\ndemocratize FinLLMs, and unlock new opportunities in open finance. Two\nassociated code repos are \\url{https://github.com/AI4Finance-Foundation/FinGPT}\nand \\url{https://github.com/AI4Finance-Foundation/FinNLP}",
        "translated": "大型语言模型(LLM)显示了在不同领域革新自然语言处理任务的潜力，引起了人们对金融的极大兴趣。访问高质量的金融数据是金融 LLM (FinLLM)面临的第一个挑战。虽然像 BloombergGPT 这样的专有模型已经利用了它们独特的数据积累，但是这种特权访问需要一种开放源码的替代方案来使互联网规模的金融数据民主化。在本文中，我们为金融部门提出了一个开源的大型语言模型 FinGPT。与专有模型不同，FinGPT 采用以数据为中心的方法，为研究人员和从业人员提供可访问和透明的资源，以开发他们的 FinLLM。我们强调了自动数据管道和轻量级低级自适应技术在构建 FinGPT 中的重要性。此外，我们展示了几个潜在的应用程序作为用户的垫脚石，如机器人建议，算法交易和低代码开发。通过开源 AI4Finance 社区内部的协作努力，FinGPT 旨在激励创新，使 FinLLM 民主化，并在开放金融领域释放新的机遇。两个相关的代码回购是 url { https://github.com/ai4finance-foundation/fingpt }和 url { https://github.com/ai4finance-foundation/finnlp }"
    },
    {
        "title": "HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence\n  for Digital Medicine",
        "url": "http://arxiv.org/abs/2306.06029v1",
        "pub_date": "2023-06-09",
        "summary": "Providing high quality explanations for AI predictions based on machine\nlearning is a challenging and complex task. To work well it requires, among\nother factors: selecting a proper level of generality/specificity of the\nexplanation; considering assumptions about the familiarity of the explanation\nbeneficiary with the AI task under consideration; referring to specific\nelements that have contributed to the decision; making use of additional\nknowledge (e.g. expert evidence) which might not be part of the prediction\nprocess; and providing evidence supporting negative hypothesis. Finally, the\nsystem needs to formulate the explanation in a clearly interpretable, and\npossibly convincing, way. Given these considerations, ANTIDOTE fosters an\nintegrated vision of explainable AI, where low-level characteristics of the\ndeep learning process are combined with higher level schemes proper of the\nhuman argumentation capacity. ANTIDOTE will exploit cross-disciplinary\ncompetences in deep learning and argumentation to support a broader and\ninnovative view of explainable AI, where the need for high-quality explanations\nfor clinical cases deliberation is critical. As a first result of the project,\nwe publish the Antidote CasiMedicos dataset to facilitate research on\nexplainable AI in general, and argumentation in the medical domain in\nparticular.",
        "translated": "为基于机器学习的人工智能预测提供高质量的解释是一项具有挑战性和复杂性的任务。要做好这项工作，除了其他因素之外，还需要: 选择适当水平的解释的一般性/特异性; 考虑关于解释受益人对正在考虑的 AI 任务的熟悉程度的假设; 参考对决策有贡献的特定元素; 利用额外的知识(例如专家证据) ，这可能不是预测过程的一部分; 以及提供支持负面假设的证据。最后，系统需要以一种清晰可解释的、可能令人信服的方式来阐述解释。考虑到这些因素，ANTIDOTE 培养了一种可解释人工智能的综合视野，其中深度学习过程的低水平特征与适合人类论证能力的高水平方案相结合。ANTIDOTE 将利用深度学习和论证方面的跨学科能力，以支持对可解释 AI 的更广泛和创新的观点，其中对临床病例审议的高质量解释的需求是至关重要的。作为这个项目的第一个成果，我们发布了解毒剂 CasiMedicos 数据集，以促进对可解释人工智能的研究，特别是在医学领域的论证。"
    },
    {
        "title": "Automated Labeling of German Chest X-Ray Radiology Reports using Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.05997v1",
        "pub_date": "2023-06-09",
        "summary": "Radiologists are in short supply globally, and deep learning models offer a\npromising solution to address this shortage as part of clinical\ndecision-support systems. However, training such models often requires\nexpensive and time-consuming manual labeling of large datasets. Automatic label\nextraction from radiology reports can reduce the time required to obtain\nlabeled datasets, but this task is challenging due to semantically similar\nwords and missing annotated data. In this work, we explore the potential of\nweak supervision of a deep learning-based label prediction model, using a\nrule-based labeler. We propose a deep learning-based CheXpert label prediction\nmodel, pre-trained on reports labeled by a rule-based German CheXpert model and\nfine-tuned on a small dataset of manually labeled reports. Our results\ndemonstrate the effectiveness of our approach, which significantly outperformed\nthe rule-based model on all three tasks. Our findings highlight the benefits of\nemploying deep learning-based models even in scenarios with sparse data and the\nuse of the rule-based labeler as a tool for weak supervision.",
        "translated": "放射科医生在全球范围内供不应求，而深度学习模式作为临床决策支持系统的一部分，为解决这一短缺提供了一个有希望的解决方案。然而，训练这样的模型通常需要昂贵和耗时的大型数据集的手动标记。从放射学报告中自动提取标签可以减少获得标签数据集所需的时间，但是由于语义相似的单词和缺少注释数据，这项任务是具有挑战性的。在这项工作中，我们探讨了弱监督的潜力，一个基于深度学习的标签预测模型，使用基于规则的标签。我们提出了一个基于深度学习的 CheXpert 标签预测模型，该模型预先对基于规则的德国 CheXpert 模型标记的报告进行训练，并对手动标记的小数据集进行微调。我们的研究结果证明了我们的方法的有效性，它在所有三个任务上都明显优于基于规则的模型。我们的研究结果强调了使用基于深度学习的模型的好处，即使是在数据稀少的情况下，以及使用基于规则的标签器作为薄弱监督的工具。"
    },
    {
        "title": "Language Models Can Learn Exceptions to Syntactic Rules",
        "url": "http://arxiv.org/abs/2306.05969v1",
        "pub_date": "2023-06-09",
        "summary": "Artificial neural networks can generalize productively to novel contexts. Can\nthey also learn exceptions to those productive rules? We explore this question\nusing the case of restrictions on English passivization (e.g., the fact that\n\"The vacation lasted five days\" is grammatical, but \"*Five days was lasted by\nthe vacation\" is not). We collect human acceptability judgments for passive\nsentences with a range of verbs, and show that the probability distribution\ndefined by GPT-2, a language model, matches the human judgments with high\ncorrelation. We also show that the relative acceptability of a verb in the\nactive vs. passive voice is positively correlated with the relative frequency\nof its occurrence in those voices. These results provide preliminary support\nfor the entrenchment hypothesis, according to which learners track and uses the\ndistributional properties of their input to learn negative exceptions to rules.\nAt the same time, this hypothesis fails to explain the magnitude of\nunpassivizability demonstrated by certain individual verbs, suggesting that\nother cues to exceptionality are available in the linguistic input.",
        "translated": "人工神经网络可以有效地推广到新的上下文。他们是否也能学到这些生产规则的例外情况？我们使用限制英语被动语态的例子来探讨这个问题(例如，“假期持续了五天”是合法的，但“ * 五天被假期持续了”不是)。我们收集了一系列动词被动句的人类可接受性判断，结果表明，语言模型 gPT-2所定义的概率分布与人类的判断具有高度相关性。我们还发现动词在主动语态和被动语态中的相对可接受性与动词在主动语态和被动语态中出现的相对频率呈正相关。这些结果为固守假设提供了初步的支持，根据这一假设，学习者跟踪并利用其输入的分布特性来学习规则的负异常。同时，这一假设也未能解释某些个别动词所表现出的非被动性程度，这表明在语言输入中还存在其他的例外线索。"
    },
    {
        "title": "An Efficient Speech Separation Network Based on Recurrent Fusion Dilated\n  Convolution and Channel Attention",
        "url": "http://arxiv.org/abs/2306.05887v1",
        "pub_date": "2023-06-09",
        "summary": "We present an efficient speech separation neural network, ARFDCN, which\ncombines dilated convolutions, multi-scale fusion (MSF), and channel attention\nto overcome the limited receptive field of convolution-based networks and the\nhigh computational cost of transformer-based networks. The suggested network\narchitecture is encoder-decoder based. By using dilated convolutions with\ngradually increasing dilation value to learn local and global features and\nfusing them at adjacent stages, the model can learn rich feature content.\nMeanwhile, by adding channel attention modules to the network, the model can\nextract channel weights, learn more important features, and thus improve its\nexpressive power and robustness. Experimental results indicate that the model\nachieves a decent balance between performance and computational efficiency,\nmaking it a promising alternative to current mainstream models for practical\napplications.",
        "translated": "我们提出了一个有效的语音分离神经网络，ARFDCN，它结合了扩张卷积，多尺度融合(MSF)和信道注意力，以克服有限的接收领域的卷积为基础的网络和高计算成本的变压器为基础的网络。所建议的网络结构是基于编码器-解码器的。通过使用渐增扩张值的扩张卷积来学习局部和全局特征，并在相邻阶段进行融合，该模型可以学习到丰富的特征内容。同时，通过在网络中增加信道注意模块，该模型可以提取信道权重，学习更多的重要特征，从而提高其表达能力和鲁棒性。实验结果表明，该模型在性能和计算效率之间取得了较好的平衡，是目前主流模型在实际应用中的一种有前途的替代方案。"
    },
    {
        "title": "Weakly-Supervised Scientific Document Classification via\n  Retrieval-Augmented Multi-Stage Training",
        "url": "http://arxiv.org/abs/2306.07193v1",
        "pub_date": "2023-06-12",
        "summary": "Scientific document classification is a critical task for a wide range of\napplications, but the cost of obtaining massive amounts of human-labeled data\ncan be prohibitive. To address this challenge, we propose a weakly-supervised\napproach for scientific document classification using label names only. In\nscientific domains, label names often include domain-specific concepts that may\nnot appear in the document corpus, making it difficult to match labels and\ndocuments precisely. To tackle this issue, we propose WANDER, which leverages\ndense retrieval to perform matching in the embedding space to capture the\nsemantics of label names. We further design the label name expansion module to\nenrich the label name representations. Lastly, a self-training step is used to\nrefine the predictions. The experiments on three datasets show that WANDER\noutperforms the best baseline by 11.9% on average. Our code will be published\nat https://github.com/ritaranx/wander.",
        "translated": "科学文档分类对于广泛的应用来说是一个关键的任务，但是获取大量的人类标记数据的成本可能是高昂的。为了应对这一挑战，我们提出了一种弱监督的方法，用于只使用标签名称的科学文档分类。在科学领域，标签名称往往包括特定领域的概念，这些概念可能不会出现在文档语料库中，因此难以精确匹配标签和文档。为了解决这个问题，我们提出了 WANDER，它利用密集检索在嵌入空间中执行匹配来捕获标签名的语义。进一步设计了标签名扩展模块，丰富了标签名表示。最后，使用一个自我训练步骤来完善预测。在三个数据集上的实验结果表明，WANDER 平均比最佳基准线高出11.9% 。我们的代码会在 https://github.com/ritaranx/wander 公布。"
    },
    {
        "title": "Fair Learning to Rank with Distribution-free Risk Control",
        "url": "http://arxiv.org/abs/2306.07188v1",
        "pub_date": "2023-06-12",
        "summary": "Learning to Rank (LTR) methods are vital in online economies, affecting users\nand item providers. Fairness in LTR models is crucial to allocate exposure\nproportionally to item relevance. The deterministic ranking model can lead to\nunfair exposure distribution when items with the same relevance receive\nslightly different scores. Stochastic LTR models, incorporating the\nPlackett-Luce (PL) model, address fairness issues but have limitations in\ncomputational cost and performance guarantees. To overcome these limitations,\nwe propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC\nleverages a pretrained scoring function to create a stochastic LTR model,\neliminating the need for expensive training. Furthermore, FairLTR-RC provides\nfinite-sample guarantees on a user-specified utility using distribution-free\nrisk control framework. By additionally incorporating the Thresholded PL (TPL)\nmodel, we are able to achieve an effective trade-off between utility and\nfairness. Experimental results on several benchmark datasets demonstrate that\nFairLTR-RC significantly improves fairness in widely-used deterministic LTR\nmodels while guaranteeing a specified level of utility.",
        "translated": "学习排名(LTR)方法在网络经济中至关重要，它会影响用户和商品供应商。LTR 模型中的公平性对于按照项目相关性按比例分配暴露是至关重要的。确定性排序模型可能导致不公平的曝光分布，当项目相同的相关性得到略有不同的分数。结合 Plackett-Luce (PL)模型的随机 LTR 模型解决了公平性问题，但在计算成本和性能保证方面存在局限性。为了克服这些局限性，我们提出了一种新的事后模型无关方法 FairLTR-RC。FairLTR-RC 利用一个预先训练的评分函数来创建一个随机 LTR 模型，从而消除了对昂贵培训的需求。此外，FairLTR-RC 使用无分布风险控制框架为用户指定的公用事业提供有限样本保证。另外，通过引入阈限物流(TPL)模型，我们能够在效用和公平之间达到有效的平衡。在几个基准数据集上的实验结果表明，FairLTR-RC 在保证特定效用水平的同时，显著提高了广泛使用的确定性 LTR 模型的公平性。"
    },
    {
        "title": "Video-to-Music Recommendation using Temporal Alignment of Segments",
        "url": "http://arxiv.org/abs/2306.07187v1",
        "pub_date": "2023-06-12",
        "summary": "We study cross-modal recommendation of music tracks to be used as soundtracks\nfor videos. This problem is known as the music supervision task. We build on a\nself-supervised system that learns a content association between music and\nvideo. In addition to the adequacy of content, adequacy of structure is crucial\nin music supervision to obtain relevant recommendations. We propose a novel\napproach to significantly improve the system's performance using\nstructure-aware recommendation. The core idea is to consider not only the full\naudio-video clips, but rather shorter segments for training and inference. We\nfind that using semantic segments and ranking the tracks according to sequence\nalignment costs significantly improves the results. We investigate the impact\nof different ranking metrics and segmentation methods.",
        "translated": "我们研究跨模态的音乐曲目推荐作为视频配乐使用。这个问题被称为音乐监督任务。我们建立了一个自我监督系统，学习音乐和视频之间的内容关联。除了内容的充分性，结构的充分性在音乐监督中也是至关重要的，以获得相关的建议。我们提出了一种新的方法来显著提高系统的性能使用结构感知的推荐。其核心思想是不仅要考虑完整的音视频剪辑，而且要考虑训练和推理的较短片段。我们发现，使用语义片段并根据序列比对成本对音轨进行排序，可以显著提高搜索结果。我们研究了不同排序指标和分割方法的影响。"
    },
    {
        "title": "Adversarial Constrained Bidding via Minimax Regret Optimization with\n  Causality-Aware Reinforcement Learning",
        "url": "http://arxiv.org/abs/2306.07106v1",
        "pub_date": "2023-06-12",
        "summary": "The proliferation of the Internet has led to the emergence of online\nadvertising, driven by the mechanics of online auctions. In these repeated\nauctions, software agents participate on behalf of aggregated advertisers to\noptimize for their long-term utility. To fulfill the diverse demands, bidding\nstrategies are employed to optimize advertising objectives subject to different\nspending constraints. Existing approaches on constrained bidding typically rely\non i.i.d. train and test conditions, which contradicts the adversarial nature\nof online ad markets where different parties possess potentially conflicting\nobjectives. In this regard, we explore the problem of constrained bidding in\nadversarial bidding environments, which assumes no knowledge about the\nadversarial factors. Instead of relying on the i.i.d. assumption, our insight\nis to align the train distribution of environments with the potential test\ndistribution meanwhile minimizing policy regret. Based on this insight, we\npropose a practical Minimax Regret Optimization (MiRO) approach that\ninterleaves between a teacher finding adversarial environments for tutoring and\na learner meta-learning its policy over the given distribution of environments.\nIn addition, we pioneer to incorporate expert demonstrations for learning\nbidding strategies. Through a causality-aware policy design, we improve upon\nMiRO by distilling knowledge from the experts. Extensive experiments on both\nindustrial data and synthetic data show that our method, MiRO with\nCausality-aware reinforcement Learning (MiROCL), outperforms prior methods by\nover 30%.",
        "translated": "互联网的扩散导致了在线广告的出现，这是由在线拍卖的机制所驱动的。在这些重复的拍卖中，软件代理商代表广告主集合参与，以优化他们的长期效用。为了满足不同的需求，投标策略被用来优化受不同支出约束的广告目标。现有的限制性投标方法通常依赖于身份证培训和测试条件，这与在线广告市场的对抗性质相矛盾，因为在线广告市场中，不同的当事人拥有潜在的相互冲突的目标。在这方面，我们探讨了在不考虑竞争因素的情况下，在竞争性投标环境下的约束投标问题。我们的洞察力不是依赖于内部识别假设，而是使环境的列车分布与潜在的测试分布保持一致，同时最大限度地减少政策遗憾。基于这种观点，我们提出了一种实用的极大极小遗憾优化(Miniax Regret Optimation，MiRO)方法，该方法在教师寻找对抗性的辅导环境和学习者元学习策略之间进行交叉。此外，我们率先采用专家演示学习投标策略。通过一个因果关系感知策略设计，我们从专家那里提取知识来改进 MiRO。对工业数据和合成数据的大量实验表明，我们的方法，带有因果感知强化学习(miROCL)的 miRO，比之前的方法性能高出30% 以上。"
    },
    {
        "title": "Imbalanced Multi-label Classification for Business-related Text with\n  Moderately Large Label Spaces",
        "url": "http://arxiv.org/abs/2306.07046v1",
        "pub_date": "2023-06-12",
        "summary": "In this study, we compared the performance of four different methods for\nmulti label text classification using a specific imbalanced business dataset.\nThe four methods we evaluated were fine tuned BERT, Binary Relevance,\nClassifier Chains, and Label Powerset. The results show that fine tuned BERT\noutperforms the other three methods by a significant margin, achieving high\nvalues of accuracy, F1 Score, Precision, and Recall. Binary Relevance also\nperforms well on this dataset, while Classifier Chains and Label Powerset\ndemonstrate relatively poor performance. These findings highlight the\neffectiveness of fine tuned BERT for multi label text classification tasks, and\nsuggest that it may be a useful tool for businesses seeking to analyze complex\nand multifaceted texts.",
        "translated": "在这项研究中，我们比较了四种不同方法的性能，多标签文本分类使用特定的不平衡业务数据集。我们评估的四种方法是微调的 BERT、二进制相关性、分类器链和标签 Powerset。结果表明，精调误码率优于其他三种方法，具有较高的精度、 F1评分、精度和召回率。二进制相关性在这个数据集上也表现良好，而分类器链和标签 Powerset 表现出相对较差的性能。这些发现突出了微调 BERT 在多标签文本分类任务中的有效性，并表明它可能是企业寻求分析复杂和多方面文本的有用工具。"
    },
    {
        "title": "Data-Copilot: Bridging Billions of Data and Humans with Autonomous\n  Workflow",
        "url": "http://arxiv.org/abs/2306.07209v1",
        "pub_date": "2023-06-12",
        "summary": "Various industries such as finance, meteorology, and energy generate vast\namounts of heterogeneous data every day. There is a natural demand for humans\nto manage, process, and display data efficiently. However, it necessitates\nlabor-intensive efforts and a high level of expertise for these data-related\ntasks. Considering that large language models (LLMs) have showcased promising\ncapabilities in semantic understanding and reasoning, we advocate that the\ndeployment of LLMs could autonomously manage and process massive amounts of\ndata while displaying and interacting in a human-friendly manner. Based on this\nbelief, we propose Data-Copilot, an LLM-based system that connects numerous\ndata sources on one end and caters to diverse human demands on the other end.\nActing like an experienced expert, Data-Copilot autonomously transforms raw\ndata into visualization results that best match the user's intent.\nSpecifically, Data-Copilot autonomously designs versatile interfaces (tools)\nfor data management, processing, prediction, and visualization. In real-time\nresponse, it automatically deploys a concise workflow by invoking corresponding\ninterfaces step by step for the user's request. The interface design and\ndeployment processes are fully controlled by Data-Copilot itself, without human\nassistance. Besides, we create a Data-Copilot demo that links abundant data\nfrom different domains (stock, fund, company, economics, and live news) and\naccurately respond to diverse requests, serving as a reliable AI assistant.",
        "translated": "金融、气象和能源等不同行业每天都会产生大量异构数据。对人类来说，有效地管理、处理和显示数据是一种自然的需求。然而，对于这些与数据相关的任务，它需要劳动密集型的努力和高水平的专业知识。考虑到大型语言模型(LLM)在语义理解和推理方面表现出了很有前途的能力，我们主张 LLM 的部署可以自主地管理和处理大量的数据，同时以人性化的方式显示和交互。基于这一信念，我们提出了 Data-Copilot，一个基于 LLM 的系统，一端连接众多数据源，另一端满足不同的人类需求。Data-Copilot 像一位经验丰富的专家一样，自主地将原始数据转换为最符合用户意图的可视化结果。具体来说，Data-Copilot 自主设计用于数据管理、处理、预测和可视化的多功能接口(工具)。在实时响应中，它通过为用户的请求逐步调用相应的接口，自动部署一个简洁的工作流。接口设计和部署过程完全由 Data-Copilot 本身控制，无需人工协助。此外，我们创建了一个 Data-Copilot 演示，链接了来自不同领域(股票、基金、公司、经济和现场新闻)的大量数据，并准确地响应不同的请求，作为一个可靠的人工智能助手。"
    },
    {
        "title": "Valley: Video Assistant with Large Language model Enhanced abilitY",
        "url": "http://arxiv.org/abs/2306.07207v1",
        "pub_date": "2023-06-12",
        "summary": "Recently, several multi-modal models have been developed for joint image and\nlanguage understanding, which have demonstrated impressive chat abilities by\nutilizing advanced large language models (LLMs). The process of developing such\nmodels is straightforward yet effective. It involves pre-training an adaptation\nmodule to align the semantics of the vision encoder and language model,\nfollowed by fine-tuning on the instruction-following data. However, despite the\nsuccess of this pipeline in image and language understanding, its effectiveness\nin joint video and language understanding has not been widely explored. In this\npaper, we aim to develop a novel multi-modal foundation model capable of\nperceiving video, image, and language within a general framework. To achieve\nthis goal, we introduce Valley: Video Assistant with Large Language model\nEnhanced ability. Specifically, our proposed Valley model is designed with a\nsimple projection module that bridges video, image, and language modalities,\nand is further unified with a multi-lingual LLM. We also collect multi-source\nvision-text pairs and adopt a spatio-temporal pooling strategy to obtain a\nunified vision encoding of video and image input for pre-training. Furthermore,\nwe generate multi-task instruction-following video data, including multi-shot\ncaptions, long video descriptions, action recognition, causal relationship\ninference, etc. To obtain the instruction-following data, we design diverse\nrounds of task-oriented conversations between humans and videos, facilitated by\nChatGPT. Qualitative examples demonstrate that our proposed model has the\npotential to function as a highly effective multilingual video assistant that\ncan make complex video understanding scenarios easy. Code, data, and models\nwill be available at https://github.com/RupertLuo/Valley.",
        "translated": "最近，一些多模态模型已经被开发出来用于联合图像和语言理解，它们通过使用先进的大语言模型(LLM)展示了令人印象深刻的聊天能力。开发这种模型的过程是简单而有效的。它包括预先训练一个适应模块，以便对准视觉编码器和语言模型的语义，然后对指令跟踪数据进行微调。然而，尽管这条管道在图像和语言理解方面取得了成功，但它在联合视频和语言理解方面的有效性还没有得到广泛的探索。在本文中，我们的目标是开发一个新的多模态基础模型，能够感知视频，图像和语言在一个通用的框架内。为了实现这一目标，我们引入了谷: 视频助理与大语言模型增强能力。具体来说，我们提出的 Valley 模型设计了一个简单的投影模块，它连接了视频、图像和语言模式，并进一步与多语言 LLM 相结合。采集多源视觉文本对，采用时空合并策略，获得视频和图像输入的统一视觉编码，用于预训练。此外，还生成了多任务指令跟踪视频数据，包括多镜头字幕、长视频描述、动作识别、因果关系推理等。为了获得指令跟踪数据，我们设计了不同轮次的任务导向的人类和视频之间的对话，促进了 ChatGPT。定性的例子表明，我们提出的模型有潜力作为一个高效的多语言视频助理，可以使复杂的视频理解场景容易。代码、数据和模型将在 https://github.com/rupertluo/valley 提供。"
    },
    {
        "title": "RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized\n  Dialogue Response Generation",
        "url": "http://arxiv.org/abs/2306.07206v1",
        "pub_date": "2023-06-12",
        "summary": "Endowing chatbots with a consistent persona is essential to an engaging\nconversation, yet it remains an unresolved challenge. In this work, we propose\na new retrieval-enhanced approach for personalized response generation.\nSpecifically, we design a hierarchical transformer retriever trained on\ndialogue domain data to perform personalized retrieval and a context-aware\nprefix encoder that fuses the retrieved information to the decoder more\neffectively. Extensive experiments on a real-world dataset demonstrate the\neffectiveness of our model at generating more fluent and personalized\nresponses. We quantitatively evaluate our model's performance under a suite of\nhuman and automatic metrics and find it to be superior compared to\nstate-of-the-art baselines on English Reddit conversations.",
        "translated": "赋予聊天机器人一个一致的角色对于一个引人入胜的对话至关重要，然而这仍然是一个未解决的挑战。在这项工作中，我们提出了一个新的检索增强的方法来生成个性化的响应。具体地说，我们设计了一个基于对话域数据训练的分层变压器检索器来执行个性化检索，以及一个上下文感知的前缀编码器来更有效地将检索到的信息融合到解码器中。在真实世界数据集上的大量实验证明了我们的模型在产生更流畅和个性化响应方面的有效性。我们定量评估了我们的模型在一套人工和自动指标下的表现，发现它比英语 Reddit 会话的最先进的基线要好。"
    },
    {
        "title": "LTCR: Long-Text Chinese Rumor Detection Dataset",
        "url": "http://arxiv.org/abs/2306.07201v2",
        "pub_date": "2023-06-12",
        "summary": "False information can spread quickly on social media, negatively influencing\nthe citizens' behaviors and responses to social events. To better detect all of\nthe fake news, especially long texts which are harder to find completely, a\nLong-Text Chinese Rumor detection dataset named LTCR is proposed. The LTCR\ndataset provides a valuable resource for accurately detecting misinformation,\nespecially in the context of complex fake news related to COVID-19. The dataset\nconsists of 1,729 and 500 pieces of real and fake news, respectively. The\naverage lengths of real and fake news are approximately 230 and 152 characters.\nWe also propose \\method, Salience-aware Fake News Detection Model, which\nachieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score\n(90.60%) on the dataset. (https://github.com/Enderfga/DoubleCheck)",
        "translated": "虚假信息可以在社交媒体上迅速传播，对公民的行为和对社会事件的反应产生负面影响。为了更好地检测所有的假新闻，特别是难以完全发现的长文本，提出了一种长文本中文谣言检测数据集 LTCR。LTCR 数据集为准确检测错误信息提供了有价值的资源，特别是在与2019冠状病毒疾病有关的复杂假新闻背景下。这个数据集包括1729条真实新闻和500条假新闻。真实和假新闻的平均长度大约是230和152个字符。本文还提出了基于显著性的假新闻检测模型，该模型对数据集的准确率最高(95.85%) ，对假新闻的召回率最高(90.91%) ，对假新闻的 F 分值最高(90.60%)。( https://github.com/enderfga/doublecheck )"
    },
    {
        "title": "A Survey of Vision-Language Pre-training from the Lens of Multimodal\n  Machine Translation",
        "url": "http://arxiv.org/abs/2306.07198v1",
        "pub_date": "2023-06-12",
        "summary": "Large language models such as BERT and the GPT series started a paradigm\nshift that calls for building general-purpose models via pre-training on large\ndatasets, followed by fine-tuning on task-specific datasets. There is now a\nplethora of large pre-trained models for Natural Language Processing and\nComputer Vision. Recently, we have seen rapid developments in the joint\nVision-Language space as well, where pre-trained models such as CLIP (Radford\net al., 2021) have demonstrated improvements in downstream tasks like image\ncaptioning and visual question answering. However, surprisingly there is\ncomparatively little work on exploring these models for the task of multimodal\nmachine translation, where the goal is to leverage image/video modality in\ntext-to-text translation. To fill this gap, this paper surveys the landscape of\nlanguage-and-vision pre-training from the lens of multimodal machine\ntranslation. We summarize the common architectures, pre-training objectives,\nand datasets from literature and conjecture what further is needed to make\nprogress on multimodal machine translation.",
        "translated": "像 BERT 和 GPT 系列这样的大型语言模型开启了一个范式转变，要求通过对大型数据集进行预训练来构建通用模型，然后对特定任务的数据集进行微调。现在有大量的自然语言处理和计算机视觉的大型预训练模型。最近，我们也看到了联合视觉语言空间的快速发展，其中预先训练的模型如 CLIP (Radford et al。 ，2021)已经在下游任务如图像字幕和视觉问题回答方面表现出改进。然而，令人惊讶的是，在多模态机器翻译的任务中，探索这些模型的工作相对较少，其目标是在文本到文本的翻译中利用图像/视频模态。为了填补这一空白，本文从多模态机器翻译的角度考察了语言和视觉预训的前景。我们总结了通用的体系结构、预训练目标和来自文献的数据集，并推测在多模式机器翻译方面还需要做些什么。"
    },
    {
        "title": "Large language models and (non-)linguistic recursion",
        "url": "http://arxiv.org/abs/2306.07195v1",
        "pub_date": "2023-06-12",
        "summary": "Recursion is one of the hallmarks of human language. While many design\nfeatures of language have been shown to exist in animal communication systems,\nrecursion has not. Previous research shows that GPT-4 is the first large\nlanguage model (LLM) to exhibit metalinguistic abilities (Begu\\v{s},\nD\\k{a}bkowski, and Rhodes 2023). Here, we propose several prompt designs aimed\nat eliciting and analyzing recursive behavior in LLMs, both linguistic and\nnon-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both\nproduce and analyze recursive structures. Thus, we present one of the first\nstudies investigating whether meta-linguistic awareness of recursion -- a\nuniquely human cognitive property -- can emerge in transformers with a high\nnumber of parameters such as GPT-4.",
        "translated": "递归是人类语言的标志之一。虽然语言的许多设计特征已被证明存在于动物交流系统中，但递归却没有。以往的研究表明，GPT-4是第一个表现出元语言能力的大型语言模型(Begu v { s } ，D k { a } bkowski，and Rhodes 2023)。在这里，我们提出了几个快速的设计，旨在引发和分析递归行为的 LLM，无论是语言和非语言。我们演示了当显式提示时，GPT-4既可以产生递归结构，也可以分析递归结构。因此，我们提出的第一个研究之一，调查是否元语言意识的递归-一个独特的人类认知属性-可以出现在变压器与大量的参数，如 GPT-4。"
    },
    {
        "title": "The Effect of Masking Strategies on Knowledge Retention by Language\n  Models",
        "url": "http://arxiv.org/abs/2306.07185v1",
        "pub_date": "2023-06-12",
        "summary": "Language models retain a significant amount of world knowledge from their\npre-training stage. This allows knowledgeable models to be applied to\nknowledge-intensive tasks prevalent in information retrieval, such as ranking\nor question answering. Understanding how and which factual information is\nacquired by our models is necessary to build responsible models. However,\nlimited work has been done to understand the effect of pre-training tasks on\nthe amount of knowledge captured and forgotten by language models during\npre-training. Building a better understanding of knowledge acquisition is the\ngoal of this paper. Therefore, we utilize a selection of pre-training tasks to\ninfuse knowledge into our model. In the following steps, we test the model's\nknowledge retention by measuring its ability to answer factual questions. Our\nexperiments show that masking entities and principled masking of correlated\nspans based on pointwise mutual information lead to more factual knowledge\nbeing retained than masking random tokens. Our findings demonstrate that, like\nthe ability to perform a task, the (factual) knowledge acquired from being\ntrained on that task is forgotten when a model is trained to perform another\ntask (catastrophic forgetting) and how to prevent this phenomenon. To foster\nreproducibility, the code, as well as the data used in this paper, are openly\navailable.",
        "translated": "语言模型从培训前阶段就保留了大量的世界知识。这使得知识型模型能够应用于信息检索中普遍存在的知识密集型任务，例如排名或问答。要建立负责任的模型，就必须了解我们的模型是如何以及获取哪些事实信息的。然而，在理解培训前任务对语言模型在培训前捕获和遗忘的知识量的影响方面所做的工作有限。加深对知识获取的理解是本文的目的。因此，我们利用一个预训练任务的选择，将知识注入到我们的模型中。在接下来的步骤中，我们通过测量模型回答实际问题的能力来测试模型的知识保持能力。我们的实验表明，屏蔽实体和基于点间互信息的相关跨度的原则性屏蔽比屏蔽随机标记能够保留更多的事实知识。我们的研究结果表明，就像执行任务的能力一样，当一个模型被训练去执行另一个任务(灾难性遗忘)时，从该任务中获得的(事实)知识会被遗忘，以及如何防止这种现象的发生。为了提高可重复性，本文中使用的代码和数据都是公开的。"
    },
    {
        "title": "Augmenting Language Models with Long-Term Memory",
        "url": "http://arxiv.org/abs/2306.07174v1",
        "pub_date": "2023-06-12",
        "summary": "Existing large language models (LLMs) can only afford fix-sized inputs due to\nthe input length limit, preventing them from utilizing rich long-context\ninformation from past inputs. To address this, we propose a framework, Language\nModels Augmented with Long-Term Memory (LongMem), which enables LLMs to\nmemorize long history. We design a novel decoupled network architecture with\nthe original backbone LLM frozen as a memory encoder and an adaptive residual\nside-network as a memory retriever and reader. Such a decoupled memory design\ncan easily cache and update long-term past contexts for memory retrieval\nwithout suffering from memory staleness. Enhanced with memory-augmented\nadaptation training, LongMem can thus memorize long past context and use\nlong-term memory for language modeling. The proposed memory retrieval module\ncan handle unlimited-length context in its memory bank to benefit various\ndownstream tasks. Typically, LongMem can enlarge the long-form memory to 65k\ntokens and thus cache many-shot extra demonstration examples as long-form\nmemory for in-context learning. Experiments show that our method outperforms\nstrong long-context models on ChapterBreak, a challenging long-context modeling\nbenchmark, and achieves remarkable improvements on memory-augmented in-context\nlearning over LLMs. The results demonstrate that the proposed method is\neffective in helping language models to memorize and utilize long-form\ncontents. Our code is open-sourced at https://aka.ms/LongMem.",
        "translated": "由于输入长度的限制，现有的大型语言模型(LLM)只能提供固定大小的输入，这使得它们无法利用来自过去输入的丰富的长上下文信息。为了解决这个问题，我们提出了一个框架，即使用长期记忆增强的语言模型(LongMem) ，它使长期记忆能够记忆长期的历史。我们设计了一种新颖的解耦网络结构，其中原骨干 LLM 作为内存编码器，自适应残余网络作为内存检索器和读取器。这种解耦的内存设计可以轻松地缓存和更新长期的过去上下文，用于内存检索，而不会受到内存过时的影响。随着记忆增强适应训练的加强，LongMem 因此可以记住很长的过去的上下文，并使用长期记忆进行语言建模。提出的内存检索模块可以在其内存库中处理无限长的上下文，有利于各种下游任务。通常，LongMem 可以将长形式内存扩大到65k 令牌，从而缓存多镜头的额外示例作为长形式内存，用于上下文学习。实验结果表明，该方法优于一个具有挑战性的长上下文建模基准 ChapterBreak 的强大长上下文模型，并且在 LLM 上实现了对记忆增强的上下文学习的显著改进。结果表明，该方法能有效地帮助语言模型记忆和利用长形式的内容。我们的代码在 https://aka.ms/longmem 是开源的。"
    },
    {
        "title": "Prompt-based Extraction of Social Determinants of Health Using Few-shot\n  Learning",
        "url": "http://arxiv.org/abs/2306.07170v1",
        "pub_date": "2023-06-12",
        "summary": "Social determinants of health (SDOH) documented in the electronic health\nrecord through unstructured text are increasingly being studied to understand\nhow SDOH impacts patient health outcomes. In this work, we utilize the Social\nHistory Annotation Corpus (SHAC), a multi-institutional corpus of de-identified\nsocial history sections annotated for SDOH, including substance use,\nemployment, and living status information. We explore the automatic extraction\nof SDOH information with SHAC in both standoff and inline annotation formats\nusing GPT-4 in a one-shot prompting setting. We compare GPT-4 extraction\nperformance with a high-performing supervised approach and perform thorough\nerror analyses. Our prompt-based GPT-4 method achieved an overall 0.652 F1 on\nthe SHAC test set, similar to the 7th best-performing system among all teams in\nthe n2c2 challenge with SHAC.",
        "translated": "通过非结构化文本记录在电子健康记录中的健康的社会决定因素(SDOH)正在被越来越多地研究，以了解 SDOH 如何影响患者的健康结果。在这项工作中，我们利用社会历史注释语料库(SHAC) ，一个多机构语料库的去识别社会历史部分为 SDOH 注释，包括物质使用，就业和生活状态信息。我们使用 GPT-4在一次性提示设置中探索使用 SHAC 以对峙格式和内联注释格式自动提取 SDOH 信息。我们比较了 GPT-4提取性能和高性能的监督方法，并进行了彻底的误差分析。我们的基于提示的 GPT-4方法在 SHAC 测试集上获得了总体0.652 F1，类似于所有团队在 SHAC 的 n2c2挑战中排名第7的最佳系统。"
    },
    {
        "title": "Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal\n  Rank with Lexicographic Precision",
        "url": "http://arxiv.org/abs/2306.07908v1",
        "pub_date": "2023-06-13",
        "summary": "Across a variety of ranking tasks, researchers use reciprocal rank to measure\nthe effectiveness for users interested in exactly one relevant item. Despite\nits widespread use, evidence suggests that reciprocal rank is brittle when\ndiscriminating between systems. This brittleness, in turn, is compounded in\nmodern evaluation settings where current, high-precision systems may be\ndifficult to distinguish. We address the lack of sensitivity of reciprocal rank\nby introducing and connecting it to the concept of best-case retrieval, an\nevaluation method focusing on assessing the quality of a ranking for the most\nsatisfied possible user across possible recall requirements. This perspective\nallows us to generalize reciprocal rank and define a new preference-based\nevaluation we call lexicographic precision or lexiprecision. By mathematical\nconstruction, we ensure that lexiprecision preserves differences detected by\nreciprocal rank, while empirically improving sensitivity and robustness across\na broad set of retrieval and recommendation tasks.",
        "translated": "在各种排名任务中，研究人员使用互惠排名来衡量对一个相关项目感兴趣的用户的有效性。尽管它被广泛使用，但有证据表明，在区分不同体系时，互惠等级是脆弱的。这种脆性，反过来，在现代评估设置中，当前，高精度的系统可能难以区分复杂。我们通过引入并联系最佳案例检索的概念来解决相互排名缺乏敏感性的问题，最佳案例检索是一种评估方法，侧重于在可能的召回需求中为最满意的可能用户评估排名的质量。这种观点允许我们推广互惠等级，并定义一种新的基于偏好的评价，我们称之为词典精度或词汇精度。通过数学建构，我们确保词汇精确度保留了通过相互排名检测到的差异，同时经验性地提高了广泛的检索和推荐任务集的灵敏度和鲁棒性。"
    },
    {
        "title": "ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support\n  Lateral Reading",
        "url": "http://arxiv.org/abs/2306.07875v1",
        "pub_date": "2023-06-13",
        "summary": "With the rapid growth and spread of online misinformation, people need tools\nto help them evaluate the credibility and accuracy of online information.\nLateral reading, a strategy that involves cross-referencing information with\nmultiple sources, may be an effective approach to achieving this goal. In this\npaper, we present ReadProbe, a tool to support lateral reading, powered by\ngenerative large language models from OpenAI and the Bing search engine. Our\ntool is able to generate useful questions for lateral reading, scour the web\nfor relevant documents, and generate well-attributed answers to help people\nbetter evaluate online information. We made a web-based application to\ndemonstrate how ReadProbe can help reduce the risk of being misled by false\ninformation. The code is available at\nhttps://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won\nthe first prize in a national AI misinformation hackathon.",
        "translated": "随着网络虚假信息的快速增长和传播，人们需要工具来帮助他们评估网络信息的可信度和准确性。横向阅读是一种涉及多源信息交叉引用的策略，可能是实现这一目标的有效途径。在这篇文章中，我们介绍了一个支持横向阅读的工具，由 OpenAI 和 Bing 搜索引擎生成的大型语言模型提供支持。我们的工具能够为横向阅读生成有用的问题，在网上搜索相关文档，并生成归属良好的答案，以帮助人们更好地评估在线信息。我们做了一个网络应用程序来演示如何通过阅读探索来帮助降低被错误信息误导的风险。密码可在 https://github.com/dakezhang1998/readprobe 查阅。我们工具的早期版本赢得了全国人工智能错误信息黑客马拉松一等奖。"
    },
    {
        "title": "KuaiSAR: A Unified Search And Recommendation Dataset",
        "url": "http://arxiv.org/abs/2306.07705v1",
        "pub_date": "2023-06-13",
        "summary": "The confluence of Search and Recommendation services is a vital aspect of\nonline content platforms like Kuaishou and TikTok. The integration of S&amp;R\nmodeling is a highly intuitive approach adopted by industry practitioners.\nHowever, there is a noticeable lack of research conducted in this area within\nthe academia, primarily due to the absence of publicly available datasets.\nConsequently, a substantial gap has emerged between academia and industry\nregarding research endeavors in this field. To bridge this gap, we introduce\nthe first large-scale, real-world dataset KuaiSAR of integrated Search And\nRecommendation behaviors collected from Kuaishou, a leading short-video app in\nChina with over 300 million daily active users. Previous research in this field\nhas predominantly employed publicly available datasets that are semi-synthetic\nand simulated, with artificially fabricated search behaviors. Distinct from\nprevious datasets, KuaiSAR records genuine user behaviors, the occurrence of\neach interaction within either search or recommendation service, and the users'\ntransitions between the two services. This work aids in joint modeling of S&amp;R,\nand the utilization of search data for recommenders (and recommendation data\nfor search engines). Additionally, due to the diverse feedback labels of\nuser-video interactions, KuaiSAR also supports a wide range of other tasks,\nincluding intent recommendation, multi-task learning, and long sequential\nmulti-behavior modeling etc. We believe this dataset will facilitate innovative\nresearch and enrich our understanding of S&amp;R services integration in real-world\napplications.",
        "translated": "搜索和推荐服务的融合是 Kuaishou 和 TikTok 等在线内容平台的一个重要方面。S & R 建模的集成是业界从业人员采用的一种高度直观的方法。然而，学术界在这一领域明显缺乏研究，主要是由于缺乏公开可用的数据集。因此，学术界和工业界在这一领域的研究工作出现了巨大的差距。为了弥补这一差距，我们介绍了第一个大规模的，真实世界的数据集 KuaiSAR 的集成搜索和推荐行为收集自 Kuaishou，一个领先的短视频应用程序在中国有超过3亿日活跃用户。以前在这个领域的研究主要使用公开可用的数据集，这些数据集是半合成的和模拟的，具有人为制造的搜索行为。与以前的数据集不同，KuaiSAR 记录了真实的用户行为、搜索或推荐服务中每个交互的发生情况以及用户在两个服务之间的转换。这项工作有助于 S & R 的联合建模，以及对推荐者的搜索数据(和搜索引擎的推荐数据)的利用。此外，由于用户与视频交互的反馈标签多种多样，KuaiSAR 还支持广泛的其他任务，包括意图推荐、多任务学习和长顺序多行为建模等。我们相信这个数据集将促进创新研究，并丰富我们对现实世界应用中的 S & R 服务集成的理解。"
    },
    {
        "title": "Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square\n  Two-tower model, HNSW, Sign Cauchy Projections",
        "url": "http://arxiv.org/abs/2306.07607v1",
        "pub_date": "2023-06-13",
        "summary": "Sparse data are common. The traditional ``handcrafted'' features are often\nsparse. Embedding vectors from trained models can also be very sparse, for\nexample, embeddings trained via the ``ReLu'' activation function. In this\npaper, we report our exploration of efficient search in sparse data with\ngraph-based ANN algorithms (e.g., HNSW, or SONG which is the GPU version of\nHNSW), which are popular in industrial practice, e.g., search and ads\n(advertising).\n  We experiment with the proprietary ads targeting application, as well as\nbenchmark public datasets. For ads targeting, we train embeddings with the\nstandard ``cosine two-tower'' model and we also develop the ``chi-square\ntwo-tower'' model. Both models produce (highly) sparse embeddings when they are\nintegrated with the ``ReLu'' activation function. In EBR (embedding-based\nretrieval) applications, after we the embeddings are trained, the next crucial\ntask is the approximate near neighbor (ANN) search for serving. While there are\nmany ANN algorithms we can choose from, in this study, we focus on the\ngraph-based ANN algorithm (e.g., HNSW-type).\n  Sparse embeddings should help improve the efficiency of EBR. One benefit is\nthe reduced memory cost for the embeddings. The other obvious benefit is the\nreduced computational time for evaluating similarities, because, for\ngraph-based ANN algorithms such as HNSW, computing similarities is often the\ndominating cost. In addition to the effort on leveraging data sparsity for\nstorage and computation, we also integrate ``sign cauchy random projections''\n(SignCRP) to hash vectors to bits, to further reduce the memory cost and speed\nup the ANN search. In NIPS'13, SignCRP was proposed to hash the chi-square\nsimilarity, which is a well-adopted nonlinear kernel in NLP and computer\nvision. Therefore, the chi-square two-tower model, SignCRP, and HNSW are now\ntightly integrated.",
        "translated": "稀疏的数据很常见。传统的“手工制作”的特点往往是稀少的。从训练过的模型中嵌入向量也可能非常稀疏，例如，通过“ ReLu”激活函数训练的嵌入。在本文中，我们报告了在稀疏数据中使用基于图的神经网络算法(例如，HNSW，或 SONG，这是 HNSW 的 GPU 版本)进行有效搜索的探索，这在工业实践中很流行，例如，搜索和广告(广告)。我们尝试使用针对应用程序的专有广告，以及基准公共数据集。对于广告定位，我们使用标准的“余弦双塔”模型训练嵌入，同时开发了“卡方双塔”模型。这两种模式在与“ ReLu”激活函数集成时都会产生(高度)稀疏的嵌入。在基于嵌入的检索(EBR)应用中，嵌入训练完成后，接下来的关键任务是近似近邻(ANN)搜索服务。虽然有很多神经网络算法可供选择，但本文主要研究基于图的神经网络算法(如 HNSW 型)。稀疏嵌入有助于提高 EBR 的效率。一个好处是减少了嵌入的内存开销。另一个明显的好处是减少了评估相似性的计算时间，因为对于基于图的神经网络算法，如 HNSW，计算相似性往往是主要的代价。除了努力利用数据稀疏性进行存储和计算，我们还集成了“符号柯西随机投影”(SignCRP)来散列向量到位，以进一步降低内存成本和加速人工神经网络搜索。在 NIPS’13中，SignCRP 被提出来对卡方相似度进行散列，这是一种在自然语言处理和计算机视觉中广泛采用的非线性核。因此，卡方双塔模型 SignCRP 和 HNSW 现在紧密结合在一起。"
    },
    {
        "title": "Unified Off-Policy Learning to Rank: a Reinforcement Learning\n  Perspective",
        "url": "http://arxiv.org/abs/2306.07528v1",
        "pub_date": "2023-06-13",
        "summary": "Off-policy Learning to Rank (LTR) aims to optimize a ranker from data\ncollected by a deployed logging policy. However, existing off-policy learning\nto rank methods often make strong assumptions about how users generate the\nclick data, i.e., the click model, and hence need to tailor their methods\nspecifically under different click models. In this paper, we unified the\nranking process under general stochastic click models as a Markov Decision\nProcess (MDP), and the optimal ranking could be learned with offline\nreinforcement learning (RL) directly. Building upon this, we leverage offline\nRL techniques for off-policy LTR and propose the Click Model-Agnostic Unified\nOff-policy Learning to Rank (CUOLR) method, which could be easily applied to a\nwide range of click models. Through a dedicated formulation of the MDP, we show\nthat offline RL algorithms can adapt to various click models without complex\ndebiasing techniques and prior knowledge of the model. Results on various\nlarge-scale datasets demonstrate that CUOLR consistently outperforms the\nstate-of-the-art off-policy learning to rank algorithms while maintaining\nconsistency and robustness under different click models.",
        "translated": "非策略学习排序(Off-policy Learning to Rank，LTR)的目标是从已部署的日志策略收集的数据中优化排序器。然而，现有的对方法进行排序的非策略学习往往对用户如何生成点击数据(即点击模型)做出强有力的假设，因此需要在不同的点击模型下特别调整他们的方法。在本文中，我们将一般随机点击模型下的排名过程统一为一个马可夫决策过程(mDP) ，并且可以直接使用离线强化学习(RL)来学习最佳排名。在此基础上，我们利用离线 RL 技术进行非策略 LTR，并提出 Click 模型-不可知统一非策略学习排名(CUOLR)方法，该方法可以很容易地应用于广泛的点击模型。通过一个专门的公式的 MDP，我们表明离线 RL 算法可以适应各种点击模型没有复杂的消偏技术和先验知识的模型。在各种大规模数据集上的结果表明，在不同点击模型下，CUOLR 在排序算法方面始终优于最先进的非策略学习，同时保持了一致性和鲁棒性。"
    },
    {
        "title": "arXiVeri: Automatic table verification with GPT",
        "url": "http://arxiv.org/abs/2306.07968v1",
        "pub_date": "2023-06-13",
        "summary": "Without accurate transcription of numerical data in scientific documents, a\nscientist cannot draw accurate conclusions. Unfortunately, the process of\ncopying numerical data from one paper to another is prone to human error. In\nthis paper, we propose to meet this challenge through the novel task of\nautomatic table verification (AutoTV), in which the objective is to verify the\naccuracy of numerical data in tables by cross-referencing cited sources. To\nsupport this task, we propose a new benchmark, arXiVeri, which comprises\ntabular data drawn from open-access academic papers on arXiv. We introduce\nmetrics to evaluate the performance of a table verifier in two key areas: (i)\ntable matching, which aims to identify the source table in a cited document\nthat corresponds to a target table, and (ii) cell matching, which aims to\nlocate shared cells between a target and source table and identify their row\nand column indices accurately. By leveraging the flexible capabilities of\nmodern large language models (LLMs), we propose simple baselines for table\nverification. Our findings highlight the complexity of this task, even for\nstate-of-the-art LLMs like OpenAI's GPT-4. The code and benchmark will be made\npublicly available.",
        "translated": "没有科学文献中数字数据的准确记录，科学家就不能得出准确的结论。不幸的是，将数字数据从一张纸复制到另一张纸的过程容易出现人为错误。在本文中，我们提出通过自动表格验证(AutoTV)这一新的任务来迎接这一挑战，其目标是通过交叉引用来源来验证表格中数字数据的准确性。为了支持这个任务，我们提出了一个新的基准，arXiVeri，它包含从 arXiv 上的开放存取学术论文中提取的表格数据。我们引入指标来评估表验证器在两个关键领域的性能: (i)表匹配，其目的是识别与目标表对应的引用文档中的源表; 和(ii)单元格匹配，其目的是在目标和源表之间定位共享单元格，并准确识别其行和列索引。通过利用现代大型语言模型(LLM)的灵活性，我们为表验证提出了简单的基线。我们的发现强调了这项任务的复杂性，即使对于像 OpenAI 的 GPT-4这样的最先进的 LLM 也是如此。代码和基准将公开发布。"
    },
    {
        "title": "MOFI: Learning Image Representations from Noisy Entity Annotated Images",
        "url": "http://arxiv.org/abs/2306.07952v1",
        "pub_date": "2023-06-13",
        "summary": "We present MOFI, a new vision foundation model designed to learn image\nrepresentations from noisy entity annotated images. MOFI differs from previous\nwork in two key aspects: ($i$) pre-training data, and ($ii$) training recipe.\nRegarding data, we introduce a new approach to automatically assign entity\nlabels to images from noisy image-text pairs. Our approach involves employing a\nnamed entity recognition model to extract entities from the alt-text, and then\nusing a CLIP model to select the correct entities as labels of the paired\nimage. The approach is simple, does not require costly human annotation, and\ncan be readily scaled up to billions of image-text pairs mined from the web.\nThrough this method, we have created Image-to-Entities (I2E), a new large-scale\ndataset with 1 billion images and 2 million distinct entities, covering rich\nvisual concepts in the wild. Building upon the I2E dataset, we study different\ntraining recipes, including supervised pre-training, contrastive pre-training,\nand multi-task learning. For constrastive pre-training, we treat entity names\nas free-form text, and further enrich them with entity descriptions.\nExperiments show that supervised pre-training with large-scale fine-grained\nentity labels is highly effective for image retrieval tasks, and multi-task\ntraining further improves the performance. The final MOFI model achieves 86.66%\nmAP on the challenging GPR1200 dataset, surpassing the previous\nstate-of-the-art performance of 72.19% from OpenAI's CLIP model. Further\nexperiments on zero-shot and linear probe image classification also show that\nMOFI outperforms a CLIP model trained on the original image-text data,\ndemonstrating the effectiveness of the I2E dataset in learning strong image\nrepresentations.",
        "translated": "提出了一种新的视觉基础模型 MOFI，该模型旨在从噪声实体注释图像中学习图像表示。MOFI 与以往的工作有两个关键方面的不同: ($i $)培训前数据和($ii $)培训配方。对于数据，我们引入了一种新的方法来自动分配实体标签图像噪声的图像-文本对。我们的方法包括使用命名实体识别模型从替代文本中提取实体，然后使用 CLIP 模型选择正确的实体作为配对图像的标签。这种方法很简单，不需要昂贵的人工注释，而且可以很容易地扩大到从网络中挖掘出的数十亿图像-文本对。通过这种方法，我们创建了图像到实体(I2E) ，这是一个新的大规模数据集，包含10亿张图像和200万个不同的实体，覆盖了丰富的野外视觉概念。在 I2E 数据集的基础上，我们研究了不同的训练方法，包括监督预训练、对比预训练和多任务学习。在对比预训练中，我们将实体名称视为自由形式的文本，并用实体描述进一步丰富实体名称。实验表明，基于大规模细粒度实体标签的监督预训练对图像检索任务具有很高的效果，多任务训练进一步提高了性能。最终的 MOFI 模型在具有挑战性的 GPR1200数据集上达到了86.66% 的 mAP，超过了之前 OpenAI 的 CLIP 模型72.19% 的最先进性能。进一步的零拍和线性探针图像分类实验也表明，MOFI 优于对原始图像-文本数据进行训练的 CLIP 模型，证明了 I2E 数据集在学习强图像表示方面的有效性。"
    },
    {
        "title": "Questioning the Survey Responses of Large Language Models",
        "url": "http://arxiv.org/abs/2306.07951v1",
        "pub_date": "2023-06-13",
        "summary": "As large language models increase in capability, researchers have started to\nconduct surveys of all kinds on these models with varying scientific\nmotivations. In this work, we examine what we can learn from a model's survey\nresponses on the basis of the well-established American Community Survey (ACS)\nby the U.S. Census Bureau. Evaluating more than a dozen different models,\nvarying in size from a few hundred million to ten billion parameters, hundreds\nof thousands of times each on questions from the ACS, we systematically\nestablish two dominant patterns. First, smaller models have a significant\nposition and labeling bias, for example, towards survey responses labeled with\nthe letter \"A\". This A-bias diminishes, albeit slowly, as model size increases.\nSecond, when adjusting for this labeling bias through randomized answer\nordering, models still do not trend toward US population statistics or those of\nany cognizable population. Rather, models across the board trend toward\nuniformly random aggregate statistics over survey responses. This pattern is\nrobust to various different ways of prompting the model, including what is the\nde-facto standard. Our findings demonstrate that aggregate statistics of a\nlanguage model's survey responses lack the signals found in human populations.\nThis absence of statistical signal cautions about the use of survey responses\nfrom large language models at present time.",
        "translated": "随着大型语言模型能力的提高，研究人员开始以不同的科学动机对这些模型进行各种各样的调查。在这项工作中，我们研究我们可以从一个模型的调查反应的基础上，由美国人口普查局建立的美国社区调查(ACS)的学习。我们评估了十几个不同的模型，这些模型的大小从几亿到一百亿个参数不等，每个模型对 ACS 提出的问题进行了数十万次评估，我们系统地建立了两种主导模式。首先，较小的模型有一个重要的位置和标签偏见，例如，对标有字母“ A”的调查回答。随着模型尺寸的增加，这种 A 偏差会逐渐减小，尽管速度很慢。其次，当通过随机回答排序调整这种标记偏差时，模型仍然没有趋向于美国人口统计或任何可认知人口的统计。相反，模型全面趋向于统一随机总体统计超过调查答复。该模式对于提示模型的各种不同方式都是健壮的，包括什么是事实上的标准。我们的研究结果表明，一个语言模型的调查回答的总体统计缺乏在人口中发现的信号。这种缺乏统计信号的情况提醒人们注意目前使用来自大型语言模型的调查答复。"
    },
    {
        "title": "BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory\n  Information",
        "url": "http://arxiv.org/abs/2306.07934v1",
        "pub_date": "2023-06-13",
        "summary": "Automated reasoning with unstructured natural text is a key requirement for\nmany potential applications of NLP and for developing robust AI systems.\nRecently, Language Models (LMs) have demonstrated complex reasoning capacities\neven without any finetuning. However, existing evaluation for automated\nreasoning assumes access to a consistent and coherent set of information over\nwhich models reason. When reasoning in the real-world, the available\ninformation is frequently inconsistent or contradictory, and therefore models\nneed to be equipped with a strategy to resolve such conflicts when they arise.\nOne widely-applicable way of resolving conflicts is to impose preferences over\ninformation sources (e.g., based on source credibility or information recency)\nand adopt the source with higher preference. In this paper, we formulate the\nproblem of reasoning with contradictory information guided by preferences over\nsources as the classical problem of defeasible reasoning, and develop a dataset\ncalled BoardgameQA for measuring the reasoning capacity of LMs in this setting.\nBoardgameQA also incorporates reasoning with implicit background knowledge, to\nbetter reflect reasoning problems in downstream applications. We benchmark\nvarious LMs on BoardgameQA and the results reveal a significant gap in the\nreasoning capacity of state-of-the-art LMs on this problem, showing that\nreasoning with conflicting information does not surface out-of-the-box in LMs.\nWhile performance can be improved with finetuning, it nevertheless remains\npoor.",
        "translated": "非结构化自然文本自动推理是自然语言处理许多潜在应用和开发健壮的人工智能系统的关键要求。最近，语言模型(LM)已经展示了复杂的推理能力，即使没有任何微调。然而，现有的自动推理评估假设模型能够获得一致和连贯的信息。在现实世界中进行推理时，可获得的信息往往不一致或相互矛盾，因此需要为模型配备一种战略，以便在出现这种冲突时解决这种冲突。一种广泛适用的解决冲突的方法是对信息来源强加偏好(例如，基于信息来源的可信度或信息的最新性) ，并以更高的偏好采用信息来源。在本文中，我们提出了由偏好引导的矛盾信息推理问题作为经典的可废止推理问题，并开发了一个名为 BoardgameQA 的数据集来测量在这种情况下 LM 的推理能力。BoardgameQA 还将推理与隐式背景知识结合起来，以更好地反映下游应用程序中的推理问题。我们在 BoardgameQA 上对各种 LM 进行了基准测试，结果显示在这个问题上最先进的 LM 在推理能力上存在显著的差距，表明在 LM 中，带有冲突信息的推理并不是开箱即用的。虽然通过微调可以提高性能，但它仍然很差。"
    },
    {
        "title": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with\n  Human Preferences",
        "url": "http://arxiv.org/abs/2306.07906v1",
        "pub_date": "2023-06-13",
        "summary": "We present WebGLM, a web-enhanced question-answering system based on the\nGeneral Language Model (GLM). Its goal is to augment a pre-trained large\nlanguage model (LLM) with web search and retrieval capabilities while being\nefficient for real-world deployments. To achieve this, we develop WebGLM with\nstrategies for the LLM-augmented retriever, bootstrapped generator, and human\npreference-aware scorer. Specifically, we identify and address the limitations\nof WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,\nand cost-effectiveness advantages. In addition, we propose systematic criteria\nfor evaluating web-enhanced QA systems. We conduct multi-dimensional human\nevaluation and quantitative ablation studies, which suggest the outperformance\nof the proposed WebGLM designs over existing systems. WebGLM with the\n10-billion-parameter GLM (10B) is shown to perform better than the\nsimilar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human\nevaluation. The code, demo, and data are at\n\\url{https://github.com/THUDM/WebGLM}.",
        "translated": "本文介绍了基于通用语言模型(GLM)的 Web 增强型问答系统 WebGLM。它的目标是增强一个预先训练的大型语言模型(LLM) ，该模型具有 Web 搜索和检索功能，同时对于现实世界的部署非常有效。为了实现这一点，我们使用 LLM 增强检索器、引导生成器和人类偏好感知记分器的策略来开发 WebGLM。具体来说，我们确定并解决了 WebGPT (OpenAI)的局限性，通过它，WebGLM 具有准确性、效率和成本效益方面的优势。此外，我们提出了评估网络增强 QA 系统的系统标准。我们进行了多维人体评估和定量消融研究，这表明所提出的 WebGLM 设计优于现有系统。具有100亿参数 GLM (10B)的 WebGLM 显示出比类似大小的 WebGPT (13B)更好的性能，甚至在人类评估中与 WebGPT (175B)相当。代码、演示和数据位于 url { https://github.com/thudm/webglm }。"
    },
    {
        "title": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
        "url": "http://arxiv.org/abs/2306.07902v1",
        "pub_date": "2023-06-13",
        "summary": "Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.",
        "translated": "尽管在多语言语料库收集和模型培训方面取得了令人印象深刻的进展，但开发大规模部署多语言模型仍然是一个重大挑战。对于依赖于文化的语言任务尤其如此。一个这样的例子是多语言情感分析领域，其中情感标记可以是微妙的，深深地隐藏在文化。这项工作提出了最广泛的开放大规模多语言数据集训练情感模型。该语料库包括79个手动选择的数据集，从超过350个数据集报告的科学文献基于严格的质量标准。语料库包括代表6个语系的27种语言。可以使用几种语言和函数特性查询数据集。此外，我们提出了一个多方面的情绪分类基准，总结了数百个实验进行了不同的基础模型，训练目标，数据集收集和微调策略。"
    },
    {
        "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use\n  Large Language Models for Text Production Tasks",
        "url": "http://arxiv.org/abs/2306.07899v1",
        "pub_date": "2023-06-13",
        "summary": "Large language models (LLMs) are remarkable data annotators. They can be used\nto generate high-fidelity supervised training data, as well as survey and\nexperimental data. With the widespread adoption of LLMs, human gold--standard\nannotations are key to understanding the capabilities of LLMs and the validity\nof their results. However, crowdsourcing, an important, inexpensive way to\nobtain human annotations, may itself be impacted by LLMs, as crowd workers have\nfinancial incentives to use LLMs to increase their productivity and income. To\ninvestigate this concern, we conducted a case study on the prevalence of LLM\nusage by crowd workers. We reran an abstract summarization task from the\nliterature on Amazon Mechanical Turk and, through a combination of keystroke\ndetection and synthetic text classification, estimate that 33-46% of crowd\nworkers used LLMs when completing the task. Although generalization to other,\nless LLM-friendly tasks is unclear, our results call for platforms,\nresearchers, and crowd workers to find new ways to ensure that human data\nremain human, perhaps using the methodology proposed here as a stepping stone.\nCode/data: https://github.com/epfl-dlab/GPTurk",
        "translated": "大型语言模型(LLM)是非常出色的数据注释器。它们可以用来生成高保真的监督训练数据，以及调查和实验数据。随着 LLM 的广泛采用，人工黄金标准注释是理解 LLM 功能及其结果有效性的关键。然而，众包作为一种获取人工注释的重要而廉价的方式，可能本身就会受到 LLM 的影响，因为众包工作者有财务动机使用 LLM 来提高他们的生产力和收入。为了调查这一问题，我们进行了一个案例研究的普遍使用 LLM 的人群工作者。我们从亚马逊土耳其机器人的文献中重新运行了一个抽象的总结任务，并且通过组合击键检测和合成文本分类，估计33-46% 的人群工作者在完成任务时使用 LLM。尽管对其他不太适合 LLM 的任务的概括还不清楚，但我们的研究结果呼吁平台、研究人员和群体工作者找到新的方法来确保人类数据仍然是人类的，或许可以使用这里提出的方法作为垫脚石。代码/资料:  https://github.com/epfl-dlab/gpturk"
    },
    {
        "title": "GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition",
        "url": "http://arxiv.org/abs/2306.07848v1",
        "pub_date": "2023-06-13",
        "summary": "Contrastive Language-Audio Pretraining (CLAP) has recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced CLAP model for speech emotion\nrecognition (SER). Specifically, we first build an effective emotion CLAP model\ntermed Emo-CLAP for SER, utilizing various self-supervised learning based\npre-trained models. Then, considering the importance of the gender attribute in\nspeech emotion modeling, two GEmo-CLAP approaches are further proposed to\nintegrate the emotion and gender information of speech signals, forming more\nreasonable objectives. Extensive experiments conducted on the IEMOCAP corpus\ndemonstrate that our proposed two GEmo-CLAP approaches consistently outperform\nthe baseline Emo-CLAP with different pre-trained models, while also achieving\nsuperior recognition performance compared with other state-of-the-art methods.",
        "translated": "对比语言-音频预训练(CLAP)最近在多个领域取得了令人瞩目的成功。本文提出了一种基于性别属性增强的语音情感识别模型 GEmo-CLAP。具体来说，我们首先利用各种基于预训练的自监督学习模型，建立了一个有效的情绪 CLAP 模型，称为情绪 CLAP 模型。然后，考虑到性别属性在语音情感建模中的重要性，进一步提出了两种 Gemo-CLAP 方法来整合语音信号的情感和性别信息，形成更加合理的目标。在 IEMOCAP 语料库上进行的大量实验表明，我们提出的两种 Gemo-CLAP 方法始终优于不同预训练模型的基线 Emo-CLAP，同时与其他最先进的方法相比，也获得了更好的识别性能。"
    },
    {
        "title": "Adversarial Capsule Networks for Romanian Satire Detection and Sentiment\n  Analysis",
        "url": "http://arxiv.org/abs/2306.07845v1",
        "pub_date": "2023-06-13",
        "summary": "Satire detection and sentiment analysis are intensively explored natural\nlanguage processing (NLP) tasks that study the identification of the satirical\ntone from texts and extracting sentiments in relationship with their targets.\nIn languages with fewer research resources, an alternative is to produce\nartificial examples based on character-level adversarial processes to overcome\ndataset size limitations. Such samples are proven to act as a regularization\nmethod, thus improving the robustness of models. In this work, we improve the\nwell-known NLP models (i.e., Convolutional Neural Networks, Long Short-Term\nMemory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), and\nBidirectional GRUs) with adversarial training and capsule networks. The\nfine-tuned models are used for satire detection and sentiment analysis tasks in\nthe Romanian language. The proposed framework outperforms the existing methods\nfor the two tasks, achieving up to 99.08% accuracy, thus confirming the\nimprovements added by the capsule layers and the adversarial training in NLP\napproaches.",
        "translated": "讽刺检测和情感分析是自然语言处理(NLP)研究的重要课题，主要研究从文本中识别讽刺语气并提取与目标相关的情感。在研究资源较少的语言中，另一种方法是基于字符级对抗过程生成人工示例，以克服数据集大小的限制。这些样本被证明是一种正则化方法，从而提高了模型的鲁棒性。在这项工作中，我们改进了著名的 NLP 模型(即，卷积神经网络，长短期记忆(LSTM) ，双向 LSTM，门控回归单元(GRU) ，和双向 GRU)与对抗训练和胶囊网络。这些经过微调的模型被用于罗马尼亚语中的讽刺探测和情感分析任务。该框架比现有的方法更好地完成了这两个任务，达到了99.08% 的准确率，从而证实了胶囊层的改进和 NLP 方法中的对抗性训练。"
    },
    {
        "title": "Web of Things and Trends in Agriculture: A Systematic Literature Review",
        "url": "http://arxiv.org/abs/2306.09079v1",
        "pub_date": "2023-06-15",
        "summary": "In the past few years, the Web of Things (WOT) became a beneficial\ngame-changing technology within the Agriculture domain as it introduces\ninnovative and promising solutions to the Internet of Things (IoT) agricultural\napplications problems by providing its services. WOT provides the support for\nintegration, interoperability for heterogeneous devices, infrastructures,\nplatforms, and the emergence of various other technologies. The main aim of\nthis study is about understanding and providing a growing and existing research\ncontent, issues, and directions for the future regarding WOT-based agriculture.\nTherefore, a systematic literature review (SLR) of research articles is\npresented by categorizing the selected studies published between 2010 and 2020\ninto the following categories: research type, approaches, and their application\ndomains. Apart from reviewing the state-of-the-art articles on WOT solutions\nfor the agriculture field, a taxonomy of WOT-base agriculture application\ndomains has also been presented in this study. A model has also presented to\nshow the picture of WOT based Smart Agriculture. Lastly, the findings of this\nSLR and the research gaps in terms of open issues have been presented to\nprovide suggestions on possible future directions for the researchers for\nfuture research.",
        "translated": "在过去的几年里，物联网(WOT)在农业领域成为了一个有益的改变游戏规则的技术，因为它通过提供服务引入了创新的和有前途的解决物联网(IoT)农业应用问题的方案。WOT 为异构设备、基础设施、平台以及其他各种技术的出现提供了集成、互操作性的支持。这项研究的主要目的是了解和提供一个不断增长和现有的研究内容，问题和未来的方向，关于基于 WOT 的农业。因此，通过将2010年至2020年间发表的选定研究分为以下几类: 研究类型，方法及其应用领域，对研究文章进行了系统的文献回顾(SLR)。除了回顾有关农业领域 WOT 解决方案的最新文章外，本研究还提出了基于 WOT 的农业应用领域的分类。本文还提出了一个模型来展示基于 WOT 的智能农业的图景。最后，本文介绍了本次研究的结果以及在公开课题方面的研究差距，为研究人员今后的研究提供了可能的方向建议。"
    },
    {
        "title": "Fast and Examination-agnostic Reciprocal Recommendation in Matching\n  Markets",
        "url": "http://arxiv.org/abs/2306.09060v1",
        "pub_date": "2023-06-15",
        "summary": "In matching markets such as job posting and online dating platforms, the\nrecommender system plays a critical role in the success of the platform. Unlike\nstandard recommender systems that suggest items to users, reciprocal\nrecommender systems (RRSs) that suggest other users must take into account the\nmutual interests of users. In addition, ensuring that recommendation\nopportunities do not disproportionately favor popular users is essential for\nthe total number of matches and for fairness among users. Existing\nrecommendation methods in matching markets, however, face computational\nchallenges on large-scale platforms and depend on specific examination\nfunctions in the position-based model (PBM). In this paper, we introduce the\nreciprocal recommendation method based on the matching with transferable\nutility (TU matching) model in the context of ranking recommendations in\nmatching markets and propose a fast and examination-model-free algorithm.\nFurthermore, we evaluate our approach on experiments with synthetic data and\nreal-world data from an online dating platform in Japan. Our method performs\nbetter than or as well as existing methods in terms of the total number of\nmatches and works well even in a large-scale dataset for which one existing\nmethod does not work.",
        "translated": "在招聘和在线约会平台等匹配市场方面，推荐系统对平台的成功起着关键作用。不像标准的推荐系统，建议项目给用户，互惠推荐系统(RRS) ，建议其他用户必须考虑到用户的共同利益。此外，确保推荐机会不会不成比例地偏向受欢迎的用户，对于匹配的总数和用户之间的公平性至关重要。然而，现有的匹配市场推荐方法在大规模平台上面临计算挑战，并且依赖于基于位置模型(PBM)中的特定检验函数。本文在匹配市场推荐排序的背景下，介绍了基于匹配可转移效用(TU 匹配)模型的互惠推荐方法，并提出了一种快速、无检验模型的算法。此外，我们评估了我们的实验方法与合成数据和真实世界的数据从一个在线约会平台在日本。就匹配总数而言，我们的方法比现有方法执行得更好，甚至在一个现有方法无法工作的大规模数据集中也能很好地工作。"
    },
    {
        "title": "Mapping Researcher Activity based on Publication Data by means of\n  Transformers",
        "url": "http://arxiv.org/abs/2306.09049v1",
        "pub_date": "2023-06-15",
        "summary": "Modern performance on several natural language processing (NLP) tasks has\nbeen enhanced thanks to the Transformer-based pre-trained language model BERT.\nWe employ this concept to investigate a local publication database. Research\npapers are encoded and clustered to form a landscape view of the scientific\ntopics, in which research is active. Authors working on similar topics can be\nidentified by calculating the similarity between their papers. Based on this,\nwe define a similarity metric between authors. Additionally we introduce the\nconcept of self-similarity to indicate the topical variety of authors.",
        "translated": "现代自然语言处理(NLP)任务的性能得到了提高，这要归功于基于变压器的预训练语言模型 BERT。我们使用这个概念来调查一个本地出版物数据库。研究论文的编码和聚类形成了一个景观的科学主题，其中研究是活跃的。研究类似主题的作者可以通过计算他们论文之间的相似性来识别。在此基础上，我们定义了作者之间的相似度量。此外，我们还引入了自相似的概念，以表明作者的主题多样性。"
    },
    {
        "title": "RecFusion: A Binomial Diffusion Process for 1D Data for Recommendation",
        "url": "http://arxiv.org/abs/2306.08947v1",
        "pub_date": "2023-06-15",
        "summary": "In this paper we propose RecFusion, which comprise a set of diffusion models\nfor recommendation. Unlike image data which contain spatial correlations, a\nuser-item interaction matrix, commonly utilized in recommendation, lacks\nspatial relationships between users and items. We formulate diffusion on a 1D\nvector and propose binomial diffusion, which explicitly models binary user-item\ninteractions with a Bernoulli process. We show that RecFusion approaches the\nperformance of complex VAE baselines on the core recommendation setting (top-n\nrecommendation for binary non-sequential feedback) and the most common datasets\n(MovieLens and Netflix). Our proposed diffusion models that are specialized for\n1D and/or binary setups have implications beyond recommendation systems, such\nas in the medical domain with MRI and CT scans.",
        "translated": "在本文中，我们提出了 RecFusion，它包含了一组用于推荐的扩散模型。与包含空间相关性的图像数据不同，通常用于推荐的用户-项目交互矩阵缺乏用户和项目之间的空间关系。我们在一维向量上描述扩散，并提出二项式扩散，它明确地模拟与伯努利过程的二进制用户-项目交互。我们表明 RecFusion 在核心推荐设置(二进制非顺序反馈的前 n 推荐)和最常见的数据集(MovieLens 和 Netflix)上接近复杂 VAE 基线的性能。我们提出的扩散模型是专门为一维和/或二进制设置的影响超出推荐系统，如在医学领域的 MRI 和 CT 扫描。"
    },
    {
        "title": "Document Entity Retrieval with Massive and Noisy Pre-training",
        "url": "http://arxiv.org/abs/2306.08937v1",
        "pub_date": "2023-06-15",
        "summary": "Visually-Rich Document Entity Retrieval (VDER) is a type of machine learning\ntask that aims at recovering text spans in the documents for each of the\nentities in question. VDER has gained significant attention in recent years\nthanks to its broad applications in enterprise AI. Unfortunately, as document\nimages often contain personally identifiable information (PII), publicly\navailable data have been scarce, not only because of privacy constraints but\nalso the costs of acquiring annotations. To make things worse, each dataset\nwould often define its own sets of entities, and the non-overlapping entity\nspaces between datasets make it difficult to transfer knowledge between\ndocuments. In this paper, we propose a method to collect massive-scale, noisy,\nand weakly labeled data from the web to benefit the training of VDER models.\nSuch a method will generate a huge amount of document image data to compensate\nfor the lack of training data in many VDER settings. Moreover, the collected\ndataset named DocuNet would not need to be dependent on specific document types\nor entity sets, making it universally applicable to all VDER tasks. Empowered\nby DocuNet, we present a lightweight multimodal architecture named UniFormer,\nwhich can learn a unified representation from text, layout, and image crops\nwithout needing extra visual pertaining. We experiment with our methods on\npopular VDER models in various settings and show the improvements when this\nmassive dataset is incorporated with UniFormer on both classic entity retrieval\nand few-shot learning settings.",
        "translated": "可视化丰富文档实体检索(VDER)是一种机器学习任务，旨在恢复文档中涉及到的每个实体的文本跨度。VDER 由于在企业人工智能中的广泛应用，近年来受到了广泛的关注。遗憾的是，由于文档图像通常包含个人身份信息(pII) ，公开可用的数据很少，这不仅是因为隐私限制，还因为获取注释的成本。更糟糕的是，每个数据集通常会定义自己的实体集，而数据集之间不重叠的实体空间使得在文档之间传递知识变得非常困难。本文提出了一种从网络上收集大规模、有噪声和弱标记数据的方法，有利于 VDER 模型的训练。这种方法将产生大量的文档图像数据，以弥补许多 VDER 设置中训练数据的不足。此外，名为 DocuNet 的收集的数据集不需要依赖于特定的文档类型或实体集，这使得它普遍适用于所有 VDER 任务。在 DocuNet 的支持下，我们提出了一个轻量级的多模态体系结构，名为 UniForm，它可以从文本、布局和图像作物中学习统一的表示，而不需要额外的视觉修饰。我们在不同的设置下对流行的 VDER 模型进行了实验，结果表明，在经典的实体检索和少镜头学习设置下，将这个海量数据集与 UniForm 结合起来，可以得到改进。"
    }
]