# CIKM2023 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[BI-GCN: Bilateral Interactive Graph Convolutional Network for Recommendation](https://doi.org/10.1145/3583780.3615232)|Yinan Zhang, Pei Wang, Congcong Liu, Xiwei Zhao, Hao Qi, Jie He, Junsheng Jin, Changping Peng, Zhangang Lin, Jingping Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BI-GCN:+Bilateral+Interactive+Graph+Convolutional+Network+for+Recommendation)|1|
|[Monotonic Neural Ordinary Differential Equation: Time-series Forecasting for Cumulative Data](https://doi.org/10.1145/3583780.3615487)|Zhichao Chen, Leilei Ding, Zhixuan Chu, Yucheng Qi, Jianmin Huang, Hao Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Monotonic+Neural+Ordinary+Differential+Equation:+Time-series+Forecasting+for+Cumulative+Data)|1|
|[Continual Learning in Predictive Autoscaling](https://doi.org/10.1145/3583780.3615463)|Hongyan Hao, Zhixuan Chu, Shiyi Zhu, Gangwei Jiang, Yan Wang, Caigao Jiang, James Y. Zhang, Wei Jiang, Siqiao Xue, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Learning+in+Predictive+Autoscaling)|1|
|[TEI2GO: A Multilingual Approach for Fast Temporal Expression Identification](https://doi.org/10.1145/3583780.3615130)|Hugo Sousa, Ricardo Campos, Alípio Jorge||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TEI2GO:+A+Multilingual+Approach+for+Fast+Temporal+Expression+Identification)|1|
|[APGL4SR: A Generic Framework with Adaptive and Personalized Global Collaborative Information in Sequential Recommendation](https://doi.org/10.1145/3583780.3614781)|Mingjia Yin, Hao Wang, Xiang Xu, Likang Wu, Sirui Zhao, Wei Guo, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen|Huawei Singapore Research Center, Singapore, Singapore; Huawei Noah's Ark Lab, Shenzhen, China; University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|The sequential recommendation system has been widely studied for its promising effectiveness in capturing dynamic preferences buried in users' sequential behaviors. Despite the considerable achievements, existing methods usually focus on intra-sequence modeling while overlooking exploiting global collaborative information by inter-sequence modeling, resulting in inferior recommendation performance. Therefore, previous works attempt to tackle this problem with a global collaborative item graph constructed by pre-defined rules. However, these methods neglect two crucial properties when capturing global collaborative information, i.e., adaptiveness and personalization, yielding sub-optimal user representations. To this end, we propose a graph-driven framework, named Adaptive and Personalized Graph Learning for Sequential Recommendation (APGL4SR), that incorporates adaptive and personalized global collaborative information into sequential recommendation systems. Specifically, we first learn an adaptive global graph among all items and capture global collaborative information with it in a self-supervised fashion, whose computational burden can be further alleviated by the proposed SVD-based accelerator. Furthermore, based on the graph, we propose to extract and utilize personalized item correlations in the form of relative positional encoding, which is a highly compatible manner of personalizing the utilization of global collaborative information. Finally, the entire framework is optimized in a multi-task learning paradigm, thus each part of APGL4SR can be mutually reinforced. As a generic framework, APGL4SR can not only outperform other baselines with significant margins, but also exhibit promising versatility, the ability to learn a meaningful global collaborative graph, and the ability to alleviate the dimensional collapse issue of item embeddings.|顺序推荐系统在捕获隐藏在用户顺序行为中的动态偏好方面有着广泛的应用前景。尽管已经取得了相当大的成就，但现有的方法往往只注重序列内建模，而忽视了通过序列间建模来开发全局协同信息，导致推荐性能较差。因此，以往的研究尝试利用预先定义的规则构造一个全局协同项目图来解决这个问题。然而，这些方法在获取全局协作信息时忽略了两个关键性质，即适应性和个性化，产生了次优的用户表示。为此，我们提出了一个图驱动的序列推荐自适应和个性化图学习框架(APGL4SR) ，该框架将自适应和个性化的全局协作信息融入到序列推荐系统中。具体来说，我们首先学习一个所有项目之间的自适应全局图，并以自监督的方式捕获全局协作信息，通过提出的基于奇异值分解的加速器可以进一步减轻全局协作信息的计算负担。在此基础上，提出了以相对位置编码的形式提取和利用个性化项目相关性，这是一种高度兼容的利用全球协同信息的个性化方式。最后，在多任务学习范式下对整个框架进行优化，使 APGL4SR 的各个部分得到相互增强。作为一个通用框架，APGL4SR 不仅具有显著的优势，而且具有良好的通用性、学习有意义的全局协作图的能力以及缓解项目嵌入的尺寸崩溃问题的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=APGL4SR:+A+Generic+Framework+with+Adaptive+and+Personalized+Global+Collaborative+Information+in+Sequential+Recommendation)|0|
|[Query-dominant User Interest Network for Large-Scale Search Ranking](https://doi.org/10.1145/3583780.3615022)|Tong Guo, Xuanping Li, Haitao Yang, Xiao Liang, Yong Yuan, Jingyou Hou, Bingqing Ke, Chao Zhang, Junlin He, Shunyu Zhang, Enyun Yu, Wenwu Ou|Kuaishou Technology Co., Ltd, Beijing, China; unaffiliated, Beijing, China|Historical behaviors have shown great effect and potential in various prediction tasks, including recommendation and information retrieval. The overall historical behaviors are various but noisy while search behaviors are always sparse. Most existing approaches in personalized search ranking adopt the sparse search behaviors to learn representation with bottleneck, which do not sufficiently exploit the crucial long-term interest. In fact, there is no doubt that user long-term interest is various but noisy for instant search, and how to exploit it well still remains an open problem.   To tackle this problem, in this work, we propose a novel model named Query-dominant user Interest Network (QIN), including two cascade units to filter the raw user behaviors and reweigh the behavior subsequences. Specifically, we propose a relevance search unit (RSU), which aims to search a subsequence relevant to the query first and then search the sub-subsequences relevant to the target item. These items are then fed into an attention unit called Fused Attention Unit (FAU). It should be able to calculate attention scores from the ID field and attribute field separately, and then adaptively fuse the item embedding and content embedding based on the user engagement of past period. Extensive experiments and ablation studies on real-world datasets demonstrate the superiority of our model over state-of-the-art methods. The QIN now has been successfully deployed on Kuaishou search, an online video search platform, and obtained 7.6% improvement on CTR.|历史行为在各种预测任务中显示出巨大的效果和潜力，包括推荐和信息检索。整体的历史行为是多样的，但是有噪声，而搜索行为总是稀疏的。大多数现有的个性化检索排名方法采用稀疏搜索行为来学习带有瓶颈的表示，这种方法没有充分利用关键的长期兴趣。事实上，毫无疑问，用户对即时搜索的长期兴趣是多种多样的，但是噪音很大，如何很好地利用它仍然是一个悬而未决的问题。为了解决这一问题，本文提出了一种新的查询主导用户兴趣网络(QIN)模型，该模型包括两个级联单元，用于过滤原始用户行为和重新权衡行为子序列。具体来说，我们提出了一种相关搜索单元(RSU) ，它的目的是先搜索与查询相关的子序列，然后再搜索与目标项相关的子子序列。然后，这些物品被输入一个称为“融合注意力单元”(FAU)的注意力单元。它应该能够分别从 ID 字段和属性字段计算注意力得分，然后根据用户过去一段时间的参与度自适应地融合项目嵌入和内容嵌入。对真实世界数据集的大量实验和消融研究表明，我们的模型优于最先进的方法。QIN 现已成功部署在快手搜索(一个在线视频搜索平台)上，点击率提高了7.6% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query-dominant+User+Interest+Network+for+Large-Scale+Search+Ranking)|0|
|[Modeling Sequential Collaborative User Behaviors For Seller-Aware Next Basket Recommendation](https://doi.org/10.1145/3583780.3614973)|Ziyi Kou, Saurav Manchanda, ShihTing Lin, Min Xie, Haixun Wang, Xiangliang Zhang|Instacart, San Francisco, CA, USA; University of Notre Dame, Notre Dame, IN, USA|Next Basket Recommendation (NBR) aims to recommend a set of products as a basket to users based on their historical shopping behavior. In this paper, we investigate the problem of NBR in online marketplaces (e.g., Instacart, Uber Eats) that connect users with multiple sellers. In such scenarios, effective NBR can significantly enhance the shopping experience of users by recommending diversified and completed products based on specific sellers, especially when a user purchases from a seller they have not visited before. However, conventional NBR approaches assume that all considered products are from the same sellers, which overlooks the complex relationships between users, sellers, and products. To address such limitations, we develop SecGT, a sequential collaborative graph transformer framework that recommends users with baskets from specific sellers based on seller-aware user preference representations that are generated by collaboratively modeling the joint user-seller-product interactions and sequentially exploring the user-agnostic basket transitions in an interactive way. We evaluate the performance of SecGT on users from a leading online marketplace at multiple cities with various involved sellers. The results show that SecGT outperforms existing NBR and also traditional product recommendation approaches on recommending baskets from cold sellers for different types of users across all cities.|下一个购物篮推荐系统(NBR)的目标是根据用户的历史购物行为向他们推荐一组产品作为购物篮。在本文中，我们研究了在线市场(如 Instacart，Uber Eats)中连接用户和多个卖家的 NBR 问题。在这种情况下，有效的 NBR 可以通过推荐基于特定卖家的多样化和完整的产品来显著提高用户的购物体验，特别是当用户从他们以前没有访问过的卖家那里购买产品时。然而，传统的 NBR 方法假设所有被考虑的产品都来自同一个销售商，这忽略了用户、销售商和产品之间的复杂关系。为了解决这些局限性，我们开发了 SecGT，这是一个连续的协作图形转换框架，根据卖方感知的用户偏好表示，通过协作建模联合用户-卖方-产品交互并以交互方式顺序探索用户不可知的篮子转换来推荐用户。我们评估的性能，从一个领先的在线市场在多个城市的用户与各种参与的卖家。结果表明，在向各城市不同类型的用户推荐冷卖篮子方面，SecGT 的表现优于现有的 NBR 和传统的产品推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Sequential+Collaborative+User+Behaviors+For+Seller-Aware+Next+Basket+Recommendation)|0|
|[Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR Prediction in Taobao](https://doi.org/10.1145/3583780.3615496)|Jingyue Gao, Shuguang Han, Han Zhu, Siran Yang, Yuning Jiang, Jian Xu, Bo Zheng|Alibaba Group, Beijing, China|Click-Through Rate (CTR) prediction serves as a fundamental component in online advertising. A common practice is to train a CTR model on advertisement (ad) impressions with user feedback. Since ad impressions are purposely selected by the model itself, their distribution differs from the inference distribution and thus exhibits sample selection bias (SSB) that affects model performance. Existing studies on SSB mainly employ sample re-weighting techniques which suffer from high variance and poor model calibration. Another line of work relies on costly uniform data that is inadequate to train industrial models. Thus mitigating SSB in industrial models with a uniform-data-free framework is worth exploring. Fortunately, many platforms display mixed results of organic items (i.e., recommendations) and sponsored items (i.e., ads) to users, where impressions of ads and recommendations are selected by different systems but share the same user decision rationales. Based on the above characteristics, we propose to leverage recommendations samples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After elaborating data augmentation, Rec4Ad learns disentangled representations with alignment and decorrelation modules for enhancement. When deployed in Taobao display advertising system, Rec4Ad achieves substantial gains in key business metrics, with a lift of up to +6.6\% CTR and +2.9\% RPM.|点进率预测是在线广告的一个基本组成部分。一个常见的做法是训练广告(广告)印象与用户反馈的点击率模型。由于广告印象是由模型本身有目的地选择的，它们的分布不同于推断分布，因此表现出影响模型性能的样本选择偏差(SSB)。现有的 SSB 研究主要采用样本重权重技术，存在方差大、模型校正差等问题。另一项工作依赖于昂贵的统一数据，这些数据不足以培训工业模型。因此，在无统一数据框架的工业模型中减少 SSB 是值得探索的。幸运的是，许多平台向用户显示有机项目(即推荐)和赞助项目(即广告)的混合结果，其中广告和推荐的印象由不同的系统选择，但共享相同的用户决策理由。基于上述特点，我们建议利用推荐样本作为免费午餐，以减轻 SSB 广告点击率模型(Rec4Ad)。在详细阐述了数据增强之后，Rec4Ad 学习了利用对齐和去相关模块进行增强的解纠缠表示。在淘宝展示广告系统中部署 Rec4Ad 后，Rec4Ad 在关键业务指标上取得了实质性进展，点击率和转速分别提高了6.6% 和2.9% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rec4Ad:+A+Free+Lunch+to+Mitigate+Sample+Selection+Bias+for+Ads+CTR+Prediction+in+Taobao)|0|
|[Fragment and Integrate Network (FIN): A Novel Spatial-Temporal Modeling Based on Long Sequential Behavior for Online Food Ordering Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615478)|Jun Li, Ge Zhang||Spatial-temporal information has been proven to be of great significance for click-through rate prediction tasks in online Location-Based Services (LBS), especially in mainstream food ordering platforms such as DoorDash, Uber Eats, Meituan, and Ele.me. Modeling user spatial-temporal preferences with sequential behavior data has become a hot topic in recommendation systems and online advertising. However, most of existing methods either lack the representation of rich spatial-temporal information or only handle user behaviors with limited length, e.g. 100. In this paper, we tackle these problems by designing a new spatial-temporal modeling paradigm named Fragment and Integrate Network (FIN). FIN consists of two networks: (i) Fragment Network (FN) extracts Multiple Sub-Sequences (MSS) from lifelong sequential behavior data, and captures the specific spatial-temporal representation by modeling each MSS respectively. Here both a simplified attention and a complicated attention are adopted to balance the performance gain and resource consumption. (ii) Integrate Network (IN) builds a new integrated sequence by utilizing spatial-temporal interaction on MSS and captures the comprehensive spatial-temporal representation by modeling the integrated sequence with a complicated attention. Both public datasets and production datasets have demonstrated the accuracy and scalability of FIN. Since 2022, FIN has been fully deployed in the recommendation advertising system of Ele.me, one of the most popular online food ordering platforms in China, obtaining 5.7% improvement on Click-Through Rate (CTR) and 7.3% increase on Revenue Per Mille (RPM).|时空信息已被证明对于在线基于位置服务(LBS)的点进率预测任务具有重要意义，特别是在主流食品订购平台如 DoorDash、 Uber Eats、美团和 Ele.me 中。利用序列行为数据建立用户时空偏好模型已成为推荐系统和在线广告研究的热点。然而，大多数现有的方法要么缺乏丰富的时空信息的表示，要么只能处理有限长度的用户行为，例如100。针对这些问题，本文设计了一种新的时空建模范式——分段集成网络(FIN)。FIN 由两个网络组成: (1)片段网络(FN)从终身序列行为数据中提取多个子序列(MSS) ，并分别对每个子序列进行建模，获取特定的时空表示。这里采用了简化注意和复杂注意来平衡性能增益和资源消耗。(2)综合网络(IN)利用 MSS 上的时空相互作用建立一个新的综合序列，通过对综合序列进行复杂注意力建模，获取综合的时空表示。公共数据集和生产数据集都证明了 FIN 的准确性和可扩展性。自2022年以来，中国最受欢迎的在线食品订购平台之一饿了么的推荐广告系统中已经全面部署了财务识别系统，点进率点击率提高了5.7% ，每公里收入提高了7.3% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragment+and+Integrate+Network+(FIN):+A+Novel+Spatial-Temporal+Modeling+Based+on+Long+Sequential+Behavior+for+Online+Food+Ordering+Click-Through+Rate+Prediction)|0|
|[Batch-Mix Negative Sampling for Learning Recommendation Retrievers](https://doi.org/10.1145/3583780.3614789)|Yongfu Fan, Jin Chen, Yongquan Jiang, Defu Lian, Fangda Guo, Kai Zheng|Southwest Jiaotong University, Chengdu, China; University of Science and Technology of China, Hefei, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Electronic Science and Technology of China, Chengdu, China|Recommendation retrievers commonly retrieve user potentially preferred items from numerous items, where the query and item representation are learned according to the dual encoders with the log-softmax loss. Under real scenarios, the number of items becomes considerably large, making it exceedingly difficult to calculate the partition function with the whole item corpus. Negative sampling, which samples a subset from the item corpus, is widely used to accelerate the model training. Among different samplers, the in-batch sampling is commonly adopted for online recommendation retrievers, which regards the other items within the mini-batch as the negative samples for the given query, owing to its time and memory efficiency. However, the sample selection bias occurs due to the skewed feedback, harming the retrieval quality. In this paper, we propose a negative sampling approach named Batch-Mix Negative Sampling (BMNS), which adopts batch mixing operation to generate additional negatives for model training. Concretely, BMNS first generates new negative items with the sampled mix coefficient from the Beta distribution, after which a tailored correct strategy guided by frequency is designed to match the sampled softmax loss. In this way, the effort of re-encoding items out of the mini-batch is reduced while also improving the representation space of the negative set. The empirical experiments on four real-world datasets demonstrate BMNS is superior to the competitive negative inbatch sampling method.|推荐检索器通常从许多项目中检索用户潜在首选项，其中根据带有 log-softmax 损失的双编码器学习查询和项表示。在实际情况下，条目的数量会变得相当大，这使得用整个条目语料库计算配分函数变得非常困难。负抽样是从项目语料库中抽取子集，广泛用于加速模型训练。在不同的抽样方法中，在线推荐检索通常采用批内抽样，由于时间和内存效率的原因，将小批内的其他项目作为给定查询的否定样本。然而，样本选择偏差的产生是由于反馈的偏差，影响了检索质量。本文提出了一种负抽样方法——批量混合负抽样(BMNS) ，该方法采用批量混合操作产生附加负数，用于模型训练。具体来说，BMNS 首先根据采样的混合系数生成新的负项，然后根据频率设计一个量身定制的正确策略，以匹配采样的软最大损失(softmax loss) Β分布。这样，既减少了从小批处理中重新编码项的工作量，又提高了负集的表示空间。在四个实际数据集上的实验表明，BMNS 方法优于竞争性负内批抽样方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Batch-Mix+Negative+Sampling+for+Learning+Recommendation+Retrievers)|0|
|[Dynamic Embedding Size Search with Minimum Regret for Streaming Recommender System](https://doi.org/10.1145/3583780.3615135)|Bowei He, Xu He, Renrui Zhang, Yingxue Zhang, Ruiming Tang, Chen Ma|The Chinese University of Hong Kong, Hong Kong, Hong Kong; Huawei Noah's Ark Lab Montreal, Montreal, PQ, Canada; Huawei Noah's Ark Lab, Shenzhen, China; City University of Hong Kong, Hong Kong, Hong Kong|With the continuous increase of users and items, conventional recommender systems trained on static datasets can hardly adapt to changing environments. The high-throughput data requires the model to be updated in a timely manner for capturing the user interest dynamics, which leads to the emergence of streaming recommender systems. Due to the prevalence of deep learning-based recommender systems, the embedding layer is widely adopted to represent the characteristics of users, items, and other features in low-dimensional vectors. However, it has been proved that setting an identical and static embedding size is sub-optimal in terms of recommendation performance and memory cost, especially for streaming recommendations. To tackle this problem, we first rethink the streaming model update process and model the dynamic embedding size search as a bandit problem. Then, we analyze and quantify the factors that influence the optimal embedding sizes from the statistics perspective. Based on this, we propose the \textbf{D}ynamic \textbf{E}mbedding \textbf{S}ize \textbf{S}earch (\textbf{DESS}) method to minimize the embedding size selection regret on both user and item sides in a non-stationary manner. Theoretically, we obtain a sublinear regret upper bound superior to previous methods. Empirical results across two recommendation tasks on four public datasets also demonstrate that our approach can achieve better streaming recommendation performance with lower memory cost and higher time efficiency.|随着用户和项目的不断增加，传统的基于静态数据集的推荐系统难以适应不断变化的环境。高吞吐量数据要求模型及时更新，以捕捉用户兴趣动态，从而导致流式推荐系统的出现。由于基于深度学习的推荐系统的普及，嵌入层被广泛采用来在低维向量中表示用户、项目等特征。然而，已经证明，设置一个相同的静态嵌入大小在推荐性能和内存成本方面是次优的，特别是对于流式推荐。为了解决这个问题，我们首先重新考虑了流模型更新过程，并将动态嵌入大小搜索模型建模为盗贼问题。然后，从统计学的角度对影响最优嵌入规模的因素进行了分析和量化。在此基础上，提出了一种动态 textbf { D }嵌入 textbf { E }嵌入 textbf { S } ize textbf { S } earch (textbf { DESS })方法，以非平稳方式最小化用户端和项目端的嵌入大小选择遗憾。从理论上，我们得到了一个次线性后悔上界优于以往的方法。对四个公共数据集的两个推荐任务的实验结果也表明，该方法能够以较低的内存开销和较高的时间效率获得较好的流推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Embedding+Size+Search+with+Minimum+Regret+for+Streaming+Recommender+System)|0|
|[Text Matching Improves Sequential Recommendation by Reducing Popularity Biases](https://doi.org/10.1145/3583780.3615077)|Zhenghao Liu, Sen Mei, Chenyan Xiong, Xiaohua Li, Shi Yu, Zhiyuan Liu, Yu Gu, Ge Yu|Carnegie Mellon University, Pittsburgh, PA, USA; Northeastern University, Shenyang, China; Tsinghua University, Beijing, China|This paper proposes Text mAtching based SequenTial rEcommendation model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.|提出了一种基于文本匹配的序列推荐模型(TASTE) ，该模型将项目和用户映射到嵌入空间中，通过匹配项目的文本表示来推荐项目。TASTE 使用项目的标识符和属性语言化项目和用户-项目交互。为了更好地描述用户行为，TASTE 还提出了一种注意稀疏方法，该方法通过减少编码过程中的自我注意计算，使 TASTE 能够模拟更长时间的用户-项目交互。我们的实验表明，在广泛使用的顺序推荐数据集上，TASTE 优于最先进的方法。TASTE 通过使用全文建模来表示长尾项目，并将预训练语言模型的优点带到推荐系统中，从而缓解了冷启动问题。我们进一步的分析表明，TASTE 通过减少以前基于项目 ID 的推荐模型的流行偏差和返回更合适的和文本相关的项目来满足用户，从而显著提高了推荐的准确性。所有密码都在 https://github.com/openmatch/taste。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text+Matching+Improves+Sequential+Recommendation+by+Reducing+Popularity+Biases)|0|
|[Cracking the Code of Negative Transfer: A Cooperative Game Theoretic Approach for Cross-Domain Sequential Recommendation](https://doi.org/10.1145/3583780.3614828)|Chung Park, Taesan Kim, Taekyoon Choi, Junui Hong, Yelim Yu, Mincheol Cho, Kyunam Lee, Sungil Ryu, Hyungjun Yoon, Minsung Choi, Jaegul Choo|SK Telelcom & Korea Advanced Institute of Science and Technology, Seoul & Daejeon, Republic of Korea; NAVER, Seongnam, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; SK Telecom & Korea Advanced Institute of Science and Technology, Seoul & Daejeon, Republic of Korea; SK Telelcom, Seoul, Republic of Korea|This paper investigates Cross-Domain Sequential Recommendation (CDSR), a promising method that uses information from multiple domains (more than three) to generate accurate and diverse recommendations, and takes into account the sequential nature of user interactions. The effectiveness of these systems often depends on the complex interplay among the multiple domains. In this dynamic landscape, the problem of negative transfer arises, where heterogeneous knowledge between dissimilar domains leads to performance degradation due to differences in user preferences across these domains. As a remedy, we propose a new CDSR framework that addresses the problem of negative transfer by assessing the extent of negative transfer from one domain to another and adaptively assigning low weight values to the corresponding prediction losses. To this end, the amount of negative transfer is estimated by measuring the marginal contribution of each domain to model performance based on a cooperative game theory. In addition, a hierarchical contrastive learning approach that incorporates information from the sequence of coarse-level categories into that of fine-level categories (e.g., item level) when implementing contrastive learning was developed to mitigate negative transfer. Despite the potentially low relevance between domains at the fine-level, there may be higher relevance at the category level due to its generalised and broader preferences. We show that our model is superior to prior works in terms of model performance on two real-world datasets across ten different domains.|本文研究了跨域序列推荐(CDSR) ，这是一种利用多个域(超过三个)的信息来生成准确和多样化推荐的有前途的方法，并考虑了用户交互的序列特性。这些系统的有效性往往取决于多个领域之间复杂的相互作用。在这种动态环境中，出现了负迁移问题，即不同领域之间的异质知识由于这些领域的用户偏好不同而导致性能下降。作为补救措施，我们提出了一个新的 CDSR 框架，通过评估从一个领域到另一个领域的负转移程度，并自适应地为相应的预测损失赋予低权值来解决负转移问题。为此，负向转移的数量是通过衡量每个领域对基于合作博弈理论的绩效模型的边际贡献来估计的。此外，在实施对比学习的过程中，还开发了一种分层对比学习方法，将粗级别类别的信息整合到细级别类别的信息中(例如，项目级别) ，以减轻负迁移。尽管在精细层面上各领域之间的相关性可能较低，但在类别层面上可能具有更高的相关性，因为它具有普遍性和更广泛的偏好。我们表明，我们的模型是优于以往的工作方面的两个真实世界的数据集在十个不同的领域的模型性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cracking+the+Code+of+Negative+Transfer:+A+Cooperative+Game+Theoretic+Approach+for+Cross-Domain+Sequential+Recommendation)|0|
|[Personalized Interest Sustainability Modeling for Sequential POI Recommendation](https://doi.org/10.1145/3583780.3615278)|Zewen Long, Liang Wang, Qiang Liu, Shu Wu|CRIPAC, MAIS, Institute of Automation, Chinese Academy of Sciences & University of Chinese Academy of Science, Beijing, China|Sequential point-of-interest (POI) recommendation endeavors to capture users' dynamic interests based on their historical check-ins, subsequently predicting the next POIs that they are most likely to visit.Existing methods conventionally capture users' personalized dynamic interests from their chronological sequences of visited POIs. However, these methods fail to explicitly consider personalized interest sustainability, which means whether each user's interest in specific POIs will sustain beyond the training time. In this work, we propose a personalized INterest Sustainability modeling framework for sequential POI REcommendation, INSPIRE for brevity. Different from existing methods that directly recommend next POIs through users' historical trajectories, our proposed INSPIRE focuses on users' personalized interest sustainability. Specifically, we first develop a new task to predict whether each user will visit the POIs in the recent period of the training time. Afterwards, to remedy the sparsity issue of users' check-in history, we propose to augment users' check-in history in three ways: geographical, intrinsic, and extrinsic schemes. Extensive experiments are conducted on two real-world datasets and results show that INSPIRE outperforms existing next POI solutions.|连续感兴趣点(POI)推荐努力根据用户的历史签入来捕获用户的动态兴趣，随后预测他们最有可能访问的下一个 POI。现有的方法通常从用户访问的 POI 的时间序列中获取用户的个性化动态兴趣。然而，这些方法没有明确考虑个性化兴趣的可持续性，这意味着每个用户对特定 POI 的兴趣是否会持续到培训时间之后。在这项工作中，我们提出了一个个性化的兴趣可持续性建模框架的顺序 POI 推荐，简短的 INSPIRE。与现有的通过用户历史轨迹直接推荐下一个 POI 的方法不同，我们提出的 INSPIRE 侧重于用户个性化兴趣的可持续性。具体来说，我们首先开发一个新的任务来预测每个用户是否会在最近的培训时间内访问 POI。然后，针对用户签入历史的稀疏性问题，提出了从地理方案、内部方案和外部方案三个方面增加用户签入历史的方法。在两个实际数据集上进行了广泛的实验，结果表明 INSPIRE 的性能优于现有的下一个 POI 解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Interest+Sustainability+Modeling+for+Sequential+POI+Recommendation)|0|
|[Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification](https://doi.org/10.1145/3583780.3615210)|Chenyu Zhao, Yunjiang Jiang, Yiming Qiu, Han Zhang, WenYun Yang|JD.com, Beijing, China|Retrieval augmentation, which enhances downstream models by a knowledge retriever and an external corpus instead of by merely increasing the number of model parameters, has been successfully applied to many natural language processing (NLP) tasks such as text classification, question answering and so on. However, existing methods that separately or asynchronously train the retriever and downstream model mainly due to the non-differentiability between the two parts, usually lead to degraded performance compared to end-to-end joint training.|检索增强技术通过知识检索器和外部语料库对下游模型进行增强，而不仅仅是增加模型参数，已经成功地应用于文本分类、问答等自然语言处理任务中。然而，现有的分别或异步训练检索器和下游模型的方法，主要是由于两部分之间的不可微性，通常导致性能下降相比，端到端联合训练。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Differentiable+Retrieval+Augmentation+via+Generative+Language+Modeling+for+E-commerce+Query+Intent+Classification)|0|
|[Enhancing E-commerce Product Search through Reinforcement Learning-Powered Query Reformulation](https://doi.org/10.1145/3583780.3615474)|Sanjay Agrawal, Srujana Merugu, Vivek Sembium|Amazon.com Inc., Bengaluru, India|Query reformulation (QR) is a widely used technique in web and product search. In QR, we map a poorly formed or low coverage user query to a few semantically similar queries that are rich in product coverage, thereby enabling effective targeted searches with less cognitive load on the user. Recent QR approaches based on generative language models are superior to informational retrieval-based methods but exhibit key limitations: (i) generated reformulations often have low lexical diversity and fail to retrieve a large set of relevant products of a wider variety, (ii) the training objective of generative models does not incorporate a our goal of improving product coverage. In this paper, we propose RLQR (Reinforcement Learning for Query Reformulations), for generating high quality diverse reformulations which aim to maximize the product coverage (number of distinct relevant products returned). We evaluate our approach against supervised generative models and strong RL-based methods. Our experiments demonstrate a 28.6% increase in product coverage compared to a standard generative model, outperforming SOTA benchmarks by a significant margin. We also conduct our experiments on an external Amazon shopping dataset and demonstrate increased product coverage over SOTA algorithms.|查询重构(QR)是一种广泛应用于网络和产品搜索的技术。在 QR 中，我们将一个形式不正确或覆盖率低的用户查询映射到几个语义相似的查询，这些查询具有丰富的产品覆盖率，从而使得有效的目标搜索能够减轻用户的认知负荷。最近基于生成语言模型的 QR 方法优于基于信息检索的方法，但表现出关键的局限性: (i)生成的重新编排通常具有较低的词汇多样性，并且不能检索更多种类的大量相关产品，(ii)生成模型的培训目标不包含我们提高产品覆盖率的目标。在本文中，我们提出了 RLQR (查询重构的强化学习) ，用于产生高质量的多样化重构，目的是最大化产品覆盖率(返回的不同相关产品的数量)。我们评估我们的方法对监督生成模型和强 RL 为基础的方法。我们的实验表明，与标准生成模型相比，产品覆盖率提高了28.6% ，远远超过 SOTA 基准。我们还在一个外部 Amazon 购物数据集上进行了实验，并证明了 SOTA 算法对产品覆盖率的提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+E-commerce+Product+Search+through+Reinforcement+Learning-Powered+Query+Reformulation)|0|
|[Multitask Ranking System for Immersive Feed and No More Clicks: A Case Study of Short-Form Video Recommendation](https://doi.org/10.1145/3583780.3615489)|Qingyun Liu, Zhe Zhao, Liang Liu, Zhen Zhang, Junjie Shan, Yuening Li, Shuchao Bi, Lichan Hong, Ed H. Chi|Google Inc, Mountain View, CA, USA; Google DeepMind, Mountain View, CA, USA|In recent years, social media users spend significant amount of time on Short-Form Video (SFV) platforms. Its success in creating an immersive viewership experience is not only from the content, but also due to its unique UI innovation: instead of providing choices for users to click, SFV platforms actively recommend content to users to watch one at a time. In this paper, we highlight unique challenges rooted from such UI changes for SFV recommendation system design. Firstly, there is yet much unexplored for sources of system biases under the new UI, as there are no clicks nor the common click-based position biases. Additionally, when training multiple types of user activities, positive labels for activities like sharing and commenting can be much sparser and more skewed than traditional click-based recommendation systems, as the latter can filter non-click impressions when generating "post-click" activities. To tackle these challenges, we introduce a unified multi-task ranking framework which puts two novel components all together into an overall system for SFV recommendation. First, we identify that there are position biases of SFVs in the recommendation sequence, namely "watch trail biases", and introduce biases correction using trail-related information. Second, to get the most benefits from multi-task learning, especially co-training tasks with extremely skewed and sparse labels, we adapt a disentangle regularization to mitigate task conflicts, introduce loss upweighting for sparse task co-training and adopt a meta-learning algorithm for efficient weight selection. We demonstrate the effectiveness and efficiency of the framework on one of today's largest SFV platforms. Our framework has been deployed to the production system for more than 6 months.|近年来，社交媒体用户在短视频(SFV)平台上花费了大量的时间。SFV 成功地创造了一种身临其境的观看体验，不仅仅是因为内容，还因为它独特的用户界面创新: SFV 平台没有为用户提供点击选择，而是积极地向用户推荐内容，让他们一次看一个。在本文中，我们强调了这种 UI 变化对 SFV 推荐系统设计的独特挑战。首先，由于没有点击，也没有常见的基于点击的位置偏差，因此在新 UI 下还有很多系统偏差的来源没有被探索。此外，在培训多种类型的用户活动时，分享和评论等活动的正面标签可能比传统的基于点击的推荐系统更稀疏和更倾斜，因为后者可以在生成“后点击”活动时过滤非点击印象。为了应对这些挑战，我们引入了一个统一的多任务排序框架，它将两个新的组件放在一起，形成一个全面的 SFV 推荐系统。首先，我们发现在推荐序列中存在着 SFV 的位置偏差，即“观察轨迹偏差”，并利用轨迹相关信息进行偏差校正。其次，为了从多任务协同学习中获得最大的效益，特别是极度倾斜和稀疏标签的协同训练任务，我们采用了一种解缠正则化来缓解任务冲突，引入了稀疏任务协同训练的损失加权，并采用了一种元学习算法来进行有效的权重选择。我们在当今最大的 SFV 平台之一上展示了该框架的有效性和效率。我们的框架已经部署到生产系统超过6个月了。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multitask+Ranking+System+for+Immersive+Feed+and+No+More+Clicks:+A+Case+Study+of+Short-Form+Video+Recommendation)|0|
|[RUEL: Retrieval-Augmented User Representation with Edge Browser Logs for Sequential Recommendation](https://doi.org/10.1145/3583780.3615498)|Ning Wu, Ming Gong, Linjun Shou, Jian Pei, Daxin Jiang|Duke University, Durham, NC, USA; Microsoft STCA, Beijing, China|Online recommender systems (RS) aim to match user needs with the vast amount of resources available on various platforms. A key challenge is to model user preferences accurately under the condition of data sparsity. To address this challenge, some methods have leveraged external user behavior data from multiple platforms to enrich user representation. However, all of these methods require a consistent user ID across platforms and ignore the information from similar users. In this study, we propose RUEL, a novel retrieval-based sequential recommender that can effectively incorporate external anonymous user behavior data from Edge browser logs to enhance recommendation. We first collect and preprocess a large volume of Edge browser logs over a one-year period and link them to target entities that correspond to candidate items in recommendation datasets. We then design a contrastive learning framework with a momentum encoder and a memory bank to retrieve the most relevant and diverse browsing sequences from the full browsing log based on the semantic similarity between user representations. After retrieval, we apply an item-level attentive selector to filter out noisy items and generate refined sequence embeddings for the final predictor. RUEL is the first method that connects user browsing data with typical recommendation datasets and can be generalized to various recommendation scenarios and datasets. We conduct extensive experiments on four real datasets for sequential recommendation tasks and demonstrate that RUEL significantly outperforms state-of-the-art baselines. We also conduct ablation studies and qualitative analysis to validate the effectiveness of each component of RUEL and provide additional insights into our method.|在线推荐系统(RS)旨在将用户的需求与各种平台上可用的大量资源相匹配。在数据稀疏的情况下，准确地建立用户偏好模型是一个关键的挑战。为了解决这个问题，一些方法利用来自多个平台的外部用户行为数据来丰富用户表示。但是，所有这些方法都需要跨平台的一致用户 ID，并忽略来自相似用户的信息。在这项研究中，我们提出了一种新的基于检索的顺序推荐系统 RUEL，它可以有效地合并来自边缘浏览器日志的外部匿名用户行为数据来增强推荐系统。我们首先在一年的时间内收集和预处理大量的 Edge 浏览器日志，并将它们链接到与推荐数据集中的候选项对应的目标实体。然后基于用户表示的语义相似性，设计了一个带有动量编码器和记忆库的对比学习框架，从完整的浏览日志中检索出最相关、最多样的浏览序列。检索后，应用项级注意选择器滤除噪声项，并为最终的预测器生成精化序列嵌入。RUEL 是第一种将用户浏览数据与典型的推荐数据集连接起来的方法，可以推广到各种推荐场景和数据集。我们在四个实际数据集上对顺序推荐任务进行了广泛的实验，并证明 RUEL 显著优于最先进的基线。我们还进行了消融研究和定性分析，以验证 RUEL 的每个组成部分的有效性，并提供额外的见解，我们的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RUEL:+Retrieval-Augmented+User+Representation+with+Edge+Browser+Logs+for+Sequential+Recommendation)|0|
|[Towards Effective Modeling and Exploitation of Search and User Context in Conversational Information Retrieval](https://doi.org/10.1145/3583780.3616005)|Praveen Acharya|Dublin City University, Dublin, Ireland|Conversational information retrieval has garnered considerable attention in recent years. A major challenge in conversational search is formulating the most effective query during the dialogue between the searcher and the conversational agent. Unlike traditional information retrieval systems that assume users can independently create queries, conversational settings allow agents to assist users in query formulation. This alleviates the burden on users by leveraging the multi-turn nature of the conversation to aid them in reaching their information goals. Conversational context plays a vital role in the query process. In this work, we focus on understanding and leveraging conversational context from two dimensions: conversational history and knowledge history. The goal is to identify and model the relevant portions from the search dialogue and the knowledge history and to use this within the search process to improve the overall performance of conversational information retrieval systems.|近年来，会话信息检索引起了相当大的关注。会话搜索的一个主要挑战是在搜索者和会话代理人之间的对话中提出最有效的查询。与传统的信息检索系统假设用户可以独立创建查询不同，会话设置允许代理协助用户制定查询。这样可以减轻用户的负担，因为可以利用对话的多回合特性来帮助他们实现信息目标。会话上下文在查询过程中起着至关重要的作用。在这项工作中，我们侧重于从两个维度理解和利用会话语境: 会话历史和知识历史。我们的目标是从搜索对话和知识历史中识别和建模相关部分，并在搜索过程中使用这些来提高会话信息检索系统的整体性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Effective+Modeling+and+Exploitation+of+Search+and+User+Context+in+Conversational+Information+Retrieval)|0|
|[CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning](https://doi.org/10.1145/3583780.3615512)|Qingtian Bian, Jiaxing Xu, Hui Fang, Yiping Ke|Nanyang Technological University, Singapore, Singapore; Shanghai University of Finance and Economics, Shanghai, China|The motivations of users to make interactions can be divided into static preference and dynamic interest. To accurately model user representations over time, recent studies in sequential recommendation utilize information propagation and evolution to mine from batches of arriving interactions. However, they ignore the fact that people are easily influenced by the recent actions of other users in the contextual scenario, and applying evolution across all historical interactions dilutes the importance of recent ones, thus failing to model the evolution of dynamic interest accurately. To address this issue, we propose a Context-Aware Pseudo-Multi-Task Recommender System (CPMR) to model the evolution in both historical and contextual scenarios by creating three representations for each user and item under different dynamics: static embedding, historical temporal states, and contextual temporal states. To dually improve the performance of temporal states evolution and incremental recommendation, we design a Pseudo-Multi-Task Learning (PMTL) paradigm by stacking the incremental single-target recommendations into one multi-target task for joint optimization. Within the PMTL paradigm, CPMR employs a shared-bottom network to conduct the evolution of temporal states across historical and contextual scenarios, as well as the fusion of them at the user-item level. In addition, CPMR incorporates one real tower for incremental predictions, and two pseudo towers dedicated to updating the respective temporal states based on new batches of interactions. Experimental results on four benchmark recommendation datasets show that CPMR consistently outperforms state-of-the-art baselines and achieves significant gains on three of them. The code is available at: https://github.com/DiMarzioBian/CPMR.|用户进行交互的动机可以分为静态偏好和动态兴趣。为了随时间精确地建立用户表示模型，最近在顺序推荐方面的研究利用信息传播和进化从到达的交互批次中挖掘信息。然而，他们忽略了这样一个事实，即人们很容易受到其他用户最近在上下文场景中的行为的影响，并且在所有的历史交互中应用进化会削弱最近交互的重要性，从而无法精确地模拟动态兴趣的进化。为了解决这个问题，我们提出了一个上下文感知的伪多任务推荐系统(Context-Aware Pseudo-multi-Task) ，通过在不同的动态下为每个用户和项目创建三种表示(静态嵌入、历史时间状态和上下文时间状态)来模拟历史和上下文场景中的演化。为了同时提高时间状态演化和增量推荐的性能，我们设计了一个伪多任务学习(PMTL)范式，将增量的单目标推荐叠加到一个多目标任务中进行联合优化。在 PMTL 范式中，CPMR 使用一个共享底层网络来跨越历史和上下文场景进行时间状态的演化，以及在用户项目级别进行时间状态的融合。此外，CPMR 还包括一个用于增量预测的实际塔，以及两个用于根据新批量的相互作用更新各自的时间状态的伪塔。对四个基准推荐数据集的实验结果表明，CPMR 的性能始终优于最先进的基准，并在其中三个基准上取得了显著的增益。密码可于以下 https://github.com/dimarziobian/cpmr 索取:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CPMR:+Context-Aware+Incremental+Sequential+Recommendation+with+Pseudo-Multi-Task+Learning)|0|
|[Leveraging Post-Click User Behaviors for Calibrated Conversion Rate Prediction Under Delayed Feedback in Online Advertising](https://doi.org/10.1145/3583780.3615161)|Yuyao Guo, Xiang Ao, Qiming Liu, Qing He|Institute of Computing Technology, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China|Obtaining accurately calibrated conversion rate predictions is essential for the bidding and ranking process in online advertising systems. Nevertheless, the inherent latency between clicks and conversions leads to delayed feedback, which may introduce bias into the prediction models. Compared to indefinitely long conversion delays, post-click user behaviors manifest within a relatively brief time and have been empirically validated to exert a favorable influence on the precision of conversion rate estimates. In light of this, we propose a novel approach that leverages post-click user behaviors to calibrate conversion rate predictions. Specifically, we treat user behaviors as predictable targets to improve accuracy and enhance timeliness. An adaptive loss function based on task uncertainty is employed for multi-task learning. To further reduce calibration error, we integrate the modified prediction model with a parameterized scaling technique. Experiments conducted on two real-world datasets demonstrate that our proposed method outperforms existing models in providing more calibrated predictions.|获得准确校准的转换率预测是必不可少的投标和排名过程中的在线广告系统。然而，点击和转换之间的内在延迟会导致延迟反馈，这可能会给预测模型带来偏差。与无限长的转换延迟相比，点击后的用户行为在相对较短的时间内表现出来，并且已经被经验验证对转换率估计的精度产生了有利的影响。鉴于此，我们提出了一种新的方法，利用点击后的用户行为来校准转换率预测。具体来说，我们将用户行为视为可预测的目标，以提高准确性和及时性。采用基于任务不确定性的自适应损失函数进行多任务学习。为了进一步减小校准误差，我们将改进的预测模型与参数化标度技术相结合。在两个真实世界数据集上进行的实验表明，我们提出的方法在提供更精确的预测方面优于现有的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Post-Click+User+Behaviors+for+Calibrated+Conversion+Rate+Prediction+Under+Delayed+Feedback+in+Online+Advertising)|0|
|[DAE: Distribution-Aware Embedding for Numerical Features in Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615212)|Bin Shen, Jingran Xu, Xu Min, Zeyu Ke, Yong He, Liang Zhang, Xin Dong, Linjian Mo|Ant Group, Hangzhou, China; Antgroup, Hangzhou, China|Numerical features are an important type of input for CTR prediction models. Recently, several discretization and numerical transformation methods have been proposed to deal with numerical features. However, existing approaches do not fully consider compatibility with different distributions. Here, we propose a novel numerical feature embedding framework, called Distribution-Aware Embedding (DAE), which is applicable to various numerical feature distributions. First, DAE efficiently approximates the cumulative distribution function by estimating the expectation of the order statistics. Then, the distribution information is applied to the embedding layer by nonlinear interpolation. Finally, to capture both local and global information, we aggregate the embeddings at multiple scales to obtain the final representation. Empirical results validate the effectiveness of DAE compared to the baselines, while demonstrating the adaptability to different CTR models and distributions.|数值特征是 CTR 预测模型的重要输入类型。近年来，人们提出了几种离散化和数值变换方法来处理数值特征。但是，现有的方法并不完全考虑与不同发行版的兼容性。在这里，我们提出了一种新的数值特征嵌入框架，称为分布感知嵌入(DAE) ，它适用于各种数值特征分布。首先，DAE 通过估计订单统计数据的期望值来有效地逼近累积分布函数。然后，通过非线性插值将分布信息应用到嵌入层。最后，为了同时捕获局部和全局信息，我们在多个尺度上聚合嵌入信息以获得最终的表示。实证结果验证了 DAE 与基线相比的有效性，同时证明了 DAE 对不同 CTR 模型和分布的适应性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAE:+Distribution-Aware+Embedding+for+Numerical+Features+in+Click-Through+Rate+Prediction)|0|
|[Unified Generative & Dense Retrieval for Query Rewriting in Sponsored Search](https://doi.org/10.1145/3583780.3615459)|Akash Kumar Mohankumar, Bhargav Dodla, Gururaj K, Amit Singh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Generative+&+Dense+Retrieval+for+Query+Rewriting+in+Sponsored+Search)|0|
|[SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search](https://doi.org/10.1145/3583780.3615500)|Wen Zan, Yaopeng Han, Xiaotian Jiang, Yao Xiao, Yang Yang, Dayao Chen, Sheng Chen|Meituan Inc., Beijing, China|In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching.   To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structured documents. At pretraining stage, we propose an effective pretraining method that employs both query and multiple fields of document as inputs, including an effective information compression method for lengthy fields. At relevance matching stage, a novel matching method is proposed by leveraging domain knowledge in search query to generate more effective document representations for relevance scoring. Extensive offline experiments and online A/B tests on millions of users verify that the proposed architectures effectively improve the performance of relevance modeling. The model has already been deployed online, serving the search traffic of Meituan for over a year.|在电子商务搜索中，查询与文档之间的相关性是满足用户体验的基本要求。与提供产品的传统电子商务平台不同，用户在生活服务平台(例如主要为产品供应商提供的美团)上进行搜索，这些平台通常有大量的结构化信息，例如名称、地址、类别、数以千计的产品。用这些丰富的结构化内容来建立搜索相关性具有挑战性，这是由于以下问题: (1)不同领域的结构性文件之间存在语言分布差异，使得很难直接采用现成的基于语言模型的方法，比如 BERT。(2)不同领域的重要性不同，领域长度差异较大，难以提取有助于相关匹配的文档信息。为了解决这些问题，本文提出了一种新的两阶段预训练和匹配体系结构，用于富结构化文档的相关性匹配。在预训练阶段，我们提出了一种有效的预训练方法，该方法同时使用文档的查询和多个字段作为输入，包括一种有效的长字段信息压缩方法。在相关匹配阶段，利用搜索查询中的领域知识，提出了一种新的匹配方法，为相关评分生成更有效的文档表示。大量的离线实验和对数百万用户的在线 A/B 测试验证了所提出的体系结构有效地提高了相关建模的性能。该模型已经在网上部署，为美团的搜索流量服务了一年多。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SPM:+Structured+Pretraining+and+Matching+Architectures+for+Relevance+Modeling+in+Meituan+Search)|0|
|[Towards Filling the Gap in Conversational Search: From Passage Retrieval to Conversational Response Generation](https://doi.org/10.1145/3583780.3615132)|Weronika Lajewska, Krisztian Balog|University of Stavanger, Stavanger, Norway|Research on conversational search has so far mostly focused on query rewriting and multi-stage passage retrieval. However, synthesizing the top retrieved passages into a complete, relevant, and concise response is still an open challenge. Having snippet-level annotations of relevant passages would enable both (1) the training of response generation models that are able to ground answers in actual statements and (2) the automatic evaluation of the generated responses in terms of completeness. In this paper, we address the problem of collecting high-quality snippet-level answer annotations for two of the TREC Conversational Assistance track datasets. To ensure quality, we first perform a preliminary annotation study, employing different task designs, crowdsourcing platforms, and workers with different qualifications. Based on the outcomes of this study, we refine our annotation protocol before proceeding with the full-scale data collection. Overall, we gather annotations for 1.8k question-paragraph pairs, each annotated by three independent crowd workers. The process of collecting data at this magnitude also led to multiple insights about the problem that can inform the design of future response-generation methods. This is an extended version of the article published with the same title in the Proceedings of CIKM'23.|会话搜索的研究目前主要集中在查询重写和多阶段文章检索两个方面。然而，将检索到的顶级段落综合成一个完整的、相关的、简洁的回应仍然是一个公开的挑战。对相关段落进行片段级注释，可以(1)训练能够在实际语句中找到答案的响应生成模型，(2)根据完整性自动评估生成的响应。在本文中，我们解决了为两个 TREC 会话辅助跟踪数据集收集高质量片段级答案注释的问题。为了保证质量，我们首先进行了初步的注释研究，采用了不同的任务设计，众包平台，以及不同资历的工人。基于本研究的结果，我们在进行全面的数据收集之前优化了我们的注释协议。总的来说，我们收集了1.8 k 问题-段落对的注释，每个注释由三个独立的人群工作者。在这种规模上收集数据的过程也导致了对这个问题的多种认识，这些认识可以为设计未来的响应生成方法提供信息。这是一个扩展版本的文章与同一标题发表在 CIKM’23会议记录。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Filling+the+Gap+in+Conversational+Search:+From+Passage+Retrieval+to+Conversational+Response+Generation)|0|
|[IUI: Intent-Enhanced User Interest Modeling for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3614939)|Mao Pan, Tao Yu, Kun Zhou, Zheng Li, Dongyue Wang, Zhuoye Ding, Xiwei Zhao, Sulong Xu|JD.com, Inc., Beijing, China|Click-Through Rate (CTR) prediction is becoming increasingly vital in many industrial applications, such as recommendations and online advertising. How to precisely capture users' dynamic and evolving interests from previous interactions (e.g., clicks, purchases, etc.) is a challenging task in CTR prediction. Mainstream approaches focus on disentangling user interests in a heuristic way or modeling user interests into a static representation. However, these approaches overlook the importance of users' current intent and the complex interactions between their current intent and global interests. To address these concerns, in this paper, we propose a novel intent-enhanced user interest modeling for click-through rate prediction in large-scale e-commerce recommendations, abbreviated as IUI. Methodologically, different from existing works, we consider users' recent interactions to be inspired by their implicit intent and then leverage an intent-aware network to model their current local interests in a more precise and fine-grained manner. In addition, to obtain a more stable co-dependent global and local interest representation, we employ a co-attention network capable of activating the corresponding interest in global-level interactions and capturing the dynamic interactions between global- and local-level interaction behaviors. Finally, we incorporate self-supervised learning into the model training by maximizing the mutual information between the global and local representations obtained via the above two networks to enhance the CTR prediction performance. Compared with existing methods, IUI benefits from the different granularity of user interest to generate a more accurate and comprehensive preference representation. Experimental results demonstrate that the proposed model outperforms previous state-of-the-art methods in various metrics on three real-world datasets. In addition, an online A/B test deployed on the JD recommendation platforms shows a promising improvement across multiple evaluation metrics.|在诸如推荐和在线广告等许多工业应用中，点进率预测(ctrl)正变得越来越重要。如何从以前的交互(例如点击、购买等)中准确捕捉用户的动态和不断变化的兴趣是 CTR 预测中的一个具有挑战性的任务。主流方法侧重于以启发式方式分离用户兴趣，或者将用户兴趣建模为静态表示。然而，这些方法忽略了用户当前意图的重要性，以及用户当前意图与全局兴趣之间的复杂交互。为了解决这些问题，在本文中，我们提出了一种新的意图增强的用户兴趣模型，用于大规模电子商务推荐中的点进率预测，简称为 IUI。在方法论上，与现有的作品不同，我们认为用户最近的互动是受到他们的隐含意图的启发，然后利用意图感知网络，以更精确和细粒度的方式建模他们当前的本地兴趣。此外，为了获得更稳定的相互依赖的全局和局部兴趣表示，我们采用了能够激活全局层面相互作用中的相应兴趣并捕获全局和局部层面相互作用行为之间的动态相互作用的共注意网络。最后，将自监督学习算法引入模型训练中，通过最大化两个网络所获得的全局和局部表示之间的互信息来提高 CTR 预测性能。与现有的方法相比，IUI 受益于不同粒度的用户兴趣，以生成更准确和全面的偏好表示。实验结果表明，该模型在三个实际数据集的各种度量指标上优于先前的最新方法。此外，部署在 JD 推荐平台上的在线 A/B 测试显示了跨多个评估指标的有希望的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IUI:+Intent-Enhanced+User+Interest+Modeling+for+Click-Through+Rate+Prediction)|0|
|[TPUF: Enhancing Cross-domain Sequential Recommendation via Transferring Pre-trained User Features](https://doi.org/10.1145/3583780.3615094)|Yujia Ding, Huan Li, Ke Chen, Lidan Shou|Zhejiang University, Hangzhou, China|Sequential recommendation has long been challenged by data sparsity issues. Most recently, cross-domain sequential recommendation (CDSR) techniques have been proposed to leverage sequential interaction data from other domains. However, accessing raw data from source domains is often restricted due to privacy concerns. To tackle this issue, we introduce TPUF, a novel CDSR model that transfers pre-trained latent user features from the source domain (UFS) instead of the original interaction data. By doing so, TPUF improves recommendation effectiveness while maintaining practicality. TPUF has three functional characteristics: (1) It is a feature mapping-and-aggregation framework that does not impose specific constraints on the nature of pre-trained UFS. (2) It incorporates a temporal feature mapping unit to effectively extract domain-shared information from UFS with temporal information recovered. (3) It additionally employs an adversarial feature alignment unit to align features across domains to combat feature transfer bias. Experimental results on real-world datasets demonstrate that TPUF outperforms other state-of-the-art cross-domain recommendation models and is compatible with multiple UFS types.|长期以来，连续推荐一直受到数据稀疏问题的挑战。最近，跨域顺序推荐(CDSR)技术被提出来利用来自其他域的顺序交互数据。然而，从源域访问原始数据通常由于隐私问题而受到限制。为了解决这个问题，我们引入了 TPUF，一种新的 CDSR 模型，它从源域(UFS)传输预先训练好的潜在用户特征，而不是传输原始的交互数据。通过这样做，TPUF 在保持实用性的同时提高了推荐的有效性。TPUF 具有三个功能特征: (1)它是一个特征映射和聚合框架，不对预先训练的 UFS 的性质施加特定的限制。(2)结合时态特征映射单元，有效地提取 UFS 中的域共享信息，并恢复时态信息。(3)采用对抗性特征对齐单元对特征进行跨域对齐，以对抗特征迁移偏差。在实际数据集上的实验结果表明，TPUF 的性能优于其他最先进的跨域推荐模型，并且可以兼容多种 UFS 类型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TPUF:+Enhancing+Cross-domain+Sequential+Recommendation+via+Transferring+Pre-trained+User+Features)|0|
|[Zero-shot Item-based Recommendation via Multi-task Product Knowledge Graph Pre-Training](https://doi.org/10.1145/3583780.3615110)|Ziwei Fan, Zhiwei Liu, Shelby Heinecke, Jianguo Zhang, Huan Wang, Caiming Xiong, Philip S. Yu|University of Illinois Chicago, Chicago, IL, USA; Salesforce AI Research, Palo Alto, CA, USA|Existing recommender systems face difficulties with zero-shot items, i.e. items that have no historical interactions with users during the training stage. Though recent works extract universal item representation via pre-trained language models (PLMs), they ignore the crucial item relationships. This paper presents a novel paradigm for the Zero-Shot Item-based Recommendation (ZSIR) task, which pre-trains a model on product knowledge graph (PKG) to refine the item features from PLMs. We identify three challenges for pre-training PKG, which are multi-type relations in PKG, semantic divergence between item generic information and relations and domain discrepancy from PKG to downstream ZSIR task. We address the challenges by proposing four pre-training tasks and novel task-oriented adaptation (ToA) layers. Moreover, this paper discusses how to fine-tune the model on new recommendation task such that the ToA layers are adapted to ZSIR task. Comprehensive experiments on 18 markets dataset are conducted to verify the effectiveness of the proposed model in both knowledge prediction and ZSIR task.|现有的推荐系统面临着“零拍摄”项目的困难，也就是说，这些项目在培训阶段与用户没有历史性的交互。近年来的研究虽然通过预训练语言模型(PLM)提取通用项表示，但忽视了关键项之间的关系。提出了一种新的基于零拍项目推荐(ZSIR)任务的实现方法，该方法通过对产品知识图(PKG)模型进行预训练来提取 PLM 中的项目特征。我们确定了 PKG 训练前的三个挑战，即 PKG 中的多类型关系、项目类属信息和关系之间的语义分歧以及从 PKG 到下游 ZSIR 任务之间的领域差异。我们通过提出四个训练前任务和新的面向任务的适应(ToA)层来应对这些挑战。此外，本文还讨论了如何对新推荐任务模型进行微调，使 ToA 层适应 ZSIR 任务。通过对18个市场数据集的综合实验，验证了该模型在知识预测和 ZSIR 任务中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Item-based+Recommendation+via+Multi-task+Product+Knowledge+Graph+Pre-Training)|0|
|[A Generalized Propensity Learning Framework for Unbiased Post-Click Conversion Rate Estimation](https://doi.org/10.1145/3583780.3614760)|Yuqing Zhou, Tianshu Feng, Mingrui Liu, Ziwei Zhu|George Mason University, Fairfax, VA, USA|This paper addresses the critical gap in the unbiased estimation of post-click conversion rate (CVR) in recommender systems. Existing CVR prediction methods, such as Inverse Propensity Score (IPS) and various Doubly Robust (DR) based estimators, overlook the impact of propensity estimation on the model bias and variance, thus leading to a debiasing performance gap. We propose a Generalized Propensity Learning (GPL) framework to directly minimize the bias and variance in CVR prediction models. The proposed method works as a complement to existing methods like IPS, DR, MRDR, and DRMSE to improve prediction performance by reducing their bias and variance. Extensive experiments on real-world datasets and semi-synthetic datasets demonstrate the significant performance promotion brought by our proposed method. Data and code can be found at: https://github.com/yuqing-zhou/GPL.|本文研究了推荐系统中点击后转换率(CVR)无偏估计的关键缺陷。现有的 CVR 预测方法，如逆倾向评分(IPS)和各种基于双稳健(DR)的估计方法，忽视了倾向估计对模型偏差和方差的影响，从而导致性能差距的消除。我们提出了一个广义倾向学习(GPL)框架，直接最小化 CVR 预测模型的偏差和方差。该方法对现有的 IPS、 DR、 MRDR 和 DRMSE 等预测方法进行了补充，减少了它们的偏差和方差，提高了预测性能。在实际数据集和半合成数据集上进行的大量实验表明，该方法能够显著提高系统的性能。数据和代码可在以下 https://github.com/yuqing-zhou/gpl 找到:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Generalized+Propensity+Learning+Framework+for+Unbiased+Post-Click+Conversion+Rate+Estimation)|0|
|[Satisfaction-Aware User Interest Network for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615288)|Mao Pan, Wen Shi, Kun Zhou, Zheng Li, Dongyue Wang, Zhuoye Ding, Xiwei Zhao, Sulong Xu|JD.com, Inc., Beijing, China|Click-Through Rate (CTR) prediction plays a pivotal role in numerous industrial applications, including online advertising and recommender systems. Existing approaches primarily focus on modeling the correlation between user interests and candidate items. However, we argue that personalized user preferences for candidate items depend not only on correlation but also on the satisfaction of associated interests. To address this limitation, we propose SUIN, a novel CTR model that integrates satisfaction factors into user interest modeling for enhanced click-through rate prediction. Specifically, we employ a user interest satisfaction-aware network to capture the degree of satisfaction for each interest, thereby enabling adaptation of the user's personalized preference based on satisfaction levels. Additionally, we leverage the exposure-unclicked signal (recommended to the user but not clicked) as supervision during training, facilitating the interest satisfaction module to better model the satisfaction degree of user interests. Besides, this module serves as a foundational building block suitable for integration into mainstream sequential-based CTR models. Extensive experiments conducted on two real-world datasets demonstrate the superiority of our proposed model, outperforming state-of-the-art methods across various evaluation metrics. Furthermore, an online A/B test deployed on large-scale recommender systems shows significant improvements achieved by our model in diverse evaluation metrics.|在许多工业应用中，包括在线广告和推荐系统中，点进率(ctrl)预测起着关键的作用。现有的方法主要集中在建模用户兴趣和候选项之间的关系。然而，我们认为个性化用户对候选项的偏好不仅取决于相关性，而且还取决于相关兴趣的满意度。为了解决这一局限性，我们提出了 SUIN 模型，这是一种新型的点击率模型，它将满意度因素集成到用户兴趣模型中，以增强点进率预测。具体来说，我们使用一个感知用户兴趣满意度的网络来获取每个兴趣的满意度，从而能够根据满意度来适应用户的个性化偏好。此外，我们利用曝光-未点击信号(推荐给用户但未点击)作为培训期间的监督，促进兴趣满意度模块，以更好地模拟用户兴趣的满意度。此外，该模块作为一个基本的积木块，适合集成到主流的顺序为基础的 CTR 模型。在两个真实世界的数据集上进行的大量实验证明了我们提出的模型的优越性，在各种评估指标上优于最先进的方法。此外，部署在大型推荐系统上的在线 A/B 测试显示，我们的模型在不同的评估指标上取得了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Satisfaction-Aware+User+Interest+Network+for+Click-Through+Rate+Prediction)|0|
|[Unsupervised Multi-Modal Representation Learning for High Quality Retrieval of Similar Products at E-commerce Scale](https://doi.org/10.1145/3583780.3615504)|Kushal Kumar, Tarik Arici, Tal Neiman, Jinyu Yang, Shioulin Sam, Yi Xu, Hakan Ferhatosmanoglu, Ismail B. Tutar|Amazon, New York, NY, USA; Amazon, Seattle, WA, USA|Identifying similar products in e-commerce is useful in discovering relationships between products, making recommendations, and increasing diversity in search results. Product representation learning is the first step to define a generalized product similarity metric for search. The second step is to extend similarity search to a large scale (e.g., e-commerce catalog scale) without sacrificing quality. In this work, we present a solution that interweaves both steps, i.e., learn representations suited to high quality retrieval using contrastive learning (CL) and retrieve similar items from a large search space using approximate nearest neighbor search (ANNS) to trade-off quality for speed. We propose a CL training strategy for learning uni-modal encoders suited to multi-modal similarity search for e-commerce. We study ANNS retrieval by generating Pareto Frontiers (PFs) without requiring labels. Our CL training strategy doubles retrieval@1 metric across categories (e.g., from 36% to 88% in category C). We also demonstrate that ANNS engine optimization using PFs help select configurations appropriately (e.g., we achieve 6.8× search speed with just 2% drop from the maximum retrieval accuracy in medium size datasets).|在电子商务中识别类似的产品有助于发现产品之间的关系，提出建议，并增加搜索结果的多样性。产品表示学习是定义用于搜索的广义产品相似度量的第一步。第二步是在不牺牲质量的情况下将最近邻搜索扩展到大规模(例如，电子商务目录规模)。在这项工作中，我们提出了一个解决方案，交织两个步骤，即，学习表示适合高质量的检索使用对比学习(CL)和检索相似的项目从一个大的搜索空间使用近似最近邻搜索(ANNS) ，以权衡质量的速度。我们建议采用 CL 培训策略，学习适用于电子商务多模态最近邻搜索的单模态编码器。我们通过生成不需要标签的帕累托前沿(PF)来研究 ANNS 检索。我们的 CL 训练策略将跨类别的检索@1指标加倍(例如，在 C 类中从36% 增加到88%)。我们还证明了使用 PF 的 ANNS 引擎优化有助于选择适当的配置(例如，我们实现了6.8倍的搜索速度，仅比中等大小数据集的最大检索精度下降2%)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Multi-Modal+Representation+Learning+for+High+Quality+Retrieval+of+Similar+Products+at+E-commerce+Scale)|0|
|[Graph Exploration Matters: Improving both Individual-Level and System-Level Diversity in WeChat Feed Recommendation](https://doi.org/10.1145/3583780.3614688)|Shuai Yang, Lixin Zhang, Feng Xia, Leyu Lin|Tencent Inc., Shenzhen, China; Tencent Inc., Beijing, China|There are roughly three stages in real industrial recommendation systems, candidates generation (retrieval), ranking and reranking. Individual-level diversity and system-level diversity are both important for industrial recommender systems. The former focus on each single user's experience, while the latter focus on the difference among users. Graph-based retrieval strategies are inevitably hijacked by heavy users and popular items, leading to the convergence of candidates for users and the lack of system-level diversity. Meanwhile, in the reranking phase, Determinantal Point Process (DPP) is deployed to increase individual-level diverisity. Heavily relying on the semantic information of items, DPP suffers from clickbait and inaccurate attributes. Besides, most studies only focus on one of the two levels of diversity, and ignore the mutual influence among different stages in real recommender systems. We argue that individual-level diversity and system-level diversity should be viewed as an integrated problem, and we provide an efficient and deployable solution for web-scale recommenders. Generally, we propose to employ the retrieval graph information in diversity-based reranking, by which to weaken the hidden similarity of items exposed to users, and consequently gain more graph explorations to improve the system-level diveristy. Besides, we argue that users' propensity for diversity changes over time in content feed recommendation. Therefore, with the explored graph, we also propose to capture the user's real-time personalized propensity to the diversity. We implement and deploy the combined system in WeChat App's Top Stories used by hundreds of millions of users. Offline simulations and online A/B tests show our solution can effectively improve both user engagement and system revenue.|在实际的行业推荐系统中，大致有三个阶段: 候选人的生成(检索)、排名和重新排名。个体层次的多样性和系统层次的多样性对于工业推荐系统都很重要。前者关注每个用户的体验，而后者关注用户之间的差异。基于图的检索策略不可避免地会受到大量用户和热门项目的劫持，导致用户候选项的收敛和系统级多样性的缺乏。与此同时，在重新排名阶段，行列式点过程(DPP)被用来增加个人层面的多样性。民进党严重依赖项目语义信息，饱受点击率和不准确属性的困扰。此外，大多数研究只关注两个层次中的一个层次的多样性，而忽略了实际推荐系统中不同层次之间的相互影响。我们认为，个人层面的多样性和系统层面的多样性应该被视为一个综合的问题，我们提供了一个有效的和可部署的解决方案，网络规模的推荐。一般来说，我们建议在基于多样性的重新排序中使用检索图信息来削弱暴露给用户的项目的隐藏相似性，从而获得更多的图探索以提高系统级的多样性。此外，我们认为用户的多样性倾向随着时间的推移而变化。因此，通过对图形的研究，我们还提出了捕捉用户对多样性的实时个性化倾向。我们在微信应用程序的热门故事中实现并部署了这个组合系统，被数亿用户使用。离线模拟和在线 A/B 测试表明，我们的解决方案可以有效地提高用户参与度和系统收入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Exploration+Matters:+Improving+both+Individual-Level+and+System-Level+Diversity+in+WeChat+Feed+Recommendation)|0|
|[Build Faster with Less: A Journey to Accelerate Sparse Model Building for Semantic Matching in Product Search](https://doi.org/10.1145/3583780.3614661)|Jiong Zhang, YauShian Wang, WeiCheng Chang, Wei Li, JyunYu Jiang, ChoJui Hsieh, HsiangFu Yu|UCLA, Los Angeles, CA, USA; Amazon, Palo Alto, CA, USA|The semantic matching problem in product search seeks to retrieve all semantically relevant products given a user query. Recent studies have shown that extreme multi-label classification~(XMC) model enjoys both low inference latency and high recall in real-world scenarios. These XMC semantic matching models adopt TF-IDF vectorizers to extract query text features and use mainly sparse matrices for the model weights. However, limited availability of libraries for efficient parallel sparse modules may lead to tediously long model building time when the problem scales to hundreds of millions of labels. This incurs significant hardware cost and renders the semantic model stale even before it is deployed. In this paper, we investigate and accelerate the model building procedures in a tree-based XMC model. On a real-world semantic matching task with 100M labels, our enhancements achieve over 10 times acceleration (from 3.1 days to 6.7 hours) while reducing hardware cost by 25%.|产品搜索中的语义匹配问题寻求检索给定用户查询的所有语义相关的产品。最近的研究表明，极端多标签分类 ~ (XMC)模型在现实场景中具有较低的推理延迟和较高的召回率。这些 XMC 语义匹配模型采用 TF-IDF 向量提取查询文本特征，模型权重以稀疏矩阵为主。然而，对于高效的并行稀疏模块来说，库的有限可用性可能导致当问题扩展到数亿个标签时，冗长的模型构建时间。这会带来巨大的硬件成本，甚至在部署语义模型之前，它就已经过时了。在本文中，我们研究并加速了一个基于树的 XMC 模型中的模型建立过程。在一个现实世界的语义匹配任务与100M 标签，我们的增强实现了10倍以上的加速(从3.1天到6.7小时) ，同时减少了25% 的硬件成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Build+Faster+with+Less:+A+Journey+to+Accelerate+Sparse+Model+Building+for+Semantic+Matching+in+Product+Search)|0|
|[Dual Interests-Aligned Graph Auto-Encoders for Cross-domain Recommendation in WeChat](https://doi.org/10.1145/3583780.3614676)|Jiawei Zheng, Hao Gu, Chonggang Song, Dandan Lin, Lingling Yi, Chuan Chen|WeChat, Tencent, Shenzhen, China|Recently, cross-domain recommendation (CDR) has been widely studied in both research and industry since it can alleviate a long-standing challenge of traditional recommendation methods, i.e., data sparsity issue, by transferring the information from a relatively richer domain (termed source domain) to a sparser domain (termed target domain). To our best knowledge, most (if not all) existing CDR methods focus on transferring either the similar content information or the user preferences embedding from the source domain to the target domain. However, they fail to improve the recommendation performance in real-world recommendation scenarios where the items in the source domain are totally different from those in the target domain in terms of attributes. To solve the above issues, we analyzed the historical interactions of users from different domains in the WeChat platform, and found that if two users have similar interests (interactions) in one domain, they are very likely to have similar interests in another domain even though the items of these two domains are totally different in terms of attributes. Based on this observation, in this paper, we propose a novel model named Dual Interests-Aligned Graph Auto-Encoders (DIAGAE) by utilizing the inter-domain interest alignment of users. Besides, our proposed model DIAGAE also leverages graph decoding objectives to align intra-domain user interests, which makes the representation of two users who have similar interests in a single domain closer. Comprehensive experimental results demonstrate that our model DIAGAE outperforms state-of-the-art methods on both public benchmark datasets and online A/B tests in WeChat live-stream recommendation scenario. Our model DIAGAE now serves the major online traffic in WeChat live-streaming recommendation scenario.|近年来，跨域推荐技术(CDR)在研究和工业界得到了广泛的研究，因为它可以通过将信息从相对丰富的域(称为源域)转移到较稀疏的域(称为目标域)来缓解传统推荐方法长期以来面临的挑战，即数据稀疏问题。据我们所知，大多数(如果不是全部的话)现有的 CDR 方法集中于将相似的内容信息或用户首选项从源域嵌入到目标域。但是，在源域中的条目在属性方面与目标域中的条目完全不同的现实推荐场景中，它们无法提高推荐性能。为了解决上述问题，我们分析了微信平台中不同领域用户的历史互动，发现如果两个用户在一个领域有相似的兴趣(互动) ，他们很可能在另一个领域有相似的兴趣，即使这两个领域的项目在属性方面完全不同。在此基础上，本文提出了一种利用用户域间兴趣对齐的双兴趣对齐图自动编码器(DIAGAE)模型。此外，我们提出的模型 DIAGAE 还利用图解码目标来调整域内用户的兴趣，使两个用户在一个单一的领域有相似的兴趣更接近的表示。综合实验结果表明，在微信实时流推荐场景中，我们的模型 DIAGAE 在公共基准数据集和在线 A/B 测试方面都优于最先进的方法。我们的模型 DIAGAE 现在服务于微信直播推荐场景中的主要在线流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Interests-Aligned+Graph+Auto-Encoders+for+Cross-domain+Recommendation+in+WeChat)|0|
|[Self-supervised Contrastive Enhancement with Symmetric Few-shot Learning Towers for Cold-start News Recommendation](https://doi.org/10.1145/3583780.3615053)|Hao Jiang, Chuanzhen Li, Juanjuan Cai, Runyu Tian, Jingling Wang|Communication University of China, Beijing, China|Nowadays, news spreads faster than it is consumed. This, alongside the rapid news cycle and delayed updates, has led to a challenging news cold-start issue. Likewise, the user cold-start problem, due to limited user engagement, has long hindered recommendations. To tackle both of them, we introduce the Symmetric Few-shot Learning framework for Cold-start News Recommendation (SFCNR), built upon self-supervised contrastive enhancement. Our approach employs symmetric few-shot learning towers (SFTs) to transform warm user/news attributes into their behavior/content features during training. We design two innovative feature alignment strategies to enhance towers training. Subsequently, this tower generates virtual features for cold users/news during inference, leveraging tower-stored prior knowledge through a personalized gating network. We assess the SFCNR on four quality news recommendation models, conducting comprehensive experiments on two kinds of News dataset. Results showcase significant performance boosts for both warm and cold-start scenarios compared to baseline models.|如今，新闻的传播速度快于消费速度。这与快速的新闻周期和延迟更新一起，导致了一个具有挑战性的新闻冷启动问题。同样，由于用户参与有限，用户冷启动问题长期以来阻碍了推荐。为了解决这两个问题，我们引入了基于自监督对比增强的冷启动新闻推荐对称少镜头学习框架(SFCNR)。我们的方法使用对称的少镜头学习塔(SFT)来转换温暖的用户/新闻属性到他们的行为/内容特征在训练期间。我们设计了两个创新的特征对齐策略来加强塔训练。随后，该塔在推理过程中为冷用户/新闻生成虚拟特征，通过个性化门控网络利用塔存储的先验知识。我们在四种优质新闻推荐模型上对 SFCNR 进行了评估，并对两种新闻数据集进行了综合实验。结果显示，与基线模型相比，暖启动和冷启动方案的性能都有显著提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+Contrastive+Enhancement+with+Symmetric+Few-shot+Learning+Towers+for+Cold-start+News+Recommendation)|0|
|[Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation](https://doi.org/10.1145/3583780.3614801)|Jiazheng Jing, Yinan Zhang, Xin Zhou, Zhiqi Shen|Nanyang Technological University, Singapore, Singapore|Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.|推荐系统近年来得到了越来越多的研究关注。现有的大多数推荐方法都是通过历史的用户-项目交互来获取用户的个性化偏好，这可能会侵犯用户的隐私。此外，这些方法往往忽略了项目流行度的时间波动的重要性，可以影响用户的决策。为了弥补这一差距，我们提出了流行感知推荐(PARE) ，它通过预测将获得最高流行度的项目来提供非个性化的推荐。PARE 由四个模块组成，每个模块关注一个不同的方面: 流行历史、时间影响、周期性影响和侧面信息。最后，利用注意层融合四个模块的输出。据我们所知，这是第一个在推荐系统中对项目流行性进行明确建模的工作。大量的实验表明，价格调整汇率的表现与最先进的复杂推荐方法相当，甚至更好。由于 PARE 优先考虑项目流行度而不是个性化的用户偏好，它可以增强现有的推荐方法作为一个补充组件。我们的实验表明，将价格调整汇率与现有的推荐方法相结合，显著地超过了独立模型的性能，突出了价格调整汇率作为现有推荐方法的补充的潜力。此外，价格调整汇率的简单性使其对工业应用非常实用，并为未来的研究提供了宝贵的基准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Capturing+Popularity+Trends:+A+Simplistic+Non-Personalized+Approach+for+Enhanced+Item+Recommendation)|0|
|[Multi-domain Recommendation with Embedding Disentangling and Domain Alignment](https://doi.org/10.1145/3583780.3614977)|Wentao Ning, Xiao Yan, Weiwen Liu, Reynold Cheng, Rui Zhang, Bo Tang|Huawei Noah's Ark Lab, Shenzhen, China; The University of Hong Kong, Hong Kong, Hong Kong; Southern University of Science and Technology, Shenzhen, China; ruizhang.info, Beijing, China|Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverages random walks from graph processing to identify similar user/item pairs from different domains and encourages similar user/item pairs to have similar embeddings, enhancing knowledge transfer. We compare EDDA with 12 state-of-the-art baselines on 3 real datasets. The results show that EDDA consistently outperforms the baselines on all datasets and domains. All datasets and codes are available at https://github.com/Stevenn9981/EDDA.|多域名推荐(MDR)的目的是为不同领域(例如，产品类型)的重叠用户/项目提供推荐，这种推荐在亚马逊、 Facebook 和 LinkedIn 等提供多种服务的平台上很常见。现有的 MDR 模型面临两个挑战: 首先，很难区分跨领域概括的知识(例如，用户喜欢廉价商品)和特定于单个领域的知识(例如，用户喜欢蓝色衣服但不喜欢蓝色汽车)。其次，他们跨领域传递知识的能力有限，重叠的领域很小。我们提出了一种新的 MDR 方法 EDDA，该方法由两个关键部分组成，即嵌入分离推荐和域对齐，分别解决了这两个难题。特别是嵌入式解缠推荐器将域间部分和域内部分的模型和嵌入分离开来，而现有的 MDR 方法大多只关注模型级的解缠。领域对齐利用图形处理中的随机游走来识别来自不同领域的相似用户/项目对，并鼓励相似的用户/项目对具有相似的嵌入，增强知识转移。我们比较了3个实际数据集上的 EDDA 和12个最先进的基线。结果表明，EDDA 在所有数据集和域上的性能均优于基线。所有数据集和代码都可以在 https://github.com/stevenn9981/edda 获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-domain+Recommendation+with+Embedding+Disentangling+and+Domain+Alignment)|0|
|[Dimension Independent Mixup for Hard Negative Sample in Collaborative Filtering](https://doi.org/10.1145/3583780.3614845)|Xi Wu, Liangwei Yang, Jibing Gong, Chao Zhou, Tianyu Lin, Xiaolong Liu, Philip S. Yu|University of Illinois Chicago, Chicago, IL, USA; YanShan University, Qinhuangdao, China|Collaborative filtering (CF) is a widely employed technique that predicts user preferences based on past interactions. Negative sampling plays a vital role in training CF-based models with implicit feedback. In this paper, we propose a novel perspective based on the sampling area to revisit existing sampling methods. We point out that current sampling methods mainly focus on Point-wise or Line-wise sampling, lacking flexibility and leaving a significant portion of the hard sampling area un-explored. To address this limitation, we propose Dimension Independent Mixup for Hard Negative Sampling (DINS), which is the first Area-wise sampling method for training CF-based models. DINS comprises three modules: Hard Boundary Definition, Dimension Independent Mixup, and Multi-hop Pooling. Experiments with real-world datasets on both matrix factorization and graph-based models demonstrate that DINS outperforms other negative sampling methods, establishing its effectiveness and superiority. Our work contributes a new perspective, introduces Area-wise sampling, and presents DINS as a novel approach that achieves state-of-the-art performance for negative sampling. Our implementations are available in PyTorch.|协同过滤(CF)是一种广泛应用的技术，它基于过去的交互预测用户偏好。负抽样在基于 CF 的隐式反馈模型的训练中起着至关重要的作用。在本文中，我们提出了一个新的视角基于抽样面积重新审视现有的抽样方法。我们指出，目前的抽样方法主要集中在点或线抽样，缺乏灵活性，并留下了很大一部分硬抽样区域未被探索。针对这一局限性，我们提出了硬负采样的尺寸无关混合(DINS)方法，这是第一种用于训练基于 CF 模型的区域采样方法。DINS 由三个模块组成: 硬边界定义模块、尺寸无关混合模块和多跳池模块。在矩阵分解模型和基于图形的模型上对真实世界数据集进行的实验表明，DINS 优于其他负采样方法，确立了它的有效性和优越性。我们的工作提供了一个新的视角，介绍了区域采样，并提出了 DINS 作为一种新颖的方法，实现了最先进的性能负采样。我们的实现在 PyTorch 中可用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dimension+Independent+Mixup+for+Hard+Negative+Sample+in+Collaborative+Filtering)|0|
|[Sequential Recommendation via an Adaptive Cross-domain Knowledge Decomposition](https://doi.org/10.1145/3583780.3615058)|Chuang Zhao, Xinyu Li, Ming He, Hongke Zhao, Jianping Fan|College of Management and Economics, Tianjin University, Tianjin, China; AI Lab at Lenovo Research, Beijing, China|Cross-domain recommendation, as an intelligent machine to alleviate data sparsity and cold start problems, has attracted extensive attention from scholars. Existing cross-domain recommendation frameworks usually leverage overlapping entities for knowledge transfer, the most popular of which are information aggregation and consistency maintenance. Despite decent improvements, the neglect of dynamic perspectives, the presence of confounding factors, and the disparities in domain properties inevitably constrain model performance. In view of this, this paper proposes a sequential recommendation framework via adaptive cross-domain knowledge decomposition, namely ARISEN, which focuses on employing adaptive causal learning to improve recommendation performance. Specifically, in order to facilitate sequence transfer, we align the user's behaviour sequences in the source domain and target domain according to the timestamps, expecting to use the abundant semantics of the former to augment the information of the latter. Regarding confounding factor removal, we introduce the causal learning technique and promote it as an adaptive representation decomposition framework on the basis of instrumental variables. For the sake of alleviating the impact of domain disparities, this paper endeavors to employ two mutually orthogonal transformation matrices for information fusion. Extensive experiments and detailed analyzes on large industrial and public data sets demonstrate that our framework can achieve substantial improvements over state-of-the-art algorithms.|跨域推荐作为一种缓解数据稀疏和冷启动问题的智能机器，已经引起了学者们的广泛关注。现有的跨领域推荐框架通常利用重叠实体进行知识转移，其中最流行的是信息聚合和一致性维护。尽管有了不错的改进，但是忽视动态视角、混杂因素的存在以及领域属性的差异不可避免地限制了模型的性能。鉴于此，本文提出了一种基于自适应跨领域知识分解的顺序推荐框架 ARISEN，重点研究了利用自适应因果学习来提高推荐性能的方法。具体来说，为了方便序列传输，我们根据时间戳对源域和目标域中的用户行为序列进行对齐，期望利用前者丰富的语义来增强后者的信息。关于去除混杂因素，我们引入了因果学习技术，并将其推广为一个基于工具变量的自适应表征分解框架。为了减轻领域差异的影响，本文尝试采用两个互正交的变换矩阵进行信息融合。大量的实验和对大型工业和公共数据集的详细分析表明，我们的框架可以比最先进的算法实现实质性的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential+Recommendation+via+an+Adaptive+Cross-domain+Knowledge+Decomposition)|0|
|[Noisy Perturbations for Estimating Query Difficulty in Dense Retrievers](https://doi.org/10.1145/3583780.3615270)|Negar Arabzadeh, Radin Hamidi Rad, Maryam Khodabakhsh, Ebrahim Bagheri|University of Waterloo, Waterloo, ON, Canada; Toronto Metropolitan University, Toronto, ON, Canada; Shahrood University of Technology, Shahrood, Iran|Estimating query difficulty, also known as Query Performance Prediction (QPP), is concerned with assessing the retrieval quality of a ranking method for an input query. Most traditional unsupervised frequency-based models and many recent supervised neural methods have been designed specifically for predicting the performance of sparse retrievers such as BM25. In this paper we propose an unsupervised QPP method for dense neural retrievers which operates by redefining the well-known concept of query robustness i.e., a more robust query to perturbations is an easier query to handle. We propose to generate query perturbations for measuring query robustness by systematically injecting noise into the contextualized neural representation of each query. We then compare the retrieved list for the original query with that of the perturbed query as a way to measure query robustness. Our experiments on four different query sets including MS MARCO, TREC Deep Learning track 2019 and 2020 and TREC DL-Hard show consistently improved performance on linear and ranking correlation metrics over the state of the art.|评估查询难度，也称为查询性能预测(QueryPerformance預，QPP) ，与评估输入查询的排序方法的检索质量有关。大多数传统的基于频率的无监督模型和许多最近的监督神经网络方法已被专门设计用于预测稀疏检索器的性能，如 BM25。本文提出了一种密集型神经元检索器的无监督 QPP 方法，该方法通过重新定义查询鲁棒性的概念来实现。我们提出通过系统地在每个查询的上下文化神经表示中注入噪声来产生查询扰动来衡量查询的鲁棒性。然后，我们将检索到的原始查询列表与受干扰的查询列表进行比较，作为衡量查询健壮性的一种方法。我们在包括 MS MARCO，TREC Deep Learning track 2019和2020以及 TREC DL-Hard 在内的四个不同的查询集上进行的实验显示，在线性和排名相关性指标方面，相对于最先进的水平，性能持续改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Noisy+Perturbations+for+Estimating+Query+Difficulty+in+Dense+Retrievers)|0|
|[Deep Context Interest Network for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615233)|Xuyang Hou, Zhe Wang, Qi Liu, Tan Qu, Jia Cheng, Jun Lei|Meituan, Beijing, China; University of Science and Technology of China, Hefei, China|Click-Through Rate (CTR) prediction, estimating the probability of a user clicking on an item, is essential in industrial applications, such as online advertising. Many works focus on user behavior modeling to improve CTR prediction performance. However, most of those methods only model users' positive interests from users' click items while ignoring the context information, which is the display items around the clicks, resulting in inferior performance. In this paper, we highlight the importance of context information on user behavior modeling and propose a novel model named Deep Context Interest Network (DCIN), which integrally models the click and its display context to learn users' context-aware interests. DCIN consists of three key modules: 1) Position-aware Context Aggregation Module (PCAM), which performs aggregation of display items with an attention mechanism; 2) Feedback-Context Fusion Module (FCFM), which fuses the representation of clicks and display contexts through non-linear feature interaction; 3) Interest Matching Module (IMM), which activates interests related with the target item. Moreover, we provide our hands-on solution to implement our DCIN model on large-scale industrial systems. The significant improvements in both offline and online evaluations demonstrate the superiority of our proposed DCIN method. Notably, DCIN has been deployed on our online advertising system serving the main traffic, which brings 1.5% CTR and 1.5% RPM lift.|点进率(ctrl)预测，估计用户点击一个项目的概率，在工业应用中是必不可少的，比如在线广告。许多工作集中在用户行为建模，以提高点击率预测性能。然而，这些方法大多只是从用户的点击项目中建立用户的积极兴趣模型，而忽略了上下文信息，即点击周围的显示项目，导致性能较差。本文强调了上下文信息在用户行为建模中的重要性，提出了一种新的模型——深度上下文兴趣网络(Deep Context Interest Network，DCIN)。DCIN 由三个关键模块组成: 1)位置感知上下文聚合模块(PCAM) ，利用注意机制对显示项目进行聚合; 2)反馈上下文融合模块(FCFM) ，通过非线性特征交互融合点击表示和显示上下文; 3)兴趣匹配模块(IMM) ，激活与目标项目相关的兴趣。此外，我们提供了我们的动手解决方案，以实现我们的 DCIN 模型的大规模工业系统。离线和在线评估的显著改进证明了我们提出的 DCIN 方法的优越性。值得注意的是，DCIN 已经部署在我们的在线广告系统服务的主要流量，这带来了1.5% 的点击率和1.5% 的转速提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Context+Interest+Network+for+Click-Through+Rate+Prediction)|0|
|[MSRA: A Multi-Aspect Semantic Relevance Approach for E-Commerce via Multimodal Pre-Training](https://doi.org/10.1145/3583780.3615224)|Hanqi Jin, Jiwei Tan, Lixin Liu, Lisong Qiu, Shaowei Yao, Xi Chen, Xiaoyi Zeng|Alibaba Group, Hangzhou, China|To enhance the effectiveness of matching user requests with millions of online products, practitioners invest significant efforts in developing semantic relevance models on large-scale e-commerce platforms. Generally, such semantic relevance models are formulated as text-matching approaches, which measure the relevance between users' search queries and the titles of candidate items (i.e., products). However, we argue that conventional relevance methods may lead to sub-optimal performance due to the limited information provided by the titles of candidate items. To alleviate this issue, we suggest incorporating additional information about candidate items from multiple aspects, including their attributes and images. This could supplement the information that may not be fully provided by titles alone. To this end, we propose a multi-aspect semantic relevance model that takes into account the match between search queries and the title, attribute and image information of items simultaneously. The model is further enhanced through pre-training using several well-designed self-supervised and weakly-supervised tasks. Furthermore, the proposed model is fine-tuned using annotated data and distilled into a representation-based architecture for efficient online deployment. Experimental results show the proposed approach significantly improves relevance and leads to considerable enhancements in business metrics.|为了提高将用户请求与数百万在线产品匹配的有效性，从业人员投入大量精力在大规模电子商务平台上开发语义相关性模型。通常，这种语义相关模型都是以文本匹配的方式构建的，用于测量用户的搜索查询与候选项(即产品)标题之间的相关性。然而，由于候选项目标题提供的信息有限，传统的关联方法可能导致性能不理想。为了缓解这个问题，我们建议从多个方面整合关于候选项目的额外信息，包括它们的属性和图像。这可以补充标题本身可能无法完全提供的信息。为此，我们提出了一个多方面的语义相关模型，该模型同时考虑了搜索查询与项目的标题、属性和图像信息之间的匹配。该模型通过使用几个设计良好的自监督和弱监督任务进行预训练得到进一步增强。此外，该模型使用带注释的数据进行了微调，并提炼为一个基于表示的体系结构，以实现有效的在线部署。实验结果表明，提出的方法显著提高了相关性，并导致业务度量的显著增强。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSRA:+A+Multi-Aspect+Semantic+Relevance+Approach+for+E-Commerce+via+Multimodal+Pre-Training)|0|
|[LEAD-ID: Language-Enhanced Denoising and Intent Distinguishing Graph Neural Network for Sponsored Search Broad Retrievals](https://doi.org/10.1145/3583780.3615175)|Xiao Zhou, Ran Wang, Haorui Li, Qiang Liu, Xingxing Wang, Dong Wang|Meituan.com, Beijing, China|As a local-based service (LBS), search ad retrieval in online meal delivery platforms should be broader to bridge the gap between vague consumption intentions of users and shortage of ad candidates limited by users' queries and positions. Recently, graph neural networks (GNNs) have been successfully applied to search ad retrieval task. However, directly applying GNNs suffer from noisy interactions and intents indistinguishability, which seriously degrades systems' effectiveness in the broad retrieval. In this paper, we propose a Language-EnhAnced Denoising and Intent Distinguishing graph neural network, LEAD-ID, which is developed and deployed at Meituan for sponsored search broad retrieval. To denoise interaction data, LEAD-ID designs hard- and soft- denoising strategies for GNNs based on a pretrained language model. A variational EM method is also employed to reduce high computational complexity of combining LMs and GNNs jointly. To distinguish various intents, LEAD-ID generates intent-aware node representations based on meticulously crafted LMs (language model) and GNNs; and then, it is guided by a contrastive learning object in an explicit and effective manner. According to offline experiments and online A/B tests, our framework significantly outperforms baselines in terms of recall and revenue.|作为一种基于本地的服务(LBS) ，在线送餐平台的搜索广告检索应该更加广泛，以弥补用户模糊的消费意图和受用户查询和位置限制的广告候选人短缺之间的差距。近年来，图神经网络(GNN)已成功地应用于广告检索任务中。然而，直接应用 GNN 存在着噪声交互和意图不可区分的问题，严重影响了系统在广义检索中的有效性。在本文中，我们提出了一个语言增强去噪和意图识别图神经网络，LEAD-ID，这是开发和部署在美团的赞助搜索广泛检索。为了对交互数据进行去噪，LEAD-ID 基于预先训练好的语言模型设计了 GNN 的软硬去噪策略。采用变分 EM 方法，降低了 LM 和 GNN 联合运算的高计算复杂度。为了区分不同的意图，LEAD-ID 基于精心制作的 LM (语言模型)和 GNN 生成意图感知的节点表示; 然后，在一个对比学习对象的指导下，以一种明确而有效的方式。根据离线实验和在线 A/B 测试，我们的框架在召回和收入方面明显优于基准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEAD-ID:+Language-Enhanced+Denoising+and+Intent+Distinguishing+Graph+Neural+Network+for+Sponsored+Search+Broad+Retrievals)|0|
|[Regression Compatible Listwise Objectives for Calibrated Ranking with Binary Relevance](https://doi.org/10.1145/3583780.3614712)|Aijun Bai, Rolf Jagerman, Zhen Qin, Le Yan, Pratyush Kar, BingRong Lin, Xuanhui Wang, Michael Bendersky, Marc Najork|Google LLC, Mountain View, CA, USA; Google LLC, Amsterdam, Netherlands; Google LLC, Paris, France; Google LLC, New York, NY, USA|As Learning-to-Rank (LTR) approaches primarily seek to improve ranking quality, their output scores are not scale-calibrated by design. This fundamentally limits LTR usage in score-sensitive applications. Though a simple multi-objective approach that combines a regression and a ranking objective can effectively learn scale-calibrated scores, we argue that the two objectives are not necessarily compatible, which makes the trade-off less ideal for either of them. In this paper, we propose a practical regression compatible ranking (RCR) approach that achieves a better trade-off, where the two ranking and regression components are proved to be mutually aligned. Although the same idea applies to ranking with both binary and graded relevance, we mainly focus on binary labels in this paper. We evaluate the proposed approach on several public LTR benchmarks and show that it consistently achieves either best or competitive result in terms of both regression and ranking metrics, and significantly improves the Pareto frontiers in the context of multi-objective optimization. Furthermore, we evaluated the proposed approach on YouTube Search and found that it not only improved the ranking quality of the production pCTR model, but also brought gains to the click prediction accuracy. The proposed approach has been successfully deployed in the YouTube production system.|由于学习到排名(LTR)方法主要寻求提高排名质量，因此它们的输出分数不是按照设计进行标度校准的。这从根本上限制了对分数敏感的应用程序中 LTR 的使用。虽然一个简单的多目标方法，结合回归和排名目标可以有效地学习量表校准的分数，我们认为，这两个目标不一定相容，这使得权衡不太理想的任何一个。在本文中，我们提出了一个实用的回归相容排序(RCR)方法，以实现更好的权衡，其中两个排序和回归组件被证明是相互一致的。虽然同样的思想也适用于二进制和分级相关性的排序，但本文主要关注二进制标签。我们在几个公共 LTR 基准上对所提出的方法进行了评估，结果表明，该方法在回归和排序指标方面始终达到最佳或有竞争力的结果，并且在多目标优化的情况下显著改善了帕累托前沿。此外，我们在 YouTube 搜索中对该方法进行了评估，发现该方法不仅提高了产品 pCTR 模型的排序质量，而且提高了点击预测的准确性。提议的方法已经成功地部署在 YouTube 制作系统中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regression+Compatible+Listwise+Objectives+for+Calibrated+Ranking+with+Binary+Relevance)|0|
|[An Unified Search and Recommendation Foundation Model for Cold-Start Scenario](https://doi.org/10.1145/3583780.3614657)|Yuqi Gong, Xichen Ding, Yehui Su, Kaiming Shen, Zhongyi Liu, Guannan Zhang|Ant Group, Hangzhou, China; Ant Group, Beijing, China|In modern commercial search engines and recommendation systems, data from multiple domains is available to jointly train the multi-domain model. Traditional methods train multi-domain models in the multi-task setting, with shared parameters to learn the similarity of multiple tasks, and task-specific parameters to learn the divergence of features, labels, and sample distributions of individual tasks. With the development of large language models, LLM can extract global domain-invariant text features that serve both search and recommendation tasks. We propose a novel framework called S\&R Multi-Domain Foundation, which uses LLM to extract domain invariant features, and Aspect Gating Fusion to merge the ID feature, domain invariant text features and task-specific heterogeneous sparse features to obtain the representations of query and item. Additionally, samples from multiple search and recommendation scenarios are trained jointly with Domain Adaptive Multi-Task module to obtain the multi-domain foundation model. We apply the S\&R Multi-Domain foundation model to cold start scenarios in the pretrain-finetune manner, which achieves better performance than other SOTA transfer learning methods. The S\&R Multi-Domain Foundation model has been successfully deployed in Alipay Mobile Application's online services, such as content query recommendation and service card recommendation, etc.|在现代商业搜索引擎和推荐系统中，来自多个域的数据可用于联合训练多域模型。传统方法在多任务环境下训练多领域模型，通过共享参数来学习多任务的相似性，通过任务特定参数来学习单个任务的特征、标签和样本分布的差异性。随着大型语言模型的发展，LLM 可以提取全局域不变的文本特征，这些特征可以同时服务于搜索和推荐任务。提出了一种新的基于领域不变特征提取的框架 S & R Multi-Domain Foundation，该框架利用 LLM 提取领域不变特征，利用方面门控融合技术融合 ID 特征、领域不变文本特征和任务特定的异构稀疏特征，得到查询和项目的表示。此外，将多个搜索和推荐场景的样本与领域自适应多任务模块联合训练，得到多领域基础模型。我们将 S & R 多领域基础模型应用于预训练-微调方式的冷启动场景，比其他 SOTA 迁移学习方法获得了更好的性能。S & R 多域基金会模式已成功应用于支付宝移动应用的在线服务，如内容查询推荐和服务卡推荐等。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Unified+Search+and+Recommendation+Foundation+Model+for+Cold-Start+Scenario)|0|
|[BOLT: An Automated Deep Learning Framework for Training and Deploying Large-Scale Search and Recommendation Models on Commodity CPU Hardware](https://doi.org/10.1145/3583780.3615458)|Nicholas Meisburger, Vihan Lakshman, Benito Geordie, Joshua Engels, David Torres Ramos, Pratik Pranav, Benjamin Coleman, Benjamin Meisburger, Shubh Gupta, Yashwanth Adunukota, Siddharth Jain, Tharun Medini, Anshumali Shrivastava|ThirdAI, Houston, TX, USA|Efficient large-scale neural network training and inference on commodity CPU hardware is of immense practical significance in democratizing deep learning (DL) capabilities. Presently, the process of training massive models consisting of hundreds of millions to billions of parameters requires the extensive use of specialized hardware accelerators, such as GPUs, which are only accessible to a limited number of institutions with considerable financial resources. Moreover, there is often an alarming carbon footprint associated with training and deploying these models. In this paper, we take a step towards addressing these challenges by introducing BOLT, a sparse deep learning library for training large-scale search and recommendation models on standard CPU hardware. BOLT provides a flexible, high-level API for constructing models that will be familiar to users of existing popular DL frameworks. By automatically tuning specialized hyperparameters, BOLT also abstracts away the algorithmic details of sparse network training. We evaluate BOLT on a number of information retrieval tasks including product recommendations, text classification, graph neural networks, and personalization. We find that our proposed system achieves competitive performance with state-of-the-art techniques at a fraction of the cost and energy consumption and an order-of-magnitude faster inference time. BOLT has also been successfully deployed by multiple businesses to address critical problems, and we highlight one customer case study in the field of e-commerce.|高效的大规模神经网络训练和推理对于普及深度学习(DL)能力具有重要的现实意义。目前，培训由数亿至数十亿个参数组成的大型模型的过程需要广泛使用专门的硬件加速器，如图形处理器，只有少数拥有大量财政资源的机构才能使用这些加速器。此外，在培训和部署这些模型时，往往存在令人担忧的碳足印。在本文中，我们通过引入 BOLT 向解决这些挑战迈出了一步，BOLT 是一个稀疏的深度学习库，用于在标准 CPU 硬件上培训大规模搜索和推荐模型。BOLT 提供了一个灵活的高级 API，用于构造现有流行的 DL 框架的用户所熟悉的模型。通过自动调整专门的超参数，BOLT 还抽象出稀疏网络训练的算法细节。我们评估 BOLT 的一些信息检索任务，包括产品推荐、文本分类、图形神经网络和个性化。我们发现，我们提出的系统实现了具有竞争力的性能与国家的最先进的技术在成本和能源消耗的一小部分和一个数量级更快的推理时间。BOLT 还被多个企业成功部署以解决关键问题，我们强调了电子商务领域的一个客户案例研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BOLT:+An+Automated+Deep+Learning+Framework+for+Training+and+Deploying+Large-Scale+Search+and+Recommendation+Models+on+Commodity+CPU+Hardware)|0|
|[Graph Learning for Exploratory Query Suggestions in an Instant Search System](https://doi.org/10.1145/3583780.3615481)|Enrico Palumbo, Andreas Damianou, Alice Wang, Alva Liu, Ghazal Fazelnia, Francesco Fabbri, Rui Ferreira, Fabrizio Silvestri, Hugues Bouchard, Claudia Hauff, Mounia Lalmas, Ben Carterette, Praveen Chandar, David Nyhan|Spotify, Barcelona, Spain; Spotify, London, United Kingdom; Spotify, Alexandria, USA; Spotify, Delft, Netherlands; Spotify, Wilmington, USA; Spotify, Rome, Italy; Spotify, Farsta, Sweden; Spotify, New York, USA; Spotify, Turin, Italy; Spotify, Cambridge, United Kingdom|Search systems in online content platforms are typically biased toward a minority of highly consumed items, reflecting the most common user behavior of navigating toward content that is already familiar and popular. Query suggestions are a powerful tool to support query formulation and to encourage exploratory search and content discovery. However, classic approaches for query suggestions typically rely either on semantic similarity, which lacks diversity and does not reflect user searching behavior, or on a collaborative similarity measure mined from search logs, which suffers from data sparsity and is biased by highly popular queries. In this work, we argue that the task of query suggestion can be modelled as a link prediction task on a heterogeneous graph including queries and documents, enabling Graph Learning methods to effectively generate query suggestions encompassing both semantic and collaborative information. We perform an offline evaluation on an internal Spotify dataset of search logs and on two public datasets, showing that node2vec leads to an accurate and diversified set of results, especially on the large scale real-world data. We then describe the implementation in an instant search scenario and discuss a set of additional challenges tied to the specific production environment. Finally, we report the results of a large scale A/B test involving millions of users and prove that node2vec query suggestions lead to an increase in online metrics such as coverage (+1.42% shown search results pages with suggestions) and engagement (+1.21% clicks), with a specifically notable boost in the number of clicks on exploratory search queries (+9.37%).|在线内容平台中的搜索系统通常偏向于少数高消费项目，这反映了最常见的用户行为，即导航到已经熟悉和流行的内容。查询建议是一个强大的工具，可以支持查询表达，并鼓励探索性搜索和内容发现。然而，经典的查询建议方法通常依赖于语义相似性，这种相似性缺乏多样性，不能反映用户的搜索行为; 或者依赖于从搜索日志中挖掘出来的协作相似性度量，这种度量受到数据稀疏性的影响，并且受到非常流行的查询的影响。本文认为，查询建议任务可以建模为包含查询和文档的异构图上的链接预测任务，使图学习方法能够有效地生成包含语义和协作信息的查询建议。我们对搜索日志的内部 Spotify 数据集和两个公共数据集进行离线评估，表明 node2vec 导致准确和多样化的结果集，特别是在大规模的现实世界数据上。然后，我们在一个即时搜索场景中描述实现，并讨论一组与特定生产环境相关的附加挑战。最后，我们报告了一个涉及数百万用户的大规模 A/B 测试的结果，并证明 node2vec 查询建议导致在线指标的增加，如覆盖率(+ 1.42% 显示带有建议的搜索结果页面)和参与度(+ 1.21% 点击率) ，特别是探索性搜索查询的点击数显著增加(+ 9.37%)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Learning+for+Exploratory+Query+Suggestions+in+an+Instant+Search+System)|0|
|[Learning and Optimization of Implicit Negative Feedback for Industrial Short-video Recommender System](https://doi.org/10.1145/3583780.3615482)|Yunzhu Pan, Nian Li, Chen Gao, Jianxin Chang, Yanan Niu, Yang Song, Depeng Jin, Yong Li|Department of Electronic Engineering, Tsinghua University, Beijing, China; Beijing Kuaishou Technology Co., Ltd., Beijing, China; Tsinghua University, Beijing, China; University of Electronic Science and Technology of China, Chengdu, China|Short-video recommendation is one of the most important recommendation applications in today's industrial information systems. Compared with other recommendation tasks, the enormous amount of feedback is the most typical characteristic. Specifically, in short-video recommendation, the easiest-to-collect user feedback is from the skipping behaviors, which leads to two critical challenges for the recommendation model. First, the skipping behavior reflects implicit user preferences, and thus it is challenging for interest extraction. Second, the kind of special feedback involves multiple objectives, such as total watching time, which is also very challenging. In this paper, we present our industrial solution in Kuaishou, which serves billion-level users every day. Specifically, we deploy a feedback-aware encoding module which well extracts user preference taking the impact of context into consideration. We further design a multi-objective prediction module which well distinguishes the relation and differences among different model objectives in the short-video recommendation. We conduct extensive online A/B testing, along with detailed and careful analysis, which verifies the effectiveness of our solution.|短视频推荐是当今工业信息系统中最重要的推荐应用之一。与其他推荐任务相比，大量的反馈是最典型的特征。具体来说，在短视频推荐中，最容易收集的用户反馈来自跳跃行为，这给推荐模型带来了两个关键的挑战。首先，跳跃行为反映了隐式用户偏好，因此对兴趣提取具有挑战性。其次，这种特殊的反馈涉及多个目标，如总观看时间，这也是非常具有挑战性的。在本文中，我们介绍了我们在 Kuaishou 的工业解决方案，这个方案每天为数十亿用户提供服务。具体来说，我们部署了一个反馈感知的编码模块，该模块在考虑上下文影响的情况下很好地提取了用户偏好。进一步设计了一个多目标预测模块，可以很好地区分短视频推荐中不同模型目标之间的关系和差异。我们进行了广泛的在线 A/B 测试，并进行了详细和仔细的分析，从而验证了我们的解决方案的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+and+Optimization+of+Implicit+Negative+Feedback+for+Industrial+Short-video+Recommender+System)|0|
|[3MN: Three Meta Networks for Multi-Scenario and Multi-Task Learning in Online Advertising Recommender Systems](https://doi.org/10.1145/3583780.3614651)|Yifei Zhang, Hua Hua, Hui Guo, Shuangyang Wang, Chongyu Zhong, Shijie Zhang|Interactive Entertainment Group, Tencent, Shenzhen, China|Recommender systems are widely applied on web. For example, online advertising systems rely on recommender systems to accurately estimate the value of display opportunities, which is critical to maximize the profits of advertisers. To reduce computational resource consumption, the core tactic of Multi-Scenario Multi-Task Learning (MSMTL) is to devise a single recommder system that is adapted to all contexts instead of implementing multiple scenario-oriented or task-oriented recommender systems. However, MSMTL is challenging because there are complicated task-task, scenario-scenario, and task-scenario interrelations; the characteristic of different tasks in different scenarios also largely varies; and samples of each context are often unevenly distributed. Previous MSMTL solutions focus on applying scenario knowledge to improve the performance of multi-task learning, while neglecting the complicated interrelations among tasks and scenarios. Moreover, samples derived from different scenarios are transferred into the latent embedding with the same dimension. This static embedding strategy impedes the practicality of model expressiveness, since the scenarios with sufficient samples are underrepresented and those with insufficient samples are over-represented. In this paper, we propose a novel three meta networks-based solution (3MN) to MSMTL that addresses all the limitations discussed above. Specifically, we innovatively bind the meta network with scenario-related input in bottom embedding layer, so that the embedding layer is capable of learning the scenario-related knowledge explicitly. To counteract the imbalanced scenario-related data distributions, our flexible embedding layer adaptively learns the representation of samples. This innovative embedding layer is also able to boost other solutions as a plug-in. Moreover, to fully capture the interrelations among scenarios and tasks, we enforce the task and scenario information into the other two meta networks, and transfer the resulted meta-knowledge into the top components (i.e., backbone network and classifier) of the recommender system, respectively. These three meta networks contribute to the superiority of our 3MN solution over state-of-the-art MSMTL solutions, which is demonstrated by extensive offline experiments. 3MN has been successfully deployed in our industrial online advertising system.|推荐系统在网络上得到了广泛的应用。例如，在线广告系统依赖于推荐系统来准确估计展示机会的价值，这对于广告商的利润最大化至关重要。为了减少计算资源消耗，多场景多任务学习(MSMTL)的核心策略是设计一个单一的推荐系统，以适应所有环境，而不是实施多场景或任务导向的推荐系统。然而，MSMTL 具有挑战性，因为存在复杂的任务-任务、场景-场景和任务-场景之间的相互关系; 不同场景中不同任务的特征也大不相同; 每个上下文的样本通常分布不均匀。以往的 MSMTL 解决方案侧重于应用场景知识来提高多任务学习的性能，而忽视了任务和场景之间复杂的相互关系。同时，将不同场景的样本转化为同维数的潜在嵌入。这种静态嵌入策略阻碍了模型表达的实用性，因为有足够样本的场景表示不足，而有不足样本的场景表示过多。在本文中，我们提出了一个新的三元网络为基础的解决方案(3MN)的 MSMTL，解决所有的限制上述讨论。具体来说，我们在底层嵌入层创新性地将元网络与场景相关的输入绑定在一起，使得嵌入层能够显式地学习场景相关的知识。为了抵消不平衡的场景相关数据分布，我们的灵活嵌入层自适应地学习样本的表示。这个创新的嵌入层还可以作为插件提升其他解决方案。此外，为了充分捕捉场景和任务之间的相互关系，我们将任务和场景信息强制加入另外两个元网络，并将得到的元知识分别转移到推荐系统的顶层组件(即骨干网络和分类器)中。这三个元网络有助于我们的3MN 解决方案优于最先进的 MSMTL 解决方案，这在大量的离线实验中得到了证明。3MN 已成功部署在我们的工业在线广告系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3MN:+Three+Meta+Networks+for+Multi-Scenario+and+Multi-Task+Learning+in+Online+Advertising+Recommender+Systems)|0|
|[GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking](https://doi.org/10.1145/3583780.3614901)|Jiaqi Bai, Hongcheng Guo, Jiaheng Liu, Jian Yang, Xinnian Liang, Zhao Yan, Zhoujun Li|State Key Lab of Software Development Environment, Beihang University, Beijing, China; DAMO Academy, Alibaba Group, Beijing, China; Tencent Cloud AI, Beijing, China; Beihang University, Beijing, China|Retrieval-enhanced text generation, which aims to leverage passages retrieved from a large passage corpus for delivering a proper answer given the input query, has shown remarkable progress on knowledge-intensive language tasks such as open-domain question answering and knowledge-enhanced dialogue generation. However, the retrieved passages are not ideal for guiding answer generation because of the discrepancy between retrieval and generation, i.e., the candidate passages are all treated equally during the retrieval procedure without considering their potential to generate the proper answers. This discrepancy makes a passage retriever deliver a sub-optimal collection of candidate passages to generate answers. In this paper, we propose the GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing the above challenge by distilling knowledge from a generative passage estimator (GPE) to a passage ranker, where the GPE is a generative language model used to measure how likely the candidate passages can generate the proper answer. We realize the distillation procedure by teaching the passage ranker learning to rank the passages ordered by the GPE. Furthermore, we improve the distillation quality by devising a curriculum knowledge distillation mechanism, which allows the knowledge provided by the GPE can be progressively distilled to the ranker through an easy-to-hard curriculum, enabling the passage ranker to correctly recognize the provenance of the answer from many plausible candidates. We conduct extensive experiments on four datasets across three knowledge-intensive language tasks. Experimental results show advantages over the state-of-the-art methods for both passage ranking and answer generation on the KILT benchmark.|检索增强型文本生成的目的是利用从大型文章语料库中检索到的段落来提供输入查询的正确答案，在开放领域问题回答和知识增强型对话生成等知识密集型语言任务方面取得了显著进展。然而，由于检索和生成之间的差异，被检索的段落并不是指导生成答案的理想选择，也就是说，候选段落在检索过程中都被平等对待，而没有考虑它们生成正确答案的潜力。这种差异使得文章检索器提供一个次优的候选文章集合来生成答案。在本文中，我们提出了生成知识改进通道排名(GripRank)方法，通过从生成通道估计(GPE)中提取知识到一个通道排名，其中 GPE 是一个生成语言模型，用于衡量候选通道产生正确答案的可能性，从而解决上述挑战。通过教导通道排序器学习对 GPE 排序的通道进行排序，实现了蒸馏过程。此外，我们通过设计一个课程知识蒸馏机制来提高蒸馏质量，该机制允许 GPE 提供的知识可以通过一个容易到难的课程逐步蒸馏到排名，使得通过排名能够正确地识别来自许多合理候选人的答案的来源。我们在三个知识密集型语言任务的四个数据集上进行了广泛的实验。实验结果表明，在 KILT 基准的文章排序和答案生成方面，该方法比目前最先进的方法具有更大的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GripRank:+Bridging+the+Gap+between+Retrieval+and+Generation+via+the+Generative+Knowledge+Improved+Passage+Ranking)|0|
|[CLosER: Conversational Legal Longformer with Expertise-Aware Passage Response Ranker for Long Contexts](https://doi.org/10.1145/3583780.3614812)|Arian Askari, Mohammad Aliannejadi, Amin Abolghasemi, Evangelos Kanoulas, Suzan Verberne|University of Amsterdam, Amsterdam, Netherlands; Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands; LIACS, Leiden University, Leiden, Netherlands; Leiden University, Amsterdam, Netherlands|In this paper, we investigate the task of response ranking in conversational legal search. We propose a novel method for conversational passage response retrieval (ConvPR) for long conversations in domains with mixed levels of expertise. Conversational legal search is challenging because the domain includes long, multi-participant dialogues with domain-specific language. Furthermore, as opposed to other domains, there typically is a large knowledge gap between the questioner (a layperson) and the responders (lawyers), participating in the same conversation. We collect and release a large-scale real-world dataset called LegalConv with nearly one million legal conversations from a legal community question answering (CQA) platform. We address the particular challenges of processing legal conversations, with our novel Conversational Legal Longformer with Expertise-Aware Response Ranker, called CLosER. The proposed method has two main innovations compared to state-of-the-art methods for ConvPR: (i) Expertise-Aware Post-Training; a learning objective that takes into account the knowledge gap difference between participants to the conversation; and (ii) a simple but effective strategy for re-ordering the context utterances in long conversations to overcome the limitations of the sparse attention mechanism of the Longformer architecture. Evaluation on LegalConv shows that our proposed method substantially and significantly outperforms existing state-of-the-art models on the response selection task. Our analysis indicates that our Expertise-Aware PostTraining, i.e., continued pre-training or domain/task adaptation, plays an important role in the achieved effectiveness. Our proposed method is generalizable to other tasks with domain-specific challenges and can facilitate future research on conversational search in other domains.|本文研究了会话法律搜索中的回答排序问题。本文提出了一种基于混合专业知识水平的会话通道反应检索方法。对话式法律搜索具有挑战性，因为该领域包括与领域特定语言的长时间、多参与者对话。此外，与其他领域不同，提问者(外行)和回答者(律师)参与同一对话时，通常存在很大的知识差距。我们收集并发布了一个名为 LegalConv 的大规模现实世界数据集，其中包括来自法律社区问答(cQA)平台的近一百万个法律对话。我们解决处理法律对话的特殊挑战，我们的新颖的对话法律长期与专家意识的响应排名，所谓的关闭。与目前最先进的 ConvPR 方法相比，提出的方法有两个主要创新: (i)专业知识意识的后期培训; 一个考虑到会话参与者之间的知识差异的学习目标; 和(ii)一个简单但有效的策略来重新排序长时间会话中的上下文语句，以克服 Longform 架构的稀疏注意机制的局限性。对 LegalConv 的评估表明，我们提出的方法在响应选择任务上大大优于现有的最先进的模型。我们的分析表明，我们的专业意识后期培训，即持续的培训前或领域/任务适应，在实现有效性方面发挥了重要作用。我们提出的方法可推广到其他具有领域特定挑战的任务，并可促进未来其他领域的会话搜索研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLosER:+Conversational+Legal+Longformer+with+Expertise-Aware+Passage+Response+Ranker+for+Long+Contexts)|0|
|[Multi-modal Mixture of Experts Represetation Learning for Sequential Recommendation](https://doi.org/10.1145/3583780.3614978)|Shuqing Bian, Xingyu Pan, Wayne Xin Zhao, Jinpeng Wang, Chuyuan Wang, JiRong Wen|Meituan, Beijing, China; Renmin University of China, Beijing, China|Within online platforms, it is critical to capture the dynamic user preference from the sequential interaction behaviors for making accurate recommendation over time. Recently, significant progress has been made in sequential recommendation with deep learning. However, existing neural sequential recommender often suffer from the data sparsity issue in real-world applications. To tackle this problem, we propose a Multi-Modal Mixture of experts model for Sequential Recommendation, named M3SRec, which leverage rich multi-modal interaction data for improving sequential recommendation. Different from existing multi-modal recommendation models, our approach jointly considers reducing the semantic gap across modalities and adapts multi-modal semantics to fit recommender systems. For this purpose, we make two important technical contributions in architecture and training. Firstly, we design a novel multi-modal mixture-of-experts (MoE) fusion network, which can deeply fuse the across-modal semantics and largely enhance the modeling capacity of complex user intents. For training, we design specific pre-training tasks that can mimic the goal of the recommendation, which help model learn the semantic relatedness between the multi-modal sequential context and the target item. Extensive experiments conducted on both public and industry datasets demonstrate the superiority of our proposed method over existing state-of-the-art methods, especially when only limited training data is available.|在在线平台中，从连续的交互行为中捕获动态用户偏好对于随时间做出准确的推荐是至关重要的。近年来，随着深度学习在序贯推荐方面取得了显著的进展。然而，现有的神经顺序推荐系统在实际应用中经常遇到数据稀疏的问题。为了解决这个问题，我们提出了一个序贯推荐的多模态混合专家模型 M3SRec，该模型利用丰富的多模态交互数据来改进序贯推荐。与现有的多模态推荐模型不同，我们的方法共同考虑缩小模态间的语义差距，并采用多模态语义来适应推荐系统。为此，我们在建筑和培训方面做出了两项重要的技术贡献。首先，我们设计了一种新的多模态专家混合(MoE)融合网络，该网络能够深入融合跨模态语义，大大提高复杂用户意图的建模能力。对于训练，我们设计了能够模拟推荐目标的特定的预训练任务，帮助模型学习多模态顺序上下文和目标项之间的语义关系。在公共数据集和行业数据集上进行的大量实验表明，我们提出的方法优于现有的最先进的方法，特别是当只有有限的训练数据可用时。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Mixture+of+Experts+Represetation+Learning+for+Sequential+Recommendation)|0|
|[BOMGraph: Boosting Multi-scenario E-commerce Search with a Unified Graph Neural Network](https://doi.org/10.1145/3583780.3614794)|Shuai Fan, Jinping Gou, Yang Li, Jiaxing Bai, Chen Lin, Wanxian Guan, Xubin Li, Hongbo Deng, Jian Xu, Bo Zheng|Alibaba Group, Hangzhou, China; Xiamen University, Xiamen, China|Mobile Taobao Application delivers search services on multiple scenarios that take textual, visual, or product queries. This paper aims to propose a unified graph neural network for these search scenarios to leverage data from multiple scenarios and jointly optimize search performances with less training and maintenance costs. Towards this end, this paper proposes BOMGraph, BOosting Multi-scenario E-commerce Search with a unified Graph neural network. BOMGraph is embodied with several components to address challenges in multi-scenario search. It captures heterogeneous information flow across scenarios by inter-scenario and intra-scenario metapaths. It learns robust item representations by disentangling specific characteristics for different scenarios and encoding common knowledge across scenarios. It alleviates label scarcity and long-tail problems in scenarios with low traffic by contrastive learning with cross-scenario augmentation. BOMGraph has been deployed in production by Alibaba's E-commerce search advertising platform. Both offline evaluations and online A/B tests demonstrate the effectiveness of BOMGraph.|移动淘宝应用程序提供多种场景的搜索服务，包括文本查询、视觉查询或产品查询。针对这些搜索场景，本文提出了一种统一的图形神经网络，以较少的训练和维护成本，充分利用多个场景的数据，共同优化搜索性能。为此，本文提出了基于统一图神经网络的 BOMGraph，以推动多场景电子商务搜索。BOMGraph 由几个组件组成，用于解决多场景搜索中的挑战。它通过场景间和场景内的元路径捕获跨场景的异构信息流。它通过分离不同场景的特定特征并跨场景编码公共知识来学习健壮的项表示。通过对比学习和跨场景扩展，缓解了低流量场景下的标签稀缺性和长尾问题。BOMGraph 已被阿里巴巴电子商务搜索广告平台投入生产。离线评估和在线 A/B 测试都证明了 BOMGraph 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BOMGraph:+Boosting+Multi-scenario+E-commerce+Search+with+a+Unified+Graph+Neural+Network)|0|
|[Large Language Models as Zero-Shot Conversational Recommenders](https://doi.org/10.1145/3583780.3614949)|Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, Bodhisattwa Prasad Majumder, Nathan Kallus, Julian J. McAuley|Netflix Inc. & Cornell University, Los Gatos, CA, USA; University of California, San Diego, La Jolla, CA, USA; Netflix Inc., Los Gatos, CA, USA|In this paper, we present empirical studies on conversational recommendation tasks using representative large language models in a zero-shot setting with three primary contributions. (1) Data: To gain insights into model behavior in "in-the-wild" conversational recommendation scenarios, we construct a new dataset of recommendation-related conversations by scraping a popular discussion website. This is the largest public real-world conversational recommendation dataset to date. (2) Evaluation: On the new dataset and two existing conversational recommendation datasets, we observe that even without fine-tuning, large language models can outperform existing fine-tuned conversational recommendation models. (3) Analysis: We propose various probing tasks to investigate the mechanisms behind the remarkable performance of large language models in conversational recommendation. We analyze both the large language models' behaviors and the characteristics of the datasets, providing a holistic understanding of the models' effectiveness, limitations and suggesting directions for the design of future conversational recommenders|本文采用三个主要贡献的零击点模型对会话推荐任务进行了实证研究。(1)数据: 为了深入了解“野外”会话推荐场景中的模型行为，我们通过刮取一个流行的讨论网站，构建了一个新的推荐相关会话数据集。这是迄今为止最大的公共现实世界对话推荐数据集。(2)评估: 在新的数据集和两个现有的会话推荐数据集上，我们观察到即使没有微调，大型语言模型也能胜过现有的微调会话推荐模型。(3)分析: 我们提出了各种探究任务来研究大语言模型在会话推荐中显著表现的机制。我们分析了大型语言模型的行为和数据集的特点，为模型的有效性、局限性提供了全面的理解，并为未来会话推荐系统的设计提供了建议|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+as+Zero-Shot+Conversational+Recommenders)|0|
|[Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems](https://doi.org/10.1145/3583780.3614775)|Hengchang Hu, Wei Guo, Yong Liu, MinYen Kan|Huawei Noah's Ark Lab, Singapore, Singapore; National University of Singapore, Singapore, Singapore|In sequential recommendation, multi-modal information (e.g., text or image) can provide a more comprehensive view of an item's profile. The optimal stage (early or late) to fuse modality features into item representations is still debated. We propose a graph-based approach (named MMSR) to fuse modality features in an adaptive order, enabling each modality to prioritize either its inherent sequential nature or its interplay with other modalities. MMSR represents each user's history as a graph, where the modality features of each item in a user's history sequence are denoted by cross-linked nodes. The edges between homogeneous nodes represent intra-modality sequential relationships, and the ones between heterogeneous nodes represent inter-modality interdependence relationships. During graph propagation, MMSR incorporates dual attention, differentiating homogeneous and heterogeneous neighbors. To adaptively assign nodes with distinct fusion orders, MMSR allows each node's representation to be asynchronously updated through an update gate. In scenarios where modalities exhibit stronger sequential relationships, the update gate prioritizes updates among homogeneous nodes. Conversely, when the interdependent relationships between modalities are more pronounced, the update gate prioritizes updates among heterogeneous nodes. Consequently, MMSR establishes a fusion order that spans a spectrum from early to late modality fusion. In experiments across six datasets, MMSR consistently outperforms state-of-the-art models, and our graph propagation methods surpass other graph neural networks. Additionally, MMSR naturally manages missing modalities.|在顺序推荐中，多模态信息(例如文本或图像)可以提供一个更全面的项目配置文件视图。最佳阶段(早期或晚期)融合情态特征的项目表示仍然存在争议。我们提出了一种基于图的方法(命名为 MMSR) ，以自适应的顺序融合模态特征，使每个模态优先考虑其固有的顺序性质或其与其他模态的相互作用。MMSR 将每个用户的历史表示为一个图，其中用户历史序列中每个项目的模态特征由交叉链接的节点表示。同质节点之间的边表示模态内部的顺序关系，异质节点之间的边表示模态间的相互依赖关系。在图的传播过程中，MMSR 融合了双重注意，区分了同质和异质邻居。为了自适应地分配具有不同融合顺序的节点，MMSR 允许通过更新门异步更新每个节点的表示。在模式表现出更强的顺序关系的场景中，更新门优先更新同质节点。相反，当模式之间的相互依赖关系更加明显时，更新门优先考虑异构节点之间的更新。因此，MMSR 建立了一个从早期到晚期的融合序列。在跨六个数据集的实验中，MMSR 始终优于最先进的模型，我们的图传播方法优于其他图神经网络。此外，MMSR 自然会管理缺失的模式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Multi-Modalities+Fusion+in+Sequential+Recommendation+Systems)|0|
|[AdaMCT: Adaptive Mixture of CNN-Transformer for Sequential Recommendation](https://doi.org/10.1145/3583780.3614773)|Juyong Jiang, Peiyan Zhang, Yingtao Luo, Chaozhuo Li, Jae Boum Kim, Kai Zhang, Senzhang Wang, Xing Xie, Sunghun Kim||Sequential recommendation (SR) aims to model users' dynamic preferences from their historical interactions. Recently, Transformer and convolution neural network (CNNs) have shown great success in learning representations for SR. Nevertheless, Transformer mainly focus on capturing content-based global interactions, while CNNs effectively exploit local features in practical recommendation scenarios. Thus, how to effectively aggregate CNNs and Transformer to model both local and global dependencies of historical item sequence still remains an open challenge and is rarely studied in SR. To this regard, we inject locality inductive bias into Transformer by combining its global attention mechanism with a local convolutional filter, and adaptively determine the mixing importance on a personalized basis through a module- and layer-aware adaptive mixture units, named AdaMCT. Moreover, considering that softmax-based attention may encourage unimodal activation, we introduce the Squeeze-Excitation Attention (with sigmoid activation) into sequential recommendation to capture multiple relevant items (keys) simultaneously. Extensive experiments on three widely used benchmark datasets demonstrate that AdaMCT significantly outperforms the previous Transformer and CNNs based models by an average of 18.46% and 60.85% respectively in terms of NDCG@5 and achieves state-of-the-art performance.|序贯推荐(SR)的目的是根据用户的历史交互对其动态偏好进行建模。近年来，变压器和卷积神经网络(CNN)在 SR 的学习表征方面取得了很大的成功。尽管如此，Transformer 主要关注于捕获基于内容的全局交互，而 CNN 在实际推荐场景中有效地利用了局部特征。因此，如何有效地聚合 CNN 和 Transformer 来模拟历史项目序列的局部和全局依赖关系仍然是一个开放的挑战，在 SR 中很少进行研究。为此，我们将变压器的全局注意机制与局部卷积滤波器相结合，将局部感应偏差注入变压器，并通过模块和层感知自适应混合单元 AdaMCT 自适应地确定混合重要性。此外，考虑到基于 softmax 的注意力可能会鼓励单峰激活，我们将挤压-兴奋注意力(具有乙状结肠激活)引入顺序推荐，以同时捕获多个相关项目(键)。在三个广泛使用的基准数据集上进行的大量实验表明，AdaMCT 在 NDCG@5方面的性能显著优于以前基于 former 和 CNN 的模型，平均分别为18.46% 和60.85% ，并且达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaMCT:+Adaptive+Mixture+of+CNN-Transformer+for+Sequential+Recommendation)|0|
|[AutoMRM: A Model Retrieval Method Based on Multimodal Query and Meta-learning](https://doi.org/10.1145/3583780.3614787)|Zhaotian Li, Binhang Qi, Hailong Sun, Xiang Gao|Beihang University, Beijing, China|With more and more Deep Neural Network (DNN) models are publicly available on model sharing platforms (e.g., HuggingFace), model reuse has become a promising way in practice to improve the efficiency of DNN model construction by avoiding the costs of model training. To that end, a pivotal step for model reuse is model retrieval, which facilitates discovering suitable models from a model hub that match the requirements of users. However, the existing model retrieval methods have inadequate performance and efficiency, since they focus on matching user requirements with the model names, and thus cannot work well for high-dimensional data such as images. In this paper, we propose a user-task-centric multimodal model retrieval method named AutoMRM. AutoMRM can retrieve DNN models suitable for the user's task according to both the dataset and description of the task. Moreover, AutoMRM utilizes meta-learning to retrieve models for previously unseen task queries. Specifically, given a task, AutoMRM extracts the latent meta-features from the dataset and description for training meta-learners offline and obtaining the representation of user task queries online. Experimental results demonstrate that AutoMRM outperforms existing model retrieval methods including the state-of-the-art method in both effectiveness and efficiency.|随着深度神经网络(DNN)模型在模型共享平台(如 HuggingFace)上的广泛应用，模型重用已成为提高 DNN 模型构建效率、避免模型训练成本的有效途径。为此，模型重用的关键步骤是模型检索，它有助于从模型中心发现符合用户需求的合适模型。然而，现有的模型检索方法由于侧重于匹配用户需求和模型名称，因此性能和效率不高，不能很好地适用于图像等高维数据。本文提出了一种以用户任务为中心的多模态模型检索方法 AutoMRM。AutoMRM 可以根据数据集和任务描述检索适合用户任务的 DNN 模型。此外，AutoMRM 利用元学习来检索以前未见到的任务查询的模型。具体来说，AutoMRM 从数据集中提取潜在的元特征，用于离线培训元学习者，并在线获取用户任务查询的表示。实验结果表明，AutoMRM 在有效性和效率方面都优于现有的模型检索方法，包括最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoMRM:+A+Model+Retrieval+Method+Based+on+Multimodal+Query+and+Meta-learning)|0|
|[Retrieving GNN Architecture for Collaborative Filtering](https://doi.org/10.1145/3583780.3615035)|Fengqi Liang, Huan Zhao, Zhenyi Wang, Wei Fang, Chuan Shi|4Paradigm, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Potsts and Telecommunications, Beijing, China|Graph Neural Networks (GNNs) have been widely used in Collaborative Filtering (CF). However, when given a new recommendation scenario, the current options are either selecting from existing GNN architectures or employing Neural Architecture Search (NAS) to obtain a well-performing GNN model, both of which are expensive in terms of human expertise or computational resources.To address the problem, in this work,we propose a novel neural retrieval approach, dubbed RGCF, to search a well-performing architecture for GNN-based CF rapidly when handling new scenarios. Specifically, we design the neural retrieval approach based on meta-learning by developing two-level meta-features, ranking loss, and task-level data augmentation, and in a retrieval paradigm, RGCF can directly return a well-performing architecture given a new dataset (query), thus being efficient inherently. Experimental results on two mainstream tasks, i.e., rating prediction and item ranking, show that RGCF outperforms all models either by human-designed or NAS on two new datasets in terms of effectiveness and efficiency. Particularly, the efficiency improvement is significant, taking as an example that RGCF is 61.7-206.3x faster than a typical reinforcement learning based NAS approach on the two new datasets. Code and data are available at https://github.com/BUPT-GAMMA/RGCF.|图形神经网络(GNN)已广泛应用于协同过滤(CF)。然而，当给出一个新的推荐场景时，目前的选择要么是从现有的 GNN 架构中选择，要么是使用神经结构搜索(NAS)来获得一个性能良好的 GNN 模型，这两者在人类专业知识或计算资源方面都是昂贵的。为了解决这个问题，在这项工作中，我们提出了一种新的神经检索方法，称为 RGCF，在处理新的场景时快速搜索一个性能良好的基于 GNN 的 CF 架构。具体而言，我们通过开发两级元特征，排序丢失和任务级数据增强来设计基于元学习的神经检索方法，并且在检索范例中，RGCF 可以直接返回给定新数据集(查询)的性能良好的架构，从而本质上是有效的。在评分预测和项目排序这两个主流任务上的实验结果表明，RGCF 在两个新数据集上的有效性和效率均优于人工设计的或 NAS 的所有模型。特别是，效率的提高是显著的，例如在两个新的数据集上，RgCF 比典型的基于强化学习的 NAS 方法快61.7-206.3倍。代码和数据可在 https://github.com/bupt-gamma/rgcf 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieving+GNN+Architecture+for+Collaborative+Filtering)|0|
|[AutoSeqRec: Autoencoder for Efficient Sequential Recommendation](https://doi.org/10.1145/3583780.3614788)|Sijia Liu, Jiahao Liu, Hansu Gu, Dongsheng Li, Tun Lu, Peng Zhang, Ning Gu|Microsoft Research Asia, Shanghai, China; Fudan University, Shanghai, China; Independent, Seattle, WA, USA|Sequential recommendation demonstrates the capability to recommend items by modeling the sequential behavior of users. Traditional methods typically treat users as sequences of items, overlooking the collaborative relationships among them. Graph-based methods incorporate collaborative information by utilizing the user-item interaction graph. However, these methods sometimes face challenges in terms of time complexity and computational efficiency. To address these limitations, this paper presents AutoSeqRec, an incremental recommendation model specifically designed for sequential recommendation tasks. AutoSeqRec is based on autoencoders and consists of an encoder and three decoders within the autoencoder architecture. These components consider both the user-item interaction matrix and the rows and columns of the item transition matrix. The reconstruction of the user-item interaction matrix captures user long-term preferences through collaborative filtering. In addition, the rows and columns of the item transition matrix represent the item out-degree and in-degree hopping behavior, which allows for modeling the user's short-term interests. When making incremental recommendations, only the input matrices need to be updated, without the need to update parameters, which makes AutoSeqRec very efficient. Comprehensive evaluations demonstrate that AutoSeqRec outperforms existing methods in terms of accuracy, while showcasing its robustness and efficiency.|顺序推荐通过建模用户的顺序行为来展示推荐项目的能力。传统方法通常将用户视为项目序列，忽略了它们之间的协作关系。基于图的方法利用用户-项目交互图来整合协作信息。然而，这些方法有时面临着时间复杂性和计算效率方面的挑战。为了解决这些局限性，本文提出了 AutoSeqRec，一个专门为顺序推荐任务设计的增量推荐模型。AutoSeqRec 基于自动编码器，在自动编码器体系结构中由一个编码器和三个解码器组成。这些组件同时考虑用户-项目交互矩阵和项目转移矩阵的行和列。用户-项目交互矩阵的重建通过协同过滤捕捉用户的长期偏好。此外，项目转移矩阵中的行和列表示项目的出度和内度跳跃行为，这允许对用户的短期兴趣进行建模。当进行增量建议时，只需要更新输入矩阵，而不需要更新参数，这使得 AutoSeqRec 非常高效。综合评估表明，AutoSeqRec 在准确性方面优于现有方法，同时展示了其健壮性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoSeqRec:+Autoencoder+for+Efficient+Sequential+Recommendation)|0|
|[MATA*: Combining Learnable Node Matching with A* Algorithm for Approximate Graph Edit Distance Computation](https://doi.org/10.1145/3583780.3614959)|Junfeng Liu, Min Zhou, Shuai Ma, Lujia Pan|Huawei Noah's Ark Lab, Shenzhen, China; Beihang University, Beijing, China|Graph Edit Distance (GED) is a general and domain-agnostic metric to measure graph similarity, widely used in graph search or retrieving tasks. However, the exact GED computation is known to be NP-complete. For instance, the widely used A* algorithms explore the entire search space to find the optimal solution which inevitably suffers scalability issues. Learning-based methods apply graph representation techniques to learn the GED by formulating a regression task, which can not recover the edit path and lead to inaccurate GED approximation (i.e., the predicted GED is smaller than the exact). To this end, in this work, we present a data-driven hybrid approach MATA* for approximate GED computation based on Graph Neural Networks (GNNs) and A* algorithms, which models from the perspective of learning to match nodes instead of directly regressing GED. Specifically, aware of the structure-dominant operations (i.e., node and edge insertion/deletion) property in GED computation, a structure-enhanced GNN is firstly designed to jointly learn local and high-order structural information for node embeddings for node matchings. Second, top-k candidate nodes are produced via a differentiable top-k operation to enable the training for node matchings, which is adhering to another property of GED, i.e., multiple optimal node matchings. Third, benefiting from the candidate nodes, MATA* only performs on the promising search directions, reaching the solution efficiently. Finally, extensive experiments show the superiority of MATA* as it significantly outperforms the combinatorial search-based, learning-based and hybrid methods and scales well to large-size graphs.|图形编辑距离(GED)是度量图形相似度的一种通用的领域不可知度量方法，广泛应用于图形搜索或检索任务中。然而，精确的 GED 计算是已知的 NP 完全的。例如，广泛使用的 A * 算法探索整个搜索空间，寻找不可避免地存在可伸缩性问题的最优解。基于学习的方法应用图表示技术，通过制定回归任务来学习 GED，回归任务不能恢复编辑路径并导致不精确的 GED 近似(即，预测的 GED 小于精确的 GED)。为此，本文提出了一种基于图神经网络(GNNs)和 A * 算法的数据驱动混合 MATA * 算法用于 GED 近似计算，该算法从学习匹配节点而不是直接回归 GED 的角度进行建模。针对 GED 计算中的结构主导操作(即节点和边插入/删除操作)特性，设计了一种结构增强的 GNN，用于联合学习节点嵌入的局部和高阶结构信息，实现节点匹配。其次，通过可微 top-k 操作生成 top-k 候选节点，从而实现节点匹配的训练，这符合 GED 的另一个特性，即多个最优节点匹配。第三，利用候选节点，MATA * 只执行有希望的搜索方向，有效地达到解决方案。最后，广泛的实验表明，MATA * 的优越性，因为它明显优于基于组合搜索，基于学习和混合方法和规模以及大型图。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MATA*:+Combining+Learnable+Node+Matching+with+A*+Algorithm+for+Approximate+Graph+Edit+Distance+Computation)|0|
|[Leveraging Event Schema to Ask Clarifying Questions for Conversational Legal Case Retrieval](https://doi.org/10.1145/3583780.3614953)|Bulou Liu, Yiran Hu, Qingyao Ai, Yiqun Liu, Yueyue Wu, Chenliang Li, Weixing Shen|Wuhan University, Wuhan, China; Tsinghua University, Quan Cheng Laboratory, & Tsinghua University, Beijing, China; Tsinghua University, Beijing, China|Legal case retrieval is a special IR task aiming to retrieve supporting cases for a given query case. Existing works have shown that conversational search paradigm can improve users' search experience in legal case retrieval. One of the keys to a practical conversational search system is how to ask high-quality clarifying questions to initiate conversations with users and understand their search intents. Recently, Large Language Models, such as ChatGPT and GPT-4, have shown superior ability in both open-domain QA and conversations with human. Thus it is natural to believe that they could be applied to legal conversational search as well. However, our preliminary study has shown that generating clarifying questions in legal conversational search with SOTA LLMs (e.g., GPT-4) often suffers from several problems such as duplication and low-utility contents. To address these problems, we propose LeClari, which leverages legal event schema as external knowledge to instruct LLMs to generate effective clarifying questions for legal conversational search. LeClari is constructed with a prompt module and a novel legal event selection module. The former defines a prompt with legal events for clarifying question generation and the latter selects potential event types by modeling the relationships of legal event types, conversational context, and candidate cases. We also propose ranking-oriented rewards and employ the reward augmented maximum likelihood (RAML) method to optimize LeClari directly based on the final retrieval performance of the conversational legal search system. Empirical results over two widely adopted legal case retrieval datasets demonstrate the effectiveness of our approach as compared with the state-of-the-art baselines.|法律案例检索是一项特殊的信息检索任务，旨在为给定的查询案例检索支持案例。已有的研究表明，会话搜索范式可以提高用户在法律案件检索中的搜索体验。实际会话搜索系统的关键问题之一是如何提出高质量的澄清性问题来启动与用户的对话并理解他们的搜索意图。最近，大型语言模型，如 ChatGPT 和 GPT-4，在开放领域的 QA 和与人类的对话方面表现出了卓越的能力。因此，很自然地认为，它们也可以应用于合法的会话搜索。然而，我们的初步研究表明，在使用 SOTA LLM (例如，GPT-4)进行法律会话搜索时，产生澄清问题常常会遇到重复和低效用内容等问题。为了解决这些问题，我们提出了 LeClari，它利用法律事件模式作为外部知识，指导 LLM 为法律会话搜索生成有效的澄清问题。LeClari 由一个提示模块和一个新的法律事件选择模块构成。前者定义了一个带有法律事件的提示符，用于说明问题的产生，后者通过建模法律事件类型、会话语境和候选案例之间的关系来选择潜在的事件类型。我们还提出了面向排序的奖励方法，并利用奖励增加的最大似然(RAML)方法直接根据会话法律搜索系统的最终检索性能对 LeClari 进行优化。通过两个广泛采用的法律案例检索数据集的实证结果表明，与最先进的基线相比，我们的方法是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Event+Schema+to+Ask+Clarifying+Questions+for+Conversational+Legal+Case+Retrieval)|0|
|[Diffusion Augmentation for Sequential Recommendation](https://doi.org/10.1145/3583780.3615134)|Qidong Liu, Fan Yan, Xiangyu Zhao, Zhaocheng Du, Huifeng Guo, Ruiming Tang, Feng Tian|Xi'an Jiaotong University, Xi'an, China; City University of Hong Kong, Hong Kong, Hong Kong; Huawei Noah's Ark Lab, Shenzhen, China; Xi'an Jiaotong University & City University of Hong Kong, Xi'an, China|Sequential recommendation (SRS) has become the technical foundation in many applications recently, which aims to recommend the next item based on the user's historical interactions. However, sequential recommendation often faces the problem of data sparsity, which widely exists in recommender systems. Besides, most users only interact with a few items, but existing SRS models often underperform these users. Such a problem, named the long-tail user problem, is still to be resolved. Data augmentation is a distinct way to alleviate these two problems, but they often need fabricated training strategies or are hindered by poor-quality generated interactions. To address these problems, we propose a Diffusion Augmentation for Sequential Recommendation (DiffuASR) for a higher quality generation. The augmented dataset by DiffuASR can be used to train the sequential recommendation models directly, free from complex training procedures. To make the best of the generation ability of the diffusion model, we first propose a diffusion-based pseudo sequence generation framework to fill the gap between image and sequence generation. Then, a sequential U-Net is designed to adapt the diffusion noise prediction model U-Net to the discrete sequence generation task. At last, we develop two guide strategies to assimilate the preference between generated and origin sequences. To validate the proposed DiffuASR, we conduct extensive experiments on three real-world datasets with three sequential recommendation models. The experimental results illustrate the effectiveness of DiffuASR. As far as we know, DiffuASR is one pioneer that introduce the diffusion model to the recommendation.|序贯推荐(SRS)已经成为许多应用程序的技术基础，其目的是根据用户的历史交互情况推荐下一个项目。然而，在推荐系统中，顺序推荐常常面临数据稀疏的问题。此外，大多数用户只与少数几个项目交互，但现有的 SRS 模型往往表现不佳。这样一个被称为长尾用户问题的问题仍有待解决。数据增强是缓解这两个问题的一种独特方式，但它们往往需要编造的培训策略，或者受到低质量生成的交互作用的阻碍。为了解决这些问题，我们提出了一种扩散增强的序列推荐(区分 ASR)为更高的质量生成。区分扩展数据集可以直接用于训练序列推荐模型，避免了复杂的训练过程。为了充分利用扩散模型的生成能力，我们首先提出了一种基于扩散的伪序列生成框架，以填补图像和序列生成之间的空白。然后，设计了一个序列 U-Net，使扩散噪声预测模型 U-Net 适应离散序列生成任务。最后，我们提出了两种引导策略来同化生成序列和起源序列之间的偏好。为了验证所提出的 DISUASR，我们使用三个连续的推荐模型在三个真实世界的数据集上进行了广泛的实验。实验结果表明了该方法的有效性。据我们所知，DISUASR 是将扩散模型引入推荐系统的先驱者之一。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion+Augmentation+for+Sequential+Recommendation)|0|
|[Deep Task-specific Bottom Representation Network for Multi-Task Recommendation](https://doi.org/10.1145/3583780.3614837)|Qi Liu, Zhilong Zhou, Gangwei Jiang, Tiezheng Ge, Defu Lian|University of Science and Technology of China, Hefei, China; Alibaba Group, Beijing, China|Neural-based multi-task learning (MTL) has gained significant improvement, and it has been successfully applied to recommendation system (RS). Recent deep MTL methods for RS (e.g. MMoE, PLE) focus on designing soft gating-based parameter-sharing networks that implicitly learn a generalized representation for each task. However, MTL methods may suffer from performance degeneration when dealing with conflicting tasks, as negative transfer effects can occur on the task-shared bottom representation. This can result in a reduced capacity for MTL methods to capture task-specific characteristics, ultimately impeding their effectiveness and hindering the ability to generalize well on all tasks. In this paper, we focus on the bottom representation learning of MTL in RS and propose the Deep Task-specific Bottom Representation Network (DTRN) to alleviate the negative transfer problem. DTRN obtains task-specific bottom representation explicitly by making each task has its own representation learning network in the bottom representation modeling stage. Specifically, it extracts the user's interests from multiple types of behavior sequences for each task through the parameter-efficient hypernetwork. To further obtain the dedicated representation for each task, DTRN refines the representation of each feature by employing a SENet-like network for each task. The two proposed modules can achieve the purpose of getting task-specific bottom representation to relieve tasks' mutual interference. Moreover, the proposed DTRN is flexible to combine with existing MTL methods. Experiments on one public dataset and one industrial dataset demonstrate the effectiveness of the proposed DTRN. Furthermore, we deploy DTRN in an industrial recommender system and gain remarkable improvements in multiple tasks.|基于神经网络的多任务学习(MTL)已经取得了显著的进步，并已成功地应用于推荐系统(RS)。最近的 RS 深层 MTL 方法(例如 MMoE，PLE)主要集中在设计基于软门控的参数共享网络，这种网络隐式地学习每个任务的通用表示。然而，MTL 方法在处理相互冲突的任务时可能会出现性能退化，因为任务共享的底层表示可能会受到负迁移效应的影响。这可能导致 MTL 方法捕获特定任务特征的能力下降，最终妨碍其有效性，并阻碍在所有任务中良好推广的能力。本文针对 RS 中 MTL 的底层表示学习问题，提出了基于深层任务的底层表示网络(DTRN)来解决负迁移问题。DTRN 通过在底层表示建模阶段使每个任务都有自己的表示学习网络，明确地获得任务特定的底层表示。具体来说，它通过参数有效的超网络从每个任务的多种类型的行为序列中提取用户的兴趣。为了进一步获得每个任务的专用表示，DTRN 通过为每个任务使用类似 SENet 的网络来改进每个特性的表示。这两个模块可以实现任务特定的底部表示，减少任务间的相互干扰。此外，提出的 DTRN 是灵活的结合现有的 MTL 方法。在一个公共数据集和一个工业数据集上的实验表明了所提出的 DTRN 方法的有效性。此外，我们在工业推荐系统部署 DTRN，并在多项任务中取得显著改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Task-specific+Bottom+Representation+Network+for+Multi-Task+Recommendation)|0|
|[Post-hoc Selection of Pareto-Optimal Solutions in Search and Recommendation](https://doi.org/10.1145/3583780.3615010)|Vincenzo Paparella, Vito Walter Anelli, Franco Maria Nardini, Raffaele Perego, Tommaso Di Noia|Politecnico di Bari, Bari, Italy; ISTI-CNR, Pisa, Italy|Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from computing a ranking of final results based on a single metric to multi-objective problems. Solving these problems leads to a set of Pareto-optimal solutions, known as Pareto frontier, in which no objective can be further improved without hurting the others. In principle, all the points on the Pareto frontier are potential candidates to represent the best model selected with respect to the combination of two, or more, metrics. To our knowledge, there are no well-recognized strategies to decide which point should be selected on the frontier. In this paper, we propose a novel, post-hoc, theoretically-justified technique, named "Population Distance from Utopia" (PDU), to identify and select the one-best Pareto-optimal solution from the frontier. In detail, PDU analyzes the distribution of the points by investigating how far each point is from its utopia point (the ideal performance for the objectives). The possibility of considering fine-grained utopia points allows PDU to select solutions tailored to individual user preferences, a novel feature we call "calibration". We compare PDU against existing state-of-the-art strategies through extensive experiments on tasks from both IR and RS. Experimental results show that PDU and combined with calibration notably impact the solution selection. Furthermore, the results show that the proposed framework selects a solution in a principled way, irrespective of its position on the frontier, thus overcoming the limits of other strategies.|信息检索(IR)和推荐系统(RS)任务正在从计算基于单一指标的最终结果排序过渡到多目标问题。解决这些问题导致一组帕累托最优解，称为帕累托边界，其中没有一个目标可以进一步改进而不损害其他目标。原则上，Pareto 前沿上的所有点都是潜在的候选者，可以代表就两个或更多指标的组合而选择的最佳模型。据我们所知，没有公认的战略来决定哪一点应该选择在前沿。本文提出了一种新的、事后的、理论证明的技术，称为“距离乌托邦的人口距离”(PDU) ，从前沿中识别和选择一个最佳的帕累托最优解。具体来说，PDU 通过调查每个点离它的乌托邦点(目标的理想性能)有多远来分析这些点的分布。考虑细粒度乌托邦点的可能性允许 PDU 选择适合个人用户偏好的解决方案，这个新特性我们称之为“校准”。通过对 IR 和 RS 任务的大量实验，我们比较了 PDU 和现有的最新策略。实验结果表明，PDU 和标定相结合对解决方案的选择有显著影响。此外，结果表明，所提出的框架以原则性的方式选择解决方案，而不考虑其在前沿的位置，从而克服了其他战略的局限性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post-hoc+Selection+of+Pareto-Optimal+Solutions+in+Search+and+Recommendation)|0|
|[MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking](https://doi.org/10.1145/3583780.3614964)|Shigang Quan, Hailong Tan, Shui Liu, Zhenzhe Zheng, Ruihao Zhu, Liangyue Li, Quan Lu, Fan Wu|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China; Cornell University, Ithaca, NY, USA|Online Travel Platforms (OTPs) have been working on improving their hotel Search & Ranking (S&R) systems that facilitate efficient matching between consumers and hotels. Existing OTPs focus on improving platform revenue. In this work, we take a first step in incorporating hotel merchants' objectives into the design of hotel S&R systems to achieve an incentive loop: the OTP tilts impressions and better-ranked positions to merchants with high service quality, and in return, the merchants provide better service to consumers. Three critical design challenges need to be resolved to achieve this incentive loop: Matthew Effect in the consumer feedback-loop, unclear relation between hotel service quality and performance, and conflicts between platform revenue and consumer experience. To address these challenges, we propose MERIT, a MERchant InceTive ranking model, which can simultaneously take the interests of merchants and consumers into account. We introduce information about the hotel service quality at the input-output level. At the input level, we incorporate factors of hotel service quality as features (as the underlying reasons for service quality), while at the output level, we introduce the metric Hotel Rating Score (HRS) as a label (as the evaluated outcome of service quality). Also, we design a monotonic structure for Merchant Tower to provide a clear relation between hotel quality and performance. Finally, we propose a Multi-objective Stratified Pairwise Loss, which can mitigate the conflicts between OTP's revenue and consumer experience. To demonstrate the effectiveness of MERIT, we compare our method with several state-of-the-art benchmarks. The offline experiment results indicate that MERIT outperforms these methods in optimizing the demands of consumers and merchants. Furthermore, we conduct an online A/B test and obtain an improvement of 3.02% for the HRS score. Based on these results, we have deployed MERIT online on Fliggy, one of the most popular OTPs in China, to serve tens of millions of consumers and hundreds of thousands of hotel merchants. To address these challenges, we propose MERIT, a MER chant I nceT ive ranking model, which can simultaneously take the interests of merchants and consumers into account. We introduce information about the hotel service quality at the input-output level. At the input level, we incorporate factors of hotel service quality as features (as the underlying reasons for service quality), while at the output level, we introduce the metric Hotel Rating Score (HRS) as a label (as the evaluated outcome of service quality). Also, we design a monotonic structure for Merchant Tower to provide a clear relation between hotel quality and performance. Finally, we propose a Multi-objective Stratified Pairwise Loss, which can mitigate the conflicts between OTP's revenue and consumer experience. To demonstrate the effectiveness of MERIT, we compare our method with several state-of-the-art benchmarks. The offline experiment results indicate that MERIT outperforms these methods in optimizing the demands of consumers and merchants. Furthermore, we conduct an online A/B test and obtain an improvement of 3.02% for the HRS score. Based on these results, we have deployed MERIT online on Fliggy, one of the most popular OTPs in China, to serve tens of millions of consumers and hundreds of thousands of hotel merchants.|在线旅游平台(OTP)一直致力于改进其酒店搜索和排名(S & R)系统，以促进消费者和酒店之间的有效匹配。现有的 OTP 侧重于提高平台收入。在这项工作中，我们首先将酒店商家的目标融入到酒店 S & R 系统的设计中，以实现激励循环: OTP 向服务质量较高的商家倾斜印象和排名较高的位置，作为回报，商家为消费者提供更好的服务。要实现这种激励回路，需要解决三个关键的设计难题: 消费者反馈回路中的马太效应、酒店服务质量与绩效之间的模糊关系以及平台收入与消费者体验之间的冲突。为了应对这些挑战，我们提出 MERIT，一个 MERchant InceTive 排名模型，它可以同时考虑商家和消费者的利益。我们从投入产出的角度介绍酒店服务质量的信息。在输入层面，我们将酒店服务质量的因素作为特征(作为服务质量的根本原因) ，而在输出层面，我们引入度量酒店评分(HRS)作为标签(作为评估服务质量的结果)。此外，我们设计了一个单调的结构商务大厦，以提供一个明确的关系，酒店质量和性能。最后，我们提出了一个多目标成对分层损失模型，它可以缓解 OTP 的收入和消费者体验之间的冲突。为了证明 MERIT 的有效性，我们将我们的方法与几个最先进的基准进行比较。离线实验结果表明，MERIT 在优化消费者和商家需求方面优于这些方法。此外，我们进行了在线 A/B 测试，HRS 得分提高了3.02% 。基于这些结果，我们在中国最受欢迎的 OTP 之一 Fliggy 上部署了 MERIT 在线服务，为数千万消费者和数十万酒店商家提供服务。为了应对这些挑战，我们提出了 MERIT 模型，这是一个可以同时考虑商家和消费者利益的 MER 商号排名模型。我们从投入产出的角度介绍酒店服务质量的信息。在输入层面，我们将酒店服务质量的因素作为特征(作为服务质量的根本原因) ，而在输出层面，我们引入度量酒店评分(HRS)作为标签(作为评估服务质量的结果)。此外，我们设计了一个单调的结构商务大厦，以提供一个明确的关系，酒店质量和性能。最后，我们提出了一个多目标成对分层损失模型，它可以缓解 OTP 的收入和消费者体验之间的冲突。为了证明 MERIT 的有效性，我们将我们的方法与几个最先进的基准进行比较。离线实验结果表明，MERIT 在优化消费者和商家需求方面优于这些方法。此外，我们进行了在线 A/B 测试，HRS 得分提高了3.02% 。基于这些结果，我们在中国最受欢迎的 OTP 之一 Fliggy 上部署了 MERIT 在线服务，为数千万消费者和数十万酒店商家提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MERIT:+A+Merchant+Incentive+Ranking+Model+for+Hotel+Search+&+Ranking)|0|
|[Enhancing Repeat-Aware Recommendation from a Temporal-Sequential Perspective](https://doi.org/10.1145/3583780.3614866)|Shigang Quan, Shui Liu, Zhenzhe Zheng, Fan Wu|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China|Repeat consumption, such as re-purchasing items and re-listening songs, is a common scenario in daily life. To model repeat consumption, the repeat-aware recommendation has been proposed to predict which item will be re-interacted based on the user-item interactions. In this paper, we investigate various inherent characteristics to enhance the performance of repeat-aware recommendation. Specifically, we explore these characteristics from two aspects: one is from the temporal aspect where we consider the time interval relationship in user behavior sequence; the other is from the sequential aspect where we consider the sequential-level relationship. Our intuition is that both thetemporal pattern andsequential pattern reflect users' intentions of repeat consumption. By utilizing these two patterns, a novel model called Temporal and Sequential repeat-aware Recommendation(TSRec for short) is proposed to enhance repeat-aware recommendation. TSRec has three main components: 1) User-specific Temporal Representation Module (UTRM), which encodes and extracts user historical repeat temporal information. 2) Item-specific Temporal Representation Module (ITRM), which incorporates item time interval information as side information to alleviate the data sparsity problem of user repeat behavior sequence. 3) Sequential Repeat-Aware Module (SRAM), which represents the similarity between user's current and the last repeat sequences. Extensive experimental results on three public benchmarks demonstrate the superiority of TSRec over state-of-the-art methods. The code is released online.|重复消费，例如重新购买物品和重新听歌，是日常生活中常见的情况。为了对重复消费进行建模，提出了基于重复感知的推荐方法来预测基于用户-项目交互的重复消费项目。为了提高重复感知推荐的性能，本文研究了重复感知推荐的各种内在特征。具体来说，我们从两个方面来探讨这些特征: 一个是从时间方面考虑用户行为序列中的时间间隔关系; 另一个是从序列方面考虑序列级关系。我们的直觉是，时间模式和序列模式都反映了用户的重复消费意图。利用这两种模式，提出了一种新的时序重复感知推荐(TSRec)模型来增强重复感知推荐。TSRec 主要由三部分组成: 1)用户特定时态表示模块(UTRM) ，对用户历史重复时态信息进行编码和提取。2)项目特定时间表示模块(ITRM) ，该模块将项目时间间隔信息作为侧信息，解决了用户重复行为序列的数据稀疏性问题。3)顺序重复感知模块(SRAM) ，表示用户当前重复序列与最后重复序列的相似性。在三个公共基准上的大量实验结果证明了 TSRec 相对于最先进的方法的优越性。代码已经在网上公布了。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Repeat-Aware+Recommendation+from+a+Temporal-Sequential+Perspective)|0|
|[ELTRA: An Embedding Method based on Learning-to-Rank to Preserve Asymmetric Information in Directed Graphs](https://doi.org/10.1145/3583780.3614862)|Masoud Reyhani Hamedani, JinSu Ryu, SangWook Kim|Hanyang University, Seoul, Republic of Korea|Double-vector embedding methods capture the asymmetric information in directed graphs first, and then preserve them in the embedding space by providingtwo latent vectors, i.e., source and target, per node. Although these methods are known to besuperior to the single-vector ones (i.e., providing asingle latent vector per node), wepoint out their three drawbacks as inability to preserve asymmetry on NU-paths, inability to preserve global nodes similarity, and impairing in/out-degree distributions. To address these, we first proposeCRW, anovel similarity measure for graphs that considers contributions ofboth in-links and out-links in similarity computation,without ignoring their directions. Then, we proposeELTRA, aneffective double-vector embedding method to preserve asymmetric information in directed graphs. ELTRA computesasymmetry preserving proximity scores (AP-scores) by employing CRW in which the contribution of out-links and in-links in similarity computation isupgraded anddowngraded, respectively. Then, for every node u, ELTRA selects its top-tclosest nodes based on AP-scores andconforms theranks of their corresponding target vectors w.r.t u's source vector in the embedding space to theiroriginal ranks. Our extensive experimental results withseven real-world datasets andsixteen embedding methods show that (1) CRWsignificantly outperforms Katz and RWR in computing nodes similarity in graphs, (2) ELTRAoutperforms the existing state-of-the-art methods in graph reconstruction, link prediction, and node classification tasks.|双向量嵌入方法首先捕获有向图中的不对称信息，然后通过每个节点提供源和目标两个潜在向量，将不对称信息保存在嵌入空间中。尽管这些方法已知优于单向量方法(即每个节点提供单个潜在向量) ，但我们指出了它们的三个缺点，即无法在 NU 路径上保持不对称性，无法保持全局节点相似性，以及损害/外度分布。为了解决这些问题，我们首先提出了 CRW，一种新的图的相似性度量，它考虑了相似性计算中的内链接和外链接的贡献，而没有忽略它们的方向。然后，我们提出了 ELTRA，一种有效的双向量嵌入方法来保持有向图中的不对称信息。ELTRA 通过使用 CRW 计算保持不对称性的邻近分数(AP 分数) ，其中外链和内链在相似性计算中的贡献分别被升级和降级。然后，对于每个节点 u，ELTRA 根据 AP 得分选择其最接近的节点，并将嵌入空间中相应的目标向量的排序与原始排序相一致。我们对7个实际数据集和16种嵌入方法的广泛实验结果表明: (1) CRW 在计算图中节点相似度方面明显优于 Katz 和 RWR; (2) ELTRAB 在图重构、链接预测和节点分类任务方面优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELTRA:+An+Embedding+Method+based+on+Learning-to-Rank+to+Preserve+Asymmetric+Information+in+Directed+Graphs)|0|
|[Periodicity May Be Emanative: Hierarchical Contrastive Learning for Sequential Recommendation](https://doi.org/10.1145/3583780.3615007)|Changxin Tian, Binbin Hu, Wayne Xin Zhao, Zhiqiang Zhang, Jun Zhou|Ant Group, Hangzhou, China; Renmin University of China, Beijing, China|Nowadays, contrastive self-supervised learning has been widely incorporated into sequential recommender systems. However, most existing contrastive sequential recommender systems simply emphasize the overall information of interaction sequences, thereby neglecting the special periodic patterns of user behavior. In this study, we propose that users exhibit emanative periodicity towards a group of correlated items, i.e., user behavior follow a certain periodic pattern while their interests may shift from one item to other related items over time. In light of this observation, we present a hierarchical contrastive learning framework to model EmAnative periodicity for SEquential Recommendation (referred to as EASE). Specifically, we design dual-channel contrastive strategy from the perspective of correlation and periodicity to capture emanative periodic patterns. Furthermore, we extend the traditional binary contrastive loss with hierarchical constraint to handle hierarchical contrastive samples, thus preserving the inherent hierarchical information of correlation and periodicity. Comprehensive experiments conducted on five datasets substantiate the effectiveness of our proposed EASE in improving sequential recommendation.|目前，对比自监督学习已广泛应用于顺序推荐系统中。然而，现有的对比序列推荐系统大多只强调交互序列的整体信息，而忽视了用户行为的特殊周期模式。在本研究中，我们提出使用者对一组相关项目表现出发射周期性，即使用者的兴趣可能随时间由一个项目转移至其他相关项目，使用者的行为仍遵循一定的周期性模式。根据这一观察，我们提出了一个层次对比学习框架来模拟顺序推荐的 EmAnative 周期性(简称 EASE)。具体来说，我们从相关性和周期性的角度设计了双通道对比策略来捕捉发射周期图案。在此基础上，将传统的具有层次约束的二进制对比度损失算法扩展到层次对比度样本的处理，从而保留了相关性和周期性的固有层次信息。在五个数据集上进行的综合实验证实了我们提出的 EASE 在改进顺序推荐方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Periodicity+May+Be+Emanative:+Hierarchical+Contrastive+Learning+for+Sequential+Recommendation)|0|
|[Diversity-aware Deep Ranking Network for Recommendation](https://doi.org/10.1145/3583780.3614848)|Zihong Wang, Yingxia Shao, Jiyuan He, Jinbao Liu, Shitao Xiao, Tao Feng, Ming Liu|Meituan Inc., Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|Diversity is a vital factor in recommendation systems.Improving the diversity in recommendations helps broaden users' horizons, bring good user experience and promote the enterprises' sales. In the past years, many efforts have been devoted to optimizing the diversity in the matching stage and the re-ranking stage of the recommendation system, but few in the ranking stage. The ranking stage is the intermediate stage of the recommendation system. Improving the diversity of the ranking stage can preserve the diversity of the matching stage, and provide a more diversified list for the re-ranking stage. Besides, the ranking models are able to achieve a better balance between accuracy and diversity. In this paper, we aim to improve the diversity in the ranking stage. To address the diversity challenges posed by the pointwise ranking model and biased user interaction history, we propose a Diversity-aware Deep Ranking Network by carefully designing two diversity-aware components that are diversity-aware listwise information fusion and balanced weighting loss. We conduct both offline and online experiments, and the results demonstrate that our proposed model effectively improves the recommendation diversity in the ranking stage while maintaining the accuracy. Moreover, the new model achieves 1.27%, 2.30% and 1.98% improvements in VBR, GMV and Coverage in Meituan, one of the world's largest E-commerce platforms.|多样性是推荐系统中的一个重要因素。提高推荐的多样性有助于拓宽用户的视野，带来良好的用户体验，促进企业的销售。近年来，在推荐系统的匹配阶段和重新排序阶段，人们致力于优化推荐系统的多样性，但在排序阶段却很少。排名阶段是推荐系统的中间阶段。提高排序阶段的多样性可以保持匹配阶段的多样性，为重排阶段提供更加多样化的列表。此外，排名模型能够在准确性和多样性之间取得更好的平衡。在本文中，我们的目标是提高排名阶段的多样性。针对逐点排序模型和有偏差的用户交互历史带来的多样性挑战，提出了一种多样性感知的深度排序网络，该网络通过精心设计两个多样性感知组件: 多样性感知列表信息融合和均衡加权损失。我们进行了离线和在线实验，结果表明，我们提出的模型有效地提高了排名阶段的推荐多样性，同时保持了准确性。此外，作为全球最大的电子商贸平台之一，新模式在视频比率、通用市场价格和美团覆盖率方面分别取得1.27% 、2.30% 和1.98% 的改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diversity-aware+Deep+Ranking+Network+for+Recommendation)|0|
|[Sentiment-aware Review Summarization with Personalized Multi-task Fine-tuning](https://doi.org/10.1145/3583780.3615056)|Hongyan Xu, Hongtao Liu, Zhepeng Lv, Qing Yang, Wenjun Wang|Tianjin University, Tianjin, China; Du Xiaoman Financial, Beijing, China|Personalized review summarization is a challenging task in recommender systems, which aims to generate condensed and readable summaries for product reviews. Recently, some methods propose to adopt the sentiment signals of reviews to enhance the review summarization. However, most previous works only share the semantic features of reviews via preliminary multi-task learning, while ignoring the rich personalized information of users and products, which is crucial to both sentiment identification and comprehensive review summarization. In this paper, we propose a sentiment-aware review summarization method with an elaborately designed multi-task fine-tuning framework to make full use of personalized information of users and products effectively based on Pretrained Language Models (PLMs). We first denote two types of personalized information including IDs and historical summaries to indicate their identification and semantics information respectively. Subsequently, we propose to incorporate the IDs of the user/product into the PLMs-based encoder to learn the personalized representations of input reviews and their historical summaries in a fine-tuning way. Based on this, an auxiliary context-aware review sentiment classification task and a further sentiment-guided personalized review summarization task are jointly learned. Specifically, the sentiment representation of input review is used to identify relevant historical summaries, which are then treated as additional semantic context features to enhance the summary generation process. Extensive experimental results show our approach could generate sentiment-consistent summaries and outperforms many competitive baselines on both review summarization and sentiment classification tasks.|在推荐系统中，个性化的评论摘要是一项具有挑战性的任务，它的目标是为产品评论生成简明易读的摘要。近年来，一些方法提出采用评论的情感信号来加强评论总结。然而，以往的研究大多只是通过初步的多任务学习来共享评论的语义特征，而忽略了用户和产品丰富的个性化信息，这对于情感识别和综合评论总结都是至关重要的。本文提出了一种基于预训练语言模型的情感感知评论摘要方法，该方法通过精心设计的多任务微调框架，有效地利用了用户和产品的个性化信息。我们首先表示两种类型的个性化信息，包括 ID 和历史汇总，分别表示它们的识别和语义信息。随后，我们建议将用户/产品的 ID 合并到基于 PLM 的编码器中，以微调的方式学习输入评论及其历史摘要的个性化表示。在此基础上，共同学习了一个辅助上下文感知的评论情感分类任务和一个进一步的情感引导的个性化评论摘要任务。具体来说，输入评论的情感表示被用来识别相关的历史摘要，然后将其作为额外的语义上下文特征来加强摘要的生成过程。广泛的实验结果表明，我们的方法可以产生情绪一致的摘要，并优于许多竞争基线审查摘要和情绪分类任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sentiment-aware+Review+Summarization+with+Personalized+Multi-task+Fine-tuning)|0|
|[A Two-tier Shared Embedding Method for Review-based Recommender Systems](https://doi.org/10.1145/3583780.3614770)|Zhen Yang, Junrui Liu, Tong Li, Di Wu, Shiqiu Yang, Huan Liu|Arizona State University, Tempe, AZ, USA; Beijing University of Technology, Beijing, China|Reviews are valuable resources that have been widely researched and used to improve the quality of recommendation services. Recent methods use multiple full embedding layers to model various levels of individual preferences, increasing the risk of the data sparsity issue. Although it is a potential way to deal with this issue that models homophily among users who have similar behaviors, the existing approaches are implemented in a coarse-grained way. They calculate user similarities by considering the homophily in their global behaviors but ignore their local behaviors under a specific context. In this paper, we propose a two-tier shared embedding model (TSE), which fuses coarse- and fine-grained ways of modeling homophily. It considers global behaviors to model homophily in a coarse-grained way, and the high-level feature in the process of each user-item interaction to model homophily in a fine-grained way. TSE designs a whole-to-part principle-based process to fuse these ways in the review-based recommendation. Experiments on five real-world datasets demonstrate that TSE significantly outperforms state-of-the-art models. It outperforms the best baseline by 20.50% on the root-mean-square error (RMSE) and 23.96% on the mean absolute error (MAE), respectively. The source code is available at https://github.com/dianziliu/TSE.git.|评论是有价值的资源，已被广泛研究和用于提高推荐服务的质量。最近的方法使用多个完整的嵌入层来模拟不同层次的个人偏好，增加了数据稀疏问题的风险。尽管在具有相似行为的用户之间建模同质性是解决这个问题的一种潜在方法，但是现有的方法都是以粗粒度的方式实现的。它们通过考虑全局行为中的同质性来计算用户相似性，但是忽略了特定环境下的局部行为。本文提出了一种两层共享嵌入模型(TSE) ，它融合了粗粒度和细粒度同构建模方法。它考虑了全局行为的粗粒度同质性建模，考虑了每个用户项交互过程中的高层次特征的细粒度同质性建模。TSE 设计了一个基于整体到部分原则的过程，将这些方法融合到基于评论的推荐中。在五个真实世界数据集上的实验表明，TSE 显著优于最先进的模型。它在均方根差(RMSE)和平均绝对误差(MAE)方面分别比最佳基线高出20.50% 和23.96% 。源代码可在 https://github.com/dianziliu/tse.git 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Two-tier+Shared+Embedding+Method+for+Review-based+Recommender+Systems)|0|
|[Improving Query Correction Using Pre-train Language Model In Search Engines](https://doi.org/10.1145/3583780.3614930)|Dezhi Ye, Bowen Tian, Jiabin Fan, Jie Liu, Tianhua Zhou, Xiang Chen, Mingming Li, Jin Ma|Tencent, Beijing, China|Query correction is a task that automatically detects and corrects errors in what users type into a search engine. Misspelled queries can lead to user dissatisfaction and churn. However, correcting a user query accurately is not an easy task. One major challenge is that a correction model must be capable of high-level language comprehension. Recently, pre-trained language models (PLMs) have been successfully applied to text correction tasks, but few works have been done on query correction. However, it is nontrivial to directly apply these PLMs to query correction in large-scale search systems due to the following challenging issues: 1) Expensive deployment. Deploying such a model requires expensive computations. 2) Lacking domain knowledge. A neural correction model needs massive training data to activate its power. To this end, we introduce KSTEM, a Knowledge-based Sequence To Edit Model for Chinese query correction. KSTEM transforms the sequence generation task into sequence tagging by mapping errors into five categories: KEEP, REPLACE, SWAP, DELETE, and INSERT, reducing computational complexity. Additionally, KSTEM adopts 2D position encoding, which is composed of the internal and external order of the words. Meanwhile, to compensate for the lack of domain knowledge, we propose a task-specific training paradigm for query correction, including edit strategy-based pre-training, user click-based post pre-train, and human label-based fine-tuning. Finally, we apply KSTEM to the industrial search system. Extensive offline and online experiments show that KSTEM significantly improves query correction performance. We hope that our experience will benefit frontier researchers.|查询纠正是一项自动检测和纠正用户在搜索引擎中输入的错误的任务。拼写错误的查询可能导致用户不满意和混乱。然而，准确地纠正用户查询并非易事。一个主要的挑战是，纠错模式必须能够高水平的语言理解。近年来，预训练语言模型(PLM)已经成功地应用于文本校正任务中，但在查询校正方面的研究还很少。然而，由于以下挑战性问题，直接应用这些 PLM 在大规模搜索系统中进行查询更正并非易事: 1)昂贵的部署。部署这样的模型需要昂贵的计算。2)缺乏领域知识。神经校正模型需要大量的训练数据来激活它的能量。为此，本文介绍了基于知识的汉语查询纠错序列编辑模型 KSTEM。KSTEM 通过将错误映射到 KEEP、 REPLACE、 SWAP、 DELETE 和 INSERT 五个类别，将序列生成任务转换为序列标记，降低了计算复杂度。此外，KSTEM 还采用了二维位置编码，由词的内部和外部顺序组成。同时，为了弥补领域知识的不足，本文提出了一种针对具体任务的查询修正训练范式，包括基于编辑策略的预训练、基于用户点击的后期预训练和基于人工标签的微调。最后，我们将 KSTEM 应用于产业搜索系统。大量的离线和在线实验表明，KSTEM 显著提高了查询纠错性能。我们希望我们的经验将有益于前沿研究人员。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Query+Correction+Using+Pre-train+Language+Model+In+Search+Engines)|0|
|[iHAS: Instance-wise Hierarchical Architecture Search for Deep Learning Recommendation Models](https://doi.org/10.1145/3583780.3614925)|Yakun Yu, Shiang Qi, Jiuding Yang, Liyao Jiang, Di Niu|University of Alberta, Edmonton, AB, Canada|Current recommender systems employ large-sized embedding tables with uniform dimensions for all features, leading to overfitting, high computational cost, and suboptimal generalizing performance. Many techniques aim to solve this issue by feature selection or embedding dimension search. However, these techniques typically select a fixed subset of features or embedding dimensions for all instances and feed all instances into one recommender model without considering heterogeneity between items or users. This paper proposes a novel instance-wise Hierarchical Architecture Search framework, iHAS, which automates neural architecture search at the instance level. Specifically, iHAS incorporates three stages: searching, clustering, and retraining. The searching stage identifies optimal instance-wise embedding dimensions across different field features via carefully designed Bernoulli gates with stochastic selection and regularizers. After obtaining these dimensions, the clustering stage divides samples into distinct groups via a deterministic selection approach of Bernoulli gates. The retraining stage then constructs different recommender models, each one designed with optimal dimensions for the corresponding group. We conduct extensive experiments to evaluate the proposed iHAS on two public benchmark datasets from a real-world recommender system. The experimental results demonstrate the effectiveness of iHAS and its outstanding transferability to widely-used deep recommendation models.|目前的推荐系统采用大型嵌入表，所有特征尺寸统一，导致拟合过度，计算成本高，泛化性能不理想。许多技术都是通过特征选择或嵌入维搜索来解决这一问题。然而，这些技术通常为所有实例选择固定的特性子集或嵌入维度，并将所有实例提供给一个推荐模型，而不考虑项目或用户之间的异构性。提出了一种新的实例级层次体系结构搜索框架 iHAS，该框架在实例级自动进行神经体系结构搜索。具体来说，iHAS 包括三个阶段: 搜索、集群和再培训。搜索阶段通过精心设计的带有随机选择和正则化子的伯努利门来确定不同场特征之间的最佳实例嵌入维数。在获得这些维度之后，聚类阶段通过贝努利门的确定性选择方法将样本划分为不同的组。然后再培训阶段构建不同的推荐模型，每个模型都为相应的群体设计了最优维度。我们进行了广泛的实验，以评估来自真实世界的两个公共基准数据集的 iHAS 推荐系统。实验结果表明了 iHAS 的有效性及其对广泛使用的深度推荐模型的突出可转移性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iHAS:+Instance-wise+Hierarchical+Architecture+Search+for+Deep+Learning+Recommendation+Models)|0|
|[Search Result Diversification Using Query Aspects as Bottlenecks](https://doi.org/10.1145/3583780.3615050)|Puxuan Yu, Razieh Rahimi, Zhiqi Huang, James Allan|University of Massachusetts Amherst, Amherst, USA|We address some of the limitations of coverage-based search result diversification models, which often consist of separate components and rely on external systems for query aspects. To overcome these challenges, we introduce an end-to-end learning framework called DUB. Our approach preserves the intrinsic interpretability of coverage-based methods while enhancing diversification performance. Drawing inspiration from the information bottleneck method, we propose an aspect extractor that generates query aspect embeddings optimized as information bottlenecks for the task of diversified document re-ranking. Experimental results demonstrate that DUB outperforms state-of-the-art diversification models.|我们解决了基于覆盖率的搜索结果多样化模型的一些局限性，这些模型通常由单独的组件组成，并依赖于外部系统进行查询。为了克服这些挑战，我们引入了一个名为 DUB 的端到端学习框架。我们的方法保留了基于覆盖的方法的内在可解释性，同时增强了多样化性能。从信息瓶颈方法的启发出发，提出了一种方面提取器，该方面提取器生成的查询方面嵌入作为信息瓶颈进行优化，用于多样化的文档重排任务。实验结果表明，DUB 的性能优于国家的最先进的多元化模式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search+Result+Diversification+Using+Query+Aspects+as+Bottlenecks)|0|
|[Attention Calibration for Transformer-based Sequential Recommendation](https://doi.org/10.1145/3583780.3614785)|Peilin Zhou, Qichen Ye, Yueqi Xie, Jingqi Gao, Shoujin Wang, Jae Boum Kim, Chenyu You, Sunghun Kim|The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Yale University, New Haven, CT, USA; The Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Upstage, Hong Kong, Hong Kong; University of Technology Sydney, Sydney, Australia; Peking University, Beijing, China|Transformer-based sequential recommendation (SR) has been booming in recent years, with the self-attention mechanism as its key component. Self-attention has been widely believed to be able to effectively select those informative and relevant items from a sequence of interacted items for next-item prediction via learning larger attention weights for these items. However, this may not always be true in reality. Our empirical analysis of some representative Transformer-based SR models reveals that it is not uncommon for large attention weights to be assigned to less relevant items, which can result in inaccurate recommendations. Through further in-depth analysis, we find two factors that may contribute to such inaccurate assignment of attention weights: sub-optimal position encoding and noisy input. To this end, in this paper, we aim to address this significant yet challenging gap in existing works. To be specific, we propose a simple yet effective framework called Attention Calibration for Transformer-based Sequential Recommendation (AC-TSR). In AC-TSR, a novel spatial calibrator and adversarial calibrator are designed respectively to directly calibrates those incorrectly assigned attention weights. The former is devised to explicitly capture the spatial relationships (i.e., order and distance) among items for more precise calculation of attention weights. The latter aims to redistribute the attention weights based on each item's contribution to the next-item prediction. AC-TSR is readily adaptable and can be seamlessly integrated into various existing transformer-based SR models. Extensive experimental results on four benchmark real-world datasets demonstrate the superiority of our proposed ACTSR via significant recommendation performance enhancements. The source code is available at https://github.com/AIM-SE/AC-TSR.|基于变压器的顺序推荐(SR)近年来兴起，自注意机制是其关键组成部分。人们普遍认为，自我注意能够有效地从一系列相互作用的项目中选择信息丰富的相关项目，通过学习这些项目的较大注意权重来进行下一个项目的预测。然而，这在现实中可能并不总是正确的。我们对一些有代表性的基于变压器的 SR 模型的实证分析表明，将大的注意力权重分配给相关性较低的项目并不罕见，这可能导致不准确的推荐。通过进一步的深入分析，我们发现了两个可能导致注意力权重分配不准确的因素: 次优位置编码和噪声输入。为此，在本文中，我们的目标是解决这一重大但具有挑战性的差距，在现有的工作。具体来说，我们提出了一个简单而有效的框架，称为基于变压器的顺序推荐注意力校正(AC-TSR)。在 AC-TSR 中，分别设计了一种新的空间校正器和对抗校正器，用于直接校正那些不正确分配的注意权重。前者旨在明确地捕捉项目之间的空间关系(即顺序和距离) ，以便更精确地计算注意力权重。后者的目的是重新分配注意权重的基础上，每个项目的贡献，下一个项目的预测。AC-TSR 很容易适应，可以无缝地集成到各种现有的基于变压器的 SR 模型中。在四个基准的真实世界数据集上的大量实验结果显示了我们提出的 ACTSR 通过显著的推荐性能增强的优越性。源代码可在 https://github.com/aim-se/ac-tsr 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attention+Calibration+for+Transformer-based+Sequential+Recommendation)|0|
|[HCL4QC: Incorporating Hierarchical Category Structures Into Contrastive Learning for E-commerce Query Classification](https://doi.org/10.1145/3583780.3614907)|Lvxing Zhu, Kexin Zhang, Hao Chen, Chao Wei, Weiru Zhang, Haihong Tang, Xiu Li|Tsinghua University, Shenzhen, China; Alibaba Group, Hangzhou, China|Query classification plays a crucial role in e-commerce, where the goal is to assign user queries to appropriate categories within a hierarchical product category taxonomy. However, existing methods rely on a limited number of words from the category description and often neglect the hierarchical structure of the category tree, resulting in suboptimal category representations. To overcome these limitations, we propose a novel approach named hierarchical contrastive learning framework for query classification (HCL4QC), which leverages the hierarchical category tree structure to improve the performance of query classification. Specifically, HCL4QC is designed as a plugin module that consists of two innovative losses, namely local hierarchical contrastive loss (LHCL) and global hierarchical contrastive loss (GHCL). LHCL adjusts representations of categories according to their positional relationship in the hierarchical tree, while GHCL ensures the semantic consistency between the parent category and its child categories. Our proposed method can be adapted to any query classification tasks that involve a hierarchical category structure. We conduct experiments on two real-world datasets to demonstrate the superiority of our hierarchical contrastive learning. The results demonstrate significant improvements in the query classification task, particularly for long-tail categories with sparse supervised information.|查询分类在电子商务中起着至关重要的作用，其目标是在分层的产品类别分类中将用户查询分配给适当的类别。然而，现有的方法仅仅依赖于类别描述中有限的词汇，往往忽略了类别树的层次结构，导致了类别表示的次优化。为了克服这些局限性，提出了一种新的查询分类层次对比学习框架(HCL4QC) ，该框架利用层次分类树结构来提高查询分类的性能。具体来说，HCL4QC 被设计成一个插件模块，由两个创新性的损失组成，即局部层次对比损失(LHCL)和全局层次对比损失(GHCL)。LHCL 根据类别在层次树中的位置关系来调整类别的表示，而 GHCL 保证了父类别与其子类别之间的语义一致性。该方法适用于任何涉及层次分类结构的查询分类任务。我们在两个真实世界的数据集上进行了实验，以验证我们的分层对比学习的优越性。实验结果表明，该算法在查询分类任务方面有明显的改进，特别是对于监督信息稀疏的长尾类别。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HCL4QC:+Incorporating+Hierarchical+Category+Structures+Into+Contrastive+Learning+for+E-commerce+Query+Classification)|0|
|[Non-Recursive Cluster-Scale Graph Interacted Model for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615180)|Yuanchen Bei, Hao Chen, Shengyuan Chen, Xiao Huang, Sheng Zhou, Feiran Huang|Jinan University, Guangzhou, China; The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Zhejiang University, Hangzhou, China|Extracting users' interests from their behavior, particularly their 1-hop neighbors, has been shown to enhance Click-Through Rate (CTR) prediction performance. However, online recommender systems impose strict constraints on the inference time of CTR models, which necessitates pruning or filtering users' 1-hop neighbors to reduce computational complexity. Furthermore, while the graph information of users and items has been proven effective in collaborative filtering models, recursive graph convolution can be computationally costly and expensive to implement. To address these challenges, we propose the Non-Recursive Cluster-scale Graph Interacted (NRCGI) model, which reorganizes graph convolutional networks in a non-recursive and cluster-scale view to enable CTR models to consider deep graph information with low computational cost. NRCGI employs non-recursive cluster-scale graph aggregation, which allows the online recommendation computational complexity to shrink from tens of thousands of items to tens to hundreds of clusters. Additionally, since NRCGI aggregates neighbors in a non-recursive view, each hop of neighbors has a clear physical meaning. NRCGI explicitly constructs meaningful interactions between the hops of neighbors of users and items to fully model users' intent towards the given item. Experimental results demonstrate that NRCGI outperforms state-of-the-art baselines in three public datasets and one industrial dataset while maintaining efficient inference.|从用户的行为中提取他们的兴趣，特别是他们的一跳邻居，已经被证明可以提高点进率(CTR)预测性能。然而，在线推荐系统对 CTR 模型的推理时间有严格的限制，为了降低计算复杂度，需要对用户的1跳邻居进行剪枝或过滤。此外，虽然用户和项目的图形信息已被证明在协同过滤模型中是有效的，递归图形卷积可能在计算上是昂贵的，实现起来也是昂贵的。为了解决这些挑战，我们提出了非递归聚类尺度图交互(NRCGI)模型，该模型以非递归和聚类尺度视图重新组织图卷积网络，以使 CTR 模型能够以低计算成本考虑深层图信息。NRCGI 采用非递归聚类规模的图聚合技术，使在线推荐计算复杂度从几万个项目减少到几十到几百个聚类。此外，由于 NRCGI 以非递归视图的形式聚合邻居，因此邻居的每个跃点都有明确的物理意义。NRCGI 显式地在用户和项目的邻居之间构造有意义的交互，以充分模拟用户对给定项目的意图。实验结果表明，在保持有效推理的同时，NRCGI 在三个公共数据集和一个工业数据集中的表现优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-Recursive+Cluster-Scale+Graph+Interacted+Model+for+Click-Through+Rate+Prediction)|0|
|[SAFE: Sequential Attentive Face Embedding with Contrastive Learning for Deepfake Video Detection](https://doi.org/10.1145/3583780.3615279)|Juho Jung, Chaewon Kang, Jeewoo Yoon, Simon S. Woo, Jinyoung Han|Raondata, Seoul, Republic of Korea; Sungkyunkwan University, Seoul, Republic of Korea; Sungkyunkwan University, Suwon, Republic of Korea|The emergence of hyper-realistic deepfake videos has raised significant concerns regarding their potential misuse. However, prior research on deepfake detection has primarily focused on image-based approaches, with little emphasis on video. With the advancement of generation techniques enabling intricate and dynamic manipulation of entire faces as well as specific facial components in a video sequence, capturing dynamic changes in both global and local facial features becomes crucial in detecting deepfake videos. This paper proposes a novel sequential attentive face embedding, SAFE, that can capture facial dynamics in a deepfake video. The proposed SAFE can effectively integrate global and local dynamics of facial features revealed in a video sequence using contrastive learning. Through a comprehensive comparison with the state-of-the-art methods on the DFDC (Deepfake Detection Challenge) dataset and the FaceForensic++ benchmark, we show that our model achieves the highest accuracy in detecting deepfake videos on both datasets.|超真实的深度假视频的出现引起了人们对其潜在滥用的严重关切。然而，先前对深度伪造检测的研究主要集中在基于图像的方法上，对视频的研究很少。随着生成技术的进步，可以对视频序列中的整个面部以及特定的面部组件进行复杂和动态的操作，捕捉全局和局部面部特征的动态变化成为检测深度伪造视频的关键。提出了一种新的序列注意人脸嵌入方法 SAFE，该方法可以在深度伪造视频中捕获人脸动态特征。该方法利用对比学习，有效地整合了视频序列中人脸特征的全局和局部动态特征。通过全面比较 DFDC 数据集和 FaceForensic + + 基准上的最新方法，我们表明我们的模型在两个数据集上检测深度伪造视频时达到了最高的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAFE:+Sequential+Attentive+Face+Embedding+with+Contrastive+Learning+for+Deepfake+Video+Detection)|0|
|[Can Embeddings Analysis Explain Large Language Model Ranking?](https://doi.org/10.1145/3583780.3615225)|Claudio Lucchese, Giorgia Minello, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Alberto Veneri|Università Ca' Foscari Venezia, Venice, Italy; Ca' Foscari University of Venice, Venice, Italy; Institute of Information Science and Technologies "Alessandro Faedo" - National Research Council of Italy, Pisa, Italy; Ca' Foscari University of Venice & Institute of Information Science and Technologies, Venice, Italy|Understanding the behavior of deep neural networks for Information Retrieval (IR) is crucial to improve trust in these effective models. Current popular approaches to diagnose the predictions made by deep neural networks are mainly based on: i) the adherence of the retrieval model to some axiomatic property of the IR system, ii) the generation of free-text explanations, or iii) feature importance attributions. In this work, we propose a novel approach that analyzes the changes of document and query embeddings in the latent space and that might explain the inner workings of IR large pre-trained language models. In particular, we focus on predicting query/document relevance, and we characterize the predictions by analyzing the topological arrangement of the embeddings in their latent space and their evolution while passing through the layers of the network. We show that there exists a link between the embedding adjustment and the predicted score, based on how tokens cluster in the embedding space. This novel approach, grounded in the query and document tokens interplay over the latent space, provides a new perspective on neural ranker explanation and a promising strategy for improving the efficiency of the models and Query Performance Prediction (QPP).|理解信息检索深层神经网络的行为对于提高人们对这些有效模型的信任至关重要。目前流行的诊断深度神经网络预测的方法主要基于: i)检索模型对 IR 系统的某些公理化特性的依从性，ii)自由文本解释的生成，或 iii)特征重要性归属。在这项工作中，我们提出了一种新的方法，分析文档和查询嵌入的变化，在潜在的空间，这可能解释了内部工作的信息检索大型预训练语言模型。特别地，我们侧重于预测查询/文档的相关性，并且通过分析嵌入在其潜在空间中的拓扑排列以及它们在通过网络层时的演化来刻画预测的特征。基于标记在嵌入空间中的聚类，我们证明了嵌入调整和预测得分之间存在联系。该方法基于查询和文档标记在潜在空间上的相互作用，为神经排序解释提供了一个新的视角，为提高模型效率和查询性能预测(QPP)提供了一种有前途的策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Embeddings+Analysis+Explain+Large+Language+Model+Ranking?)|0|
|[A Self-Learning Resource-Efficient Re-Ranking Method for Clinical Trials Search](https://doi.org/10.1145/3583780.3615174)|Maciej Rybinski, Vincent Nguyen, Sarvnaz Karimi|CSIRO, Sydney, Australia|Complex search scenarios, such as those in biomedical settings, can be challenging. One such scenario is matching a patient's profile to relevant clinical trials. There are multiple criteria that should match for a document (clinical trial) to be considered relevant to a query (patient's profile represented with an admission note). While different neural ranking methods have been proposed for searching clinical trials, resource-efficient approaches to ranker training are less studied. A resource-efficient method uses training data in moderation. We propose a self-learning reranking method that achieves results comparable to those of more complicated, fully supervised, systems. Our experiments demonstrate our method's robustness and competitiveness compared to the state-of-the-art approaches in clinical trial search.|复杂的搜索场景，例如在生物医学环境中，可能是具有挑战性的。其中一种情况是将患者的特征与相关的临床试验相匹配。有多个标准，应该匹配的文件(临床试验)被认为是相关的查询(病人的配置文件代表入院说明)。虽然不同的神经排序方法已被提出搜索临床试验，资源效率的方法排序训练的研究较少。一种节约资源的方法适度使用训练数据。我们提出了一种自学习重新排序的方法，实现的结果相当于那些更复杂的，完全监督的系统。我们的实验证明了我们的方法的稳健性和竞争力相比，在临床试验搜索的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Self-Learning+Resource-Efficient+Re-Ranking+Method+for+Clinical+Trials+Search)|0|
|[Efficient Multi-Task Learning via Generalist Recommender](https://doi.org/10.1145/3583780.3615229)|Luyang Wang, Cangcheng Tang, Chongyang Zhang, Jun Ruan, Kai Huang, Jason Jinquan Dai|Verizon, Basking Ridge, NJ, USA; Verizon, Alpharetta, GA, USA; Intel Corporation, Santa Clara, CA, USA; Verizon, Boston, MA, USA|Multi-task learning (MTL) is a common machine learning technique that allows the model to share information across different tasks and improve the accuracy of recommendations for all of them. Many existing MTL implementations suffer from scalability issues as the training and inference performance can degrade with the increasing number of tasks, which can limit production use case scenarios for MTL-based recommender systems. Inspired by the recent advances of large language models, we developed an end-to-end efficient and scalable Generalist Recommender (GRec). GRec takes comprehensive data signals by utilizing NLP heads, parallel Transformers, as well as a wide and deep structure to process multi-modal inputs. These inputs are then combined and fed through a newly proposed task-sentence level routing mechanism to scale the model capabilities on multiple tasks without compromising performance. Offline evaluations and online experiments show that GRec significantly outperforms our previous recommender solutions. GRec has been successfully deployed on one of the largest telecom websites and apps, effectively managing high volumes of online traffic every day.|多任务学习(Multi-Task Learning，MTL)是一种常见的机器学习技术，它允许模型在不同的任务之间共享信息，并提高对所有任务的推荐的准确性。许多现有的 MTL 实现都存在可伸缩性问题，因为培训和推理性能可能随着任务数量的增加而下降，这可能会限制基于 MTL 的推荐系统的生产用例场景。受到大型语言模型最新进展的启发，我们开发了一个端到端高效且可扩展的通用推荐程序(Generalist Revimender，GRec)。GRec 利用自然语言处理(NLP)磁头、并联变压器以及广泛而深入的结构来处理多模态输入，从而获得全面的数据信号。然后，这些输入通过新提出的任务句子级路由机制进行组合和馈送，以在不影响性能的情况下扩展多任务的模型能力。脱机评估和在线实验表明，GRec 明显优于我们以前的推荐解决方案。GREc 已成功部署在世界上最大的电信网站和应用程序之一上，有效地管理了每天大量的在线流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Multi-Task+Learning+via+Generalist+Recommender)|0|
|[MTKDN: Multi-Task Knowledge Disentanglement Network for Recommendation](https://doi.org/10.1145/3583780.3615271)|Haotian Wu, Bowen Xing, Ivor W. Tsang|CFAR, Agency for Science, Technology and Research & IHPC, Agency for Science, Technology and Research, Singapore, Singapore; Beijing Jiaotong University, CFAR, Agency for Science, Technology and Research, & IHPC, Agency for Science, Technology and Research, Beijing, China; University of Technology Sydney, CFAR, Agency for Science, Technology and Research, & IHPC, Agency for Science, Technology and Research, Sydney, NSW, Australia|Multi-task learning (MTL) is a widely adopted machine learning paradigm in recommender systems. However, existing MTL models often suffer from performance degeneration with negative transfer and seesaw phenomena. Some works attempt to alleviate the negative transfer and seesaw issues by separating task-specific and shared experts to mitigate the harmful interference between task-specific and shared knowledge. Despite the success of these efforts, task-specific and shared knowledge have still not been thoroughly decoupled. There may still exist unnecessary mixture between the shared and task-specific knowledge, which may harm MLT models' performances. To tackle this problem, in this paper, we propose multi-task knowledge disentanglement network (MTKDN) to further reduce harmful interference between the shared and task-specific knowledge. Specifically, we propose a novel contrastive disentanglement mechanism to explicitly decouple the shared and task-specific knowledge in corresponding hidden spaces. In this way, the unnecessary mixture between shared and task-specific knowledge can be reduced. As for optimization objectives, we propose individual optimization objectives for shared and task-specific experts, by which we can encourage these two kinds of experts to focus more on extracting the shared and task-specific knowledge, respectively. Additionally, we propose a margin regularization to ensure that the fusion of shared and task-specific knowledge can outperform exploiting either of them alone. We conduct extensive experiments on open-source large-scale recommendation datasets. The experimental results demonstrate that MTKDN significantly outperforms state-of-the-art MTL models. In addition, the ablation experiments further verify the necessity of our proposed contrastive disentanglement mechanism and the novel loss settings.|多任务学习(MTL)是推荐系统中广泛采用的机器学习范式。然而，现有的 MTL 模型往往遭受性能退化的负转移和跷跷板现象。有些作品试图通过将具体任务专家和共享专家分开来缓解负面转移和跷跷板问题，以减轻具体任务专家和共享知识之间的有害干扰。尽管这些努力取得了成功，但特定任务和共享知识仍然没有完全解耦。共享知识和特定任务知识之间可能仍然存在不必要的混合，这可能会损害 MLT 模型的性能。为了解决这一问题，本文提出了多任务知识解缠网络(MTKDN) ，以进一步减少共享知识和特定任务知识之间的有害干扰。具体来说，我们提出了一种新的对比解缠机制，以显式解耦共享和任务特定的知识在相应的隐藏空间。通过这种方式，可以减少共享知识和特定任务知识之间不必要的混合。对于优化目标，我们提出了共享专家和任务特定专家的个体优化目标，通过这些目标可以鼓励这两类专家更多地关注共享知识和任务特定知识的提取。此外，我们提出了一个边际正则化，以确保融合共享和任务特定的知识可以胜过利用任何一个单独。我们在开源的大规模推荐数据集上进行了广泛的实验。实验结果表明，MTKDN 的性能明显优于最先进的 MTL 模型。此外，烧蚀实验进一步验证了我们提出的对比解缠机制和新型损耗设置的必要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MTKDN:+Multi-Task+Knowledge+Disentanglement+Network+for+Recommendation)|0|
|[FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for CTR Prediction](https://doi.org/10.1145/3583780.3615242)|Pengtao Zhang, Zheng Zheng, Junlin Zhang|Brandeis University, Waltham, MA, USA; Sina Weibo, Beijing, China|Click-Through Rate (CTR) estimation has become one of the most fundamental tasks in many real-world applications and various deep models have been proposed. Some research has proved that FiBiNet is one of the best performance models and outperforms all other models on Avazu dataset. However, the large model size of FiBiNet hinders its wider application. In this paper, we propose a novel FiBiNet++ model to redesign FiBiNet's model structure, which greatly reduces model size while further improves its performance. One of the primary techniques involves our proposed "Low Rank Layer" focused on feature interaction, which serves as a crucial driver of achieving a superior compression ratio for models. Extensive experiments on three public datasets show that FiBiNet++ effectively reduces non-embedding model parameters of FiBiNet by 12x to 16x on three datasets. On the other hand, FiBiNet++ leads to significant performance improvements compared to state-of-the-art CTR methods, including FiBiNet. The source code is in https://github.com/recommendation-algorithm/FiBiNet.|点进率估计已经成为现实应用中最基本的任务之一，各种深度模型已经被提出。一些研究已经证明，FiBiNet 是最好的性能模型之一，在 Avazu 数据集上优于所有其他模型。然而，FiBiNet 的大型模型阻碍了它的广泛应用。本文提出了一种新的 FiBiNet + + 模型，重新设计了 FiBiNet 的模型结构，大大减小了模型尺寸，进一步提高了性能。其中一个主要的技术涉及我们提出的“低等级层”，重点是功能交互，这是一个关键的驱动器，以实现一个优越的压缩比模型。在三个公共数据集上进行的大量实验表明，FiBiNet + + 在三个数据集上有效地将 FiBiNet 的非嵌入模型参数减少了12 ~ 16倍。另一方面，与包括 FiBiNet 在内的最先进的 CTR 方法相比，FiBiNet + + 带来了显著的性能改进。源代码在 https://github.com/recommendation-algorithm/fibinet 里。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FiBiNet++:+Reducing+Model+Size+by+Low+Rank+Feature+Interaction+Layer+for+CTR+Prediction)|0|
|[Learning To Rank Diversely At Airbnb](https://doi.org/10.1145/3583780.3614692)|Malay Haldar, Mustafa Abdool, Liwei He, Dillon Davis, Huiji Gao, Sanjeev Katariya|Airbnb, Inc., San Francisco, CA, USA; Airbnb, Inc., San Jose, CA, USA; Airbnb, Inc., Cupertino, CA, USA; Airbnb, Inc., Seattle, WA, USA; Airbnb, Inc., Sunnyvale, CA, USA|Airbnb is a two-sided marketplace, bringing together hosts who own listings for rent, with prospective guests from around the globe. Applying neural network-based learning to rank techniques has led to significant improvements in matching guests with hosts. These improvements in ranking were driven by a core strategy: order the listings by their estimated booking probabilities, then iterate on techniques to make these booking probability estimates more and more accurate. Embedded implicitly in this strategy was an assumption that the booking probability of a listing could be determined independently of other listings in search results. In this paper we discuss how this assumption, pervasive throughout the commonly-used learning to rank frameworks, is false. We provide a theoretical foundation correcting this assumption, followed by efficient neural network architectures based on the theory. Explicitly accounting for possible similarities between listings, and reducing them to diversify the search results generated strong positive impact. We discuss these metric wins as part of the online A/B tests of the theory. Our method provides a practical way to diversify search results for large-scale production ranking systems.|Airbnb 是一个双面市场，汇集了拥有出租房源的房东，以及来自世界各地的潜在客户。将基于神经网络的学习应用于排序技术已经导致了客户与主机匹配方面的重大改进。排名方面的这些改进是由一个核心策略驱动的: 根据预订概率的估计对列表进行排序，然后迭代技术，使这些预订概率估计越来越准确。该策略隐含的假设是，一个列表的预订概率可以独立于搜索结果中的其他列表来确定。在本文中，我们将讨论这个贯穿于常用的对框架进行排序的学习过程中的假设是如何错误的。我们提供了一个理论基础，纠正这一假设，其次是有效的神经网络架构的基础上的理论。明确说明列表之间可能存在的相似之处，并减少列表数量以使搜索结果多样化，产生了强有力的积极影响。我们讨论这些度量胜利作为在线 A/B 理论测试的一部分。该方法为大规模生产排序系统提供了一种实用的搜索结果多样化方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+To+Rank+Diversely+At+Airbnb)|0|
|[Dynamic Group Parameter Modeling for Click-Through-Rate Prediction](https://doi.org/10.1145/3583780.3615471)|Xuan Ma, Jian Wang, Zhiyuan Chen, Zehua Zhang, Jie He, Changping Peng, Zhangang Lin, Jingping Shao|JD.com, Beijing, China|It is noted that Click-Through-Rate(CTR) prediction plays an important part in recommendation systems and online advertising. Over the past few years, numerous studies have been conducted to improve the accuracy of CTR prediction by exploring data inherent patterns. These studies indicate that training CTR models with group-specific parameters on divided data groups can lead to significant improvements. However, most works generally divide groups manually with some prior knowledge, and such a fixed group division method may hinder the expression of user common interests. To address this limitation, we propose a novel group parameter modeling method, where the user group division and group parameter learning processes are completed in an automatic and dynamic way. Our method employs a three-stage approach, consisting of group information selection, group representation learning, and group parameter generation, which allows the efficient expression of user common interests. We conduct experiments on both public datasets and industrial datasets, and the experimental results demonstrate the effectiveness of our method. We have also deployed the model in an online advertising system and observed significant improvements in both CTR and Revenue Per Mille (RPM).|点击率(CTR)预测在推荐系统和在线广告中起着重要作用。在过去的几年中，通过探索数据固有的模式，已经进行了大量的研究来提高 CTR 预测的准确性。这些研究表明，在分组的数据组上训练具有组特定参数的 CTR 模型可以导致显著的改进。然而，大多数工作一般都是利用一定的先验知识进行人工分组，这种固定的分组方法可能会阻碍用户共同兴趣的表达。针对这一局限性，提出了一种新的组参数建模方法，用户组划分和组参数学习过程可以自动动态地完成。我们的方法采用了三个阶段的方法，包括群体信息选择、群表示论学习和群体参数生成，这样可以有效地表达用户的共同兴趣。我们在公共数据集和工业数据集上进行了实验，实验结果表明了该方法的有效性。我们还在一个在线广告系统中部署了该模型，并观察到在点击率和每公里收入(RPM)方面的显著改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Group+Parameter+Modeling+for+Click-Through-Rate+Prediction)|0|
|[Practice on Effectively Extracting NLP Features for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3614707)|Hao Yang, Ziliang Wang, Weijie Bian, Yifan Zeng|Shopee Discovery Ads, Beijing, China|Click-through rate (CTR) prediction is critical for industrial applications such as recommendation system and online advertising. Practically, there are a series of research proved that Natural Language Processing (NLP) features are helpful to improve CTR task performance. As these works show, there are different ways to extract NLP features. For example, keywords of item title are extracted as open-box feature by term frequency?inverse document frequency (tf-idf) method while item semantic embedding is extracted as black-box feature by shallow models (\emphe.g., word2vec) or deep learning models (e.g., BERT). However, these NLP models are pre-trained on NLP task, which is very different from the CTR task. Then it leads to the limited improvement of Area Under the ROC Curve (AUC) in CTR task. On the other hand, traditional NLP models for CTR task only consider open-box feature or black-box feature separately, which also leads to the discounted effect. Lastly, many NLP models are mainly used to extract semantic features only on item side. These methods take little account of user side information, or only IDs related features (\emphe.g., item's IDs) in user behavior sequence are introduced. In our work, we proposed a new network named BERT Attention method based on both Item and User information (BAIU). The target of BAIU is consistent with the CTR task, which is helpful to extract more effective NLP features. Also, both open-box and black-box features are simultaneously extracted by this network, which makes the model to learn more useful NLP features for CTR task and also makes the model more interpretable. Extensive experiments on both public data and our commercial data validate the effectiveness of our approach. Finally, the online experiment brings 2.2% gain of CTR on recommendation.|对于推荐系统和在线广告等工业应用而言，点进率(ctrl)预测至关重要。实践证明，自然语言处理(NLP)特性有助于提高 CTR 任务性能。正如这些工作所显示的，有不同的方法提取自然语言处理特征。例如，项目标题的关键词通过词频-逆文档频率(tf-idf)方法提取为开箱特征，而项目语义嵌入通过浅层模型(word2vec)或深层学习模型(BERT)提取为黑箱特征。然而，这些自然语言处理模型是在自然语言处理任务上进行预训练的，这与 CTR 任务有很大的不同。然后，它导致 ROC 曲线下面积(aUC)在 CTR 任务中的有限改进。另一方面，传统的点击率任务自然语言处理模型只考虑开箱特征和黑箱特征，这也导致了模型的折现效应。最后，许多自然语言处理模型主要用于仅在项目一侧提取语义特征。这些方法很少考虑用户端信息，或者只引入用户行为序列中与 ID 相关的特征(例如，项的 ID)。在我们的工作中，我们提出了一种新的基于项目和用户信息(BAIU)的网络方法—— BERT 注意方法。BAIU 的目标与 CTR 任务一致，有助于提取更有效的自然语言处理特征。该网络同时提取了开箱特征和黑箱特征，使模型学习到更多有用的自然语言处理特征，使模型更具可解释性。对公共数据和我们的商业数据的大量实验验证了我们的方法的有效性。最后，在线实验给推荐带来了2.2% 的点击率增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practice+on+Effectively+Extracting+NLP+Features+for+Click-Through+Rate+Prediction)|0|
|[DiscoverPath: A Knowledge Refinement and Retrieval System for Interdisciplinarity on Biomedical Research](https://doi.org/10.1145/3583780.3614739)|YuNeng Chuang, Guanchu Wang, ChiaYuan Chang, KweiHerng Lai, Daochen Zha, Ruixiang Tang, Fan Yang, Alfredo CostillaReyes, Kaixiong Zhou, Xiaoqian Jiang, Xia Hu|UTHealth at Houston, Houston, TX, USA; Texas A&M University, College Station, TX, USA; Rice University, Houston, TX, USA|The exponential growth in scholarly publications necessitates advanced tools for efficient article retrieval, especially in interdisciplinary fields where diverse terminologies are used to describe similar research. Traditional keyword-based search engines often fall short in assisting users who may not be familiar with specific terminologies. To address this, we present a knowledge graph-based paper search engine for biomedical research to enhance the user experience in discovering relevant queries and articles. The system, dubbed DiscoverPath, employs Named Entity Recognition (NER) and part-of-speech (POS) tagging to extract terminologies and relationships from article abstracts to create a KG. To reduce information overload, DiscoverPath presents users with a focused subgraph containing the queried entity and its neighboring nodes and incorporates a query recommendation system, enabling users to iteratively refine their queries. The system is equipped with an accessible Graphical User Interface that provides an intuitive visualization of the KG, query recommendations, and detailed article information, enabling efficient article retrieval, thus fostering interdisciplinary knowledge exploration. DiscoverPath is open-sourced at https://github.com/ynchuang/DiscoverPath.|学术出版物的指数增长需要先进的工具来进行有效的文章检索，特别是在跨学科领域，在这些领域中，不同的术语被用来描述类似的研究。传统的基于关键字的搜索引擎往往不能帮助那些可能不熟悉特定术语的用户。为了解决这个问题，我们提供了一个基于知识图表的生物医学研究纸质搜索引擎，以增强用户发现相关查询和文章的体验。这个名为 Discover Path 的系统使用命名实体识别(NER)和词性标签(POS)从文章摘要中提取术语和关系来创建 KG。为了减少信息超载，Discover Path 为用户提供了一个包含被查询实体及其邻近节点的聚焦子图，并结合了一个查询推荐系统，使用户能够迭代地完善他们的查询。该系统配备了一个易于使用的图形用户界面，可以直观地显示幼稚园、查询建议和详细的文章信息，从而提供有效的文章检索，从而促进跨学科的知识探索。发现路径在 https://github.com/ynchuang/DiscoverPath 是开源的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiscoverPath:+A+Knowledge+Refinement+and+Retrieval+System+for+Interdisciplinarity+on+Biomedical+Research)|0|
|[KuaiSAR: A Unified Search And Recommendation Dataset](https://doi.org/10.1145/3583780.3615123)|Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Dewei Leng, Yanan Niu, Yang Song, Xiao Zhang, Jun Xu|Kuaishou Technology Co., Ltd, Beijing, China; Renmin Unversity of China, Beijing, China|The confluence of Search and Recommendation services is a vital aspect of online content platforms like Kuaishou and TikTok. The integration of S&R modeling is a highly intuitive approach adopted by industry practitioners. However, there is a noticeable lack of research conducted in this area within the academia, primarily due to the absence of publicly available datasets. Consequently, a substantial gap has emerged between academia and industry regarding research endeavors in this field. To bridge this gap, we introduce the first large-scale, real-world dataset KuaiSAR of integrated Search And Recommendation behaviors collected from Kuaishou, a leading short-video app in China with over 300 million daily active users. Previous research in this field has predominantly employed publicly available datasets that are semi-synthetic and simulated, with artificially fabricated search behaviors. Distinct from previous datasets, KuaiSAR records genuine user behaviors, the occurrence of each interaction within either search or recommendation service, and the users' transitions between the two services. This work aids in joint modeling of S&R, and the utilization of search data for recommenders (and recommendation data for search engines). Additionally, due to the diverse feedback labels of user-video interactions, KuaiSAR also supports a wide range of other tasks, including intent recommendation, multi-task learning, and long sequential multi-behavior modeling etc. We believe this dataset will facilitate innovative research and enrich our understanding of S&R services integration in real-world applications.|搜索和推荐服务的融合是 Kuaishou 和 TikTok 等在线内容平台的一个重要方面。S & R 建模的集成是业界从业人员采用的一种高度直观的方法。然而，学术界在这一领域明显缺乏研究，主要是由于缺乏公开可用的数据集。因此，在这个领域的研究工作方面，学术界和工业界之间出现了巨大的差距。为了弥补这一差距，我们介绍了第一个大规模的，真实世界的数据集 KuaiSAR 的集成搜索和推荐行为收集自 Kuaishou，一个领先的短视频应用程序在中国有超过3亿日活跃用户。以前在这个领域的研究主要使用公开可用的数据集，这些数据集是半合成的和模拟的，具有人为制造的搜索行为。与以前的数据集不同，KuaiSAR 记录了真实的用户行为、搜索或推荐服务中每个交互的发生情况以及用户在两个服务之间的转换。这项工作有助于 S & R 的联合建模，以及对推荐者的搜索数据(和搜索引擎的推荐数据)的利用。此外，由于用户与视频交互的反馈标签多种多样，KuaiSAR 还支持广泛的其他任务，包括意图推荐、多任务学习和长顺序多行为建模等。我们相信这个数据集将促进创新研究，丰富我们对现实世界应用中的 S & R 服务集成的理解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KuaiSAR:+A+Unified+Search+And+Recommendation+Dataset)|0|
|[HyperBandit: Contextual Bandit with Hypernewtork for Time-Varying User Preferences in Streaming Recommendation](https://doi.org/10.1145/3583780.3614921)|Chenglei Shen, Xiao Zhang, Wei Wei, Jun Xu|Renmin University of China, Beijing, China; Huazhong University of Science and Technology, Wuhan, China|In real-world streaming recommender systems, user preferences often dynamically change over time (e.g., a user may have different preferences during weekdays and weekends). Existing bandit-based streaming recommendation models only consider time as a timestamp, without explicitly modeling the relationship between time variables and time-varying user preferences. This leads to recommendation models that cannot quickly adapt to dynamic scenarios. To address this issue, we propose a contextual bandit approach using hypernetwork, called HyperBandit, which takes time features as input and dynamically adjusts the recommendation model for time-varying user preferences. Specifically, HyperBandit maintains a neural network capable of generating the parameters for estimating time-varying rewards, taking into account the correlation between time features and user preferences. Using the estimated time-varying rewards, a bandit policy is employed to make online recommendations by learning the latent item contexts. To meet the real-time requirements in streaming recommendation scenarios, we have verified the existence of a low-rank structure in the parameter matrix and utilize low-rank factorization for efficient training. Theoretically, we demonstrate a sublinear regret upper bound against the best policy. Extensive experiments on real-world datasets show that the proposed HyperBandit consistently outperforms the state-of-the-art baselines in terms of accumulated rewards.|在现实世界的流媒体推荐系统中，用户的偏好通常会随着时间而动态变化(例如，用户在工作日和周末可能会有不同的偏好)。现有的基于盗贼的流媒体推荐模型只考虑时间作为时间戳，而没有明确建模时间变量和时变用户偏好之间的关系。这导致推荐模型不能快速适应动态场景。为了解决这个问题，我们提出了一种使用超网络的上下文绑架方法，称为 HyperBandit，它以时间特征作为输入，并动态调整推荐模型以适应时变的用户偏好。具体来说，HyperBandit 维护了一个神经网络，该网络能够生成用于估计时变奖励的参数，同时考虑到时间特征和用户偏好之间的相关性。利用估计的时变奖励，采用强盗策略，通过学习潜在项目上下文提出在线推荐。为了满足流媒体推荐场景的实时性要求，我们验证了参数矩阵中低秩结构的存在性，并利用低秩分解进行有效的训练。从理论上证明了最优策略的次线性后悔上界。在真实世界数据集上的大量实验表明，提出的 HyperBandit 在累积奖励方面始终优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyperBandit:+Contextual+Bandit+with+Hypernewtork+for+Time-Varying+User+Preferences+in+Streaming+Recommendation)|0|
|[Dually Enhanced Delayed Feedback Modeling for Streaming Conversion Rate Prediction](https://doi.org/10.1145/3583780.3614856)|Sunhao Dai, Yuqi Zhou, Jun Xu, JiRong Wen|Renmin University of China, Beijing, China|In online industrial advertising systems, conversion actions (e.g., purchases or downloads) often occur significantly delayed, even up to several days or weeks after the user clicks. This phenomenon leads to the crucial challenge calleddelayed feedback problem in streaming CVR prediction, that is, the online systems cannot receive the true label of conversions immediately for continuous training. To mitigate the delayed feedback problem, recent state-of-the-art methods often apply sample duplicate mechanisms to introduce early certain conversion information. Nevertheless, these works have overlooked a crucial issue of rapid shifts in data distribution and considered both the newly observed data and duplicated early data together, resulting in biases in both distributions. In this work, we propose a Dually enhanced Delayed Feedback Model (DDFM), which tackles the above issues by treating the newly observed data and duplicated early data separately. DDFM consists of dual unbiased CVR estimators that share the same form but utilize different latent variables as weights: one for the newly observed data and the other for the duplicated early data. To avoid high variance, we adopt an addition-only formula for these latent variables, eliminating multiplication or division operations. Furthermore, we design a shared-bottom network that efficiently and jointly estimates the latent variables in DDFM. Theoretical analysis demonstrates the unbiasedness and convergence properties of DDFM. Extensive experiments on both public and industrial large-scale real-world datasets exhibit that our proposed DDFM consistently outperforms existing state-of-the-art methods.|在在线工业广告系统中，转换操作(例如购买或下载)经常出现明显延迟，甚至在用户点击后几天或几周。这种现象导致了流式 CVR 预测中的关键问题——延迟反馈问题，即在线系统不能立即得到连续训练所需的转换的真实标签。为了缓解延迟反馈问题，最新的技术方法通常应用样本重复机制来引入早期确定的转换信息。然而，这些工作忽略了数据分布快速变化的关键问题，同时考虑了新观测数据和重复的早期数据，导致两种分布的偏差。在这项工作中，我们提出了一个双增强延迟反馈模型(DDFM) ，它通过分别处理新观测数据和重复早期数据来解决上述问题。DDFM 由双无偏 CVR 估计器组成，它们具有相同的形式，但利用不同的潜变量作为权值: 一个用于新观测数据，另一个用于重复的早期数据。为了避免高方差，我们对这些潜在变量采用一个只加的公式，消除了乘法或除法运算。此外，我们还设计了一个共享底层网络，可以有效地联合估计 DDFM 中的潜变量。理论分析证明了 DDFM 的无偏性和收敛性。在公共和工业大规模真实世界数据集上的大量实验表明，我们提出的 DDFM 始终优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dually+Enhanced+Delayed+Feedback+Modeling+for+Streaming+Conversion+Rate+Prediction)|0|
|[Knowledge-Aware Cross-Semantic Alignment for Domain-Level Zero-Shot Recommendation](https://doi.org/10.1145/3583780.3614945)|Junji Jiang, Hongke Zhao, Ming He, Likang Wu, Kai Zhang, Jianping Fan|Tianjin University, Tianjin, China; AI Lab at Lenovo Research, Beijing, China; University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|Recommendation systems have attracted attention from academia and industry due to their wide range of application scenarios. However, cold start remains a challenging problem limited by sparse user interactions. Some scholars propose to transfer the dense information from the source domain to the target domain through cross-domain recommendation, but most of the work assumes that there is a small amount of historical interaction in the target domain. However, this approach essentially presupposes the existence of at least some historical interaction within the target domain. In this paper, we focus on the domain-level zero-shot recommendation (DZSR) problem. To address the above challenges, we propose a knowledge-aware cross-semantic alignment (K-CSA) framework to learn transferable source domain semantic information. The motivation is to establish stable alignments of interests in different domains through class semantic descriptions (CSDs). Specifically, due to the lack of effective information in the target domain, we learn semantic representations of source and target domain items based on knowledge graphs. Moreover, we conduct multi-view K-means to extract item CSDs from the learned semantic representations. Further, K-CSA learns universal user CSDs through the designed multi-head self-attention. To facilitate the transference of user interest from the source domain to the target domain, we devise a cross-semantic contrastive learning strategy, grounded in the prototype distribution matrix. We conduct extensive experiments on several real-world cross-domain datasets, and the experimental results clearly demonstrate the superiority of our proposed K-CSA compared with other baselines.|推荐系统由于其广泛的应用场景吸引了学术界和工业界的注意。然而，受稀疏用户交互的限制，冷启动仍然是一个具有挑战性的问题。一些学者提出通过跨域推荐将密集信息从源域转移到目标域，但大多数工作假设目标域中存在少量的历史交互。然而，这种方法基本上是以目标域内至少存在一些历史交互为前提的。本文主要研究领域级零拍推荐(DZSR)问题。为了应对上述挑战，我们提出了一个知识感知跨语义比对(k-CSA)框架来学习可转移源域语义信息。其动机是通过类语义描述(CSD)在不同领域建立稳定的兴趣对齐。具体来说，由于目标领域缺乏有效的信息，我们基于知识图学习源和目标领域项目的语义表示。此外，我们还进行了多视图 K- 均值从学习的语义表征中提取项目 CSD。此外，K-CSA 通过设计的多头自我注意来学习通用用户 CSD。为了促进用户兴趣从源域向目标域的转移，我们设计了一种基于原型分布矩阵的跨语义对比学习策略。我们在几个实际的跨域数据集上进行了广泛的实验，实验结果清楚地表明了我们提出的 K-CSA 相对于其他基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-Aware+Cross-Semantic+Alignment+for+Domain-Level+Zero-Shot+Recommendation)|0|
|[Continuous Personalized Knowledge Tracing: Modeling Long-Term Learning in Online Environments](https://doi.org/10.1145/3583780.3614822)|Chunpai Wang, Shaghayegh Sahebi|JPMorgan Chase & Co., New York, NY, USA; University at Albany - SUNY, Albany, NY, USA|With the advance of online education systems, accessibility to learning materials has increased. In these systems, students can practice independently and learn from different learning materials over long periods of time. As a result, it is essential to trace students' knowledge states over long learning sequences while maintaining a personalized model of each individual student's progress. However, the existing deep learning-based knowledge tracing models are either not personalized or not tailored for handling long sequences. Handling long sequences are especially essential in the online education environments, in where models are preferred to be updated with the newly collected user data in a timely manner as students could acquire knowledge on each learning activity. In this paper, we propose a knowledge tracing model, Continuous Personalized Knowledge Tracing (CPKT), that can mimic the real-world long-term continuous learning scenario by incorporating a novel online model training paradigm that is suitable for the knowledge tracing problem. To achieve personalized knowledge tracing, we propose two model components: 1) personalized memory slots to maintain learner's knowledge in a lifelong manner, and 2) personalized user embeddings that help to accurately predict the individual responses, correctly detect the personalized knowledge acquisition and forgetting patterns, and better interpret and analyze the learner's progress. Additionally, we propose transition-aware stochastic shared embedding according to the learning transition matrix to regularize the online model training. Extensive experiments on four real-world datasets showcase the effectiveness and superiority of CPKT, especially for students with longer sequences.|随着在线教育系统的发展，获取学习材料的机会越来越多。在这些系统中，学生可以长时间独立练习和从不同的学习材料中学习。因此，在长时间的学习序列中追踪学生的知识状态，同时保持每个学生进步的个性化模型是至关重要的。然而，现有的基于深度学习的知识跟踪模型要么不个性化，要么不适合处理长序列。处理长序列在在线教育环境中尤为重要，在这种环境中，由于学生可以获得关于每项学习活动的知识，因此倾向于使用新收集的用户数据及时更新模型。在本文中，我们提出了一个知识跟踪模型，连续个性化知识跟踪(CPKT) ，它可以模拟真实世界的长期连续学习情景，通过引入一个新的在线模型训练范式，适合于知识跟踪问题。为了实现个性化的知识追踪，我们提出了两个模型组件: 1)个性化的记忆槽，以终身的方式维护学习者的知识; 2)个性化的用户嵌入，有助于准确预测个体的反应，正确检测个性化的知识获取和遗忘模式，并更好地解释和分析学习者的进步。此外，我们根据学习转移矩阵提出了具有过渡意识的随机共享嵌入，以规范在线模型训练。在四个实际数据集上的大量实验表明了 CPKT 的有效性和优越性，特别是对于序列较长的学生。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continuous+Personalized+Knowledge+Tracing:+Modeling+Long-Term+Learning+in+Online+Environments)|0|
|[Modeling Preference as Weighted Distribution over Functions for User Cold-start Recommendation](https://doi.org/10.1145/3583780.3614972)|Jingxuan Wen, Huafeng Liu, Liping Jing|Beijing Jiaotong University, Beijing, China|=User cold-start recommendation is a well-known challenge in current recommender systems. The cause is that the number of user interactions is too few to accurately estimate user preferences. Furthermore, the uncertainty of user interactions intensifies along with the number of user interactions decreasing. Although existing meta-learning based models with globally sharing knowledge show good performance in most cold-start scenarios, the ability of handling challenges on intention importance and prediction uncertainty is missing: (1) Intra-user uncertainty. When estimating user preferences (reflected in the user's latent representation), each of user interactions is independently considered in the form of user-item pair, which cannot capture the correlation between user interactions, as well as considering the global intent under user interactions. (2) Inter-user importance. During the model training, all users are treated as equally important, which cannot distinguish the contribution of users in the model training process. Assigning the same weight to all users may lead to users with high uncertainty incorrectly guiding the model learning in the early stage of training. To tackle the above challenges, in this paper, we focus on modeling user preference as a weighted distribution over functions (WDoF) for user cold-start recommendation, which not only models the intra-user uncertainty through neural processes with Multinomial likelihood but also considers the importance of different users with curriculum learning during the model training process. Furthermore, we provide a theoretical explanation that why the proposed model performs better than regular neural processes based recommendation methods. Experiments on four real-world datasets demonstrate the effectiveness of the proposed model over several state-of-the-art cold-start recommendation methods.|= 用户冷启动推荐在当前的推荐系统中是一个众所周知的挑战。原因是用户交互的数量太少，无法准确估计用户偏好。此外，用户交互的不确定性随着用户交互次数的减少而增加。虽然现有的基于元学习的全局知识共享模型在大多数冷启动情景下表现出良好的性能，但缺乏处理意图重要性和预测不确定性挑战的能力: (1)用户内部的不确定性。在估计用户偏好时(反映在用户的潜在表示中) ，每个用户交互都以用户项对的形式独立考虑，不能捕获用户交互之间的相关性，也不能考虑用户交互下的全局意图。(2)用户之间的重要性。在模型训练过程中，所有用户都被视为同等重要的用户，不能区分用户在模型训练过程中的贡献。给所有用户赋予相同的权重可能会导致高不确定性用户在训练的早期阶段错误地指导模型学习。针对上述挑战，本文将用户偏好建模为用户冷启动推荐的加权函数分布(WDoF) ，不仅通过多项式似然的神经过程模拟用户内部的不确定性，而且在模型训练过程中考虑了不同用户课程学习的重要性。此外，我们提供了一个理论上的解释，为什么所提出的模型性能优于常规的神经过程为基础的推荐方法。在四个实际数据集上的实验结果表明了该模型对于几种最新的冷启动推荐方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Preference+as+Weighted+Distribution+over+Functions+for+User+Cold-start+Recommendation)|0|
|[Multimodal Optimal Transport Knowledge Distillation for Cross-domain Recommendation](https://doi.org/10.1145/3583780.3614983)|Wei Yang, Jie Yang, Yuan Liu|Tencent Technology, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China|Recommendation systems have been widely used in e-commerce, news media, and short video platforms. With the abundance of images, text, and audio information, users often engage in personalized interactions based on their multimodal preferences. With the continuous expansion of application scenarios, cross domain recommendation issues have become important, such as recommendations in both the public and private domains of e-commerce. The current cross domain recommendation methods have achieved certain results through methods such as shared encoders and contrastive learning. However, few studies have focused on the effective extraction and utilization of multimodal information in cross domain recommendations. Furthermore, due to the existence of distribution drift issues, directly constructing feature alignment between source domain and target domain representations is not an effective way. Therefore, we propose a Multimodal Optimal Transport Knowledge Distillation (MOTKD) method for cross domain recommendation. Specifically, we propose a multimodal graph attention network to model the multimodal preference representation of users. Then, we introduce a proxy distribution space as a bridge between the source and target domains. Based on the common proxy distribution, we utilize the optimal transport method to achieve cross domain knowledge transfer. Further, in order to improve the auxiliary training effect of source domain supervised signals on target domain, we design a multi-level cross domain knowledge distillation module. We conducted extensive experiments on two pairs of cross domain datasets composed of four datasets. The experimental results indicate that our proposed MOTKD method outperforms other state-of-the-art models.|推荐系统已广泛应用于电子商务、新闻媒体和短视频平台。随着丰富的图像，文字和音频信息，用户往往从事个性化的交互基于他们的多模态偏好。随着应用场景的不断扩展，跨域推荐问题变得越来越重要，例如电子商务的公共和私人领域的推荐。现有的跨域推荐方法通过共享编码器和对比学习等方法取得了一定的效果。然而，很少有研究关注跨领域推荐中多模态信息的有效提取和利用。此外，由于分布漂移问题的存在，直接构造源域和目标域表示之间的特征对齐并不是一种有效的方法。因此，我们提出了一种跨域推荐的多模式最优运输知识提取(MOTKD)方法。具体来说，我们提出了一个多模态图注意网络来模拟用户的多模态偏好表示。然后，引入一个代理分布空间作为源域和目标域之间的桥梁。在公共代理分布的基础上，利用最优传输方法实现跨领域的知识转移。进一步，为了提高源域监督信号对目标域的辅助训练效果，我们设计了一个多级跨域知识提取模块。我们对由四个数据集组成的两对跨域数据集进行了广泛的实验。实验结果表明，我们提出的 MOTKD 方法优于其他最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Optimal+Transport+Knowledge+Distillation+for+Cross-domain+Recommendation)|0|
|[Task-Difficulty-Aware Meta-Learning with Adaptive Update Strategies for User Cold-Start Recommendation](https://doi.org/10.1145/3583780.3615074)|Xuhao Zhao, Yanmin Zhu, Chunyang Wang, Mengyuan Jing, Jiadi Yu, Feilong Tang|Shanghai Jiao Tong University, Shanghai, China|User cold-start recommendation is one of the most challenging problems that limit the effectiveness of recommender systems. Meta-learning-based methods are introduced to address this problem by learning initialization parameters for cold-start tasks. Recent studies attempt to enhance the initialization methods. They first represent each task by the cold-start user and interacted items. Then they distinguish tasks based on the task relevance to learn adaptive initialization. However, this manner is based on the assumption that user preferences can be reflected by the interacted items saliently, which is not always true in reality. In addition, we argue that previous approaches suffer from their adaptive framework (e.g., adaptive initialization), which reduces the adaptability in the process of transferring meta-knowledge to personalized RSs. In response to the issues, we propose a task-difficulty-aware meta-learning with adaptive update strategies (TDAS) for user cold-start recommendation. First, we design a task difficulty encoder, which can represent user preference salience, task relevance, and other task characteristics by modeling task difficulty information. Second, we adopt a novel framework with task-adaptive local update strategies by optimizing the initialization parameters with task-adaptive per-step and per-layer hyperparameters. Extensive experiments based on three real-world datasets demonstrate that our TDAS outperforms the state-of-the-art methods. The source code is available at https://github.com/XuHao-bit/TDAS.|用户冷启动推荐是限制推荐系统有效性的最具挑战性的问题之一。为了解决这个问题，引入了基于元学习的方法，学习冷启动任务的初始化参数。最近的研究试图改进初始化方法。它们首先由冷启动用户和交互项表示每个任务。然后根据任务相关性区分任务，学习自适应初始化。然而，这种方式是基于这样的假设，即用户的偏好可以通过交互的项显著地反映出来，这在现实中并不总是正确的。此外，我们认为以前的方法受到其自适应框架(例如，自适应初始化)的影响，这降低了元知识向个性化 RSS 传输过程中的适应性。针对这些问题，我们提出了一种基于任务难度感知的元学习算法，该算法采用自适应更新策略(TDAS)对用户进行冷启动推荐。首先，我们设计了一个任务难度编码器，通过对任务难度信息进行建模来表示用户偏好显著性、任务相关性等任务特征。其次，采用任务自适应局部更新策略，通过每步任务自适应和每层超参数对初始化参数进行优化，提出了一种新的任务自适应局部更新策略框架。基于三个真实世界数据集的大量实验表明，我们的 TDAS 优于最先进的方法。源代码可在 https://github.com/xuhao-bit/tdas 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Difficulty-Aware+Meta-Learning+with+Adaptive+Update+Strategies+for+User+Cold-Start+Recommendation)|0|
|[Retrievability Bias Estimation Using Synthetically Generated Queries](https://doi.org/10.1145/3583780.3615221)|Amin Abolghasemi, Suzan Verberne, Arian Askari, Leif Azzopardi|University of Strathclyde, Glasgow, United Kingdom; Leiden University, Leiden, Netherlands|Ranking with pre-trained language models (PLMs) has shown to be highly effective for various Information Retrieval tasks. Previous studies investigated the performance of these models in terms of effectiveness and efficiency. However, there is no prior work on evaluating PLM-based rankers in terms of their retrievability bias. In this paper, we evaluate the retrievability bias of PLM-based rankers with the use of synthetically generated queries. We compare the retrievability bias in two of the most common PLM-based rankers, a Bi-Encoder BERT ranker and a Cross-Encoder BERT re-ranker against BM25, which was found to be one of the least biased models in prior work. We conduct a series of experiments with which we explore the plausibility of using synthetic queries generated with a generative model, docT5query, in the evaluation of retrievability bias. Our experiments show promising results on the use of synthetically generated queries for the purpose of retrievability bias estimation. Moreover, we find that the estimated bias values resulting from synthetically generated queries are lower than the ones estimated with user-generated queries on the MS MARCO evaluation benchmark. This indicates that synthetically generated queries might cause less bias than user-generated queries and therefore, by using such queries in training PLM-based rankers, we might be able to reduce the retrievability bias in these models.|使用预先训练好的语言模型(PLM)进行排名已被证明对于各种信息检索任务非常有效。以往的研究从效能和效率的角度研究了这些模型的性能。然而，目前还没有关于评估基于 PLM 的排名在他们的检索偏差方面的工作。本文利用综合生成的查询来评估基于 PLM 的排序器的可检索性偏差。我们比较了两种最常见的基于 PLM 的排序器，双编码器 BERT 排序器和交叉编码器 BERT 重排序器对 BM25的可检索性偏差，这被发现是先前工作中偏差最小的模型之一。我们进行了一系列的实验，通过这些实验，我们探索了使用一个名为 doct5 query 的生成模型生成的合成查询来评估可检索性偏差的可行性。实验结果表明，综合生成的查询用于可检索性偏差估计具有良好的效果。此外，我们发现在 MS MARCO 评估基准上，由合成生成查询所得到的估计偏差值低于由用户生成查询所得到的估计偏差值。这表明综合生成的查询可能比用户生成的查询引起的偏差更小，因此，通过在训练基于 PLM 的排名中使用这样的查询，我们可能能够减少这些模型中的可检索性偏差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrievability+Bias+Estimation+Using+Synthetically+Generated+Queries)|0|
|[On the Reliability of User Feedback for Evaluating the Quality of Conversational Agents](https://doi.org/10.1145/3583780.3615286)|Jordan Massiah, Emine Yilmaz, Yunlong Jiao, Gabriella Kazai|Amazon & University College London, London, United Kingdom; Amazon, London, United Kingdom|We analyse the reliability of users' explicit feedback for evaluating the quality of conversational agents. Using data from a commercial conversational system, we analyse how user feedback compares with human annotations; how well it aligns with implicit user satisfaction signals, such as retention; and how much user feedback is needed to reliably evaluate the quality of a conversational system.|我们分析了用户显性反馈对于评价会话代理质量的可靠性。使用来自商业会话系统的数据，我们分析了用户反馈与人工注释的比较; 它与隐含的用户满意信号(如保留)的匹配程度; 以及需要多少用户反馈才能可靠地评估会话系统的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Reliability+of+User+Feedback+for+Evaluating+the+Quality+of+Conversational+Agents)|0|
|[SeqGen: A Sequence Generator via User Side Information for Behavior Sparsity in Recommendation](https://doi.org/10.1145/3583780.3615244)|Xu Min, Xiaolu Zhang, Bin Shen, Shuhan Wang, Yong He, Changsheng Li, Jun Zhou|Ant Group, Hangzhou, China; Beijing Institute of Technology, Beijing, China; Ant Group, Beijing, China|In real-world industrial advertising systems, user behavior sparsity is a key issue that affects online recommendation performance. We observe that users with rich behaviors can obtain better recommendation results than those with sparse behaviors in a conversion-rate (CVR) prediction model. Inspired by this phenomenon, we propose a new method SeqGen, in an effort to exploit user side information to bridge the gap between rich and sparse behaviors. SeqGen is a learnable and pluggable module, which can be easily integrated into any CVR model and no longer requires two-stage training as in previous works. In particular, SeqGen learns a mapping relationship between the user side information and behavior sequences, only on the basis of the users with long behavior sequences. After that, SeqGen can generate rich sequence features for users with sparse behaviors based on their side information, so as to alleviate the issue of user behavior sparsity. The generated sequence features will then be fed into the classifier tower of an arbitrary CVR model together with the original sequence features. To the best of our knowledge, our approach constitutes the first attempt to exploit user side information for addressing the user behavior sparsity issue. We validate the effectiveness of SeqGen on the publicly available dataset MovieLens-1M, and our method receives an improvement of up to 0.5% in terms of the AUC score. More importantly, we successfully deploy SeqGen in the commercial advertising system Xlight of Alipay, which improves the grouped AUC of the CVR model by 0.6% and brings a boost of 0.49% in terms of the conversion rate on A/B testing.|在现实工业广告系统中，用户行为稀疏性是影响在线推荐性能的关键问题。在 CVR 预测模型中，我们观察到行为丰富的用户比行为稀疏的用户获得更好的推荐结果。受到这一现象的启发，我们提出了一种新的方法 SeqGen，尝试利用用户端信息来弥补丰富和稀疏行为之间的差距。SeqGen 是一个可学习和可插拔的模块，它可以很容易地集成到任何 CVR 模型中，不再像以前的作品那样需要两阶段的培训。特别是，SeqGen 只在具有长行为序列的用户的基础上学习用户端信息和行为序列之间的映射关系。然后，SeqGen 可以根据用户的侧信息为稀疏行为的用户生成丰富的序列特征，从而缓解用户行为稀疏的问题。然后将生成的序列特征与原始序列特征一起反馈到任意 CVR 模型的分类器塔中。据我们所知，我们的方法是第一次尝试利用用户端信息来解决用户行为稀疏性问题。我们验证了 SeqGen 在公开数据集 MovieLens-1M 上的有效性，并且我们的方法在 AUC 评分方面获得了高达0.5% 的改善。更重要的是，我们成功地在支付宝的商业广告系统 Xlight 中部署了 SeqGen，它将 CVR 模型的分组 AUC 提高了0.6% ，在 A/B 测试中的转换率提高了0.49% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SeqGen:+A+Sequence+Generator+via+User+Side+Information+for+Behavior+Sparsity+in+Recommendation)|0|
|[Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning](https://doi.org/10.1145/3583780.3615457)|Zeyuan Chen, Wei Chen, Jia Xu, Zhongyi Liu, Wei Zhang|East China Normal University, Shanghai, China; Ant Group, Hangzhou, China|Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robustness of BARL-ASe by strengthening representation and logit learning. Furthermore, we discuss how to deal with the long-tail query-item matching of the mini apps search scenario of Alipay practically. Experiments on real-world industry data and online A/B testing demonstrate our proposal achieves promising performance with low latency.|相关性建模的目的是为相应的查询定位合适的条目，这对于搜索引擎保证用户体验是至关重要的。尽管大多数传统的方法都是通过评估查询和条目之间的语义相似性来解决这个问题，但是纯语义匹配并不是一切。实际上，从搜索日志的用户历史行为数据中提取的辅助查询项交互可以为进一步揭示用户的搜索意图提供提示。基于此，我们设计了一种新的支付宝搜索行为增强关联学习模型(BARL-ASE) ，该模型利用目标项的邻居查询和目标查询的邻居查询来补充目标查询项语义匹配。具体来说，我们的模型建立了多级共注意，从邻居视图和目标视图中提取粗粒度和细粒度的语义表示。该模型随后采用邻居-目标自监督学习，通过加强表示和逻辑学习来提高 BARL-ASE 的准确性和鲁棒性。此外，本文还讨论了如何实际处理支付宝迷你应用搜索场景中的长尾查询项匹配问题。在现实工业数据和在线 A/B 测试中的实验表明，该方案具有良好的性能和较低的延迟。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Semantics:+Learning+a+Behavior+Augmented+Relevance+Model+with+Self-supervised+Learning)|0|
|[Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction](https://doi.org/10.1145/3583780.3615475)|Yunfeng Zhao, Xu Yan, Xiaoqiang Gui, Shuguang Han, XiangRong Sheng, Guoxian Yu, Jufeng Chen, Zhao Xu, Bo Zheng|Alibaba Group, Hangzhou, China; School of Software, Shandong University, Jinan, China|Conversion rate (CVR) prediction is an essential task for large-scale e-commerce platforms. However, refund behaviors frequently occur after conversion in online shopping systems, which drives us to pay attention to effective conversion for building healthier shopping services. This paper defines the probability of item purchasing without any subsequent refund as an effective conversion rate (ECVR). A simple paradigm for ECVR prediction is to decompose it into two sub-tasks: CVR prediction and post-conversion refund rate (RFR) prediction. However, RFR prediction suffers from data sparsity (DS) and sample selection bias (SSB) issues, as the refund behaviors are only available after user purchase. Furthermore, there is delayed feedback in both conversion and refund events and they are sequentially dependent, named cascade delayed feedback (CDF), which significantly harms data freshness for model training. Previous studies mainly focus on tackling DS and SSB or delayed feedback for a single event. To jointly tackle these issues in ECVR prediction, we propose an Entire space CAscade Delayed feedback modeling (ECAD) method. Specifically, ECAD deals with DS and SSB by constructing two tasks including CVR prediction and conversion \& refund rate (CVRFR) prediction using the entire space modeling framework. In addition, it carefully schedules auxiliary tasks to leverage both conversion and refund time within data to alleviate CDF. Experimental results on the offline industrial dataset and online A/B testing demonstrate the effectiveness of ECAD. In addition, ECAD has been deployed in one of the recommender systems in Alibaba, contributing to a significant improvement of ECVR.|转化率(CVR)预测是大型电子商务平台的一项基本任务。然而，在网上购物系统中，退款行为经常发生在转换之后，这促使我们关注有效的转换以建立更健康的购物服务。本文将不随后退款的物品购买概率定义为有效转换率(ECVR)。ECVR 预测的一个简单范例是将其分解为两个子任务: CVR 预测和转换后退款率(RFR)预测。然而，RFR 预测存在数据稀疏(DS)和样本选择偏差(SSB)问题，因为退款行为只能在用户购买之后才能得到。此外，在转换事件和退款事件中都存在延迟反馈，并且它们是相互依赖的，称为级联延迟反馈(CDF) ，这严重损害了模型训练的数据新鲜度。以往的研究主要集中在处理 DS 和 SSB 或单个事件的延迟反馈。为了共同解决 ECVR 预测中的这些问题，我们提出了一种全空间级联延迟反馈建模(ECAD)方法。具体来说，ECAD 利用整个空间建模框架构造了 CVR 预测和转换退款率(CVRFR)预测两个任务来处理 DS 和 SSB。此外，它仔细地安排辅助任务，以利用数据中的转换和退款时间来缓解 CDF。离线工业数据集和在线 A/B 测试的实验结果证明了 ECAD 的有效性。此外，阿里巴巴其中一个推荐系统已采用 ECAD，有助显著改善 ECVR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entire+Space+Cascade+Delayed+Feedback+Modeling+for+Effective+Conversion+Rate+Prediction)|0|
|[MUSER: A Multi-View Similar Case Retrieval Dataset](https://doi.org/10.1145/3583780.3615125)|Qingquan Li, Yiran Hu, Feng Yao, Chaojun Xiao, Zhiyuan Liu, Maosong Sun, Weixing Shen|Tsinghua University, Beijing, China|Similar case retrieval (SCR) is a representative legal AI application that plays a pivotal role in promoting judicial fairness. However, existing SCR datasets only focus on the fact description section when judging the similarity between cases, ignoring other valuable sections (e.g., the court's opinion) that can provide insightful reasoning process behind. Furthermore, the case similarities are typically measured solely by the textual semantics of the fact descriptions, which may fail to capture the full complexity of legal cases from the perspective of legal knowledge. In this work, we present MUSER, a similar case retrieval dataset based on multi-view similarity measurement and comprehensive legal element with sentence-level legal element annotations. Specifically, we select three perspectives (legal fact, dispute focus, and law statutory) and build a comprehensive and structured label schema of legal elements for each of them, to enable accurate and knowledgeable evaluation of case similarities. The constructed dataset originates from Chinese civil cases and contains 100 query cases and 4,024 candidate cases. We implement several text classification algorithms for legal element prediction and various retrieval methods for retrieving similar cases on MUSER. The experimental results indicate that incorporating legal elements can benefit the performance of SCR models, but further efforts are still required to address the remaining challenges posed by MUSER. The source code and dataset are released at https://github.com/THUlawtech/MUSER.|类似案件检索(SCR)是一种具有代表性的法律人工智能应用，对促进司法公正起着举足轻重的作用。然而，现有的 SCR 数据集只集中在事实描述部分，当判断案件之间的相似性时，忽略了其他有价值的部分(例如，法院的意见) ，可以提供深刻的推理过程背后。此外，案件的相似性通常仅通过事实描述的文本语义来衡量，这可能无法从法律知识的角度捕捉到法律案件的全部复杂性。本文提出了一个基于多视图相似度量和综合法律要素的相似案例检索数据集 MUSER。具体来说，我们选取法律事实、争议焦点和法律成文法三个视角，为每一个视角建立一个全面而结构化的法律要素标签模式，以便能够准确而知识化地评价案件的相似性。所构建的数据集来源于中国民事案件，包含100个查询案件和4024个候选案件。在 MUSER 上实现了法律元素预测的文本分类算法和相似案例检索的各种检索方法。实验结果表明，纳入法律因素有利于可持续性研究模型的性能，但仍需作出进一步努力，以解决 MUSER 提出的其余挑战。源代码和数据集在 https://github.com/thulawtech/muser 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MUSER:+A+Multi-View+Similar+Case+Retrieval+Dataset)|0|
|[A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER](https://doi.org/10.1145/3583780.3614766)|Guanting Dong, Zechen Wang, Jinxu Zhao, Gang Zhao, Daichi Guo, Dayuan Fu, Tingfeng Hui, Chen Zeng, Keqing He, Xuefeng Li, Liwen Wang, Xinyue Cui, Weiran Xu|Meituan Group, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|The objective of few-shot named entity recognition is to identify named entities with limited labeled instances. Previous works have primarily focused on optimizing the traditional token-wise classification framework, while neglecting the exploration of information based on NER data characteristics. To address this issue, we propose a Multi-Task Semantic Decomposition Framework via Joint Task-specific Pre-training (MSDP) for few-shot NER. Drawing inspiration from demonstration-based and contrastive learning, we introduce two novel pre-training tasks: Demonstration-based Masked Language Modeling (MLM) and Class Contrastive Discrimination. These tasks effectively incorporate entity boundary information and enhance entity representation in Pre-trained Language Models (PLMs). In the downstream main task, we introduce a multi-task joint optimization framework with the semantic decomposing method, which facilitates the model to integrate two different semantic information for entity classification. Experimental results of two few-shot NER benchmarks demonstrate that MSDP consistently outperforms strong baselines by a large margin. Extensive analyses validate the effectiveness and generalization of MSDP.|少镜头命名实体识别的目标是识别具有有限标记实例的命名实体。以往的工作主要集中在优化传统的标记分类框架，而忽视了基于 NER 数据特征的信息探索。针对这一问题，提出了一种基于联合任务特定预训练(MSDP)的多任务语义分解框架。借鉴基于演示和对比学习的方法，我们介绍了两种新颖的预训练任务: 基于演示的掩蔽语言建模(MLM)和类别对比鉴别。这些任务有效地整合了实体边界信息，增强了预训练语言模型(PLM)中的实体表示。在下游的主要任务中，我们引入了一个基于语义分解的多任务联合优化框架，该框架有利于模型集成两个不同的语义信息进行实体分类。两个短镜头 NER 基准测试的实验结果表明，MSDP 的性能始终大大优于强基准测试。广泛的分析验证了 MSDP 的有效性和推广性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Task+Semantic+Decomposition+Framework+with+Task-specific+Pre-training+for+Few-Shot+NER)|0|
|[CLSPRec: Contrastive Learning of Long and Short-term Preferences for Next POI Recommendation](https://doi.org/10.1145/3583780.3614813)|Chenghua Duan, Wei Fan, Wei Zhou, Hu Liu, Junhao Wen|Chongqing University, Chongqing, China|Next point-of-interest (POI) recommendation optimizes user travel experiences and enhances platform revenues by providing users with potentially appealing next location choices. In recent research, scholars have successfully mined users' general tastes and varying interests by modeling long-term and short-term check-in sequences. However, conventional methods for long and short-term modeling predominantly employ distinct encoders to process long and short-term interaction data independently, with disparities in encoders and data limiting the ultimate performance of these models. Instead, we propose a shared trajectory encoder and a novel Contrastive learning of Long and Short-term Preferences for next POI Recommendation (CLSPRec) model to better utilize the preference similarity among the same users and distinguish different users' travel preferences for more accurate next POI prediction. CLSPRec adopts a masking strategy in long-term sequences to enhance model robustness and further strengthens user representation through short-term sequences. Extensive experiments on three real-world datasets validate the superiority of our model. Our code is publicly available at https://github.com/Wonderdch/CLSPRec.|下一个兴趣点(Next Point-of-interest，POI)推荐通过为用户提供具有潜在吸引力的下一个地点选择，优化了用户的旅游体验，增强了平台收入。在最近的研究中，学者们通过建立长期和短期的签入序列模型，成功地挖掘了用户的一般品味和不同的兴趣。然而，用于长期和短期建模的传统方法主要使用不同的编码器来独立处理长期和短期的交互数据，编码器和数据的差异限制了这些模型的最终性能。相反，我们提出了一个共享的轨迹编码器和一个新的下一个 POI 推荐的长期和短期偏好对比学习(CLSPRec)模型，以更好地利用相同用户之间的偏好相似性，并区分不同用户的出行偏好，以便更准确地预测下一个 POI。CLSPRec 在长序列中采用掩蔽策略来增强模型的鲁棒性，并通过短序列进一步增强用户表示。在三个实际数据集上的大量实验验证了该模型的优越性。我们的代码可以在 https://github.com/wonderdch/clsprec 上公开获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLSPRec:+Contrastive+Learning+of+Long+and+Short-term+Preferences+for+Next+POI+Recommendation)|0|
|[Predictive Uncertainty-based Bias Mitigation in Ranking](https://doi.org/10.1145/3583780.3615011)|Maria Heuss, Daniel Cohen, Masoud Mansoury, Maarten de Rijke, Carsten Eickhoff|University of Amsterdam, Amsterdam, Netherlands; University of Tübingen, Tübingen, Germany; Dataminr, NYC, NY, USA|Societal biases that are contained in retrieved documents have received increased interest. Such biases, which are often prevalent in the training data and learned by the model, can cause societal harms, by misrepresenting certain groups, and by enforcing stereotypes. Mitigating such biases demands algorithms that balance the trade-off between maximized utility for the user with fairness objectives, which incentivize unbiased rankings. Prior work on bias mitigation often assumes that ranking scores, which correspond to the utility that a document holds for a user, can be accurately determined. In reality, there is always a degree of uncertainty in the estimate of expected document utility. This uncertainty can be approximated by viewing ranking models through a Bayesian perspective, where the standard deterministic score becomes a distribution.   In this work, we investigate whether uncertainty estimates can be used to decrease the amount of bias in the ranked results, while minimizing loss in measured utility. We introduce a simple method that uses the uncertainty of the ranking scores for an uncertainty-aware, post hoc approach to bias mitigation. We compare our proposed method with existing baselines for bias mitigation with respect to the utility-fairness trade-off, the controllability of methods, and computational costs. We show that an uncertainty-based approach can provide an intuitive and flexible trade-off that outperforms all baselines without additional training requirements, allowing for the post hoc use of this approach on top of arbitrary retrieval models.|检索到的文件中包含的社会偏见越来越受到关注。这样的偏见，通常在培训数据中普遍存在，并被模型学习到，通过歪曲特定群体和强制执行刻板印象，可能造成社会危害。减轻这种偏见需要算法，平衡之间的权衡最大效用的用户和公平的目标，激励无偏排名。先前关于减少偏差的工作通常假设排名分数，这对应于一个文档为用户持有的效用，可以被准确地确定。实际上，在预期文档效用的估计中总是存在一定程度的不确定性。这种不确定性可以通过贝叶斯透视图查看排名模型来近似化，其中标准的确定性得分成为一个分布。在这项工作中，我们调查是否不确定性估计可以用来减少排名结果中的偏差量，同时最小化测量效用的损失。我们介绍了一个简单的方法，使用不确定性的排名得分的不确定性的不确定性，事后的方法来减少偏见。在效用-公平权衡、方法的可控性和计算成本方面，我们将提出的方法与现有的减少偏差的基线进行了比较。我们展示了一个基于不确定性的方法可以提供一个直观和灵活的权衡，在没有额外的训练要求的情况下优于所有的基线，允许在任意检索模型之上事后使用这种方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predictive+Uncertainty-based+Bias+Mitigation+in+Ranking)|0|
|[Single-User Injection for Invisible Shilling Attack against Recommender Systems](https://doi.org/10.1145/3583780.3615062)|Chengzhi Huang, Hui Li|Xiamen University, Xiamen, China|Recommendation systems (RS) are crucial for alleviating the information overload problem. Due to its pivotal role in guiding users to make decisions, unscrupulous parties are lured to launch attacks against RS to affect the decisions of normal users and gain illegal profits. Among various types of attacks, shilling attack is one of the most subsistent and profitable attacks. In shilling attack, an adversarial party injects a number of well-designed fake user profiles into the system to mislead RS so that the attack goal can be achieved. Although existing shilling attack methods have achieved promising results, they all adopt the attack paradigm of multi-user injection, where some fake user profiles are required. This paper provides the first study of shilling attack in an extremely limited scenario: only one fake user profile is injected into the victim RS to launch shilling attacks (i.e., single-user injection). We propose a novel single-user injection method SUI-Attack for invisible shilling attack. SUI-Attack is a graph based attack method that models shilling attack as a node generation task over the user-item bipartite graph of the victim RS, and it constructs the fake user profile by generating user features and edges that link the fake user to items. Extensive experiments demonstrate that SUI-Attack can achieve promising attack results in single-user injection. In addition to its attack power, SUI-Attack increases the stealthiness of shilling attack and reduces the risk of being detected. We provide our implementation at: https://github.com/KDEGroup/SUI-Attack.|推荐系统(RS)对于缓解信息超载问题至关重要。由于 RS 在引导用户做出决策方面发挥着关键作用，因此引诱不法分子对 RS 发起攻击，以影响正常用户的决策并获取非法利润。在各种类型的攻击中，先令攻击是最具生命力和最有利可图的攻击之一。在先令攻击中，敌对方向系统中注入大量精心设计的虚假用户资料，以误导 RS，从而达到攻击目的。现有的先令攻击方法虽然取得了良好的效果，但都采用了多用户注入的攻击范式，需要一些伪造的用户配置文件。本文提供了在极其有限的情况下的先令攻击的第一个研究: 只有一个假的用户配置文件被注入到受害者的 RS 发动先令攻击(即，单用户注入)。针对隐形先令攻击，提出了一种新的单用户注入方法 SUI- 攻击。SUI 攻击是一种基于图的攻击方法，在受害者 RS 的用户-项目二分图上将先令攻击建模为一个节点生成任务，通过生成用户特征和边将假用户与项目连接起来，构造假用户轮廓。大量的实验表明，SUI 攻击可以在单用户注入中获得良好的攻击效果。除了它的攻击威力，SUI 攻击增加了先令攻击的隐蔽性，并降低了被发现的风险。我们在以下 https://github.com/kdegroup/sui-attack 提供实施方案:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Single-User+Injection+for+Invisible+Shilling+Attack+against+Recommender+Systems)|0|
|[Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start Recommendation](https://doi.org/10.1145/3583780.3614965)|Minchang Kim, Yongjin Yang, Jung Hyun Ryu, Taesup Kim|Seoul National University, Seoul, Republic of Korea|Sequential recommenders have made great strides in capturing a user's preferences. Nevertheless, the cold-start recommendation remains a fundamental challenge in which only a few user-item interactions are available for personalization. Gradient-based meta-learning approaches have recently emerged in the sequential recommendation field due to their fast adaptation and easy-to-integrate abilities. The meta-learning algorithms formulate the cold-start recommendation as a few-shot learning problem, where each user is represented as a task to be adapted. However, while meta-learning algorithms generally assume that task-wise samples are evenly distributed over classes or values, user-item interactions are not that way in real-world applications (e.g., watching favorite videos multiple times, leaving only good ratings and no bad ones). As a result, in the real-world, imbalanced user feedback that accounts for most task training data may dominate the user adaptation and prevent meta-learning algorithms from learning meaningful meta-knowledge for personalized recommendations. To alleviate this limitation, we propose a novel sequential recommendation framework based on gradient-based meta-learning that captures the imbalance of each user's rating distribution and accordingly computes adaptive loss for user-specific learning. It is the first work to tackle the impact of imbalanced ratings in cold-start sequential recommendation scenarios. We design adaptive weighted loss and improve the existing meta-learning algorithms for state-of-the-art sequential recommendation methods. Extensive experiments conducted on real-world datasets demonstrate the effectiveness of our framework.|顺序推荐系统在捕获用户的首选项方面取得了长足的进步。然而，冷启动建议仍然是一个根本性的挑战，因为只有少数用户项交互可用于个性化。基于梯度的元学习方法由于其快速的适应性和易于集成的能力，近年来出现在顺序推荐领域。元学习算法将冷启动推荐表示为一个短镜头学习问题，将每个用户表示为一个需要调整的任务。然而，虽然元学习算法通常假设任务智能样本均匀分布在类或值上，但在现实世界的应用程序中，用户项交互并非如此(例如，多次观看最喜欢的视频，只留下好的评分，没有坏的)。因此，在现实世界中，占用大多数任务训练数据的不平衡的用户反馈可能会主导用户适应性，并阻碍元学习算法学习有意义的元知识以获得个性化推荐。为了解决这一问题，本文提出了一种基于梯度元学习的顺序推荐框架，该框架能够捕捉每个用户评分分布的不平衡性，从而计算用户特定学习的自适应损失。这是第一个处理冷启动顺序推荐情景中评分不平衡的影响的工作。设计了自适应加权损失算法，并对现有的元学习算法进行了改进。在真实世界数据集上进行的大量实验证明了我们框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Learning+with+Adaptive+Weighted+Loss+for+Imbalanced+Cold-Start+Recommendation)|0|
|[Learning the Co-evolution Process on Live Stream Platforms with Dual Self-attention for Next-topic Recommendations](https://doi.org/10.1145/3583780.3614952)|HsuChao Lai, Philip S. Yu, JiunLong Huang|University of Illinois at Chicago, Chicago, IL, USA; National Yang Ming Chiao Tung University, Hsinchu, Taiwan Roc|Live stream platforms have gained popularity in light of emerging social media platforms. Unlike traditional on-demand video platforms, viewers and streamers on the live stream platforms are able to interact in real-time, and this makes viewer interests and live stream topics mutually affect each other on the fly, which is the unique co-evolution phenomenon on live stream platforms. In this paper, we make the first attempt to introduce a novel next-topic recommendation problem for the streamers, LSNR, which incorporates the co-evolution phenomenon. A novel framework CENTR introducing the Co-evolutionary Sequence Embedding Structure that captures the temporal relations of viewer interests and live stream topic sequences with two stacks of self-attention layers is proposed. Instead of learning the sequences individually, a novel dual self-attention mechanism is designed to model interactions between the sequences. The dual self-attention includes two modules, LCA and LVA, to leverage viewer loyalty to improve efficiency and flexibility. Finally, to facilitate cold-start recommendations for new streamers, a collaborative diffusion mechanism is implemented to improve a meta learner. Through the experiments in real datasets, CENTR outperforms state-of-the-art recommender systems in both regular and cold-start scenarios.|随着社交媒体平台的兴起，直播平台越来越受欢迎。与传统的视频点播平台不同，直播平台上的观众和流媒体可以实时互动，这使得观众的兴趣和直播话题在运动中相互影响，这是直播平台上独特的协同进化现象。在本文中，我们首次尝试引入一个新的流媒体下一主题推荐问题，LSNR，它结合了协同进化现象。提出了一种引入协同进化序列嵌入结构的新框架 CENTR，该结构能够捕获观看者兴趣与实时流主题序列之间的时间关系。提出了一种新的双重自我注意机制来模拟序列之间的相互作用，而不是单独学习序列。双重自我关注包括两个模块，LCA 和 LVA，以利用观众忠诚度，提高效率和灵活性。最后，为了促进新流媒体的冷启动建议，实现了一个协作扩散机制，以改善元学习者。通过在实际数据集中的实验，CENTR 在常规和冷启动情况下都优于最先进的推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+the+Co-evolution+Process+on+Live+Stream+Platforms+with+Dual+Self-attention+for+Next-topic+Recommendations)|0|
|[HAMUR: Hyper Adapter for Multi-Domain Recommendation](https://doi.org/10.1145/3583780.3615137)|Xiaopeng Li, Fan Yan, Xiangyu Zhao, Yichao Wang, Bo Chen, Huifeng Guo, Ruiming Tang|Huawei Noah's Ark Lab, Shenzhen, China; City University of Hong Kong, Hong Kong, Hong Kong|Multi-Domain Recommendation (MDR) has gained significant attention in recent years, which leverages data from multiple domains to enhance their performance concurrently.However, current MDR models are confronted with two limitations. Firstly, the majority of these models adopt an approach that explicitly shares parameters between domains, leading to mutual interference among them. Secondly, due to the distribution differences among domains, the utilization of static parameters in existing methods limits their flexibility to adapt to diverse domains. To address these challenges, we propose a novel model Hyper Adapter for Multi-Domain Recommendation (HAMUR). Specifically, HAMUR consists of two components: (1). Domain-specific adapter, designed as a pluggable module that can be seamlessly integrated into various existing multi-domain backbone models, and (2). Domain-shared hyper-network, which implicitly captures shared information among domains and dynamically generates the parameters for the adapter. We conduct extensive experiments on two public datasets using various backbone networks. The experimental results validate the effectiveness and scalability of the proposed model.|多域推荐(MDR)近年来受到了广泛的关注，它利用来自多个域的数据来同时提高它们的性能。然而，当前的 MDR 模型面临两个限制。首先，这些模型中的大多数都采用了域之间显式共享参数的方法，导致了域之间的相互干扰。其次，由于领域之间的分布差异，现有方法中静态参数的使用限制了它们适应不同领域的灵活性。为了应对这些挑战，我们提出了一种新型的多域推荐超级适配器(HAMUR)模型。具体来说，HAMUR 由两部分组成: (1)。特定于领域的适配器，设计为可插入模块，可以无缝集成到各种现有的多领域主干模型，以及(2)。域共享超网络，它隐式地捕获域之间的共享信息并动态地生成适配器的参数。我们使用不同的骨干网络对两个公共数据集进行了广泛的实验。实验结果验证了该模型的有效性和可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HAMUR:+Hyper+Adapter+for+Multi-Domain+Recommendation)|0|
|[Prompt Distillation for Efficient LLM-based Recommendation](https://doi.org/10.1145/3583780.3615017)|Lei Li, Yongfeng Zhang, Li Chen|Rutgers University, New Brunswick, NJ, USA; Hong Kong Baptist University, Hong Kong, Hong Kong|Large language models (LLM) have manifested unparalleled modeling capability on various tasks, e.g., multi-step reasoning, but the input to these models is mostly limited to plain text, which could be very long and contain noisy information. Long text could take long time to process, and thus may not be efficient enough for recommender systems that require immediate response. In LLM-based recommendation models, user and item IDs are usually filled in a template (i.e., discrete prompt) to allow the models to understand a given task, but the models usually need extensive fine-tuning to bridge the user/item IDs and the template words and to unleash the power of LLM for recommendation. To address the problems, we propose to distill the discrete prompt for a specific task to a set of continuous prompt vectors so as to bridge IDs and words and to reduce the inference time. We also design a training strategy with an attempt to improve the efficiency of training these models. Experimental results on three real-world datasets demonstrate the effectiveness of our PrOmpt Distillation (POD) approach on both sequential recommendation and top-N recommendation tasks. Although the training efficiency can be significantly improved, the improvement of inference efficiency is limited. This finding may inspire researchers in the community to further improve the inference efficiency of LLM-based recommendation models.|大型语言模型(LLM)在多种任务(如多步推理)上表现出了无与伦比的建模能力，但是这些模型的输入大多局限于纯文本，这些文本可能非常长并且包含有噪声的信息。处理冗长的文本可能需要很长的时间，因此对于需要立即响应的推荐系统来说，效率可能不够高。在基于 LLM 的推荐模型中，用户和项目 ID 通常填写在一个模板中(即，离散提示符) ，以使模型能够理解给定的任务，但是模型通常需要大量的微调来连接用户/项目 ID 和模板词，并释放 LLM 的推荐功能。为了解决这个问题，我们提出将特定任务的离散提示提取到一组连续的提示向量中，从而桥接 ID 和单词，减少推理时间。我们还设计了一个训练策略，试图提高这些模型的训练效率。在三个实际数据集上的实验结果表明了本文提示精馏(POD)方法在顺序推荐和前 N 推荐任务上的有效性。虽然训练效率可以显著提高，但推理效率的提高是有限的。这一发现可能会激励社区研究人员进一步提高基于 LLM 的推荐模型的推理效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Distillation+for+Efficient+LLM-based+Recommendation)|0|
|[Bias Invariant Approaches for Improving Word Embedding Fairness](https://doi.org/10.1145/3583780.3614792)|Siyu Liao, Ringting Zhang, Barbara Poblete, Vanessa Murdock|Amazon.com, Seattle, WA, USA; University of Chile & Amazon.com, Santiago, Chile|Many public pre-trained word embeddings have been shown to encode different types of biases. Embeddings are often obtained from training on large pre-existing corpora, and therefore resulting biases can be a reflection of unfair representations in the original data. Bias, in this scenario, is a challenging problem since current mitigation techniques require knowing and understanding existing biases in the embedding, which is not always possible. In this work, we propose to improve word embedding fairness by borrowing methods from the field of data privacy. The idea behind this approach is to treat bias as if it were a special type of training data leakage. This has the unique advantage of not requiring prior knowledge of potential biases in word embeddings. We investigated two types of privacy algorithms, and measured their effect on bias using four different metrics. To investigate techniques from differential privacy, we applied Gaussian perturbation to public pre-trained word embeddings. To investigate noiseless privacy, we applied vector quantization during training. Experiments show that both approaches improve fairness for commonly used embeddings, and additionally, noiseless privacy techniques reduce the size of the resulting embedding representation.|许多公开的预先训练的词语嵌入已经被证明可以编码不同类型的偏见。嵌入常常是通过对大型预先存在的语料库进行训练而获得的，因此产生的偏差可能是原始数据中不公平表示的反映。在这种情况下，偏差是一个具有挑战性的问题，因为当前的缓解技术需要了解和理解嵌入中存在的偏差，而这并不总是可能的。本文从数据隐私的角度出发，提出了一种改进嵌入公平性的方法。这种方法背后的思想是把偏差当作一种特殊类型的训练数据泄漏来处理。这样做的独特优点是不需要事先知道嵌入词中的潜在偏差。我们研究了两种类型的隐私算法，并使用四种不同的指标来测量它们对偏差的影响。为了研究基于差分隐私的嵌入技术，我们将高斯扰动应用于公共预先训练的单词嵌入。为了研究无声的私隐，我们在训练期间使用了向量量化。实验结果表明，这两种方法都提高了常用嵌入算法的公平性，并且无噪隐私技术减小了嵌入表示的大小。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+Invariant+Approaches+for+Improving+Word+Embedding+Fairness)|0|
|[PopDCL: Popularity-aware Debiased Contrastive Loss for Collaborative Filtering](https://doi.org/10.1145/3583780.3615009)|Zhuang Liu, Haoxuan Li, Guanming Chen, Yuanxin Ouyang, Wenge Rong, Zhang Xiong|Beihang University, Beijing, China|Collaborative filtering (CF) is the basic method for recommendation with implicit feedback. Recently, various state-of-the-art CF integrates graph neural networks. However, they often suffer from popularity bias, causing recommendations to deviate from users' genuine preferences. Additionally, several contrastive learning methods based on the in-batch sample strategy have been proposed to train the CF model effectively, but they are prone to suffering from sample bias. To address this problem, debiased contrastive loss has been employed in the recommendation, but instead of personalized debiasing, it treats each user equally. In this paper, we propose a popularity-aware debiased contrastive loss for CF, which can adaptively correct the positive and negative scores based on the popularity of users and items. Our approach aims to reduce the negative impact of popularity and sample bias simultaneously. We theoretically analyze the effectiveness of the proposed method and reveal the relationship between popularity and gradient, which justifies the correction strategy. We extensively evaluate our method on three public benchmarks over balanced and imbalanced settings. The results demonstrate its superiority over the existing debiased strategies, not only on the entire datasets but also when segmenting the datasets based on item popularity.|协同过滤(CF)是内隐反馈推荐的基本方法。最近，各种最先进的 CF 集成了图神经网络。然而，他们经常受到流行偏见的影响，导致推荐偏离用户的真实偏好。此外，为了有效地训练 CF 模型，人们提出了几种基于批内样本策略的对比学习方法，但这些方法容易产生样本偏差。为了解决这个问题，去偏对比度损失被用于推荐，但它不是个性化的去偏，它对每个用户一视同仁。本文提出了一种基于流行度的消偏对比度损失算法，该算法可以根据用户和项目的流行度自适应地修正正负分值。我们的方法旨在同时减少受欢迎程度和样本偏差的负面影响。从理论上分析了该方法的有效性，揭示了流行度与梯度的关系，从而验证了该方法的正确性。我们广泛评估我们的方法在三个公共基准平衡和不平衡的设置。实验结果表明，无论是在整个数据集上，还是在基于项目知名度的数据集分割上，该方法都优于现有的去偏策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PopDCL:+Popularity-aware+Debiased+Contrastive+Loss+for+Collaborative+Filtering)|0|
|[ForeSeer: Product Aspect Forecasting Using Temporal Graph Embedding](https://doi.org/10.1145/3583780.3614887)|Zixuan Liu, Gaurush Hiranandani, Kun Qian, Edward W. Huang, Yi Xu, Belinda Zeng, Karthik Subbian, Sheng Wang|; University of Washington, Seattle, WA, USA; Amazon, Seattle, WA, USA; Amazon, Palo Alto, CA, USA|Developing text mining approaches to mine aspects from customer reviews has been well-studied due to its importance in understanding customer needs and product attributes. In contrast, it remains unclear how to predict the future emerging aspects of a new product that currently has little review information. This task, which we named product aspect forecasting, is critical for recommending new products, but also challenging because of the missing reviews. Here, we propose ForeSeer, a novel textual mining and product embedding approach progressively trained on temporal product graphs for this novel product aspect forecasting task. ForeSeer transfers reviews from similar products on a large product graph and exploits these reviews to predict aspects that might emerge in future reviews. A key novelty of our method is to jointly provide review, product, and aspect embeddings that are both time-sensitive and less affected by extremely imbalanced aspect frequencies. We evaluated ForeSeer on a real-world product review system containing 11,536,382 reviews and 11,000 products over 3 years. We observe that ForeSeer substantially outperformed existing approaches with at least 49.1\% AUPRC improvement under the real setting where aspect associations are not given. ForeSeer further improves future link prediction on the product graph and the review aspect association prediction. Collectively, Foreseer offers a novel framework for review forecasting by effectively integrating review text, product network, and temporal information, opening up new avenues for online shopping recommendation and e-commerce applications.|由于文本挖掘在理解客户需求和产品属性方面的重要性，开发从客户评论中挖掘方面的文本挖掘方法已经得到了很好的研究。相比之下，目前尚不清楚如何预测新产品的未来新出现的方面，目前几乎没有审查信息。这项任务，我们命名为产品方面的预测，是至关重要的推荐新产品，但也具有挑战性，因为缺少审查。在这里，我们提出了 ForeSeer，一种新的文本挖掘和产品嵌入方法，逐步训练的时间产品图为这种新的产品方面的预测任务。ForeSeer 将类似产品的评论转移到一个较大的产品图上，并利用这些评论来预测未来评论中可能出现的方面。我们的方法的一个关键的新颖之处是联合提供审查、产品和方面嵌入，它们都是时间敏感的，并且受极不平衡的方面频率的影响较小。我们在一个包含11,536,382个评论和11,000个产品的真实世界产品评论系统上对 ForeSeer 进行了评估。我们观察到 ForeSeer 在没有给出方面关联的实际情况下，至少有49.1% 的 AUPRC 改进，大大优于现有的方法。ForeSeer 进一步改进了产品图上的未来链接预测和评论方面的关联预测。通过有效地整合评论文本、产品网络和时间信息，为在线购物推荐和电子商务应用开辟了新的途径，Foreseer 提供了一个新颖的评论预测框架。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ForeSeer:+Product+Aspect+Forecasting+Using+Temporal+Graph+Embedding)|0|
|[Neural Personalized Topic Modeling for Mining User Preferences on Social Media](https://doi.org/10.1145/3583780.3614987)|Luyang Liu, Qunyang Lin, Haonan Tong, Hongyin Zhu, Ke Liu, Min Wang, Chuang Zhang|Inspur Electronic Information Industry Co., Ltd., Beijing, China|With the rapid development of web services, social media has been a prevalent and readily way for people to express themselves and share their daily lives. Consequently, numerous user-generated content is accumulated on social media platforms. These data usually contain rich information and knowledge for users, which is a viable source for user data mining. As one of the prevalent techniques in user data mining, mining personalized topics and discovering user preferences from social media data attract much interest in academic and industrial communities. The emerging Neural Topic Models(NTMs) have recently shown leading performance and scalability by employing neural networks. However, most existing NTMs usually model topics simply from observed document token information and do not explicitly take user preferences into the generative process, which inevitably fails to model personalized topics. To address this issue, we introduce Neural Personalized Topic Model(NPTM), a novel NTM that can discover personalized topics and user preferences. NPTM introduces a novel hybrid generative process for combining user preferences and contextualized document codes in modeling personalized topics. A transformer-based document encoder to obtain contextualized document codes. For user preference modeling, NPTM regards user-related information as trainable user embeddings, further determining user preferences over the topics. Following the proposed hybrid generative process, we present a module-wise asynchronous optimization strategy to get coherent topics and user preferences. Then, we apply our model to two challenging real-world social media post collections and compare them against several baseline methods to verify our contributions. The experimental results demonstrate the effectiveness of the proposed method.|随着网络服务的快速发展，社交媒体已经成为人们表达自己和分享日常生活的一种流行和便捷的方式。因此，社交媒体平台上积累了大量的用户生成内容。这些数据通常包含丰富的用户信息和知识，这是用户数据挖掘的可行来源。作为用户数据挖掘的一种流行技术，从社会媒体数据中挖掘个性化主题和发现用户偏好引起了学术界和工业界的广泛关注。新兴的神经主题模型(NTMs)通过使用神经网络表现出领先的性能和可扩展性。然而，大多数现有的 NTM 通常只是根据观察到的文档令牌信息对主题进行建模，并没有明确地将用户偏好引入到生成过程中，这就不可避免地无法对个性化主题进行建模。为了解决这个问题，我们引入了神经个性化主题模型(NPTM) ，这是一种新的可以发现个性化主题和用户偏好的神经个性化主题模型。NPTM 引入了一种新的混合生成过程，将用户偏好和上下文文档代码相结合，对个性化主题进行建模。一种基于转换器的获取上下文文档编码的文档编码器。对于用户偏好建模，NPTM 将用户相关信息视为可训练的用户嵌入，进一步确定用户对主题的偏好。根据所提出的混合生成过程，我们提出了一个模块化的异步优化策略，以获得一致的主题和用户偏好。然后，我们将我们的模型应用于两个具有挑战性的现实社会媒体帖子集合，并将它们与几个基线方法进行比较，以验证我们的贡献。实验结果表明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Personalized+Topic+Modeling+for+Mining+User+Preferences+on+Social+Media)|0|
|[Improving Long-Tail Item Recommendation with Graph Augmentation](https://doi.org/10.1145/3583780.3614929)|Sichun Luo, Chen Ma, Yuanzhang Xiao, Linqi Song|University of Hawaii at Manoa, Honolulu, HI, USA; City University of Hong Kong, Hong Kong, Hong Kong; City University of Hong Kong & City University of Hong Kong Shenzhen Research Institute, Hong Kong, Hong Kong|The ubiquitous long-tail distribution of inherent user behaviors results in worse recommendation performance for the items with fewer user records (i.e., tail items) than those with richer ones (i.e., head items). Graph-based recommendation methods (e.g., using graph neural networks) have recently emerged as a powerful tool for recommender systems, often outperforming traditional methods. However, existing techniques for alleviating the long-tail problem mainly focus on traditional methods. There is a lack of graph-based methods that can efficiently deal with the long-tail problem. In this paper, we propose a novel approach, Graph Augmentation for Long-tail Recommendation (GALORE), which can be plugged into any graph-based recommendation models to improve the performance for tail items. GALORE incorporates an edge addition module that enriches the graph's connectivity for tail items by injecting additional item-to-item edges. To further balance the graph structure, GALORE utilizes a degree-aware edge dropping strategy, preserving the more valuable edges from the tail items while selectively discarding less informative edges from the head items. Beyond structural augmentation, we synthesize new data samples, thereby addressing the data scarcity issue for tail items. We further introduce a two-stage training strategy to facilitate the learning for both head and tail items. Comprehensive empirical studies conducted on four datasets show that GALORE outperforms existing methods in terms of the performance for tail items as well as the overall performance.|无处不在的固有用户行为的长尾分布导致用户记录较少的条目(即尾条目)的推荐性能低于用户记录较丰富的条目(即头条目)的推荐性能。基于图形的推荐方法(例如，使用图形神经网络)最近已经成为推荐系统的一个强大工具，其性能通常优于传统方法。然而，现有的解决长尾问题的技术主要集中在传统方法上。缺乏基于图论的方法来有效地处理长尾问题。在本文中，我们提出了一种新的方法，图增强的长尾推荐(GALORE) ，可以插入到任何基于图的推荐模型，以提高性能的尾项。GALORE 合并了一个边缘添加模块，通过注入额外的项目到项目的边缘，丰富了图形对尾部项目的连通性。为了进一步平衡图形结构，GALORE 使用了一种度感知的边缘丢弃策略，保留了尾部项目中更有价值的边缘，同时选择性地丢弃了头部项目中信息量较小的边缘。除了结构增强，我们还合成了新的数据样本，从而解决了尾部项目的数据稀缺问题。我们进一步引入了一个两阶段的训练策略，以促进头部和尾部项目的学习。对四个数据集进行的综合实证研究表明，GALORE 在尾部项目的性能以及整体性能方面优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Long-Tail+Item+Recommendation+with+Graph+Augmentation)|0|
|[Parallel Knowledge Enhancement based Framework for Multi-behavior Recommendation](https://doi.org/10.1145/3583780.3615004)|Chang Meng, Chenhao Zhai, Yu Yang, Hengyu Zhang, Xiu Li|Tsinghua University, Shenzhen, China|Multi-behavior recommendation algorithms aim to leverage the multiplex interactions between users and items to learn users' latent preferences. Recent multi-behavior recommendation frameworks contain two steps: fusion and prediction. In the fusion step, advanced neural networks are used to model the hierarchical correlations between user behaviors. In the prediction step, multiple signals are utilized to jointly optimize the model with a multi-task learning (MTL) paradigm. However, recent approaches have not addressed the issue caused by imbalanced data distribution in the fusion step, resulting in the learned relationships being dominated by high-frequency behaviors. In the prediction step, the existing methods use a gate mechanism to directly aggregate expert information generated by coupling input, leading to negative information transfer. To tackle these issues, we propose a Parallel Knowledge Enhancement Framework (PKEF) for multi-behavior recommendation. Specifically, we enhance the hierarchical information propagation in the fusion step using parallel knowledge (PKF). Meanwhile, in the prediction step, we decouple the representations to generate expert information and introduce a projection mechanism during aggregation to eliminate gradient conflicts and alleviate negative transfer (PME). We conduct comprehensive experiments on three real-world datasets to validate the effectiveness of our model. The results further demonstrate the rationality and effectiveness of the designed PKF and PME modules. The source code and datasets are available at https://github.com/MC-CV/PKEF.|多行为推荐算法旨在利用用户和项目之间的多重交互来了解用户的潜在偏好。最近的多行为推荐框架包含两个步骤: 融合和预测。在融合步骤中，采用先进的神经网络对用户行为之间的层次关系进行建模。在预测步骤中，利用多个信号与多任务学习(MTL)范式联合优化模型。然而，最近的方法还没有解决由于融合步骤中数据分布不平衡所引起的问题，导致学习关系被高频行为所主导。在预测步骤中，现有的方法采用门机制直接聚合由耦合输入产生的专家信息，导致负信息传递。为了解决这些问题，我们提出了一个用于多行为推荐的并行知识增强框架(PKEF)。具体地说，我们在融合步骤中使用并行知识(PKF)来增强层次信息的传播。同时，在预测步骤中，对表示进行解耦，生成专家信息，并在聚合过程中引入投影机制，消除梯度冲突，减轻负迁移(PME)。为了验证模型的有效性，我们在三个实际数据集上进行了综合实验。仿真结果进一步验证了所设计的 PKF 模块和 PME 模块的合理性和有效性。源代码和数据集可在 https://github.com/mc-cv/pkef 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Parallel+Knowledge+Enhancement+based+Framework+for+Multi-behavior+Recommendation)|0|
|[DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective](https://doi.org/10.1145/3583780.3614833)|Pu Miao, Zeyao Du, Junlin Zhang|Sina Weibo, BeiJing, China; China Literature Limited, Shang Hai, China; Sina Weibo, Beijing, China|Several prior studies have suggested that word frequency biases can cause the Bert model to learn indistinguishable sentence embeddings. Contrastive learning schemes such as SimCSE and ConSERT have already been adopted successfully in unsupervised sentence embedding to improve the quality of embeddings by reducing this bias. However, these methods still introduce new biases such as sentence length bias and false negative sample bias, that hinders model's ability to learn more fine-grained semantics. In this paper, we reexamine the challenges of contrastive sentence embedding learning from a debiasing perspective and argue that effectively eliminating the influence of various biases is crucial for learning high-quality sentence embeddings. We think all those biases are introduced by simple rules for constructing training data in contrastive learning and the key for contrastive learning sentence embedding is to mimic the distribution of training data in supervised machine learning in unsupervised way. We propose a novel contrastive framework for sentence embedding, termed DebCSE, which can eliminate the impact of these biases by an inverse propensity weighted sampling method to select high-quality positive and negative pairs according to both the surface and semantic similarity between sentences. Extensive experiments on semantic textual similarity (STS) benchmarks reveal that DebCSE significantly outperforms the latest state-of-the-art models with an average Spearman's correlation coefficient of 80.33% on BERTbase.|已有的研究表明，词频偏差可以导致 Bert 模型学习不可区分的句子嵌入。对比学习方法如 SimCSE 和 ConSERT 已经成功地应用于无监督句子嵌入中，通过减少这种偏差来提高嵌入质量。然而，这些方法仍然引入了新的偏差，如句子长度偏差和错误的否定样本偏差，阻碍了模型学习更细粒度语义的能力。本文从消除偏差的角度重新审视对比句嵌入学习的挑战，认为有效地消除各种偏差的影响对于学习高质量的句子嵌入是至关重要的。我们认为所有这些偏差都是由构建对比学习中的训练数据的简单规则引入的，而对比学习句子嵌入的关键是以无监督的方式模拟训练数据在监督式学习中的分布。我们提出了一个新的句子嵌入对比框架，称为 DebCSE，它可以消除这些偏见的影响，通过反倾向加权抽样方法，根据句子之间的表面和语义相似性选择高质量的正负对。对语义文本相似度(STS)测试的大量实验表明，DebCSE 的性能明显优于最新的最先进的模型，在 BERTbase 上 Spearman 的平均相关系数为80.33% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DebCSE:+Rethinking+Unsupervised+Contrastive+Sentence+Embedding+Learning+in+the+Debiasing+Perspective)|0|
|[Bi-channel Multiple Sparse Graph Attention Networks for Session-based Recommendation](https://doi.org/10.1145/3583780.3614791)|Shutong Qiao, Wei Zhou, Junhao Wen, Hongyu Zhang, Min Gao|Chongqing University, Chongqing, China|Session-based Recommendation (SBR) has recently received significant attention due to its ability to provide personalized recommendations based on the interaction sequences of anonymous session users. The challenges facing SBR consist mainly of how to utilize information other than the current session and how to reduce the negative impact of irrelevant information in the session data on the prediction. To address these challenges, we propose a novel graph attention network-based model called Multiple Sparse Graph Attention Networks (MSGAT). MSGAT leverages two parallel channels to model intra-session and inter-session information. In the intra-session channel, we utilize a gated graph neural network to perform initial encoding, followed by a self-attention mechanism to generate the target representation. The global representation is then noise-reduced based on the target representation. Additionally, the target representation is used as a medium to connect the two channels. In the inter-session channel, the noise-reduced relation representation is generated using the global attention mechanism of target perception. Moreover, MSGAT fully considers session similarity from the intent perspective by integrating valid information from both channels. Finally, the intent neighbor collaboration module effectively combines relevant information to enhance the current session representation. Extensive experiments on five datasets demonstrate that simultaneous modeling of intra-session and inter-session data can effectively enhance the performance of the SBR model.|基于会话的推荐技术(SBS)由于能够根据匿名会话用户的交互序列提供个性化的推荐，近年来受到了广泛的关注。SBR 面临的挑战主要包括如何利用本届会议以外的信息，以及如何减少会议数据中不相关信息对预测的负面影响。为了应对这些挑战，我们提出了一种新的基于图注意网络的模型，称为多稀疏图注意网络(MSGAT)。MSGAT 利用两个并行通道对会话内和会话间信息建模。在会话内信道中，利用门控图神经网络进行初始编码，然后利用自注意机制生成目标表示。然后在目标表示的基础上对全局表示进行噪声抑制。此外，目标表示形式被用作连接两个通道的媒介。在会话间信道中，利用目标感知的全局注意机制生成降噪关系表示。此外，MSGAT 通过整合来自两个通道的有效信息，从意图的角度充分考虑了会话相似性。最后，意向邻居协作模块有效地结合了相关信息，增强了当前的会话表示。对五个数据集的大量实验表明，同时建模会话内和会话间数据可以有效地提高 SBR 模型的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bi-channel+Multiple+Sparse+Graph+Attention+Networks+for+Session-based+Recommendation)|0|
|[CDR: Conservative Doubly Robust Learning for Debiased Recommendation](https://doi.org/10.1145/3583780.3614805)|Zijie Song, Jiawei Chen, Sheng Zhou, Qihao Shi, Yan Feng, Chun Chen, Can Wang|Zhejiang University, Hangzhou, China; Hangzhou City University, Hangzhou, China|In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.   To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.|在推荐系统(RS)中，用户行为数据是观察性的而不是实验性的，这导致了数据中广泛的偏差。因此，处理偏差已经成为推荐系统领域的一个主要挑战。近年来，双鲁棒学习(DR)以其显著的性能和鲁棒性得到了广泛的关注。然而，我们的实验结果表明，现有的 DR 方法受到所谓的有毒归责的严重影响，其中归责明显偏离真相，并成为适得其反。为了解决这个问题，本文提出了保守的双稳健策略(CDR) ，它通过检查估计的均值和方差来过滤估计。理论分析表明，CDR 方差减小，尾界改善，实验结果表明，CDR 方差显著提高了性能，并且确实能够减少有毒插补的频率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CDR:+Conservative+Doubly+Robust+Learning+for+Debiased+Recommendation)|0|
|[Disentangled Interest importance aware Knowledge Graph Neural Network for Fund Recommendation](https://doi.org/10.1145/3583780.3614846)|Ke Tu, Wei Qu, Zhengwei Wu, Zhiqiang Zhang, Zhongyi Liu, Yiming Zhao, Le Wu, Jun Zhou, Guannan Zhang|Ant Financial, Hangzhou, China; Alipay, Beijing, China; Ant Group, Hangzhou, China; Ant Financial Services Group, Hangzhou, China; Ant Group, Beijing, China; Hefei University of Technology, Hefei, China|At present, people are gradually becoming aware of financial management and thus fund recommendation attracts more and more attention to help them find suitable funds quickly. As a user usually takes many factors (e.g., fund theme, fund manager) into account when investing a fund and the fund usually consists of a substantial collection of investments, effectively modeling multi-interest representations is more crucial for personalized fund recommendation than the traditional goods recommendation. However, existing multi-interest methods are largely sub-optimal for fund recommendation, since they ignore financial domain knowledge and diverse fund investment intentions. In this work, we propose a Disentangled Interest importance aware Knowledge Graph Neural Network (DIKGNN) for personalized fund recommendation on FinTech platforms. In particular, we restrict the multiple intent spaces by introducing the attribute nodes from the fund knowledge graph as the minimum intent modeling unit to utilize financial domain knowledge and provide interpretability. In the intent space, we define disentangled intent representations, equipped with intent importance distributions to describe the diverse fund investment intentions. Then we design a new neighbor aggregation mechanism with the learned intent importance distribution upon the interaction graph and knowledge graph to collect multi-intent information. Furthermore, we leverage micro independence and macro balance constraints on the representations and distributions respectively to encourage intent independence and diversity. The extensive experiments on public recommendation benchmarks demonstrate that DIKGNN can achieve substantial improvement over state-of-the-art methods. Our proposed model is also evaluated over one real-world industrial fund dataset from a FinTech platform and has been deployed online.|目前，人们逐渐意识到财务管理的重要性，因此基金推荐越来越受到人们的重视，以帮助他们尽快找到合适的基金。由于投资者在投资基金时通常会考虑多种因素(如基金主题、基金经理等) ，而基金通常由大量的投资组合构成，因此有效地建立多利益表示模型对于个性化基金推荐比传统的商品推荐更为重要。然而，现有的多利率基金推荐方法由于忽视了金融领域的知识和基金投资意向的多样性，在很大程度上不能满足基金推荐的要求。在这项工作中，我们提出了一个分离利益重要性感知知识图神经网络(DIKGNN)个性化基金推荐在金融科技平台。特别地，我们通过引入基金知识图中的属性节点作为最小意图建模单元来限制多意图空间，以利用金融领域的知识并提供可解释性。在意向空间中，我们定义了非纠缠意向表示，并配备了意向重要性分布来描述不同的基金投资意向。然后设计了一种新的邻居聚集机制，在交互图和知识图上分布学习意图的重要性，以收集多意图信息。此外，我们利用微观独立性和宏观平衡约束分别表示和分布，以鼓励意向独立性和多样性。对公众推荐基准的广泛实验表明，DIKGNN 可以取得实质性的改善国家的最新方法。我们提出的模型也评估了一个来自金融科技平台的真实世界的工业基金数据集，并已在线部署。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Interest+importance+aware+Knowledge+Graph+Neural+Network+for+Fund+Recommendation)|0|
|[Node-dependent Semantic Search over Heterogeneous Graph Neural Networks](https://doi.org/10.1145/3583780.3614989)|Zhenyi Wang, Huan Zhao, Fengqi Liang, Chuan Shi|4Paradigm Inc., Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|In recent years, Heterogeneous Graph Neural Networks (HGNNs) have been the state-of-the-art approaches for various tasks on Heterogeneous Graphs (HGs), e.g., recommendation and social network analysis. Despite the success of existing HGNNs, the utilization of the intricate semantic information in HGs is still insufficient. In this work, we study the problem of how to design powerful HGNNs under the guidance of node-dependent semantics. Specifically, to perform semantic search over HGNNs, we propose to develop semantic structures in terms of relation selection and connection selection, which could guide a task-relevant message flow. Furthermore, to better capture the diversified property of different node samples in HGs, we design predictors to adaptively decide the semantic structures per node. Extensive experiments on seven benchmarking datasets across different downstream tasks, i.e., node classification and recommendation, show that our method can consistently outperform various state-of-the-art baselines with shorter inference latency, which justifies its effectiveness and efficiency. The code and data are available at https://github.com/BUPT-GAMMA/NDS.|近年来，异构图神经网络(HGNN)已经成为异构图(HGs)上各种任务(如推荐和社会网络分析)的最新研究方法。尽管现有的 HGNN 取得了成功，但在 HGs 中使用的复杂语义信息仍然不足。本文主要研究如何在节点依赖语义的指导下设计强大的 HGNN。具体来说，为了在 HGNN 上进行语义搜索，我们提出了在关系选择和连接选择方面开发语义结构，以指导任务相关的消息流。此外，为了更好地捕捉 HG 中不同节点样本的多样性，我们设计了预测器来自适应地确定每个节点的语义结构。对不同下游任务(即节点分类和推荐)的7个基准测试数据集进行的大量实验表明，我们的方法能够以更短的推理延迟持续优于各种最先进的基线，这证明了其有效性和效率。代码和数据可在 https://github.com/bupt-gamma/nds 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Node-dependent+Semantic+Search+over+Heterogeneous+Graph+Neural+Networks)|0|
|[Towards Communication-Efficient Model Updating for On-Device Session-Based Recommendation](https://doi.org/10.1145/3583780.3615088)|Xin Xia, Junliang Yu, Guandong Xu, Hongzhi Yin|University of Technology Sydney, Sydney, NSW, Australia; The University of Queensland, Brisbane, QLD, Australia|On-device recommender systems recently have garnered increasing attention due to their advantages of providing prompt response and securing privacy. To stay current with evolving user interests, cloud-based recommender systems are periodically updated with new interaction data. However, on-device models struggle to retrain themselves because of limited onboard computing resources. As a solution, we consider the scenario where the model retraining occurs on the server side and then the updated parameters are transferred to edge devices via network communication. While this eliminates the need for local retraining, it incurs a regular transfer of parameters that significantly taxes network bandwidth. To mitigate this issue, we develop an efficient approach based on compositional codes to compress the model update. This approach ensures the on-device model is updated flexibly with minimal additional parameters whilst utilizing previous knowledge. The extensive experiments conducted on multiple session-based recommendation models with distinctive architectures demonstrate that the on-device model can achieve comparable accuracy to the retrained server-side counterpart through transferring an update 60x smaller in size. The codes are available at \url{https://github.com/xiaxin1998/ODUpdate}.|设备上推荐系统最近受到越来越多的关注，因为它们具有提供快速响应和保护隐私的优点。为了与不断变化的用户兴趣保持同步，基于云的推荐系统定期更新新的交互数据。然而，由于机载计算资源有限，在设备上的模型很难进行再培训。作为解决方案，我们考虑在服务器端进行模型再训练，然后通过网络通信将更新后的参数传输到边缘设备。虽然这消除了对本地再培训的需要，但它引起定期参数传输，大大增加了网络带宽的负担。为了解决这一问题，我们提出了一种基于复合代码的模型更新压缩方法。这种方法确保在设备上的模型更新灵活，最小的额外参数，同时利用以前的知识。在具有独特体系结构的多会话推荐模型上进行的大量实验表明，设备上模型可以通过传输小60倍的更新来达到与再训练的服务器端模型相当的精度。这些代码可以在 url { https://github.com/xiaxin1998/odupdate }获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Communication-Efficient+Model+Updating+for+On-Device+Session-Based+Recommendation)|0|
|[CoSaR: Combating Label Noise Using Collaborative Sample Selection and Adversarial Regularization](https://doi.org/10.1145/3583780.3614826)|Xiaobo Zhang, Yutao Liu, Hao Wang, Wei Wang, Panpan Ni, Ji Zhang|Southwest Jiaotong University, Chendu, China; Southwest Jiaotong University, Chengdu, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; University of Southern Queensland, Toowoomba, Australia|Learning with noisy labels is nontrivial for deep learning models. Sample selection is a widely investigated research topic for handling noisy labels. However, most existing methods face challenges such as imprecise selection, a lack of global selection capabilities, and the need for tedious hyperparameter tuning. In this paper, we propose CoSaR (Collaborative Selection and adversarial Regularization ), a twin-networks based model that performs globally adaptive sample selection to tackle label noise. Specifically, the collaborative selection estimates the average distribution distances between predictions and generation labels through the collaboration of two networks to address the bias of the average distribution distances and the manual tuning of hyperparameters. Adversarial regularization is integrated into CoSaR to restrict the network's tendency to fit and memorize noisy labels, thereby enhancing its collaborative selection capability. In addition, we employ a label smoothing regularization and two types of data augmentation to enhance the robustness of the model further. Extensive experiments on both synthetic and real-world noisy datasets demonstrate that the proposed model outperforms baseline methods remarkably, with an accuracy improvement ranging between +0.56% and +15.14%.|对于深度学习模型来说，使用噪声标签进行学习是非常重要的。样本选择是一个广泛研究的课题，处理噪声标签。然而，大多数现有的方法都面临挑战，如选择不精确、缺乏全局选择能力以及需要冗长的超参数调优。本文提出了一种基于双网络的协同选择与对抗正则化(CoSaR)模型，该模型对标签噪声进行全局自适应样本选择。具体而言，协作选择通过两个网络的协作来估计预测和产生标签之间的平均分布距离，以解决平均分布距离的偏差和手动调整超参数。将对抗性规则化集成到 CoSaR 中，以限制网络适配和记忆噪声标签的倾向，从而增强其协同选择能力。此外，我们采用了标签平滑正则化和两种数据增强方法来进一步增强模型的鲁棒性。在合成和真实噪声数据集上的大量实验表明，该模型的性能明显优于基线方法，精度提高幅度在 + 0.56% 和 + 15.14% 之间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoSaR:+Combating+Label+Noise+Using+Collaborative+Sample+Selection+and+Adversarial+Regularization)|0|
|[HST-GT: Heterogeneous Spatial-Temporal Graph Transformer for Delivery Time Estimation in Warehouse-Distribution Integration E-Commerce](https://doi.org/10.1145/3583780.3614918)|Xiaohui Zhao, Shuai Wang, Hai Wang, Tian He, Desheng Zhang, Guang Wang|Southeast University, Nanjing, China; Rutgers University, New Brunswick, NJ, USA; JD Logistics, Beijing, China; Florida State University, Tallahassee, FL, USA|Warehouse-distribution integration has been adopted by many e-commerce retailers (e.g., Amazon, TAOBAO, and JD) as an efficient business mode. In warehouse-distribution integration e-commerce, one of the most important problems is to estimate the full-link delivery time for better decision-making. Existing solutions for traditional warehouse-distribution separation mode are challenging to address this problem due to two unique features in the integration mode including (i) contextual influence caused by neighbor units in heterogeneous delivery networks, (ii) uncertain delivery time caused by the dynamic temporal data (e.g., online sales volume) and heterogeneity of delivery units. To incorporate these new factors, we propose Heterogeneous Spatial-Temporal Graph Transformer (HST-GT), a novel full-link delivery time estimation method under the warehouse-distribution integration mode, where we (i) develop heterogeneous graph transformers to capture hierarchical heterogeneous information; and (ii) design a set of spatial-temporal transformers based on heterogeneous features to fully exploit the correlation of spatial and temporal information. We extensively evaluate our method based on one-month real-world data consisting of hundreds of warehouses and sorting centers, and millions of historical orders collected from one of the largest e-commerce retailers in the world. Experimental results demonstrate that our method outperforms state-of-the-art baselines in various metrics.|仓储-分销集成已被许多电子商务零售商(如亚马逊、淘宝和 JD)采用为一种高效的商业模式。在仓储-配送一体化电子商务中，为了更好地进行决策，需要解决的一个重要问题就是如何估计全程配送时间。由于集成模式中的两个独特特征，传统的仓储-分销分离模式的现有解决方案难以解决这一问题，这两个特征包括: (i)异构配送网络中邻居单元引起的上下文影响，(ii)动态时态数据(如在线销售量)引起的不确定配送时间和配送单元的异质性。为了吸收这些新的因素，我们提出了异构时空图形转换器(HST-GT) ，这是一种在仓库-分布式集成模式下的新的全链路传输时间估计方法。我们(i)开发异构图形转换器来捕获层次化的异构信息; (ii)设计一组基于异构特征的时空转换器来充分利用空间和时间信息的相关性。我们广泛评估我们的方法基于一个月的真实世界数据，包括数百个仓库和分拣中心，以及从世界上最大的电子商务零售商之一收集的数百万历史订单。实验结果表明，我们的方法优于国家的最先进的基线在各种指标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HST-GT:+Heterogeneous+Spatial-Temporal+Graph+Transformer+for+Delivery+Time+Estimation+in+Warehouse-Distribution+Integration+E-Commerce)|0|
|[Scalable Neural Contextual Bandit for Recommender Systems](https://doi.org/10.1145/3583780.3615048)|Zheqing Zhu, Benjamin Van Roy|Stanford University, Stanford, USA; Meta AI, Stanford University, Menlo Park, USA|High-quality recommender systems ought to deliver both innovative and relevant content through effective and exploratory interactions with users. Yet, supervised learning-based neural networks, which form the backbone of many existing recommender systems, only leverage recognized user interests, falling short when it comes to efficiently uncovering unknown user preferences. While there has been some progress with neural contextual bandit algorithms towards enabling online exploration through neural networks, their onerous computational demands hinder widespread adoption in real-world recommender systems. In this work, we propose a scalable sample-efficient neural contextual bandit algorithm for recommender systems. To do this, we design an epistemic neural network architecture, Epistemic Neural Recommendation (ENR), that enables Thompson sampling at a large scale. In two distinct large-scale experiments with real-world tasks, ENR significantly boosts click-through rates and user ratings by at least 9% and 6% respectively compared to state-of-the-art neural contextual bandit algorithms. Furthermore, it achieves equivalent performance with at least 29% fewer user interactions compared to the best-performing baseline algorithm. Remarkably, while accomplishing these improvements, ENR demands orders of magnitude fewer computational resources than neural contextual bandit baseline algorithms.|高质量的推荐系统应该通过与用户有效和探索性的互动交付创新和相关的内容。然而，作为许多现有推荐系统骨干的基于监督学习的神经网络，只能利用已识别的用户兴趣，在有效发现未知用户偏好方面存在不足。虽然神经上下文盗贼算法在通过神经网络实现在线探索方面取得了一些进展，但是它们繁重的计算需求阻碍了在现实世界中推荐系统的广泛采用。在这项工作中，我们提出了一个可扩展的样本效率神经上下文盗贼算法的推荐系统。为了做到这一点，我们设计了一个认知神经网络结构，认知神经推荐(ENR) ，使汤普森采样在大规模。在两个不同的大规模实验与现实世界的任务，ENR 显着提高点击率和用户评分至少9% 和6% 分别相比，国家的最先进的神经上下文土匪算法。此外，与性能最好的基线算法相比，它至少减少了29% 的用户交互，从而实现了相同的性能。值得注意的是，在完成这些改进的同时，ENR 所需的计算资源数量级比神经上下文强盗基线算法要少。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Neural+Contextual+Bandit+for+Recommender+Systems)|0|
|[PCENet: Psychological Clues Exploration Network for Multimodal Personality Assessment](https://doi.org/10.1145/3583780.3615005)|Yangfu Zhu, Yuting Wei, Meiling Li, Tingting Zhang, Siqi Wei, Bin Wu|Beijing University of Posts and Telecommunications,, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|Multimodal personality assessment aims to identify and express human personality traits in videos. Existing methods primarily focus on multimodal fusion while ignoring the inherent psychological clues essential for this interdisciplinary task. Modality clues: personality traits are stable over time due to their genetic and environmental origins, resulting in stable personality traits in the multimodal data. Trait clues: multiple traits often co-occur with non-negligible correlations, which can collectively aid trait identification. To simultaneously capture the above psychological clues, we propose a novel Psychological Clues Exploration Network (PCENet) for multimodal personality assessment, which is a human-like judgment paradigm with more generalization capability. Specifically, we first devise a multimodal hierarchical disentanglement, which clearly aligns stable representations among different modalities and separates the mutability of each modality. Subsequently, a Transformer-backbone decoder equipped with modality-to-trait attention is exploited to adaptively generate a tailored representation for each trait with the guidance of trait semantics. The trait semantics are obtained by exploiting trait correlations through self-attention. Extensive experiments on the First Impression V2 dataset demonstrate that our PCENet outperforms the state-of-the-art methods for multimodal personality assessment.|多模态人格评估旨在识别和表达视频中的人格特征。现有的方法主要侧重于多模态融合，而忽视了这一跨学科任务所必需的内在心理线索。情态线索: 由于遗传和环境起源，人格特征随着时间的推移是稳定的，在多模态数据中导致稳定的人格特征。性状线索: 多个性状常常与不可忽视的相关性共同出现，这可以共同帮助性状识别。为了同时捕捉上述心理线索，我们提出了一个新的心理线索探索网络(PCENet)的多模态人格评估，这是一个类人的判断范式，具有更多的泛化能力。具体来说，我们首先设计了一个多模态层次分离，它清楚地调整了不同模态之间的稳定表示，并分离了每种模态的可变性。然后，在特征语义的指导下，利用具有模态-特征注意的主干变压器解码器自适应地为每个特征生成一个量身定制的表示。特质语义是通过自我注意利用特质相关获得的。对第一印象 V2数据集的大量实验表明，我们的 PCENet 优于最先进的多模态人格评估方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PCENet:+Psychological+Clues+Exploration+Network+for+Multimodal+Personality+Assessment)|0|
|[G-STO: Sequential Main Shopping Intention Detection via Graph-Regularized Stochastic Transformer](https://doi.org/10.1145/3583780.3614890)|Yuchen Zhuang, Xin Shen, Yan Zhao, Chaosheng Dong, Ming Wang, Jin Li, Chao Zhang|Amazon, New York, NY, USA; Amazon, Seattle, WA, USA; Georgia Institute of Technology, Atlanta, GA, USA|Sequential recommendation requires understanding the dynamic patterns of users' behaviors, contexts, and preferences from their historical interactions. Most existing works focus on modeling user-item interactions only from the item level, ignoring that they are driven by latent shopping intentions (e.g., ballpoint pens, miniatures, etc). The detection of the underlying shopping intentions of users based on their historical interactions is a crucial aspect for e-commerce platforms, such as Amazon, to enhance the convenience and efficiency of their customers' shopping experiences. Despite its significance, the area of main shopping intention detection remains under-investigated in the academic literature. To fill this gap, we propose a graph-regularized stochastic Transformer method, G-STO. By considering intentions as sets of products and user preferences as compositions of intentions, we model both of them as stochastic Gaussian embeddings in the latent representation space. Instead of training the stochastic representations from scratch, we develop a global intention relational graph as prior knowledge for regularization, allowing relevant shopping intentions to be distributionally close. Finally, we feed the newly regularized stochastic embeddings into Transformer-based models to encode sequential information from the intention transitions. We evaluate our main shopping intention identification model on three different real-world datasets, where G-STO achieves significantly superior performances to the baselines by 18.08% in Hit@1, 7.01% in Hit@10, and 6.11% in NDCG@10 on average.|顺序推荐需要从用户的历史交互中理解用户行为、上下文和偏好的动态模式。大多数现有的作品只关注于从商品层次建模用户-商品交互，忽略了它们是由潜在的购物意图驱动的(例如，圆珠笔，微缩模型等)。基于用户历史交互的潜在购物意图的检测是亚马逊等电子商务平台提高用户购物体验的便利性和效率的一个关键方面。尽管其意义重大，主要的购物意图检测领域仍然没有得到充分的研究在学术文献。为了填补这个空白，我们提出了一个图正则化的随机变压器方法，G-STO。通过将意图看作是产品集合，将用户偏好看作是意图的组合，我们将两者建模为潜在表征空间中的随机高斯嵌入。我们不需要从头开始训练随机表示，而是开发一个全局意图关系图作为正则化的先验知识，允许相关的购物意图分布接近。最后，我们将新的正则化随机嵌入输入到基于变压器的模型中，从意图转换中编码序列信息。我们在三个不同的真实世界数据集上评估了我们的主要购物意向识别模型，其中 G-STO 在 Hit@1中的性能明显优于基线18.08% ，在 Hit@10中的性能为7.01% ，在 NDCG@10中的性能平均为6.11% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=G-STO:+Sequential+Main+Shopping+Intention+Detection+via+Graph-Regularized+Stochastic+Transformer)|0|
|[TCCM: Time and Content-Aware Causal Model for Unbiased News Recommendation](https://doi.org/10.1145/3583780.3615272)|Yewang Chen, Weiyao Ye, Guipeng Xv, Chen Lin, Xiaomin Zhu|Xiamen University, Xiamen, China; Academy of Military Sciences, Beijing, China; Huaqiao University, Xiamen, China|Popularity bias significantly impacts news recommendation systems, as popular news articles receive more exposure and are often delivered to irrelevant users, resulting in unsatisfactory performance. Existing methods have not adequately addressed the issue of popularity bias in news recommendations, largely due to the neglect of the time factor and the impact of news content on popularity. In this paper, we propose a novel approach called Time and Content-aware Causal Model, namely TCCM. It models the effects of three factors on user interaction behavior, i.e., the time factor, the news popularity, and the matching between news content and user interest. TCCM also estimates news popularity more accurately by incorporating the news content, i.e., the popularity of entity and words. Causal intervention techniques are applied to obtain debiased recommendations. Extensive experiments on well-known benchmark datasets demonstrate that the proposed approach outperforms a range of state-of-the-art techniques.|受欢迎度偏差对新闻推荐系统有显著影响，因为受欢迎的新闻文章曝光率更高，而且常常被传递给不相关的用户，从而导致不令人满意的性能。现有的研究方法没有充分解决新闻推荐中的受欢迎程度偏差问题，这主要是由于忽视了时间因素和新闻内容对受欢迎程度的影响。在本文中，我们提出了一种新的方法称为时间和内容感知的因果模型，即 TCCM。它模拟了三个因素对用户交互行为的影响，即时间因素、新闻受欢迎程度以及新闻内容与用户兴趣的匹配程度。TCCM 还通过结合新闻内容，即实体和词汇的受欢迎程度，更准确地估计新闻的受欢迎程度。应用因果干预技术来获得消除偏见的建议。在著名基准数据集上的大量实验表明，所提出的方法优于一系列最先进的技术。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TCCM:+Time+and+Content-Aware+Causal+Model+for+Unbiased+News+Recommendation)|0|
|[Attribute-enhanced Dual Channel Representation Learning for Session-based Recommendation](https://doi.org/10.1145/3583780.3615245)|Qian Chen, Jianjun Li, Zhiqiang Guo, Guohui Li, Zhiying Deng|Huazhong University of Science and Technology, Wuhan, China|Session-based recommendation (SBR) aims to predict the anonymous user's next-click items by modeling the short-term sequence pattern. As most existing SBR models generally generate item representations based only on information propagation over the short sequence while ignoring additional valuable knowledge, their expressive abilities are somewhat limited by data sparsity caused by short sequence. Though there have been some attempts on utilizing items' attributes, they basically embed attributes into items directly, ignoring the fact that 1) there is no contextual relationship among attributes; and 2) users have varying levels of attention to different attributes, which still leads to unsatisfactory performance. To tackle the issues, we propose a novel Attribute-enhanced Dual Channel Representation Learning (ADRL) model for SBR, in which we independently model session representations in attribute-related pattern and sequence-related pattern. Specifically, we learn session representations with sequence patterns from the session graph, and we further design an frequency-driven attribute aggregator to generate the attribute-related session representations within a session. The proposed attribute aggregator is plug-and-play, as it can be coupled with most existing SBR models. Extensive experiments on three real-world public datasets demonstrate the superiority of the proposed ADRL over several state-of-the-art baselines, as well as the effectiveness and efficiency of our attribute aggregator module.|基于会话的推荐(SBS)通过建立短期序列模式来预测匿名用户的下一次点击项目。由于现有的 SBR 模型大多只是基于短序列的信息传播来产生条目表示，而忽略了附加的有价值的知识，因此它们的表示能力受到短序列造成的数据稀疏的限制。尽管已经有一些尝试利用项目的属性，他们基本上直接将属性嵌入到项目中，忽略了这样一个事实: 1)属性之间没有上下文关系; 2)用户对不同属性的关注程度不同，这仍然会导致不令人满意的性能。为了解决这一问题，我们提出了一种新的基于属性增强的双通道表示学习(ADRL)模型，该模型独立地对会话表示进行属性相关模式和序列相关模式的建模。具体来说，我们从会话图中学习具有序列模式的会话表示，并且进一步设计一个频率驱动的属性聚合器来在会话中生成与属性相关的会话表示。提出的属性聚合器是即插即用的，因为它可以与大多数现有的 SBR 模型耦合。在三个真实世界的公共数据集上的大量实验表明了所提出的 ADRL 相对于几个最先进的基线的优越性，以及我们的属性聚合器模块的有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attribute-enhanced+Dual+Channel+Representation+Learning+for+Session-based+Recommendation)|0|
|[Simulating Users in Interactive Web Table Retrieval](https://doi.org/10.1145/3583780.3615187)|Björn Engelmann, Timo Breuer, Philipp Schaer|TH Köln (University of Applied Sciences), Köln, Germany|Considering the multimodal signals of search items is beneficial for retrieval effectiveness. Especially in web table retrieval (WTR) experiments, accounting for multimodal properties of tables boosts effectiveness. However, it still remains an open question how the single modalities affect user experience in particular. Previous work analyzed WTR performance in ad-hoc retrieval benchmarks, which neglects interactive search behavior and limits the conclusion about the implications for real-world user environments.   To this end, this work presents an in-depth evaluation of simulated interactive WTR search sessions as a more cost-efficient and reproducible alternative to real user studies. As a first of its kind, we introduce interactive query reformulation strategies based on Doc2Query, incorporating cognitive states of simulated user knowledge. Our evaluations include two perspectives on user effectiveness by considering different cost paradigms, namely query-wise and time-oriented measures of effort. Our multi-perspective evaluation scheme reveals new insights about query strategies, the impact of modalities, and different user types in simulated WTR search sessions.|考虑检索项的多模态信号有利于提高检索效率。特别是在 Web 表检索(WTR)实验中，考虑表的多模态特性可以提高检索效率。然而，单一模式如何特别影响用户体验仍然是一个悬而未决的问题。以往的工作分析了自组织检索基准的 WTR 性能，忽略了交互式搜索行为，限制了对实际用户环境影响的结论。为此，这项工作提出了一个深入的评价模拟交互式 WTR 搜索会话作为一个更具成本效益和可重复的替代真正的用户研究。首次提出了基于 Doc2Query 的交互式查询重构策略，该策略融合了模拟用户知识的认知状态。通过考虑不同的成本范式，我们的评估包括对用户有效性的两个视角，即查询式和面向时间的工作量度。我们的多视角评估方案揭示了在模拟 WTR 搜索会话中关于查询策略、模式影响和不同用户类型的新见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simulating+Users+in+Interactive+Web+Table+Retrieval)|0|
|[Test-Time Embedding Normalization for Popularity Bias Mitigation](https://doi.org/10.1145/3583780.3615281)|Dain Kim, Jinhyeok Park, Dongwoo Kim|POSTECH, Pohang, Republic of Korea|Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results. In this work, we propose 'Test Time Embedding Normalization' as a simple yet effective strategy for mitigating popularity bias, which surpasses the performance of the previous mitigation approaches by a significant margin. Our approach utilizes the normalized item embedding during the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity. Through extensive experiments, we show that our method combined with the sampled softmax loss effectively reduces popularity bias compare to previous approaches for bias mitigation. We further investigate the relationship between user and item embeddings and find that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity. The analysis explains the mechanism behind the success of our approach in eliminating the impact of popularity bias. Our code is available at https://github.com/ml-postech/TTEN.|在推荐系统领域，流行度偏差是一个普遍存在的问题，在这个领域中，流行项目往往占据推荐结果的主导地位。在这项工作中，我们提出了“测试时间嵌入规范化”作为一个简单而有效的策略，以减轻流行偏差，这超过了以前的缓解方法的性能显着差距。该方法在推理阶段利用归一化项目嵌入来控制项目嵌入量的影响，项目嵌入量与项目知名度高度相关。通过大量的实验，我们发现与以往的偏差抑制方法相比，我们的方法结合采样软最大损失有效地降低了流行偏差。我们进一步研究了用户与项目嵌入之间的关系，发现无论项目受欢迎程度如何，用户与项目嵌入之间的角度相似度都能区分出优选项目和不优选项目。该分析解释了我们的方法在消除流行偏见影响方面取得成功背后的机制。我们的代码可以在 https://github.com/ml-postech/tten 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Test-Time+Embedding+Normalization+for+Popularity+Bias+Mitigation)|0|
|[Boosting Meta-Learning Cold-Start Recommendation with Graph Neural Network](https://doi.org/10.1145/3583780.3615283)|Han Liu, Hongxiang Lin, Xiaotong Zhang, Fenglong Ma, Hongyang Chen, Lei Wang, Hong Yu, Xianchao Zhang|Peking University, Beijing, China; The Pennsylvania State University, University Park, USA; Zhejiang Lab, Hangzhou, China; Dalian University of Technology, Dalian, China; Meituan, Beijing, China|Meta-learning methods have shown to be effective in dealing with cold-start recommendation. However, most previous methods rely on an ideal assumption that there exists a similar data distribution between source and target tasks, which are unsuitable for the scenario that only extremely limited number of new user or item interactions are available. In this paper, we propose to boost meta-learning cold-start recommendation with graph neural network (MeGNN). First, it utilizes the global neighborhood translation learning to obtain consistent potential interactions for all new user and item nodes, which can refine their representations. Second, it employs the local neighborhood translation learning to predict specific potential interactions for each node, thus guaranteeing the personalized requirement. In experiments, we combine MeGNN with two representative meta-learning models MeLU and TaNP. Extensive results on two widely-used datasets show the superiority of MeGNN in four different scenarios.|元学习方法已被证明在处理冷启动推荐时是有效的。但是，大多数以前的方法都依赖于一个理想的假设，即在源任务和目标任务之间存在类似的数据分布，这种假设不适合于只有极其有限的新用户或项交互可用的场景。本文提出了一种基于图神经网络(MeGNN)的元学习冷启动推荐算法。首先，利用全局邻域翻译学习来获得所有新的用户和项目节点的一致的潜在交互，从而改进它们的表示。其次，利用局部邻域翻译学习来预测每个节点的特定潜在交互，从而保证个性化需求。在实验中，我们将 MeGNN 与两个有代表性的元学习模型 MeLU 和 TaNP 相结合。在两个广泛使用的数据集上的广泛结果显示了 MeGNN 在四种不同场景下的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Meta-Learning+Cold-Start+Recommendation+with+Graph+Neural+Network)|0|
|[STGIN: Spatial-Temporal Graph Interaction Network for Large-scale POI Recommendation](https://doi.org/10.1145/3583780.3615200)|Shaohua Liu, Yu Qi, Gen Li, Mingjian Chen, Teng Zhang, Jia Cheng, Jun Lei|Meituan, Shanghai, China|In Location-Based Services, Point-Of-Interest(POI) recommendation plays a crucial role in both user experience and business opportunities. Graph neural networks have been proven effective in providing personalized POI recommendation services. However, there are still two critical challenges. First, existing graph models attempt to capture users' diversified interests through a unified graph, which limits their ability to express interests in various spatial-temporal contexts. Second, the efficiency limitations of graph construction and graph sampling in large-scale systems make it difficult to adapt quickly to new real-time interests. To tackle the above challenges, we propose a novel Spatial-Temporal Graph Interaction Network. Specifically, we construct subgraphs of spatial, temporal, spatial-temporal, and global views respectively to precisely characterize the user's interests in various contexts. In addition, we design an industry-friendly framework to track the user's latest interests. Extensive experiments on the real-world dataset show that our method outperforms state-of-the-art models. This work has been successfully deployed in a large e-commerce platform, delivering a 1.1% CTR and 6.3% RPM improvement.|在基于位置的服务中，兴趣点(POI)推荐在用户体验和商业机会中都扮演着至关重要的角色。图形神经网络在提供个性化 POI 推荐服务方面已被证明是有效的。然而，仍然存在两个关键的挑战。首先，现有的图模型试图通过一个统一的图来捕捉用户的多样化兴趣，这限制了用户在不同的时空背景下表达兴趣的能力。其次，在大规模系统中，由于图的构造和采样效率的限制，很难快速适应新的实时需求。为了解决上述问题，我们提出了一种新的时空图交互网络。具体来说，我们分别构造了空间、时间、空间-时间和全局视图的子图，以精确表征用户在不同情境下的兴趣。此外，我们还设计了一个行业友好的框架来跟踪用户的最新兴趣。在真实世界数据集上的大量实验表明，我们的方法优于最先进的模型。这项工作已经成功地部署在一个大型电子商务平台，提供了1.1% 的点击率和6.3% 的 RPM 改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STGIN:+Spatial-Temporal+Graph+Interaction+Network+for+Large-scale+POI+Recommendation)|0|
|[FairGraph: Automated Graph Debiasing with Gradient Matching](https://doi.org/10.1145/3583780.3615176)|Yezi Liu|University of California, Irvine, Irvine, CA, USA|As a prevalence data structure in the real world, graphs have found extensive applications ranging from modeling social networks to molecules. However, the existence of diverse biases within graphs gives rise to unfair representations learned by graph neural networks (GNNs). Addressing this issue has typically been approached from a modeling perspective, which not only compromises the integrity of the model structure but also entails additional effort and cost for retraining model parameters when the architecture changes. In this study, we adopt a data-centric standpoint to tackle the problem of fairness, focusing on graph debiasing for Graph Neural Networks. Our specific objective is to eliminate various biases from the input graph by generating a fair synthetic graph. By training GNNs on this fair graph, we aim to achieve an optimal accuracy-fairness trade-off. To this end, we propose FairGraph, which approaches the graph debiasing problem by mimicking the GNN training trajectory of the input graph through an optimization process involving a gradient-matching loss and fairness constraints. Through extensive experiments conducted on three benchmark datasets, we demonstrate the effectiveness of FairGraph and its ability to automatedly generate fair graphs that are transferable across different GNN architectures.|作为现实世界中流行的数据结构，图表已经发现了广泛的应用，从建模社会网络到分子。然而，图中存在不同的偏差会导致图神经网络学习到的不公平表示。解决这个问题通常是从建模的角度出发的，这不仅损害了模型结构的完整性，而且在体系结构发生变化时需要额外的努力和成本来重新训练模型参数。在本研究中，我们采用以数据为中心的观点来解决公平性问题，重点是图神经网络的图形消偏。我们的具体目标是通过生成一个公平的综合图来消除输入图中的各种偏差。通过在这个公平图上训练 GNN，我们的目标是实现最佳的精度-公平权衡。为此，我们提出了 FairGraph，它通过一个包含梯度匹配损失和公平约束的优化过程来模拟输入图的 GNN 训练轨迹，从而解决图的去偏问题。通过在三个基准数据集上进行的大量实验，我们证明了 FairGraph 的有效性及其自动生成可跨不同 GNN 架构转移的 Fair 图的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairGraph:+Automated+Graph+Debiasing+with+Gradient+Matching)|0|
|[Product Entity Matching via Tabular Data](https://doi.org/10.1145/3583780.3615172)|Ali Naeim abadi, Mir Tafseer Nayeem, Davood Rafiei|University of Alberta, Edmonton, AB, Canada|Product Entity Matching (PEM)--a subfield of record linkage that focuses on linking records that refer to the same product--is a challenging task for many entity matching models. For example, recent transformer models report a near-perfect performance score on many datasets while their performance is the lowest on PEM datasets. In this paper, we study PEM under the common setting where the information is spread over text and tables. We show that adding tables can enrich the existing PEM datasets and those tables can act as a bridge between the entities being matched. We also propose TATEM, an effective solution that leverages Pre-trained Language Models (PLMs) with a novel serialization technique to encode tabular product data and an attribute ranking module to make our model more data-efficient. Our experiments on both current benchmark datasets and our proposed datasets show significant improvements compared to state-of-the-art methods, including Large Language Models (LLMs) in zero-shot and few-shot settings.|产品实体匹配(Product Entity Matching，PEM)——记录链接的一个子领域，其重点是链接引用同一产品的记录——对于许多实体匹配模型来说是一项具有挑战性的任务。例如，最近的变压器模型在许多数据集上报告了接近完美的性能得分，而在 PEM 数据集上它们的性能最低。在本文中，我们研究质子交换膜下的公共设置，其中的信息是分布在文本和表格。我们表明，添加表可以丰富现有的 PEM 数据集，并且这些表可以作为匹配实体之间的桥梁。我们还提出了 TATEM，一个有效的解决方案，利用预训练语言模型(PLM)与一种新的序列化技术来编码表格产品数据和属性排序模块，使我们的模型更有效的数据。我们对当前基准数据集和我们提出的数据集的实验表明，与最先进的方法相比，包括大语言模型(LLM)在零拍摄和少拍摄设置方面有显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Product+Entity+Matching+via+Tabular+Data)|0|
|[Neural Disentanglement of Query Difficulty and Semantics](https://doi.org/10.1145/3583780.3615189)|Sara Salamat, Negar Arabzadeh, Shirin Seyedsalehi, Amin Bigdeli, Morteza Zihayat, Ebrahim Bagheri|University of Waterloo, Waterloo, ON, Canada; Toronto Metropolitan University, Toronto, ON, Canada|Researchers have shown that the retrieval effectiveness of queries may depend on other factors in addition to the semantics of the query. In other words, several queries expressed with the same intent, and even using overlapping keywords, may exhibit completely different degrees of retrieval effectiveness. As such, the objective of our work in this paper is to propose a neural disentanglement method that is able to disentangle query semantics from query difficulty. The disentangled query semantics representation provides the means to determine semantic association between queries whereas the disentangled query difficulty representation would allow for the estimation of query effectiveness. We show through our experiments on the query performance prediction; and, query similarity calculation tasks that our proposed disentanglement method is able to show better performance compared to the state of the art.|研究表明，查询的检索效果除了取决于查询的语义外，还取决于其他因素。换句话说，几个具有相同意图的查询，甚至使用重叠关键字，可能表现出完全不同程度的检索效率。因此，本文的工作目标是提出一种能够将查询语义从查询难度中分离出来的神经网络分离方法。分离查询语义表示提供了确定查询之间语义关联的方法，而分离查询难度表示则可以评估查询的有效性。通过对查询性能预测和查询相似度计算任务的实验表明，本文提出的分离方法能够比现有方法表现出更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Disentanglement+of+Query+Difficulty+and+Semantics)|0|
|[EdgeNet : Encoder-decoder generative Network for Auction Design in E-commerce Online Advertising](https://doi.org/10.1145/3583780.3615192)|Guangyuan Shen, Shengjie Sun, Dehong Gao, Duanxiao Song, Libin Yang, Zhen Wang, Yongping Shi, Wei Ning||We present a new encoder-decoder generative network dubbed EdgeNet, which introduces a novel encoder-decoder framework for data-driven auction design in online e-commerce advertising. We break the neural auction paradigm of Generalized-Second-Price(GSP), and improve the utilization efficiency of data while ensuring the economic characteristics of the auction mechanism. Specifically, EdgeNet introduces a transformer-based encoder to better capture the mutual influence among different candidate advertisements. In contrast to GSP based neural auction model, we design an autoregressive decoder to better utilize the rich context information in online advertising auctions. EdgeNet is conceptually simple and easy to extend to the existing end-to-end neural auction framework. We validate the efficiency of EdgeNet on a wide range of e-commercial advertising auction, demonstrating its potential in improving user experience and platform revenue.|提出了一种新的编解码生成网络 EdgeNet，该网络为在线电子商务广告中的数据驱动拍卖设计提供了一种新的编解码框架。我们打破了广义二级价格(GSP)的神经拍卖范式，在保证拍卖机制的经济性的同时，提高了数据的利用效率。具体来说，EdgeNet 引入了一种基于变压器的编码器，以更好地捕捉不同候选广告之间的相互影响。与基于 GSP 的神经拍卖模型相比，我们设计了一个自回归解码器，以更好地利用在线广告拍卖中丰富的上下文信息。EdgeNet 概念简单，易于扩展到现有的端到端神经拍卖框架。我们验证了 EdgeNet 在广泛的电子商务广告拍卖中的效率，证明了它在改善用户体验和平台收入方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EdgeNet+:+Encoder-decoder+generative+Network+for+Auction+Design+in+E-commerce+Online+Advertising)|0|
|[G-Meta: Distributed Meta Learning in GPU Clusters for Large-Scale Recommender Systems](https://doi.org/10.1145/3583780.3615208)|Youshao Xiao, Shangchun Zhao, Zhenglei Zhou, Zhaoxin Huan, Lin Ju, Xiaolu Zhang, Lin Wang, Jun Zhou|Ant Group, Hangzhou, China|Recently, a new paradigm, meta learning, has been widely applied to Deep Learning Recommendation Models (DLRM) and significantly improves statistical performance, especially in cold-start scenarios. However, the existing systems are not tailored for meta learning based DLRM models and have critical problems regarding efficiency in distributed training in the GPU cluster. It is because the conventional deep learning pipeline is not optimized for two task-specific datasets and two update loops in meta learning. This paper provides a high-performance framework for large-scale training for Optimization-based Meta DLRM models over the G PU cluster, namely G -Meta. Firstly, G-Meta utilizes both data parallelism and model parallelism with careful orchestration regarding computation and communication efficiency, to enable high-speed distributed training. Secondly, it proposes a Meta-IO pipeline for efficient data ingestion to alleviate the I/O bottleneck. Various experimental results show that G-Meta achieves notable training speed without loss of statistical performance. Since early 2022, G-Meta has been deployed in Alipay's core advertising and recommender system, shrinking the continuous delivery of models by four times. It also obtains 6.48% improvement in Conversion Rate (CVR) and 1.06% increase in CPM (Cost Per Mille) in Alipay's homepage display advertising, with the benefit of larger training samples and tasks.|最近，一种新的学习模式元学习被广泛应用于深度学习推荐模型(DLRM) ，并显著提高了统计性能，特别是在冷启动情景下。然而，现有的系统并不适合基于元学习的 DLRM 模型，并且在 GPU 集群的分布式培训效率方面存在关键问题。这是因为传统的深度学习流水线没有针对元学习中的两个任务特定的数据集和两个更新循环进行优化。本文提供了一个在 G PU 集群上进行基于优化的元 DLRM 模型大规模培训的高性能框架，即 G-Meta。首先，G-Meta 利用了资料平行和模型的并行性，在计算和通信效率方面进行了精心的编排，从而实现了高速的分布式训练。其次，提出了一种有效的数据摄取元 IO 管道，以缓解 I/O 瓶颈。各种实验结果表明，G-Meta 在不损失统计性能的前提下，达到了显著的训练速度。自2022年初以来，g-Meta 一直部署在支付宝的核心广告和推荐系统中，将模型的持续交付缩减了4倍。在支付宝主页显示广告中，转化率(CVR)提高了6.48% ，每公里成本(CPM)提高了1.06% ，这些都得益于更大的培训样本和任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=G-Meta:+Distributed+Meta+Learning+in+GPU+Clusters+for+Large-Scale+Recommender+Systems)|0|
|[MEBS: Multi-task End-to-end Bid Shading for Multi-slot Display Advertising](https://doi.org/10.1145/3583780.3615486)|Zhen Gong, Lvyin Niu, Yang Zhao, Miao Xu, Haoqi Zhang, Zhenzhe Zheng, Zhilin Zhang, Rongquan Bai, Chuan Yu, Jian Xu, Bo Zheng, Fan Wu|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Beijing, China|Online bidding and auction are crucial aspects of the online advertising industry. Conventionally, there is only one slot for ad display and most current studies focus on it. Nowadays, multi-slot display advertising is gradually becoming popular where many ads could be displayed in a list and shown as a whole to users. However, multi-slot display advertising leads to different cost-effectiveness. Advertisers have the incentive to adjust bid prices so as to win the most economical ad positions. In this study, we introduce bid shading into multi-slot display advertising for bid price adjustment with a Multi-task End-to-end Bid Shading~(MEBS) method. We prove the optimality of our method theoretically and examine its performance experimentally. Through extensive offline and online experiments, we demonstrate the effectiveness and efficiency of our method, and we obtain a 7.01% lift in Gross Merchandise Volume, a 7.42% lift in Return on Investment, and a 3.26% lift in ad buy count.|在线招标和拍卖是在线广告业的重要方面。传统上，只有一个广告展示时段，目前大多数研究集中在它。如今，多插槽显示广告正逐渐流行，许多广告可以显示在一个列表中，并作为一个整体显示给用户。然而，多插槽显示广告导致不同的成本效益。广告商有动机调整投标价格，以赢得最经济的广告位置。在本研究中，我们利用多任务端到端的投标底纹 ~ (MEBS)方法，将投标底纹引入多时隙显示广告中，以调整投标价格。从理论上证明了该方法的最优性，并对其性能进行了实验验证。通过大量的线下和线上实验，我们证明了我们的方法的有效性和效率，我们获得了7.01% 的商品总量增长，7.42% 的投资回报增长，3.26% 的广告购买数量增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MEBS:+Multi-task+End-to-end+Bid+Shading+for+Multi-slot+Display+Advertising)|0|
|[DFFM: Domain Facilitated Feature Modeling for CTR Prediction](https://doi.org/10.1145/3583780.3615469)|Wei Guo, Chenxu Zhu, Fan Yan, Bo Chen, Weiwen Liu, Huifeng Guo, Hongkun Zheng, Yong Liu, Ruiming Tang|Huawei Noah's Ark Lab, Shanghai, China; Huawei Technologies Co Ltd, Shenzhen, China; Huawei Noah's Ark Lab, Huawei, Shanghai, China|CTR prediction is critical to industrial recommender systems. Recently, with the growth of business domains in enterprises, much attention has been focused on the multi-domain CTR recommendation. Numerous models have been proposed that attempt to use a unified model to serve multiple domains. Although much progress has been made, we argue that they ignore the importance of feature interactions and user behaviors when modeling cross-domain relations, which is a coarse-grained utilizing of domain information. To solve this problem, we propose Domain Facilitated Feature Modeling (DFFM) for CTR prediction. It incorporates domain-related information into the parameters of the feature interaction and user behavior modules, allowing for domain-specific learning of these two aspects. Extensive experiments are conducted on two public datasets and one industrial dataset to demonstrate the effectiveness of DFFM. We deploy the DFFM model in Huawei advertising platform and gain a 4.13% improvement of revenue on a two week online A/B test. Currently DFFM model has been used as the main traffic model, serving for hundreds of millions of people.|CTR 预测是工业推荐系统的关键。近年来，随着企业业务领域的不断扩大，多领域 CTR 推荐引起了人们的广泛关注。许多模型试图使用一个统一的模型来服务于多个领域。虽然已经取得了很大的进展，但是我们认为他们忽视了特征交互和用户行为在跨领域关系建模中的重要性，这是对领域信息的粗粒度利用。为了解决这个问题，我们提出了领域简化特征建模(DFFM)的 CTR 预测。它将领域相关信息整合到特征交互和用户行为模块的参数中，允许特定领域学习这两个方面。为了验证 DFFM 算法的有效性，在两个公共数据集和一个工业数据集上进行了大量的实验。我们在华为广告平台采用了 dFFM 模式，通过两周的在线 A/B 测试，收入提高了4.13% 。目前 DFFM 模型已经成为主要的流量模型，服务于数亿人。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DFFM:+Domain+Facilitated+Feature+Modeling+for+CTR+Prediction)|0|
|[Masked Multi-Domain Network: Multi-Type and Multi-Scenario Conversion Rate Prediction with a Single Model](https://doi.org/10.1145/3583780.3614697)|Wentao Ouyang, Xiuwu Zhang, Chaofeng Guo, Shukui Ren, Yupei Sui, Kun Zhang, Jinmei Luo, Yunfeng Chen, Dongbo Xu, Xiangzheng Liu, Yanlong Du|Alibaba Group, Beijing, China|In real-world advertising systems, conversions have different types in nature and ads can be shown in different display scenarios, both of which highly impact the actual conversion rate (CVR). This results in the multi-type and multi-scenario CVR prediction problem. A desired model for this problem should satisfy the following requirements: 1) Accuracy: the model should achieve fine-grained accuracy with respect to any conversion type in any display scenario. 2) Scalability: the model parameter size should be affordable. 3) Convenience: the model should not require a large amount of effort in data partitioning, subset processing and separate storage. Existing approaches cannot simultaneously satisfy these requirements. For example, building a separate model for each (conversion type, display scenario) pair is neither scalable nor convenient. Building a unified model trained on all the data with conversion type and display scenario included as two features is not accurate enough. In this paper, we propose the Masked Multi-domain Network (MMN) to solve this problem. To achieve the accuracy requirement, we model domain-specific parameters and propose a dynamically weighted loss to account for the loss scale imbalance issue within each mini-batch. To achieve the scalability requirement, we propose a parameter sharing and composition strategy to reduce model parameters from a product space to a sum space. To achieve the convenience requirement, we propose an auto-masking strategy which can take mixed data from all the domains as input. It avoids the overhead caused by data partitioning, individual processing and separate storage. Both offline and online experimental results validate the superiority of MMN for multi-type and multi-scenario CVR prediction. MMN is now the serving model for real-time CVR prediction in UC Toutiao.|在现实世界的广告系统中，转化率具有不同的性质，广告可以在不同的显示场景中显示，这两者都对实际转化率(CVR)有很大的影响。这导致了多类型和多情景 CVR 预测问题。这个问题的期望模型应该满足以下要求: 1)精度: 模型应该达到细粒度的精度相对于任何转换类型在任何显示场景。2)可伸缩性: 模型参数的大小应该是可以承受的。3)方便性: 模型不需要在数据分区、子集处理和独立存储方面做大量的工作。现有的方法不能同时满足这些需求。例如，为每个(转换类型，显示场景)对构建单独的模型既不可伸缩也不方便。将转换类型和显示场景作为两个特征包含在内，对所有数据建立统一的训练模型是不够准确的。本文提出了掩蔽多域网络(MMN)来解决这一问题。为了达到精度要求，我们对特定领域的参数进行建模，并提出一个动态加权损失，以解决每个小批量内损失规模不平衡的问题。为了满足可扩展性的要求，我们提出了一种参数共享和合成策略，将模型参数从乘积空间减少到和空间。为了达到方便的要求，我们提出了一种自动掩蔽的策略，可以从所有领域的混合数据作为输入。它避免了由于数据分区、单独处理和单独存储而造成的开销。离线和在线实验结果验证了 MMN 在多类型、多情景 CVR 预测中的优越性。MMN 现在是 UC 今日头条实时 CVR 预测的服务模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Masked+Multi-Domain+Network:+Multi-Type+and+Multi-Scenario+Conversion+Rate+Prediction+with+a+Single+Model)|0|
|[TrendSpotter: Forecasting E-commerce Product Trends](https://doi.org/10.1145/3583780.3615503)|Gayatri Ryali, Shreyas S, Sivaramakrishnan Kaveri, Prakash Mandayam Comar|Amazon.com Inc., Bengaluru, India|Internet users actively search for trending products on various social media services like Instagram and YouTube which serve as popular hubs for discovering and exploring fashionable and popular items. It is imperative for e-commerce giants to have the capability to accurately identify, predict and subsequently showcase these trending products to the customers. E-commerce stores can effectively cater to the evolving demands of the customer base and enhance the overall shopping experience by offering recent and most sought-after products in a timely manner. In this work we propose a framework for predicting and surfacing trending products in e-commerce stores, the first of its kind to the best of our knowledge. We begin by defining what constitutes a trending product using sound statistical tests. We then introduce a machine learning-based early trend prediction system called TrendSpotter to help users identify upcoming product trends. TrendSpotter is a unique adaptation of the state-of-the-art InceptionTime model\citeInceptionTime that predicts the future popularity of a product based on its current customer engagement, such as clicks, purchases, and other relevant product attributes. The effectiveness of our approach is demonstrated through A/B tests, where we first showcase the effectiveness of our statistical test based labeling strategy, resulting in an incremental sales lift of 59 bps\footnotebps or basis points are a measure of percentages. 1 bps = 0.01% across two experiments on home page and search page. Subsequently, we conduct a comparison between our machine learning model and the statistical labeling baseline and observe an additional sales gain of 14 bps, reflecting the importance of early identification of trending products.|互联网用户在 Instagram 和 YouTube 等社交媒体上积极搜索流行产品，这些社交媒体是发现和探索时尚和流行物品的热门中心。电子商务巨头必须具备准确识别、预测和随后向客户展示这些趋势产品的能力。电子商务商店能够有效地满足顾客群不断变化的需求，并通过及时提供最新和最受欢迎的产品，提高整体购物体验。在这项工作中，我们提出了一个框架，预测和表面趋势的产品在电子商务商店，这是第一个类似的最好的我们的知识。我们首先使用可靠的统计检验来定义什么是趋势产品。然后，我们引入一个基于机器学习的早期趋势预测系统，称为趋势观察器，以帮助用户识别即将出现的产品趋势。TrendSpotter 是对最先进的 InceptionTime 模型 citeInceptionTime 的独特改编，该模型根据当前的客户参与度，如点击、购买和其他相关产品属性，预测产品未来的受欢迎程度。我们的方法的有效性通过 A/B 测试得到了证明，我们首先展示了我们基于统计测试的标签策略的有效性，从而使销售额增加了59个基点。1bps = 0.01% ，通过主页和搜索页面的两个实验。随后，我们对我们的机器学习模型和统计标签基线进行了比较，观察到额外的14个基点的销售收益，反映了早期识别趋势产品的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrendSpotter:+Forecasting+E-commerce+Product+Trends)|0|
|[An Incremental Update Framework for Online Recommenders with Data-Driven Prior](https://doi.org/10.1145/3583780.3615456)|Chen Yang, Jin Chen, Qian Yu, Xiangdong Wu, Kui Ma, Zihao Zhao, Zhiwei Fang, Wenlong Chen, Chaosheng Fan, Jie He, Changping Peng, Zhangang Lin, Jingping Shao|JD.com, Beijing, China; UESTC, Chengdu, China|Online recommenders have attained growing interest and created great revenue for businesses. Given numerous users and items, incremental update becomes a mainstream paradigm for learning large-scale models in industrial scenarios, where only newly arrived data within a sliding window is fed into the model, meeting the strict requirements of quick response. However, this strategy would be prone to overfitting to newly arrived data. When there exists a significant drift of data distribution, the long-term information would be discarded, which harms the recommendation performance. Conventional methods address this issue through native model-based continual learning methods, without analyzing the data characteristics for online recommenders. To address the aforementioned issue, we propose an incremental update framework for online recommenders with Data-Driven Prior (DDP), which is composed of Feature Prior (FP) and Model Prior (MP). The FP performs the click estimation for each specific value to enhance the stability of the training process. The MP incorporates previous model output into the current update while strictly following the Bayes rules, resulting in a theoretically provable prior for the robust update. In this way, both the FP and MP are well integrated into the unified framework, which is model-agnostic and can accommodate various advanced interaction models. Extensive experiments on two publicly available datasets as well as an industrial dataset demonstrate the superior performance of the proposed framework.|在线推荐已经获得了越来越多的兴趣，并为企业创造了巨大的收入。鉴于用户和项目众多，增量更新成为工业场景中学习大规模模型的主流范式，在工业场景中，只有滑动窗口中新到达的数据才被输入模型，以满足快速响应的严格要求。但是，这种策略容易过度适应新到达的数据。当数据分布存在显著漂移时，长期信息会被丢弃，从而影响推荐性能。传统的方法通过基于本地模型的连续学习方法来解决这个问题，而没有分析在线推荐的数据特征。为了解决上述问题，我们提出了一种基于数据驱动优先级(DDP)的在线推荐增量更新框架，该框架由特征优先级(FP)和模型优先级(MP)组成。FP 对每个特定值执行点击估计，以增强培训过程的稳定性。MP 在严格遵循贝叶斯规则的同时，将以前的模型输出合并到当前更新中，从而为鲁棒更新提供了一个理论上可证明的先验。通过这种方式，FP 和 MP 很好地集成到统一框架中，这是模型不可知的，可以适应各种先进的交互模型。在两个公开可用的数据集和一个工业数据集上的大量实验证明了该框架的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Incremental+Update+Framework+for+Online+Recommenders+with+Data-Driven+Prior)|0|
|[SHARK: A Lightweight Model Compression Approach for Large-scale Recommender Systems](https://doi.org/10.1145/3583780.3615499)|Beichuan Zhang, Chenggen Sun, Jianchao Tan, Xinjun Cai, Jun Zhao, Mengqi Miao, Kang Yin, Chengru Song, Na Mou, Yang Song|Kuaishou, Beijing, China|Increasing the size of embedding layers has shown to be effective in improving the performance of recommendation models, yet gradually causing their sizes to exceed terabytes in industrial recommender systems, and hence the increase of computing and storage costs. To save resources while maintaining model performances, we propose SHARK, the model compression practice we have summarized in the recommender system of industrial scenarios. SHARK consists of two main components. First, we use the novel first-order component of Taylor expansion as importance scores to prune the number of embedding tables (feature fields). Second, we introduce a new row-wise quantization method to apply different quantization strategies to each embedding. We conduct extensive experiments on both public and industrial datasets, demonstrating that each component of our proposed SHARK framework outperforms previous approaches. We conduct A/B tests in multiple models on Kuaishou, such as short video, e-commerce, and advertising recommendation models. The results of the online A/B test showed SHARK can effectively reduce the memory footprint of the embedded layer. For the short-video scenarios, the compressed model without any performance drop significantly saves 70% storage and thousands of machines, improves 30\% queries per second (QPS), and has been deployed to serve hundreds of millions of users and process tens of billions of requests every day.|在工业推荐系统中，增加嵌入层的大小可以有效地提高推荐模型的性能，但是会逐渐导致其大小超过 TB，从而增加计算和存储成本。为了在保持模型性能的同时节省资源，我们提出了 SHARK，这是我们在工业场景推荐系统中总结的模型压缩实践。鲨鱼由两个主要部分组成。首先，我们利用泰勒展开的一阶分量作为重要性分数来裁剪嵌入表(特征域)的数目。其次，我们介绍了一种新的行量化方法，对每个嵌入应用不同的量化策略。我们在公共和工业数据集上进行了广泛的实验，证明了我们提出的 SHARK 框架的每个组件都优于以前的方法。我们在 Kuaishou 进行多种模式的 A/B 测试，例如短片、电子商务和广告推荐模式。在线 A/B 测试结果表明，SHARK 可以有效地减少嵌入层的内存占用。对于短视频场景，没有任何性能下降的压缩模型显著地节省了70% 的存储和数千台机器，提高了每秒30% 的查询(QPS) ，并且已经被部署用于服务数亿用户和每天处理数百亿个请求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SHARK:+A+Lightweight+Model+Compression+Approach+for+Large-scale+Recommender+Systems)|0|
|[Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal Labeling Framework](https://doi.org/10.1145/3583780.3615483)|Yang Zhang, Yimeng Bai, Jianxin Chang, Xiaoxue Zang, Song Lu, Jing Lu, Fuli Feng, Yanan Niu, Yang Song|University of Science and Technology of China & USTC Beijing Research Institute, Hefei, China; University of Science and Technology of China, Hefei, China; Kuaishou Technology, Beijing, China|With the proliferation of short video applications, the significance of short video recommendations has vastly increased. Unlike other recommendation scenarios, short video recommendation systems heavily rely on feedback from watch time. Existing approaches simply treat watch time as a direct label, failing to effectively harness its extensive semantics and introduce bias, thereby limiting the potential for modeling user interests based on watch time. To overcome this challenge, we propose a framework named Debiasied Multiple-semantics-extracting Labeling (DML). DML constructs labels that encompass various semantics by utilizing quantiles derived from the distribution of watch time, prioritizing relative order rather than absolute label values. This approach facilitates easier model learning while aligning with the ranking objective of recommendations. Furthermore, we introduce a method inspired by causal adjustment to refine label definitions, thereby reducing the impact of bias on the label and directly mitigating bias at the label level. We substantiate the effectiveness of our DML framework through both online and offline experiments. Extensive results demonstrate that our DML could effectively leverage watch time to discover users' real interests, enhancing their engagement in our application.|随着短视频应用程序的激增，短视频推荐的重要性大大增加。与其他推荐场景不同，短视频推荐系统严重依赖于观看时间的反馈。现有的方法只是简单地将手表时间作为一个直接标签，未能有效地利用其广泛的语义并引入偏见，从而限制了基于手表时间建模用户兴趣的潜力。为了克服这一挑战，我们提出了一个名为 Debiasied 多语义抽取标记(DML)的框架。DML 通过利用从手表时间分布派生的分位数构造包含各种语义的标签，优先考虑相对顺序而不是绝对标签值。这种方法促进了更容易的模型学习，同时与建议的排名目标保持一致。此外，我们引入了一种方法，受因果调整的启发，以完善标签的定义，从而减少偏见的影响，标签和直接减轻偏见的水平。我们通过两个在线和离线的实验证实了我们的 DML 框架的有效性。大量的结果表明，我们的 DML 可以有效地利用观看时间来发现用户的真正兴趣，提高他们在我们的应用程序中的参与度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Watch-time+Feedback+for+Short-Video+Recommendations:+A+Causal+Labeling+Framework)|0|
|[COPR: Consistency-Oriented Pre-Ranking for Online Advertising](https://doi.org/10.1145/3583780.3615465)|Zhishan Zhao, Jingyue Gao, Yu Zhang, Shuguang Han, Siyuan Lou, XiangRong Sheng, Zhe Wang, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng|Alibaba Group, Beijing, China|Cascading architecture has been widely adopted in large-scale advertising systems to balance efficiency and effectiveness. In this architecture, the pre-ranking model is expected to be a lightweight approximation of the ranking model, which handles more candidates with strict latency requirements. Due to the gap in model capacity, the pre-ranking and ranking models usually generate inconsistent ranked results, thus hurting the overall system effectiveness. The paradigm of score alignment is proposed to regularize their raw scores to be consistent. However, it suffers from inevitable alignment errors and error amplification by bids when applied in online advertising. To this end, we introduce a consistency-oriented pre-ranking framework for online advertising, which employs a chunk-based sampling module and a plug-and-play rank alignment module to explicitly optimize consistency of ECPM-ranked results. A $\Delta NDCG$-based weighting mechanism is adopted to better distinguish the importance of inter-chunk samples in optimization. Both online and offline experiments have validated the superiority of our framework. When deployed in Taobao display advertising system, it achieves an improvement of up to +12.3\% CTR and +5.6\% RPM.|为了平衡效率和效果，级联体系结构在大规模广告系统中得到了广泛的应用。在这种体系结构中，预排序模型被期望是排序模型的轻量级近似，它处理具有严格延迟要求的更多候选者。由于模型容量的差距，预排序模型和排序模型通常会产生不一致的排序结果，从而影响系统的整体有效性。提出了分数对齐的范式，以规范他们的原始分数是一致的。然而，在网络广告中应用时，不可避免地会出现一致性错误和出价放大错误。为此，我们引入了一个面向一致性的在线广告预排序框架，该框架采用基于块的抽样模块和即插即用的排序对齐模块来显式优化 ECPM 排序结果的一致性。为了更好地区分块间样本在优化中的重要性，采用了基于 $Delta NDCG 的加权机制。这两个在线和离线实验都验证了我们框架的优越性。在淘宝展示广告系统中，点击率和转速分别提高了12.3% 和5.6% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COPR:+Consistency-Oriented+Pre-Ranking+for+Online+Advertising)|0|
|[Learning What to Ask: Mining Product Attributes for E-commerce Sales from Massive Dialogue Corpora](https://doi.org/10.1145/3583780.3614745)|Yan Fan, Chengyu Wang, Fan Feng, Hengbin Cui, Yuchuan Wu, Yongbin Li|Alibaba Group, Hangzhou, China|Conversational Recommender Systems (CRSs) are extensively applied in e-commercial platforms that recommend items to users. To ensure accurate recommendation, agents usually ask for users' preferences towards specific product attributes which are pre-defined by humans. In e-commercial platforms, however, the number of products easily reaches to billions, making it prohibitive to pre-define decisive attributes for efficient recommendation due to the lack of substantial human resources and the scarce domain expertise. In this work, we present AliMeMOSAIC, a novel knowledge mining and conversational assistance framework that extracts core product attributes from massive dialogue corpora for better conversational recommendation experience. It first extracts user-agent interaction utterances from massive corpora that contain product attributes. A Joint Attribute and Value Extraction (JAVE) network is designed to extract product attributes from user-agent interaction utterances. Finally, AliMeMOSAIC generates attribute sets that frequently appear in dialogues as the target attributes for agents to request, and serve as an assistant to guide the dialogue flow. To prove the effectiveness of AliMeMOSAIC, we show that it consistently improves the overall recommendation performance of our CRS system. An industrial demonstration scenario is further presented to show how it benefits online shopping experiences.|会话推荐系统(CRS)广泛应用于向用户推荐项目的电子商务平台。为了确保准确的推荐，代理通常会询问用户对特定产品属性的偏好，这些属性是由人工预先定义的。然而，在电子商务平台上，产品的数量很容易达到数十亿，由于缺乏大量人力资源和稀缺的领域专门知识，因此无法预先确定有效推荐的决定性属性。在这项工作中，我们提出了 AliMeMOSAIC，一个新的知识挖掘和会话辅助框架，提取核心产品属性从大量的对话语料库，以更好的会话推荐体验。它首先从包含产品属性的海量语料库中提取用户-代理交互语句。设计了一个联合属性和价值提取(JAVE)网络，从用户-代理交互语句中提取产品属性。最后，AliMeMOSAIC 生成对话中经常出现的属性集，作为代理请求的目标属性，并作为指导对话流的助手。为了证明 AliMeMOSAIC 的有效性，我们展示了它持续改善了我们的 CRS 系统的整体推荐性能。进一步介绍了一个工业示范场景，以说明它如何有利于在线购物体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+What+to+Ask:+Mining+Product+Attributes+for+E-commerce+Sales+from+Massive+Dialogue+Corpora)|0|
|[Uplift Modeling: From Causal Inference to Personalization](https://doi.org/10.1145/3583780.3615298)|Felipe Moraes, Hugo Manuel Proença, Anastasiia Kornilova, Javier Albert, Dmitri Goldenberg|Booking.com, Tel-Aviv, Israel; Booking.com, Amsterdam, Netherlands|Uplift modeling is a collection of machine learning techniques for estimating causal effects of a treatment at the individual or subgroup levels. Over the last years, causality and uplift modeling have become key trends in personalization at online e-commerce platforms, enabling the selection of the best treatment for each user in order to maximize the target business metric. Uplift modeling can be particularly useful for personalized promotional campaigns, where the potential benefit caused by a promotion needs to be weighed against the potential costs. In this tutorial we will cover basic concepts of causality and introduce the audience to state-of-the-art techniques in uplift modeling. We will discuss the advantages and the limitations of different approaches and dive into the unique setup of constrained uplift modeling. Finally, we will present real-life applications and discuss challenges in implementing these models in production.|提升建模是机器学习技术的集合，用于估计个体或亚组水平治疗的因果效应。在过去几年中，因果关系和提升建模已成为在线电子商务平台个性化的主要趋势，使得能够为每个用户选择最佳待遇，以最大限度地实现目标业务指标。提升模型对于个性化的促销活动特别有用，因为需要权衡促销活动带来的潜在收益和潜在成本。在本教程中，我们将涵盖因果关系的基本概念，并向观众介绍最先进的提升建模技术。我们将讨论不同方法的优点和局限性，并深入探讨约束抬升模型的独特设置。最后，我们将展示实际应用程序，并讨论在生产中实现这些模型的挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uplift+Modeling:+From+Causal+Inference+to+Personalization)|0|
|[Vigil: Effective End-to-end Monitoring for Large-scale Recommender Systems at Glance](https://doi.org/10.1145/3583780.3615997)|Priyansh Saxena, Manisha R|Glance, Bangalore, India|The success of large-scale recommender systems hinges upon their ability to deliver accurate and timely recommendations to a diverse user base. At Glance, we deliver snackable personalized content to the lock screens of 200M smartphones. In this context, continuous monitoring is paramount as it safeguards data integrity, detects drifts, addresses evolving user preferences, optimizes system downtime, and ultimately augments the system's effectiveness and user satisfaction. In this talk, we delve into Vigil, a set of monitoring practices developed to provide comprehensive end-to-end monitoring of recommender systems at Glance. These practices revolve around three key pillars: mitigating developer fatigue, ensuring precise predictions, and establishing a centralized monitoring framework. By adopting these practices, we have observed a 30% reduction in compute cost, a 26% drop in downtime, and a surge in developer productivity demonstrated by a 45% decrease in turnaround time.|大型推荐系统的成功取决于它们向不同用户群提供准确和及时的推荐的能力。在 Glance，我们为2亿部智能手机的锁定屏幕提供可点心的个性化内容。在这种情况下，持续监控是至关重要的，因为它可以保证数据的完整性，检测漂移，解决不断变化的用户偏好，优化系统停机时间，并最终提高系统的有效性和用户满意度。在这个演讲中，我们深入研究了 Vigil，这是一组监控实践，开发它们是为了在 Glance 中提供对推荐系统的全面的端到端监控。这些实践围绕着三个关键支柱: 减轻开发人员疲劳、确保精确的预测以及建立一个集中的监控框架。通过采用这些实践，我们观察到计算成本降低了30% ，停机时间减少了26% ，开发人员生产力大幅提高，周转时间减少了45% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Vigil:+Effective+End-to-end+Monitoring+for+Large-scale+Recommender+Systems+at+Glance)|0|
|[Prod2Vec-Var: A Session Based Recommendation System with Enhanced Diversity](https://doi.org/10.1145/3583780.3615995)|Hacer Turgut, Tan Doruk Yetki, Ömür Bali, Tayfun Arda Yücel|iLab Ventures, Istanbul, Turkey|Understanding user behavior and leveraging this information in recommendation systems pose challenges for websites lacking a login system or with limited logged-in users. This study introduces the Prod2Vec-Var recommendation system, a modified version of a session-based recommendation algorithm aimed at enhancing the performance of product recommendation systems with a cold-start extension. The proposed model builds upon the original prod2vec algorithm, incorporating an additional step to improve the diversity of product recommendations. The project entails a well-designed data pipeline, effectively processing user actions to align them with the model, and implementing unique functions that expand the range of products capturing users' attention. Moreover, a straightforward yet effective cold-start model is developed to address newly added products that have not been viewed by users. The outcome of our project, namely product suggestions, is presented to users of cimri.com, one of iLab's affiliated companies, which attracts millions of daily visits, thereby enabling seamless access to desired products. Experimental results demonstrated the superior performance of our model compared to the other two different strategies in running recommendation on popular products, as evidenced by favorable R@1, R@5, R@10, and R@15 metrics. Concerning less popular products, we observed an improvement in our model's performance as the value of K increased, ultimately achieving optimal results in terms of R@15. Additionally, our cold-start model for new products substantiated the efficacy of our methodology, yielding the highest scores across R@5, R@10, and R@15 metrics.|理解用户行为并在推荐系统中利用这些信息对缺乏登录系统或登录用户有限的网站构成挑战。本研究介绍了 Prod2Vec-Var 推荐系统，它是基于会话的推荐算法的一个修改版本，旨在通过冷启动扩展来提高产品推荐系统的性能。提出的模型建立在原始的 prod2vec 算法的基础上，包含了一个额外的步骤来改善产品推荐的多样性。该项目需要一个设计良好的数据管道，有效地处理用户行为，使其与模型保持一致，并实现独特的功能，以扩大产品的范围，吸引用户的注意力。此外，还开发了一个简单而有效的冷启动模型，以处理用户尚未查看的新增产品。我们的项目成果，即产品建议，将呈现给 cimri.com 的用户，cimri.com 是 iLab 的附属公司之一，每天吸引数百万的访问量，从而使人们能够无缝地访问想要的产品。实验结果表明，与其他两种不同的策略相比，我们的模型在推荐流行产品方面表现出更好的性能，这可以通过有利的 R@1、 R@5、 R@10和 R@15指标来证明。关于不太受欢迎的产品，我们观察到随着 K 值的增加，我们模型的性能有所改善，最终达到 R@15的最佳结果。此外，我们新产品的冷启动模型证实了我们方法的有效性，在 R@5、 R@10和 R@15指标上得分最高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prod2Vec-Var:+A+Session+Based+Recommendation+System+with+Enhanced+Diversity)|0|
|[RePair: An Extensible Toolkit to Generate Large-Scale Datasets for Query Refinement via Transformers](https://doi.org/10.1145/3583780.3615129)|Yogeswar Lakshmi Narayanan, Hossein Fani|University of Windsor, Windsor, ON, Canada|Query refinement is the process of transforming users' queries into newrefined versions without semantic drift to enhance the relevance of search results. Prior query refiners were benchmarked on web query logs followingweak assumptions that users' input queries within a search session are about a single topic and improve gradually, which is not necessarily accurate in practice. In this paper, we contribute RePair, an open-source configurable toolkit to generatelarge-scale gold-standard benchmark datasets whose pairs of (original query, refined versions) arealmost surely guaranteed to be in the same semantic context. RePair takes a dataset of queries and their relevance judgements (e.g., msmarco or aol), a sparse or dense retrieval method (e.g., bm25 or colbert ), and an evaluation metric (e.g., map or mrr), and outputs refined versions of queries, each of which with the relevance improvement guarantees under the retrieval method in terms of the evaluation metric. RePair benefits from text-to-text-transfer-transformer (t5) to generate gold-standard datasets for any input query sets and is designed with extensibility in mind. Out of the box, RePair includes gold-standard datasets for aol and msmarco.passage as well as benchmark results of state-of-the-art supervised query suggestion methods on the generated datasets at https://github.com/fani-lab/RePair.|查询精化是将用户的查询转换为不带语义漂移的新精化版本以增强搜索结果相关性的过程。之前的查询精炼器在网络查询日志上进行了基准测试，这是基于一个薄弱的假设，即用户在搜索会话中的输入查询是关于单个主题的，并且是逐渐改进的，这在实践中并不一定准确。在本文中，我们提供了 RePair，一个开源的可配置工具包，用于生成大规模的黄金标准基准数据集，这些数据集的对(原始查询，精化版本)几乎肯定是在相同的语义上下文中。RePair 采用查询及其相关性判断(例如，mmarco 或 aol)、稀疏或密集检索方法(例如，bm25或 colbert)和评估度量(例如，map 或 mrr)的数据集，并输出精化版本的查询，其中每个查询在检索方法下的相关性改进都在评估度量方面得到保证。RePair 受益于文本到文本传输转换器(t5) ，可以为任何输入查询集生成黄金标准的数据集，并且在设计时考虑到了可扩展性。开箱即用，RePair 包括美国在线和 mmarco.pass 的黄金标准数据集，以及最先进的监督查询建议方法在 https://github.com/fani-lab/RePair 生成的数据集上的基准结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RePair:+An+Extensible+Toolkit+to+Generate+Large-Scale+Datasets+for+Query+Refinement+via+Transformers)|0|
|[Combining Inductive and Deductive Reasoning for Query Answering over Incomplete Knowledge Graphs](https://doi.org/10.1145/3583780.3614816)|Medina Andresel, TrungKien Tran, Csaba Domokos, Pasquale Minervini, Daria Stepanova|AIT Austrian Institute of Technology, Vienna, Austria; Bosch Center for Artificial Intelligence, Renningen, Germany; University of Edinburgh, Edinburgh, United Kingdom|Current methods for embedding-based query answering over incomplete Knowledge Graphs (KGs) only focus on inductive reasoning, i.e., predicting answers by learning patterns from the data, and lack the complementary ability to do deductive reasoning, which requires the application of domain knowledge to infer further information. To address this shortcoming, we investigate the problem of incorporating ontologies into embedding-based query answering models by defining the task of embedding-based ontology-mediated query answering. We propose various integration strategies into prominent representatives of embedding models that involve (1) different ontology-driven data augmentation techniques and (2) adaptation of the loss function to enforce the ontology axioms. We design novel benchmarks for the considered task based on the LUBM and the NELL KGs and evaluate our methods on them. The achieved improvements in the setting that requires both inductive and deductive reasoning are from 20% to 55% in HITS@3.|目前基于嵌入式查询回答的不完整知识图(kGs)方法只关注归纳推理，即通过学习数据模式来预测答案，缺乏做演绎推理的互补能力，这需要应用领域知识来推断进一步的信息。针对这一缺陷，本文通过定义基于嵌入本体的查询回答任务，研究了将本体融入基于嵌入的查询回答模型中的问题。我们提出了各种集成策略的嵌入模型的突出代表，涉及(1)不同的本体驱动的数据增强技术和(2)适应的损失函数，以执行本体公理。我们基于 LUBM 和 NELL 幼儿园设计了新的任务基准，并对我们的方法进行了评估。在 HITS@3中，要求同时具有归纳性和演绎推理的环境改善率由20% 提高到55% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combining+Inductive+and+Deductive+Reasoning+for+Query+Answering+over+Incomplete+Knowledge+Graphs)|0|
|[GraphERT- Transformers-based Temporal Dynamic Graph Embedding](https://doi.org/10.1145/3583780.3614899)|Moran Beladev, Gilad Katz, Lior Rokach, Uriel Singer, Kira Radinsky|Ben Gurion University of the Negev, Beer Sheva, Israel; Technion, Haifa, Israel|Dynamic temporal graphs evolve over time, adding and removing nodes and edges between time snapshots. The tasks performed on such graphs are diverse and include detecting temporal trends, finding graph-to-graph similarities, and graph visualization and clustering. For all these tasks, it is necessary to embed the entire graph in a low-dimensional space by using graph-level representations instead of the more common node-level representations. This embedding requires handling the appearance of new nodes over time as well as capturing temporal patterns of the entire graph. Most existing methods perform temporal node embeddings and focus on different methods of aggregating them for a graph-based representation. In this work, we propose an end-to-end architecture that captures both the node embeddings and their influence in a structural context during a specific time period of the graph. We present GraphERT (Graph Embedding Representation using Transformers), a novel approach to temporal graph-level embeddings. Our method pioneers the use of Transformers to seamlessly integrate graph structure learning with temporal analysis. By employing a masked language model on sequences of graph random walks, together with a novel temporal classification task, our model not only comprehends the intricate graph dynamics but also unravels the temporal significance of each node and path. This novel training paradigm empowers GraphERT to capture the essence of both the structural and temporal aspects of graphs, surpassing state-of-the-art approaches across multiple tasks on real-world datasets.|动态时间图随着时间的推移而发展，在时间快照之间添加和删除节点和边。在这些图上执行的任务是多种多样的，包括检测时间趋势，发现图到图的相似性，以及图的可视化和聚类。对于所有这些任务，有必要通过使用图级表示代替更常见的节点级表示将整个图嵌入到低维空间中。这种嵌入需要随着时间的推移处理新节点的出现，并捕获整个图的时间模式。大多数现有的方法执行时间节点嵌入，并集中在不同的方法聚合它们为一个基于图的表示。在这项工作中，我们提出了一个端到端的架构，捕获两个节点嵌入和它们的影响在一个结构上下文在一个特定的时间段的图。本文提出了一种新的时态图级嵌入方法——图形嵌入表示(GraphERT)。我们的方法率先使用变压器，以无缝集成图结构学习与时间分析。该模型通过对图的随机游动序列采用掩蔽语言模型，结合一种新的时间分类任务，不仅理解了复杂的图动态，而且揭示了每个节点和路径的时间意义。这种新颖的训练范式使 GraphERT 能够捕捉图形的结构和时间方面的本质，超越现实世界数据集上多个任务的最新方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphERT-+Transformers-based+Temporal+Dynamic+Graph+Embedding)|0|
|[Faster Approximation Algorithms for Parameterized Graph Clustering and Edge Labeling](https://doi.org/10.1145/3583780.3614878)|Vedangi Bengali, Nate Veldt|Texas A&M University, College Station, TX, USA|Graph clustering is a fundamental task in network analysis where the goal is to detect sets of nodes that are well-connected to each other but sparsely connected to the rest of the graph. We present faster approximation algorithms for an NP-hard parameterized clustering framework called LambdaCC, which is governed by a tunable resolution parameter and generalizes many other clustering objectives such as modularity, sparsest cut, and cluster deletion. Previous LambdaCC algorithms are either heuristics with no approximation guarantees, or computationally expensive approximation algorithms. We provide fast new approximation algorithms that can be made purely combinatorial. These rely on a new parameterized edge labeling problem we introduce that generalizes previous edge labeling problems that are based on the principle of strong triadic closure and are of independent interest in social network analysis. Our methods are orders of magnitude more scalable than previous approximation algorithms and our lower bounds allow us to obtain a posteriori approximation guarantees for previous heuristics that have no approximation guarantees of their own.|图聚类是网络分析中的一个基本任务，其目标是检测彼此连接良好但与图的其余部分连接稀疏的节点集。我们提出了一个名为 LambdaCC 的 NP- 硬参数化聚类框架的更快的近似算法，该框架由一个可调的分辨率参数控制，并推广了许多其他聚类目标，如模块化，最稀疏切割和集群删除。以前的 LambdaCC 算法要么是没有近似保证的启发式算法，要么是计算昂贵的近似算法。我们提供了新的快速近似算法，可以使纯组合。这些都依赖于一个新的参数化边标注问题，我们引入了推广以前的边标注问题是基于强三元闭包原理，并在社会网络分析中的独立兴趣。我们的方法比以前的近似算法具有更大的数量级，我们的下限允许我们为以前的启发式算法获得一个没有近似保证的后验近似保证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Faster+Approximation+Algorithms+for+Parameterized+Graph+Clustering+and+Edge+Labeling)|0|
|[Relevance-based Infilling for Natural Language Counterfactuals](https://doi.org/10.1145/3583780.3615029)|Lorenzo Betti, Carlo Abrate, Francesco Bonchi, Andreas Kaltenbrunner|CENTAI & Sapienza University, Turin, Italy; ISI Foundation & Central European University, Turin, Italy; CENTAI & Eurecat, Turin, Italy; ISI Foundation & Universitat Oberta de Catalunya, Turin, Italy|Counterfactual explanations are a natural way for humans to gain understanding and trust in the outcomes of complex machine learning algorithms. In the context of natural language processing, generating counterfactuals is particularly challenging as it requires the generated text to be fluent, grammatically correct, and meaningful. In this study, we improve the current state of the art for the generation of such counterfactual explanations for text classifiers. Our approach, named RELITC (Relevance-based Infilling for Textual Counterfactuals), builds on the idea of masking a fraction of text tokens based on their importance in a given prediction task and employs a novel strategy, based on the entropy of their associated probability distributions, to determine the infilling order of these tokens. Our method uses less time than competing methods to generate counterfactuals that require less changes, are closer to the original text and preserve its content better, while being competitive in terms of fluency. We demonstrate the effectiveness of the method on four different datasets and show the quality of its outcomes in a comparison with human generated counterfactuals.|反事实解释是人类理解和信任复杂机器学习算法结果的一种自然方式。在自然语言处理的环境中，生成反事实特别具有挑战性，因为它要求生成的文本流畅、语法正确和有意义。在这项研究中，我们改善了目前的技术状况，以生成这样的反事实解释的文本量词。我们的方法被命名为 RELITC (基于相关性的文本反事实填充) ，它基于根据文本标记在给定预测任务中的重要性来掩盖一小部分文本标记的想法，并采用一种新的策略，基于相关概率分布的熵来确定这些标记的填充顺序。我们的方法比竞争的方法用更少的时间来产生反事实，需要更少的变化，更接近原始文本，更好地保存其内容，同时在流畅性方面具有竞争力。我们证明了该方法在四个不同的数据集上的有效性，并通过与人类产生的反事实的比较显示了其结果的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevance-based+Infilling+for+Natural+Language+Counterfactuals)|0|
|[How Expressive are Graph Neural Networks in Recommendation?](https://doi.org/10.1145/3583780.3614917)|Xuheng Cai, Lianghao Xia, Xubin Ren, Chao Huang|The University of Hong Kong, Hong Kong, China|Graph Neural Networks (GNNs) have demonstrated superior performance on various graph learning tasks, including recommendation, where they leverage user-item collaborative filtering signals in graphs. However, theoretical formulations of their capability are scarce, despite their empirical effectiveness in state-of-the-art recommender models. Recently, research has explored the expressiveness of GNNs in general, demonstrating that message passing GNNs are at most as powerful as the Weisfeiler-Lehman test, and that GNNs combined with random node initialization are universal. Nevertheless, the concept of "expressiveness" for GNNs remains vaguely defined. Most existing works adopt the graph isomorphism test as the metric of expressiveness, but this graph-level task may not effectively assess a model's ability in recommendation, where the objective is to distinguish nodes of different closeness. In this paper, we provide a comprehensive theoretical analysis of the expressiveness of GNNs in recommendation, considering three levels of expressiveness metrics: graph isomorphism (graph-level), node automorphism (node-level), and topological closeness (link-level). We propose the topological closeness metric to evaluate GNNs' ability to capture the structural distance between nodes, which aligns closely with the objective of recommendation. To validate the effectiveness of this new metric in evaluating recommendation performance, we introduce a learning-less GNN algorithm that is optimal on the new metric and can be optimal on the node-level metric with suitable modification. We conduct extensive experiments comparing the proposed algorithm against various types of state-of-the-art GNN models to explore the explainability of the new metric in the recommendation task. For reproducibility, implementation codes are available at https://github.com/HKUDS/GTE.|图形神经网络(GNN)在各种图形学习任务中表现出了卓越的性能，包括推荐，它们利用图形中的用户项目协同过滤信号。然而，他们的能力的理论公式是稀缺的，尽管他们的经验有效性在国家的最先进的推荐模型。最近，研究人员对 GNN 的表达能力进行了一般性的探索，证明了信息传递 GNN 的最大强度与 Weisfeiler-Lehman 检验相当，并且 GNN 与随机节点初始化相结合是通用的。尽管如此，GNN 的“表现性”概念仍然含糊不清。现有的大多数工作都采用图同构测试作为表达能力的度量标准，但是这种图级任务可能不能有效地评估模型的推荐能力，其目标是区分不同亲密度的节点。本文从图同构(图级)、节点自同构(节点级)和拓扑亲密度(链路级)三个层次对推荐中 GNN 的表达能力进行了全面的理论分析。我们提出拓扑贴近度量来评估 GNN 捕获节点间结构距离的能力，这与推荐的目标非常接近。为了验证这一新指标在评估推荐性能方面的有效性，我们引入了一种无学习 GNN 算法，该算法在新指标上是最优的，并且在适当修改后可以在节点级指标上达到最优。我们进行了广泛的实验比较提出的算法与各种类型的国家最先进的 GNN 模型，以探索新的指标在推荐任务的可解释性。为确保可重复性，实施守则可于 https://github.com/hkuds/gte 索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Expressive+are+Graph+Neural+Networks+in+Recommendation?)|0|
|[L2R: Lifelong Learning for First-stage Retrieval with Backward-Compatible Representations](https://doi.org/10.1145/3583780.3614947)|Yinqiong Cai, Keping Bi, Yixing Fan, Jiafeng Guo, Wei Chen, Xueqi Cheng|CAS Key Lab of Network Data Science and Technology, ICT, CAS & University of Chinese Academy of Sciences, Beijing, China|First-stage retrieval is a critical task that aims to retrieve relevant document candidates from a large-scale collection. While existing retrieval models have achieved impressive performance, they are mostly studied on static data sets, ignoring that in the real-world, the data on the Web is continuously growing with potential distribution drift. Consequently, retrievers trained on static old data may not suit new-coming data well and inevitably produce sub-optimal results. In this work, we study lifelong learning for first-stage retrieval, especially focusing on the setting where the emerging documents are unlabeled since relevance annotation is expensive and may not keep up with data emergence. Under this setting, we aim to develop model updating with two goals: (1) to effectively adapt to the evolving distribution with the unlabeled new-coming data, and (2) to avoid re-inferring all embeddings of old documents to efficiently update the index each time the model is updated. We first formalize the task and then propose a novel Lifelong Learning method for the first-stage Retrieval, namely L2R. L2R adopts the typical memory mechanism for lifelong learning, and incorporates two crucial components: (1) selecting diverse support negatives for model training and memory updating for effective model adaptation, and (2) a ranking alignment objective to ensure the backward-compatibility of representations to save the cost of index rebuilding without hurting the model performance. For evaluation, we construct two new benchmarks from LoTTE and Multi-CPR datasets to simulate the document distribution drift in realistic retrieval scenarios. Extensive experiments show that L^2R significantly outperforms competitive lifelong learning baselines.|第一阶段检索是一项关键任务，其目的是从大规模的文档集合中检索相关的候选文档。虽然现有的检索模型已经取得了令人印象深刻的性能，但它们大多是在静态数据集上进行研究，忽略了在现实世界中，Web 上的数据随着潜在的分布漂移而不断增长。因此，对静态旧数据进行训练的检索器可能不能很好地适应新数据，并不可避免地产生次优结果。在这项工作中，我们研究了第一阶段检索的终身学习，特别关注于新出现的文档没有标记的情况，因为相关注释的成本很高，而且可能跟不上数据出现的速度。在这种情况下，我们的目标是开发模型更新有两个目标: (1)有效地适应演化的分布与未标记的新来的数据，(2)避免重新推断所有嵌入的旧文档，以有效地更新索引每次模型更新。我们首先将任务形式化，然后为第一阶段的检索提出一种新的终身学习方法，即 L2R。L2R 采用了典型的终身学习记忆机制，包括两个关键部分: (1)选择不同的支持否定来进行模型训练和记忆更新，以便有效地进行模型适应; (2)排序对齐目标，以确保表征的向后兼容性，从而在不损害模型性能的情况下节省索引重建的成本。为了进行评估，我们从 LoTTE 和 Multi-CPR 数据集中构建了两个新的基准来模拟真实检索场景中的文档分布漂移。大量实验表明，L ^ 2R 的表现明显优于竞争性的终身学习基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=L2R:+Lifelong+Learning+for+First-stage+Retrieval+with+Backward-Compatible+Representations)|0|
|[Incorporating Constituent Syntax into Grammatical Error Correction with Multi-Task Learning](https://doi.org/10.1145/3583780.3614931)|Chen Chen, Bo He, Jing Yuan, Chunyan Hou, Xiaojie Yuan|Nankai University, Tianjin, China; Tianjin University of Technology, Tianjin, China|Grammatical Error Correction (GEC) is usually considered as a translation task where an erroneous sentence is treated as the source language and the corrected sentence as the target language. The state-of-the-art GEC models often adopt transformer-based sequence-to-sequence architecture of machine translation. However, most of these approaches ignore the syntactic information because the syntax of an erroneous sentence is also full of errors and not beneficial to GEC. In this paper, we propose a novel Error-Correction Constituent Parsing (ECCP) task which uses the constituent parsing of corrected sentences to avoid the harmful effect of the erroneous sentence. We also propose an architecture that includes one encoder and two decoders. There are millions of parameters in transformer-based GEC models, and the labeled training data is substantially less than synthetic pre-training data. Therefore, adapter layers are added to the proposed architecture, and adapter tuning is used for fine-tuning our model to alleviate the low-resource issue. We conduct experiments on CoNLL-2014, BEA-2019, and JFLEG test datasets in unsupervised and supervised settings. Experimental results show that our method outperforms the-state-of-art baselines and achieves superior performance on all datasets.|语法错误纠正(GEC)通常被认为是一个翻译任务，其中错误的句子被视为源语言，被纠正的句子被视为目标语言。目前最先进的 GEC 模型通常采用基于变压器的序列到序列的机器翻译体系结构。然而，这些方法大多忽略了句法信息，因为错误句子的句法也充满了错误，不利于 GEC。本文提出了一种新的纠错成分分析(ECCP)任务，利用纠错句的成分分析来避免错误句的有害影响。我们还提出了一个包括一个编码器和两个解码器的体系结构。在基于变压器的 GEC 模型中有数百万个参数，标记的训练数据大大少于合成的训练前数据。因此，将适配器层添加到提出的体系结构中，并使用适配器调优来微调我们的模型，以缓解资源不足的问题。我们在 CoNLL-2014、 BEA-2019和 JFLEG 测试数据集上进行了无监督和监督环境下的实验。实验结果表明，该方法的性能优于现有的基线方法，在所有数据集上都取得了较好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Constituent+Syntax+into+Grammatical+Error+Correction+with+Multi-Task+Learning)|0|
|[HEProto: A Hierarchical Enhancing ProtoNet based on Multi-Task Learning for Few-shot Named Entity Recognition](https://doi.org/10.1145/3583780.3614908)|Wei Chen, Lili Zhao, Pengfei Luo, Tong Xu, Yi Zheng, Enhong Chen|Huawei Cloud Computing Technologies Co., Ltd, Hangzhou, China; University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|Few-shot Named Entity Recognition (NER) task, which aims to identify and classify entities from different domains with limited training samples, has long been treated as a basic step for knowledge graph (KG) construction. Great efforts have been made on this task with competitive performance, however, they usually treat the two subtasks, namely span detection and type classification, as mutually independent, and the integrity and correlation between subtasks have been largely ignored. Moreover, prior arts may fail to absorb the coarse-grained features of entities, resulting in a semantic-insufficient representation of entity types. To that end, in this paper, we propose a Hierarchical Enhancing ProtoNet (HEProto) based on multi-task learning, which is utilized to jointly learn these two subtasks and model their correlation. Specifically, we adopt contrastive learning to enhance the span boundary information and the type semantic representations in these two subtasks. Then, the hierarchical prototypical network is designed to leverage the coarse-grained information of entities in the type classification stage, which could help the model to better learn the fine-grained semantic representations. Along this line, we construct a similarity margin loss to reduce the similarity between fine-grained entities and other irrelevant coarse-grained prototypes. Finally, extensive experiments on the Few-NERD dataset prove that our solution outperforms competitive baseline methods. The source code of HEProto is available at \hrefhttps://github.com/fanshu6hao/HEProto https://github.com/fanshu6hao/HEProto.|少镜头命名实体识别(NER)任务是利用有限的训练样本对来自不同领域的实体进行识别和分类，长期以来一直被视为构建知识图(KG)的基本步骤。但是，人们往往将跨度检测和类型分类这两个子任务看作是相互独立的，而忽视了子任务之间的完整性和相关性。此外，现有技术可能无法吸收实体的粗粒度特征，导致实体类型的语义表示不足。为此，本文提出了一种基于多任务学习的分层增强协议网(HEProto) ，利用它来联合学习这两个子任务并建立它们之间的关联模型。具体来说，我们采用对比学习来增强这两个子任务中的跨度边界信息和类型语义表示。然后，设计层次化原型网络，在类型分类阶段利用实体的粗粒度信息，帮助模型更好地学习细粒度的语义表示。沿着这条线，我们构造一个相似性边界损失来减少细粒度实体和其他不相关的粗粒度原型之间的相似性。最后，在极少数 NERD 数据集上的大量实验证明了我们的解决方案优于竞争基线方法。HEproto 的源代码可以在 hrefhttps:// github.com/fanshu6hao/HEProto  https://github.com/fanshu6hao/HEProto 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HEProto:+A+Hierarchical+Enhancing+ProtoNet+based+on+Multi-Task+Learning+for+Few-shot+Named+Entity+Recognition)|0|
|[Continual Learning for Generative Retrieval over Dynamic Corpora](https://doi.org/10.1145/3583780.3614821)|Jiangui Chen, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Wei Chen, Yixing Fan, Xueqi Cheng|University of Amsterdam, Amsterdam, Netherlands; ICT, CAS & University of Chinese Academy of Sciences, Beijing, China|Generative retrieval (GR) directly predicts the identifiers of relevant documents (i.e., docids) based on a parametric model. It has achieved solid performance on many ad-hoc retrieval tasks. So far, these tasks have assumed a static document collection. In many practical scenarios, however, document collections are dynamic, where new documents are continuously added to the corpus. The ability to incrementally index new documents while preserving the ability to answer queries with both previously and newly indexed relevant documents is vital to applying GR models. In this paper, we address this practical continual learning problem for GR. We put forward a novel Continual-LEarner for generatiVE Retrieval (CLEVER) model and make two major contributions to continual learning for GR: (i) To encode new documents into docids with low computational cost, we present Incremental Product Quantization, which updates a partial quantization codebook according to two adaptive thresholds; and (ii) To memorize new documents for querying without forgetting previous knowledge, we propose a memory-augmented learning mechanism, to form meaningful connections between old and new documents. Empirical results demonstrate the effectiveness and efficiency of the proposed model.|生成检索(GR)基于参数模型直接预测相关文档(即文档)的标识符。它在许多自组织检索任务中取得了可靠的性能。到目前为止，这些任务都假定为静态文档集合。然而，在许多实际场景中，文档集合是动态的，其中新文档不断地添加到语料库中。增量索引新文档的能力，同时保留用先前和新索引的相关文档回答查询的能力，对于应用 GR 模型至关重要。在本文中，我们解决了这个实际的 GR 连续学习问题。我们提出了一种新的生成式虚拟检索(CLEVER)的 Continual-LEarner 模型，并为 GR 的持续学习做出了两个主要贡献: (i)为了以较低的计算成本将新文档编码成文档，我们提出了增量产品量化，它根据两个自适应阈值更新部分量化码书; (ii)为了在不忘记先前知识的情况下记忆查询新文档，我们提出了一种记忆增强学习机制，在新旧文档之间形成有意义的联系。实证结果证明了该模型的有效性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Learning+for+Generative+Retrieval+over+Dynamic+Corpora)|0|
|[I3 Retriever: Incorporating Implicit Interaction in Pre-trained Language Models for Passage Retrieval](https://doi.org/10.1145/3583780.3614923)|Qian Dong, Yiding Liu, Qingyao Ai, Haitao Li, Shuaiqiang Wang, Yiqun Liu, Dawei Yin, Shaoping Ma|Baidu Inc., Beijing, China; Tsinghua University, Beijing, China|Passage retrieval is a fundamental task in many information systems, such as web search and question answering, where both efficiency and effectiveness are critical concerns. In recent years, neural retrievers based on pre-trained language models (PLM), such as dual-encoders, have achieved huge success. Yet, studies have found that the performance of dual-encoders are often limited due to the neglecting of the interaction information between queries and candidate passages. Therefore, various interaction paradigms have been proposed to improve the performance of vanilla dual-encoders. Particularly, recent state-of-the-art methods often introduce late-interaction during the model inference process. However, such late-interaction based methods usually bring extensive computation and storage cost on large corpus. Despite their effectiveness, the concern of efficiency and space footprint is still an important factor that limits the application of interaction-based neural retrieval models. To tackle this issue, we Incorporate Implicit Interaction into dual-encoders, and propose I3 retriever. In particular, our implicit interaction paradigm leverages generated pseudo-queries to simulate query-passage interaction, which jointly optimizes with query and passage encoders in an end-to-end manner. It can be fully pre-computed and cached, and its inference process only involves simple dot product operation of the query vector and passage vector, which makes it as efficient as the vanilla dual encoders. We conduct comprehensive experiments on MSMARCO and TREC2019 Deep Learning Datasets, demonstrating the I3 retriever's superiority in terms of both effectiveness and efficiency. Moreover, the proposed implicit interaction is compatible with special pre-training and knowledge distillation for passage retrieval, which brings a new state-of-the-art performance. The codes are available at https://github.com/Deriq-Qian-Dong/III-Retriever.|短文检索是许多信息系统(如网络搜索和问答系统)的基本任务，其效率和有效性是关键问题。近年来，基于预训练语言模型(PLM)的神经检索器(如双编码器)取得了巨大的成功。然而，研究发现，由于忽略了查询和候选段之间的交互信息，双编码器的性能往往受到限制。因此，人们提出了各种交互模式来提高普通双编码器的性能。特别是，最近最先进的方法经常在模型推理过程中引入后期交互。然而，这种基于后期交互的方法通常会在大型语料库上带来大量的计算和存储开销。尽管有效，但对效率和空间足迹的关注仍然是限制基于交互的神经检索模型应用的一个重要因素。为了解决这个问题，我们将隐式交互集成到双编码器中，并提出了 I3检索器。特别是，我们的隐式交互范例利用生成的伪查询来模拟查询-通道交互，它与查询和通道编码器以端到端的方式进行联合优化。它可以完全预先计算和缓存，其推理过程只涉及查询向量和通道向量的简单点乘操作，这使得它像普通的双重编码器一样高效。我们在 MSMARCO 和 TREC2019深度学习数据集上进行了全面的实验，证明了 I3检索器在有效性和效率方面的优势。此外，提出的隐式交互与文章检索的专门预训练和知识提取兼容，带来了新的技术水平的性能。密码可以在 https://github.com/deriq-qian-dong/iii-retriever 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=I3+Retriever:+Incorporating+Implicit+Interaction+in+Pre-trained+Language+Models+for+Passage+Retrieval)|0|
|[Optimal Linear Subspace Search: Learning to Construct Fast and High-Quality Schedulers for Diffusion Models](https://doi.org/10.1145/3583780.3614999)|Zhongjie Duan, Chengyu Wang, Cen Chen, Jun Huang, Weining Qian|East China Normal University, Shanghai, China; Alibaba Group, Hangzhou, China|In recent years, diffusion models have become the most popular and powerful methods in the field of image synthesis, even rivaling human artists in artistic creativity. However, the key issue currently limiting the application of diffusion models is its extremely slow generation process. Although several methods were proposed to speed up the generation process, there still exists a trade-off between efficiency and quality. In this paper, we first provide a detailed theoretical and empirical analysis of the generation process of the diffusion models based on schedulers. We transform the designing problem of schedulers into the determination of several parameters, and further transform the accelerated generation process into an expansion process of the linear subspace. Based on these analyses, we consequently propose a novel method called Optimal Linear Subspace Search (OLSS), which accelerates the generation process by searching for the optimal approximation process of the complete generation process in the linear subspaces spanned by latent variables. OLSS is able to generate high-quality images with a very small number of steps. To demonstrate the effectiveness of our method, we conduct extensive comparative experiments on open-source diffusion models. Experimental results show that with a given number of steps, OLSS can significantly improve the quality of generated images. Using an NVIDIA A100 GPU, we make it possible to generate a high-quality image by Stable Diffusion within only one second without other optimization techniques.|近年来，扩散模型已经成为图像合成领域中最流行、最有力的方法，甚至在艺术创造力方面可以与人类艺术家相媲美。然而，目前限制扩散模型应用的关键问题是其生成过程极其缓慢。虽然提出了几种方法来加快生成过程，但仍然存在效率和质量之间的平衡。本文首先对基于调度器的扩散模型的生成过程进行了详细的理论和实证分析。将调度器的设计问题转化为多个参数的确定问题，并将加速生成过程进一步转化为线性子空间的展开过程。在此基础上，提出了一种新的最优线性子空间搜索(OLSS)方法，该方法通过在潜变量跨度的线性子空间中搜索完全生成过程的最优逼近过程来加速生成过程。OLSS 只需很少的步骤就能生成高质量的图像。为了证明我们方法的有效性，我们对开源扩散模型进行了广泛的比较实验。实验结果表明，在给定步长的情况下，OLSS 可以显著提高图像的质量。使用 NVIDIA A100图形处理器，我们可以在不使用其他优化技术的情况下，通过稳定扩散在仅仅一秒钟内生成高质量的图像。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Linear+Subspace+Search:+Learning+to+Construct+Fast+and+High-Quality+Schedulers+for+Diffusion+Models)|0|
|[KG4Ex: An Explainable Knowledge Graph-Based Approach for Exercise Recommendation](https://doi.org/10.1145/3583780.3614943)|Quanlong Guan, Fang Xiao, Xinghe Cheng, Liangda Fang, Ziliang Chen, Guanliang Chen, Weiqi Luo|Jinan University, Guangzhou, China; Monash University, Melbourne, Australia|Effective exercise recommendation is crucial for guiding students' learning trajectories and fostering their interest in the subject matter. However, the vast exercise resource and the varying learning abilities of individual students pose a significant challenge in selecting appropriate exercise questions. Collaborative filtering-based methods often struggle with recommending suitable exercises, while deep learning-based methods lack explanation, limiting their practical adoption. To address these limitations, this paper proposes KG4Ex, a knowledge graph-based exercise recommendation method. KG4Ex facilitates the matching of diverse students with suitable exercises while providing recommendation reasons. Specifically, we introduce a feature extraction module to represent students' learning states and construct a knowledge graph for exercise recommendation. This knowledge graph comprises three key entities (knowledge concepts, students, and exercises) and their interrelationships, and can be used to recommend suitable exercises. Extensive experiments on three real-world datasets and expert interviews demonstrate the superiority of KG4Ex over existing baseline methods and highlight its strong explainability.|有效的练习推荐对于引导学生的学习轨迹和培养他们对科目的兴趣是至关重要的。然而，大量的练习资源和个别学生不同的学习能力对选择合适的练习题提出了重大挑战。基于协作过滤的方法往往难以推荐合适的练习，而基于深度学习的方法缺乏解释，限制了它们的实际应用。针对这些局限性，本文提出了一种基于知识图的练习推荐方法 KG4Ex。KG4Ex 在提供推荐理由的同时，为不同类型的学生提供合适的练习。具体地说，我们引入了一个特征提取模块来表示学生的学习状态，并构造了一个用于练习推荐的知识图。这个知识图包括三个关键实体(知识概念、学生和练习)及其相互关系，可以用来推荐合适的练习。通过对三个现实世界数据集的大量实验和专家访谈，证明了 KG4Ex 相对于现有基线方法的优越性，并突出了其强大的可解释性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KG4Ex:+An+Explainable+Knowledge+Graph-Based+Approach+for+Exercise+Recommendation)|0|
|[Targeted Shilling Attacks on GNN-based Recommender Systems](https://doi.org/10.1145/3583780.3615073)|Sihan Guo, Ting Bai, Weihong Deng|Beijing University of Posts and Telecommunications, Beijing , China; Beijing University of Posts and Telecommunications, Beijing, China|GNN-based recommender systems have shown their vulnerability to shilling attacks in recent studies. By conducting shilling attacks on recommender systems, the attackers aim to have homogeneous impacts on all users. However, such indiscriminate attacks suffer from a waste of resources because even if the target item is promoted to users who are not interested, they are unlikely to click on them. In this paper, we conduct targeted shilling attacks in GNN-based recommender systems. By automatically constructing the features and edges of the fake users, our proposed framework AutoAttack achieves accurate attacks on a specific group of users while minimizing the impact on non-target users. Specifically, the features of fake users are generated based on a similarity function, which is optimized according to the features of target users. The structure of fake users is learned by conducting spectral clustering on the target users based on their graph Laplacian matrix, which contains the degree and adjacency information that provides guidance to the edge generation of fake users. We conduct extensive experiments on four real-world datasets in different GNN-based RS and evaluate the performance of our method on the shilling attack and recommendation tasks comprehensively, showing the effectiveness and flexibility of our framework.|在最近的研究中，基于 GNN 的推荐系统已经显示了它们对先令攻击的脆弱性。通过对推荐系统进行先令式攻击，攻击者的目标是对所有用户产生同样的影响。然而，这种不分青红皂白的攻击造成资源浪费，因为即使目标项目被推广给不感兴趣的用户，他们也不太可能点击这些项目。本文在基于 GNN 的推荐系统中进行有针对性的先令攻击。通过自动构造虚假用户的特征和边缘，我们提出的框架自动攻击实现了对特定用户群的准确攻击，同时最小化了对非目标用户的影响。具体来说，基于相似度函数生成虚假用户的特征，并根据目标用户的特征进行优化。虚假用户的结构是通过基于目标用户的图形 SVD 来了解的，图形 Laplacian Matrix 包含程度和邻接信息，为虚假用户的边缘生成提供指导。我们在四个不同的基于 GNN 的 RS 的真实世界数据集上进行了广泛的实验，全面评估了我们的方法在先令攻击和推荐任务上的性能，显示了我们的框架的有效性和灵活性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Targeted+Shilling+Attacks+on+GNN-based+Recommender+Systems)|0|
|[Robust Basket Recommendation via Noise-tolerated Graph Contrastive Learning](https://doi.org/10.1145/3583780.3615039)|Xinrui He, Tianxin Wei, Jingrui He|University of Illinois at Urbana-Champaign, Champaign, USA|The growth of e-commerce has seen a surge in popularity of platforms like Amazon, eBay, and Taobao. This has given rise to a unique shopping behavior involving baskets - sets of items purchased together. As a less studied interaction mode in the community, the question of how should shopping basket complement personalized recommendation systems remains under-explored. While previous attempts focused on jointly modeling user purchases and baskets, the distinct semantic nature of these elements can introduce noise when directly integrated. This noise negatively impacts the model's performance, further exacerbated by significant noise (e.g., a user is misled to click an item or recognizes it as uninteresting after consuming it) within both user and basket behaviors. In order to cope with the above difficulties, we propose a novel Basket recommendation framework via Noise-tolerated Contrastive Learning, named BNCL, to handle the noise existing in the cross-behavior integration and within-behavior modeling. First, we represent the basket-item interactions as the hypergraph to model the complex basket behavior, where all items appearing in the same basket are treated as a single hyperedge. Second, cross-behavior contrastive learning is designed to suppress the noise during the fusion of diverse behaviors. Next, to further inhibit the within-behavior noise of the user and basket interactions, we propose to exploit invariant properties of the recommenders w.r.t augmentations through within-behavior contrastive learning. A novel consistency-aware augmentation approach is further designed to better identify the noisy interactions with the consideration of the above two types of interactions. Our framework BNCL offers a generic training paradigm that is applicable to different backbones. Extensive experiments on three shopping transaction datasets verify the effectiveness of our proposed method.|随着电子商务的发展，像亚马逊、 eBay 和淘宝这样的平台越来越受欢迎。这就产生了一种独特的购物行为，包括一篮子一套的商品一起购买。作为一种研究较少的社区互动模式，购物篮应该如何补充个性化推荐系统的问题仍然没有得到充分的探讨。虽然以前的尝试侧重于联合建模用户购买和购物篮，但是当直接集成时，这些元素独特的语义特性可能会引入噪音。这种噪音会对模型的性能产生负面影响，而在用户和购物篮的行为中，显著的噪音会进一步加剧这种影响(例如，用户被误导去点击一个项目，或者在消费之后认为它没有意思)。为了克服上述困难，我们提出了一种新的基于噪声容忍对比学习的 Basket 推荐框架 BNCL，用于处理跨行为集成和行为内建模中存在的噪声。首先，我们将篮子项目的交互作用表示为超图来模拟复杂的篮子行为，其中出现在同一个篮子中的所有项目都被视为一个单一的超边。其次，设计交叉行为对比学习来抑制不同行为融合过程中的噪声。接下来，为了进一步抑制用户和篮子交互的行为内噪声，我们建议通过行为内对比学习来利用推荐者 w.r.t 增强的不变性。进一步设计了一种新的一致性增强方法，以便在考虑上述两类相互作用的情况下更好地识别噪声相互作用。我们的框架 BNCL 提供了一个通用的培训范例，适用于不同的骨干。在三个购物交易数据集上的大量实验验证了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Basket+Recommendation+via+Noise-tolerated+Graph+Contrastive+Learning)|0|
|[Search-Efficient Computerized Adaptive Testing](https://doi.org/10.1145/3583780.3615049)|Yuting Hong, Shiwei Tong, Wei Huang, Yan Zhuang, Qi Liu, Enhong Chen, Xin Li, Yuanjing He|Open University of China, Beijing, China; University of Science and Technology of China & iFLYTEK Co., Ltd, Hefei, China; University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|Computerized Adaptive Testing (CAT) arises as a promising personalized test mode in online education, targeting at revealing students' latent knowledge state by selecting test items adaptively. The item selection strategy is the core component of CAT, which searches for the best suitable test item based on students' current estimated ability at each test step. However, existing selection strategies behave in a brute-force manner, which results in the time complexity being linear to the number of items (N) in the item pool, i.e., O(N). Thus, in reality, the search latency becomes the bottleneck for CAT with a large-scale item pool. To this end, we propose a Search-Efficient Computerized Adaptive Testing framework (SECAT), which aims at enhancing CAT with an efficient selection strategy. Specifically, SECAT contains two main phases: item pool indexing and item search. In the item pool indexing phase, we apply a student-aware spatial partition method on the item pool to divide the test items into many sub-spaces, considering the adaptability of test items. In the item search phase, we optimize the traditional single-round search strategy with the asymptotic theory and propose a multi-round search strategy that can further improve the time efficiency. Compared with existing strategies, the time complexity of SECAT decreases from O(N) to O(logN). Across two real-world datasets, SECAT achieves over 200x speed up with negligible accuracy degradation.|计算机自适应测试(CAT)作为一种新兴的网络教育个性化测试模式，旨在通过自适应选择测试项目来揭示学生的潜在知识状态。试题选择策略是计算机辅助测试(CAT)的核心组成部分，它根据学生在每个测试步骤中的当前估计能力来寻找最适合的试题。然而，现有的选择策略表现出一种蛮力的方式，导致时间复杂度与项目池中的项目数(N)成线性关系，即 O (N)。因此，在现实中，搜索延迟成为大规模项目池 CAT 的瓶颈。为此，我们提出了一个搜索效率高的计算机自适应测试框架(SECAT) ，旨在通过一种有效的选择策略来增强 CAT。具体来说，SECAT 包含两个主要阶段: 项目池索引和项目搜索。在试题库索引阶段，考虑试题的适应性，在试题库上采用学生感知的空间划分方法，将试题划分为多个子空间。在项目搜索阶段，我们利用渐近理论优化了传统的单轮搜索策略，并提出了多轮搜索策略，进一步提高了时间效率。与已有策略相比，SECAT 的时间复杂度从 O (N)降低到 O (logN)。通过两个真实世界的数据集，SECAT 在可以忽略不计的精度降低的情况下实现了超过200倍的速度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search-Efficient+Computerized+Adaptive+Testing)|0|
|[Celebrity-aware Graph Contrastive Learning Framework for Social Recommendation](https://doi.org/10.1145/3583780.3614806)|Zheng Hu, Satoshi Nakagawa, Liang Luo, Yu Gu, Fuji Ren|The University of Tokyo, Tokyo, Japan; University of Electronic Science and Technology of China, Chengdu, China|Social networks exhibit a distinct "celebrity effect" whereby influential individuals have a more significant impact on others compared to ordinary individuals, unlike other network structures such as citation networks and knowledge graphs. Despite its common occurrence in social networks, the celebrity effect is frequently overlooked by existing social recommendation methods when modeling social relationships, thereby hindering the full exploitation of social networks to mine similarities between users. In this paper, we fill this gap and propose a Celebrity-aware Graph Contrastive Learning Framework for Social Recommendation (CGCL), which explicitly models the celebrity effect in the social domain. Technically, we measure the different influences of celebrity and ordinary nodes by mining social network structure features, such as closeness centrality. To model the celebrity effect in social networks, we design a novel user-user impact-aware aggregation method, which incorporates the celebrity-aware influence information into the message propagation process. Additionally, we design a graph neural network-based framework which incorporates social semantics into the user-item interaction modeling with contrastive learning-enhanced data augmentation. The experimental results on three real-world datasets show the effectiveness of the proposed framework. We conduct ablation experiments to prove that the key components of our model benefit the recommendation performance improvement.|与引用网络和知识图表等其他网络结构不同，社交网络表现出明显的“名人效应”，与普通个体相比，有影响力的个体对他人的影响更为显著。尽管名人效应在社交网络中普遍存在，但现有的社交推荐方法在对社交关系建模时往往忽视了名人效应，从而阻碍了对社交网络的充分利用以挖掘用户之间的相似性。在本文中，我们填补了这一空白，并提出了一个名人感知的图形对比学习框架(CGCL)的社会推荐，显式模型的名人效应的社会领域。在技术上，我们通过挖掘社会网络结构特征，如亲密度中心性，来衡量名人和普通节点的不同影响。为了模拟社交网络中的名人效应，我们设计了一种新的用户-用户影响感知聚合方法，该方法将名人感知的影响信息融入到信息传播过程中。此外，我们还设计了一个基于图神经网络的框架，该框架将社会语义引入到用户项目交互建模中，通过对比学习增强数据增强。在三个实际数据集上的实验结果表明了该框架的有效性。通过烧蚀实验证明了该模型的关键部分有利于推荐性能的提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Celebrity-aware+Graph+Contrastive+Learning+Framework+for+Social+Recommendation)|0|
|[Independent Distribution Regularization for Private Graph Embedding](https://doi.org/10.1145/3583780.3614933)|Qi Hu, Yangqiu Song|HKUST, Hong Kong, Hong Kong|Learning graph embeddings is a crucial task in graph mining tasks. An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc. However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from unstable training issues. In this paper, we propose a novel approach called Private Variational Graph AutoEncoders (PVGAE) with the aid of independent distribution penalty as a regularization term. Specifically, we split the original variational graph autoencoder (VGAE) to learn sensitive and non-sensitive latent representations using two sets of encoders. Additionally, we introduce a novel regularization to enforce the independence of the encoders. We prove the theoretical effectiveness of regularization from the perspective of mutual information. Experimental results on three real-world datasets demonstrate that PVGAE outperforms other baselines in private embedding learning regarding utility performance and privacy protection.|图嵌入学习是图挖掘任务中的一个关键问题。一个有效的图嵌入模型可以从图结构化数据中学习低维表示，用于数据发布，有利于各种下游应用，如节点分类、链路预测等。然而，最近的研究表明，图嵌入容易受到属性推理攻击，使攻击者能够从学习的图嵌入中推断出私有节点的属性。为了解决这些问题，出现了保护隐私的图嵌入方法，旨在同时考虑初级学习和通过对抗学习保护隐私。然而，现有的大多数方法都假设表示模型在训练阶段可以提前访问所有敏感属性，但由于隐私偏好的不同，这种假设并不总是成立。此外，隐私保护表征学习中常用的对抗学习技术存在不稳定的训练问题。在本文中，我们提出了一种新的方法称为私有变分图自动编码器(PVGAE)的援助下，独立分布罚金作为一个正则化项。具体来说，我们将原始的变分图自动编码器(VGAE)分离，使用两组编码器来学习敏感和非敏感的潜在表示。此外，我们还引入了一种新的正则化方法来增强编码器的独立性。从互信息的角度证明了正则化的理论有效性。在三个实际数据集上的实验结果表明，PVGAE 在效用性能和隐私保护方面优于其他基线的私有嵌入学习。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Independent+Distribution+Regularization+for+Private+Graph+Embedding)|0|
|[Enhancing the Robustness via Adversarial Learning and Joint Spatial-Temporal Embeddings in Traffic Forecasting](https://doi.org/10.1145/3583780.3614868)|Juyong Jiang, Binqing Wu, Ling Chen, Kai Zhang, Sunghun Kim|East China Normal University, Shanghai, China; Zhejiang University, Hangzhou, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China|Traffic forecasting is an essential problem in urban planning and computing. The complex dynamic spatial-temporal dependencies among traffic objects (e.g., sensors and road segments) have been calling for highly flexible models; unfortunately, sophisticated models may suffer from poor robustness especially in capturing the trend of the time series (1st-order derivatives with time), leading to unrealistic forecasts. To address the challenge of balancing dynamics and robustness, we propose TrendGCN, a new scheme that extends the flexibility of GCNs and the distribution-preserving capacity of generative and adversarial loss for handling sequential data with inherent statistical correlations. On the one hand, our model simultaneously incorporates spatial (node-wise) embeddings and temporal (time-wise) embeddings to account for heterogeneous space-and-time convolutions; on the other hand, it uses GAN structure to systematically evaluate statistical consistencies between the real and the predicted time series in terms of both the temporal trending and the complex spatial-temporal dependencies. Compared with traditional approaches that handle step-wise predictive errors independently, our approach can produce more realistic and robust forecasts. Experiments on six benchmark traffic forecasting datasets and theoretical analysis both demonstrate the superiority and the state-of-the-art performance of TrendGCN. Source code is available at https://github.com/juyongjiang/TrendGCN.|交通量预测是城市规划和计算中的一个基本问题。交通对象(如传感器和路段)之间复杂的动态时空依赖性一直要求高度灵活的模型; 不幸的是，复杂的模型可能会受到鲁棒性差的影响，特别是在捕捉时间序列的趋势(随时间的一阶导数)时，导致不切实际的预测。为了解决平衡动态和稳健性的挑战，我们提出了 TrendGCN，这是一种新的方案，扩展了 GCNs 的灵活性以及生成和对抗性损失的分布保持能力，用于处理具有固有统计相关性的顺序数据。一方面，我们的模型同时结合了空间(节点)嵌入和时间(时间)嵌入来解释异质的时空卷积; 另一方面，它使用 GAN 结构来系统地评估实际时间序列和预测时间序列之间的统计一致性，包括时间趋势和复杂的时空相关性。与独立处理逐步预测误差的传统方法相比，我们的方法可以产生更加真实和稳健的预测。通过对6个基准流量预测数据集的实验和理论分析，验证了趋势 GCN 的优越性和最新性能。源代码可在 https://github.com/juyongjiang/trendgcn 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+the+Robustness+via+Adversarial+Learning+and+Joint+Spatial-Temporal+Embeddings+in+Traffic+Forecasting)|0|
|[Replace Scoring with Arrangement: A Contextual Set-to-Arrangement Framework for Learning-to-Rank](https://doi.org/10.1145/3583780.3615031)|Jiarui Jin, Xianyu Chen, Weinan Zhang, Mengyue Yang, Yang Wang, Yali Du, Yong Yu, Jun Wang|East China Normal University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; University College London, London, United Kingdom; King's College London, London, United Kingdom|Learning-to-rank is a core technique in the top-N recommendation task, where an ideal ranker would be a mapping from an item set to an arrangement (a.k.a. permutation). Most existing solutions fall in the paradigm of probabilistic ranking principle (PRP), i.e., first score each item in the candidate set and then perform a sort operation to generate the top ranking list. However, these approaches neglect the contextual dependence among candidate items during individual scoring, and the sort operation is non-differentiable. To bypass the above issues, we propose Set-To-Arrangement Ranking (STARank), a new framework directly generates the permutations of the candidate items without the need for individually scoring and sort operations; and is end-to-end differentiable. As a result, STARank can operate when only the ground-truth permutations are accessible without requiring access to the ground-truth relevance scores for items. For this purpose, STARank first reads the candidate items in the context of the user browsing history, whose representations are fed into a Plackett-Luce module to arrange the given items into a list. To effectively utilize the given ground-truth permutations for supervising STARank, we leverage the internal consistency property of Plackett-Luce models to derive a computationally efficient list-wise loss. Experimental comparisons against 9 the state-of-the-art methods on 2 learning-to-rank benchmark datasets and 3 top-N real-world recommendation datasets demonstrate the superiority of STARank in terms of conventional ranking metrics. Notice that these ranking metrics do not consider the effects of the contextual dependence among the items in the list, we design a new family of simulation-based ranking metrics, where existing metrics can be regarded as special cases. STARank can consistently achieve better performance in terms of PBM and UBM simulation-based metrics.|学习排名是排名前 N 的推荐任务中的一项核心技术，理想的排名应该是从一个项目集到一个排列(又称排列)的映射。大多数现有的解决方案属于概率排序原则(PRP)的范式，即首先给候选集中的每个项目打分，然后执行排序操作来生成最高排名列表。然而，这些方法忽略了个体评分过程中候选项之间的上下文依赖性，且排序操作是不可微的。为了绕过上述问题，我们提出了一个新的框架集到排列排序(STARank) ，它直接生成候选项的排列，而不需要单独的评分和排序操作，并且是端到端可微的。因此，STARank 可以在只有地面真相排列可以访问时运行，而不需要访问项目的地面真相相关分数。为此，STARank 首先在用户浏览历史记录的上下文中读取候选项，其表示被提供给 Plackett-Luce 模块，以便将给定的项排列成列表。为了有效地利用给定的地面真理排列来监督 STARank，我们利用 Plackett-Luce 模型的内部一致性特性来导出一个计算有效的列表损失。通过对2个学习排名基准数据集和3个排名前 N 的实际推荐数据集的9种最新方法的实验比较，证明了 STARank 在常规排名指标方面的优越性。请注意，这些排名指标没有考虑列表中项目之间的上下文相关性的影响，我们设计了一个新的基于模拟的排名指标家族，其中现有的指标可以被视为特殊情况。STARank 在基于 PBM 和基于 UBM 仿真的度量方面能够持续地获得更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Replace+Scoring+with+Arrangement:+A+Contextual+Set-to-Arrangement+Framework+for+Learning-to-Rank)|0|
|[Real-time Emotion Pre-Recognition in Conversations with Contrastive Multi-modal Dialogue Pre-training](https://doi.org/10.1145/3583780.3615024)|Xincheng Ju, Dong Zhang, Suyang Zhu, Junhui Li, Shoushan Li, Guodong Zhou|Soochow University, Suzhou, China|This paper presents our pioneering effort in addressing a new and realistic scenario in multi-modal dialogue systems called Multi-modal Real-time Emotion Pre-recognition in Conversations (MREPC). The objective is to predict the emotion of a forthcoming target utterance that is highly likely to occur. We believe that this task can enhance the dialogue system's understanding of the interlocutor's state of mind, enabling it to prepare an appropriate response in advance. However, addressing MREPC poses the following challenges:1) Previous studies on emotion elicitation typically focus on textual modality and perform sentiment forecasting within a fixed contextual scenario. 2) Previous studies on multi-modal emotion recognition aim to predict the emotion of existing utterances, making it difficult to extend these approaches to MREPC due to the absence of the target utterance. To tackle these challenges, we construct two benchmark multi-modal datasets for MREPC and propose a task-specific multi-modal contrastive pre-training approach. This approach leverages large-scale unlabeled multi-modal dialogues to facilitate emotion pre-recognition for potential utterances of specific target speakers. Through detailed experiments and extensive analysis, we demonstrate that our proposed multi-modal contrastive pre-training architecture effectively enhances the performance of multi-modal real-time emotion pre-recognition in conversations.|本文介绍了我们在处理多模态对话系统中的一个新的和现实的场景，称为多模态实时情绪会话预识别(MREPC)的开拓性工作。目的是预测一个即将到来的目标话语的情绪，这是非常可能发生的。我们相信，这一任务可以提高对话系统对对话者心理状态的理解，使其能够提前准备好适当的应对措施。然而，解决 MREPC 问题带来了以下挑战: 1)以往的情绪诱发研究主要集中在语篇情态上，在固定的语境情景下进行情绪预测。2)以往对多模态情绪识别的研究主要是针对已有话语的情绪预测，但由于目标话语的缺失，这些方法难以推广到 MREPC。为了应对这些挑战，我们构建了两个基准的 MREPC 多模态数据集，并提出了一种针对特定任务的多模态对比预训练方法。该方法利用大规模未标记的多模态对话，促进对特定目标说话人潜在话语的情感预识别。通过详细的实验和广泛的分析表明，本文提出的多模态对比预训练结构有效地提高了会话中多模态实时情绪预识别的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Real-time+Emotion+Pre-Recognition+in+Conversations+with+Contrastive+Multi-modal+Dialogue+Pre-training)|0|
|[Nudging Neural Click Prediction Models to Pay Attention to Position](https://doi.org/10.1145/3583780.3614994)|Efi Karra Taniskidou, Wenjie Zhao, Iain Murray, Roberto Pellegrini|Amazon & The University of Edinburgh, Edinburgh, United Kingdom; Amazon, Edinburgh, United Kingdom|Predicting the click-through rate (CTR) of an item is a fundamental task in online advertising and recommender systems. CTR prediction models are typically trained on user click data from traffic logs. However, users are more likely to interact with items that were shown prominently on a website. CTR models often over-estimate the value of such items and show them more often, at the expense of items of higher quality that were previously shown at less prominent positions. This self-reinforcing position bias effect reduces both the immediate and long-term quality of recommendations for users. In this paper, we revisit position bias in a family of state-of-the-art neural models for CTR prediction, and use synthetic data to demonstrate the difficulty of controlling for position. We propose an approach that encourages neural networks to use position (or other confounding variables) as much as possible to explain the training data, and a metric that can directly measure bias. Experiments on two real-world datasets demonstrate the effectiveness of our approach in correcting for position-like features in 2 state-of-the-art CTR prediction models.|在在线广告和推荐系统中，预测商品的点进率是一项基本任务。CTR 预测模型通常根据流量日志中的用户点击数据进行训练。然而，用户更可能与网站上显著显示的项目进行交互。CTR 模型往往高估这些项目的价值，并更经常地显示它们，以牺牲以前显示在不太突出位置的高质量项目为代价。这种自我强化的位置偏差效应降低了对用户推荐的即时和长期质量。在本文中，我们回顾了位置偏差在一个国家的最先进的 CTR 预测神经模型的家庭，并使用合成数据来说明位置控制的困难。我们提出了一种方法，鼓励神经网络使用位置(或其他混杂变量)尽可能多地解释训练数据，并指标，可以直接测量偏倚。在两个真实世界的数据集上的实验证明了我们的方法在两个最先进的 CTR 预测模型中校正位置类特征的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nudging+Neural+Click+Prediction+Models+to+Pay+Attention+to+Position)|0|
|[A Model-Agnostic Method to Interpret Link Prediction Evaluation of Knowledge Graph Embeddings](https://doi.org/10.1145/3583780.3614763)|Narayanan Asuri Krishnan, Carlos R. Rivero|Rochester Institute of Technology, Rochester, NY, USA|In link prediction evaluation, an embedding model assigns plausibility scores to unseen triples in a knowledge graph using an input partial triple. Performance metrics like mean rank are useful to compare models side by side, but do not shed light on their behavior. Interpreting link prediction evaluation and comparing models based on such interpretation are appealing. Current interpretation methods have mainly focused on single predictions or other tasks different from link prediction. Since knowledge graph embedding methods are diverse, interpretation methods that are applicable only to certain machine learning approaches cannot be used. In this paper, we propose a model-agnostic method for interpreting link prediction evaluation as a whole. The interpretation consists of Horn rules mined from the knowledge graph containing the triples a model deems plausible. We combine precision and recall measurements of mined rules using Fβ score to quantify interpretation accuracy. To maximize interpretation accuracy when comparing models, we study two approximations to the hard problem of merging rules. Our quantitative study shows that interpretation accuracy serves to compare diverse models side by side, and that these comparisons are different from those using ranks. Our qualitative study shows that several models globally capture expected semantics, and that models make a common set of predictions despite of redundancy reduction.|在链接预测评价中，嵌入模型使用输入部分三元组将合理性分值赋给知识图中的未知三元组。像平均排名这样的性能指标对于并排比较模型很有用，但是不能说明它们的行为。解释链接预测评价和基于这种解释的比较模型是很有吸引力的。目前的解释方法主要集中在单个预测或其他不同于链接预测的任务。由于知识图嵌入方法多种多样，不能采用仅适用于某些机器学习方法的解释方法。本文提出了一种从整体上解释链路预测评价的模型不可知方法。解释包括从知识图中挖掘的 Horn 规则，其中包含模型认为合理的三元组。我们结合了准确率召回率挖掘规则的测量结果，使用 Fβ 评分来量化解释的准确性。为了在比较模型时最大限度地提高解释的准确性，我们研究了合并规则这一难题的两个近似值。我们的定量研究表明，解释的准确性服务于比较不同的模型并排，这些比较是不同的使用等级。我们的定性研究表明，几个模型全局捕获预期的语义，模型作出了一个共同的预测集，尽管冗余减少。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Model-Agnostic+Method+to+Interpret+Link+Prediction+Evaluation+of+Knowledge+Graph+Embeddings)|0|
|[Towards Automatic ICD Coding via Knowledge Enhanced Multi-Task Learning](https://doi.org/10.1145/3583780.3615087)|Xinhang Li, Xiangyu Zhao, Yong Zhang, Chunxiao Xing|City University of Hong Kong, Hong Kong, Hong Kong; Tsinghua University, Beijing, China|The aim of ICD coding is to assign International Classification of Diseases (ICD) codes to unstructured clinical notes or discharge summaries. Numerous methods have been proposed for automatic ICD coding in an effort to reduce human labor and errors. However, existing works disregard the data imbalance problem of clinical notes. In addition, the noisy clinical note issue has not been thoroughly investigated. To address such issues, we propose a knowledge enhanced Graph Attention Network (GAT) under multi-task learning setting. Specifically, multi-level information transitions and interactions have been implemented. On the one hand, a large heterogeneous text graph is constructed to capture both intra- and inter-note correlations between various semantic concepts, thereby alleviating the data imbalance issue. On the other hand, two auxiliary healthcare tasks have been proposed to facilitate the sharing of information across tasks. Moreover, to tackle the issue of noisy clinical notes, we propose to utilize the rich structured knowledge facts and information provided by medical domain knowledge, thereby encouraging the model to focus on the clinical notes' noteworthy portion and valuable information. The experimental results on the widely-used medical dataset, MIMIC-III, demonstrate the advantages of our proposed framework.|ICD 编码的目的是为非结构化的临床记录或出院摘要分配国际疾病与相关健康问题统计分类(ICD)编码。为了减少人工劳动和错误，人们提出了许多 ICD 自动编码的方法。然而，现有的研究忽视了临床注释的数据不平衡问题。此外，噪音临床注意事项并没有被彻底调查。为了解决这些问题，我们提出了一种多任务学习环境下的知识增强型图注意网络(GAT)。具体来说，已经实现了多级信息转换和交互。一方面，构造了一个大型的异构文本图来捕捉各种语义概念之间的注释内和注释间的相关性，从而缓解数据不平衡问题。另一方面，我们提出了两项辅助保健工作，以促进各项工作之间的信息共享。此外，为了解决临床记录噪声的问题，我们建议利用医学领域知识所提供的丰富的结构化知识事实和信息，从而鼓励模型关注临床记录的值得注意的部分和有价值的信息。在广泛使用的医学数据集 MIMIC-III 上的实验结果证明了该框架的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Automatic+ICD+Coding+via+Knowledge+Enhanced+Multi-Task+Learning)|0|
|[Graph Enhanced Hierarchical Reinforcement Learning for Goal-oriented Learning Path Recommendation](https://doi.org/10.1145/3583780.3614897)|Qingyao Li, Wei Xia, Li'ang Yin, Jian Shen, Renting Rui, Weinan Zhang, Xianyu Chen, Ruiming Tang, Yong Yu|Huawei Noah's Art Lab, Shenzhen, China; Huawei Noah's Ark Lab, Shenzhen, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiaotong University, Shanghai, China|Goal-oriented Learning path recommendation aims to recommend learning items (concepts or exercises) step-by-step to a learner to promote the mastery level of her specific learning goals. By formulating this task as a Markov decision process, reinforcement learning (RL) methods have demonstrated great power. Although extensive research efforts have been made, previous methods still fail to recommend effective goal-oriented paths due to the under-utilizing of goals. Specifically, it is mainly reflected in two aspects: (1)The lack of goal planning. When learners have multiple goals with different difficulties, the previous methods can't fully utilize the difficulties and dependencies between goal learning items to plan the sequence of achieving these goals, making the path chaotic and inefficient; (2)The lack of efficiency in goal achieving. When pursuing a single goal, the path may contain learning items unrelated to the goal, which makes realizing a certain goal inefficient. To address these challenges, we present a novel Graph Enhanced Hierarchical Reinforcement Learning (GEHRL) framework for goal-oriented learning path recommendation. The framework divides learning path recommendation into two parts: sub-goal selection(planning) and sub-goal achieving(learning item recommendation). Specifically, we employ a high-level agent as a sub-goal selector to select sub-goals for the low-level agent to achieve. The low-level agent in the framework is to recommend learning items to the learner. To make the path only contain goal-related learning items to improve the efficiency of achieving the goal, we develop a graph-based candidate selector to constrain the action space of the low-level agent based on the sub-goal and knowledge graph. We also develop test-based internal reward for low-level training so that the sparsity problem of external reward can be alleviated. Extensive experiments on three different simulators demonstrate our framework achieves state-of-the-art performance.|目标导向学习路径推荐旨在向学习者逐步推荐学习项目(概念或练习) ，以提高其对特定学习目标的掌握程度。通过把这个任务作为一个马可夫决策过程，强化学习(RL)方法已经证明了它的巨大威力。尽管已经做了大量的研究工作，以往的方法仍然不能推荐有效的目标导向的路径，由于目标利用不足。具体来说，主要体现在两个方面: (1)目标规划的缺失。当学习者有不同困难的多个目标时，以往的方法不能充分利用目标学习项目之间的困难和依赖关系来规划实现这些目标的顺序，使得路径混乱和效率低下; (2)目标实现效率低下。在追求单一目标时，路径中可能包含与目标无关的学习项，使得实现某一目标效率低下。为了应对这些挑战，我们提出了一个新的图形增强层次强化学习(GEHRL)框架，用于面向目标的学习路径推荐。该框架将学习路径推荐分为子目标选择(规划)和子目标实现(学习项目推荐)两部分。具体来说，我们使用高级代理作为子目标选择器，为低级代理选择要实现的子目标。框架中的底层代理是向学习者推荐学习项目。为了使路径只包含与目标相关的学习项，提高实现目标的效率，提出了一种基于子目标和知识图的候选选择器来约束底层智能体的行为空间。我们还针对低水平培训开发了基于测试的内部奖励，以缓解外部奖励稀缺的问题。在三个不同的模拟器上进行的大量实验表明，我们的框架实现了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Enhanced+Hierarchical+Reinforcement+Learning+for+Goal-oriented+Learning+Path+Recommendation)|0|
|[THGNN: An Embedding-based Model for Anomaly Detection in Dynamic Heterogeneous Social Networks](https://doi.org/10.1145/3583780.3615079)|Yilin Li, Jiaqi Zhu, Congcong Zhang, Yi Yang, Jiawen Zhang, Ying Qiao, Hongan Wang|Institute of Software, Chinese Academy of Sciences, Beijing, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Institute of Software, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China|Anomaly detection, particularly the detection of anomalous behaviors in dynamic and heterogeneous social networks, is becoming more and more crucial in real life. Traditional rule-based and feature-based methods cannot well capture the structural and temporal patterns of ever-changing user behaviors. Moreover, most of the existing works based on network embedding either rely on discretized snapshots, which have ignored accurate temporal relations among user behaviors and weakened the impact of new edges, or fail to utilize dynamic and heterogeneous information simultaneously to distinguish varying effects of new edges on existing nodes. In this paper, we propose an end-to-end continuous-time model, named Temporal Heterogeneous Graph Neural Network (THGNN), to detect anomalous behaviors (edges) in dynamic heterogeneous social networks. Specifically, the model constantly updates node embeddings by propagating the information of a new edge to its source and target nodes as well as their neighbors. In this process, heterogeneous encoders are employed to handle different types of nodes and edges. What is more, a novel dual-level distributive attention mechanism is designed to allocate the influence degree of a currently interacting node to its multiple neighbors, considering the combined effect of edge type and time interval information. That can be regarded as an extension of the classical aggregative attention mechanism in the opposite direction. Extensive experiments on four real-world datasets demonstrate that THGNN outperforms all the baselines on the task of anomalous edge detection, achieving an average AUC gain of 6% across all datasets.|异常检测，特别是在动态和异构的社交网络中发现异常行为，在现实生活中变得越来越重要。传统的基于规则和基于特征的方法不能很好地捕获不断变化的用户行为的结构和时间模式。此外，现有的基于网络嵌入的工作大多依赖于离散快照，忽略了用户行为之间精确的时间关系，削弱了新边的影响，或者未能同时利用动态和异构信息来区分新边对现有节点的不同影响。本文提出了一种端到端连续时间模型——时态异构图神经网络(THGNN) ，用于检测动态异构社会网络中的异常行为(边)。具体来说，该模型通过将新边的信息传播到源节点和目标节点以及它们的邻居，不断地更新节点嵌入。在这个过程中，异构编码器被用来处理不同类型的节点和边缘。同时，考虑到边缘类型和时间间隔信息的组合效应，设计了一种新的双层分布式注意机制来分配当前交互节点对其多个邻居的影响程度。这可以看作是对经典的聚集性注意机制在相反方向上的延伸。在四个实际数据集上的大量实验表明，THGNN 在异常边缘检测任务上优于所有基线，在所有数据集上平均获得6% 的 AUC 增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=THGNN:+An+Embedding-based+Model+for+Anomaly+Detection+in+Dynamic+Heterogeneous+Social+Networks)|0|
|[MadSGM: Multivariate Anomaly Detection with Score-based Generative Models](https://doi.org/10.1145/3583780.3614956)|Haksoo Lim, Sewon Park, Minjung Kim, Jaehoon Lee, Seonkyu Lim, Noseong Park|Samsung SDS, Seoul, Republic of Korea; LG AI Research, Seoul, Republic of Korea; Yonsei University, Seoul, Republic of Korea|The time-series anomaly detection is one of the most fundamental tasks for time-series. Unlike the time-series forecasting and classification, the time-series anomaly detection typically requires unsupervised (or self-supervised) training since collecting and labeling anomalous observations are difficult. In addition, most existing methods resort to limited forms of anomaly measurements and therefore, it is not clear whether they are optimal in all circumstances. To this end, we present a multivariate time-series anomaly detector based on score-based generative models, called MadSGM, which considers the broadest ever set of anomaly measurement factors: i) reconstruction-based, ii) density-based, and iii) gradient-based anomaly measurements. We also design a conditional score network and its denoising score matching loss for the time-series anomaly detection. Experiments on five real-world benchmark datasets illustrate that MadSGM achieves the most robust and accurate predictions.|时间序列异常检测是时间序列最基本的任务之一。与时间序列预测和分类不同，时间序列异常检测通常需要无监督(或自我监督)的训练，因为收集和标记异常观测是困难的。此外，大多数现有方法采用有限形式的异常测量，因此，不清楚它们是否在所有情况下都是最佳的。为此，我们提出了一个基于基于评分的生成模型的多变量时间序列异常检测器，称为 MadSGM，其考虑了有史以来最广泛的一组异常测量因素: i)基于重建的，ii)基于密度的，和 iii)基于梯度的异常测量。我们还设计了一个条件得分网络及其去噪得分匹配丢失的时间序列异常检测。对五个真实世界基准数据集的实验表明，MadSGM 能够实现最稳健和准确的预测。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MadSGM:+Multivariate+Anomaly+Detection+with+Score-based+Generative+Models)|0|
|[Hierarchical Prompt Tuning for Few-Shot Multi-Task Learning](https://doi.org/10.1145/3583780.3614913)|Jingping Liu, Tao Chen, Zujie Liang, Haiyun Jiang, Yanghua Xiao, Feng Wei, Yuxi Qian, Zhenghong Hao, Bing Han|Ant Group, Shanghai, China; East China University of Science and Technology, Shanghai, China; Fudan University, Shanghai, China|Prompt tuning has enhanced the performance of Pre-trained Language Models for multi-task learning in few-shot scenarios. However, existing studies fail to consider that the prompts among different layers in Transformer are different due to the diverse information learned at each layer. In general, the bottom layers in the model tend to capture low-level semantic or structural information, while the upper layers primarily acquire task-specific knowledge. Hence, we propose a novel hierarchical prompt tuning model for few-shot multi-task learning to capture this regularity. The designed model mainly consists of three types of prompts: shared prompts, auto-adaptive prompts, and task-specific prompts. Shared prompts facilitate the sharing of general information across all tasks. Auto-adaptive prompts dynamically select and integrate relevant prompt information from all tasks into the current task. Task-specific prompts concentrate on learning task-specific knowledge. To enhance the model's adaptability to diverse inputs, we introduce deep instance-aware language prompts as the foundation for constructing the above prompts. To evaluate the effectiveness of our proposed method, we conduct extensive experiments on multiple widely-used datasets. The experimental results demonstrate that the proposed method achieves state-of-the-art performance for multi-task learning in few-shot settings and outperforms ChatGPT in the full-data setting.|及时调优提高了预训练语言模型在少镜头情景下多任务学习的性能。然而，现有的研究没有考虑到变压器不同层之间的提示是不同的，因为在每一层学习的不同信息。一般来说，模型的底层倾向于捕获低层次的语义或结构信息，而上层主要获取特定于任务的知识。因此，我们提出了一个新的分层提示调整模型来捕捉这种规律性的少拍多任务学习。所设计的模型主要包括三种类型的提示: 共享提示、自适应提示和任务特定提示。共享提示有助于在所有任务之间共享一般信息。自适应提示动态选择并将所有任务中的相关提示信息集成到当前任务中。特定于任务的提示集中于学习特定于任务的知识。为了增强模型对不同输入的适应性，我们引入了深度实例感知语言提示作为构造上述提示的基础。为了评估我们提出的方法的有效性，我们在多个广泛使用的数据集上进行了广泛的实验。实验结果表明，该方法在少镜头情况下获得了最佳的多任务学习性能，在全数据情况下优于 ChatGPT。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Prompt+Tuning+for+Few-Shot+Multi-Task+Learning)|0|
|[SMEF: Social-aware Multi-dimensional Edge Features-based Graph Representation Learning for Recommendation](https://doi.org/10.1145/3583780.3615063)|Xiao Liu, Shunmei Meng, Qianmu Li, Lianyong Qi, Xiaolong Xu, Wanchun Dou, Xuyun Zhang|Nanjing University, Nanjing, China; Department of Cyber Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Macquarie University, Sydney, Australia; Digital Economy Research Institute, Nanjing University of Science & Technology, Nanjing, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; Nanjing University of Information Science & Technology, Nanjing, China; Department of Computer Science and Engineering, Nanjing University of Science and Technology & State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China|Exploring user-item interaction cues is crucial for the performance of recommender systems. Explicit investigation of interaction cues is made possible by using graph-based models, where each user-item relationship is described by an edge, and the introduction of user-user social network. While existing graph-based recommendation methods use only a single-value edge to define the relationship between a pair of user and item, which limits the ability to represent complex user-item interactions. Furthermore, some social recommendation methods overlook the heterogeneous user behavior patterns in social and interaction relationships, resulting in the suboptimal performance of existing systems. In this paper, we propose a novel Social-aware Multi-dimensional Edge Feature-based Graph Representation Learning method, called SMEF. It represents all users and items as a graph and deep learns a multi-dimensional edge feature to explicitly describe the task-specific relationships of each user-item pair. Specifically, the proposed SMEF focuses on two distinct user behavior patterns toward social friends and interactive items, which explore the underlying heterogeneous relationship cues within them. This way, the learned multi-dimensional edge features encode user information from both social and interaction aspects. The proposed SMEF is a plug-and-play module that can be combined with different recommendation frameworks and Graph Neural Networks (GNNs) backbones to generate high quality user representations. The experimental results achieved on three publicly accessible datasets show that our SMEF-based method outperforms strong baselines.|探索用户项交互线索对于推荐系统的性能至关重要。通过使用基于图的模型(其中每个用户-项目关系由一个边描述)和引入用户-用户社交网络，可以对交互线索进行明确的调查。而现有的基于图的推荐方法只使用单值边界来定义一对用户和项目之间的关系，这限制了表示复杂用户-项目交互的能力。此外，一些社交推荐方法忽视了社交和交互关系中的异构用户行为模式，导致现有系统的性能不理想。本文提出了一种新的基于社会感知的多维边缘特征的图形表示学习方法，称为 SMF。它将所有用户和项目表示为一个图形，并深入学习一个多维边缘特性，以显式地描述每个用户-项目对的特定于任务的关系。具体而言，本研究针对两种不同的使用者行为模式，分别针对社交朋友与互动项目，探讨其中潜在的异质性关系线索。这样，学习的多维边缘特征从社会和交互两个方面对用户信息进行编码。该模块可以与不同的推荐框架和图形神经网络(GNN)骨干结合，生成高质量的用户表示。在三个公开可访问数据集上的实验结果表明，我们提出的基于 MESF 的方法性能优于强基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SMEF:+Social-aware+Multi-dimensional+Edge+Features-based+Graph+Representation+Learning+for+Recommendation)|0|
|[Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph](https://doi.org/10.1145/3583780.3615054)|Yi Liu, Hongrui Xuan, Bohan Li, Meng Wang, Tong Chen, Hongzhi Yin|Nanjing University of Aeronautics and Astronautics, Nanjing, China; Tongji University, Shanghai, China; The University of Queensland, Brisbane, Australia|Knowledge graphs (KGs) are commonly used as side information to enhance collaborative signals and improve recommendation quality. In the context of knowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged as promising solutions for modeling factual and semantic information in KGs. However, the long-tail distribution of entities leads to sparsity in supervision signals, which weakens the quality of item representation when utilizing KG enhancement. Additionally, the binary relation representation of KGs simplifies hyper-relational facts, making it challenging to model complex real-world information. Furthermore, the over-smoothing phenomenon results in indistinguishable representations and information loss. To address these challenges, we propose the SDK (Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph) framework. This framework establishes a cross-view hypergraph self-supervised learning mechanism for KG enhancement. Specifically, we model hyper-relational facts in KGs to capture interdependencies between entities under complete semantic conditions. With the refined representation, a hypergraph is dynamically constructed to preserve features in the deep vector space, thereby alleviating the over-smoothing problem. Furthermore, we mine external supervision signals from both the global perspective of the hypergraph and the local perspective of collaborative filtering (CF) to guide the model prediction process. Extensive experiments conducted on different datasets demonstrate the superiority of the SDK framework over state-of-the-art models. The results showcase its ability to alleviate the effects of over-smoothing and supervision signal sparsity.|知识图作为辅助信息被广泛应用于增强协作信号和提高推荐质量。在知识感知推荐(KGR)的背景下，图形神经网络(GNN)已经成为幼儿园建立事实和语义信息模型的有希望的解决方案。然而，实体的长尾分布导致监督信号的稀疏性，使得 KG 增强的项目表示质量下降。此外，KGs 的二进制关系表示简化了超关系事实，使得对复杂的现实世界信息进行建模具有挑战性。此外，过度平滑现象导致不可区分的表示和信息损失。针对这些挑战，本文提出了基于超关系知识图的自监督动态超图推荐(SDK)框架。该框架建立了一种用于 KG 增强的跨视图超图自监督学习机制。具体来说，我们在 KG 中对超关系事实建模，以在完全语义条件下捕获实体之间的相互依赖性。该方法通过动态构造超图来保留深向量空间中的特征，从而解决了超图的过平滑问题。此外，我们从超图的全局视角和协同过滤的局部视角来挖掘外部监督信号，以指导模型的预测过程。在不同数据集上进行的大量实验表明，SDK 框架优于最先进的模型。实验结果表明，该算法能够有效地缓解过平滑和监控信号稀疏的影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Dynamic+Hypergraph+Recommendation+based+on+Hyper-Relational+Knowledge+Graph)|0|
|[Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method](https://doi.org/10.1145/3583780.3614793)|YuAn Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Wei Chen, Yixing Fan, Xueqi Cheng|University of Amsterdam, Amsterdam, Netherlands; ICT, CAS & University of Chinese Academy of Sciences, Beijing, China|Neural ranking models (NRMs) and dense retrieval (DR) models have given rise to substantial improvements in overall retrieval performance. In addition to their effectiveness, and motivated by the proven lack of robustness of deep learning-based approaches in other areas, there is growing interest in the robustness of deep learning-based approaches to the core retrieval problem. Adversarial attack methods that have so far been developed mainly focus on attacking NRMs, with very little attention being paid to the robustness of DR models. In this paper, we introduce the adversarial retrieval attack (AREA) task. The AREA task is meant to trick DR models into retrieving a target document that is outside the initial set of candidate documents retrieved by the DR model in response to a query. We consider the decision-based black-box adversarial setting, which is realistic in real-world search engines. To address the AREA task, we first employ existing adversarial attack methods designed for NRMs. We find that the promising results that have previously been reported on attacking NRMs, do not generalize to DR models: these methods underperform a simple term spamming method. We attribute the observed lack of generalizability to the interaction-focused architecture of NRMs, which emphasizes fine-grained relevance matching. DR models follow a different representation-focused architecture that prioritizes coarse-grained representations. We propose to formalize attacks on DR models as a contrastive learning problem in a multi-view representation space. The core idea is to encourage the consistency between each view representation of the target document and its corresponding viewer via view-wise supervision signals. Experimental results demonstrate that the proposed method can significantly outperform existing attack strategies in misleading the DR model with small indiscernible text perturbations.|神经排序模型(NRM)和密集检索(DR)模型在总体检索性能方面有了很大的提高。除了这些方法的有效性外，由于在其他领域基于深度学习的方法缺乏稳健性，人们对基于深度学习的方法解决核心检索问题的稳健性越来越感兴趣。目前发展起来的对抗性攻击方法主要集中在攻击 NRM，很少关注 DR 模型的鲁棒性。本文介绍了对抗性检索攻击(AREA)任务。AREA 任务是为了欺骗 DR 模型来检索目标文档，该目标文档位于 DR 模型在响应查询时检索的候选文档的初始集之外。我们考虑基于决策的黑盒对抗设置，这在现实世界的搜索引擎中是现实的。为了解决 AREA 任务，我们首先使用为 NRM 设计的现有对手攻击方法。我们发现，以前报道的攻击 NRM 的有希望的结果并没有推广到 DR 模型: 这些方法不如一个简单的术语发送方法。我们将观察到的缺乏普遍性归因于以交互为中心的 NRM 体系结构，它强调细粒度的相关性匹配。DR 模型遵循不同的以表示为中心的体系结构，该体系结构对粗粒度表示进行优先级排序。我们提出将对 DR 模型的攻击形式化为一个多视图表示空间中的对比学习问题。其核心思想是通过视图监控信号鼓励目标文档的每个视图表示与其相应的查看器之间的一致性。实验结果表明，该方法能够明显优于现有的攻击策略，具有较小的不可分辨文本扰动误导 DR 模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Black-box+Adversarial+Attacks+against+Dense+Retrieval+Models:+A+Multi-view+Contrastive+Learning+Method)|0|
|[Selecting Walk Schemes for Database Embedding](https://doi.org/10.1145/3583780.3615052)|Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, Benny Kimelfeld|RWTH Aachen University, Aachen, Germany; Technion, Haifa, Israel|Machinery for data analysis often requires a numeric representation of the input. Towards that, a common practice is to embed components of structured data into a high-dimensional vector space. We study the embedding of the tuples of a relational database, where existing techniques are often based on optimization tasks over a collection of random walks from the database. The focus of this paper is on the recent FoRWaRD algorithm that is designed for dynamic databases, where walks are sampled by following foreign keys between tuples. Importantly, different walks have different schemas, or ?walk schemes," that are derived by listing the relations and attributes along the walk. Also importantly, different walk schemes describe relationships of different natures in the database. We show that by focusing on a few informative walk schemes, we can obtain tuple embedding significantly faster, while retaining the quality. We define the problem of scheme selection for tuple embedding, devise several approaches and strategies for scheme selection, and conduct a thorough empirical study of the performance over a collection of downstream tasks. Our results confirm that with effective strategies for scheme selection, we can obtain high-quality embeddings considerably (e.g., three times) faster, preserve the extensibility to newly inserted tuples, and even achieve an increase in the precision of some tasks.|用于数据分析的机器通常需要输入的数字表示。为此，一个常见的做法是将结构化数据的组件嵌入到高维向量空间中。我们研究了关系数据库元组的嵌入，其中现有的技术通常是基于优化任务，从数据库中随机游走的集合。本文的重点是针对动态数据库设计的最新的 ForRWaRD 算法，该算法通过在元组之间跟随外键来采样行走。重要的是，不同的散步有不同的模式，还是？这是通过列出步行过程中的关系和属性得出的。同样重要的是，不同的遍历方案描述数据库中不同性质的关系。实验结果表明，在保证质量的前提下，通过对几种信息量较大的步进方案进行分析，可以显著提高元组嵌入的速度。我们定义了元组嵌入的方案选择问题，设计了几种方案选择的方法和策略，并对下游任务集的性能进行了深入的实证研究。实验结果表明，采用有效的方案选择策略，可以更快地获得高质量的嵌入，保持新插入元组的可扩展性，甚至可以提高某些任务的精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Selecting+Walk+Schemes+for+Database+Embedding)|0|
|[Timestamps as Prompts for Geography-Aware Location Recommendation](https://doi.org/10.1145/3583780.3615083)|Yan Luo, Haoyi Duan, Ye Liu, FuLai Chung|Zhejiang University, Hangzhou, China; The Hong Kong Polytechnic University, Hong Kong, Hong Kong|Location recommendation plays a vital role in improving users' travel experience. The timestamp of the POI to be predicted is of great significance, since a user will go to different places at different times. However, most existing methods either do not use this kind of temporal information, or just implicitly fuse it with other contextual information. In this paper, we revisit the problem of location recommendation and point out that explicitly modeling temporal information is a great help when the model needs to predict not only the next location but also further locations. In addition, state-of-the-art methods do not make effective use of geographic information and suffer from the hard boundary problem when encoding geographic information by gridding. To this end, a Temporal Prompt-based and Geography-aware (TPG) framework is proposed. The temporal prompt is firstly designed to incorporate temporal information of any further check-in. A shifted window mechanism is then devised to augment geographic data for addressing the hard boundary problem. Via extensive comparisons with existing methods and ablation studies on five real-world datasets, we demonstrate the effectiveness and superiority of the proposed method under various settings. Most importantly, our proposed model has the superior ability of interval prediction. In particular, the model can predict the location that a user wants to go to at a certain time while the most recent check-in behavioral data is masked, or it can predict specific future check-in (not just the next one) at a given timestamp.|位置推荐在改善用户的旅游体验方面起着至关重要的作用。预测的 POI 的时间戳非常重要，因为用户将在不同的时间到达不同的地点。然而，大多数现有的方法要么不使用这种时间信息，要么只是隐式地将其与其他上下文信息融合在一起。在本文中，我们再次回顾了位置推荐的问题，并指出当模型不仅需要预测下一个位置，而且需要预测更远的位置时，显式地建立时间信息是一个很大的帮助。另外，现有的方法在对地理信息进行网格化编码时，不能有效地利用地理信息，存在硬边界问题。为此，提出了一个基于时态提示和地理感知(TPG)的框架。时间提示符首先设计为合并任何进一步签入的时间信息。然后设计了一种移动窗口机制来增加地理数据，以解决硬边界问题。通过与现有方法的广泛比较以及对五个实际数据集的烧蚀研究，我们证明了该方法在不同环境下的有效性和优越性。最重要的是，我们提出的模型具有优越的区间预测能力。特别是，当最近的签入行为数据被掩盖时，该模型可以预测用户在特定时间想要去的位置，或者它可以预测给定时间戳的特定未来签入(不仅仅是下一次)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Timestamps+as+Prompts+for+Geography-Aware+Location+Recommendation)|0|
|[LambdaRank Gradients are Incoherent](https://doi.org/10.1145/3583780.3614948)|Federico Marcuzzi, Claudio Lucchese, Salvatore Orlando|Università Ca' Foscari Venezia, Venice, Italy|In Information Retrieval (IR), the Learning-to-Rank (LTR) task requires building a ranking model that optimises a specific IR metric. One of the most effective approaches to do so is the well-known LambdaRank algorithm. LambdaRank uses gradient descent optimisation, and at its core, it defines approximate gradients, the so-called lambdas, for a non-differentiable IR metric. Intuitively, each lambda describes how much a document's score should be "pushed" up/down to reduce the ranking error. In this work, we show that lambdas may be incoherent w.r.t. the metric being optimised: e.g., a document with high relevance in the ground truth may receive a smaller gradient push than a document with lower relevance. This behaviour goes far beyond the expected degree of approximation. We analyse such behaviour of LambdaRank gradients and we introduce some strategies to reduce their incoherencies. We demonstrate through extensive experiments, conducted using publicly available datasets, that the proposed approach reduces the frequency of the incoherencies in LambdaRank and derivatives, and leads to models that achieve statistically significant improvements in the NDCG metric, without compromising the training efficiency.|在信息检索中，学习排名(Learning-to-Rank，LTR)任务需要建立一个排名模型来优化一个特定的 IR 指标。最有效的方法之一是著名的 LambdaRank 算法。LambdaRank 使用梯度下降法优化，在其核心，它定义了近似梯度，即所谓的 lambdas，用于不可微 IR 度量。直观地说，每个 lambda 描述了一个文档的分数应该“上推”多少，以减少排名错误。在这项工作中，我们表明，lambdas 可能是不连贯的 W.R.T。的度量被优化: 例如，一个文件与地面真相高相关性可能会收到一个较小的梯度推动比一个文件与低相关性。这种行为远远超出了预期的近似程度。我们分析了这种行为的 LambdaRank 梯度和我们介绍了一些策略，以减少他们的不一致性。我们通过使用公开可用的数据集进行的广泛实验证明，所提出的方法降低了 LambdaRank 和衍生物中不相干的频率，并导致模型在 NDCG 指标中实现统计学显着的改善，而不损害训练效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LambdaRank+Gradients+are+Incoherent)|0|
|[System Initiative Prediction for Multi-turn Conversational Information Seeking](https://doi.org/10.1145/3583780.3615070)|Chuan Meng, Mohammad Aliannejadi, Maarten de Rijke|University of Amsterdam, Amsterdam, Netherlands|Identifying the right moment for a system to take the initiative is essential to conversational information seeking (CIS). Existing studies have extensively studied the clarification need prediction task, i.e., predicting when to ask a clarifying question, however, it only covers one specific system-initiative action. We define the system initiative prediction (SIP) task as predicting whether a CIS system should take the initiative at the next turn. Our analysis reveals that for effective modeling of SIP, it is crucial to capture dependencies between adjacent user?system initiative-taking decisions. We propose to model SIP by CRFs. Due to their graphical nature, CRFs are effective in capturing such dependencies and have greater transparency than more complex methods, e.g., LLMs. Applying CRFs to SIP comes with two challenges: (i) CRFs need to be given the unobservable system utterance at the next turn, and (ii) they do not explicitly model multi-turn features. We model SIP as an input-incomplete sequence labeling problem and propose a multi-turn system initiative predictor (MuSIc) that has (i) prior-posterior inter-utterance encoders to eliminate the need to be given the unobservable system utterance, and (ii) a multi-turn feature-aware CRF layer to incorporate multi-turn features into the dependencies between adjacent initiative-taking decisions. Experiments show that MuSIc outperforms LLM-based baselines including LLaMA, achieving state-of-the-art results on SIP. We also show the benefits of SIP on clarification need prediction and action prediction.|确定系统采取主动的合适时机对于会话信息搜索(CIS)至关重要。现有的研究已经广泛地研究了澄清需求预测任务，即预测何时提出澄清问题，但它只涉及一个具体的系统-主动行为。我们将系统主动预测(SIP)任务定义为预测一个 CIS 系统是否应该在下一轮采取主动。我们的分析表明，对于 SIP 的有效建模，捕获相邻用户系统主动决策之间的依赖性是至关重要的。我们提出用 CRF 来建立 SIP 模型。由于它们的图形化特性，通用报告格式能够有效地捕获这种依赖关系，并且比更复杂的方法(例如 LLM)具有更大的透明度。将 CRF 应用于 SIP 有两个挑战: (i) CRF 需要在下一个回合中被赋予不可观察的系统语句，以及(ii)它们没有明确地建模多回合特征。我们将 SIP 建模为一个输入不完全序列标记问题，并提出了一个多回合系统主动预测器(MuSic) ，它具有(i)先验-后验语音编码器以消除给定不可观测系统语音的需要，以及(ii)一个多回合特征感知 CRF 层以将多回合特征纳入相邻主动决策之间的依赖关系。实验结果表明，MuSIC 的性能优于基于 LLM 的基线(包括 LLaMA) ，在 SIP 上取得了一流的效果。我们还展示了 SIP 在澄清需求预测和作用预测方面的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=System+Initiative+Prediction+for+Multi-turn+Conversational+Information+Seeking)|0|
|[Hybrid Contrastive Constraints for Multi-Scenario Ad Ranking](https://doi.org/10.1145/3583780.3614920)|Shanlei Mu, Penghui Wei, Wayne Xin Zhao, Shaoguo Liu, Liang Wang, Bo Zheng|Gaoling School of Artificial Intelligence, Renmin University of China & Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China; Alibaba Group, Beijing, China|Multi-scenario ad ranking aims at leveraging the data from multiple domains or channels for training a unified ranking model to improve the performance at each individual scenario. Although the research on this task has made important progress, it still lacks the consideration of cross-scenario relations, thus leading to limitation in learning capability and difficulty in interrelation modeling. In this paper, we propose a Hybrid Contrastive Constrained approach (HC^2) for multi-scenario ad ranking. To enhance the modeling of data interrelation, we elaborately design a hybrid contrastive learning approach to capture commonalities and differences among multiple scenarios. The core of our approach consists of two elaborated contrastive losses, namely generalized and individual contrastive loss, which aim at capturing common knowledge and scenario-specific knowledge, respectively. To adapt contrastive learning to the complex multi-scenario setting, we propose a series of important improvements. For generalized contrastive loss, we enhance contrastive learning by extending the contrastive samples (label-aware and diffusion noise enhanced contrastive samples) and reweighting the contrastive samples (reciprocal similarity weighting). For individual contrastive loss, we use the strategies of dropout-based augmentation and {cross-scenario encoding} for generating meaningful positive and negative contrastive samples, respectively. Extensive experiments on both offline evaluation and online test have demonstrated the effectiveness of the proposed HC$^2$ by comparing it with a number of competitive baselines.|多场景广告排名的目的是利用来自多个领域或渠道的数据来训练一个统一的排名模型，以提高每个场景的性能。本课题的研究虽然取得了重要进展，但仍然缺乏对跨场景关系的考虑，从而导致学习能力的局限性和相互关系建模的困难。本文提出了一种基于混合对比约束的多场景广告排名方法(HC ^ 2)。为了加强数据相关性的建模，我们精心设计了一种混合对比学习方法来捕捉多个场景之间的共性和差异。我们的方法的核心包括两个详细的对比损失，即广义对比损失和个体对比损失，分别旨在获取共同知识和情景特定的知识。为了使对比学习适应复杂的多场景环境，我们提出了一系列重要的改进措施。对于广义对比损失，我们通过扩展对比样本(标签感知和扩散噪声增强的对比样本)和重新加权对比样本(互惠相似性加权)来增强对比学习。对于个体对比损失，我们分别使用基于辍学的增强策略和{交叉情景编码}来产生有意义的正向和负向对比样本。离线评估和在线测试的广泛实验已经证明了所提出的 HC $^ 2 $的有效性，通过比较它与一些竞争性的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hybrid+Contrastive+Constraints+for+Multi-Scenario+Ad+Ranking)|0|
|[Contrastive Learning of Temporal Distinctiveness for Survival Analysis in Electronic Health Records](https://doi.org/10.1145/3583780.3614824)|Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao|University of Kansas, Lawrence, KS, USA; West Virginia University, Morgantown, WV, USA; University of Florida, Gainesville, FL, USA|Survival analysis plays a crucial role in many healthcare decisions, where the risk prediction for the events of interest can support an informative outlook for a patient's medical journey. Given the existence of data censoring, an effective way of survival analysis is to enforce the pairwise temporal concordance between censored and observed data, aiming to utilize the time interval before censoring as partially observed time-to-event labels for supervised learning. Although existing studies mostly employed ranking methods to pursue an ordering objective, contrastive methods which learn a discriminative embedding by having data contrast against each other, have not been explored thoroughly for survival analysis. Therefore, in this paper, we propose a novel Ontology-aware Temporality-based Contrastive Survival (OTCSurv) analysis framework that utilizes survival durations from both censored and observed data to define temporal distinctiveness and construct negative sample pairs with adjustable hardness for contrastive learning. Specifically, we first use an ontological encoder and a sequential self-attention encoder to represent the longitudinal EHR data with rich contexts. Second, we design a temporal contrastive loss to capture varying survival durations in a supervised setting through a hardness-aware negative sampling mechanism. Last, we incorporate the contrastive task into the time-to-event predictive task with multiple loss components. We conduct extensive experiments using a large EHR dataset to forecast the risk of hospitalized patients who are in danger of developing acute kidney injury (AKI), a critical and urgent medical condition. The effectiveness and explainability of the proposed model are validated through comprehensive quantitative and qualitative studies.|生存分析在许多医疗决策中起着至关重要的作用，其中对感兴趣的事件的风险预测可以支持对患者医疗旅程的信息性展望。鉴于数据审查的存在，一个有效的生存分析方法是加强审查数据和观察数据之间的成对时间一致性，目的是利用审查前的时间间隔作为部分观察到的监督式学习时间-事件标签。虽然现有的研究大多采用排序方法来追求排序目标，但对比分析方法通过数据对比来学习判别嵌入，尚未深入探讨用于生存分析的方法。因此，本文提出了一种新的基于本体感知时间性的对比生存(OTCSurv)分析框架，该框架利用截尾数据和观测数据的生存时间来定义时间差异性，并构造具有可调硬度的负样本对用于对比学习。具体来说，我们首先使用一个本体编码器和一个顺序自我注意编码器来表示具有丰富上下文的纵向 EHR 数据。其次，我们设计了一个时间对比损失，通过硬度感知的负采样机制，在监督环境下捕获不同的生存期。最后，我们将对比任务融入到具有多个损失分量的时间-事件预测任务中。我们使用一个大型的 EHR 数据集进行了广泛的实验，以预测有发展为急性肾损伤(AKI)危险的住院患者的风险，急性肾损伤是一种危险和紧急的医疗状况。通过全面的定量和定性研究，验证了该模型的有效性和可解释性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+of+Temporal+Distinctiveness+for+Survival+Analysis+in+Electronic+Health+Records)|0|
|[MUSE: Music Recommender System with Shuffle Play Recommendation Enhancement](https://doi.org/10.1145/3583780.3614976)|Yunhak Oh, Sukwon Yun, Dongmin Hyun, Sein Kim, Chanyoung Park|KAIST, Daejeon, Republic of Korea; POSTECH, Pohang, Republic of Korea|Recommender systems have become indispensable in music streaming services, enhancing user experiences by personalizing playlists and facilitating the serendipitous discovery of new music. However, the existing recommender systems overlook the unique challenges inherent in the music domain, specifically shuffle play, which provides subsequent tracks in a random sequence. Based on our observation that the shuffle play sessions hinder the overall training process of music recommender systems mainly due to the high unique transition rates of shuffle play sessions, we propose a Music Recommender System with Shuffle Play Recommendation Enhancement (MUSE). MUSE employs the self-supervised learning framework that maximizes the agreement between the original session and the augmented session, which is augmented by our novel session augmentation method, called transition-based augmentation. To further facilitate the alignment of the representations between the two views, we devise two fine-grained matching strategies, i.e., item- and similarity-based matching strategies. Through rigorous experiments conducted across diverse environments, we demonstrate MUSE's efficacy over 12 baseline models on a large-scale Music Streaming Sessions Dataset (MSSD) from Spotify. The source code of MUSE is available at \url{https://github.com/yunhak0/MUSE}.|在音乐流媒体服务中，推荐系统已经变得不可或缺，它通过个性化播放列表和促进偶然发现新音乐来增强用户体验。然而，现有的推荐系统忽略了音乐领域固有的独特挑战，特别是随机播放，它提供随机序列的后续曲目。根据我们的观察，主要由于洗牌游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游。MUSE 采用自监督学习框架，最大限度地提高了原始会话和扩展会话之间的一致性，并通过我们新颖的会话扩展方法(称为基于转换的扩展)进行了扩展。为了进一步促进两个视图之间的匹配，我们设计了两种细粒度匹配策略，即基于项目和相似性的匹配策略。通过在不同环境中进行的严格实验，我们在来自 Spotify 的大规模音乐流媒体会话数据集(MSSD)上证明了 MUSE 超过12个基线模型的功效。MUSE 的源代码可以在 url { https://github.com/yunhak0/MUSE }找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MUSE:+Music+Recommender+System+with+Shuffle+Play+Recommendation+Enhancement)|0|
|[Dual-Oriented Contrast for Recommendation with A Stop-Gradient Operation](https://doi.org/10.1145/3583780.3614852)|Byungkook Oh, Yul Kim, Bumky Min|Samsung Research, Seoul, Republic of Korea|Recently, contrastive loss is adopted as a main objective of recommender systems. InfoNCE-like losses penalize hard negative items more and control the strength of penalties with a temperature, called hardness-aware sensitivity. However, since they leverageuser->item patterns in a non-symmetric way, negative items are pushed away from anchor users and attract semantically-similar items to each other, focusing on the distribution of item embeddings. We point out that user embeddings also have inherent semantic structures that can be captured fromitem->user patterns. This paper presents Dual-oriented Contrast(DuCo), a novel symmetric learning objective for recommendation to learn more comprehensive representations fromusereftrightarrowitem patterns. DuCo controls user-/item-centric hardness-aware sensitivities and simultaneously optimizes the score distributions over sampled items (user-oriented contrast) and users (item-oriented contrast). This aims to explore ideal user and item distributions that are locally clustered and globally uniform. However, since user-/item-side temperatures are interdependent, naive control over temperatures may break the underlying semantic structures of the other side. To this end, we employ a stop-gradient operation to preserve the individual characteristics of user/item embedding distributions. Furthermore, we balance user-/item-oriented contrasts during learning to maintain consistent high-rank performance (e.g., recall@1). Empirical results show that DuCo contributes to the top-k user and item prediction simultaneously, and outperforms state-of-the-art learning objectives across different backbones from ID-based to neighbor-based encoders.|近年来，对比损失被作为推荐系统的主要目标。类似于 InfoNCE 的损失更多地惩罚硬负面项目，并用温度控制惩罚的强度，称为硬度感知灵敏度。然而，由于它们以一种非对称的方式利用 user-> item 模式，负面条目被推离锚用户，并且相互吸引语义相似的条目，关注条目嵌入的分布。我们指出，用户嵌入还具有可以从 mitem-> 用户模式捕获的固有语义结构。本文提出了一种新的对称推荐学习目标——双向对比度(DuCo)。DuCo 控制以用户/项目为中心的硬度感知敏感性，并同时优化分数分布的抽样项目(面向用户的对比)和用户(面向项目的对比)。这旨在探索理想的本地集群和全局统一的用户和项目分布。但是，由于用户/项目端的温度是相互依赖的，因此对温度的天真控制可能会破坏另一端的底层语义结构。为此，我们使用了一个停止梯度操作来保留用户/项嵌入分布的各自特征。此外，我们在学习过程中平衡用户/项目导向的对比，以保持一致的高等级性能(例如，召回@1)。实证结果表明，DuCo 能够同时提供最佳用户和项目预测，并且在从基于 ID 的编码器到基于邻居的编码器的不同骨干网络中，其学习效果优于最先进的学习目标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-Oriented+Contrast+for+Recommendation+with+A+Stop-Gradient+Operation)|0|
|[Quad-Tier Entity Fusion Contrastive Representation Learning for Knowledge Aware Recommendation System](https://doi.org/10.1145/3583780.3615020)|Rongqing Kenneth Ong, Wei Qiu, Andy W. H. Khong|Nanyang Technological University, Singapore, Singapore|Knowledge graph (KG) has recently emerged as a powerful source of auxiliary information in the realm of knowledge-aware recommendation (KGR) systems. However, due to the lack of supervision signals caused by the sparse nature of user-item interactions, existing supervised graph neural network (GNN) models suffer from performance degradation. Moreover, the over-smoothing issue further limits the number of GNN layers or hops required to propagate messages - these models ignore the non-local information concealed deep within the knowledge graph. We propose the Quad-Tier Entity Fusion Contrastive Representation Learning (QTEF-CRL) knowledge-aware framework to achieve learning of deep user preferences from four perspectives: the collaborative, semantic, preference, and structural view. Unlike existing methods, the proposed tri-local and single-global quad-tier architecture exploits the knowledge graph holistically to achieve effective self-supervised representation learning. The newly-introduced preference view constructed from the collaborative knowledge graph (CKG) comprises a preference graph and preference-guided GNN that are specifically designed to capture non-local information explicitly. Experiments conducted on three datasets highlight the efficacy of our proposed model.|在知识感知推荐(KGR)系统领域，知识图(KG)已经成为一个强大的辅助信息源。然而，由于用户-项目交互的稀疏性造成监督信号的缺乏，现有的监督图神经网络(GNN)模型存在性能下降的问题。此外，过于平滑的问题进一步限制了传播消息所需的 GNN 层数或跳数——这些模型忽略了隐藏在知识图深处的非本地信息。我们提出了四层实体融合对比表示学习(QTEF-CRL)知识感知框架，从协作、语义、偏好和结构四个角度实现深度用户偏好的学习。与现有的方法不同，本文提出的三局部和单全局四层结构全面地利用知识图来实现有效的自监督表示学习。由协同知识图(CKG)构造的新的偏好视图包括偏好图和偏好引导的 GNN，它们是专门为显式捕获非局部信息而设计的。在三个数据集上进行的实验突出了我们提出的模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quad-Tier+Entity+Fusion+Contrastive+Representation+Learning+for+Knowledge+Aware+Recommendation+System)|0|
|[A Retrieve-and-Read Framework for Knowledge Graph Link Prediction](https://doi.org/10.1145/3583780.3614769)|Vardaan Pahuja, Boshi Wang, Hugo Latapie, Jayanth Srinivasa, Yu Su|Cisco Research, San Jose, CA, USA; The Ohio State University, Columbus, OH, USA|Knowledge graph (KG) link prediction aims to infer new facts based on existing facts in the KG. Recent studies have shown that using the graph neighborhood of a node via graph neural networks (GNNs) provides more useful information compared to just using the query information. Conventional GNNs for KG link prediction follow the standard message-passing paradigm on the entire KG, which leads to over-smoothing of representations and also limits their scalability. On a large scale, it becomes computationally expensive to aggregate useful information from the entire KG for inference. To address the limitations of existing KG link prediction frameworks, we propose a novel retrieve-and-read framework, which first retrieves a relevant subgraph context for the query and then jointly reasons over the context and the query with a high-capacity reader. As part of our exemplar instantiation for the new framework, we propose a novel Transformer-based GNN as the reader, which incorporates graph-based attention structure and cross-attention between query and context for deep fusion. This design enables the model to focus on salient context information relevant to the query. Empirical results on two standard KG link prediction datasets demonstrate the competitive performance of the proposed method.|知识图(KG)链接预测的目的是根据 KG 中已有的事实推断出新的事实。最近的研究表明，通过图神经网络(GNN)使用节点的图邻域比仅仅使用查询信息提供更多有用的信息。用于 KG 链路预测的传统 GNN 遵循整个 KG 上的标准消息传递范式，这导致表示过于平滑，也限制了它们的可伸缩性。在大规模情况下，从整个 KG 中聚合有用的信息进行推理的计算开销变得很大。针对现有 KG 链路预测框架的局限性，提出了一种新的检索-读取框架，该框架首先检索查询的相关子图上下文，然后与大容量阅读器对上下文和查询进行联合推理。作为新框架示例实例的一部分，我们提出了一种新的基于 Transform- 的 GNN 作为读者，它结合了基于图的注意结构和查询与上下文之间的交叉注意来进行深度融合。这种设计使模型能够关注与查询相关的显著上下文信息。在两个标准 KG 链路预测数据集上的实验结果证明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Retrieve-and-Read+Framework+for+Knowledge+Graph+Link+Prediction)|0|
|[Toward a Better Understanding of Loss Functions for Collaborative Filtering](https://doi.org/10.1145/3583780.3615086)|Seongmin Park, Mincheol Yoon, Jaewoong Lee, Hogun Park, Jongwuk Lee|Sungkyunkwan University, Suwon, Republic of Korea|Collaborative filtering (CF) is a pivotal technique in modern recommender systems. The learning process of CF models typically consists of three components: interaction encoder, loss function, and negative sampling. Although many existing studies have proposed various CF models to design sophisticated interaction encoders, recent work shows that simply reformulating the loss functions can achieve significant performance gains. This paper delves into analyzing the relationship among existing loss functions. Our mathematical analysis reveals that the previous loss functions can be interpreted as alignment and uniformity functions: (i) the alignment matches user and item representations, and (ii) the uniformity disperses user and item distributions. Inspired by this analysis, we propose a novel loss function that improves the design of alignment and uniformity considering the unique patterns of datasets called Margin-aware Alignment and Weighted Uniformity (MAWU). The key novelty of MAWU is two-fold: (i) margin-aware alignment (MA) mitigates user/item-specific popularity biases, and (ii) weighted uniformity (WU) adjusts the significance between user and item uniformities to reflect the inherent characteristics of datasets. Extensive experimental results show that MF and LightGCN equipped with MAWU are comparable or superior to state-of-the-art CF models with various loss functions on three public datasets.|协同过滤(CF)是现代推荐系统中的一项关键技术。CF 模型的学习过程通常由三部分组成: 交互编码器、损耗函数和负采样。虽然许多现有的研究已经提出了各种 CF 模型来设计复杂的交互编码器，最近的工作表明，简单地重新制定损失函数可以取得显著的性能增益。本文深入分析了现有损失函数之间的关系。我们的数学分析表明，先前的损失函数可以解释为对齐和一致性函数: (i)对齐匹配用户和项目表示，和(ii)一致性分散用户和项目分布。受此分析的启发，我们提出了一种新的损失函数，改进了排列和均匀性的设计，考虑到独特的模式数据集称为边缘感知排列和加权均匀性(MAWU)。MAWU 的关键新颖性有两个方面: (i)边际感知对齐(MA)减轻用户/项目特定的流行偏见，和(ii)加权一致性(WU)调整用户和项目一致性之间的显着性以反映数据集的固有特征。大量的实验结果表明，配备 MAWU 的 MF 和 LightGCN 在三个公共数据集上具有各种损失函数，与最先进的 CF 模型相比具有可比性或优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+a+Better+Understanding+of+Loss+Functions+for+Collaborative+Filtering)|0|
|[Evaluating and Optimizing the Effectiveness of Neural Machine Translation in Supporting Code Retrieval Models: A Study on the CAT Benchmark](https://doi.org/10.1145/3583780.3614869)|Hung Phan, Ali Jannesari|Iowa State University, Ames, IA, USA|Neural Machine Translation (NMT) is widely applied in software engineering tasks. The effectiveness of NMT for code retrieval relies on the ability to learn from the sequence of tokens in the source language to the sequence of tokens in the target language. While NMT performs well in pseudocode-to-code translation, it might have challenges in learning to translate from natural language query to source code in newly curated real-world code documentation/ implementation datasets. In this work, we analyze the performance of NMT in natural language-to-code translation in the newly curated CAT benchmark that includes the optimized versions of three Java datasets TLCodeSum, CodeSearchNet, Funcom, and a Python dataset PCSD. Our evaluation shows that NMT has low accuracy, measured by CrystalBLEU and Meteor metrics in this task. To alleviate the duty of NMT in learning complex representation of source code, we propose ASTTrans Representation, a tailored representation of an Abstract Syntax Tree (AST) using a subset of non-terminal nodes. We show that the classical approach NMT performs significantly better in learning ASTTrans Representation over code tokens with up to 36% improvement on Meteor score. Moreover, we leverage ASTTrans Representation to conduct combined code search processes from the state-of-the-art code search processes using GraphCodeBERT and UniXcoder. Our NMT models of learning ASTTrans Representation can boost the Mean Reciprocal Rank of these state-of-the-art code search processes by up to 3.08% and improve 23.08% of queries' results over the CAT benchmark.|神经机器翻译(NMT)在软件工程任务中有着广泛的应用。NMT 对于代码检索的有效性依赖于从源语言中的令牌序列学习到目标语言中的令牌序列的能力。虽然 NMT 在伪代码到代码的转换中表现良好，但是在学习如何在新策划的真实世界代码文档/实现数据集中从自然语言查询转换为源代码时，可能会遇到挑战。在这项工作中，我们分析了 NMT 在自然语言到代码的翻译中的性能，新策划的 CAT 基准包括三个 Java 数据集 tlcodeSum，codeSearchNet，Funcom 和一个 Python 数据集 PCSD 的优化版本。我们的评估表明，NMT 的准确度较低，测量晶体 BLEU 和流星指标在这个任务。为了减轻 NMT 在学习源代码复杂表示方面的责任，我们提出了一种基于非终端节点子集的抽象语法树表示(AST)。我们表明，经典的方法 NMT 在学习 ASTTrans 表示明显优于代码令牌，提高了36% 的流星分数。此外，我们利用 ASTTrans 表示来使用 GraphCodeBERT 和 UniXcoder 从最先进的代码搜索过程中进行组合代码搜索过程。我们的学习 ASTTrans 表示的 NMT 模型可以将这些最先进的代码搜索过程的平均倒数排名提高3.08% ，比 CAT 基准提高23.08% 的查询结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+and+Optimizing+the+Effectiveness+of+Neural+Machine+Translation+in+Supporting+Code+Retrieval+Models:+A+Study+on+the+CAT+Benchmark)|0|
|[Dual-Process Graph Neural Network for Diversified Recommendation](https://doi.org/10.1145/3583780.3614853)|Yuanyi Ren, Hang Ni, Yingxue Zhang, Xi Wang, Guojie Song, Dong Li, Jianye Hao|Peking University, Beijing, China; Northwestern Polytechnical University, Xi'an, China; Huawei Noah's Ark Lab, Beijing, China; Huawei Noah's Ark Lab, Markham, Canada|The recommender system is one of the most fundamental information services. A significant effort has been devoted to improving prediction accuracy, inevitably leading to the potential degradation of recommendation diversity. Moreover, individuals have different needs for diversity. To address these problems, diversity-enhanced approaches are proposed to modify the recommender models. However, these methods fail to break free from the relevance-oriented paradigm and are mostly haunted by sharply-declined accuracy and high computational costs. To tackle these challenges, we propose the Dual-Process Graph Neural Network (DPGNN), an efficient diversity-enhanced recommender system, resonating with the dual-process model of human cognition and the arousal theory of human interest. The first stage reduces the risk of suboptimal output during the training procedure, which helps to find a solution outside the relevance-oriented paradigm. Moreover, the second stage utilizes user-specific rating adjustments, boosting the recommendation diversity and accommodating users' distinctive needs with minimum computational costs. Extensive experiments on real-world datasets verify the effectiveness of our method in improving diversity, while maintaining accuracy with low computational costs.|推荐系统是最基本的信息服务之一。为了提高预测的准确性，人们付出了巨大的努力，这不可避免地导致了推荐多样性的潜在退化。此外，个体对多样性有不同的需求。为了解决这些问题，提出了基于多样性增强的方法来修改推荐模型。然而，这些方法未能摆脱以关联为导向的范式，并且大多受到精度急剧下降和计算成本高的困扰。为了应对这些挑战，我们提出了双进程图形神经网络(DPGNN) ，一种有效的多样性增强推荐系统，与人类认知的双进程模型和人类兴趣唤醒理论产生共鸣。第一阶段降低了培训过程中产出不理想的风险，这有助于找到一个以关联为导向的范式之外的解决方案。此外，第二阶段利用用户特定的评分调整，提高推荐的多样性，以最小的计算成本满足用户的特殊需求。在真实世界数据集上的大量实验证明了该方法在提高多样性的同时以较低的计算成本保持准确性方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-Process+Graph+Neural+Network+for+Diversified+Recommendation)|0|
|[Dual-view Contrastive Learning for Auction Recommendation](https://doi.org/10.1145/3583780.3614854)|Dan Ni Ren, Leong Hou U, Wei Liu|University of Macau, Macau SAR, Macao; Sun Yat-sen University, Guangdong, China|Recommendation systems in auction platforms like eBay function differently in comparison to those found in traditional trading platforms. The bidding process involves multiple users competing for a product, with the highest bidder winning the item. As a result, each transaction is independent and characterized by varying transaction prices. The individual nature of auction items means that users cannot purchase identical items, adding to the uniqueness of the purchasing history. Bidders in auction systems rely on their judgment to determine the value of a product, as bidding prices reflect preferences rather than cost-free actions like clicking or collecting. Conventional methodologies that heavily rely on user-item purchase history are ill-suited to handle these unique and extreme product features. Unfortunately, prior recommendation approaches have failed to give due attention to the contextual intricacies of auction items, thereby missing out on the full potential of the invaluable bidding record at hand. This paper introduces a novel contrastive learning approach for auction recommendation, addressing the challenges of data sparsity and uniqueness in auction recommendation. Our method focuses on capturing multiple behavior relations and item context through contrastive pairs construction, contrastive embedding, and contrastive optimization techniques from both user and item perspectives. By overcoming the limitations of previous approaches, our method delivers promising results on two auction datasets, highlighting the practicality and effectiveness of our model.|EBay 等拍卖平台中的推荐系统与传统交易平台中的推荐系统功能不同。投标过程涉及多个用户竞争一个产品，出价最高者中标。因此，每笔交易都是独立的，拥有属性不同的交易价格。拍卖物品的个别性质意味着用户不能购买相同的物品，增加了购买历史的唯一性。拍卖系统中的投标人依靠自己的判断来确定产品的价值，因为投标价格反映的是偏好，而不是点击或收集等无成本的行为。严重依赖于用户商品购买历史的传统方法不适合处理这些独特和极端的产品特性。遗憾的是，先前的推荐办法未能适当注意到拍卖物品的复杂背景，从而错过了手头宝贵的投标记录的全部潜力。针对拍卖推荐中存在的数据稀疏性和唯一性等问题，提出了一种新的拍卖推荐对比学习方法。该方法从用户和项目的角度出发，通过对比对构造、对比嵌入和对比优化技术来捕获多个行为关系和项目上下文。通过克服以往方法的局限性，我们的方法在两个拍卖数据集上提供了有希望的结果，突出了我们的模型的实用性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-view+Contrastive+Learning+for+Auction+Recommendation)|0|
|[GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction](https://doi.org/10.1145/3583780.3614894)|Yucheng Shi, Yushun Dong, Qiaoyu Tan, Jundong Li, Ninghao Liu|University of Virginia, Charlottesville, VA, USA; University of Georgia, Athens, GA, USA; Texas A&M University, College Station, TX, USA|Self-supervised learning with masked autoencoders has recently gained popularity for its ability to produce effective image or textual representations, which can be applied to various downstream tasks without retraining. However, we observe that the current masked autoencoder models lack good generalization ability on graph data. To tackle this issue, we propose a novel graph masked autoencoder framework called GiGaMAE. Different from existing masked autoencoders that learn node presentations by explicitly reconstructing the original graph components (e.g., features or edges), in this paper, we propose to collaboratively reconstruct informative and integrated latent embeddings. By considering embeddings encompassing graph topology and attribute information as reconstruction targets, our model could capture more generalized and comprehensive knowledge. Furthermore, we introduce a mutual information based reconstruction loss that enables the effective reconstruction of multiple targets. This learning objective allows us to differentiate between the exclusive knowledge learned from a single target and common knowledge shared by multiple targets. We evaluate our method on three downstream tasks with seven datasets as benchmarks. Extensive experiments demonstrate the superiority of GiGaMAE against state-of-the-art baselines. We hope our results will shed light on the design of foundation models on graph-structured data. Our code is available at: https://github.com/sycny/GiGaMAE.|掩蔽自动编码器的自监督学习因其能够产生有效的图像或文本表示而得到广泛应用，可以在不需要再培训的情况下应用于各种下游任务。然而，我们观察到目前的掩码自动编码器模型缺乏良好的图形数据泛化能力。为了解决这个问题，我们提出了一种新的图形掩码自动编码框架，称为 GiGaMAE。与现有的隐式自动编码器不同，隐式自动编码器通过显式重构原始的图形组件(如特征或边)来学习节点表示，本文提出了协同重构信息化和集成化的潜在嵌入。该模型以包含图形拓扑和属性信息的嵌入为重构目标，可以获得更广泛、更全面的知识。此外，我们还引入了一种基于互信息的重建损失算法，可以有效地重建多个目标。这种学习目标使我们能够区分从单个目标学习的专有知识和由多个目标共享的共同知识。我们用七个数据集作为基准，在三个下游任务上评估我们的方法。大量的实验证明了 GiGaMAE 相对于最先进的基线的优越性。我们希望我们的研究结果能够对基于图结构数据的基础模型的设计有所帮助。我们的代码可以在以下 https://github.com/sycny/gigamae 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GiGaMAE:+Generalizable+Graph+Masked+Autoencoder+via+Collaborative+Latent+Space+Reconstruction)|0|
|[Joint Rebalancing and Charging for Shared Electric Micromobility Vehicles with Energy-informed Demand](https://doi.org/10.1145/3583780.3614942)|Heng Tan, Yukun Yuan, Shuxin Zhong, Yu Yang|University of Tennessee at Chattanooga, Chattanooga, TN, USA; Rutgers University, New Brunswick, NJ, USA; Lehigh University, Bethlehem, PA, USA|Shared electric micromobility (e.g., shared electric bikes and electric scooters), as an emerging way of urban transportation, has been increasingly popular in recent years. However, managing thousands of micromobility vehicles in a city, such as rebalancing and charging vehicles to meet spatial-temporally varied demand, is challenging. Existing management frameworks generally consider demand as the number of requests without the energy consumption of these requests, which can lead to less effective management. To address this limitation, we design RECOMMEND, a rebalancing and charging framework for shared electric micromobility vehicles with energy-informed demand to improve the system revenue. Specifically, we first re-define the demand from the perspective of energy consumption and predict the future energy-informed demand based on the state-of-the-art spatial-temporal prediction method. Then we fuse the predicted energy-informed demand into different components of a rebalancing and charging framework based on reinforcement learning. We evaluate the RECOMMEND system with 2-month real-world electric micromobility system operation data. Experimental results show that our method can be easily integrated into a general RL framework and outperform state-of-the-art baselines by at least 26.89% in terms of net revenue.|共享电动微型交通(如共享电动自行车和电动滑板车) ，作为一种新兴的城市交通方式，近年来越来越受欢迎。然而，在一个城市管理数以千计的微型移动车辆，如重新平衡和充电车辆，以满足时空不同的需求，是具有挑战性的。现有管理框架一般将需求视为没有这些需求的能源消耗的需求数量，这可能导致管理效率较低。为了解决这一局限性，我们设计了一个再平衡和充电框架 RECOMMEND，用于具有能源信息需求的共享电动微型移动车辆，以提高系统收入。具体来说，我们首先从能源消费的角度重新定义需求，并基于最新的时空预测方法对未来的能源知情需求进行预测。然后，我们将预测的能源需求融入基于强化学习的再平衡和收费框架的不同组成部分。我们使用2个月的实际电子微移动系统运行数据对 RECOMMEND 系统进行了评估。实验结果表明，该方法可以很容易地集成到一个通用的 RL 框架中，并且在净收入方面比最先进的基线至少高出26.89% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Rebalancing+and+Charging+for+Shared+Electric+Micromobility+Vehicles+with+Energy-informed+Demand)|0|
|[Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization](https://doi.org/10.1145/3583780.3614870)|Abhisek Tiwari, Anisha Saha, Sriparna Saha, Pushpak Bhattacharyya, Minakshi Dhar|Indian Institute of Technology, Bombay, Bombay, India; Indian Institute of Technology, Patna, Patna, India; All India Institute of Medical Sciences, Rishikesh, Rishikesh, India|With the advancement of telemedicine, both researchers and medical practitioners are working hand-in-hand to develop various techniques to automate various medical operations, such as diagnosis report generation. In this paper, we first present a multi-modal clinical conversation summary generation task that takes a clinician-patient interaction (both textual and visual information) and generates a succinct synopsis of the conversation. We propose a knowledge-infused, multi-modal, multi-tasking medical domain identification and clinical conversation summary generation (MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and visual features and unify the fused feature vector using a gated mechanism. Furthermore, we developed a multi-modal, multi-intent clinical conversation summarization corpus annotated with intent, symptom, and summary. The extensive set of experiments, both quantitatively and qualitatively, led to the following findings: (a) critical significance of visuals, (b) more precise and medical entity preserving summary with additional knowledge infusion, and (c) a correlation between medical department identification and clinical synopsis generation. Furthermore, the dataset and source code are available at https://github.com/NLP-RL/MM-CliConSummation.|随着远程医疗的发展，研究人员和医务人员正携手合作，开发各种技术，以自动化各种医疗操作，如诊断报告生成。在本文中，我们首先提出了一个多模态的临床会话摘要生成任务，采用临床医生-患者的互动(文本和视觉信息) ，并生成一个简洁的会话概要。我们提出了一个知识注入、多模态、多任务的医学领域识别和临床会话摘要生成(MM-CliConsum)框架。它利用适配器来注入知识和可视化特征，并使用门控机制统一融合特征向量。此外，我们开发了一个多模式，多意图临床会话摘要语料库注释意图，症状和总结。广泛的一系列定量和定性实验导致了以下发现: (a)视觉的关键意义，(b)更精确的医疗实体保存总结与额外的知识输入，以及(c)医疗部门识别和临床概要生成之间的相关性。此外，数据集和源代码也可以在 https://github.com/nlp-rl/mm-cliconsummation 中找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Experience+and+Evidence+are+the+eyes+of+an+excellent+summarizer!+Towards+Knowledge+Infused+Multi-modal+Clinical+Conversation+Summarization)|0|
|[Towards Deeper, Lighter and Interpretable Cross Network for CTR Prediction](https://doi.org/10.1145/3583780.3615089)|Fangye Wang, Hansu Gu, Dongsheng Li, Tun Lu, Peng Zhang, Ning Gu||Click Through Rate (CTR) prediction plays an essential role in recommender systems and online advertising. It is crucial to effectively model feature interactions to improve the prediction performance of CTR models. However, existing methods face three significant challenges. First, while most methods can automatically capture high-order feature interactions, their performance tends to diminish as the order of feature interactions increases. Second, existing methods lack the ability to provide convincing interpretations of the prediction results, especially for high-order feature interactions, which limits the trustworthiness of their predictions. Third, many methods suffer from the presence of redundant parameters, particularly in the embedding layer. This paper proposes a novel method called Gated Deep Cross Network (GDCN) and a Field-level Dimension Optimization (FDO) approach to address these challenges. As the core structure of GDCN, Gated Cross Network (GCN) captures explicit high-order feature interactions and dynamically filters important interactions with an information gate in each order. Additionally, we use the FDO approach to learn condensed dimensions for each field based on their importance. Comprehensive experiments on five datasets demonstrate the effectiveness, superiority and interpretability of GDCN. Moreover, we verify the effectiveness of FDO in learning various dimensions and reducing model parameters. The code is available on https://github.com/anonctr/GDCN.|点击通过率(CTR)预测在推荐系统和在线广告中起着至关重要的作用。有效的特征交互建模对于提高 CTR 模型的预测性能至关重要。然而，现有的方法面临三个重大挑战。首先，虽然大多数方法可以自动捕获高阶特征交互，但是它们的性能往往会随着特征交互次序的增加而下降。其次，现有的方法缺乏对预测结果提供令人信服的解释的能力，特别是对于高阶特征相互作用，这限制了它们的预测的可信度。第三，许多方法都存在冗余参数，特别是在嵌入层。本文提出了一种新的方法，称为门控深交叉网络(GDCN)和场级尺寸优化(FDO)的方法来解决这些挑战。门限交叉网络(GCN)作为 GDCN 的核心结构，捕获显式的高阶特征交互，并动态过滤每个阶段与信息门的重要交互。此外，我们使用 FDO 方法根据每个领域的重要性来学习压缩维度。通过对五个数据集的综合实验，验证了 GDCN 算法的有效性、优越性和可解释性。此外，我们还验证了 FDO 在学习各种维数和降低模型参数方面的有效性。密码可以在 https://github.com/anonctr/gdcn 上找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Deeper,+Lighter+and+Interpretable+Cross+Network+for+CTR+Prediction)|0|
|[AFRF: Angle Feature Retrieval Based Popularity Forecasting](https://doi.org/10.1145/3583780.3614776)|Haoyu Wang, Zongxia Xie, Meiyao Liu, Canhua Guan|Tianjin University, Tianjin, China|Social media popularity forecasting has become a hot research topic in recent years. It is of great significance in assisting public opinion monitoring and advertising placement. Time series prediction is one of the simple and commonly used methods for popularity forecasting, which takes the popularity of the first few time steps in the observed data as inputs. However, the complete popularity trend of each social media is known in the training dataset, while the historical time series information except for the first few time steps is neglected in the existing models. In order to utilize the complete historical information from the observed data, a retrieval method is introduced in this paper. Therefore, how to retrieve similar social media based on the first few steps time series and how to integrate the similar historical information have become two challenges. A two-stage prediction method named Angle Feature Retrieval based Forecasting (AFRF) is proposed in this paper to solve the upper two problems. In the first stage, based on the angle features of series, we retrieve K similar series from the historical posts and concatenate them with the target series as the model's input. In the second stage, an attention mechanism is used to learn the temporal relationships among the series and generate future popularity forecasts. We evaluated the multi-step and single-point forecasting performance of AFRF on three real-world datasets and compared it with state-of-the-art popularity forecasting methods, such as temporal feature-based and cascade-based methods, verifying the effectiveness of AFRF.|社交媒体受欢迎程度预测已成为近年来的研究热点。它对辅助舆论监督和广告投放具有重要意义。时间序列预测是一种简单、常用的流行度预测方法，它以观测数据中前几个时间步长的流行度作为输入。然而，在训练数据集中已经知道每个社会媒体的完全流行趋势，而在现有的模型中，除了前几个时间步骤之外的历史时间序列信息被忽略了。为了充分利用观测数据中的完整历史信息，本文提出了一种检索方法。因此，如何基于前几步时间序列检索相似的社会媒体，如何整合相似的历史信息，已成为两大挑战。针对上述两个问题，提出了一种基于角度特征反演的两阶段预测方法(AFRF)。在第一阶段，根据序列的角度特征，从历史文章中提取出 K 个相似序列，并将它们与目标序列连接起来作为模型的输入。在第二阶段，使用注意机制来学习序列之间的时间关系，并生成未来的流行预测。对 AFRF 在三个实际数据集上的多步预测性能和单点预测性能进行了评估，并与基于时间特征和基于级联的流行性预测方法进行了比较，验证了 AFRF 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AFRF:+Angle+Feature+Retrieval+Based+Popularity+Forecasting)|0|
|[SplitGNN: Spectral Graph Neural Network for Fraud Detection against Heterophily](https://doi.org/10.1145/3583780.3615067)|Bin Wu, Xinyu Yao, Boyan Zhang, KuoMing Chao, Yinsheng Li|University of Roehampton, London, United Kingdom; Fudan University, Shanghai, China|Fraudsters in the real world frequently add more legitimate links while concealing their direct ones with other fraudsters, leading to heterophily in fraud graphs, which is a problem that most GNN-based techniques are not built to solve. Several works have been proposed to tackle the issue from the spatial domain. However, researches on addressing the heterophily problem in the spectral domain are still limited due to a lack of understanding of spectral energy distribution in graphs with heterophily. In this paper, we analyze the spectral distribution with different heterophily degrees and observe that the heterophily of fraud nodes leads to the spectral energy moving from low-frequency to high-frequency. Further, we verify that splitting graphs using heterophilic and homophilic edges can obtain more significant expressions of signals in different frequency bands. The observation drives us to propose the spectral graph neural network, SplitGNN, to capture signals for fraud detection against heterophily. SplitGNN uses an edge classifier to split the original graph and adopts flexible band-pass graph filters to learn representations. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed method. The code and data are available at https://github.com/Split-GNN/SplitGNN.|现实世界中的欺诈者经常添加更多的合法链接，同时隐藏他们与其他欺诈者的直接链接，从而导致欺诈图中的异质性，这是大多数基于 GNN 的技术无法解决的问题。已经提出了几个工作，以解决从空间领域的问题。然而，由于缺乏对具有异质性的图的光谱能量分布的理解，有关谱域异质性问题的研究仍然十分有限。本文分析了欺诈节点不同异质性程度的频谱分布，发现欺诈节点的异质性导致频谱能量由低频向高频移动。进一步，我们验证了使用异质和同质边的分裂图可以在不同的频带获得更有意义的信号表达式。这一观测结果促使我们提出了谱图神经网络 SplitGNN 来捕获信号用于对异质性的欺诈检测。SplitGNN 使用边分类器对原始图进行分割，并采用灵活的带通图滤波器来学习表示。在实际数据集上的大量实验证明了该方法的有效性。代码和数据可在 https://github.com/split-gnn/splitgnn 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SplitGNN:+Spectral+Graph+Neural+Network+for+Fraud+Detection+against+Heterophily)|0|
|[DPGN: Denoising Periodic Graph Network for Life Service Recommendation](https://doi.org/10.1145/3583780.3614850)|Hao Xu, Huixuan Chi, Danyang Liu, Sheng Zhou, Mengdi Zhang|Meituan, Beijing, China; Zhejiang University, Hangzhou, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Different from traditional e-commerce platforms, life service recommender systems provide hundreds of millions of users with daily necessities services such as nearby food ordering. In this scenario, users have instant intentions and living habits, which exhibit a periodic tendency to click or buy products with similar intentions. This can be summarized as the intentional periodicity problem, which was not well-studied in previous works. Existing periodic-related recommenders exploit time-sensitive functions to capture the evolution of user preferences. However, these methods are easily affected by the real noisy signal in life service platforms, wherein the recent noisy signals can mislead the instant intention and living habits modeling. We summarize it as the noise issue. Although there are some denoising recommenders, these methods cannot effectively solve the noise issue for intentional periodicity modeling. To alleviate the issues, we propose a novel Denoising Periodic Graph Network (DPGN) for life service recommendation. First, to alleviate the noisy signals and model the instant intention accurately, we propose (i) temporal pooling (TP) to encode the most representative information shared by recent behaviors; (ii) temporal encoding (TE) to encode the relative time intervals. Second, to capture the user's living habits accurately, we propose the memory mechanism to maintain a series of instant intentions in different time periods. Third, to further capture the intentional periodicity, we propose the temporal graph transformer (TGT) layer to aggregate temporal information. Last, the denoising task is further proposed to alleviate the noisy signals. Extensive experiments on both real-world public and industrial datasets validate the state-of-the-art performance of DPGN. Code is available in https://github.com/ytchx1999/DPGN|与传统的电子商务平台不同，生活服务推荐系统为数亿用户提供日常必需品服务，如附近的食品订购。在这种情况下，用户有即时的意图和生活习惯，这表现出一个周期性的趋势，点击或购买具有相似意图的产品。这可以概括为有意识的周期性问题，在以前的工作中没有得到很好的研究。现有的与周期相关的推荐程序利用时间敏感的功能来捕获用户偏好的演变。然而，这些方法很容易受到生活服务平台中真实噪声信号的影响，其中最近的噪声信号会误导人们的即时意图和生活习惯建模。我们把它归结为噪音问题。虽然有一些去噪建议，但这些方法不能有效地解决有意识的周期性建模的噪声问题。为了解决这些问题，我们提出了一种新的消噪周期图网络(DPGN)用于终身服务推荐。首先，为了减轻噪声信号的影响，准确地模拟瞬时意图，我们提出: (1)时间池(TP)对最近行为共享的最有代表性的信息进行编码; (2)时间编码(TE)对相对时间间隔进行编码。其次，为了准确地捕捉用户的生活习惯，我们提出了在不同时间段保持一系列即时意图的记忆机制。第三，为了进一步捕获有意识的周期性，我们提出了时间图转换(TGT)层来聚集时间信息。最后，进一步提出降噪任务，以减轻噪声信号。在真实世界的公共数据集和工业数据集上的大量实验验证了 DPGN 的最新性能。代码可在 https://github.com/ytchx1999/dpgn 下载|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPGN:+Denoising+Periodic+Graph+Network+for+Life+Service+Recommendation)|0|
|[Identifying Regional Driving Risks via Transductive Cross-City Transfer Learning Under Negative Transfer](https://doi.org/10.1145/3583780.3614924)|Hua Yan, Hao Wang, Desheng Zhang, Yu Yang|Rutgers University, Piscataway, NJ, USA; Lehigh University, Bethlehem, PA, USA|Identifying regional driving risks is important for real-world applications such as driving safety warning applications, public safety management, and insurance company premium pricing. Previous approaches are either based on traffic accident reports or vehicular sensor data. They either fail to identify potential risks, such as near-miss collisions, which would need other important measurements (e.g., hard break, acceleration, etc.), or fail to generalize to cities without vehicular sensor data, severely limiting their practicality. In this work, we address these two challenges and successfully identify regional driving risks in a target city without vehicular sensor data via cross-city transfer learning. Specifically, we design a novel framework RiskTrans by optimizing both the predictor and the relationship between cities to achieve transfer learning. We advance the existing works from two aspects: (i) we achieve it in a transductive manner without accessing labeled data in the target cities; (ii) we identify and address the problem of negative transfer in cross-city transfer learning, a prominent issue that is often (surprisingly) neglected in previous works. Finally, we conduct extensive experiments based on data collected from 175 thousand vehicles in six cities. The results show RiskTrans outperforms baselines by at least 50.2% and reduces negative transfer by 49.4%.|识别区域驾驶风险对于驾驶安全警告应用程序、公共安全管理和保险公司保险费定价等实际应用程序非常重要。以前的方法要么基于交通事故报告，要么基于车辆传感器数据。他们要么不能识别潜在的风险，例如差点撞上，这将需要其他重要的测量(例如，硬碰撞，加速度等) ，或者不能推广到没有车辆传感器数据的城市，严重限制了他们的实用性。在这项工作中，我们解决这两个挑战，并成功地识别区域驾驶风险在目标城市没有车辆传感器数据通过跨城市转移学习。具体来说，我们设计了一个新的框架 RiskTrans，通过优化预测器和城市之间的关系来实现迁移学习。我们从两个方面推进现有的工作: (1)我们实现了转换的方式，而没有访问目标城市的标记数据; (2)我们识别和解决跨城市迁移学习中的负迁移问题，这是一个突出的问题，往往(令人惊讶)被忽视在以前的工作。最后，我们在六个城市17.5万辆汽车的数据基础上进行了广泛的实验。结果显示 RiskTrans 的业绩至少比基线水平高出50.2% ，负转移减少了49.4% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Regional+Driving+Risks+via+Transductive+Cross-City+Transfer+Learning+Under+Negative+Transfer)|0|
|[FARA: Future-aware Ranking Algorithm for Fairness Optimization](https://doi.org/10.1145/3583780.3614877)|Tao Yang, Zhichao Xu, Zhenduo Wang, Qingyao Ai|DCST, Tsinghua University, Quan Cheng Laboratory, Zhongguancun Laboratory, Beijing, China; University of Utah, Salt Lake City, UT, USA|Ranking systems are the key components of modern Information Retrieval (IR) applications, such as search engines and recommender systems. Besides the ranking relevance to users, the exposure fairness to item providers has also been considered an important factor in ranking optimization. Many fair ranking algorithms have been proposed to jointly optimize both ranking relevance and fairness. However, we find that most existing fair ranking methods adopt greedy algorithms that only optimize rankings for the next immediate session or request. As shown in this paper, such a myopic paradigm could limit the upper bound of ranking optimization and lead to suboptimal performance in the long term. To this end, we propose FARA, a novel Future-Aware Ranking Algorithm for ranking relevance and fairness optimization. Instead of greedily optimizing rankings for the next immediate session, FARA plans ahead by jointly optimizing multiple ranklists together and saving them for future sessions. Particularly, FARA first uses the Taylor expansion to investigate how future ranklists will influence the overall fairness of the system. Then, based on the analysis of the Taylor expansion, FARA adopts a two-phase optimization algorithm where we first solve an optimal future exposure planning problem and then construct the optimal ranklists according to the optimal future exposure planning. Theoretically, we show that FARA is optimal for ranking relevance and fairness joint optimization. Empirically, our extensive experiments on three semi-synthesized datasets show that FARA is efficient, effective, and can deliver significantly better ranking performance compared to state-of-the-art fair ranking methods.|排名系统是现代信息检索应用(如搜索引擎和推荐系统)的关键组成部分。除了与用户的排名相关性之外，项目提供者的曝光公平性也被认为是排名优化的一个重要因素。许多公平排序算法被提出来共同优化排序的相关性和公平性。然而，我们发现大多数现有的公平排名方法采用贪婪算法，只优化下一个即时会话或请求的排名。如本文所述，这种短视的范式可能会限制排序优化的上界，并导致长期的次优性能。为此，我们提出了一种新的未来感知排序算法 FARA，用于排序相关性和公平性优化。FARA 没有贪婪地优化下一阶段的排名，而是提前计划，联合优化多个排名，并将它们保存到未来的阶段。特别是，FARA 首先利用泰勒扩展来调查未来的排行榜将如何影响系统的整体公平性。然后，在分析泰勒展开的基础上，采用两阶段优化算法，首先解决未来曝光规划问题，然后根据未来曝光规划的优化结果构造最优排名表。从理论上证明了 FARA 对于排序相关性和公平性联合优化是最优的。经验上，我们在三个半合成数据集上的大量实验表明，FARA 是有效的，有效的，并且能够提供比最先进的公平排序方法更好的排序性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FARA:+Future-aware+Ranking+Algorithm+for+Fairness+Optimization)|0|
|[Co-guided Random Walk for Polarized Communities Search](https://doi.org/10.1145/3583780.3614814)|Fanyi Yang, Huifang Ma, Cairui Yan, Zhixin Li, Liang Chang|NorthWest Normal University, Lanzhou, China; Northwest Normal University, Lanzhou, China; Guangxi Normal University, Guilin, China; Guilin University of Electronic Technology, Guilin, China|Polarized Communities Search (PCS) aims to identify query-dependent communities where positive links predominantly connect nodes within each community, while negative links primarily connect nodes across different communities. Existing solutions primarily focus on modeling network topology, disregarding the crucial factor of node attributes. However, it is non-trivial to incorporate node attributes into PCS. In this paper, we propose a novel method called CO-guided RAndom walk in attributed signed networks (CORA) for PCS. Our approach involves constructing an attribute-based signed network to represent the auxiliary relations between nodes. We introduce a weight assignment mechanism to assess the reliability of edges in the signed network. Then, we design a co-guided random walk scheme that operates on two signed networks to model the connections between network topology and node attributes, thereby enhancing the search outcomes. Finally, we identify polarized communities using the Rayleigh quotient in the signed network. Extensive experiments conducted on three public datasets demonstrate the superior performance of CORA compared to state-of-the-art baselines for polarized communities search.|极化社区搜索(PCS)旨在识别查询依赖的社区，其中正向链接主要连接每个社区内的节点，而负向链接主要连接不同社区的节点。现有的解决方案主要侧重于建模网络拓扑，忽略了节点属性的关键因素。然而，将节点属性合并到 PCS 中是非常重要的。在本文中，我们提出了一种新的方法称为 CO 引导的随机游走在属性签名网络(CORA)的 PCS。我们的方法包括构造一个基于属性的有符号网络来表示节点之间的辅助关系。我们引入了一种权重分配机制来评估有符号网络中边的可靠性。然后，我们设计一个共同引导的随机游走方案，在两个签名网络上操作，建立网络拓扑和节点属性之间的联系模型，从而提高搜索结果。最后，我们利用有符号网络中的瑞利商来识别极化群落。在三个公共数据集上进行的大量实验表明，与最先进的极化社区搜索基线相比，CORA 具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-guided+Random+Walk+for+Polarized+Communities+Search)|0|
|[Federated News Recommendation with Fine-grained Interpolation and Dynamic Clustering](https://doi.org/10.1145/3583780.3614881)|Sanshi Lei Yu, Qi Liu, Fei Wang, Yang Yu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+News+Recommendation+with+Fine-grained+Interpolation+and+Dynamic+Clustering)|0|
|[VILE: Block-Aware Visual Enhanced Document Retrieval](https://doi.org/10.1145/3583780.3615107)|Huaying Yuan, Zhicheng Dou, Yujia Zhou, Yu Guo, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VILE:+Block-Aware+Visual+Enhanced+Document+Retrieval)|0|
|[MemoNet: Memorizing All Cross Features' Representations Efficiently via Multi-Hash Codebook Network for CTR Prediction](https://doi.org/10.1145/3583780.3614963)|Pengtao Zhang, Junlin Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemoNet:+Memorizing+All+Cross+Features'+Representations+Efficiently+via+Multi-Hash+Codebook+Network+for+CTR+Prediction)|0|
|[FATA-Trans: Field And Time-Aware Transformer for Sequential Tabular Data](https://doi.org/10.1145/3583780.3614879)|Dongyu Zhang, Liang Wang, Xin Dai, Shubham Jain, Junpeng Wang, Yujie Fan, ChinChia Michael Yeh, Yan Zheng, Zhongfang Zhuang, Wei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FATA-Trans:+Field+And+Time-Aware+Transformer+for+Sequential+Tabular+Data)|0|
|[Efficient Exact Minimum k-Core Search in Real-World Graphs](https://doi.org/10.1145/3583780.3614861)|Qifan Zhang, Shengxin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Exact+Minimum+k-Core+Search+in+Real-World+Graphs)|0|
|[Decentralized Graph Neural Network for Privacy-Preserving Recommendation](https://doi.org/10.1145/3583780.3614834)|Xiaolin Zheng, Zhongyu Wang, Chaochao Chen, Jiashu Qian, Yao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decentralized+Graph+Neural+Network+for+Privacy-Preserving+Recommendation)|0|
|[FedPSE: Personalized Sparsification with Element-wise Aggregation for Federated Learning](https://doi.org/10.1145/3583780.3614882)|Longfei Zheng, Yingting Liu, Xiaolong Xu, Chaochao Chen, Yuzhou Tang, Lei Wang, Xiaolong Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedPSE:+Personalized+Sparsification+with+Element-wise+Aggregation+for+Federated+Learning)|0|
|[Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems](https://doi.org/10.1145/3583780.3614823)|Guanglin Zhou, Chengkai Huang, Xiaocong Chen, Xiwei Xu, Chen Wang, Liming Zhu, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Counterfactual+Learning+for+Causality-aware+Interpretable+Recommender+Systems)|0|
|[Personalized Location-Preference Learning for Federated Task Assignment in Spatial Crowdsourcing](https://doi.org/10.1145/3583780.3615008)|Xiaolong Zhong, Hao Miao, Dazhuo Qiu, Yan Zhao, Kai Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Location-Preference+Learning+for+Federated+Task+Assignment+in+Spatial+Crowdsourcing)|0|
|[Improving Adversarial Transferability via Frequency-based Stationary Point Search](https://doi.org/10.1145/3583780.3614927)|Zhiyu Zhu, Huaming Chen, Jiayu Zhang, Xinyi Wang, Zhibo Jin, Qinghua Lu, Jun Shen, KimKwang Raymond Choo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Adversarial+Transferability+via+Frequency-based+Stationary+Point+Search)|0|
|[Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in Recommender Systems](https://doi.org/10.1145/3583780.3615165)|Ludovico Boratto, Francesco Fabbri, Gianni Fenu, Mirko Marras, Giacomo Medda||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Graph+Augmentation+for+Consumer+Unfairness+Mitigation+in+Recommender+Systems)|0|
|[Region-Wise Attentive Multi-View Representation Learning For Urban Region Embedding](https://doi.org/10.1145/3583780.3615194)|Weiliang Chan, Qianqian Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Region-Wise+Attentive+Multi-View+Representation+Learning+For+Urban+Region+Embedding)|0|
|['Choose your Data Wisely': Active Learning based Selection with Multi-Objective Optimisation for Mitigating Stereotypes](https://doi.org/10.1145/3583780.3615261)|Manish Chandra, Debasis Ganguly, Tulika Saha, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q='Choose+your+Data+Wisely':+Active+Learning+based+Selection+with+Multi-Objective+Optimisation+for+Mitigating+Stereotypes)|0|
|[MI-DPG: Decomposable Parameter Generation Network Based on Mutual Information for Multi-Scenario Recommendation](https://doi.org/10.1145/3583780.3615223)|Wenzhuo Cheng, Ke Ding, Xin Dong, Yong He, Liang Zhang, Linjian Mo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MI-DPG:+Decomposable+Parameter+Generation+Network+Based+on+Mutual+Information+for+Multi-Scenario+Recommendation)|0|
|[Incorporating Co-purchase Correlation for Next-basket Recommendation](https://doi.org/10.1145/3583780.3615257)|Yu Hao Chou, PuJen Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Co-purchase+Correlation+for+Next-basket+Recommendation)|0|
|[DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations](https://doi.org/10.1145/3583780.3615218)|Wei Dai, Yingmin Su, Xiaofeng Pan, Yufeng Wang, Zhenyu Zhu, Nan Xu, Chengjun Mao, Bo Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPAN:+Dynamic+Preference-based+and+Attribute-aware+Network+for+Relevant+Recommendations)|0|
|[Learning Sparse Lexical Representations Over Specified Vocabularies for Retrieval](https://doi.org/10.1145/3583780.3615207)|Jeffrey M. Dudek, Weize Kong, Cheng Li, Mingyang Zhang, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Sparse+Lexical+Representations+Over+Specified+Vocabularies+for+Retrieval)|0|
|[KGPR: Knowledge Graph Enhanced Passage Ranking](https://doi.org/10.1145/3583780.3615252)|Jinyuan Fang, Zaiqiao Meng, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGPR:+Knowledge+Graph+Enhanced+Passage+Ranking)|0|
|[Multi-step Prompting for Few-shot Emotion-Grounded Conversations](https://doi.org/10.1145/3583780.3615265)|Mauzama Firdaus, Gopendra Vikram Singh, Asif Ekbal, Pushpak Bhattacharyya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-step+Prompting+for+Few-shot+Emotion-Grounded+Conversations)|0|
|[Extracting Methodology Components from AI Research Papers: A Data-driven Factored Sequence Labeling Approach](https://doi.org/10.1145/3583780.3615258)|Madhusudan Ghosh, Debasis Ganguly, Partha Basuchowdhuri, Sudip Kumar Naskar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extracting+Methodology+Components+from+AI+Research+Papers:+A+Data-driven+Factored+Sequence+Labeling+Approach)|0|
|[Lightweight Adaptation of Neural Language Models via Subspace Embedding](https://doi.org/10.1145/3583780.3615269)|Amit Kumar Jaiswal, Haiming Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lightweight+Adaptation+of+Neural+Language+Models+via+Subspace+Embedding)|0|
|[Multi-Granularity Attention Model for Group Recommendation](https://doi.org/10.1145/3583780.3615140)|Jianye Ji, Jiayan Pei, Shaochuan Lin, Taotao Zhou, Hengxu He, Jia Jia, Ning Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granularity+Attention+Model+for+Group+Recommendation)|0|
|[CSPM: A Contrastive Spatiotemporal Preference Model for CTR Prediction in On-Demand Food Delivery Services](https://doi.org/10.1145/3583780.3615239)|Guyu Jiang, Xiaoyun Li, Rongrong Jing, Ruoqi Zhao, Xingliang Ni, Guodong Cao, Ning Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CSPM:+A+Contrastive+Spatiotemporal+Preference+Model+for+CTR+Prediction+in+On-Demand+Food+Delivery+Services)|0|
|[MvFS: Multi-view Feature Selection for Recommender System](https://doi.org/10.1145/3583780.3615243)|Youngjune Lee, Yeongjong Jeong, Keunchan Park, SeongKu Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MvFS:+Multi-view+Feature+Selection+for+Recommender+System)|0|
|[HEPT Attack: Heuristic Perpendicular Trial for Hard-label Attacks under Limited Query Budgets](https://doi.org/10.1145/3583780.3615198)|Qi Li, Xingyu Li, Xiaodong Cui, Keke Tang, Peican Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HEPT+Attack:+Heuristic+Perpendicular+Trial+for+Hard-label+Attacks+under+Limited+Query+Budgets)|0|
|[Retrieval-Based Unsupervised Noisy Label Detection on Text Data](https://doi.org/10.1145/3583780.3615146)|Peiyang Liu, Jinyu Yang, Lin Wang, Sen Wang, Yunlai Hao, Huihui Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Based+Unsupervised+Noisy+Label+Detection+on+Text+Data)|0|
|[Counterfactual Adversarial Learning for Recommendation](https://doi.org/10.1145/3583780.3615152)|Jialin Liu, Zijian Zhang, Xiangyu Zhao, Jun Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Adversarial+Learning+for+Recommendation)|0|
|[Understanding the Multi-vector Dense Retrieval Models](https://doi.org/10.1145/3583780.3615282)|Qi Liu, Jiaxin Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Multi-vector+Dense+Retrieval+Models)|0|
|[Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting](https://doi.org/10.1145/3583780.3615160)|Hangchen Liu, Zheng Dong, Renhe Jiang, Jiewen Deng, Jinliang Deng, Quanjun Chen, Xuan Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Adaptive+Embedding+Makes+Vanilla+Transformer+SOTA+for+Traffic+Forecasting)|0|
|[Personalized Differentially Private Federated Learning without Exposing Privacy Budgets](https://doi.org/10.1145/3583780.3615247)|Junxu Liu, Jian Lou, Li Xiong, Xiaofeng Meng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Differentially+Private+Federated+Learning+without+Exposing+Privacy+Budgets)|0|
|[A Flash Attention Transformer for Multi-Behaviour Recommendation](https://doi.org/10.1145/3583780.3615206)|Tendai Mukande, Esraa Ali, Annalina Caputo, Ruihai Dong, Noel E. O'Connor||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Flash+Attention+Transformer+for+Multi-Behaviour+Recommendation)|0|
|[Differential Privacy in HyperNetworks for Personalized Federated Learning](https://doi.org/10.1145/3583780.3615203)|Vaisnavi Nemala, Phung Lai, NhatHai Phan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Differential+Privacy+in+HyperNetworks+for+Personalized+Federated+Learning)|0|
|[Pre-training with Aspect-Content Text Mutual Prediction for Multi-Aspect Dense Retrieval](https://doi.org/10.1145/3583780.3615157)|Xiaojie Sun, Keping Bi, Jiafeng Guo, Xinyu Ma, Yixing Fan, Hongyu Shan, Qishen Zhang, Zhongyi Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-training+with+Aspect-Content+Text+Mutual+Prediction+for+Multi-Aspect+Dense+Retrieval)|0|
|[Sequential Text-based Knowledge Update with Self-Supervised Learning for Generative Language Models](https://doi.org/10.1145/3583780.3615188)|HaoRu Sung, YingJhe Tang, YuChung Cheng, PaiLin Chen, TsaiYen Li, HenHsen Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential+Text-based+Knowledge+Update+with+Self-Supervised+Learning+for+Generative+Language+Models)|0|
|[RecRec: Algorithmic Recourse for Recommender Systems](https://doi.org/10.1145/3583780.3615181)|Sahil Verma, Ashudeep Singh, Varich Boonsanong, John P. Dickerson, Chirag Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecRec:+Algorithmic+Recourse+for+Recommender+Systems)|0|
|[Network Embedding with Adaptive Multi-hop Contrast](https://doi.org/10.1145/3583780.3615179)|Chenhao Wang, Yong Liu, Yan Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Network+Embedding+with+Adaptive+Multi-hop+Contrast)|0|
|[A Joint Training-Calibration Framework for Test-Time Personalization with Label Shift in Federated Learning](https://doi.org/10.1145/3583780.3615173)|Jian Xu, ShaoLun Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Joint+Training-Calibration+Framework+for+Test-Time+Personalization+with+Label+Shift+in+Federated+Learning)|0|
|[Geometry Interaction Augmented Graph Collaborative Filtering](https://doi.org/10.1145/3583780.3615204)|Jie Xu, Chaozhuo Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometry+Interaction+Augmented+Graph+Collaborative+Filtering)|0|
|[Graph-based Alignment and Uniformity for Recommendation](https://doi.org/10.1145/3583780.3615185)|Liangwei Yang, Zhiwei Liu, Chen Wang, Mingdai Yang, Xiaolong Liu, Jing Ma, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-based+Alignment+and+Uniformity+for+Recommendation)|0|
|[Predicting Interaction Quality of Conversational Assistants With Spoken Language Understanding Model Confidences](https://doi.org/10.1145/3583780.3615493)|Yue Gao, Enrico Piovano, Tamer Soliman, Monir Moniruzzaman, Anoop Kumar, Melanie Bradford, Subhrangshu Nandi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Interaction+Quality+of+Conversational+Assistants+With+Spoken+Language+Understanding+Model+Confidences)|0|
|[pADR: Towards Personalized Adverse Drug Reaction Prediction by Modeling Multi-sourced Data](https://doi.org/10.1145/3583780.3615490)|Junyu Luo, Cheng Qian, Xiaochen Wang, Lucas Glass, Fenglong Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=pADR:+Towards+Personalized+Adverse+Drug+Reaction+Prediction+by+Modeling+Multi-sourced+Data)|0|
|[Exploiting Sequential Music Preferences via Optimisation-Based Sequencing](https://doi.org/10.1145/3583780.3615476)|Dmitrii Moor, Yi Yuan, Rishabh Mehrotra, Zhenwen Dai, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Sequential+Music+Preferences+via+Optimisation-Based+Sequencing)|0|
|[Deep Query Rewriting For Geocoding](https://doi.org/10.1145/3583780.3615466)|Pravakar Roy, Chirag Sharma, Chao Gao, Kumarswamy Valegerepura||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Query+Rewriting+For+Geocoding)|0|
|[An Efficient Content-based Time Series Retrieval System](https://doi.org/10.1145/3583780.3614655)|ChinChia Michael Yeh, Huiyuan Chen, Xin Dai, Yan Zheng, Junpeng Wang, Vivian Lai, Yujie Fan, Audrey Der, Zhongfang Zhuang, Liang Wang, Wei Zhang, Jeff M. Phillips||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Content-based+Time+Series+Retrieval+System)|0|
|[Multi-gate Mixture-of-Contrastive-Experts with Graph-based Gating Mechanism for TV Recommendation](https://doi.org/10.1145/3583780.3615488)|Cong Zhang, Dongyang Liu, Lin Zuo, Junlan Feng, Chao Deng, Jian Sun, Haitao Zeng, Yaohong Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-gate+Mixture-of-Contrastive-Experts+with+Graph-based+Gating+Mechanism+for+TV+Recommendation)|0|
|[Popularity-aware Distributionally Robust Optimization for Recommendation System](https://doi.org/10.1145/3583780.3615492)|Jujia Zhao, Wenjie Wang, Xinyu Lin, Leigang Qu, Jizhi Zhang, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Popularity-aware+Distributionally+Robust+Optimization+for+Recommendation+System)|0|
|[DeepTagger: Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries](https://doi.org/10.1145/3583780.3615467)|Simiao Zuo, Pengfei Tang, Xinyu Hu, Qiang Lou, Jian Jiao, Denis Charles||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeepTagger:+Knowledge+Enhanced+Named+Entity+Recognition+for+Web-Based+Ads+Queries)|0|
|[A Data-Driven Index Recommendation System for Slow Queries](https://doi.org/10.1145/3583780.3614731)|Gan Peng, Peng Cai, Kaikai Ye, Kai Li, Jinlong Cai, Yufeng Shen, Han Su||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Data-Driven+Index+Recommendation+System+for+Slow+Queries)|0|
|[IMinimize: A System for Negative Influence Minimization via Vertex Blocking](https://doi.org/10.1145/3583780.3614743)|Siyi Teng, Jiadong Xie, Mingkai Zhang, Kai Wang, Fan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IMinimize:+A+System+for+Negative+Influence+Minimization+via+Vertex+Blocking)|0|
|[Towards Improving Accuracy and Computation Cost Optimization of Recommendation Systems](https://doi.org/10.1145/3583780.3616006)|Abdelghani Azri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Improving+Accuracy+and+Computation+Cost+Optimization+of+Recommendation+Systems)|0|
|[Explaining Learning to Rank Methods to Improve Them](https://doi.org/10.1145/3583780.3616002)|Alberto Veneri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explaining+Learning+to+Rank+Methods+to+Improve+Them)|0|
|[Data Augmentation for Conversational AI](https://doi.org/10.1145/3583780.3615291)|Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Augmentation+for+Conversational+AI)|0|
|[Tutorial: Data Denoising Metrics in Recommender Systems](https://doi.org/10.1145/3583780.3615297)|Pengfei Wang, Chenliang Li, Lixin Zou, Zhichao Feng, Kaiyuan Li, Xiaochen Li, Xialong Liu, Shangguang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tutorial:+Data+Denoising+Metrics+in+Recommender+Systems)|0|
|[Reasoning beyond Triples: Recent Advances in Knowledge Graph Embeddings](https://doi.org/10.1145/3583780.3615294)|Bo Xiong, Mojtaba Nayyeri, Daniel Daza, Michael Cochez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reasoning+beyond+Triples:+Recent+Advances+in+Knowledge+Graph+Embeddings)|0|
|[Comparative Analysis of Open Source and Commercial Embedding Models for Question Answering](https://doi.org/10.1145/3583780.3615994)|Georgios Balikas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comparative+Analysis+of+Open+Source+and+Commercial+Embedding+Models+for+Question+Answering)|0|
|[Practical Lessons Learned From Detecting, Preventing and Mitigating Harmful Experiences on Facebook](https://doi.org/10.1145/3583780.3615511)|Prathyusha Senthil Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Lessons+Learned+From+Detecting,+Preventing+and+Mitigating+Harmful+Experiences+on+Facebook)|0|
|[A Test Collection of Synthetic Documents for Training Rankers: ChatGPT vs. Human Experts](https://doi.org/10.1145/3583780.3615111)|Arian Askari, Mohammad Aliannejadi, Evangelos Kanoulas, Suzan Verberne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Test+Collection+of+Synthetic+Documents+for+Training+Rankers:+ChatGPT+vs.+Human+Experts)|0|
|[Anserini Gets Dense Retrieval: Integration of Lucene's HNSW Indexes](https://doi.org/10.1145/3583780.3615112)|Xueguang Ma, Tommaso Teofili, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anserini+Gets+Dense+Retrieval:+Integration+of+Lucene's+HNSW+Indexes)|0|
|[ITA-ELECTION-2022: A Multi-Platform Dataset of Social Media Conversations Around the 2022 Italian General Election](https://doi.org/10.1145/3583780.3615121)|Francesco Pierri, Geng Liu, Stefano Ceri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ITA-ELECTION-2022:+A+Multi-Platform+Dataset+of+Social+Media+Conversations+Around+the+2022+Italian+General+Election)|0|
|[Explore Epistemic Uncertainty in Domain Adaptive Semantic Segmentation](https://doi.org/10.1145/3583780.3614872)|Kai Yao, Zixian Su, Xi Yang, Jie Sun, Kaizhu Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explore+Epistemic+Uncertainty+in+Domain+Adaptive+Semantic+Segmentation)|0|
|[Temporal Convolutional Explorer Helps Understand 1D-CNN's Learning Behavior in Time Series Classification from Frequency Domain](https://doi.org/10.1145/3583780.3615076)|Junru Zhang, Lang Feng, Yang He, Yuhan Wu, Yabo Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Convolutional+Explorer+Helps+Understand+1D-CNN's+Learning+Behavior+in+Time+Series+Classification+from+Frequency+Domain)|0|
|[PS-SA: An Efficient Self-Attention via Progressive Sampling for User Behavior Sequence Modeling](https://doi.org/10.1145/3583780.3615495)|Jiacen Hu, Zhangming Chan, Yu Zhang, Shuguang Han, Siyuan Lou, Baolin Liu, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PS-SA:+An+Efficient+Self-Attention+via+Progressive+Sampling+for+User+Behavior+Sequence+Modeling)|0|
|[Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constraint](https://doi.org/10.1145/3583780.3614839)|Harshita Chopra, Atanu R. Sinha, Sunav Choudhary, Ryan A. Rossi, Paavan Kumar Indela, Veda Pranav Parwatala, Srinjayee Paul, Aurghya Maiti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Delivery+Optimized+Discovery+in+Behavioral+User+Segmentation+under+Budget+Constraint)|0|
|[Understanding User Immersion in Online Short Video Interaction](https://doi.org/10.1145/3583780.3615099)|Zhiyu He, Shaorun Zhang, Peijie Sun, Jiayu Li, Xiaohui Xie, Min Zhang, Yiqun Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+User+Immersion+in+Online+Short+Video+Interaction)|0|
|[Tight-Sketch: A High-Performance Sketch for Heavy Item-Oriented Data Stream Mining with Limited Memory Size](https://doi.org/10.1145/3583780.3615080)|Weihe Li, Paul Patras||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tight-Sketch:+A+High-Performance+Sketch+for+Heavy+Item-Oriented+Data+Stream+Mining+with+Limited+Memory+Size)|0|
|[printf: Preference Modeling Based on User Reviews with Item Images and Textual Information via Graph Learning](https://doi.org/10.1145/3583780.3615012)|HaoLun Lin, JyunYu Jiang, MingHao Juan, PuJen Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=printf:+Preference+Modeling+Based+on+User+Reviews+with+Item+Images+and+Textual+Information+via+Graph+Learning)|0|
|[The Role of Unattributed Behavior Logs in Predictive User Segmentation](https://doi.org/10.1145/3583780.3615078)|Atanu R. Sinha, Harshita Chopra, Aurghya Maiti, Atishay Ganesh, Sarthak Kapoor, Saili Myana, Saurabh Mahapatra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Role+of+Unattributed+Behavior+Logs+in+Predictive+User+Segmentation)|0|
|[Treatment Effect Estimation across Domains](https://doi.org/10.1145/3583780.3615096)|YiXuan Sun, YaLin Zhang, Wei Wang, Longfei Li, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Treatment+Effect+Estimation+across+Domains)|0|
|[CLOCK: Online Temporal Hierarchical Framework for Multi-scale Multi-granularity Forecasting of User Impression](https://doi.org/10.1145/3583780.3614810)|Xiaoyu Wang, Yonghui Guo, Xiaoyang Ma, Dongbo Huang, Lan Xu, Haisheng Tan, Hao Zhou, XiangYang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLOCK:+Online+Temporal+Hierarchical+Framework+for+Multi-scale+Multi-granularity+Forecasting+of+User+Impression)|0|
|[Optimizing Upstream Representations for Out-of-Domain Detection with Supervised Contrastive Learning](https://doi.org/10.1145/3583780.3615001)|Bo Wang, Tsunenori Mine||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Upstream+Representations+for+Out-of-Domain+Detection+with+Supervised+Contrastive+Learning)|0|
|[Dual Intents Graph Modeling for User-centric Group Discovery](https://doi.org/10.1145/3583780.3614855)|Xixi Wu, Yun Xiong, Yao Zhang, Yizhu Jiao, Jiawei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Intents+Graph+Modeling+for+User-centric+Group+Discovery)|0|
|[DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction](https://doi.org/10.1145/3583780.3614851)|Chengqing Yu, Fei Wang, Zezhi Shao, Tao Sun, Lin Wu, Yongjun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DSformer:+A+Double+Sampling+Transformer+for+Multivariate+Time+Series+Long-term+Prediction)|0|
|[Manipulating Out-Domain Uncertainty Estimation in Deep Neural Networks via Targeted Clean-Label Poisoning](https://doi.org/10.1145/3583780.3614957)|Huimin Zeng, Zhenrui Yue, Yang Zhang, Lanyu Shang, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Manipulating+Out-Domain+Uncertainty+Estimation+in+Deep+Neural+Networks+via+Targeted+Clean-Label+Poisoning)|0|
|[All about Sample-Size Calculations for A/B Testing: Novel Extensions & Practical Guide](https://doi.org/10.1145/3583780.3614779)|Jing Zhou, Jiannan Lu, Anas Shallah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=All+about+Sample-Size+Calculations+for+A/B+Testing:+Novel+Extensions+&+Practical+Guide)|0|
|[Enhancing Information Diffusion Prediction with Self-Supervised Disentangled User and Cascade Representations](https://doi.org/10.1145/3583780.3615230)|Zhangtao Cheng, Wenxue Ye, Leyuan Liu, Wenxin Tai, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Information+Diffusion+Prediction+with+Self-Supervised+Disentangled+User+and+Cascade+Representations)|0|
|[Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulators to Enhance Dialogue System](https://doi.org/10.1145/3583780.3615220)|Zhiyuan Hu, Yue Feng, Anh Tuan Luu, Bryan Hooi, Aldo Lipani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Potential+of+User+Feedback:+Leveraging+Large+Language+Model+as+User+Simulators+to+Enhance+Dialogue+System)|0|
|[Training Heterogeneous Graph Neural Networks using Bandit Sampling](https://doi.org/10.1145/3583780.3615276)|TaYang Wang, Rajgopal Kannan, Viktor K. Prasanna||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Training+Heterogeneous+Graph+Neural+Networks+using+Bandit+Sampling)|0|
|[Robust User Behavioral Sequence Representation via Multi-scale Stochastic Distribution Prediction](https://doi.org/10.1145/3583780.3614714)|Chilin Fu, Weichang Wu, Xiaolu Zhang, Jun Hu, Jing Wang, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+User+Behavioral+Sequence+Representation+via+Multi-scale+Stochastic+Distribution+Prediction)|0|
|[Addressing Selection Bias in Computerized Adaptive Testing: A User-Wise Aggregate Influence Function Approach](https://doi.org/10.1145/3583780.3615455)|Soonwoo Kwon, Sojung Kim, Seunghyun Lee, JinYoung Kim, Suyeong An, Kyuseok Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Selection+Bias+in+Computerized+Adaptive+Testing:+A+User-Wise+Aggregate+Influence+Function+Approach)|0|
|[The Price is Right: Removing A/B Test Bias in a Marketplace of Expirable Goods](https://doi.org/10.1145/3583780.3615502)|Thu Le, Alex Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Price+is+Right:+Removing+A/B+Test+Bias+in+a+Marketplace+of+Expirable+Goods)|0|
|[Optimal Real-Time Bidding Strategy for Position Auctions in Online Advertising](https://doi.org/10.1145/3583780.3614727)|Weitong Ou, Bo Chen, Weiwen Liu, Xinyi Dai, Weinan Zhang, Wei Xia, Xuan Li, Ruiming Tang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Real-Time+Bidding+Strategy+for+Position+Auctions+in+Online+Advertising)|0|
|[STREAMER 3.0: Towards Online Monitoring and Distributed Learning](https://doi.org/10.1145/3583780.3614755)|Baudouin Naline, Sandra GarciaRodriguez, Karine Zeitouni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STREAMER+3.0:+Towards+Online+Monitoring+and+Distributed+Learning)|0|
|[Proactive Streaming Analytics at Scale: A Journey from the State-of-the-art to a Production Platform](https://doi.org/10.1145/3583780.3615293)|Nikos Giatrakos, Elias Alevizos, Antonios Deligiannakis, Ralf Klinkenberg, Alexander Artikis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proactive+Streaming+Analytics+at+Scale:+A+Journey+from+the+State-of-the-art+to+a+Production+Platform)|0|
|[Generalization Bound for Estimating Causal Effects from Observational Network Data](https://doi.org/10.1145/3583780.3614892)|Ruichu Cai, Zeqin Yang, Weilin Chen, Yuguang Yan, Zhifeng Hao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalization+Bound+for+Estimating+Causal+Effects+from+Observational+Network+Data)|0|
|[Beyond Trading Data: The Hidden Influence of Public Awareness and Interest on Cryptocurrency Volatility](https://doi.org/10.1145/3583780.3614790)|Zeyd Boukhers, Azeddine Bouabdallah, Cong Yang, Jan Jürjens||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Trading+Data:+The+Hidden+Influence+of+Public+Awareness+and+Interest+on+Cryptocurrency+Volatility)|0|
|[Causality and Independence Enhancement for Biased Node Classification](https://doi.org/10.1145/3583780.3614804)|Guoxin Chen, Yongqing Wang, Fangda Guo, Qinglang Guo, Jiangli Shao, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality+and+Independence+Enhancement+for+Biased+Node+Classification)|0|
|[Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer](https://doi.org/10.1145/3583780.3614946)|Liyue Chen, Linian Wang, Jinyu Xu, Shuai Chen, Weiqiang Wang, Wenbiao Zhao, Qiyu Li, Leye Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-inspired+Subdomain+Adaptation+for+Cross-Domain+Knowledge+Transfer)|0|
|[Rebalancing Social Feed to Minimize Polarization and Disagreement](https://doi.org/10.1145/3583780.3615025)|Federico Cinus, Aristides Gionis, Francesco Bonchi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rebalancing+Social+Feed+to+Minimize+Polarization+and+Disagreement)|0|
|[AI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models vs. Human Answers in Controversial Topics](https://doi.org/10.1145/3583780.3614777)|Vahid Ghafouri, Vibhor Agarwal, Yong Zhang, Nishanth Sastry, Jose M. Such, Guillermo SuarezTangil||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+in+the+Gray:+Exploring+Moderation+Policies+in+Dialogic+Large+Language+Models+vs.+Human+Answers+in+Controversial+Topics)|0|
|[Safe-NORA: Safe Reinforcement Learning-based Mobile Network Resource Allocation for Diverse User Demands](https://doi.org/10.1145/3583780.3615043)|Wenzhen Huang, Tong Li, Yuting Cao, Zhe Lyu, Yanping Liang, Li Yu, Depeng Jin, Junge Zhang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Safe-NORA:+Safe+Reinforcement+Learning-based+Mobile+Network+Resource+Allocation+for+Diverse+User+Demands)|0|
|[Deep Variational Bayesian Modeling of Haze Degradation Process](https://doi.org/10.1145/3583780.3614838)|Eun Woo Im, Junsung Shin, Sungyong Baik, Tae Hyun Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Variational+Bayesian+Modeling+of+Haze+Degradation+Process)|0|
|[Diffusion Variational Autoencoder for Tackling Stochasticity in Multi-Step Regression Stock Price Prediction](https://doi.org/10.1145/3583780.3614844)|Kelvin J. L. Koa, Yunshan Ma, Ritchie Ng, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion+Variational+Autoencoder+for+Tackling+Stochasticity+in+Multi-Step+Regression+Stock+Price+Prediction)|0|
|[Non-Compliant Bandits](https://doi.org/10.1145/3583780.3614990)|Branislav Kveton, Yi Liu, Johan Matteo Kruijssen, Yisu Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-Compliant+Bandits)|0|
|[ST-MoE: Spatio-Temporal Mixture-of-Experts for Debiasing in Traffic Prediction](https://doi.org/10.1145/3583780.3615068)|Shuhao Li, Yue Cui, Yan Zhao, Weidong Yang, Ruiyuan Zhang, Xiaofang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ST-MoE:+Spatio-Temporal+Mixture-of-Experts+for+Debiasing+in+Traffic+Prediction)|0|
|[UniTE: A Unified Treatment Effect Estimation Method for One-sided and Two-sided Marketing](https://doi.org/10.1145/3583780.3615100)|Runshi Liu, Zhipeng Hou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniTE:+A+Unified+Treatment+Effect+Estimation+Method+for+One-sided+and+Two-sided+Marketing)|0|
|[Online Efficient Secure Logistic Regression based on Function Secret Sharing](https://doi.org/10.1145/3583780.3614998)|Jing Liu, Jamie Cui, Cen Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Efficient+Secure+Logistic+Regression+based+on+Function+Secret+Sharing)|0|
|[Khronos: A Real-Time Indexing Framework for Time Series Databases on Large-Scale Performance Monitoring Systems](https://doi.org/10.1145/3583780.3614944)|Xinyu Liu, Zijing Wei, Wenqing Yu, Shaozhi Liu, Gang Wang, Xiaoguang Liu, Yusen Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Khronos:+A+Real-Time+Indexing+Framework+for+Time+Series+Databases+on+Large-Scale+Performance+Monitoring+Systems)|0|
|[Exploring Low-Dimensional Manifolds of Deep Neural Network Parameters for Improved Model Optimization](https://doi.org/10.1145/3583780.3614873)|Ke Lu, Xiaotong He, Ze Qin, Xinyao Li, Zhekai Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Low-Dimensional+Manifolds+of+Deep+Neural+Network+Parameters+for+Improved+Model+Optimization)|0|
|[Integrating Priors into Domain Adaptation Based on Evidence Theory](https://doi.org/10.1145/3583780.3614935)|Ying Lv, Jianpeng Ma, Yiqiu Zhang, Gang Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Priors+into+Domain+Adaptation+Based+on+Evidence+Theory)|0|
|[A Principled Decomposition of Pointwise Mutual Information for Intention Template Discovery](https://doi.org/10.1145/3583780.3614767)|Denghao Ma, Kevin ChenChuan Chang, Yueguo Chen, Xueqiang Lv, Liang Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Principled+Decomposition+of+Pointwise+Mutual+Information+for+Intention+Template+Discovery)|0|
|[Good Intentions: Adaptive Parameter Management via Intent Signaling](https://doi.org/10.1145/3583780.3614895)|Alexander RenzWieland, Andreas Kieslinger, Robert Gericke, Rainer Gemulla, Zoi Kaoudi, Volker Markl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Good+Intentions:+Adaptive+Parameter+Management+via+Intent+Signaling)|0|
|[Automatic and Precise Data Validation for Machine Learning](https://doi.org/10.1145/3583780.3614786)|Shreya Shankar, Labib Fawaz, Karl Gyllstrom, Aditya G. Parameswaran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+and+Precise+Data+Validation+for+Machine+Learning)|0|
|[TOAK: A Topology-oriented Attack Strategy for Degrading User Identity Linkage in Cross-network Learning](https://doi.org/10.1145/3583780.3615084)|Jiangli Shao, Yongqing Wang, Fangda Guo, Boshen Shi, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TOAK:+A+Topology-oriented+Attack+Strategy+for+Degrading+User+Identity+Linkage+in+Cross-network+Learning)|0|
|[Improving Graph Domain Adaptation with Network Hierarchy](https://doi.org/10.1145/3583780.3614928)|Boshen Shi, Yongqing Wang, Fangda Guo, Jiangli Shao, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Graph+Domain+Adaptation+with+Network+Hierarchy)|0|
|[EmFore: Online Learning of Email Folder Classification Rules](https://doi.org/10.1145/3583780.3614863)|Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Gust Verbruggen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EmFore:+Online+Learning+of+Email+Folder+Classification+Rules)|0|
|[SAND: Semantic Annotation of Numeric Data in Web Tables](https://doi.org/10.1145/3583780.3615046)|Yuchen Su, Davood Rafiei, Behrad Khorram Nazari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAND:+Semantic+Annotation+of+Numeric+Data+in+Web+Tables)|0|
|[Graph Inference via the Energy-efficient Dynamic Precision Matrix Estimation with One-bit Data](https://doi.org/10.1145/3583780.3614898)|Xiao Tan, Yangyang Shen, Meng Wang, Beilun Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Inference+via+the+Energy-efficient+Dynamic+Precision+Matrix+Estimation+with+One-bit+Data)|0|
|[Multi-Representation Variational Autoencoder via Iterative Latent Attention and Implicit Differentiation](https://doi.org/10.1145/3583780.3614980)|NhuThuat Tran, Hady W. Lauw||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Representation+Variational+Autoencoder+via+Iterative+Latent+Attention+and+Implicit+Differentiation)|0|
|[Citation Intent Classification and Its Supporting Evidence Extraction for Citation Graph Construction](https://doi.org/10.1145/3583780.3614808)|HongJin Tsai, AnZi Yen, HenHsen Huang, HsinHsi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Citation+Intent+Classification+and+Its+Supporting+Evidence+Extraction+for+Citation+Graph+Construction)|0|
|[FAMC-Net: Frequency Domain Parity Correction Attention and Multi-Scale Dilated Convolution for Time Series Forecasting](https://doi.org/10.1145/3583780.3614876)|Min Wang, Hua Wang, Fan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FAMC-Net:+Frequency+Domain+Parity+Correction+Attention+and+Multi-Scale+Dilated+Convolution+for+Time+Series+Forecasting)|0|
|[MultiPLe: Multilingual Prompt Learning for Relieving Semantic Confusions in Few-shot Event Detection](https://doi.org/10.1145/3583780.3614984)|Siyuan Wang, Jianming Zheng, Wanyu Chen, Fei Cai, Xueshan Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiPLe:+Multilingual+Prompt+Learning+for+Relieving+Semantic+Confusions+in+Few-shot+Event+Detection)|0|
|[Understanding and Modeling Collision Avoidance Behavior for Realistic Crowd Simulation](https://doi.org/10.1145/3583780.3615098)|Zihan Yu, Guozhen Zhang, Yong Li, Depeng Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+and+Modeling+Collision+Avoidance+Behavior+for+Realistic+Crowd+Simulation)|0|
|[iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and Re-occurrence Preservation](https://doi.org/10.1145/3583780.3614926)|Siwei Zhang, Yun Xiong, Yao Zhang, Xixi Wu, Yiheng Sun, Jiawei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iLoRE:+Dynamic+Graph+Representation+with+Instant+Long-term+Modeling+and+Re-occurrence+Preservation)|0|
|[Task Relation Distillation and Prototypical Pseudo Label for Incremental Named Entity Recognition](https://doi.org/10.1145/3583780.3615075)|Duzhen Zhang, Hongliu Li, Wei Cong, Rongtao Xu, Jiahua Dong, Xiuyi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task+Relation+Distillation+and+Prototypical+Pseudo+Label+for+Incremental+Named+Entity+Recognition)|0|
|[Communication-Efficient Decentralized Online Continuous DR-Submodular Maximization](https://doi.org/10.1145/3583780.3614817)|Qixin Zhang, Zengde Deng, Xiangru Jian, Zaiyi Chen, Haoyuan Hu, Yu Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Communication-Efficient+Decentralized+Online+Continuous+DR-Submodular+Maximization)|0|
|[HTMapper: Bidirectional Head-Tail Mapping for Nested Named Entity Recognition](https://doi.org/10.1145/3583780.3614919)|Jin Zhao, Zhixu Li, Yanghua Xiao, Jiaqing Liang, Jingping Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HTMapper:+Bidirectional+Head-Tail+Mapping+for+Nested+Named+Entity+Recognition)|0|
|[GCformer: An Efficient Solution for Accurate and Scalable Long-Term Multivariate Time Series Forecasting](https://doi.org/10.1145/3583780.3615136)|Yanjun Zhao, Ziqing Ma, Tian Zhou, Mengni Ye, Liang Sun, Yi Qian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GCformer:+An+Efficient+Solution+for+Accurate+and+Scalable+Long-Term+Multivariate+Time+Series+Forecasting)|0|
|[DynED: Dynamic Ensemble Diversification in Data Stream Classification](https://doi.org/10.1145/3583780.3615266)|Soheil Abadifard, Sepehr Bakhshi, Sanaz Gheibuni, Fazli Can||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DynED:+Dynamic+Ensemble+Diversification+in+Data+Stream+Classification)|0|
|[HOVER: Homophilic Oversampling via Edge Removal for Class-Imbalanced Bot Detection on Graphs](https://doi.org/10.1145/3583780.3615264)|Bradley Ashmore, Lingwei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HOVER:+Homophilic+Oversampling+via+Edge+Removal+for+Class-Imbalanced+Bot+Detection+on+Graphs)|0|
|[Accelerating Concept Learning via Sampling](https://doi.org/10.1145/3583780.3615158)|Alkid Baci, Stefan Heindorf||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+Concept+Learning+via+Sampling)|0|
|[Unsupervised Anomaly Detection & Diagnosis: A Stein Variational Gradient Descent Approach](https://doi.org/10.1145/3583780.3615167)|Zhichao Chen, Leilei Ding, Jianmin Huang, Zhixuan Chu, Qingyang Dai, Hao Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Anomaly+Detection+&+Diagnosis:+A+Stein+Variational+Gradient+Descent+Approach)|0|
|[Segment Augmentation and Prediction Consistency Neural Network for Multi-label Unknown Intent Detection](https://doi.org/10.1145/3583780.3615163)|Miaoxin Chen, Cao Liu, Boqi Dai, HaiTao Zheng, Ting Song, Jiansong Chen, Guanglu Wan, Rui Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Segment+Augmentation+and+Prediction+Consistency+Neural+Network+for+Multi-label+Unknown+Intent+Detection)|0|
|[Assessing Student Performance with Multi-granularity Attention from Online Classroom Dialogue](https://doi.org/10.1145/3583780.3615143)|Jiahao Chen, Zitao Liu, Shuyan Huang, Yaying Huang, Xiangyu Zhao, Boyu Gao, Weiqi Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Student+Performance+with+Multi-granularity+Attention+from+Online+Classroom+Dialogue)|0|
|[Learning Invariant Representations for New Product Sales Forecasting via Multi-Granularity Adversarial Learning](https://doi.org/10.1145/3583780.3615219)|Zhenzhen Chu, Chengyu Wang, Cen Chen, Dawei Cheng, Yuqi Liang, Weining Qian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Invariant+Representations+for+New+Product+Sales+Forecasting+via+Multi-Granularity+Adversarial+Learning)|0|
|[OnlineAutoClust: A Framework for Online Automated Clustering](https://doi.org/10.1145/3583780.3615148)|Radwa El Shawi, Dmitri Rozgonjuk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OnlineAutoClust:+A+Framework+for+Online+Automated+Clustering)|0|
|[Synergistic Disease Similarity Measurement via Unifying Hierarchical Relation Perception and Association Capturing](https://doi.org/10.1145/3583780.3615274)|Zihao Gao, Huifang Ma, Yike Wang, Zhixin Li, Liang Chang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Synergistic+Disease+Similarity+Measurement+via+Unifying+Hierarchical+Relation+Perception+and+Association+Capturing)|0|
|[Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value Extraction](https://doi.org/10.1145/3583780.3615142)|Jiaying Gong, WeiTe Chen, Hoda Eldardiry||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-Enhanced+Multi-Label+Few-Shot+Product+Attribute-Value+Extraction)|0|
|[Perturbation-Based Two-Stage Multi-Domain Active Learning](https://doi.org/10.1145/3583780.3615222)|Rui He, Zeyu Dai, Shan He, Ke Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Perturbation-Based+Two-Stage+Multi-Domain+Active+Learning)|0|
|[KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks](https://doi.org/10.1145/3583780.3615241)|Nicolas Heist, Sven Hertling, Heiko Paulheim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGrEaT:+A+Framework+to+Evaluate+Knowledge+Graphs+via+Downstream+Tasks)|0|
|[Forgetting-aware Linear Bias for Attentive Knowledge Tracing](https://doi.org/10.1145/3583780.3615191)|Yoonjin Im, Eunseong Choi, Heejin Kook, Jongwuk Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forgetting-aware+Linear+Bias+for+Attentive+Knowledge+Tracing)|0|
|[Exploring Cohesive Subgraphs in Hypergraphs: The (k, g)-core Approach](https://doi.org/10.1145/3583780.3615275)|Dahee Kim, Junghoon Kim, Sungsu Lim, Hyun Ji Jeong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Cohesive+Subgraphs+in+Hypergraphs:+The+(k,+g)-core+Approach)|0|
|[AmpliBias: Mitigating Dataset Bias through Bias Amplification in Few-shot Learning for Generative Models](https://doi.org/10.1145/3583780.3615184)|Donggeun Ko, Dongjun Lee, Namjun Park, Kyoungrae Noh, Hyeonjin Park, Jaekwang Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AmpliBias:+Mitigating+Dataset+Bias+through+Bias+Amplification+in+Few-shot+Learning+for+Generative+Models)|0|
|[Causal Discovery in Temporal Domain from Interventional Data](https://doi.org/10.1145/3583780.3615177)|Peiwen Li, Yuan Meng, Xin Wang, Fang Shen, Yue Li, Jialong Wang, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Discovery+in+Temporal+Domain+from+Interventional+Data)|0|
|[T-SaS: Toward Shift-aware Dynamic Adaptation for Streaming Data](https://doi.org/10.1145/3583780.3615267)|Weijieying Ren, Tianxiang Zhao, Wei Qin, Kunpeng Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=T-SaS:+Toward+Shift-aware+Dynamic+Adaptation+for+Streaming+Data)|0|
|[Adversarial Density Ratio Estimation for Change Point Detection](https://doi.org/10.1145/3583780.3615248)|Shreyas S, Prakash Mandayam Comar, Sivaramakrishnan Kaveri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Density+Ratio+Estimation+for+Change+Point+Detection)|0|
|[Improving Diversity in Unsupervised Keyphrase Extraction with Determinantal Point Process](https://doi.org/10.1145/3583780.3615141)|Mingyang Song, Huafeng Liu, Liping Jing||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Diversity+in+Unsupervised+Keyphrase+Extraction+with+Determinantal+Point+Process)|0|
|[Exposing Model Theft: A Robust and Transferable Watermark for Thwarting Model Extraction Attacks](https://doi.org/10.1145/3583780.3615211)|Ruixiang Tang, Hongye Jin, Mengnan Du, Curtis Wigington, Rajiv Jain, Xia Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exposing+Model+Theft:+A+Robust+and+Transferable+Watermark+for+Thwarting+Model+Extraction+Attacks)|0|
|[Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning](https://doi.org/10.1145/3583780.3615199)|Tianmeng Yang, Min Zhou, Yujing Wang, Zhengjie Lin, Lujia Pan, Bin Cui, Yunhai Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Semantic+Confusion+from+Hostile+Neighborhood+for+Graph+Active+Learning)|0|
|[Target-oriented Few-shot Transferring via Measuring Task Similarity](https://doi.org/10.1145/3583780.3615149)|Zhipeng Zhou, Wei Gong, Haoquan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Target-oriented+Few-shot+Transferring+via+Measuring+Task+Similarity)|0|
|[Enhancing Catalog Relationship Problems with Heterogeneous Graphs and Graph Neural Networks Distillation](https://doi.org/10.1145/3583780.3615472)|Boxin Du, Robert A. Barton, Grant Galloway, Junzhou Huang, Shioulin Sam, Ismail B. Tutar, Changhe Yuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Catalog+Relationship+Problems+with+Heterogeneous+Graphs+and+Graph+Neural+Networks+Distillation)|0|
|[DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource Real Estate Appraisal](https://doi.org/10.1145/3583780.3615470)|WeiWei Du, WeiYao Wang, WenChih Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DoRA:+Domain-Based+Self-Supervised+Learning+Framework+for+Low-Resource+Real+Estate+Appraisal)|0|
|[A Stochastic Online Forecast-and-Optimize Framework for Real-Time Energy Dispatch in Virtual Power Plants under Uncertainty](https://doi.org/10.1145/3583780.3614653)|Wei Jiang, Zhongkai Yi, Li Wang, Hanwei Zhang, Jihai Zhang, Fangquan Lin, Cheng Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Stochastic+Online+Forecast-and-Optimize+Framework+for+Real-Time+Energy+Dispatch+in+Virtual+Power+Plants+under+Uncertainty)|0|
|[Generating Product Insights from Community Q&A](https://doi.org/10.1145/3583780.3615480)|Lital Kuchy, Ran Levy, Avihai Mejer, Noam Segev, Shunit Agmon, Miriam Farber||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Product+Insights+from+Community+Q&A)|0|
|[GBTTE: Graph Attention Network Based Bus Travel Time Estimation](https://doi.org/10.1145/3583780.3614730)|Yuecheng Rong, Juntao Yao, Jun Liu, Yifan Fang, Wei Luo, Hao Liu, Jie Ma, Zepeng Dan, Jinzhu Lin, Zhi Wu, Yan Zhang, Chuanming Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GBTTE:+Graph+Attention+Network+Based+Bus+Travel+Time+Estimation)|0|
|[STREAMS: Towards Spatio-Temporal Causal Discovery with Reinforcement Learning for Streamflow Rate Prediction](https://doi.org/10.1145/3583780.3614719)|Paras Sheth, Ahmadreza Mosallanezhad, Kaize Ding, Reepal Shah, John Sabo, Huan Liu, K. Selçuk Candan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STREAMS:+Towards+Spatio-Temporal+Causal+Discovery+with+Reinforcement+Learning+for+Streamflow+Rate+Prediction)|0|
|[Combating Ad Fatigue via Frequency-Recency Features in Online Advertising Systems](https://doi.org/10.1145/3583780.3615461)|Natalia Silberstein, Or Shoham, Assaf Klein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combating+Ad+Fatigue+via+Frequency-Recency+Features+in+Online+Advertising+Systems)|0|
|[PRODIGY: Product Design Guidance at Scale](https://doi.org/10.1145/3583780.3615494)|Sambeet Tiady, Anirban Majumder, Deepak Gupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PRODIGY:+Product+Design+Guidance+at+Scale)|0|
|[LittleMu: Deploying an Online Virtual Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts](https://doi.org/10.1145/3583780.3615484)|Shangqing Tu, Zheyuan Zhang, Jifan Yu, Chunyang Li, Siyu Zhang, Zijun Yao, Lei Hou, Juanzi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LittleMu:+Deploying+an+Online+Virtual+Teaching+Assistant+via+Heterogeneous+Sources+Integration+and+Chain+of+Teach+Prompts)|0|
|[MArBLE: Hierarchical Multi-Armed Bandits for Human-in-the-Loop Set Expansion](https://doi.org/10.1145/3583780.3615485)|Muntasir Wahed, Daniel Gruhl, Ismini Lourentzou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MArBLE:+Hierarchical+Multi-Armed+Bandits+for+Human-in-the-Loop+Set+Expansion)|0|
|[SEDAR: A Semantic Data Reservoir for Heterogeneous Datasets](https://doi.org/10.1145/3583780.3614753)|Sayed Hoseini, Ahmed Ali, Haron Shaker, Christoph Quix||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEDAR:+A+Semantic+Data+Reservoir+for+Heterogeneous+Datasets)|0|
|[EFFECTS: Explorable and Explainable Feature Extraction Framework for Multivariate Time-Series Classification](https://doi.org/10.1145/3583780.3614740)|Ido Ikar, Amit Somech||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFFECTS:+Explorable+and+Explainable+Feature+Extraction+Framework+for+Multivariate+Time-Series+Classification)|0|
|[Misinformation Concierge: A Proof-of-Concept with Curated Twitter Dataset on COVID-19 Vaccination](https://doi.org/10.1145/3583780.3614746)|Shakshi Sharma, Anwitaman Datta, Vigneshwaran Shankaran, Rajesh Sharma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Misinformation+Concierge:+A+Proof-of-Concept+with+Curated+Twitter+Dataset+on+COVID-19+Vaccination)|0|
|[NumJoin: Discovering Numeric Joinable Tables with Semantically Related Columns](https://doi.org/10.1145/3583780.3614750)|Pranav Subramaniam, Udayan Khurana, Kavitha Srinivas, Horst Samulowitz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NumJoin:+Discovering+Numeric+Joinable+Tables+with+Semantically+Related+Columns)|0|
|[Cluster-Explorer: An interactive Framework for Explaining Black-Box Clustering Results](https://doi.org/10.1145/3583780.3614734)|Sariel Tutay, Amit Somech||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cluster-Explorer:+An+interactive+Framework+for+Explaining+Black-Box+Clustering+Results)|0|
|[Investigating Natural and Artificial Dynamics in Graph Data Mining and Machine Learning](https://doi.org/10.1145/3583780.3616007)|Dongqi Fu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Natural+and+Artificial+Dynamics+in+Graph+Data+Mining+and+Machine+Learning)|0|
|[Intersectional Bias Mitigation in Pre-trained Language Models: A Quantum-Inspired Approach](https://doi.org/10.1145/3583780.3616003)|Omid Shokrollahi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intersectional+Bias+Mitigation+in+Pre-trained+Language+Models:+A+Quantum-Inspired+Approach)|0|
|[Tutorial on User Simulation for Evaluating Information Access Systems](https://doi.org/10.1145/3583780.3615296)|Krisztian Balog, ChengXiang Zhai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tutorial+on+User+Simulation+for+Evaluating+Information+Access+Systems)|0|
|[Leveraging Graph Neural Networks for User Profiling: Recent Advances and Open Challenges](https://doi.org/10.1145/3583780.3615292)|Erasmo Purificato, Ludovico Boratto, Ernesto William De Luca||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Graph+Neural+Networks+for+User+Profiling:+Recent+Advances+and+Open+Challenges)|0|
|[From User Activity Traces to Navigation Graph for Software Enhancement: An Application of Graph Neural Network (GNN) on a Real-World Non-Attributed Graph](https://doi.org/10.1145/3583780.3615998)|Ikram Boukharouba, Florence Sèdes, Christophe Bortolaso, Florent Mouysset||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+User+Activity+Traces+to+Navigation+Graph+for+Software+Enhancement:+An+Application+of+Graph+Neural+Network+(GNN)+on+a+Real-World+Non-Attributed+Graph)|0|
|[Proactive and Automatic Detection of Product Misclassifications at Massive Scale](https://doi.org/10.1145/3583780.3615510)|Ling Jiang, Xiaoyu Chu, Saaransh Gulati, Pulkit Garg, Andrew Borthwick, Gang Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proactive+and+Automatic+Detection+of+Product+Misclassifications+at+Massive+Scale)|0|
|[KID34K: A Dataset for Online Identity Card Fraud Detection](https://doi.org/10.1145/3583780.3615122)|EunJu Park, SeungYeon Back, Jeongho Kim, Simon S. Woo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KID34K:+A+Dataset+for+Online+Identity+Card+Fraud+Detection)|0|
|[OpenGDA: Graph Domain Adaptation Benchmark for Cross-network Learning](https://doi.org/10.1145/3583780.3615127)|Boshen Shi, Yongqing Wang, Fangda Guo, Jiangli Shao, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OpenGDA:+Graph+Domain+Adaptation+Benchmark+for+Cross-network+Learning)|0|
|[Generative AI and the Future of Information Access](https://doi.org/10.1145/3583780.3615317)|Chirag Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+and+the+Future+of+Information+Access)|0|
|[Knowledge Graphs for Knowing More and Knowing for Sure](https://doi.org/10.1145/3583780.3615316)|Steffen Staab||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graphs+for+Knowing+More+and+Knowing+for+Sure)|0|
|[Optimizing for Member Value in an Edge Building Marketplace](https://doi.org/10.1145/3583780.3615000)|Ayan Acharya, Siyuan Gao, Ankan Saha, Borja Ocejo, Kinjal Basu, Sathiya Keerthi Selvaraj, Rahul Mazumder, Aman Gupta, Parag Agrawal, Ayan Acharya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+for+Member+Value+in+an+Edge+Building+Marketplace)|0|
|[Interpretable Natural Language Understanding](https://doi.org/10.1145/3583780.3615315)|Yulan He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Natural+Language+Understanding)|0|
|[Deep Integrated Explanations](https://doi.org/10.1145/3583780.3614836)|Oren Barkan, Yehonatan Elisha, Jonathan Weill, Yuval Asher, Amit Eshel, Noam Koenigstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Integrated+Explanations)|0|
|[MPMRC-MNER: A Unified MRC framework for Multimodal Named Entity Recognition based Multimodal Prompt](https://doi.org/10.1145/3583780.3614975)|Xigang Bao, Mengyuan Tian, Zhiyuan Zha, Biao Qin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MPMRC-MNER:+A+Unified+MRC+framework+for+Multimodal+Named+Entity+Recognition+based+Multimodal+Prompt)|0|
|[Bridged-GNN: Knowledge Bridge Learning for Effective Knowledge Transfer](https://doi.org/10.1145/3583780.3614796)|Wendong Bi, Xueqi Cheng, Bingbing Xu, Xiaoqian Sun, Easton Li Xu, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridged-GNN:+Knowledge+Bridge+Learning+for+Effective+Knowledge+Transfer)|0|
|[Enabling Health Data Sharing with Fine-Grained Privacy](https://doi.org/10.1145/3583780.3614864)|Luca Bonomi, Sepand Gousheh, Liyue Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enabling+Health+Data+Sharing+with+Fine-Grained+Privacy)|0|
|[Fair&Share: Fast and Fair Multi-Criteria Selections](https://doi.org/10.1145/3583780.3614874)|Kathleen Cachel, Elke A. Rundensteiner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair&Share:+Fast+and+Fair+Multi-Criteria+Selections)|0|
|[MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation](https://doi.org/10.1145/3583780.3614962)|Zekun Cai, Renhe Jiang, Xinyu Yang, Zhaonan Wang, Diansheng Guo, Hill Hiroki Kobayashi, Xuan Song, Ryosuke Shibasaki||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemDA:+Forecasting+Urban+Time+Series+with+Memory-based+Drift+Adaptation)|0|
|[Inducing Causal Structure for Abstractive Text Summarization](https://doi.org/10.1145/3583780.3614934)|Lu Chen, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inducing+Causal+Structure+for+Abstractive+Text+Summarization)|0|
|[Region Profile Enhanced Urban Spatio-Temporal Prediction via Adaptive Meta-Learning](https://doi.org/10.1145/3583780.3615027)|Jie Chen, Tong Liu, Ruiyuan Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Region+Profile+Enhanced+Urban+Spatio-Temporal+Prediction+via+Adaptive+Meta-Learning)|0|
|[Learning Pair-Centric Representation for Link Sign Prediction with Subgraph](https://doi.org/10.1145/3583780.3614951)|Jushuo Chen, Feifei Dai, Xiaoyan Gu, Haihui Fan, Jiang Zhou, Bo Li, Weiping Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Pair-Centric+Representation+for+Link+Sign+Prediction+with+Subgraph)|0|
|[Meta-Transfer-Learning for Time Series Data with Extreme Events: An Application to Water Temperature Prediction](https://doi.org/10.1145/3583780.3614966)|Shengyu Chen, Nasrin Kalanat, Simon Topp, Jeffrey M. Sadler, Yiqun Xie, Zhe Jiang, Xiaowei Jia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Transfer-Learning+for+Time+Series+Data+with+Extreme+Events:+An+Application+to+Water+Temperature+Prediction)|0|
|[Hadamard Adapter: An Extreme Parameter-Efficient Adapter Tuning Method for Pre-trained Language Models](https://doi.org/10.1145/3583780.3614904)|Yuyan Chen, Qiang Fu, Ge Fan, Lun Du, JianGuang Lou, Shi Han, Dongmei Zhang, Zhixu Li, Yanghua Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hadamard+Adapter:+An+Extreme+Parameter-Efficient+Adapter+Tuning+Method+for+Pre-trained+Language+Models)|0|
|[Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models](https://doi.org/10.1145/3583780.3614905)|Yuyan Chen, Qiang Fu, Yichen Yuan, Zhihao Wen, Ge Fan, Dayiheng Liu, Dongmei Zhang, Zhixu Li, Yanghua Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hallucination+Detection:+Robustly+Discerning+Reliable+Answers+in+Large+Language+Models)|0|
|[Deep Generative Imputation Model for Missing Not At Random Data](https://doi.org/10.1145/3583780.3614835)|Jialei Chen, Yuanbo Xu, Pengyang Wang, Yongjian Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Generative+Imputation+Model+for+Missing+Not+At+Random+Data)|0|
|[Towards Spoken Language Understanding via Multi-level Multi-grained Contrastive Learning](https://doi.org/10.1145/3583780.3615093)|Xuxin Cheng, Wanshi Xu, Zhihong Zhu, Hongxiang Li, Yuexian Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Spoken+Language+Understanding+via+Multi-level+Multi-grained+Contrastive+Learning)|0|
|[DAS-CL: Towards Multimodal Machine Translation via Dual-Level Asymmetric Contrastive Learning](https://doi.org/10.1145/3583780.3614832)|Xuxin Cheng, Zhihong Zhu, Yaowei Li, Hongxiang Li, Yuexian Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAS-CL:+Towards+Multimodal+Machine+Translation+via+Dual-Level+Asymmetric+Contrastive+Learning)|0|
|[PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial Networks for Radar-Based Precipitation Nowcasting](https://doi.org/10.1145/3583780.3615006)|Jaeho Choi, Yura Kim, KwangHo Kim, SungHwa Jung, Ikhyun Cho||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PCT-CycleGAN:+Paired+Complementary+Temporal+Cycle-Consistent+Adversarial+Networks+for+Radar-Based+Precipitation+Nowcasting)|0|
|[Can Knowledge Graphs Simplify Text?](https://doi.org/10.1145/3583780.3615514)|Anthony Colas, Haodi Ma, Xuanli He, Yang Bai, Daisy Zhe Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Knowledge+Graphs+Simplify+Text?)|0|
|[Cross-heterogeneity Graph Few-shot Learning](https://doi.org/10.1145/3583780.3614830)|Pengfei Ding, Yan Wang, Guanfeng Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-heterogeneity+Graph+Few-shot+Learning)|0|
|[NeoMaPy: A Parametric Framework for Reasoning with MAP Inference on Temporal Markov Logic Networks](https://doi.org/10.1145/3583780.3614757)|Victor David, Raphaël FournierS'niehotta, Nicolas Travers||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeoMaPy:+A+Parametric+Framework+for+Reasoning+with+MAP+Inference+on+Temporal+Markov+Logic+Networks)|0|
|[Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking](https://doi.org/10.1145/3583780.3615036)|Hang Dong, Jiaoyan Chen, Yuan He, Yinan Liu, Ian Horrocks||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reveal+the+Unknown:+Out-of-Knowledge-Base+Mention+Discovery+with+Entity+Linking)|0|
|[Spatial-Temporal Graph Boosting Networks: Enhancing Spatial-Temporal Graph Neural Networks via Gradient Boosting](https://doi.org/10.1145/3583780.3615066)|Yujie Fan, ChinChia Michael Yeh, Huiyuan Chen, Yan Zheng, Liang Wang, Junpeng Wang, Xin Dai, Zhongfang Zhuang, Wei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatial-Temporal+Graph+Boosting+Networks:+Enhancing+Spatial-Temporal+Graph+Neural+Networks+via+Gradient+Boosting)|0|
|[Cognitive-inspired Graph Redundancy Networks for Multi-source Information Fusion](https://doi.org/10.1145/3583780.3614815)|Yao Fu, Junhong Wan, Junlan Yu, Weihao Jiang, Shiliang Pu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cognitive-inspired+Graph+Redundancy+Networks+for+Multi-source+Information+Fusion)|0|
|[Cross-Scenario Maneuver Decision with Adaptive Perception for Autonomous Driving](https://doi.org/10.1145/3583780.3614831)|Yuan Fu, Shuncheng Liu, Yuyang Xia, Fangda Guo, Kai Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Scenario+Maneuver+Decision+with+Adaptive+Perception+for+Autonomous+Driving)|0|
|[On the Trade-off between Over-smoothing and Over-squashing in Deep Graph Neural Networks](https://doi.org/10.1145/3583780.3614997)|Jhony H. Giraldo, Konstantinos Skianis, Thierry Bouwmans, Fragkiskos D. Malliaros||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Trade-off+between+Over-smoothing+and+Over-squashing+in+Deep+Graph+Neural+Networks)|0|
|[Homophily-enhanced Structure Learning for Graph Clustering](https://doi.org/10.1145/3583780.3614915)|Ming Gu, Gaoming Yang, Sheng Zhou, Ning Ma, Jiawei Chen, Qiaoyu Tan, Meihan Liu, Jiajun Bu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Homophily-enhanced+Structure+Learning+for+Graph+Clustering)|0|
|[Hierarchical Meta-Learning with Hyper-Tasks for Few-Shot Learning](https://doi.org/10.1145/3583780.3614911)|Yunchuan Guan, Yu Liu, Ke Zhou, Junyuan Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Meta-Learning+with+Hyper-Tasks+for+Few-Shot+Learning)|0|
|[RoCourseNet: Robust Training of a Prediction Aware Recourse Model](https://doi.org/10.1145/3583780.3615040)|Hangzhi Guo, Feiran Jia, Jinghui Chen, Anna Cinzia Squicciarini, Amulya Yadav||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RoCourseNet:+Robust+Training+of+a+Prediction+Aware+Recourse+Model)|0|
|[Attacking Neural Networks with Neural Networks: Towards Deep Synchronization for Backdoor Attacks](https://doi.org/10.1145/3583780.3614784)|Zihan Guan, Lichao Sun, Mengnan Du, Ninghao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attacking+Neural+Networks+with+Neural+Networks:+Towards+Deep+Synchronization+for+Backdoor+Attacks)|0|
|[MGICL: Multi-Grained Interaction Contrastive Learning for Multimodal Named Entity Recognition](https://doi.org/10.1145/3583780.3614967)|Aibo Guo, Xiang Zhao, Zhen Tan, Weidong Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MGICL:+Multi-Grained+Interaction+Contrastive+Learning+for+Multimodal+Named+Entity+Recognition)|0|
|[Interpretable Fake News Detection with Graph Evidence](https://doi.org/10.1145/3583780.3614936)|Hao Guo, Weixin Zeng, Jiuyang Tang, Xiang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Fake+News+Detection+with+Graph+Evidence)|0|
|[Towards Fair Graph Neural Networks via Graph Counterfactual](https://doi.org/10.1145/3583780.3615092)|Zhimeng Guo, Jialiang Li, Teng Xiao, Yao Ma, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Graph+Neural+Networks+via+Graph+Counterfactual)|0|
|[James ate 5 oranges = Steve bought 5 pencils: Structure-Aware Denoising for Paraphrasing Word Problems](https://doi.org/10.1145/3583780.3614940)|Rishabh Gupta, Venktesh V, Mukesh K. Mohania, Vikram Goyal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=James+ate+5+oranges+=+Steve+bought+5+pencils:+Structure-Aware+Denoising+for+Paraphrasing+Word+Problems)|0|
|[Enhancing Spatio-temporal Traffic Prediction through Urban Human Activity Analysis](https://doi.org/10.1145/3583780.3614867)|Sumin Han, Youngjun Park, Minji Lee, Jisun An, Dongman Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Spatio-temporal+Traffic+Prediction+through+Urban+Human+Activity+Analysis)|0|
|[On Root Cause Localization and Anomaly Mitigation through Causal Inference](https://doi.org/10.1145/3583780.3614995)|Xiao Han, Lu Zhang, Yongkai Wu, Shuhan Yuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Root+Cause+Localization+and+Anomaly+Mitigation+through+Causal+Inference)|0|
|[SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction](https://doi.org/10.1145/3583780.3615047)|Muntasir Hoq, Sushanth Reddy Chilla, Melika Ahmadi Ranjbar, Peter Brusilovsky, Bita Akram||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SANN:+Programming+Code+Representation+Using+Attention+Neural+Network+with+Optimized+Subtree+Extraction)|0|
|[Designing and Evaluating Presentation Strategies for Fact-Checked Content](https://doi.org/10.1145/3583780.3614841)|Danula Hettiachchi, Kaixin Ji, Jenny Kennedy, Anthony McCosker, Flora D. Salim, Mark Sanderson, Falk Scholer, Damiano Spina||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Designing+and+Evaluating+Presentation+Strategies+for+Fact-Checked+Content)|0|
|[HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion](https://doi.org/10.1145/3583780.3614922)|Zhiwei Hu, Víctor GutiérrezBasulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyperFormer:+Enhancing+Entity+and+Relation+Interaction+for+Hyper-Relational+Knowledge+Graph+Completion)|0|
|[Liberate Pseudo Labels from Over-Dependence: Label Information Migration on Sparsely Labeled Graphs](https://doi.org/10.1145/3583780.3614954)|Zhihui Hu, Yao Fu, Hong Zhao, Xiaoyu Cai, Weihao Jiang, Shiliang Pu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Liberate+Pseudo+Labels+from+Over-Dependence:+Label+Information+Migration+on+Sparsely+Labeled+Graphs)|0|
|[Enhanced Template-Free Reaction Prediction with Molecular Graphs and Sequence-based Data Augmentation](https://doi.org/10.1145/3583780.3614865)|Haozhe Hu, Yongquan Jiang, Yan Yang, Jim X. Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhanced+Template-Free+Reaction+Prediction+with+Molecular+Graphs+and+Sequence-based+Data+Augmentation)|0|
|[Spans, Not Tokens: A Span-Centric Model for Multi-Span Reading Comprehension](https://doi.org/10.1145/3583780.3615064)|Zixian Huang, Jiaying Zhou, Chenxu Niu, Gong Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spans,+Not+Tokens:+A+Span-Centric+Model+for+Multi-Span+Reading+Comprehension)|0|
|[STAMINA (Spatial-Temporal Aligned Meteorological INformation Attention) and FPL (Focal Precip Loss): Advancements in Precipitation Nowcasting for Heavy Rainfall Events](https://doi.org/10.1145/3583780.3615069)|PingChia Huang, YuehLi Chen, YiSyuan Liou, BingChen Tsai, ChunChieh Wu, Winston H. Hsu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STAMINA+(Spatial-Temporal+Aligned+Meteorological+INformation+Attention)+and+FPL+(Focal+Precip+Loss):+Advancements+in+Precipitation+Nowcasting+for+Heavy+Rainfall+Events)|0|
|[SAGE: A Storage-Based Approach for Scalable and Efficient Sparse Generalized Matrix-Matrix Multiplication](https://doi.org/10.1145/3583780.3615044)|MyungHwan Jang, YunYong Ko, HyuckMoo Gwon, Ikhyeon Jo, Yongjun Park, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAGE:+A+Storage-Based+Approach+for+Scalable+and+Efficient+Sparse+Generalized+Matrix-Matrix+Multiplication)|0|
|[Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning](https://doi.org/10.1145/3583780.3615030)|Lucas Jarnac, Miguel Couceiro, Pierre Monnin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevant+Entity+Selection:+Knowledge+Graph+Bootstrapping+via+Zero-Shot+Analogical+Pruning)|0|
|[PriSHAP: Prior-guided Shapley Value Explanations for Correlated Features](https://doi.org/10.1145/3583780.3615013)|Guanyu Jiang, Fuzhen Zhuang, Bowen Song, Tianyi Zhang, Deqing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PriSHAP:+Prior-guided+Shapley+Value+Explanations+for+Correlated+Features)|0|
|[A Momentum Loss Reweighting Method for Improving Recall](https://doi.org/10.1145/3583780.3614764)|Chenzhi Jiang, Yin Jin, Ningtao Wang, Ruofan Wu, Xing Fu, Weiqiang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Momentum+Loss+Reweighting+Method+for+Improving+Recall)|0|
|[Hierarchical Multi-Label Classification with Partial Labels and Unknown Hierarchy](https://doi.org/10.1145/3583780.3614912)|Suhyeon Jo, DongHyeok Shin, Byeonghu Na, JoonHo Jang, IlChul Moon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Multi-Label+Classification+with+Partial+Labels+and+Unknown+Hierarchy)|0|
|[Robust Graph Clustering via Meta Weighting for Noisy Graphs](https://doi.org/10.1145/3583780.3615038)|Hyeonsoo Jo, Fanchen Bu, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Graph+Clustering+via+Meta+Weighting+for+Noisy+Graphs)|0|
|[CFOM: Lead Optimization For Drug Discovery With Limited Data](https://doi.org/10.1145/3583780.3614807)|Natan Kaminsky, Uriel Singer, Kira Radinsky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CFOM:+Lead+Optimization+For+Drug+Discovery+With+Limited+Data)|0|
|[Diving into a Sea of Opinions: Multi-modal Abstractive Summarization with Comment Sensitivity](https://doi.org/10.1145/3583780.3614849)|Raghvendra Kumar, Ratul Chakraborty, Abhishek Tiwari, Sriparna Saha, Naveen Saini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diving+into+a+Sea+of+Opinions:+Multi-modal+Abstractive+Summarization+with+Comment+Sensitivity)|0|
|[Prompting Strategies for Citation Classification](https://doi.org/10.1145/3583780.3615018)|Suchetha N. Kunnath, David Pride, Petr Knoth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompting+Strategies+for+Citation+Classification)|0|
|[VFedAD: A Defense Method Based on the Information Mechanism Behind the Vertical Federated Data Poisoning Attack](https://doi.org/10.1145/3583780.3615106)|Jinrong Lai, Tong Wang, Chuan Chen, Yihao Li, Zibin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VFedAD:+A+Defense+Method+Based+on+the+Information+Mechanism+Behind+the+Vertical+Federated+Data+Poisoning+Attack)|0|
|[A Re-evaluation of Deep Learning Methods for Attributed Graph Clustering](https://doi.org/10.1145/3583780.3614768)|Xinying Lai, Dingming Wu, Christian S. Jensen, Kezhong Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Re-evaluation+of+Deep+Learning+Methods+for+Attributed+Graph+Clustering)|0|
|[Tackling Diverse Minorities in Imbalanced Classification](https://doi.org/10.1145/3583780.3615071)|KweiHerng Lai, Daochen Zha, Huiyuan Chen, Mangesh Bendre, Yuzhong Chen, Mahashweta Das, Hao Yang, Xia Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tackling+Diverse+Minorities+in+Imbalanced+Classification)|0|
|[DuoGAT: Dual Time-oriented Graph Attention Networks for Accurate, Efficient and Explainable Anomaly Detection on Time-series](https://doi.org/10.1145/3583780.3614857)|Jongsoo Lee, Byeongtae Park, DongKyu Chae||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DuoGAT:+Dual+Time-oriented+Graph+Attention+Networks+for+Accurate,+Efficient+and+Explainable+Anomaly+Detection+on+Time-series)|0|
|[GUARD: Graph Universal Adversarial Defense](https://doi.org/10.1145/3583780.3614903)|Jintang Li, Jie Liao, Ruofan Wu, Liang Chen, Zibin Zheng, Jiawang Dan, Changhua Meng, Weiqiang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GUARD:+Graph+Universal+Adversarial+Defense)|0|
|[Class-Specific Word Sense Aware Topic Modeling via Soft Orthogonalized Topics](https://doi.org/10.1145/3583780.3614809)|Wenbo Li, Yao Yang, Einoshin Suzuki||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Class-Specific+Word+Sense+Aware+Topic+Modeling+via+Soft+Orthogonalized+Topics)|0|
|[Relation-Aware Diffusion Model for Controllable Poster Layout Generation](https://doi.org/10.1145/3583780.3615028)|Fengheng Li, An Liu, Wei Feng, Honghe Zhu, Yaoyu Li, Zheng Zhang, Jingjing Lv, Xin Zhu, Junjie Shen, Zhangang Lin, Jingping Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relation-Aware+Diffusion+Model+for+Controllable+Poster+Layout+Generation)|0|
|[ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph Neural Networks](https://doi.org/10.1145/3583780.3614772)|Yiqiao Li, Jianlong Zhou, Yifei Dong, Niusha Shafiabady, Fang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACGAN-GNNExplainer:+Auxiliary+Conditional+Generative+Explainer+for+Graph+Neural+Networks)|0|
|[REST: Drug-Drug Interaction Prediction via Reinforced Student-Teacher Curriculum Learning](https://doi.org/10.1145/3583780.3615033)|Xinhang Li, Zhaopeng Qiu, Xiangyu Zhao, Yong Zhang, Chunxiao Xing, Xian Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REST:+Drug-Drug+Interaction+Prediction+via+Reinforced+Student-Teacher+Curriculum+Learning)|0|
|[Simplifying Temporal Heterogeneous Network for Continuous-Time Link prediction](https://doi.org/10.1145/3583780.3615059)|Ce Li, Rongpei Hong, Xovee Xu, Goce Trajcevski, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simplifying+Temporal+Heterogeneous+Network+for+Continuous-Time+Link+prediction)|0|
|[Heterogeneous Temporal Graph Neural Network Explainer](https://doi.org/10.1145/3583780.3614909)|Jiazheng Li, Chunhui Zhang, Chuxu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+Temporal+Graph+Neural+Network+Explainer)|0|
|[Harnessing the Power of Pre-trained Vision-Language Models for Efficient Medical Report Generation](https://doi.org/10.1145/3583780.3614961)|Qi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+the+Power+of+Pre-trained+Vision-Language+Models+for+Efficient+Medical+Report+Generation)|0|
|[Contrastive Representation Learning Based on Multiple Node-centered Subgraphs](https://doi.org/10.1145/3583780.3614825)|Dong Li, Wenjun Wang, Minglai Shao, Chen Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Representation+Learning+Based+on+Multiple+Node-centered+Subgraphs)|0|
|[Multi-Order Relations Hyperbolic Fusion for Heterogeneous Graphs](https://doi.org/10.1145/3583780.3614979)|Junlin Li, Yueheng Sun, Minglai Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Order+Relations+Hyperbolic+Fusion+for+Heterogeneous+Graphs)|0|
|[SAILOR: Structural Augmentation Based Tail Node Representation Learning](https://doi.org/10.1145/3583780.3615045)|Jie Liao, Jintang Li, Liang Chen, Bingzhe Wu, Yatao Bian, Zibin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAILOR:+Structural+Augmentation+Based+Tail+Node+Representation+Learning)|0|
|[Adaptation Speed Analysis for Fairness-aware Causal Models](https://doi.org/10.1145/3583780.3614774)|Yujie Lin, Chen Zhao, Minglai Shao, Xujiang Zhao, Haifeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptation+Speed+Analysis+for+Fairness-aware+Causal+Models)|0|
|[On the Thresholding Strategy for Infrequent Labels in Multi-label Classification](https://doi.org/10.1145/3583780.3614996)|YuJen Lin, ChihJen Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Thresholding+Strategy+for+Infrequent+Labels+in+Multi-label+Classification)|0|
|[Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank](https://doi.org/10.1145/3583780.3614829)|Zhanyu Liu, Guanjie Zheng, Yanwei Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-city+Few-Shot+Traffic+Forecasting+via+Traffic+Pattern+Bank)|0|
|[GranCATs: Cross-Lingual Enhancement through Granularity-Specific Contrastive Adapters](https://doi.org/10.1145/3583780.3614896)|Meizhen Liu, Jiakai He, Xu Guo, Jianye Chen, Siu Cheung Hui, Fengyu Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GranCATs:+Cross-Lingual+Enhancement+through+Granularity-Specific+Contrastive+Adapters)|0|
|[Quantifying the Effectiveness of Advertising: A Bootstrap Proportion Test for Brand Lift Testing](https://doi.org/10.1145/3583780.3615021)|Wanjun Liu, Xiufan Yu, Jialiang Mao, Xiaoxu Wu, Justin Dyer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+the+Effectiveness+of+Advertising:+A+Bootstrap+Proportion+Test+for+Brand+Lift+Testing)|0|
|[BRep-BERT: Pre-training Boundary Representation BERT with Sub-graph Node Contrastive Learning](https://doi.org/10.1145/3583780.3614795)|Yunzhong Lou, Xueyang Li, Haotian Chen, Xiangdong Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BRep-BERT:+Pre-training+Boundary+Representation+BERT+with+Sub-graph+Node+Contrastive+Learning)|0|
|[Forward Creation, Reverse Selection: Achieving Highly Pertinent Multimodal Responses in Dialogue Contexts](https://doi.org/10.1145/3583780.3614888)|Ge Luo, Manman Zhang, Yuchen Ma, Sheng Li, Zhenxing Qian, Xinpeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forward+Creation,+Reverse+Selection:+Achieving+Highly+Pertinent+Multimodal+Responses+in+Dialogue+Contexts)|0|
|[Context-Aware Prompt for Generation-based Event Argument Extraction with Diffusion Models](https://doi.org/10.1145/3583780.3614820)|Lei Luo, Yajing Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-Aware+Prompt+for+Generation-based+Event+Argument+Extraction+with+Diffusion+Models)|0|
|[Multi-scale Graph Pooling Approach with Adaptive Key Subgraph for Graph Representations](https://doi.org/10.1145/3583780.3614981)|Yiqin Lv, Zhiliang Tian, Zheng Xie, Yiping Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-scale+Graph+Pooling+Approach+with+Adaptive+Key+Subgraph+for+Graph+Representations)|0|
|[Rethinking Sensors Modeling: Hierarchical Information Enhanced Traffic Forecasting](https://doi.org/10.1145/3583780.3614910)|Qian Ma, Zijian Zhang, Xiangyu Zhao, Haoliang Li, Hongwei Zhao, Yiqi Wang, Zitao Liu, Wanyu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Sensors+Modeling:+Hierarchical+Information+Enhanced+Traffic+Forecasting)|0|
|[MultiCAD: Contrastive Representation Learning for Multi-modal 3D Computer-Aided Design Models](https://doi.org/10.1145/3583780.3614982)|Weijian Ma, Minyang Xu, Xueyang Li, Xiangdong Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiCAD:+Contrastive+Representation+Learning+for+Multi-modal+3D+Computer-Aided+Design+Models)|0|
|[A Graph Neural Network Model for Concept Prerequisite Relation Extraction](https://doi.org/10.1145/3583780.3614761)|Debjani Mazumder, Jiaul H. Paik, Anupam Basu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Graph+Neural+Network+Model+for+Concept+Prerequisite+Relation+Extraction)|0|
|[Disparity, Inequality, and Accuracy Tradeoffs in Graph Neural Networks for Node Classification](https://doi.org/10.1145/3583780.3614847)|Arpit Merchant, Carlos Castillo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disparity,+Inequality,+and+Accuracy+Tradeoffs+in+Graph+Neural+Networks+for+Node+Classification)|0|
|[Unlocking the Potential of Non-PSD Kernel Matrices: A Polar Decomposition-based Transformation for Improved Prediction Models](https://doi.org/10.1145/3583780.3615102)|Maximilian Münch, Manuel Röder, FrankMichael Schleif||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Potential+of+Non-PSD+Kernel+Matrices:+A+Polar+Decomposition-based+Transformation+for+Improved+Prediction+Models)|0|
|[Joint Link Prediction Via Inference from a Model](https://doi.org/10.1145/3583780.3614941)|Parmis Naddaf, Erfaneh Mahmoudzaheh Ahmadi Nejad, Kiarash Zahirnia, Manfred Jaeger, Oliver Schulte||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Link+Prediction+Via+Inference+from+a+Model)|0|
|[Non-Uniform Adversarial Perturbations for Discrete Tabular Datasets](https://doi.org/10.1145/3583780.3614992)|Jay Nandy, Jatin Chauhan, Rishi Saket, Aravindan Raghuveer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-Uniform+Adversarial+Perturbations+for+Discrete+Tabular+Datasets)|0|
|[Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models](https://doi.org/10.1145/3583780.3614960)|Preben M. Ness, Dusica Marijan, Sunanda Bose||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+the+Effect+of+Causal+Disentanglement+on+the+Adversarial+Robustness+of+Neural+Network+Models)|0|
|[How Discriminative Are Your Qrels? How To Study the Statistical Significance of Document Adjudication Methods](https://doi.org/10.1145/3583780.3614916)|David Otero, Javier Parapar, Nicola Ferro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Discriminative+Are+Your+Qrels?+How+To+Study+the+Statistical+Significance+of+Document+Adjudication+Methods)|0|
|[Rule-based Knowledge Graph Completion with Canonical Models](https://doi.org/10.1145/3583780.3615042)|Simon Ott, Patrick Betz, Daria Stepanova, Mohamed H. GadElrab, Christian Meilicke, Heiner Stuckenschmidt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rule-based+Knowledge+Graph+Completion+with+Canonical+Models)|0|
|[Concept Evolution in Deep Learning Training: A Unified Interpretation Framework and Discoveries](https://doi.org/10.1145/3583780.3614819)|Haekyu Park, Seongmin Lee, Benjamin Hoover, Austin P. Wright, Omar Shaikh, Rahul Duggal, Nilaksh Das, Kevin Li, Judy Hoffman, Duen Horng Chau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Concept+Evolution+in+Deep+Learning+Training:+A+Unified+Interpretation+Framework+and+Discoveries)|0|
|[RotDiff: A Hyperbolic Rotation Representation Model for Information Diffusion Prediction](https://doi.org/10.1145/3583780.3615041)|Hongliang Qiao, Shanshan Feng, Xutao Li, Huiwei Lin, Han Hu, Wei Wei, Yunming Ye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RotDiff:+A+Hyperbolic+Rotation+Representation+Model+for+Information+Diffusion+Prediction)|0|
|[Federated Competing Risk Analysis](https://doi.org/10.1145/3583780.3614880)|Md Mahmudur Rahman, Sanjay Purushotham||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Competing+Risk+Analysis)|0|
|[Incremental Graph Classification by Class Prototype Construction and Augmentation](https://doi.org/10.1145/3583780.3614932)|Yixin Ren, Li Ke, Dong Li, Hui Xue, Zhao Li, Shuigeng Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incremental+Graph+Classification+by+Class+Prototype+Construction+and+Augmentation)|0|
|[Seq-HyGAN: Sequence Classification via Hypergraph Attention Network](https://doi.org/10.1145/3583780.3615057)|Khaled Mohammed Saifuddin, Corey May, Farhan Tanvir, Muhammad Ifte Khairul Islam, Esra Akbas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Seq-HyGAN:+Sequence+Classification+via+Hypergraph+Attention+Network)|0|
|[PaperLM: A Pre-trained Model for Hierarchical Examination Paper Representation Learning](https://doi.org/10.1145/3583780.3615003)|Minghui Shan, Yixiao Ma, Shulan Ruan, Zhi Cao, Shiwei Tong, Qi Liu, Yu Su, Shijin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PaperLM:+A+Pre-trained+Model+for+Hierarchical+Examination+Paper+Representation+Learning)|0|
|[Transferable Structure-based Adversarial Attack of Heterogeneous Graph Neural Network](https://doi.org/10.1145/3583780.3615095)|Yu Shang, Yudong Zhang, Jiansheng Chen, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transferable+Structure-based+Adversarial+Attack+of+Heterogeneous+Graph+Neural+Network)|0|
|[CANA: Causal-enhanced Social Network Alignment](https://doi.org/10.1145/3583780.3614799)|Jiangli Shao, Yongqing Wang, Fangda Guo, Boshen Shi, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CANA:+Causal-enhanced+Social+Network+Alignment)|0|
|[Representation Learning in Continuous-Time Dynamic Signed Networks](https://doi.org/10.1145/3583780.3615032)|Kartik Sharma, Mohit Raghavendra, YeonChang Lee, Anand Kumar M, Srijan Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+Learning+in+Continuous-Time+Dynamic+Signed+Networks)|0|
|[Investigating the Impact of Multimodality and External Knowledge in Aspect-level Complaint and Sentiment Analysis](https://doi.org/10.1145/3583780.3614937)|Apoorva Singh, Apoorv Verma, Raghav Jain, Sriparna Saha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+the+Impact+of+Multimodality+and+External+Knowledge+in+Aspect-level+Complaint+and+Sentiment+Analysis)|0|
|[Follow the Will of the Market: A Context-Informed Drift-Aware Method for Stock Prediction](https://doi.org/10.1145/3583780.3614886)|ChenHui Song, Xi Xiao, Bin Zhang, ShuTao Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Follow+the+Will+of+the+Market:+A+Context-Informed+Drift-Aware+Method+for+Stock+Prediction)|0|
|[Towards Fair Financial Services for All: A Temporal GNN Approach for Individual Fairness on Transaction Networks](https://doi.org/10.1145/3583780.3615091)|Zixing Song, Yuji Zhang, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Financial+Services+for+All:+A+Temporal+GNN+Approach+for+Individual+Fairness+on+Transaction+Networks)|0|
|[Topic-Aware Contrastive Learning and K-Nearest Neighbor Mechanism for Stance Detection](https://doi.org/10.1145/3583780.3615085)|Yepeng Sun, Jicang Lu, Ling Wang, Shunhang Li, Ningbo Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topic-Aware+Contrastive+Learning+and+K-Nearest+Neighbor+Mechanism+for+Stance+Detection)|0|
|[Fairness through Aleatoric Uncertainty](https://doi.org/10.1145/3583780.3614875)|Anique Tahir, Lu Cheng, Huan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+through+Aleatoric+Uncertainty)|0|
|[EAGLE: Enhance Target-Oriented Dialogs by Global Planning and Topic Flow Integration](https://doi.org/10.1145/3583780.3614860)|Zee Hen Tang, MiYen Yeh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EAGLE:+Enhance+Target-Oriented+Dialogs+by+Global+Planning+and+Topic+Flow+Integration)|0|
|[Spatio-Temporal Meta Contrastive Learning](https://doi.org/10.1145/3583780.3615065)|Jiabin Tang, Lianghao Xia, Jie Hu, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Meta+Contrastive+Learning)|0|
|[Single-Cell Multimodal Prediction via Transformers](https://doi.org/10.1145/3583780.3615061)|Wenzhuo Tang, Hongzhi Wen, Renming Liu, Jiayuan Ding, Wei Jin, Yuying Xie, Hui Liu, Jiliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Single-Cell+Multimodal+Prediction+via+Transformers)|0|
|[Explainable Spatio-Temporal Graph Neural Networks](https://doi.org/10.1145/3583780.3614871)|Jiabin Tang, Lianghao Xia, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Spatio-Temporal+Graph+Neural+Networks)|0|
|[PSLF: Defending Against Label Leakage in Split Learning](https://doi.org/10.1145/3583780.3615019)|Xinwei Wan, Jiankai Sun, Shengjie Wang, Lei Chen, Zhenzhe Zheng, Fan Wu, Guihai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PSLF:+Defending+Against+Label+Leakage+in+Split+Learning)|0|
|[GraphFADE: Field-aware Decorrelation Neural Network for Graphs with Tabular Features](https://doi.org/10.1145/3583780.3614900)|Junhong Wan, Yao Fu, Junlan Yu, Weihao Jiang, Shiliang Pu, Ruiheng Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphFADE:+Field-aware+Decorrelation+Neural+Network+for+Graphs+with+Tabular+Features)|0|
|[MPerformer: An SE(3) Transformer-based Molecular Perceptron](https://doi.org/10.1145/3583780.3614974)|Fanmeng Wang, Hongteng Xu, Xi Chen, Shuqi Lu, Yuqing Deng, Wenbing Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MPerformer:+An+SE(3)+Transformer-based+Molecular+Perceptron)|0|
|[Iteratively Learning Representations for Unseen Entities with Inter-Rule Correlations](https://doi.org/10.1145/3583780.3614938)|Zihan Wang, Kai Zhao, Yongquan He, Zhumin Chen, Pengjie Ren, Maarten de Rijke, Zhaochun Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Iteratively+Learning+Representations+for+Unseen+Entities+with+Inter-Rule+Correlations)|0|
|[UrbanFloodKG: An Urban Flood Knowledge Graph System for Risk Assessment](https://doi.org/10.1145/3583780.3615105)|Yu Wang, Feng Ye, Binquan Li, Gaoyang Jin, Dong Xu, Fengsheng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UrbanFloodKG:+An+Urban+Flood+Knowledge+Graph+System+for+Risk+Assessment)|0|
|[Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations](https://doi.org/10.1145/3583780.3614885)|Yongjie Wang, Hangwei Qian, Yongjie Liu, Wei Guo, Chunyan Miao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flexible+and+Robust+Counterfactual+Explanations+with+Minimal+Satisfiable+Perturbations)|0|
|[Low-bit Quantization for Deep Graph Neural Networks with Smoothness-aware Message Propagation](https://doi.org/10.1145/3583780.3614955)|Shuang Wang, Bahaeddin Eravci, Rustam Guliyev, Hakan Ferhatosmanoglu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low-bit+Quantization+for+Deep+Graph+Neural+Networks+with+Smoothness-aware+Message+Propagation)|0|
|[A Mix-up Strategy to Enhance Adversarial Training with Imbalanced Data](https://doi.org/10.1145/3583780.3614762)|Wentao Wang, Harry Shomer, Yuxuan Wan, Yaxin Li, Jiangtao Huang, Hui Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Mix-up+Strategy+to+Enhance+Adversarial+Training+with+Imbalanced+Data)|0|
|[NOVO: Learnable and Interpretable Document Identifiers for Model-Based IR](https://doi.org/10.1145/3583780.3614993)|Zihan Wang, Yujia Zhou, Yiteng Tu, Zhicheng Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NOVO:+Learnable+and+Interpretable+Document+Identifiers+for+Model-Based+IR)|0|
|[WOT-Class: Weakly Supervised Open-world Text Classification](https://doi.org/10.1145/3583780.3615109)|Tianle Wang, Zihan Wang, Weitang Liu, Jingbo Shang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WOT-Class:+Weakly+Supervised+Open-world+Text+Classification)|0|
|[Selecting Top-k Data Science Models by Example Dataset](https://doi.org/10.1145/3583780.3615051)|Mengying Wang, Sheng Guan, Hanchao Ma, Yiyang Bian, Haolai Che, Abhishek Daundkar, Alp Sehirlioglu, Yinghui Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Selecting+Top-k+Data+Science+Models+by+Example+Dataset)|0|
|[A Multi-Modality Framework for Drug-Drug Interaction Prediction by Harnessing Multi-source Data](https://doi.org/10.1145/3583780.3614765)|Qianlong Wen, Jiazheng Li, Chuxu Zhang, Yanfang Ye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Modality+Framework+for+Drug-Drug+Interaction+Prediction+by+Harnessing+Multi-source+Data)|0|
|[Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News Detection](https://doi.org/10.1145/3583780.3615015)|Jiaying Wu, Shen Li, Ailin Deng, Miao Xiong, Bryan Hooi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-and-Align:+Prompt-Based+Social+Alignment+for+Few-Shot+Fake+News+Detection)|0|
|[Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction](https://doi.org/10.1145/3583780.3614818)|Yang Wu, Xurui Li, Xuhong Zhang, Yangyang Kang, Changlong Sun, Xiaozhong Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Community-Based+Hierarchical+Positive-Unlabeled+(PU)+Model+Fusion+for+Chronic+Disease+Prediction)|0|
|[Rethinking Sentiment Analysis under Uncertainty](https://doi.org/10.1145/3583780.3615034)|Yuefei Wu, Bin Shi, Jiarun Chen, Yuhang Liu, Bo Dong, Qinghua Zheng, Hua Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Sentiment+Analysis+under+Uncertainty)|0|
|[HiPo: Detecting Fake News via Historical and Multi-Modal Analyses of Social Media Posts](https://doi.org/10.1145/3583780.3614914)|Tianshu Xiao, Sichang Guo, Jingcheng Huang, Riccardo Spolaor, Xiuzhen Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiPo:+Detecting+Fake+News+via+Historical+and+Multi-Modal+Analyses+of+Social+Media+Posts)|0|
|[An Efficient Selective Ensemble Learning with Rejection Approach for Classification](https://doi.org/10.1145/3583780.3614780)|Hao Xu, Chiranjeet Chetia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Selective+Ensemble+Learning+with+Rejection+Approach+for+Classification)|0|
|[Density-Aware Temporal Attentive Step-wise Diffusion Model For Medical Time Series Imputation](https://doi.org/10.1145/3583780.3614840)|Jingwen Xu, Fei Lyu, Pong C. Yuen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Density-Aware+Temporal+Attentive+Step-wise+Diffusion+Model+For+Medical+Time+Series+Imputation)|0|
|[Minimizing Polarization in Noisy Leader-Follower Opinion Dynamics](https://doi.org/10.1145/3583780.3614968)|Wanyue Xu, Zhongzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Minimizing+Polarization+in+Noisy+Leader-Follower+Opinion+Dynamics)|0|
|[Time-series Shapelets with Learnable Lengths](https://doi.org/10.1145/3583780.3615082)|Akihiro Yamaguchi, Ken Ueno, Hisashi Kashima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-series+Shapelets+with+Learnable+Lengths)|0|
|[Few-Shot Learning via Task-Aware Discriminant Local Descriptors Network](https://doi.org/10.1145/3583780.3614883)|Leilei Yan, Fanzhang Li, Xiaohan Zheng, Li Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-Shot+Learning+via+Task-Aware+Discriminant+Local+Descriptors+Network)|0|
|[A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge](https://doi.org/10.1145/3583780.3614758)|Kailai Yang, Tianlin Zhang, Shaoxiong Ji, Sophia Ananiadou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Bipartite+Graph+is+All+We+Need+for+Enhancing+Emotional+Reasoning+with+Commonsense+Knowledge)|0|
|[CARPG: Cross-City Knowledge Transfer for Traffic Accident Prediction via Attentive Region-Level Parameter Generation](https://doi.org/10.1145/3583780.3614802)|Guang Yang, Yuequn Zhang, Jinquan Hang, Xinyue Feng, Zejun Xie, Desheng Zhang, Yu Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CARPG:+Cross-City+Knowledge+Transfer+for+Traffic+Accident+Prediction+via+Attentive+Region-Level+Parameter+Generation)|0|
|[Group Identification via Transitional Hypergraph Convolution with Cross-view Self-supervised Learning](https://doi.org/10.1145/3583780.3614902)|Mingdai Yang, Zhiwei Liu, Liangwei Yang, Xiaolong Liu, Chen Wang, Hao Peng, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Group+Identification+via+Transitional+Hypergraph+Convolution+with+Cross-view+Self-supervised+Learning)|0|
|[Mulco: Recognizing Chinese Nested Named Entities through Multiple Scopes](https://doi.org/10.1145/3583780.3615026)|Jiuding Yang, Jinwen Luo, Weidong Guo, Jerry Chen, Di Niu, Yu Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mulco:+Recognizing+Chinese+Nested+Named+Entities+through+Multiple+Scopes)|0|
|[FINRule: Feature Interactive Neural Rule Learning](https://doi.org/10.1145/3583780.3614884)|Lu Yu, Meng Li, YaLin Zhang, Longfei Li, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FINRule:+Feature+Interactive+Neural+Rule+Learning)|0|
|[MUSE: Multi-view Contrastive Learning for Heterophilic Graphs via Information Reconstruction](https://doi.org/10.1145/3583780.3614985)|Mengyi Yuan, Minjie Chen, Xiang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MUSE:+Multi-view+Contrastive+Learning+for+Heterophilic+Graphs+via+Information+Reconstruction)|0|
|[Target-Oriented Maneuver Decision for Autonomous Vehicle: A Rule-Aided Reinforcement Learning Framework](https://doi.org/10.1145/3583780.3615072)|Ximu Zeng, Quanlin Yu, Shuncheng Liu, Yuyang Xia, Han Su, Kai Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Target-Oriented+Maneuver+Decision+for+Autonomous+Vehicle:+A+Rule-Aided+Reinforcement+Learning+Framework)|0|
|[AKE-GNN: Effective Graph Learning with Adaptive Knowledge Exchange](https://doi.org/10.1145/3583780.3614778)|Liang Zeng, Jin Xu, Zijun Yao, Yanqiao Zhu, Jian Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AKE-GNN:+Effective+Graph+Learning+with+Adaptive+Knowledge+Exchange)|0|
|[DYANE: DYnamic Attributed Node rolEs Generative Model](https://doi.org/10.1145/3583780.3614858)|Giselle Zeno, Jennifer Neville||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DYANE:+DYnamic+Attributed+Node+rolEs+Generative+Model)|0|
|[TriD-MAE: A Generic Pre-trained Model for Multivariate Time Series with Missing Values](https://doi.org/10.1145/3583780.3615097)|Kai Zhang, Chao Li, Qinmin Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TriD-MAE:+A+Generic+Pre-trained+Model+for+Multivariate+Time+Series+with+Missing+Values)|0|
|[RDGSL: Dynamic Graph Representation Learning with Structure Learning](https://doi.org/10.1145/3583780.3615023)|Siwei Zhang, Yun Xiong, Yao Zhang, Yiheng Sun, Xi Chen, Yizhu Jiao, Yangyong Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RDGSL:+Dynamic+Graph+Representation+Learning+with+Structure+Learning)|0|
|[PromptST: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction](https://doi.org/10.1145/3583780.3615016)|Zijian Zhang, Xiangyu Zhao, Qidong Liu, Chunxu Zhang, Qian Ma, Wanyu Wang, Hongwei Zhao, Yiqi Wang, Zitao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PromptST:+Prompt-Enhanced+Spatio-Temporal+Multi-Attribute+Prediction)|0|
|[Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection](https://doi.org/10.1145/3583780.3615002)|Shijie Zhang, Xin Yan, Xuejiao Yang, Binfeng Jia, Shuangyang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Out+of+the+Box+Thinking:+Improving+Customer+Lifetime+Value+Modelling+via+Expert+Routing+and+Game+Whale+Detection)|0|
|[No Length Left Behind: Enhancing Knowledge Tracing for Modeling Sequences of Excessive or Insufficient Lengths](https://doi.org/10.1145/3583780.3614988)|Moyu Zhang, Xinning Zhu, Chunhong Zhang, Feng Pan, Wenchen Qian, Hui Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=No+Length+Left+Behind:+Enhancing+Knowledge+Tracing+for+Modeling+Sequences+of+Excessive+or+Insufficient+Lengths)|0|
|[Counterfactual Monotonic Knowledge Tracing for Assessing Students' Dynamic Mastery of Knowledge Concepts](https://doi.org/10.1145/3583780.3614827)|Moyu Zhang, Xinning Zhu, Chunhong Zhang, Wenchen Qian, Feng Pan, Hui Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Monotonic+Knowledge+Tracing+for+Assessing+Students'+Dynamic+Mastery+of+Knowledge+Concepts)|0|
|[Non-IID always Bad? Semi-Supervised Heterogeneous Federated Learning with Local Knowledge Enhancement](https://doi.org/10.1145/3583780.3614991)|Chao Zhang, Fangzhao Wu, Jingwei Yi, Derong Xu, Yang Yu, Jindong Wang, Yidong Wang, Tong Xu, Xing Xie, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-IID+always+Bad?+Semi-Supervised+Heterogeneous+Federated+Learning+with+Local+Knowledge+Enhancement)|0|
|[Mutual Information-Driven Multi-View Clustering](https://doi.org/10.1145/3583780.3614986)|Lei Zhang, Lele Fu, Tong Wang, Chuan Chen, Chuanfu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mutual+Information-Driven+Multi-View+Clustering)|0|
|[Closed-form Machine Unlearning for Matrix Factorization](https://doi.org/10.1145/3583780.3614811)|Shuijing Zhang, Jian Lou, Li Xiong, Xiaoyu Zhang, Jing Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Closed-form+Machine+Unlearning+for+Matrix+Factorization)|0|
|[Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs](https://doi.org/10.1145/3583780.3615081)|Haozhen Zhang, Xueting Han, Xi Xiao, Jing Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-aware+Graph+Structure+Learning+via+Sequence+Prediction+on+Temporal+Graphs)|0|
|[Mask- and Contrast-Enhanced Spatio-Temporal Learning for Urban Flow Prediction](https://doi.org/10.1145/3583780.3614958)|Xu Zhang, Yongshun Gong, Xinxin Zhang, Xiaoming Wu, Chengqi Zhang, Xiangjun Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mask-+and+Contrast-Enhanced+Spatio-Temporal+Learning+for+Urban+Flow+Prediction)|0|
|[A Co-training Approach for Noisy Time Series Learning](https://doi.org/10.1145/3583780.3614759)|Weiqi Zhang, Jianfeng Zhang, Jia Li, Fugee Tsung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Co-training+Approach+for+Noisy+Time+Series+Learning)|0|
|[Unleashing the Power of Shared Label Structures for Human Activity Recognition](https://doi.org/10.1145/3583780.3615101)|Xiyuan Zhang, Ranak Roy Chowdhury, Jiayun Zhang, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unleashing+the+Power+of+Shared+Label+Structures+for+Human+Activity+Recognition)|0|
|[AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities](https://doi.org/10.1145/3583780.3614782)|Jingdan Zhang, Jiaan Wang, Xiaodan Wang, Zhixu Li, Yanghua Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AspectMMKG:+A+Multi-modal+Knowledge+Graph+with+Aspect-aware+Entities)|0|
|[Towards Dynamic and Reliable Private Key Management for Hierarchical Access Structure in Decentralized Storage](https://doi.org/10.1145/3583780.3615090)|Yifang Zhang, Mingyue Wang, Yu Guo, Fangda Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Dynamic+and+Reliable+Private+Key+Management+for+Hierarchical+Access+Structure+in+Decentralized+Storage)|0|
|[MLPST: MLP is All You Need for Spatio-Temporal Prediction](https://doi.org/10.1145/3583780.3614969)|Zijian Zhang, Ze Huang, Zhiwei Hu, Xiangyu Zhao, Wanyu Wang, Zitao Liu, Junbo Zhang, S. Joe Qin, Hongwei Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MLPST:+MLP+is+All+You+Need+for+Spatio-Temporal+Prediction)|0|
|[Geometric Graph Learning for Protein Mutation Effect Prediction](https://doi.org/10.1145/3583780.3614893)|Kangfei Zhao, Yu Rong, Biaobin Jiang, Jianheng Tang, Hengtong Zhang, Jeffrey Xu Yu, Peilin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+Graph+Learning+for+Protein+Mutation+Effect+Prediction)|0|
|[Simulating Student Interactions with Two-stage Imitation Learning for Intelligent Educational Systems](https://doi.org/10.1145/3583780.3615060)|Guanhao Zhao, Zhenya Huang, Yan Zhuang, Jiayu Liu, Qi Liu, Zhiding Liu, Jinze Wu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simulating+Student+Interactions+with+Two-stage+Imitation+Learning+for+Intelligent+Educational+Systems)|0|
|[Highly-Optimized Forgetting for Creating Signature-Based Views of Ontologies](https://doi.org/10.1145/3583780.3614771)|Yizheng Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Highly-Optimized+Forgetting+for+Creating+Signature-Based+Views+of+Ontologies)|0|
|[Unveiling the Role of Message Passing in Dual-Privacy Preservation on GNNs](https://doi.org/10.1145/3583780.3615104)|Tianyi Zhao, Hui Hu, Lu Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+the+Role+of+Message+Passing+in+Dual-Privacy+Preservation+on+GNNs)|0|
|[DiffUFlow: Robust Fine-grained Urban Flow Inference with Denoising Diffusion Model](https://doi.org/10.1145/3583780.3614842)|Yuhao Zheng, Lian Zhong, Senzhang Wang, Yu Yang, Weixi Gu, Junbo Zhang, Jianxin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiffUFlow:+Robust+Fine-grained+Urban+Flow+Inference+with+Denoising+Diffusion+Model)|0|
|[Assessing the Continuous Causal Responses of Typhoon-related Weather on Human Mobility: An Empirical Study in Japan](https://doi.org/10.1145/3583780.3615513)|Zhiwen Zhang, Hongjun Wang, Zipei Fan, Ryosuke Shibasaki, Xuan Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+the+Continuous+Causal+Responses+of+Typhoon-related+Weather+on+Human+Mobility:+An+Empirical+Study+in+Japan)|0|
|[Learning Node Abnormality with Weak Supervision](https://doi.org/10.1145/3583780.3614950)|Qinghai Zhou, Kaize Ding, Huan Liu, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Node+Abnormality+with+Weak+Supervision)|0|
|[Privacy-Preserving Federated Learning via Disentanglement](https://doi.org/10.1145/3583780.3615014)|Wenjie Zhou, Piji Li, Zhaoyang Han, Xiaozhen Lu, Juan Li, Zhaochun Ren, Zhe Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Federated+Learning+via+Disentanglement)|0|
|[CANDY: A Causality-Driven Model for Hotel Dynamic Pricing](https://doi.org/10.1145/3583780.3614800)|Ruitao Zhu, Wendong Xiao, Yao Yu, Yizhi Yu, Zhenzhe Zheng, Ke Bu, Dong Li, Fan Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CANDY:+A+Causality-Driven+Model+for+Hotel+Dynamic+Pricing)|0|
|[FVW: Finding Valuable Weight on Deep Neural Network for Model Pruning](https://doi.org/10.1145/3583780.3614889)|Zhiyu Zhu, Huaming Chen, Zhibo Jin, Xinyi Wang, Jiayu Zhang, Minhui Xue, Qinghua Lu, Jun Shen, KimKwang Raymond Choo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FVW:+Finding+Valuable+Weight+on+Deep+Neural+Network+for+Model+Pruning)|0|
|[Fine-Grained Socioeconomic Prediction from Satellite Images with Distributional Adjustment](https://doi.org/10.1145/3583780.3615226)|Donghyun Ahn, Minhyuk Song, SeungEon Lee, Yubin Choi, Jihee Kim, Sangyoon Park, Hyunjoo Yang, Meeyoung Cha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fine-Grained+Socioeconomic+Prediction+from+Satellite+Images+with+Distributional+Adjustment)|0|
|[Logarithmic Dimension Reduction for Quantum Neural Networks](https://doi.org/10.1145/3583780.3615240)|Hankyul Baek, Soohyun Park, Joongheon Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logarithmic+Dimension+Reduction+for+Quantum+Neural+Networks)|0|
|[A Comparative Study of Reference Reliability in Multiple Language Editions of Wikipedia](https://doi.org/10.1145/3583780.3615254)|Aitolkyn Baigutanova, Diego SáezTrumper, Miriam Redi, Meeyoung Cha, Pablo Aragón||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Comparative+Study+of+Reference+Reliability+in+Multiple+Language+Editions+of+Wikipedia)|0|
|[Linkage Attack on Skeleton-based Motion Visualization](https://doi.org/10.1145/3583780.3615263)|Thomas Carr, Aidong Lu, Depeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Linkage+Attack+on+Skeleton-based+Motion+Visualization)|0|
|[Identify Risky Rules to Reduce Side Effects in Association Rule Hiding](https://doi.org/10.1145/3583780.3615259)|Peng Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identify+Risky+Rules+to+Reduce+Side+Effects+in+Association+Rule+Hiding)|0|
|[Patient Clustering via Integrated Profiling of Clinical and Digital Data](https://doi.org/10.1145/3583780.3615262)|Dongjin Choi, Andy Xiang, Ozgur Ozturk, Deep Shrestha, Barry L. Drake, Hamid Haidarian, Faizan Javed, Haesun Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Patient+Clustering+via+Integrated+Profiling+of+Clinical+and+Digital+Data)|0|
|[Reconciling Training and Evaluation Objectives in Location Agnostic Surrogate Explainers](https://doi.org/10.1145/3583780.3615284)|Matthew Clifford, Jonathan Erskine, Alexander Hepburn, Peter A. Flach, Raúl SantosRodríguez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reconciling+Training+and+Evaluation+Objectives+in+Location+Agnostic+Surrogate+Explainers)|0|
|[Efficient Variant Calling on Human Genome Sequences Using a GPU-Enabled Commodity Cluster](https://doi.org/10.1145/3583780.3615268)|Manas Jyoti Das, Khawar Shehzad, Praveen Rao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Variant+Calling+on+Human+Genome+Sequences+Using+a+GPU-Enabled+Commodity+Cluster)|0|
|[Self-supervised Learning and Graph Classification under Heterophily](https://doi.org/10.1145/3583780.3615166)|Yilin Ding, Zhen Liu, Hao Hao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+Learning+and+Graph+Classification+under+Heterophily)|0|
|[Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA](https://doi.org/10.1145/3583780.3615150)|Guanting Dong, Rumei Li, Sirui Wang, Yupeng Zhang, Yunsen Xian, Weiran Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+the+KB-Text+Gap:+Leveraging+Structured+Knowledge-aware+Pre-training+for+KBQA)|0|
|[Geometric Matrix Completion via Sylvester Multi-Graph Neural Network](https://doi.org/10.1145/3583780.3615170)|Boxin Du, Changhe Yuan, Fei Wang, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+Matrix+Completion+via+Sylvester+Multi-Graph+Neural+Network)|0|
|[Neighborhood Homophily-based Graph Convolutional Network](https://doi.org/10.1145/3583780.3615195)|Shengbo Gong, Jiajun Zhou, Chenxuan Xie, Qi Xuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighborhood+Homophily-based+Graph+Convolutional+Network)|0|
|[Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond](https://doi.org/10.1145/3583780.3615277)|Kalpa Gunaratna, Vijay Srinivasan, Hongxia Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+and+Accurate+Natural+Language+Understanding+for+Voice+Assistants+and+Beyond)|0|
|[Hateful Comment Detection and Hate Target Type Prediction for Video Comments](https://doi.org/10.1145/3583780.3615260)|Shrey Gupta, Pratyush Priyadarshi, Manish Gupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hateful+Comment+Detection+and+Hate+Target+Type+Prediction+for+Video+Comments)|0|
|[Latent Aspect Detection via Backtranslation Augmentation](https://doi.org/10.1145/3583780.3615205)|Farinam Hemmatizadeh, Christine Wong, Alice Yu, Hossein Fani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Latent+Aspect+Detection+via+Backtranslation+Augmentation)|0|
|[Stochastic Subgraph Neighborhood Pooling for Subgraph Classification](https://doi.org/10.1145/3583780.3615227)|Shweta Ann Jacob, Paul Louis, Amirali SalehiAbari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stochastic+Subgraph+Neighborhood+Pooling+for+Subgraph+Classification)|0|
|[Uncertainty Quantification via Spatial-Temporal Tweedie Model for Zero-inflated and Long-tail Travel Demand Prediction](https://doi.org/10.1145/3583780.3615215)|Xinke Jiang, Dingyi Zhuang, Xianghui Zhang, Hao Chen, Jiayuan Luo, Xiaowei Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty+Quantification+via+Spatial-Temporal+Tweedie+Model+for+Zero-inflated+and+Long-tail+Travel+Demand+Prediction)|0|
|[Effective Slogan Generation with Noise Perturbation](https://doi.org/10.1145/3583780.3615193)|Jongeun Kim, MinChung Kim, Taehwan Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Slogan+Generation+with+Noise+Perturbation)|0|
|[S-Mixup: Structural Mixup for Graph Neural Networks](https://doi.org/10.1145/3583780.3615280)|Junghurn Kim, Sukwon Yun, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=S-Mixup:+Structural+Mixup+for+Graph+Neural+Networks)|0|
|[Class Label-aware Graph Anomaly Detection](https://doi.org/10.1145/3583780.3615249)|Junghoon Kim, Yeonjun In, Kanghoon Yoon, Junmo Lee, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Class+Label-aware+Graph+Anomaly+Detection)|0|
|[Can a Chatbot be Useful in Childhood Cancer Survivorship? Development of a Chatbot for Survivors of Childhood Cancer](https://doi.org/10.1145/3583780.3615234)|Mirae Kim, Kyubum Hwang, Hayoung Oh, Heejin Kim, MinAh Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+a+Chatbot+be+Useful+in+Childhood+Cancer+Survivorship?+Development+of+a+Chatbot+for+Survivors+of+Childhood+Cancer)|0|
|[You're Not Alone in Battle: Combat Threat Analysis Using Attention Networks and a New Open Benchmark](https://doi.org/10.1145/3583780.3615196)|Soo Yong Lee, Juwon Kim, Kiwoong Park, Dong Kuk Ryu, Sang Heun Shim, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You're+Not+Alone+in+Battle:+Combat+Threat+Analysis+Using+Attention+Networks+and+a+New+Open+Benchmark)|0|
|[Look At Me, No Replay! SurpriseNet: Anomaly Detection Inspired Class Incremental Learning](https://doi.org/10.1145/3583780.3615236)|Anton Lee, Yaqian Zhang, Heitor Murilo Gomes, Albert Bifet, Bernhard Pfahringer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Look+At+Me,+No+Replay!+SurpriseNet:+Anomaly+Detection+Inspired+Class+Incremental+Learning)|0|
|[UNDO: Effective and Accurate Unlearning Method for Deep Neural Networks](https://doi.org/10.1145/3583780.3615235)|Sangyong Lee, Simon S. Woo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UNDO:+Effective+and+Accurate+Unlearning+Method+for+Deep+Neural+Networks)|0|
|[ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal](https://doi.org/10.1145/3583780.3615168)|Hojoon Lee, Hawon Jeong, Byungkun Lee, Kyungyup Daniel Lee, Jaegul Choo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ST-RAP:+A+Spatio-Temporal+Framework+for+Real+Estate+Appraisal)|0|
|[Temporal and Topological Augmentation-based Cross-view Contrastive Learning Model for Temporal Link Prediction](https://doi.org/10.1145/3583780.3615231)|Dongyuan Li, Shiyin Tan, Yusong Wang, Kotaro Funakoshi, Manabu Okumura||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+and+Topological+Augmentation-based+Cross-view+Contrastive+Learning+Model+for+Temporal+Link+Prediction)|0|
|[CORD: A Three-Stage Coarse-to-Fine Framework for Relation Detection in Knowledge Base Question Answering](https://doi.org/10.1145/3583780.3615178)|Yanzeng Li, Sen Hu, Wenjuan Han, Lei Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CORD:+A+Three-Stage+Coarse-to-Fine+Framework+for+Relation+Detection+in+Knowledge+Base+Question+Answering)|0|
|[Homogeneous Cohort-Aware Group Cognitive Diagnosis: A Multi-grained Modeling Perspective](https://doi.org/10.1145/3583780.3615287)|Shuhuan Liu, Xiaoshan Yu, Haiping Ma, Ziwen Wang, Chuan Qin, Xingyi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Homogeneous+Cohort-Aware+Group+Cognitive+Diagnosis:+A+Multi-grained+Modeling+Perspective)|0|
|[Epidemiology-aware Deep Learning for Infectious Disease Dynamics Prediction](https://doi.org/10.1145/3583780.3615139)|Mutong Liu, Yang Liu, Jiming Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Epidemiology-aware+Deep+Learning+for+Infectious+Disease+Dynamics+Prediction)|0|
|[Towards Trustworthy Rumor Detection with Interpretable Graph Structural Learning](https://doi.org/10.1145/3583780.3615228)|Leyuan Liu, Junyi Chen, Zhangtao Cheng, Wenxin Tai, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Trustworthy+Rumor+Detection+with+Interpretable+Graph+Structural+Learning)|0|
|[TemDep: Temporal Dependency Priority for Multivariate Time Series Prediction](https://doi.org/10.1145/3583780.3615164)|Shu Liu, Jiaheng Wang, Jiamin Chen, Jianliang Gao, Yuhui Zhong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TemDep:+Temporal+Dependency+Priority+for+Multivariate+Time+Series+Prediction)|0|
|[DCGNN: Dual-Channel Graph Neural Network for Social Bot Detection](https://doi.org/10.1145/3583780.3615237)|Nuoyan Lyu, Bingbing Xu, Fangda Guo, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DCGNN:+Dual-Channel+Graph+Neural+Network+for+Social+Bot+Detection)|0|
|[Contrastive Learning for Rumor Detection via Fitting Beta Mixture Model](https://doi.org/10.1145/3583780.3615138)|Jiachen Ma, Jing Dai, Yong Liu, Meng Han, Chunyu Ai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+for+Rumor+Detection+via+Fitting+Beta+Mixture+Model)|0|
|[Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem](https://doi.org/10.1145/3583780.3615151)|Kaito Majima, Shotaro Ishihara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+News-Centric+Crossword+Puzzles+As+A+Constraint+Satisfaction+and+Optimization+Problem)|0|
|[Age-Aware Guidance via Masking-Based Attention in Face Aging](https://doi.org/10.1145/3583780.3615183)|Junyeong Maeng, Kwanseok Oh, HeungIl Suk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Age-Aware+Guidance+via+Masking-Based+Attention+in+Face+Aging)|0|
|[Metapath-Guided Data-Augmentation For Knowledge Graphs](https://doi.org/10.1145/3583780.3615186)|Saurav Manchanda||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metapath-Guided+Data-Augmentation+For+Knowledge+Graphs)|0|
|[Learning Visibility Attention Graph Representation for Time Series Forecasting](https://doi.org/10.1145/3583780.3615289)|Shengzhong Mao, XiaoJun Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Visibility+Attention+Graph+Representation+for+Time+Series+Forecasting)|0|
|[A Robust Backward Compatibility Metric for Model Retraining](https://doi.org/10.1145/3583780.3615213)|Ryuta Matsuno, Keita Sakuma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Robust+Backward+Compatibility+Metric+for+Model+Retraining)|0|
|[Graph Contrastive Learning with Graph Info-Min](https://doi.org/10.1145/3583780.3615162)|En Meng, Yong Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+with+Graph+Info-Min)|0|
|[Generative Graph Augmentation for Minority Class in Fraud Detection](https://doi.org/10.1145/3583780.3615255)|Lin Meng, Hesham Mostafa, Marcel Nassar, Xiaonan Zhang, Jiawei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Graph+Augmentation+for+Minority+Class+in+Fraud+Detection)|0|
|[Efficient Differencing of System-level Provenance Graphs](https://doi.org/10.1145/3583780.3615171)|Yuta Nakamura, Iyad Kanj, Tanu Malik||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Differencing+of+System-level+Provenance+Graphs)|0|
|[Camaraderie: Content-based Knowledge Transfer for Medical Image Labelling using Supervised Autoencoders in a Decentralized Setting](https://doi.org/10.1145/3583780.3615216)|Advait Padhye, Shreeja Bhakat, Humaira Firdowse, Atharv Savarkar, Ganesh Ramakrishnan, Kshitij S. Jadhav||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Camaraderie:+Content-based+Knowledge+Transfer+for+Medical+Image+Labelling+using+Supervised+Autoencoders+in+a+Decentralized+Setting)|0|
|[Quantum Split Learning for Privacy-Preserving Information Management](https://doi.org/10.1145/3583780.3615144)|Soohyun Park, Hankyul Baek, Joongheon Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantum+Split+Learning+for+Privacy-Preserving+Information+Management)|0|
|[Quantitative Decomposition of Prediction Errors Revealing Multi-Cause Impacts: An Insightful Framework for MLOps](https://doi.org/10.1145/3583780.3615238)|Keita Sakuma, Ryuta Matsuno, Yoshio Kameda||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantitative+Decomposition+of+Prediction+Errors+Revealing+Multi-Cause+Impacts:+An+Insightful+Framework+for+MLOps)|0|
|[VN-Solver: Vision-based Neural Solver for Combinatorial Optimization over Graphs](https://doi.org/10.1145/3583780.3615156)|Mina Samizadeh, Guangmo Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VN-Solver:+Vision-based+Neural+Solver+for+Combinatorial+Optimization+over+Graphs)|0|
|[Findability: A Novel Measure of Information Accessibility](https://doi.org/10.1145/3583780.3615256)|Aman Sinha, Priyanshu Raj Mall, Dwaipayan Roy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Findability:+A+Novel+Measure+of+Information+Accessibility)|0|
|[Learning to Simulate Complex Physical Systems: A Case Study](https://doi.org/10.1145/3583780.3615169)|Jiasheng Shi, Fu Lin, Weixiong Rao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Simulate+Complex+Physical+Systems:+A+Case+Study)|0|
|[Higher-Order Peak Decomposition](https://doi.org/10.1145/3583780.3615209)|Xingyu Tan, Jingya Qian, Chen Chen, Sima Qing, Yanping Wu, Xiaoyang Wang, Wenjie Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Higher-Order+Peak+Decomposition)|0|
|[Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models](https://doi.org/10.1145/3583780.3615273)|Nancy Tyagi, Surjodeep Sarkar, Manas Gaur||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Knowledge+and+Reinforcement+Learning+for+Enhanced+Reliability+of+Language+Models)|0|
|[Clustering-property Matters: A Cluster-aware Network for Large Scale Multivariate Time Series Forecasting](https://doi.org/10.1145/3583780.3615253)|Yuan Wang, Zezhi Shao, Tao Sun, Chengqing Yu, Yongjun Xu, Fei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clustering-property+Matters:+A+Cluster-aware+Network+for+Large+Scale+Multivariate+Time+Series+Forecasting)|0|
|[Adaptive Graph Neural Diffusion for Traffic Demand Forecasting](https://doi.org/10.1145/3583780.3615153)|Yiling Wu, Xinfeng Zhang, Yaowei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Graph+Neural+Diffusion+for+Traffic+Demand+Forecasting)|0|
|[Promoting Diversity in Mixed Complex Cooperative and Competitive Multi-Agent Environment](https://doi.org/10.1145/3583780.3615217)|Jia Wu, Zixiao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Promoting+Diversity+in+Mixed+Complex+Cooperative+and+Competitive+Multi-Agent+Environment)|0|
|[MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction](https://doi.org/10.1145/3583780.3615190)|Jie Yang, Soyeon Caren Han, Siqu Long, Josiah Poon, Goran Nenadic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MC-DRE:+Multi-Aspect+Cross+Integration+for+Drug+Event/Entity+Extraction)|0|
|[Positive-Unlabeled Node Classification with Structure-aware Graph Learning](https://doi.org/10.1145/3583780.3615250)|Hansi Yang, Yongqi Zhang, Quanming Yao, James T. Kwok||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Positive-Unlabeled+Node+Classification+with+Structure-aware+Graph+Learning)|0|
|[Toward a Foundation Model for Time Series Data](https://doi.org/10.1145/3583780.3615155)|ChinChia Michael Yeh, Xin Dai, Huiyuan Chen, Yan Zheng, Yujie Fan, Audrey Der, Vivian Lai, Zhongfang Zhuang, Junpeng Wang, Liang Wang, Wei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+a+Foundation+Model+for+Time+Series+Data)|0|
|[Simplex2vec Backward: From Vectors Back to Simplicial Complex](https://doi.org/10.1145/3583780.3615147)|Huixin Zhan, Kun Zhang, Zhong Chen, Victor S. Sheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simplex2vec+Backward:+From+Vectors+Back+to+Simplicial+Complex)|0|
|[Unlocking the Potential of Deep Learning in Peak-Hour Series Forecasting](https://doi.org/10.1145/3583780.3615159)|Zhenwei Zhang, Xin Wang, Jingyuan Xie, Heling Zhang, Yuantao Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Potential+of+Deep+Learning+in+Peak-Hour+Series+Forecasting)|0|
|[POSPAN: Position-Constrained Span Masking for Language Model Pre-training](https://doi.org/10.1145/3583780.3615197)|Zhenyu Zhang, Lei Shen, Yuming Zhao, Meng Chen, Xiaodong He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=POSPAN:+Position-Constrained+Span+Masking+for+Language+Model+Pre-training)|0|
|[Knowledge Graph Error Detection with Hierarchical Path Structure](https://doi.org/10.1145/3583780.3615201)|Zhao Zhang, Fuwei Zhang, Fuzhen Zhuang, Yongjun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Error+Detection+with+Hierarchical+Path+Structure)|0|
|[XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters](https://doi.org/10.1145/3583780.3615285)|Xuanyu Zhang, Qing Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XuanYuan+2.0:+A+Large+Chinese+Financial+Chat+Model+with+Hundreds+of+Billions+Parameters)|0|
|[Weight Matters: An Empirical Investigation of Distance Oracles on Knowledge Graphs](https://doi.org/10.1145/3583780.3615246)|Ke Zhang, Jiageng Chen, Zixian Huang, Gong Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weight+Matters:+An+Empirical+Investigation+of+Distance+Oracles+on+Knowledge+Graphs)|0|
|[FCT-GAN: Enhancing Global Correlation of Table Synthesis via Fourier Transform](https://doi.org/10.1145/3583780.3615202)|Zilong Zhao, Robert Birke, Lydia Y. Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FCT-GAN:+Enhancing+Global+Correlation+of+Table+Synthesis+via+Fourier+Transform)|0|
|[A Semi-Supervised Anomaly Network Traffic Detection Framework via Multimodal Traffic Information Fusion](https://doi.org/10.1145/3583780.3615214)|Yu Zheng, Xinglin Lian, Zhangxuan Dang, Chunlei Peng, Chao Yang, Jianfeng Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Semi-Supervised+Anomaly+Network+Traffic+Detection+Framework+via+Multimodal+Traffic+Information+Fusion)|0|
|[Nowcast-to-Forecast: Token-Based Multiple Remote Sensing Data Fusion for Precipitation Forecast](https://doi.org/10.1145/3583780.3614702)|Sojung An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nowcast-to-Forecast:+Token-Based+Multiple+Remote+Sensing+Data+Fusion+for+Precipitation+Forecast)|0|
|[CallMine: Fraud Detection and Visualization of Million-Scale Call Graphs](https://doi.org/10.1145/3583780.3614662)|Mirela Teixeira Cazzolato, Saranya Vijayakumar, MengChieh Lee, Catalina Vajiac, Namyong Park, Pedro Fidalgo, Agma J. M. Traina, Christos Faloutsos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CallMine:+Fraud+Detection+and+Visualization+of+Million-Scale+Call+Graphs)|0|
|[Continually-Adaptive Representation Learning Framework for Time-Sensitive Healthcare Applications](https://doi.org/10.1145/3583780.3615464)|Akash Choudhuri, Hankyu Jang, Alberto M. Segre, Philip M. Polgreen, Kishlay Jha, Bijaya Adhikari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continually-Adaptive+Representation+Learning+Framework+for+Time-Sensitive+Healthcare+Applications)|0|
|[Content-Based Email Classification at Scale](https://doi.org/10.1145/3583780.3615462)|Kirstin Early, Neil O'Hare, Christopher C. LuVogt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Content-Based+Email+Classification+at+Scale)|0|
|[AutoBuild: Automatic Community Building Labeling for Last-mile Delivery](https://doi.org/10.1145/3583780.3614658)|Zhiqing Hong, Dongjiang Cao, Haotian Wang, Guang Wang, Tian He, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoBuild:+Automatic+Community+Building+Labeling+for+Last-mile+Delivery)|0|
|[Urban-scale POI Updating with Crowd Intelligence](https://doi.org/10.1145/3583780.3614724)|Zhiqing Hong, Haotian Wang, Wenjun Lyu, Hai Wang, Yunhuai Liu, Guang Wang, Tian He, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Urban-scale+POI+Updating+with+Crowd+Intelligence)|0|
|[Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles](https://doi.org/10.1145/3583780.3615460)|Soo Kyung Kim, Kalai Ramea, Salva Rühling Cachay, Haruki Hirasawa, Subhashis Hazarika, Dipti Hingmire, Peetak Mitra, Philip J. Rasch, Hansi A. Singh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Climate+Intervention+Analysis+using+AI+Model+Guided+by+Statistical+Physics+Principles)|0|
|[A Hierarchical Imitation Learning-based Decision Framework for Autonomous Driving](https://doi.org/10.1145/3583780.3615454)|Hebin Liang, Zibin Dong, Yi Ma, Xiaotian Hao, Yan Zheng, Jianye Hao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hierarchical+Imitation+Learning-based+Decision+Framework+for+Autonomous+Driving)|0|
|[Enhancing Dynamic On-demand Food Order Dispatching via Future-informed and Spatial-temporal Extended Decisions](https://doi.org/10.1145/3583780.3615473)|Yile Liang, Donghui Li, Jiuxia Zhao, Xuetao Ding, Huanjia Lian, Jinghua Hao, Renqing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Dynamic+On-demand+Food+Order+Dispatching+via+Future-informed+and+Spatial-temporal+Extended+Decisions)|0|
|[FAF: A Risk Detection Framework on Industry-Scale Graphs](https://doi.org/10.1145/3583780.3615477)|Yice Luo, Guannan Wang, Yongchao Liu, Jiaxin Yue, Weihong Cheng, Binjie Fei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FAF:+A+Risk+Detection+Framework+on+Industry-Scale+Graphs)|0|
|[Retention is All You Need](https://doi.org/10.1145/3583780.3615497)|Karishma Mohiuddin, Mirza Ariful Alam, Mirza Mohtashim Alam, Pascal Welke, Michael Martin, Jens Lehmann, Sahar Vahdati||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retention+is+All+You+Need)|0|
|[GraphFC: Customs Fraud Detection with Label Scarcity](https://doi.org/10.1145/3583780.3614690)|Karandeep Singh, YuChe Tsai, ChengTe Li, Meeyoung Cha, ShouDe Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphFC:+Customs+Fraud+Detection+with+Label+Scarcity)|0|
|[Generating Optimized Molecules without Patent Infringement](https://doi.org/10.1145/3583780.3615479)|Sally Turutov, Kira Radinsky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Optimized+Molecules+without+Patent+Infringement)|0|
|[Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks](https://doi.org/10.1145/3583780.3615505)|Zhihao Wen, Yuan Fang, Yihan Liu, Yang Guo, Shuji Hao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Voucher+Abuse+Detection+with+Prompt-based+Fine-tuning+on+Graph+Neural+Networks)|0|
|[Logistics Audience Expansion via Temporal Knowledge Graph](https://doi.org/10.1145/3583780.3614695)|Hua Yan, Yingqiang Ge, Haotian Wang, Desheng Zhang, Yu Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logistics+Audience+Expansion+via+Temporal+Knowledge+Graph)|0|
|[DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions](https://doi.org/10.1145/3583780.3614671)|Jinhui Yi, Huan Yan, Haotian Wang, Jian Yuan, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeepSTA:+A+Spatial-Temporal+Attention+Network+for+Logistics+Delivery+Timely+Rate+Prediction+in+Anomaly+Conditions)|0|
|[Detecting Social Bot on the Fly using Contrastive Learning](https://doi.org/10.1145/3583780.3615468)|Ming Zhou, Dan Zhang, Yuandong Wang, YangliAo Geng, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Social+Bot+on+the+Fly+using+Contrastive+Learning)|0|
|[SNAKE Challenge: Sanitization Algorithms under Attack](https://doi.org/10.1145/3583780.3614754)|Tristan Allard, Louis Béziaud, Sébastien Gambs||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SNAKE+Challenge:+Sanitization+Algorithms+under+Attack)|0|
|[AQUAPLANE: The Argument Quality Explainer App](https://doi.org/10.1145/3583780.3614733)|Sebastian Britner, Lorik Dumani, Ralf Schenkel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AQUAPLANE:+The+Argument+Quality+Explainer+App)|0|
|[Contrastive Keyword Extraction from Versioned Documents](https://doi.org/10.1145/3583780.3614735)|Lukas Eder, Ricardo Campos, Adam Jatowt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Keyword+Extraction+from+Versioned+Documents)|0|
|[ParkFlow: Intelligent Dispersal for Mitigating Parking Shortages Using Multi-Granular Spatial-Temporal Analysis](https://doi.org/10.1145/3583780.3614751)|Yang Fan Chiang, ChunWei Shen, JheWei Tsai, PeiXuan Li, TzuChang Lee, HsunPing Hsieh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ParkFlow:+Intelligent+Dispersal+for+Mitigating+Parking+Shortages+Using+Multi-Granular+Spatial-Temporal+Analysis)|0|
|[The µ-RA System for Recursive Path Queries over Graphs](https://doi.org/10.1145/3583780.3614756)|Amela Fejza, Pierre Genevès, Nabil Layaïda, Sarah Chlyah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+µ-RA+System+for+Recursive+Path+Queries+over+Graphs)|0|
|[DataDoc Analyzer: A Tool for Analyzing the Documentation of Scientific Datasets](https://doi.org/10.1145/3583780.3614737)|Joan GinerMiguelez, Abel Gómez, Jordi Cabot||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DataDoc+Analyzer:+A+Tool+for+Analyzing+the+Documentation+of+Scientific+Datasets)|0|
|[MORPHER: Structural Transformation of Ill-formed Rows](https://doi.org/10.1145/3583780.3614747)|Mazhar Hameed, Gerardo Vitagliano, Felix Naumann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MORPHER:+Structural+Transformation+of+Ill-formed+Rows)|0|
|[LARCH: Large Language Model-based Automatic Readme Creation with Heuristics](https://doi.org/10.1145/3583780.3614744)|Yuta Koreeda, Terufumi Morishita, Osamu Imaichi, Yasuhiro Sogawa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LARCH:+Large+Language+Model-based+Automatic+Readme+Creation+with+Heuristics)|0|
|[CRUISE-Screening: Living Literature Reviews Toolbox](https://doi.org/10.1145/3583780.3614736)|Wojciech Kusa, Petr Knoth, Allan Hanbury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CRUISE-Screening:+Living+Literature+Reviews+Toolbox)|0|
|[HugNLP: A Unified and Comprehensive Library for Natural Language Processing](https://doi.org/10.1145/3583780.3614742)|Jianing Wang, Nuo Chen, Qiushi Sun, Wenkang Huang, Chengyu Wang, Ming Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HugNLP:+A+Unified+and+Comprehensive+Library+for+Natural+Language+Processing)|0|
|[PyABSA: A Modularized Framework for Reproducible Aspect-based Sentiment Analysis](https://doi.org/10.1145/3583780.3614752)|Heng Yang, Chen Zhang, Ke Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PyABSA:+A+Modularized+Framework+for+Reproducible+Aspect-based+Sentiment+Analysis)|0|
|[NP-SSL: A Modular and Extensible Self-supervised Learning Library with Neural Processes](https://doi.org/10.1145/3583780.3614749)|Zesheng Ye, Jing Du, Yao Liu, Yihong Zhang, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NP-SSL:+A+Modular+and+Extensible+Self-supervised+Learning+Library+with+Neural+Processes)|0|
|[MOSS: AI Platform for Discovery of Corrosion-Resistant Materials](https://doi.org/10.1145/3583780.3614748)|Biao Yin, Nicholas Josselyn, Ziming Zhang, Elke A. Rundensteiner, Thomas A. Considine, John V. Kelley, Berend C. Rinderspacher, Robert E. Jensen, James F. Snyder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MOSS:+AI+Platform+for+Discovery+of+Corrosion-Resistant+Materials)|0|
|[Demonstration of ViTA: Visualizing, Testing and Analyzing Index Advisors](https://doi.org/10.1145/3583780.3614738)|Wei Zhou, Chen Lin, Xuanhe Zhou, Guoliang Li, Tianqing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demonstration+of+ViTA:+Visualizing,+Testing+and+Analyzing+Index+Advisors)|0|
|[An AI-based Simulation and Optimization Framework for Logistic Systems](https://doi.org/10.1145/3583780.3614732)|Zefang Zong, Huan Yan, Hongjie Sui, Haoxiang Li, Peiqi Jiang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+AI-based+Simulation+and+Optimization+Framework+for+Logistic+Systems)|0|
|[Data and Decision Fusion with Uncertainty Quantification for ML-based Healthcare Decision Systems](https://doi.org/10.1145/3583780.3616004)|Grigor Bezirganyan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+and+Decision+Fusion+with+Uncertainty+Quantification+for+ML-based+Healthcare+Decision+Systems)|0|
|[A Neuro-symbolic Approach to Enhance Interpretability of Graph Neural Network through the Integration of External Knowledge](https://doi.org/10.1145/3583780.3616008)|Kislay Raj||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Neuro-symbolic+Approach+to+Enhance+Interpretability+of+Graph+Neural+Network+through+the+Integration+of+External+Knowledge)|0|
|[Enhancing Badminton Player Performance via a Closed-Loop AI Approach: Imitation, Simulation, Optimization, and Execution](https://doi.org/10.1145/3583780.3616001)|KuangDa Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Badminton+Player+Performance+via+a+Closed-Loop+AI+Approach:+Imitation,+Simulation,+Optimization,+and+Execution)|0|
|[Exploiting Homeostatic Synaptic Modulation in Spiking Neural Networks for Semi-Supervised Graph Learning](https://doi.org/10.1145/3583780.3616000)|Mingkun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Homeostatic+Synaptic+Modulation+in+Spiking+Neural+Networks+for+Semi-Supervised+Graph+Learning)|0|
|[Some Useful Things to Know When Combining IR and NLP: the Easy, the Hard and the Ugly](https://doi.org/10.1145/3583780.3615295)|Omar Alonso, Kenneth Church||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Some+Useful+Things+to+Know+When+Combining+IR+and+NLP:+the+Easy,+the+Hard+and+the+Ugly)|0|
|[Application of Deep Clustering Algorithms](https://doi.org/10.1145/3583780.3615290)|Collin Leiber, Lukas Miklautz, Claudia Plant, Christian Böhm||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Application+of+Deep+Clustering+Algorithms)|0|
|[RT2S: A Framework for Learning with Noisy Labels](https://doi.org/10.1145/3583780.3615996)|Indranil Bhattacharya, Ze Ye, Kaushik Pavani, Sunny Dasgupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RT2S:+A+Framework+for+Learning+with+Noisy+Labels)|0|
|[Type Theory as a Unifying Paradigm for Modern Databases](https://doi.org/10.1145/3583780.3615999)|Christoph Dorn, Haikal Pribadi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Type+Theory+as+a+Unifying+Paradigm+for+Modern+Databases)|0|
|[Comparing Fine-Tuned Transformers and Large Language Models for Sales Call Classification: A Case Study](https://doi.org/10.1145/3583780.3615509)|Roy Eisenstadt, Abedelkader Asi, Royi Ronen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comparing+Fine-Tuned+Transformers+and+Large+Language+Models+for+Sales+Call+Classification:+A+Case+Study)|0|
|[Application and Evaluation of Large Language Models for the Generation of Survey Questions](https://doi.org/10.1145/3583780.3615506)|Antonio Maiorino, Zoe Padgett, Chun Wang, Misha Yakubovskiy, Peng Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Application+and+Evaluation+of+Large+Language+Models+for+the+Generation+of+Survey+Questions)|0|
|[Harnessing GPT for Topic-Based Call Segmentation in Microsoft Dynamics 365 Sales](https://doi.org/10.1145/3583780.3615508)|Itzik Malkiel, Uri Alon, Yakir Yehuda, Shahar Keren, Oren Barkan, Royi Ronen, Noam Koenigstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+GPT+for+Topic-Based+Call+Segmentation+in+Microsoft+Dynamics+365+Sales)|0|
|[Astrolabe: Visual Graph Database Queries with Tabular Output](https://doi.org/10.1145/3583780.3615992)|Michael Miller||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Astrolabe:+Visual+Graph+Database+Queries+with+Tabular+Output)|0|
|[LAMM: Language Aware Active Learning for Multilingual Models](https://doi.org/10.1145/3583780.3615507)|Ze Ye, Dantong Liu, Kaushik Pavani, Sunny Dasgupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LAMM:+Language+Aware+Active+Learning+for+Multilingual+Models)|0|
|[Unleashing the Power of Large Language Models for Legal Applications](https://doi.org/10.1145/3583780.3615993)|Dell Zhang, Alina Petrova, Dietrich Trautmann, Frank Schilder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unleashing+the+Power+of+Large+Language+Models+for+Legal+Applications)|0|
|[Info-Wild: Knowledge Extraction and Management for Wildlife Conservation](https://doi.org/10.1145/3583780.3615313)|Prasenjit Mitra, Shreya Ghosh, Bistra Dilkina, Thomas Müller||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Info-Wild:+Knowledge+Extraction+and+Management+for+Wildlife+Conservation)|0|
|[Anomaly and Novelty detection for Satellite and Drone systems (ANSD '23)](https://doi.org/10.1145/3583780.3615306)|Shahroz Tariq, Daewon Chung, Simon Woo, Youjin Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anomaly+and+Novelty+detection+for+Satellite+and+Drone+systems+(ANSD+'23))|0|
|[Knowledge-driven Analytics and Systems Impacting Human Quality of Life- Neurosymbolic AI, Explainable AI and Beyond](https://doi.org/10.1145/3583780.3615300)|Arijit Ukil, Joao Gama, Antonio J. Jara, Leandro Marín||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-driven+Analytics+and+Systems+Impacting+Human+Quality+of+Life-+Neurosymbolic+AI,+Explainable+AI+and+Beyond)|0|
|[Knowledge-enhanced Artificial Intelligence in Drug Discovery (KAIDD)](https://doi.org/10.1145/3583780.3615309)|Qingpeng Zhang, Jiannan Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-enhanced+Artificial+Intelligence+in+Drug+Discovery+(KAIDD))|0|
|[Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement](https://doi.org/10.1145/3583780.3615126)|Hang Dong, Jiaoyan Chen, Yuan He, Ian Horrocks||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ontology+Enrichment+from+Texts:+A+Biomedical+Dataset+for+Concept+Discovery+and+Placement)|0|
|[FlaCGEC: A Chinese Grammatical Error Correction Dataset with Fine-grained Linguistic Annotation](https://doi.org/10.1145/3583780.3615119)|Hanyue Du, Yike Zhao, Qingyuan Tian, Jiani Wang, Lei Wang, Yunshi Lan, Xuesong Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FlaCGEC:+A+Chinese+Grammatical+Error+Correction+Dataset+with+Fine-grained+Linguistic+Annotation)|0|
|[PGB: A PubMed Graph Benchmark for Heterogeneous Network Representation Learning](https://doi.org/10.1145/3583780.3615128)|Eric Wonhee Lee, Joyce C. Ho||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PGB:+A+PubMed+Graph+Benchmark+for+Heterogeneous+Network+Representation+Learning)|0|
|[CTCam: Enhancing Transportation Evaluation through Fusion of Cellular Traffic and Camera-Based Vehicle Flows](https://doi.org/10.1145/3583780.3615116)|ChungYi Lin, ShenLung Tung, HungTing Su, Winston H. Hsu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CTCam:+Enhancing+Transportation+Evaluation+through+Fusion+of+Cellular+Traffic+and+Camera-Based+Vehicle+Flows)|0|
|[Datasets and Interfaces for Benchmarking Heterogeneous Graph Neural Networks](https://doi.org/10.1145/3583780.3615117)|Yijian Liu, Hongyi Zhang, Cheng Yang, Ao Li, Yugang Ji, Luhao Zhang, Tao Li, Jinyu Yang, Tianyu Zhao, Juan Yang, Hai Huang, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Datasets+and+Interfaces+for+Benchmarking+Heterogeneous+Graph+Neural+Networks)|0|
|[ContributionSum: Generating Disentangled Contributions for Scientific Papers](https://doi.org/10.1145/3583780.3615115)|MengHuan Liu, AnZi Yen, HenHsen Huang, HsinHsi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ContributionSum:+Generating+Disentangled+Contributions+for+Scientific+Papers)|0|
|[ClinicalRisk: A New Therapy-related Clinical Trial Dataset for Predicting Trial Status and Failure Reasons](https://doi.org/10.1145/3583780.3615113)|Junyu Luo, Zhi Qiao, Lucas Glass, Cao Xiao, Fenglong Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ClinicalRisk:+A+New+Therapy-related+Clinical+Trial+Dataset+for+Predicting+Trial+Status+and+Failure+Reasons)|0|
|[ThyExp: An explainable AI-assisted Decision Making Toolkit for Thyroid Nodule Diagnosis based on Ultra-sound Images](https://doi.org/10.1145/3583780.3615131)|Jamie Morris, Zehao Liu, Huizhi Liang, Sidhartha Nagala, Xia Hong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ThyExp:+An+explainable+AI-assisted+Decision+Making+Toolkit+for+Thyroid+Nodule+Diagnosis+based+on+Ultra-sound+Images)|0|
|[GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Generation](https://doi.org/10.1145/3583780.3615120)|Ji Qi, Jifan Yu, Teng Tu, Kunyu Gao, Yifan Xu, Xinyu Guan, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GOAL:+A+Challenging+Knowledge-grounded+Video+Captioning+Benchmark+for+Real-time+Soccer+Commentary+Generation)|0|
|[DynamicESG: A Dataset for Dynamically Unearthing ESG Ratings from News Articles](https://doi.org/10.1145/3583780.3615118)|YuMin Tseng, ChungChi Chen, HenHsen Huang, HsinHsi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DynamicESG:+A+Dataset+for+Dynamically+Unearthing+ESG+Ratings+from+News+Articles)|0|
|[MDCC: A Multimodal Dynamic Dataset for Donation-based Crowdfunding Campaigns](https://doi.org/10.1145/3583780.3615124)|Xovee Xu, Jiayang Li, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDCC:+A+Multimodal+Dynamic+Dataset+for+Donation-based+Crowdfunding+Campaigns)|0|
|[Causality-guided Graph Learning for Session-based Recommendation](https://doi.org/10.1145/3583780.3614803)|Dianer Yu, Qian Li, Hongzhi Yin, Guandong Xu|University of Technology, Sydney, Sydney, NSW, Australia; University of Queensland, Brisbane, QLD, Australia; Curtin University, Perth, WA, Australia|Session-based recommendation systems (SBRs) aim to capture user preferences over time by taking into account the sequential order of interactions within sessions. One promising approach within this domain is session graph-based recommendation, which leverages graph-based models to represent and analyze user sessions. However, current graph-based methods for SBRs mainly rely on attention or pooling mechanisms that are prone to exploiting shortcut paths and thus lead to suboptimal recommendations. To address this issue, we propose Causality-guided Graph Learning for Session-based Recommendation (CGSR) that is capable of blocking shortcut paths on the session graph and exploring robust causal connections capturing users' true preferences. Specifically, by employing back-door adjustment of causality, we can generate a distilled causal session graph capturing causal relations among items. CGSR then performs high-order aggregation on the distilled graph, incorporating information from various edge types, to estimate the session preference of the user. This enables us to provide more accurate recommendations grounded in causality while offering fine-grained interaction explanations by highlighting influential items in the graph. Extensive experiments on three datasets show the superior performance of CGSR compared to state-of-the-art SBRs.|基于会话的推荐系统(SBRs)旨在通过考虑会话内交互的顺序顺序来获取用户的偏好。这个领域中一个很有前途的方法是基于会话图的推荐，它利用基于图的模型来表示和分析用户会话。然而，目前基于图表的 SBR 方法主要依赖于注意力或汇集机制，这些机制易于利用捷径，从而导致次优建议。为了解决这个问题，我们提出了基于因果关系的会话推荐图学习(CGSR) ，它能够阻塞会话图上的快捷路径，并探索捕捉用户真实偏好的健壮的因果关系。具体来说，通过因果关系的后门调整，我们可以生成一个提取的因果会话图，捕捉项目之间的因果关系。然后 CGSR 对提取的图进行高阶聚合，结合来自各种边缘类型的信息，以估计用户的会话偏好。这使我们能够提供更准确的建议，基于因果关系，同时提供细粒度的交互解释，突出显示图中有影响力的项目。在三个数据集上的大量实验表明，CGSR 的性能优于最先进的 SBR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality-guided+Graph+Learning+for+Session-based+Recommendation)|-1|
|[gFOV: A Full-Stack SPARQL Query Optimizer & Plan Visualizer](https://doi.org/10.1145/3583780.3614741)|Yue Pang, Linglin Yang, Lei Zou, M. Tamer Özsu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=gFOV:+A+Full-Stack+SPARQL+Query+Optimizer+&+Plan+Visualizer)|-1|
|[Semantic-aware Node Synthesis for Imbalanced Heterogeneous Information Networks](https://doi.org/10.1145/3583780.3615055)|Xinyi Gao, Wentao Zhang, Tong Chen, Junliang Yu, Nguyen Quoc Viet Hung, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic-aware+Node+Synthesis+for+Imbalanced+Heterogeneous+Information+Networks)|-1|
|[Unsupervised Aspect Term Extraction by Integrating Sentence-level Curriculum Learning with Token-level Self-paced Learning](https://doi.org/10.1145/3583780.3615103)|Jihong Ouyang, Zhiyao Yang, Chang Xuan, Bing Wang, Yiyuan Wang, Ximing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Aspect+Term+Extraction+by+Integrating+Sentence-level+Curriculum+Learning+with+Token-level+Self-paced+Learning)|-1|
|[Weak Regression Enhanced Lifelong Learning for Improved Performance and Reduced Training Data](https://doi.org/10.1145/3583780.3615108)|Tong Liu, Xulong Wang, He Huang, Po Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weak+Regression+Enhanced+Lifelong+Learning+for+Improved+Performance+and+Reduced+Training+Data)|-1|
|[Calibrate Graph Neural Networks under Out-of-Distribution Nodes via Deep Q-learning](https://doi.org/10.1145/3583780.3614797)|Weili Shi, Xueying Yang, Xujiang Zhao, Haifeng Chen, Zhiqiang Tao, Sheng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibrate+Graph+Neural+Networks+under+Out-of-Distribution+Nodes+via+Deep+Q-learning)|-1|
|[MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling](https://doi.org/10.1145/3583780.3614970)|Ziwei Yang, Zheng Chen, Yasuko Matsubara, Yasushi Sakurai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoCLIM:+Towards+Accurate+Cancer+Subtyping+via+Multi-Omics+Contrastive+Learning+with+Omics-Inference+Modeling)|-1|
|[RLIFE: Remaining Lifespan Prediction for E-scooters](https://doi.org/10.1145/3583780.3615037)|Shuxin Zhong, William Yubeaton, Wenjun Lyu, Guang Wang, Desheng Zhang, Yu Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RLIFE:+Remaining+Lifespan+Prediction+for+E-scooters)|-1|
|[Semi-supervised Curriculum Ensemble Learning for Financial Precision Marketing](https://doi.org/10.1145/3583780.3615251)|HsinYu Chen, ChengTe Li, TingYu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-supervised+Curriculum+Ensemble+Learning+for+Financial+Precision+Marketing)|-1|
|[A Deep Conditional Generative Approach for Constrained Community Detection](https://doi.org/10.1145/3583780.3615145)|Chaobo He, Junwei Cheng, Quanlong Guan, Xiang Fei, Hanchao Li, Yong Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Deep+Conditional+Generative+Approach+for+Constrained+Community+Detection)|-1|
|[Pseudo Triplet Networks for Classification Tasks with Cross-Source Feature Incompleteness](https://doi.org/10.1145/3583780.3615154)|Cayon Liow, ChengTe Li, ChunPai Yang, ShouDe Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pseudo+Triplet+Networks+for+Classification+Tasks+with+Cross-Source+Feature+Incompleteness)|-1|
|[Towards Understanding of Deepfake Videos in the Wild](https://doi.org/10.1145/3583780.3614729)|Beomsang Cho, Binh M. Le, Jiwon Kim, Simon S. Woo, Shahroz Tariq, Alsharif Abuadbba, Kristen Moore||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Understanding+of+Deepfake+Videos+in+the+Wild)|-1|
|[Commonsense Temporal Action Knowledge (CoTAK) Dataset](https://doi.org/10.1145/3583780.3615114)|Steven J. Lynden, Hailemariam Mehari Yohannes, KyoungSook Kim, Adam Jatowt, Akiyoshi Matono, HaiTao Yu, Xin Liu, Yijun Duan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Commonsense+Temporal+Action+Knowledge+(CoTAK)+Dataset)|-1|
