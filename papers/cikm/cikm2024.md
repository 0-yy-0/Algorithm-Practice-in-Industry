# CIKM2024 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Enhancing Click-through Rate Prediction in Recommendation Domain with Search Query Representation](https://doi.org/10.1145/3627673.3679849)|Yuening Wang, Man Chen, Yaochen Hu, Wei Guo, Yingxue Zhang, Huifeng Guo, Yong Liu, Mark Coates|McGill University, Montreal, Canada; Huawei Noah's Ark Lab, Shenzhen, China; Huawei Noah's Ark Lab, Singapore, Singapore; Huawei Noah's Ark Lab, Markham, Canada; Huawei Noah's Ark Lab, Montreal, Canada|Many platforms, such as e-commerce websites, offer both search and recommendation services simultaneously to better meet users' diverse needs. Recommendation services suggest items based on user preferences, while search services allow users to search for items before providing recommendations. Since users and items are often shared between the search and recommendation domains, there is a valuable opportunity to enhance the recommendation domain by leveraging user preferences extracted from the search domain. Existing approaches either overlook the shift in user intention between these domains or fail to capture the significant impact of learning from users' search queries on understanding their interests. In this paper, we propose a framework that learns from user search query embeddings within the context of user preferences in the recommendation domain. Specifically, user search query sequences from the search domain are used to predict the items users will click at the next time point in the recommendation domain. Additionally, the relationship between queries and items is explored through contrastive learning. To address issues of data sparsity, the diffusion model is incorporated to infer positive items the user will select after searching with certain queries in a denoising manner, which is particularly effective in preventing false positives. Effectively extracting this information, the queries are integrated into click-through rate prediction in the recommendation domain. Experimental analysis demonstrates that our model outperforms state-of-the-art models in the recommendation domain.|许多平台，如电子商务网站，同时提供搜索和推荐服务，以更好地满足用户多样化的需求。推荐服务根据用户的偏好推荐商品，而搜索服务则允许用户在提供推荐之前搜索商品。由于用户和商品通常在搜索和推荐领域之间共享，因此有机会通过利用从搜索领域提取的用户偏好来增强推荐领域。现有方法要么忽略了这两个领域之间用户意图的转变，要么未能捕捉到从用户搜索查询中学习对理解用户兴趣的重大影响。本文提出了一种框架，该框架在推荐领域的用户偏好背景下学习用户搜索查询嵌入。具体来说，使用搜索领域的用户搜索查询序列来预测用户在推荐领域中下一次点击的商品。此外，通过对比学习探索查询与商品之间的关系。为了解决数据稀疏性问题，采用了扩散模型以去噪方式推断用户在使用某些查询进行搜索后将选择的正向商品，这在防止误报方面特别有效。有效地提取这些信息后，将查询整合到推荐领域的点击率预测中。实验分析表明，我们的模型在推荐领域的表现优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Click-through+Rate+Prediction+in+Recommendation+Domain+with+Search+Query+Representation)|0|
|[Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation](https://doi.org/10.1145/3627673.3679728)|Hyunsik Jeon, Seeun Yoon, Julian J. McAuley||Calibrated recommendation, which aims to maintain personalized proportions of categories within recommendations, is crucial in practical scenarios since it enhances user satisfaction by reflecting diverse interests. However, achieving calibration in a sequential setting (i.e., calibrated sequential recommendation) is challenging due to the need to adapt to users' evolving preferences. Previous methods typically leverage reranking algorithms to calibrate recommendations after training a model without considering the effect of calibration and do not effectively tackle the conflict between relevance and calibration during the reranking process. In this work, we propose LeapRec (Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a novel approach for the calibrated sequential recommendation that addresses these challenges. LeapRec consists of two phases, model training phase and reranking phase. In the training phase, a backbone model is trained using our proposed calibration-disentangled learning-to-rank loss, which optimizes personalized rankings while integrating calibration considerations. In the reranking phase, relevant items are prioritized at the top of the list, with items needed for calibration following later to address potential conflicts between relevance and calibration. Through extensive experiments on four real-world datasets, we show that LeapRec consistently outperforms previous methods in the calibrated sequential recommendation. Our code is available at https://github.com/jeon185/LeapRec.|校准推荐旨在保持推荐中类别的个性化比例，这在实际场景中至关重要，因为它通过反映多样化的兴趣来增强用户满意度。然而，在序列环境中实现校准（即校准序列推荐）具有挑战性，因为需要适应用户不断变化的偏好。先前的方法通常利用重新排序算法在训练模型后进行推荐校准，而没有考虑校准效果，并且在重新排序过程中未能有效解决相关性与校准之间的冲突。在这项工作中，我们提出了LeapRec（校准解耦学习和相关性优先重新排序），这是一种新颖的校准序列推荐方法，旨在解决这些挑战。LeapRec包括两个阶段，模型训练阶段和重新排序阶段。在训练阶段，使用我们提出的校准解耦学习排序损失训练骨干模型，该损失在优化个性化排序的同时整合了校准考虑。在重新排序阶段，相关项目优先置于列表顶部，而需要校准的项目随后放置，以解决相关性与校准之间可能的冲突。通过在四个真实世界数据集上的广泛实验，我们展示了LeapRec在校准序列推荐方面始终优于先前的方法。我们的代码可在https://github.com/jeon185/LeapRec获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibration-Disentangled+Learning+and+Relevance-Prioritized+Reranking+for+Calibrated+Sequential+Recommendation)|0|
|[Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search](https://doi.org/10.1145/3627673.3679534)|Fengran Mo, Chen Qu, Kelong Mao, Yihong Wu, Zhan Su, Kaiyu Huang, JianYun Nie||Conversational search supports multi-turn user-system interactions to solve complex information needs. Different from the traditional single-turn ad-hoc search, conversational search encounters a more challenging problem of context-dependent query understanding with the lengthy and long-tail conversational history context. While conversational query rewriting methods leverage explicit rewritten queries to train a rewriting model to transform the context-dependent query into a stand-stone search query, this is usually done without considering the quality of search results. Conversational dense retrieval methods use fine-tuning to improve a pre-trained ad-hoc query encoder, but they are limited by the conversational search data available for training. In this paper, we leverage both rewritten queries and relevance judgments in the conversational search data to train a better query representation model. The key idea is to align the query representation with those of rewritten queries and relevant documents. The proposed model – Query Representation Alignment Conversational Dense Retriever, QRACDR, is tested on eight datasets, including various settings in conversational search and ad-hoc search. The results demonstrate the strong performance of QRACDR compared with state-of-the-art methods, and confirm the effectiveness of representation alignment.|对话搜索支持多轮用户-系统交互，以解决复杂的信息需求。与传统的单轮即席搜索不同，对话搜索面临着一个更具挑战性的问题，即在长篇且长尾的对话历史背景下进行依赖上下文的查询理解。虽然对话查询重写方法利用显式的重写查询来训练重写模型，将依赖上下文的查询转换为独立的搜索查询，但这通常不考虑搜索结果的质量。对话密集检索方法通过微调预训练的即席查询编码器来改进，但受限于可用于训练的对话搜索数据。本文中，我们利用对话搜索数据中的重写查询和相关性判断来训练一个更好的查询表示模型。关键思想是将查询表示与重写查询和相关文档的表示对齐。提出的模型——查询表示对齐对话密集检索器（QRACDR），在八个数据集上进行了测试，包括对话搜索和即席搜索的各种设置。结果显示，QRACDR相比最先进的方法表现出强劲的性能，并证实了表示对齐的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Query+Representation+with+Rewritten+Query+and+Relevance+Judgments+in+Conversational+Search)|0|
|[Improved Estimation of Ranks for Learning Item Recommenders with Negative Sampling](https://doi.org/10.1145/3627673.3679943)|Anushya Subbiah, Steffen Rendle, Vikram Aggarwal||In recommendation systems, there has been a growth in the number of recommendable items (# of movies, music, products). When the set of recommendable items is large, training and evaluation of item recommendation models becomes computationally expensive. To lower this cost, it has become common to sample negative items. However, the recommendation quality can suffer from biases introduced by traditional negative sampling mechanisms. In this work, we demonstrate the benefits from correcting the bias introduced by sampling of negatives. We first provide sampled batch version of the well-studied WARP and LambdaRank methods. Then, we present how these methods can benefit from improved ranking estimates. Finally, we evaluate the recommendation quality as a result of correcting rank estimates and demonstrate that WARP and LambdaRank can be learned efficiently with negative sampling and our proposed correction technique.|在推荐系统中，可推荐项目的数量（如电影、音乐、产品）有所增加。当可推荐项目的集合规模较大时，训练和评估项目推荐模型的计算成本会变得非常高。为了降低这一成本，通常会采用负样本采样的方法。然而，传统的负样本采样机制可能会引入偏差，从而影响推荐质量。在这项工作中，我们展示了通过纠正负样本采样引入的偏差所带来的好处。我们首先提供了经过深入研究的WARP和LambdaRank方法的采样批次版本。然后，我们展示了这些方法如何从改进的排序估计中受益。最后，我们评估了纠正排序估计后的推荐质量，并证明WARP和LambdaRank可以通过负样本采样和我们的修正技术高效地进行学习。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improved+Estimation+of+Ranks+for+Learning+Item+Recommenders+with+Negative+Sampling)|0|
|[Scalable Dynamic Embedding Size Search for Streaming Recommendation](https://doi.org/10.1145/3627673.3679638)|Yunke Qu, Liang Qu, Tong Chen, Xiangyu Zhao, Quoc Viet Hung Nguyen, Hongzhi Yin||Recommender systems typically represent users and items by learning their embeddings, which are usually set to uniform dimensions and dominate the model parameters. However, real-world recommender systems often operate in streaming recommendation scenarios, where the number of users and items continues to grow, leading to substantial storage resource consumption for these embeddings. Although a few methods attempt to mitigate this by employing embedding size search strategies to assign different embedding dimensions in streaming recommendations, they assume that the embedding size grows with the frequency of users/items, which eventually still exceeds the predefined memory budget over time. To address this issue, this paper proposes to learn Scalable Lightweight Embeddings for streaming recommendation, called SCALL, which can adaptively adjust the embedding sizes of users/items within a given memory budget over time. Specifically, we propose to sample embedding sizes from a probabilistic distribution, with the guarantee to meet any predefined memory budget. By fixing the memory budget, the proposed embedding size sampling strategy can increase and decrease the embedding sizes in accordance to the frequency of the corresponding users or items. Furthermore, we develop a reinforcement learning-based search paradigm that models each state with mean pooling to keep the length of the state vectors fixed, invariant to the changing number of users and items. As a result, the proposed method can provide embedding sizes to unseen users and items. Comprehensive empirical evaluations on two public datasets affirm the advantageous effectiveness of our proposed method.|推荐系统通常通过学习嵌入来表示用户和物品，这些嵌入通常设置为统一的维度，并且主导模型参数。然而，现实世界的推荐系统经常在流式推荐场景中运行，其中用户和物品的数量持续增长，导致这些嵌入的存储资源消耗巨大。尽管一些方法试图通过采用嵌入大小搜索策略在流式推荐中分配不同的嵌入维度来缓解这一问题，但它们假设嵌入大小随着用户/物品的频率增长，最终仍然会超过预定义的内存预算。为了解决这个问题，本文提出了一种名为SCALL的流式推荐可扩展轻量级嵌入学习方法，它能够在给定的内存预算内随时间自适应地调整用户/物品的嵌入大小。具体来说，我们提出从概率分布中采样嵌入大小，以确保满足任何预定义的内存预算。通过固定内存预算，所提出的嵌入大小采样策略可以根据相应用户或物品的频率增加或减少嵌入大小。此外，我们开发了一种基于强化学习的搜索范式，该范式通过均值池化来建模每个状态，以保持状态向量的长度固定，不受用户和物品数量变化的影响。因此，所提出的方法可以为未见过的用户和物品提供嵌入大小。在两个公共数据集上的综合实证评估证实了我们提出的方法的优势有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Dynamic+Embedding+Size+Search+for+Streaming+Recommendation)|0|
|[Ask or Recommend: An Empirical Study on Conversational Product Search](https://doi.org/10.1145/3627673.3679875)|Heli Ma, Jie Zou, Mohammad Aliannejadi, Evangelos Kanoulas, Yi Bin, Yang Yang|University of Amsterdam, Amstedam, Netherlands; Tongji University, Shanghai, China; University of Science and Technology of China, Chengdu, China; University of Amsterdam, Amsterdam, Netherlands; University of Electronic Science and Technology of China, Chengdu, China|Conversational Product Search (CPS) provides an engaging way for users to find products through effective natural language conversations. However, understanding the effect of conversational characteristics on user search performance and when to ask clarifying questions or recommend products remains unexplored. To fill the gap, we conduct an empirical study in this paper. Specifically, we developed a conversational system that allows participants to join as customers or shopping assistants, to simulate the conversational product search activity. Data collected from conversations and participant feedback indicate that: (a) CPS systems tend to ask clarifying questions early in the conversation when users express the intent of issuing a new query and chitchat, while they tend to recommend products at a later stage of conversations; asking clarifying questions early and recommending products lately can significantly improve search performance and user's satisfaction; (b) asking clarifying questions and more fine-grained search keywords positively influence search performance in terms of finding relevant products; (c) although the conversation time has a positive impact on the number of recommended products, the performance gain diminishes with longer conversation time; (d) more clarifying questions, more conversation turns, and longer system response time lead to decreased user satisfaction.|对话式产品搜索（Conversational Product Search, CPS）为用户提供了一种通过高效自然语言对话寻找产品的互动方式。然而，对话特性对用户搜索表现的影响以及何时提问澄清问题或推荐产品的问题尚未得到深入研究。为了填补这一空白，本文进行了一项实证研究。具体而言，我们开发了一个对话系统，允许参与者扮演顾客或购物助手的角色，模拟对话式产品搜索活动。从对话中收集的数据及参与者反馈表明：(a) CPS系统在用户表达新查询意图和闲聊时，倾向于在对话初期提问澄清问题，而在对话后期则更倾向于推荐产品；尽早提问澄清问题和延迟推荐产品可以显著提升搜索表现和用户满意度；(b)提问澄清问题和更细粒度的搜索关键词对查找相关产品有正面影响，从而提高搜索表现；(c)尽管对话时间对推荐产品数量有正面影响，但随对话时间延长，性能提升逐渐减少；(d)更多的澄清问题、更多的对话轮次和更长的系统响应时间会导致用户满意度下降。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ask+or+Recommend:+An+Empirical+Study+on+Conversational+Product+Search)|0|
|[Towards Better Seach Query Classification with Distribution-Diverse Multi-Expert Knowledge Distillation in JD Ads Search](https://doi.org/10.1145/3627673.3680049)|KunPeng Ning, Ming Pang, Zheng Fang, Xue Jiang, XiWei Zhao, Changping Peng, Zhangang Lin, Jinghe Hu, Jingping Shao, Li Yuan|Business Growth BU, JD.COM, Beijing, China; Peking University, ShenZhen, China; Peking University, Shenzhen, China|In the dynamic landscape of online advertising, decoding user intent remains a pivotal challenge, particularly in the context of query classification. Swift classification models, exemplified by FastText, cater to the demand for real-time responses but encounter limitations in handling intricate queries. Conversely, accuracy-centric models like BERT introduce challenges associated with increased latency. This paper undertakes a nuanced exploration, navigating the delicate balance between efficiency and accuracy. It unveils FastText's latent potential as an 'online dictionary' for historical queries while harnessing the semantic robustness of BERT for novel and complex scenarios. The proposed Distribution-Diverse Multi-Expert (DDME) framework employs multiple teacher models trained from diverse data distributions. Through meticulous data categorization and enrichment, it elevates the classification performance across the query spectrum. Empirical results within the JD ads search system validate the superiority of our proposed approaches.|在在线广告的动态环境中，解读用户意图仍然是一个关键挑战，尤其是在查询分类的背景下。以FastText为代表的快速分类模型满足了实时响应的需求，但在处理复杂查询时存在局限性。相反，以准确性为中心的模型如BERT，虽然引入了延迟增加的挑战，但在处理复杂查询时表现出色。本文深入探讨了在效率和准确性之间寻求微妙平衡的问题。研究发现，FastText作为历史查询的“在线词典”具有潜在价值，同时利用BERT的语义丰富性来应对新颖和复杂的场景。提出的分布多样多专家（DDME）框架采用了从不同数据分布中训练的多个教师模型。通过细致的数据分类和丰富化处理，该框架提升了查询分类的整体性能。在京东广告搜索系统中的实证结果验证了我们提出的方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Better+Seach+Query+Classification+with+Distribution-Diverse+Multi-Expert+Knowledge+Distillation+in+JD+Ads+Search)|0|
|[Spectral and Geometric Spaces Representation Regularization for Multi-Modal Sequential Recommendation](https://doi.org/10.1145/3627673.3679647)|Zihao Li, Xuekong Xu, Zuoli Tang, Lixin Zou, Qian Wang, Chenliang Li||Recent works demonstrate the effectiveness of multi-modal information for sequential recommendation. However, the computational cost and representation degeneration fail to be focused specifically and addressed adequately in multi-modality recommendation. To this end, we first identify and formalize three properties i.e., diversity, compactness, and consistency from the geometric space and spectrum perspective. Building upon this foundation, we devise tailored loss functions to regularize the above three properties for representation optimization. Theoretical underpinnings and experimental results demonstrate the efficacy of an enhanced item representation in ameliorating degeneration. Furthermore, we propose an efficient and expandable image-centered method, named E2 ImgRec, to mitigate the immense cost of computation. Concretely, we substitute the linear projection operations in the self-attention module and feed-forward network layer with two learnable rescaling vectors or efficient recommendation, then leverage cross-attention for multi-modality information fusion. Extensive experiments on three public datasets illustrate our method outperforms representative ID-based solutions and multi-modal based state-of-the-arts with only up to 39.9% in memory usage and 4.3× acceleration in training time. The code for replication is available at https://github.com/WHUIR/E2ImgRec.|近期的研究展示了多模态信息在序列推荐中的有效性。然而，多模态推荐中的计算成本和表示退化问题尚未得到充分关注和解决。为此，我们首先从几何空间和频谱的角度识别并形式化了三个特性，即多样性、紧凑性和一致性。在此基础上，我们设计了定制的损失函数来规范上述三个特性，以优化表示。理论基础和实验结果表明，增强的物品表示能够有效改善退化问题。此外，我们提出了一种高效且可扩展的以图像为中心的方法，名为E2 ImgRec，以缓解巨大的计算成本。具体而言，我们用两个可学习的重缩放向量替代了自注意力模块和前馈网络层中的线性投影操作，并利用交叉注意力进行多模态信息融合。在三个公开数据集上的广泛实验表明，我们的方法在内存使用率最高仅为39.9%和训练时间加速4.3倍的情况下，优于基于ID的代表性解决方案和多模态的最新技术。可复现代码已发布在https://github.com/WHUIR/E2ImgRec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spectral+and+Geometric+Spaces+Representation+Regularization+for+Multi-Modal+Sequential+Recommendation)|0|
|[Retrieval-Oriented Knowledge for Click-Through Rate Prediction](https://doi.org/10.1145/3627673.3679842)|Huanshuo Liu, Bo Chen, Menghui Zhu, Jianghao Lin, Jiarui Qin, Hao Zhang, Yang Yang, Ruiming Tang||Click-through rate (CTR) prediction plays an important role in personalizedrecommendations. Recently, sample-level retrieval-based models (e.g., RIM) haveachieved remarkable performance by retrieving and aggregating relevant samples.However, their inefficiency at the inference stage makes them impractical forindustrial applications. To overcome this issue, this paper proposes auniversal plug-and-play Retrieval-Oriented Knowledge (ROK) framework.Specifically, a knowledge base, consisting of a retrieval-oriented embeddinglayer and a knowledge encoder, is designed to preserve and imitate theretrieved aggregated representations in a decomposition-reconstructionparadigm. Knowledge distillation and contrastive learning methods are utilizedto optimize the knowledge base, and the learned retrieval-enhancedrepresentations can be integrated with arbitrary CTR models in bothinstance-wise and feature-wise manners. Extensive experiments on threelarge-scale datasets show that ROK achieves competitive performance with theretrieval-based CTR models while reserving superior inference efficiency andmodel compatibility.|点击率（CTR）预测在个性化推荐中扮演着重要角色。近期，基于样本级检索的模型（如RIM）通过检索并聚合相关样本来取得了显著的性能。然而，这些模型在推理阶段的效率低下使其难以应用于工业场景。为解决这一问题，本文提出了一种通用的即插即用型检索导向知识（ROK）框架。具体而言，设计了一个由检索导向嵌入层和知识编码器组成的知识库，该知识库在分解-重构范式中保留并模仿检索到的聚合表示。利用知识蒸馏和对比学习方法来优化知识库，所学到的检索增强表示可以与任意CTR模型在实例级和特征级方式上进行集成。在三个大规模数据集上的广泛实验表明，ROK在保留优越的推理效率和模型兼容性的同时，实现了与基于检索的CTR模型相当的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Oriented+Knowledge+for+Click-Through+Rate+Prediction)|0|
|[Mitigating Exposure Bias in Online Learning to Rank Recommendation: A Novel Reward Model for Cascading Bandits](https://doi.org/10.1145/3627673.3679763)|Masoud Mansoury, Bamshad Mobasher, Herke van Hoof||Exposure bias is a well-known issue in recommender systems where items and suppliers are not equally represented in the recommendation results. This bias becomes particularly problematic over time as a few items are repeatedly over-represented in recommendation lists, leading to a feedback loop that further amplifies this bias. Although extensive research has addressed this issue in model-based or neighborhood-based recommendation algorithms, less attention has been paid to online recommendation models, such as those based on top-K contextual bandits, where recommendation models are dynamically updated with ongoing user feedback. In this paper, we study exposure bias in a class of well-known contextual bandit algorithms known as Linear Cascading Bandits. We analyze these algorithms in their ability to handle exposure bias and provide a fair representation of items in the recommendation results. Our analysis reveals that these algorithms fail to mitigate exposure bias in the long run during the course of ongoing user interactions. We propose an Exposure-Aware reward model that updates the model parameters based on two factors: 1) implicit user feedback and 2) the position of the item in the recommendation list. The proposed model mitigates exposure bias by controlling the utility assigned to the items based on their exposure in the recommendation list. Our experiments with two real-world datasets show that our proposed reward model improves the exposure fairness of the linear cascading bandits over time while maintaining the recommendation accuracy. It also outperforms the current baselines. Finally, we prove a high probability upper regret bound for our proposed model, providing theoretical guarantees for its performance.|曝光偏差是推荐系统中一个众所周知的问题，其中物品和供应商在推荐结果中的表现并不均衡。随着时间的推移，这种偏差变得尤为严重，因为少数物品在推荐列表中被过度重复展示，形成了一个反馈循环，进一步加剧了这种偏差。尽管大量研究已经解决了基于模型或基于邻域的推荐算法中的这一问题，但对于在线推荐模型（如基于top-K上下文强盗的模型）的关注较少，这些模型会根据用户的持续反馈动态更新推荐模型。在本文中，我们研究了一类著名的上下文强盗算法——线性级联强盗算法中的曝光偏差问题。我们分析了这些算法在处理曝光偏差和在推荐结果中公平展示物品方面的能力。我们的分析表明，这些算法在长期用户交互过程中无法有效缓解曝光偏差。我们提出了一种曝光感知奖励模型，该模型根据两个因素更新模型参数：1）隐式用户反馈和2）物品在推荐列表中的位置。所提出的模型通过根据物品在推荐列表中的曝光程度调整分配给它们的效用，来缓解曝光偏差。我们在两个真实世界数据集上的实验表明，所提出的奖励模型随着时间的推移提高了线性级联强盗算法的曝光公平性，同时保持了推荐准确性。此外，它还优于当前的基线模型。最后，我们证明了所提出模型的高概率上界遗憾界限，为其性能提供了理论保证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Exposure+Bias+in+Online+Learning+to+Rank+Recommendation:+A+Novel+Reward+Model+for+Cascading+Bandits)|0|
|[MemoCRS: Memory-enhanced Sequential Conversational Recommender Systems with Large Language Models](https://doi.org/10.1145/3627673.3679599)|Yunjia Xi, Weiwen Liu, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu||Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through multi-round natural language dialogues. However, most existing CRS models mainly focus on dialogue comprehension and preferences mining from the current dialogue session, overlooking user preferences in historical dialogue sessions. The preferences embedded in the user's historical dialogue sessions and the current session exhibit continuity and sequentiality, and we refer to CRSs with this characteristic as sequential CRSs. In this work, we leverage memory-enhanced LLMs to model the preference continuity, primarily focusing on addressing two key issues: (1) redundancy and noise in historical dialogue sessions, and (2) the cold-start users problem. To this end, we propose a Memory-enhanced Conversational Recommender System Framework with Large Language Models (dubbed MemoCRS) consisting of user-specific memory and general memory. User-specific memory is tailored to each user for their personalized interests and implemented by an entity-based memory bank to refine preferences and retrieve relevant memory, thereby reducing the redundancy and noise of historical sessions. The general memory, encapsulating collaborative knowledge and reasoning guidelines, can provide shared knowledge for users, especially cold-start users. With the two kinds of memory, LLMs are empowered to deliver more precise and tailored recommendations for each user. Extensive experiments on both Chinese and English datasets demonstrate the effectiveness of MemoCRS.|对话推荐系统（CRSs）旨在通过多轮自然语言对话捕捉用户偏好并提供个性化推荐。然而，大多数现有的CRS模型主要关注当前对话会话中的对话理解和偏好挖掘，忽视了历史对话会话中的用户偏好。用户历史对话会话和当前会话中嵌入的偏好具有连续性和顺序性，我们将具备这种特性的CRS称为顺序CRS。在本研究中，我们利用记忆增强型LLMs来建模偏好连续性，主要解决两个关键问题：（1）历史对话会话中的冗余和噪声，（2）冷启动用户问题。为此，我们提出了一种基于大语言模型的记忆增强对话推荐系统框架（称为MemoCRS），该框架包括用户特定记忆和通用记忆。用户特定记忆针对每个用户的个性化兴趣定制，并通过基于实体的记忆库实现，以精炼偏好并检索相关记忆，从而减少历史会话的冗余和噪声。通用记忆封装了协作知识和推理指南，可以为所有用户提供共享知识，特别是冷启动用户。通过这两种记忆，LLMs能够为每个用户提供更精确和定制化的推荐。在中英文数据集上的广泛实验证明了MemoCRS的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemoCRS:+Memory-enhanced+Sequential+Conversational+Recommender+Systems+with+Large+Language+Models)|0|
|[Early Exit Strategies for Approximate k-NN Search in Dense Retrieval](https://doi.org/10.1145/3627673.3679903)|Francesco Busolin, Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Salvatore Trani||Learned dense representations are a popular family of techniques for encoding queries and documents using high-dimensional embeddings, which enable retrieval by performing approximate k nearest-neighbors search (A-kNN). A popular technique for making A-kNN search efficient is based on a two-level index, where the embeddings of documents are clustered offline and, at query processing, a fixed number N of clusters closest to the query is visited exhaustively to compute the result set. In this paper, we build upon state-of-the-art for early exit A-kNN and propose an unsupervised method based on the notion of patience, which can reach competitive effectiveness with large efficiency gains. Moreover, we discuss a cascade approach where we first identify queries that find their nearest neighbor within the closest t << N clusters, and then we decide how many more to visit based on our patience approach or other state-of-the-art strategies. Reproducible experiments employing state-of-the-art dense retrieval models and publicly available resources show that our techniques improve the A-kNN efficiency with up to 5x speedups while achieving negligible effectiveness losses. All the code used is available at https://github.com/francescobusolin/faiss_pEE|学习到的密集表示是一种流行的技术家族，用于使用高维嵌入对查询和文档进行编码，通过执行近似k近邻搜索（A-kNN）来实现检索。使A-kNN搜索高效的一种流行技术是基于两级索引，其中文档的嵌入在离线状态下被聚类，在查询处理时，固定数量的N个最接近查询的聚类被穷尽地访问以计算结果集。在本文中，我们基于最先进的早期退出A-kNN技术，提出了一种基于耐心理念的无监督方法，该方法能够在大幅提高效率的同时达到竞争性的有效性。此外，我们讨论了一种级联方法，首先识别在其最接近的t << N个聚类内找到最近邻的查询，然后根据我们的耐心理念或其他最先进策略决定访问更多聚类的数量。使用最先进的密集检索模型和公开可用资源的可重复实验表明，我们的技术在实现几乎无有效性损失的情况下，将A-kNN效率提高了最多5倍的速度。所有使用的代码均可在https://github.com/francescobusolin/faiss_pEE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Early+Exit+Strategies+for+Approximate+k-NN+Search+in+Dense+Retrieval)|0|
|[MODRL-TA: A Multi-Objective Deep Reinforcement Learning Framework for Traffic Allocation in E-Commerce Search](https://doi.org/10.1145/3627673.3679964)|Peng Cheng, Huimu Wang, Jinyuan Zhao, Yihao Wang, Enqiang Xu, Yu Zhao, Zhuojian Xiao, Songlin Wang, Guoyu Tang, Lin Liu, Sulong Xu||Traffic allocation is a process of redistributing natural traffic to products by adjusting their positions in the post-search phase, aimed at effectively fostering merchant growth, precisely meeting customer demands, and ensuring the maximization of interests across various parties within e-commerce platforms. Existing methods based on learning to rank neglect the long-term value of traffic allocation, whereas approaches of reinforcement learning suffer from balancing multiple objectives and the difficulties of cold starts within realworld data environments. To address the aforementioned issues, this paper propose a multi-objective deep reinforcement learning framework consisting of multi-objective Q-learning (MOQ), a decision fusion algorithm (DFM) based on the cross-entropy method(CEM), and a progressive data augmentation system(PDA). Specifically. MOQ constructs ensemble RL models, each dedicated to an objective, such as click-through rate, conversion rate, etc. These models individually determine the position of items as actions, aiming to estimate the long-term value of multiple objectives from an individual perspective. Then we employ DFM to dynamically adjust weights among objectives to maximize long-term value, addressing temporal dynamics in objective preferences in e-commerce scenarios. Initially, PDA trained MOQ with simulated data from offline logs. As experiments progressed, it strategically integrated real user interaction data, ultimately replacing the simulated dataset to alleviate distributional shifts and the cold start problem. Experimental results on real-world online e-commerce systems demonstrate the significant improvements of MODRL-TA, and we have successfully deployed MODRL-TA on an e-commerce search platform.|流量分配是通过调整产品在搜索后阶段的位置来重新分配自然流量，旨在有效促进商家增长、精准满足客户需求，并确保电子商务平台各方的利益最大化。现有的基于学习排序的方法忽视了流量分配的长期价值，而强化学习的方法则在平衡多个目标和处理现实数据环境中的冷启动问题上存在困难。为解决上述问题，本文提出了一种多目标深度强化学习框架，包括多目标Q学习（MOQ）、基于交叉熵方法（CEM）的决策融合算法（DFM）和渐进式数据增强系统（PDA）。具体而言，MOQ构建了专注于不同目标（如点击率、转化率等）的集成强化学习模型，每个模型独立决定商品的位置作为动作，旨在从个体角度估计多个目标的长期价值。随后，我们采用DFM动态调整目标之间的权重以最大化长期价值，解决电子商务场景中目标偏好的时间动态性。最初，PDA使用离线日志中的模拟数据训练MOQ。随着实验的进行，它策略性地整合了真实用户交互数据，最终替代模拟数据集以缓解分布偏移和冷启动问题。在真实在线电子商务系统上的实验结果显示了MODRL-TA的显著改进，并且我们已成功将MODRL-TA部署在电子商务搜索平台上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MODRL-TA:+A+Multi-Objective+Deep+Reinforcement+Learning+Framework+for+Traffic+Allocation+in+E-Commerce+Search)|0|
|[Enhancing CTR Prediction through Sequential Recommendation Pre-training: Introducing the SRP4CTR framework](https://doi.org/10.1145/3627673.3679914)|Ruidong Han, Qianzhong Li, He Jiang, Rui Li, Yurou Zhao, Xiang Li, Wei Lin||Understanding user interests is crucial for Click-Through Rate (CTR) prediction tasks. In sequential recommendation, pre-training from user historical behaviors through self-supervised learning can better comprehend user dynamic preferences, presenting the potential for direct integration with CTR tasks. Previous methods have integrated pre-trained models into downstream tasks with the sole purpose of extracting semantic information or well-represented user features, which are then incorporated as new features. However, these approaches tend to ignore the additional inference costs to the downstream tasks, and they do not consider how to transfer the effective information from the pre-trained models for specific estimated items in CTR prediction. In this paper, we propose a Sequential Recommendation Pre-training framework for CTR prediction (SRP4CTR) to tackle the above problems. Initially, we discuss the impact of introducing pre-trained models on inference costs. Subsequently, we introduced a pre-trained method to encode sequence side information concurrently.During the fine-tuning process, we incorporate a cross-attention block to establish a bridge between estimated items and the pre-trained model at a low cost. Moreover, we develop a querying transformer technique to facilitate the knowledge transfer from the pre-trained model to industrial CTR models. Offline and online experiments show that our method outperforms previous baseline models.|理解用户兴趣对于点击率（CTR）预测任务至关重要。在序列推荐中，通过自监督学习从用户历史行为中进行预训练，能更好地理解用户的动态偏好，为直接整合到CTR任务中提供了潜力。以往的方法将预训练模型整合到下游任务中，主要是为了提取语义信息或良好表示的用户特征，并将其作为新特征引入。然而，这些方法往往忽略了增加的推理成本，以及如何将预训练模型中的有效信息传递给CTR预测中特定的估计项。本文提出了一种用于CTR预测的序列推荐预训练框架（SRP4CTR），以解决上述问题。首先，我们讨论了引入预训练模型对推理成本的影响。接着，我们引入了一种预训练方法，以同时编码序列侧信息。在微调过程中，我们通过一个交叉注意力模块，以较低的成本在估计项和预训练模型之间建立桥梁。此外，我们开发了一种查询变换器技术，以促进预训练模型中的知识向工业CTR模型的转移。离线和在线实验表明，我们的方法优于以往的基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+CTR+Prediction+through+Sequential+Recommendation+Pre-training:+Introducing+the+SRP4CTR+framework)|0|
|[MARS: Matching Attribute-aware Representations for Text-based Sequential Recommendation](https://doi.org/10.1145/3627673.3679960)|Hyunsoo Kim, Junyoung Kim, Minjin Choi, Sunkyung Lee, Jongwuk Lee||Sequential recommendation aims to predict the next item a user is likely to prefer based on their sequential interaction history. Recently, text-based sequential recommendation has emerged as a promising paradigm that uses pre-trained language models to exploit textual item features to enhance performance and facilitate knowledge transfer to unseen datasets. However, existing text-based recommender models still struggle with two key challenges: (i) representing users and items with multiple attributes, and (ii) matching items with complex user interests. To address these challenges, we propose a novel model, Matching Attribute-aware Representations for Text-based Sequential Recommendation (MARS)}. MARS extracts detailed user and item representations through attribute-aware text encoding, capturing diverse user intents with multiple attribute-aware representations. It then computes user-item scores via attribute-wise interaction matching, effectively capturing attribute-level user preferences. Our extensive experiments demonstrate that MARS significantly outperforms existing sequential models, achieving improvements of up to 24.43% and 29.26% in Recall@10 and NDCG@10 across five benchmark datasets. Code is available at https://github.com/junieberry/MARS|顺序推荐旨在根据用户的顺序交互历史预测他们可能偏好的下一个项目。近年来，基于文本的顺序推荐作为一种有前景的范式出现，它利用预训练的语言模型来利用文本项目特征，以提升性能并促进知识向未见数据集的转移。然而，现有的基于文本的推荐模型仍面临两个关键挑战：（i）用多个属性表示用户和项目，以及（ii）匹配具有复杂用户兴趣的项目。为解决这些挑战，我们提出了一种新颖的模型，即基于文本的顺序推荐匹配属性感知表示（MARS）。MARS通过属性感知的文本编码提取详细的用户和项目表示，利用多个属性感知表示捕捉多样化的用户意图。然后，它通过属性层面的交互匹配计算用户-项目分数，有效捕捉属性级别的用户偏好。我们的广泛实验表明，MARS显著优于现有的顺序推荐模型，在五个基准数据集上的Recall@10和NDCG@10分别提高了24.43%和29.26%。代码可在https://github.com/junieberry/MARS获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MARS:+Matching+Attribute-aware+Representations+for+Text-based+Sequential+Recommendation)|0|
|[How to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval](https://doi.org/10.1145/3627673.3679939)|Fengran Mo, Longxiang Zhao, Kaiyu Huang, Yue Dong, Degen Huang, JianYun Nie||Personalized conversational information retrieval (CIR) combines conversational and personalizable elements to satisfy various users' complex information needs through multi-turn interaction based on their backgrounds. The key promise is that the personal textual knowledge base (PTKB) can improve the CIR effectiveness because the retrieval results can be more related to the user's background. However, PTKB is noisy: not every piece of knowledge in PTKB is relevant to the specific query at hand. In this paper, we explore and test several ways to select knowledge from PTKB and use it for query reformulation by using a large language model (LLM). The experimental results show the PTKB might not always improve the search results when used alone, but LLM can help generate a more appropriate personalized query when high-quality guidance is provided.|个性化对话信息检索（CIR）结合了对话性和可个性化元素，通过基于用户背景的多轮交互来满足不同用户的复杂信息需求。其核心优势在于，个性化文本知识库（PTKB）能够提升CIR的效果，因为检索结果可以更贴近用户的背景。然而，PTKB存在噪声问题：并非PTKB中的每条知识都与当前的具体查询相关。本文探讨并测试了几种从PTKB中选择知识并用于查询重构的方法，这些方法借助大型语言模型（LLM）实现。实验结果表明，单独使用PTKB并不总能提升搜索结果，但在高质量指引下，LLM能够生成更为合适的个性化查询。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+to+Leverage+Personal+Textual+Knowledge+for+Personalized+Conversational+Information+Retrieval)|0|
|[Enhancing Relevance of Embedding-based Retrieval at Walmart](https://doi.org/10.1145/3627673.3680047)|Juexin Lin, Sachin Yadav, Feng Liu, Nicholas Rossi, Praveen Reddy Suram, Satya Chembolu, Prijith Chandran, Hrushikesh Mohapatra, Tony Lee, Alessandro Magnani, Ciya Liao||Embedding-based neural retrieval (EBR) is an effective search retrieval method in product search for tackling the vocabulary gap between customer search queries and products. The initial launch of our EBR system at Walmart yielded significant gains in relevance and add-to-cart rates [1]. However, despite EBR generally retrieving more relevant products for reranking, we have observed numerous instances of relevance degradation. Enhancing retrieval performance is crucial, as it directly influences product reranking and affects the customer shopping experience. Factors contributing to these degradations include false positives/negatives in the training data and the inability to handle query misspellings. To address these issues, we present several approaches to further strengthen the capabilities of our EBR model in terms of retrieval relevance. We introduce a Relevance Reward Model (RRM) based on human relevance feedback. We utilize RRM to remove noise from the training data and distill it into our EBR model through a multi-objective loss. In addition, we present the techniques to increase the performance of our EBR model, such as typo-aware training, and semi-positive generation. The effectiveness of our EBR is demonstrated through offline relevance evaluation, online AB tests, and successful deployments to live production. [1] Alessandro Magnani, Feng Liu, Suthee Chaidaroon, Sachin Yadav, Praveen Reddy Suram, Ajit Puthenputhussery, Sijie Chen, Min Xie, Anirudh Kashi, Tony Lee, et al. 2022. Semantic retrieval at walmart. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 3495-3503.|基于嵌入的神经检索（EBR）是一种在产品搜索中有效应对客户搜索查询与产品之间词汇差异的搜索检索方法。我们最初在沃尔玛推出的EBR系统显著提升了相关性和加入购物车的比率[1]。然而，尽管EBR通常能检索到更相关的产品以进行重新排序，我们仍观察到许多相关性下降的情况。提升检索性能至关重要，因为它直接影响产品重新排序并影响客户购物体验。导致这些下降的因素包括训练数据中的假阳性/阴性以及无法处理查询拼写错误。为解决这些问题，我们提出了几种方法来进一步增强EBR模型在检索相关性方面的能力。我们引入了一个基于人类相关性反馈的相关性奖励模型（RRM）。我们利用RRM来消除训练数据中的噪声，并通过多目标损失将其提炼到EBR模型中。此外，我们还提出了提升EBR模型性能的技术，如拼写感知训练和半正例生成。通过离线相关性评估、在线AB测试以及成功部署到实际生产中，展示了我们EBR的有效性。[1] Alessandro Magnani, Feng Liu, Suthee Chaidaroon, Sachin Yadav, Praveen Reddy Suram, Ajit Puthenputhussery, Sijie Chen, Min Xie, Anirudh Kashi, Tony Lee, 等. 2022. 沃尔玛的语义检索. 在第28届ACM SIGKDD知识发现与数据挖掘会议论文集. 3495-3503.|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Relevance+of+Embedding-based+Retrieval+at+Walmart)|0|
|[Relevance Filtering for Embedding-based Retrieval](https://doi.org/10.1145/3627673.3680095)|Nicholas Rossi, Juexin Lin, Feng Liu, Zhen Yang, Tony Lee, Alessandro Magnani, Ciya Liao||In embedding-based retrieval, Approximate Nearest Neighbor (ANN) search enables efficient retrieval of similar items from large-scale datasets. While maximizing recall of relevant items is usually the goal of retrieval systems, a low precision may lead to a poor search experience. Unlike lexical retrieval, which inherently limits the size of the retrieved set through keyword matching, dense retrieval via ANN search has no natural cutoff. Moreover, the cosine similarity scores of embedding vectors are often optimized via contrastive or ranking losses, which make them difficult to interpret. Consequently, relying on top-K or cosine-similarity cutoff is often insufficient to filter out irrelevant results effectively. This issue is prominent in product search, where the number of relevant products is often small. This paper introduces a novel relevance filtering component (called "Cosine Adapter") for embedding-based retrieval to address this challenge. Our approach maps raw cosine similarity scores to interpretable scores using a query-dependent mapping function. We then apply a global threshold on the mapped scores to filter out irrelevant results. We are able to significantly increase the precision of the retrieved set, at the expense of a small loss of recall. The effectiveness of our approach is demonstrated through experiments on both public MS MARCO dataset and internal Walmart product search data. Furthermore, online A/B testing on the Walmart site validates the practical value of our approach in real-world e-commerce settings.|在基于嵌入的检索中，近似最近邻（ANN）搜索能够从大规模数据集中高效地检索相似项目。尽管最大化相关项目的召回率通常是检索系统的目标，但低精度可能会导致糟糕的搜索体验。与通过关键词匹配自然限制检索集大小的词法检索不同，通过ANN搜索的密集检索没有自然的截止点。此外，嵌入向量的余弦相似度分数通常通过对比或排序损失进行优化，这使得它们难以解释。因此，仅依赖于前K个结果或余弦相似度截止点往往不足以有效过滤掉不相关的结果。在产品搜索中，这一问题尤为突出，因为相关产品的数量通常较少。本文为基于嵌入的检索引入了一种新颖的相关性过滤组件（称为“余弦适配器”），以应对这一挑战。我们的方法使用查询依赖的映射函数将原始余弦相似度分数映射为可解释的分数，然后对映射后的分数应用全局阈值以过滤掉不相关的结果。我们能够在召回率小幅损失的情况下显著提高检索集的精度。通过在公共MS MARCO数据集和内部沃尔玛产品搜索数据上的实验，证明了我们方法的有效性。此外，在沃尔玛网站上的在线A/B测试验证了我们的方法在实际电子商务环境中的实用价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevance+Filtering+for+Embedding-based+Retrieval)|0|
|[Advancing Re-Ranking with Multimodal Fusion and Target-Oriented Auxiliary Tasks in E-Commerce Search](https://doi.org/10.1145/3627673.3680063)|Enqiang Xu, Xinhui Li, Zhigong Zhou, Jiahao Ji, Jinyuan Zhao, Dadong Miao, Songlin Wang, Lin Liu, Sulong Xu||In the rapidly evolving field of e-commerce, the effectiveness of search re-ranking models is crucial for enhancing user experience and driving conversion rates. Despite significant advancements in feature representation and model architecture, the integration of multimodal information remains underexplored. This study addresses this gap by investigating the computation and fusion of textual and visual information in the context of re-ranking. We propose Advancing Re-Ranking with Multimodal Fusion and Target-Oriented Auxiliary Tasks (ARMMT), which integrates an attention-based multimodal fusion technique and an auxiliary ranking-aligned task to enhance item representation and improve targeting capabilities. This method not only enriches the understanding of product attributes but also enables more precise and personalized recommendations. Experimental evaluations on JD.com's search platform demonstrate that ARMMT achieves state-of-the-art performance in multimodal information integration, evidenced by a 0.22% increase in the Conversion Rate (CVR), significantly contributing to Gross Merchandise Volume (GMV). This pioneering approach has the potential to revolutionize e-commerce re-ranking, leading to elevated user satisfaction and business growth.|在电子商务快速发展的领域中，搜索重排序模型的有效性对于提升用户体验和推动转化率至关重要。尽管在特征表示和模型架构方面取得了显著进展，但多模态信息的整合仍未得到充分探索。本研究通过探讨重排序情境下文本和视觉信息的计算与融合，填补了这一空白。我们提出了基于多模态融合与面向目标的辅助任务的进阶重排序模型（ARMMT），该模型整合了基于注意力的多模态融合技术与辅助排序对齐任务，以增强商品表示并提升目标定位能力。这种方法不仅丰富了对产品属性的理解，还实现了更精确和个性化的推荐。在京东搜索平台上的实验评估表明，ARMMT在多模态信息整合方面达到了最先进的性能，体现在转化率（CVR）提高了0.22%，显著促进了商品交易总额（GMV）的增长。这一开创性方法有望革新电子商务重排序，带来用户满意度和业务增长的双重提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Re-Ranking+with+Multimodal+Fusion+and+Target-Oriented+Auxiliary+Tasks+in+E-Commerce+Search)|0|
|[Missing Interest Modeling with Lifelong User Behavior Data for Retrieval Recommendation](https://doi.org/10.1145/3627673.3680019)|Gaode Chen, Yuezihan Jiang, Rui Huang, Kuo Cai, Yunze Luo, Ruina Sun, Qi Zhang, Han Li, Kun Gai|Kuaishou Technology, Beijing, China|Rich user behavior data has been proven to be of great value for recommendation systems. Modeling lifelong user behavior data in the retrieval stage to explore user long-term preference and obtain comprehensive retrieval results is crucial. Existing lifelong modeling methods cannot applied to the retrieval stage because they extract target-relevant items through the coupling between the user and the target item. Moreover, the current retrieval methods fail to precisely capture user interests when the length of the user behavior sequence increases further. That leads to a gap in the ability of retrieval models to model lifelong user behavior data. In this paper, we propose the concept of missing interest, leveraging the idea of complementarity, which serves as a supplement to short-term interest based on lifelong behavior data in the retrieval stage. Specifically, we design a missing interest operator and deploy it in Kafka data stream, without incurring latency or storage costs. This operator derives categories and authors of items that the user was previously interested in but has recently missed, and uses these as triggers to output missing features to the downstream retrieval model. Our retrieval model is a complete dual-tower structure that combines short-term and missing interests on the user side to provide a comprehensive depiction of lifelong behaviors. Since 2023, the presented solution has been deployed in Kuaishou, one of the most popular short-video streaming platforms in China with hundreds of millions of active users.|丰富的用户行为数据已被证明对推荐系统具有巨大价值。在检索阶段对终身用户行为数据进行建模，以探索用户的长期偏好并获得全面的检索结果至关重要。现有的终身建模方法无法应用于检索阶段，因为它们通过用户与目标项目之间的耦合来提取目标相关项目。此外，当前的检索方法在用户行为序列长度进一步增加时无法精确捕捉用户兴趣。这导致了检索模型在终身用户行为数据建模能力上的差距。本文提出了缺失兴趣的概念，利用互补的思想，作为基于终身行为数据在检索阶段对短期兴趣的补充。具体来说，我们设计了一个缺失兴趣操作符，并将其部署在Kafka数据流中，不会产生延迟或存储成本。该操作符推导出用户之前感兴趣但最近错过的项目的类别和作者，并使用这些作为触发器向下游检索模型输出缺失特征。我们的检索模型是一个完整的双塔结构，结合了用户端的短期兴趣和缺失兴趣，全面描绘了终身行为。自2023年以来，所提出的解决方案已部署在中国最受欢迎的短视频流媒体平台之一——快手，该平台拥有数亿活跃用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Missing+Interest+Modeling+with+Lifelong+User+Behavior+Data+for+Retrieval+Recommendation)|0|
|[Relative Contrastive Learning for Sequential Recommendation with Similarity-based Positive Sample Selection](https://doi.org/10.1145/3627673.3679681)|Zhikai Wang, Yanyan Shen, Zexi Zhang, Li He, Yichun Li, Hao Gu, Yinghua Zhang|Shanghai Jiao Tong University, Shanghai, China; Meituan, Shanghai, China|Contrastive Learning (CL) enhances the training of sequential recommendation (SR) models through informative self-supervision signals. Existing methods often rely on data augmentation strategies to create positive samples and promote representation invariance. Some strategies such as item reordering and item substitution may inadvertently alter user intent. Supervised Contrastive Learning (SCL) based methods find an alternative to augmentation-based CL methods by selecting same-target sequences (interaction sequences with the same target item) to form positive samples. However, SCL-based methods suffer from the scarcity of same-target sequences and consequently lack enough signals for contrastive learning. In this work, we propose to use similar sequences (with different target items) as additional positive samples and introduce a Relative Contrastive Learning (RCL) framework for sequential recommendation. RCL comprises a dual-tiered positive sample selection module and a relative contrastive learning module. The former module selects same-target sequences as strong positive samples and selects similar sequences as weak positive samples. The latter module employs a weighted relative contrastive loss, ensuring that each sequence is represented closer to its strong positive samples than its weak positive samples. We apply RCL on two mainstream deep learning-based SR models, and our empirical results reveal that RCL can achieve 4.88% improvement averagely than the state-of-the-art SR methods on five public datasets and one private dataset. The code can be found at https://github.com/Cloudcatcher888/RCL.|对比学习（CL）通过提供信息丰富的自监督信号，增强了序列推荐（SR）模型的训练。现有方法通常依赖于数据增强策略来创建正样本并促进表示的不变性。一些策略如物品重新排序和物品替换可能会无意中改变用户意图。基于监督对比学习（SCL）的方法通过选择相同目标序列（与相同目标物品的交互序列）来形成正样本，从而为基于增强的CL方法提供了替代方案。然而，SCL方法面临相同目标序列稀缺的问题，因此缺乏足够的对比学习信号。在这项工作中，我们提出使用相似序列（具有不同目标物品）作为额外的正样本，并引入了一个相对对比学习（RCL）框架用于序列推荐。RCL包括一个双层正样本选择模块和一个相对对比学习模块。前者模块选择相同目标序列作为强正样本，并选择相似序列作为弱正样本。后者模块采用加权相对对比损失，确保每个序列的表示更接近其强正样本而非弱正样本。我们将RCL应用于两个主流的基于深度学习的SR模型，我们的实验结果显示，RCL在五个公共数据集和一个私有数据集上平均比最先进的SR方法提高了4.88%。代码可在https://github.com/Cloudcatcher888/RCL找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relative+Contrastive+Learning+for+Sequential+Recommendation+with+Similarity-based+Positive+Sample+Selection)|0|
|[Momentum Contrastive Bidirectional Encoding with Self-Distillation for Sequential Recommendation](https://doi.org/10.1145/3627673.3679965)|Dingyi Zhang, Haoyu Wenren, Yue Wang, Yingming Li|Zhejiang University, Hangzhou, China; Alipay (Hangzhou) Information Technology Co., Ltd, Hangzhou, China|In this paper, we propose a new Momentum Contrastive Bidirectional Encoding network with S elf-D istillation (MoCoBE-SD) to alleviate the data sparsity and noise issues in sequential recommendation by providing rich informative supervisions from both sequence-level and item-level perspectives. In particular, a Momentum Contrastive Bidirectional Encoding (MoCoBE) network is first proposed by constructing momentum updated encoder based on an online bidirectional self-attention encoder, where a momentum contrastive learning task and a masked item prediction task are simultaneously optimized. Building upon MoCoBE, a well-elaborated Self-Distillation (SD) scheme is incorporated to further suppress the noise influence. Specifically, a well-trained sequence encoder by MoCoBE is adopted as the teacher encoder to provide refined supervision for the masked item prediction, which constitutes our MoCoBE-SD framework. Extensive experiments on three public datasets show that MoCoBE-SD outperforms the existing state-of-the-art methods consistently.|本文提出了一种新的动量对比双向编码网络，结合自蒸馏技术（MoCoBE-SD），以缓解序列推荐中数据稀疏和噪声问题。通过从序列级和项目级两个角度提供丰富的信息监督来实现这一目标。具体而言，首先提出了一种动量对比双向编码（MoCoBE）网络，该网络基于在线双向自注意力编码器构建了动量更新的编码器，同时优化了动量对比学习任务和掩码项目预测任务。在MoCoBE的基础上，引入了一种精心设计的自蒸馏（SD）方案，以进一步抑制噪声的影响。具体来说，通过MoCoBE训练好的序列编码器被用作教师编码器，为掩码项目预测提供精细化的监督，从而构成了我们的MoCoBE-SD框架。在三个公共数据集上的广泛实验表明，MoCoBE-SD在性能上持续优于现有的最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Momentum+Contrastive+Bidirectional+Encoding+with+Self-Distillation+for+Sequential+Recommendation)|0|
|[A Real-Time Adaptive Multi-Stream GPU System For Online Approximate Nearest Neighborhood Search](https://doi.org/10.1145/3627673.3680054)|Yiping Sun, Yang Shi, Jiaolong Du||In recent years, Approximate Nearest Neighbor Search (ANNS) has played a pivotal role in modern search and recommendation systems, especially in emerging LLM applications like Retrieval-Augmented Generation. There is a growing exploration into harnessing the parallel computing capabilities of GPUs to meet the substantial demands of ANNS. However, existing systems primarily focus on offline scenarios, overlooking the distinct requirements of online applications that necessitate real-time insertion of new vectors. This limitation renders such systems inefficient for real-world scenarios. Moreover, previous architectures struggled to effectively support real-time insertion due to their reliance on serial execution streams. In this paper, we introduce a novel Real-Time Adaptive Multi-Stream GPU ANNS System (RTAMS-GANNS). Our architecture achieves its objectives through three key advancements: 1) We initially examined the real-time insertion mechanisms in existing GPU ANNS systems and discovered their reliance on repetitive copying and memory allocation, which significantly hinders real-time effectiveness on GPUs. As a solution, we introduce a dynamic vector insertion algorithm based on memory blocks, which includes in-place rearrangement. 2) To enable real-time vector insertion in parallel, we introduce a multi-stream parallel execution mode, which differs from existing systems that operate serially within a single stream. Our system utilizes a dynamic resource pool, allowing multiple streams to execute concurrently without additional execution blocking. 3) Through extensive experiments and comparisons, our approach effectively handles varying QPS levels across different datasets, reducing latency by up to 40 proposed system has also been deployed in real-world industrial search and recommendation systems, serving hundreds of millions of users daily, and has achieved good results.|近年来，近似最近邻搜索（ANNS）在现代搜索和推荐系统中发挥了关键作用，特别是在诸如增强检索生成（Retrieval-Augmented Generation）等新兴的大型语言模型（LLM）应用中。越来越多的研究致力于利用GPU的并行计算能力来满足ANNS的巨大需求。然而，现有的系统主要关注离线场景，忽视了在线应用的独特需求，这些需求需要实时插入新向量。这种局限性使得这些系统在现实场景中效率低下。此外，先前的架构由于依赖串行执行流，难以有效支持实时插入。在本文中，我们介绍了一种新型实时自适应多流GPU ANNS系统（RTAMS-GANNS）。我们的架构通过三个关键进展实现了其目标：1）我们首先研究了现有GPU ANNS系统中的实时插入机制，发现它们依赖于重复的复制和内存分配，这严重阻碍了GPU上的实时效率。作为解决方案，我们引入了一种基于内存块的动态向量插入算法，包括就地重排。2）为了实现并行实时向量插入，我们引入了一种多流并行执行模式，这与现有系统在单一流中串行操作不同。我们的系统利用动态资源池，允许多个流并发执行而无需额外的执行阻塞。3）通过广泛的实验和比较，我们的方法有效地处理了不同数据集上的不同QPS水平，延迟降低了高达40%。所提出的系统也已部署在实际的工业搜索和推荐系统中，每天服务于数亿用户，并取得了良好的效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Real-Time+Adaptive+Multi-Stream+GPU+System+For+Online+Approximate+Nearest+Neighborhood+Search)|0|
|[MERLIN: Multimodal & Multilingual Embedding for Recommendations at Large-scale via Item Associations](https://doi.org/10.1145/3627673.3680106)|Sambeet Tiady, Arihant Jain, Dween Rabius Sanny, Khushi Gupta, Srinivas Virinchi, Swapnil Gupta, Anoop Saladi, Deepak Gupta|Amazon.com, Bangalore, India|Product recommendations incentivize customers to make multi-unit purchases by surfacing relevant products, leading to lower cost per unit for e-commerce stores and lower prices for their customers. However, the humongous scale of products, implicit co-purchase asymmetry and variation in co-purchase behavior across different categories, are orthogonal problems to solve. To address these problems, we propose MERLIN (Multimodal & Multilingual Embedding for Recommendations at Large-scale via Item associations), a Graph Neural Network that generates product recommendations from a heterogeneous and directed product graph. We mine category associations to remove noisy product co-purchase associations, leading to higher quality recommendations. Leveraging product co-view relationships, we finetune SentenceBERT model for textual representation, and train a self-supervised knowledge distillation model to learn visual representation, which allows us to learn product representations which are multi-lingual and multi-modal in nature. We selectively align node embeddings leveraging co-viewed products. MERLIN model can handle node asymmetry by learning dual embeddings for each product, and can generate recommendations for cold-start products by employing catalog metadata such as title, category and image. Extensive offline experiments on internal and external datasets show that MERLIN model outperforms state-of-the-art baselines for node recommendation and link prediction task. We conduct ablations to quantify the impact of our model components and choices. Further, MERLIN model delivers significant improvement in sales measured through an A/B experiment.|产品推荐通过展示相关产品激励顾客进行多单位购买，从而降低电商商店的单位成本和顾客的购买价格。然而，产品规模的巨大、隐含的共同购买不对称性以及不同类别间共同购买行为的变化，是相互独立的问题。为了解决这些问题，我们提出了MERLIN（通过项目关联进行大规模推荐的多模态与多语言嵌入），这是一个从异构且有向的产品图中生成产品推荐的图神经网络。我们挖掘类别关联来消除噪声产品共同购买关联，从而提高推荐质量。利用产品共同浏览关系，我们微调了SentenceBERT模型以获取文本表示，并训练了一个自监督的知识蒸馏模型来学习视觉表示，这使我们能够学习到本质上是多语言和多模态的产品表示。我们通过共同浏览的产品有选择地对齐节点嵌入。MERLIN模型通过为每个产品学习双重嵌入来处理节点不对称性，并通过使用标题、类别和图像等目录元数据为冷启动产品生成推荐。在内、外部数据集上的广泛离线实验表明，MERLIN模型在节点推荐和链接预测任务上优于最先进的基线模型。我们进行了消融实验，以量化我们模型组件和选择的影响。此外，通过A/B实验测量的销售数据显示，MERLIN模型带来了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MERLIN:+Multimodal+&+Multilingual+Embedding+for+Recommendations+at+Large-scale+via+Item+Associations)|0|
|[Towards Advancing Text-Based User and Item Representation in Personalized Recommendation](https://doi.org/10.1145/3627673.3680270)|Hanjia Lyu|University of Rochester, Rochester, NY, USA|In the realm of personalized recommendation systems, accurately capturing user preferences and item characteristics is important for delivering relevant and satisfying recommendations. This study introduces innovative approaches using Large Language Models (LLMs) to generate detailed textual descriptions that enhance both user and item representations. We propose a dual strategy: for user representation, we employ supervised fine-tuning coupled with Retrieval-Augmented Generation (RAG) to keep the model current with dynamic user preferences; for item representation, we leverage the extensive knowledge base of LLMs to enrich item descriptions and infer traits from user interactions. These methods promise a deeper, more nuanced understanding of both users and items, potentially leading to superior recommendation accuracy. We adopt a rigorous evaluation methodology, ensuring the reliability of our results and the effectiveness of our proposed system. This paper discusses these methodologies, presents our preliminary findings, and highlights the potential of text-augmented profiles in advancing recommendation systems.|在个性化推荐系统领域，准确捕捉用户偏好和物品特征对于提供相关且令人满意的推荐至关重要。本研究引入了利用大型语言模型（LLMs）生成详细文本描述的创新方法，以增强用户和物品的表示。我们提出了一种双重策略：对于用户表示，我们采用监督微调结合检索增强生成（RAG），以使模型与动态用户偏好保持同步；对于物品表示，我们利用LLMs的广泛知识库来丰富物品描述，并从用户交互中推断特征。这些方法有望对用户和物品实现更深入、更细致的理解，从而可能提高推荐准确性。我们采用严格的评估方法，确保结果的可靠性和所提出系统的有效性。本文讨论了这些方法，展示了初步研究成果，并强调了文本增强型用户和物品描述在推进推荐系统方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Advancing+Text-Based+User+and+Item+Representation+in+Personalized+Recommendation)|0|
|[Contrastive Learning on Medical Intents for Sequential Prescription Recommendation](https://doi.org/10.1145/3627673.3679836)|Arya Hadizadeh Moghaddam, Mohsen Nayebi Kerdabadi, Mei Liu, Zijun Yao||Recent advancements in sequential modeling applied to Electronic Health Records (EHR) have greatly influenced prescription recommender systems. While the recent literature on drug recommendation has shown promising performance, the study of discovering a diversity of coexisting temporal relationships at the level of medical codes over consecutive visits remains less explored. The goal of this study can be motivated from two perspectives. First, there is a need to develop a sophisticated sequential model capable of disentangling the complex relationships across sequential visits. Second, it is crucial to establish multiple and diverse health profiles for the same patient to ensure a comprehensive consideration of different medical intents in drug recommendation. To achieve this goal, we introduce Attentive Recommendation with Contrasted Intents (ARCI), a multi-level transformer-based method designed to capture the different but coexisting temporal paths across a shared sequence of visits. Specifically, we propose a novel intent-aware method with contrastive learning, that links specialized medical intents of the patients to the transformer heads for extracting distinct temporal paths associated with different health profiles. We conducted experiments on two real-world datasets for the prescription recommendation task using both ranking and classification metrics. Our results demonstrate that ARCI has outperformed the state-of-the-art prescription recommendation methods and is capable of providing interpretable insights for healthcare practitioners.|近年来，应用于电子健康记录（EHR）的序列建模的进展极大地影响了处方推荐系统。尽管最近关于药物推荐的文献展示了令人鼓舞的性能，但在连续就诊中，在医疗代码层面发现多种共存的时间关系的研究仍较少探索。本研究的目标可以从两个角度来推动。首先，需要开发一种复杂的序列模型，能够解开跨连续就诊的复杂关系。其次，为同一患者建立多个多样化的健康档案至关重要，以确保在药物推荐中全面考虑不同的医疗意图。为了实现这一目标，我们引入了带有对比意图的注意力推荐（ARCI），这是一种基于多层变换器的方法，旨在捕捉共享序列就诊中不同的但共存的时间路径。具体来说，我们提出了一种新颖的意图感知方法，结合对比学习，将患者的专门医疗意图链接到变换器头部，以提取与不同健康档案相关的独特时间路径。我们在两个真实世界的数据集上进行了处方推荐任务的实验，使用了排名和分类指标。结果表明，ARCI在性能上优于最先进的处方推荐方法，并能够为医疗从业者提供可解释的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+on+Medical+Intents+for+Sequential+Prescription+Recommendation)|0|
|[Behavior-Dependent Linear Recurrent Units for Efficient Sequential Recommendation](https://doi.org/10.1145/3627673.3679717)|Chengkai Liu, Jianghao Lin, Hanzhou Liu, Jianling Wang, James Caverlee||Sequential recommender systems aims to predict the users' next interaction through user behavior modeling with various operators like RNNs and attentions. However, existing models generally fail to achieve the three golden principles for sequential recommendation simultaneously, i.e., training efficiency, low-cost inference, and strong performance. To this end, we propose RecBLR, an Efficient Sequential Recommendation Model based on Behavior-Dependent Linear Recurrent Units to accomplish the impossible triangle of the three principles. By incorporating gating mechanisms and behavior-dependent designs into linear recurrent units, our model significantly enhances user behavior modeling and recommendation performance. Furthermore, we unlock the parallelizable training as well as inference efficiency for our model by designing a hardware-aware scanning acceleration algorithm with a customized CUDA kernel. Extensive experiments on real-world datasets with varying lengths of user behavior sequences demonstrate RecBLR's remarkable effectiveness in simultaneously achieving all three golden principles - strong recommendation performance, training efficiency, and low-cost inference, while exhibiting excellent scalability to datasets with long user interaction histories.|顺序推荐系统旨在通过使用RNN和注意力等操作符对用户行为进行建模来预测用户的下一次交互。然而，现有的模型通常无法同时实现顺序推荐的三个黄金原则，即训练效率、低成本推理和强大的性能。为此，我们提出了RecBLR，一种基于行为依赖线性循环单元的高效顺序推荐模型，以实现这三个原则的不可能三角。通过将门控机制和行为依赖设计融入线性循环单元，我们的模型显著增强了用户行为建模和推荐性能。此外，我们通过设计一个硬件感知的扫描加速算法和定制的CUDA内核，为我们的模型解锁了可并行化的训练以及推理效率。在具有不同长度用户行为序列的实际数据集上的广泛实验表明，RecBLR在同时实现所有三个黄金原则方面表现出色——强大的推荐性能、训练效率和低成本推理，同时在处理具有长用户交互历史的数据集时展现出卓越的可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Behavior-Dependent+Linear+Recurrent+Units+for+Efficient+Sequential+Recommendation)|0|
|[MultiLoRA: Multi-Directional Low Rank Adaptation for Multi-Domain Recommendation](https://doi.org/10.1145/3627673.3679549)|Zijian Song, Wenhan Zhang, Lifang Deng, Jiandong Zhang, Kaigui Bian, Bin Cui|Lazada Group, Beijing, China; School of CS, Peking University & AI Innovation Center, Peking University, Beijing, China|To address the business needs of industrial recommendation systems, an increasing number of Multi-Domain Recommendation (MDR) methods are designed to improve recommendation performance on multiple domains simultaneously. Most MDR methods follow a multi-task learning paradigm, suffering from poor deployability and negative transfer. Due to the great success of large pre-trained models, the pre-train & fine-tune paradigm is attracting increasing attention. The latest methods introduce parameter-efficient fine-tuning techniques like prompt-tuning, showcasing high efficiency and effectiveness. However, these methods neglect the fundamental differences between recommendation and NLP tasks. The inadequate capacity of recommendation models restricts the effectiveness of prompts and adapters. Worse still, traditional natural domain division may group non-identically distributed samples into the same domain, violating the assumption of independent and identically distributed (i.i.d.) data. In this paper, we propose MultiLoRA, a Multi-directional Low Rank Adaptation paradigm for multi-domain recommendation. First we pre-train a universal model using all data samples. Then we conduct multiple domain divisions on the sample space. Under each division, we fine-tune the pre-trained model to obtain a set of domain-specific LoRAs. Finally, we learn a LoRA fusion module to integrate domain-specific preference patterns across multiple divisions. Experimental results on real-world datasets demonstrate notable advantages of MultiLoRA: (1) achieving SOTA performance, (2) showcasing remarkable compatibility, and (3) proving highly efficient, featuring only 2% trainable parameters compared to the backbone.|为了满足工业推荐系统的业务需求，越来越多的多领域推荐（MDR）方法被设计出来，以同时提升多个领域的推荐性能。大多数MDR方法遵循多任务学习的范式，存在部署性差和负迁移的问题。由于大型预训练模型取得了巨大成功，预训练与微调的范式正受到越来越多的关注。最新的方法引入了如提示调优等参数高效的微调技术，展示了高效性和有效性。然而，这些方法忽略了推荐任务与自然语言处理任务之间的根本差异。推荐模型的不足能力限制了提示词和适配器的有效性。更糟糕的是，传统的自然领域划分可能将非同分布的样本归入同一领域，违反了独立同分布（i.i.d.）数据的假设。在本文中，我们提出了MultiLoRA，一种面向多领域推荐的多向低秩适应范式。首先，我们使用所有数据样本预训练一个通用模型。然后，我们在样本空间上进行多次领域划分。在每次划分下，我们对预训练模型进行微调，以获得一组领域特定的LoRAs。最后，我们学习一个LoRA融合模块，以整合多个划分中的领域特定偏好模式。在真实世界数据集上的实验结果显示了MultiLoRA的显著优势：（1）实现了SOTA性能，（2）展示了出色的兼容性，（3）证明了高效率，仅具有与骨干模型相比2%的可训练参数。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiLoRA:+Multi-Directional+Low+Rank+Adaptation+for+Multi-Domain+Recommendation)|0|
|[Bridging User Dynamics: Transforming Sequential Recommendations with Schrödinger Bridge and Diffusion Models](https://doi.org/10.1145/3627673.3679756)|Wenjia Xie, Rui Zhou, Hao Wang, Tingjia Shen, Enhong Chen||Sequential recommendation has attracted increasing attention due to its ability to accurately capture the dynamic changes in user interests. We have noticed that generative models, especially diffusion models, which have achieved significant results in fields like image and audio, hold considerable promise in the field of sequential recommendation. However, existing sequential recommendation methods based on diffusion models are constrained by a prior distribution limited to Gaussian distribution, hindering the possibility of introducing user-specific information for each recommendation and leading to information loss. To address these issues, we introduce the Schrödinger Bridge into diffusion-based sequential recommendation models, creating the SdifRec model. This allows us to replace the Gaussian prior of the diffusion model with the user's current state, directly modeling the process from a user's current state to the target recommendation. Additionally, to better utilize collaborative information in recommendations, we propose an extended version of SdifRec called con-SdifRec, which utilizes user clustering information as a guiding condition to further enhance the posterior distribution. Finally, extensive experiments on multiple public benchmark datasets have demonstrated the effectiveness of SdifRec and con-SdifRec through comparison with several state-of-the-art methods. Further in-depth analysis has validated their efficiency and robustness.|顺序推荐因其能够准确捕捉用户兴趣的动态变化而受到越来越多的关注。我们注意到，生成模型，特别是扩散模型，在图像和音频等领域取得了显著成果，在顺序推荐领域也展现出巨大的潜力。然而，现有的基于扩散模型的顺序推荐方法受限于仅限于高斯分布的先验分布，这阻碍了在每次推荐中引入特定用户信息的可能性，导致信息损失。为了解决这些问题，我们将薛定谔桥引入基于扩散的顺序推荐模型，创建了SdifRec模型。这使得我们能够将扩散模型的高斯先验替换为用户当前状态，直接模拟从用户当前状态到目标推荐的过程。此外，为了更好地利用推荐中的协同信息，我们提出了SdifRec的扩展版本，称为con-SdifRec，它利用用户聚类信息作为指导条件，进一步增强后验分布。最后，在多个公共基准数据集上的广泛实验通过与几种最先进方法的比较，证明了SdifRec和con-SdifRec的有效性。进一步的深入分析验证了它们的效率和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+User+Dynamics:+Transforming+Sequential+Recommendations+with+Schrödinger+Bridge+and+Diffusion+Models)|0|
|[Generating Intent-aware Clarifying Questions in Conversational Information Retrieval Systems](https://doi.org/10.1145/3627673.3679851)|Ziliang Zhao, Zhicheng Dou, Yujia Zhou|Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China|Generating clarifying questions can effectively clarify users' complicated search intent in conversational search systems. However, existing methods based on pre-defined templates are inadequate in understanding explicit user intents, making generated questions monotonous or inaccurate in some cases. In this paper, we define the ''intent'' of a query as a verb representing the potential behavior, action, or task the user may take. We study generating clarifying questions from a new perspective by incorporating the intents explicitly to form ''intent-aware'' questions with high informativeness and accuracy. Since obtaining gold intent-aware questions is expensive, we propose a rule-based method and a continual learning model to generate intent-aware questions as weak supervision signals. The former leverages search results to mine contextual intent-aware words or phrases, and the latter relies on parallel corpora to paraphrase template-based questions by incorporating the intents. The generated weak supervision data are then applied to fine-tune a BART-based model for end-to-end intent-aware question generation. We also explore to prompt a large language model to generate intent-aware questions. Experimental results on a public clarification dataset demonstrate that our proposed methods improve users' search experience compared to existing methods.|生成澄清问题可以有效澄清对话搜索系统中用户复杂的搜索意图。然而，现有基于预定义模板的方法在理解明确用户意图方面存在不足，导致生成的问题在某些情况下单调或不准确。本文中，我们将查询的“意图”定义为用户可能采取的潜在行为、动作或任务的动词表示。我们通过明确结合意图，从新的角度研究生成信息丰富且准确的“意图感知”澄清问题。由于获取黄金标准的意图感知问题成本高昂，我们提出了一种基于规则的方法和一种持续学习模型，以生成意图感知的弱监督信号。前者利用搜索结果挖掘上下文中的意图感知词或短语，后者则依赖平行语料库通过结合意图对基于模板的问题进行释义。生成的弱监督数据随后用于微调基于BART的模型，以实现端到端的意图感知问题生成。我们还探索了引导大型语言模型生成意图感知问题的方法。在公开的澄清数据集上的实验结果表明，与现有方法相比，我们提出的方法提升了用户的搜索体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Intent-aware+Clarifying+Questions+in+Conversational+Information+Retrieval+Systems)|0|
|[Enhancing E-Commerce Query Rewriting: A Large Language Model Approach with Domain-Specific Pre-Training and Reinforcement Learning](https://doi.org/10.1145/3627673.3680109)|Aijun Dai, Zhenyu Zhu, Haiqing Hu, Guoyu Tang, Lin Liu, Sulong Xu|JD.com, Beijing, China; JD.com, Bejing, China|In the domain of e-commerce, query rewriting is a potent strategy for bridging the lexical gap between search queries and product descriptions, thereby enhancing the recall rate of search engines. This research introduces a query rewriting framework predicated on large language models (LLM), encompassing three phases of training: domain-specific pre-training, supervised fine-tuning (SFT) and reinforcement learning (RL) for objective alignment. To detail, the process initiates with domain-specific pre-training using consumer behavior data and product descriptions from JD.com. Subsequently, we filter and utilize high-quality query-rewrite pairs for SFT. The final stage employs RL to refine the model's objective alignment, utilizing an offline search system as the simulation environment. The RL's training reward is derived from the recall rate, aiming to optimize the number of relevant products the rewrites retrieve. Through offline evaluations, our method has demonstrated its capacity to substantially enhance the efficacy of LLMs for e-commerce query rewriting. Moreover, online A/B testing has corroborated that our approach significantly boosts the number of purchases made per user (UCVR). Since December 2023, our approach has been successfully implemented on JD.com, one of China's most frequented online shopping platforms.|在电子商务领域，查询重写是弥合搜索查询与产品描述之间词汇鸿沟的有效策略，从而提高搜索引擎的召回率。本研究引入了一种基于大型语言模型（LLM）的查询重写框架，该框架包括三个训练阶段：领域特定的预训练、有监督的微调（SFT）和用于目标对齐的强化学习（RL）。具体而言，该过程首先使用京东的消费行为数据和产品描述进行领域特定的预训练。随后，我们筛选并利用高质量的查询-重写对进行SFT。最后阶段采用RL来优化模型的目标对齐，利用离线搜索系统作为模拟环境。RL的训练奖励基于召回率，旨在优化重写查询所检索到的相关产品数量。通过离线评估，我们的方法展示了其显著提升LLM在电子商务查询重写中效能的能力。此外，在线A/B测试证实了我们的方法显著提高了每位用户的购买转化率（UCVR）。自2023年12月以来，我们的方法已成功应用于京东，这是中国访问量最大的在线购物平台之一。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+E-Commerce+Query+Rewriting:+A+Large+Language+Model+Approach+with+Domain-Specific+Pre-Training+and+Reinforcement+Learning)|0|
|[Deep Uncertainty-Based Explore for Index Construction and Retrieval in Recommendation System](https://doi.org/10.1145/3627673.3680077)|Xin Jiang, Kaiqiang Wang, Yinlong Wang, Fengchang Lv, Taiyang Peng, Shuai Yang, Xianteng Wu, Pengye Zhang, Shuo Yuan, Yifan Zeng||In recommendation systems, the relevance and novelty of the final results are selected through a cascade system of Matching -> Ranking -> Strategy. The matching model serves as the starting point of the pipeline and determines the upper bound of the subsequent stages. Balancing the relevance and novelty of matching results is a crucial step in the design and optimization of recommendation systems, contributing significantly to improving recommendation quality. However, the typical matching algorithms have not simultaneously addressed the relevance and novelty perfectly. One main reason is that deep matching algorithms exhibit significant uncertainty when estimating items in the long tail (e.g., due to insufficient training samples) items.The uncertainty not only affects the training of the models but also influences the confidence in the index construction and beam search retrieval process of these models. This paper proposes the UICR (Uncertainty-based explore for Index Construction and Retrieval) algorithm, which introduces the concept of uncertainty modeling in the matching stage and achieves multi-task modeling of model uncertainty and index uncertainty. The final matching results are obtained by combining the relevance score and uncertainty score infered by the model. Experimental results demonstrate that the UICR improves novelty without sacrificing relevance on realworld industrial productive environments and multiple open-source datasets. Remarkably, online A/B test results of display advertising in Shopee demonstrates the effectiveness of the proposed algorithm.|在推荐系统中，最终结果的相关性和新颖性是通过匹配（Matching）->排序（Ranking）->策略（Strategy）的级联系统来选择的。匹配模型作为管道的起点，决定了后续阶段的上限。平衡匹配结果的相关性和新颖性是推荐系统设计和优化的关键步骤，对提高推荐质量有显著贡献。然而，典型的匹配算法并没有同时完美地解决相关性和新颖性问题。主要原因之一是深度匹配算法在估计长尾（例如，由于训练样本不足）项目时表现出显著的不确定性。这种不确定性不仅影响模型的训练，还影响这些模型在索引构建和束搜索检索过程中的置信度。本文提出了基于不确定性的索引构建和检索（UICR）算法，该算法在匹配阶段引入了不确定性建模的概念，实现了模型不确定性和索引不确定性的多任务建模。最终的匹配结果是通过结合模型推断的相关性分数和不确定性分数获得的。实验结果表明，UICR在不牺牲相关性的情况下提高了新颖性，在现实世界的工业生产环境和多个开源数据集上都得到了验证。值得注意的是，Shopee展示广告的在线A/B测试结果证明了所提出算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Uncertainty-Based+Explore+for+Index+Construction+and+Retrieval+in+Recommendation+System)|0|
|[Towards Seamless User Query to REST API Conversion](https://doi.org/10.1145/3627673.3680275)|Han Xu|University of Illinois Urbana-Champaign, Urbana, IL, USA|Integrating Large Language Models (LLMs) with external tools and APIs is essential for fields such as information retrieval and knowledge management. While LLMs have made significant strides, their effective integration with external APIs-essential for real-world applications-remains challenging. This paper introduces RESTful-Llama, a novel method designed to empower open-source LLMs to accurately convert natural language instructions into well-formed RESTful API calls. Moreover, RESTful-Llama utilizes DOC-Prompt, a newly proposed technique for generating fine-tuning datasets from publicly available API documentation. Initial experiments demonstrate that RESTful-Llama significantly enhances the accuracy of generated REST API requests.|将大型语言模型（LLMs）与外部工具和API集成对于信息检索和知识管理等领域至关重要。尽管LLMs取得了显著进展，但它们与外部API的有效集成——这对于实际应用至关重要——仍然具有挑战性。本文介绍了RESTful-Llama，这是一种新颖的方法，旨在使开源LLMs能够准确地将自然语言指令转换为格式良好的RESTful API调用。此外，RESTful-Llama利用了DOC-Prompt，这是一种新提出的技术，用于从公开可用的API文档生成微调数据集。初步实验表明，RESTful-Llama显著提高了生成的REST API请求的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Seamless+User+Query+to+REST+API+Conversion)|0|
|[Product Retrieval and Ranking for Alphanumeric Queries](https://doi.org/10.1145/3627673.3679080)|Hadeel Saadany, Swapnil Bhosale, Samarth Agrawal, Zhe Wu, Constantin Orasan, Diptesh Kanojia|People-Centred AI, University of Surrey, Guildford, United Kingdom; eBay Inc., Seattle, USA; Centre for Translation Studies, University of Surrey, Guildford, United Kingdom; eBay Inc., San Jose, USA|This talk addresses the challenge of improving user experience on e-commerce platforms by enhancing product ranking relevant to user's search queries. Queries such as S2716DG consist of alphanumeric characters where a letter or number can signify important detail for the product/model. Speaker describes recent research where we curate samples from existing datasets at eBay, manually annotated with buyer-centric relevance scores, and centrality scores which reflect how well the product title matches the user's intent. We introduce a User-intent Centrality Optimization (UCO) approach for existing models, which optimizes for the user intent in semantic product search. To that end, we propose a dual-loss based optimization to handle hard negatives, i.e., product titles that are semantically relevant but do not reflect the user's intent. Our contributions include curating a challenging evaluation set and implementing UCO, resulting in significant improvements in product ranking efficiency, observed for different evaluation metrics. Our work aims to ensure that the most buyer-centric titles for a query are ranked higher, thereby, enhancing the user experience on e-commerce platforms.|本次演讲探讨了通过提升与用户搜索查询相关的产品排序来改善电子商务平台用户体验的挑战。诸如S2716DG之类的查询包含字母数字字符，其中字母或数字可能代表产品/型号的重要细节。演讲者描述了最近的研究，我们在eBay的现有数据集中精选样本，这些样本经过手动标注，具有以买家为中心的相关性评分和中心性评分，后者反映了产品标题与用户意图的匹配程度。我们引入了一种用户意图中心性优化（User-intent Centrality Optimization, UCO）方法，用于现有模型，该方法优化了语义产品搜索中的用户意图。为此，我们提出了一种基于双重损失的优化方法来处理硬负样本，即那些在语义上相关但未反映用户意图的产品标题。我们的贡献包括策划一个具有挑战性的评估集和实现UCO，从而在不同的评估指标下显著提高了产品排序效率。我们的工作旨在确保对于一个查询，最符合买家意图的标题排名更高，从而增强电子商务平台的用户体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Product+Retrieval+and+Ranking+for+Alphanumeric+Queries)|0|
|[PTSR: Prefix-Target Graph-based Sequential Recommendation](https://doi.org/10.1145/3627673.3679718)|Jiayu Chen, Xiaoyu Du, Yonghua Pan, Jinhui Tang|Nanjing University of Science and Technology, Nanjing, China|Sequential recommendation approaches predict the next items (targets) by analyzing prefix subsequences. These methods primarily model the correlations between prefixes and targets but often neglect the inherent correlations among prefixes and items. In this paper, we propose a Prefix-Target Graph-based Sequential Recommendation Approach (PTSR), which constructs a prefix-target graph (PTG) to collect observed correlations among prefixes and targets. It utilizes a graph neural network to model these inherent correlations, thus improving the item representations used in the predictive model. Specifically, prefixes linked to the same target reflect similar intents, while targets linked to the same prefix indicate available choices. This allows the graph neural network to effectively capture high-level correlations among prefixes and items, enhancing recommendation accuracy. We conduct extensive experiments on four real-world datasets to demonstrate the superiority of PTSR compared to state-of-the-art (SOTA) sequential recommendation methods. The source code of the PTSR is available at https://github.com/TosakRin/PTSR.|顺序推荐方法通过分析前缀子序列来预测下一个项目（目标）。这些方法主要建模前缀与目标之间的关联，但往往忽略了前缀和项目之间固有的关联。本文提出了一种基于前缀-目标图的顺序推荐方法（PTSR），该方法构建了一个前缀-目标图（PTG）以收集前缀与目标之间观察到的关联。它利用图神经网络来建模这些固有关联，从而改进预测模型中使用的项目表示。具体而言，与同一目标相连的前缀反映了相似的意图，而与同一前缀相连的目标则表示可用的选择。这使得图神经网络能够有效地捕捉前缀和项目之间的高层次关联，从而提高推荐准确性。我们在四个真实世界数据集上进行了广泛的实验，以证明PTSR相较于最先进的（SOTA）顺序推荐方法的优越性。PTSR的源代码可在https://github.com/TosakRin/PTSR获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PTSR:+Prefix-Target+Graph-based+Sequential+Recommendation)|0|
|[PACIFIC: Enhancing Sequential Recommendation via Preference-aware Causal Intervention and Counterfactual Data Augmentation](https://doi.org/10.1145/3627673.3679803)|Jinpeng Chen, Huachen Guan, Huan Li, Fan Zhang, Liwei Huang, Guangyao Pang, Xiongnan Jin|; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Beijing Institute of Remote Sensing, Beijing, China|Sequential recommendation has been receiving increasing attention from researchers. Existing sequential recommendation models leverage deep learning models to capture sequential features. However, these methods ignore confounders in the recommendation process, which can lead the model to learn incorrect correlations and fail to accurately capture users' true preferences. Moreover, these methods rely on extensive interaction sequences, but sequential data often suffers from sparsity issues. To address these limitations, this paper proposes a P reference- a ware C ausal I ntervention and Counter f a c tual Data Augmentation ( Pacific ) framework to enhance sequential recommendation. Initially, we model the causal graph of sequential recommendation and categorize user preferences into global long-term preferences, local long-term preferences, and short-term preferences. Then, we introduce the front-door criterion to eliminate the interference of confounders and design different self-attention mechanisms to estimate the causal effects, aiming to capture users' true preferences. In addition, based on counterfactual thinking, we design a counterfactual data augmentation module to generate enriched sequences. Experimental results on four real-world datasets demonstrate the superiority of our proposed approach over state-of-the-art sequential recommendation methods.|序列推荐近年来引起了研究人员的广泛关注。现有的序列推荐模型利用深度学习模型来捕捉序列特征。然而，这些方法忽略了推荐过程中的混杂因素，这可能导致模型学习到错误的关联，无法准确捕捉用户的真实偏好。此外，这些方法依赖于大量的交互序列，但序列数据往往存在稀疏性问题。为了解决这些局限性，本文提出了一个P reference-a ware C ausal I ntervention and Counter f a c tual Data Augmentation（Pacific）框架，以增强序列推荐。首先，我们建模了序列推荐的因果图，并将用户偏好分为全局长期偏好、局部长期偏好和短期偏好。然后，我们引入了前门准则来消除混杂因素的干扰，并设计了不同的自注意力机制来估计因果效应，旨在捕捉用户的真实偏好。此外，基于反事实思维，我们设计了一个反事实数据增强模块，以生成丰富的序列。在四个真实世界数据集上的实验结果表明，我们提出的方法优于最先进的序列推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PACIFIC:+Enhancing+Sequential+Recommendation+via+Preference-aware+Causal+Intervention+and+Counterfactual+Data+Augmentation)|0|
|[Context Matters: Enhancing Sequential Recommendation with Context-aware Diffusion-based Contrastive Learning](https://doi.org/10.1145/3627673.3679655)|Ziqiang Cui, Haolun Wu, Bowei He, Ji Cheng, Chen Ma|City University of Hong Kong, Hong Kong SAR, Hong Kong; McGill University, Montréal, Canada|Contrastive learning has been effectively utilized to enhance the training of sequential recommendation models by leveraging informative self-supervised signals. Most existing approaches generate augmented views of the same user sequence through random augmentation and subsequently maximize their agreement in the representation space. However, these methods often neglect the rationality of the augmented samples. Due to significant uncertainty, random augmentation can disrupt the semantic information and interest evolution patterns inherent in the original user sequences. Moreover, pulling semantically inconsistent sequences closer in the representation space can render the user sequence embeddings insensitive to variations in user preferences, which contradicts the primary objective of sequential recommendation. To address these limitations, we propose the Context-aware Diffusion-based Contrastive Learning for Sequential Recommendation, named CaDiRec. The core idea is to leverage context information to generate more reasonable augmented views. Specifically, CaDiRec employs a context-aware diffusion model to generate alternative items for the given positions within a sequence. These generated items are aligned with their respective context information and can effectively replace the corresponding original items, thereby generating a positive view of the original sequence. By considering two different augmentations of the same user sequence, we can construct a pair of positive samples for contrastive learning. To ensure representation cohesion, we train the entire framework in an end-to-end manner, with shared item embeddings between the diffusion model and the recommendation model. Extensive experiments on five benchmark datasets demonstrate the advantages of our proposed method over existing baselines.|对比学习已被有效利用，通过利用信息丰富的自监督信号来增强序列推荐模型的训练。大多数现有方法通过随机增强生成同一用户序列的增强视图，并在表示空间中最大化它们的共识。然而，这些方法往往忽略了增强样本的合理性。由于存在显著的不确定性，随机增强可能会破坏原始用户序列中固有的语义信息和兴趣演变模式。此外，在表示空间中将语义不一致的序列拉近会导致用户序列嵌入对用户偏好变化的敏感性降低，这与序列推荐的主要目标相悖。为了解决这些局限性，我们提出了基于上下文感知的扩散对比学习用于序列推荐，命名为CaDiRec。其核心思想是利用上下文信息生成更合理的增强视图。具体来说，CaDiRec采用上下文感知的扩散模型为序列中给定位置生成替代项。这些生成的项与其上下文信息对齐，并能有效替换相应的原始项，从而生成原始序列的正视图。通过考虑同一用户序列的两种不同增强，我们可以构建一对用于对比学习的正样本。为确保表示的一致性，我们以端到端的方式训练整个框架，并在扩散模型和推荐模型之间共享项嵌入。在五个基准数据集上的广泛实验证明了我们提出的方法相对于现有基线的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context+Matters:+Enhancing+Sequential+Recommendation+with+Context-aware+Diffusion-based+Contrastive+Learning)|0|
|[A General Strategy Graph Collaborative Filtering for Recommendation Unlearning](https://doi.org/10.1145/3627673.3679637)|Yongjing Hao, Fuzhen Zhuang, Deqing Wang, Guanfeng Liu, Victor S. Sheng, Pengpeng Zhao|Soochow University, Suzhou, Jiangsu, China; Beihang University, Beijing, China; Macquarie University, Sydney, Australia; Texas Tech University, Lubbock, USA|Recommender systems play a crucial role in delivering personalized services to users, but the increasing volume of user data raises significant concerns about privacy, security, and utility. However, existing machine unlearning methods cannot be directly applied to recommendation systems as they overlook the collaborative information shared across users and items. More recently, a method known as RecEraser was introduced, offering partitioning and aggregation-based approaches. Nevertheless, these approaches have limitations due to their inadequate handling of additional overhead costs. In this paper, we propose A General Strategy Graph Collaborative Filtering for Recommendation Unlearning (GSGCF-RU), which is a novel model-agnostic learnable delete operator that optimizes unlearning edge consistency and feature representation consistency. Specifically, the GSGCF-RU model utilizes unlearning edge consistency to eliminate the influence of deleted elements, followed by feature representation consistency to retain knowledge after deletion. Lastly, experimental results on three real-world public benchmarks demonstrate that GSGCF-RU not only achieves efficient recommendation unlearning but also surpasses state-of-the-art methods in terms of model utility. The source code can be found at https://github.com/YongjingHao/GSGCF-RU.|推荐系统在为用户提供个性化服务方面起着至关重要的作用，但随着用户数据量的增加，隐私、安全和效用问题日益突出。然而，现有的机器遗忘方法无法直接应用于推荐系统，因为它们忽略了用户和物品之间共享的协作信息。最近，一种名为RecEraser的方法被提出，采用了基于分区和聚合的策略。然而，这些方法由于未能充分处理额外的开销成本而存在局限性。本文提出了一种通用策略图协同过滤推荐遗忘（GSGCF-RU）方法，这是一种新颖的模型无关可学习删除操作符，优化了遗忘边缘一致性和特征表示一致性。具体而言，GSGCF-RU模型利用遗忘边缘一致性来消除已删除元素的影响，随后通过特征表示一致性来保留删除后的知识。最后，在三个真实世界的公共基准上的实验结果表明，GSGCF-RU不仅实现了高效的推荐遗忘，而且在模型效用方面超越了最先进的方法。源代码可在https://github.com/YongjingHao/GSGCF-RU找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+General+Strategy+Graph+Collaborative+Filtering+for+Recommendation+Unlearning)|0|
|[Interpretable Triplet Importance for Personalized Ranking](https://doi.org/10.1145/3627673.3679536)|Bowei He, Chen Ma||Personalized item ranking has been a crucial component contributing to the performance of recommender systems. As a representative approach, pairwise ranking directly optimizes the ranking with user implicit feedback by constructing (user, positive item, negative item) triplets. Several recent works have noticed that treating all triplets equally may hardly achieve the best effects. They assign different importance scores to negative items, user-item pairs, or triplets, respectively. However, almost all the generated importance scores are groundless and hard to interpret, thus far from trustworthy and transparent. To tackle these, we propose the Triplet Shapley – a Shapely value-based method to measure the triplet importance in an interpretable manner. Due to the huge number of triplets, we transform the original Shapley value calculation to the Monte Carlo (MC) approximation, where the guarantee for the approximation unbiasedness is also provided. To stabilize the MC approximation, we adopt a control covariates-based method. Finally, we utilize the triplet Shapley value to guide the resampling of important triplets for benefiting the model learning. Extensive experiments are conducted on six public datasets involving classical matrix factorization- and graph neural network-based recommendation models. Empirical results and subsequent analysis show that our model consistently outperforms the state-of-the-art methods.|个性化项目排序已成为提升推荐系统性能的关键组成部分。作为代表性方法，成对排序通过构建（用户，正项，负项）三元组，直接优化用户隐式反馈的排序。近期研究注意到，同等对待所有三元组可能难以达到最佳效果。因此，它们分别对负项、用户-项目对或三元组分配不同的重要性分数。然而，几乎所有生成的重要性分数都缺乏依据且难以解释，因此远非可靠和透明。为解决这些问题，我们提出了三元组Shapley——一种基于Shapley值的方法，以可解释的方式衡量三元组的重要性。由于三元组数量庞大，我们将原始Shapley值计算转换为蒙特卡洛（MC）近似，并提供了近似无偏性的保证。为稳定MC近似，我们采用了基于控制协变量的方法。最后，我们利用三元组Shapley值来指导重要三元组的重新采样，以促进模型学习。在涉及经典矩阵分解和图神经网络推荐模型的六个公开数据集上进行了广泛的实验。实证结果和后续分析表明，我们的模型始终优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Triplet+Importance+for+Personalized+Ranking)|0|
|[CausalMed: Causality-Based Personalized Medication Recommendation Centered on Patient Health State](https://doi.org/10.1145/3627673.3679542)|Xiang Li, Shunpan Liang, Yu Lei, Chen Li, Yulei Hou, Dashun Zheng, Tengfei Ma|; Xinjiang University of Science & Technology School of Information Science and Engineering; Yanshan University School of Mechanical Engineering; Yanshan University School of Information Science and Engineering; Hunan University School of Computer Science and Engineering|Medication recommendation systems are developed to recommend suitable medications tailored to specific patient. Previous researches primarily focus on learning medication representations, which have yielded notable advances. However, these methods are limited to capturing personalized patient representations due to the following primary limitations: (i) unable to capture the differences in the impact of diseases/procedures on patients across various patient health states; (ii) fail to model the direct causal relationships between medications and specific health state of patients, resulting in an inability to determine which specific disease each medication is treating. To address these limitations, we propose CausalMed, a patient health state-centric model capable of enhancing the personalization of patient representations. Specifically, CausalMed first captures the causal relationship between diseases/procedures and medications through causal discovery and evaluates their causal effects. Building upon this, CausalMed focuses on analyzing the health state of patients, capturing the dynamic differences of diseases/procedures in different health states of patients, and transforming diseases/procedures into medications on direct causal relationships. Ultimately, CausalMed integrates information from longitudinal visits to recommend medication combinations. Extensive experiments on real-world datasets show that our method learns more personalized patient representation and outperforms state-of-the-art models in accuracy and safety.|药物推荐系统旨在为特定患者推荐合适的药物。以往的研究主要集中在学习药物表征上，取得了显著进展。然而，这些方法由于以下主要限制，无法捕捉个性化的患者表征：（i）无法捕捉疾病/程序对不同患者健康状态影响的差异；（ii）未能建模药物与患者特定健康状态之间的直接因果关系，导致无法确定每种药物具体治疗哪种疾病。为解决这些限制，我们提出了CausalMed，一种以患者健康状态为中心的模型，能够增强患者表征的个性化。具体来说，CausalMed首先通过因果发现捕捉疾病/程序与药物之间的因果关系，并评估其因果效应。在此基础上，CausalMed专注于分析患者的健康状态，捕捉疾病/程序在不同健康状态下的动态差异，并基于直接因果关系将疾病/程序转化为药物。最终，CausalMed整合了纵向就诊信息，推荐药物组合。在真实世界数据集上的广泛实验表明，我们的方法学习到了更个性化的患者表征，并在准确性和安全性方面优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CausalMed:+Causality-Based+Personalized+Medication+Recommendation+Centered+on+Patient+Health+State)|0|
|[PSNE: Efficient Spectral Sparsification Algorithms for Scaling Network Embedding](https://doi.org/10.1145/3627673.3679540)|Longlong Lin, Yunfeng Yu, Zihao Wang, Zeli Wang, Yuying Zhao, Jin Zhao, Tao Jia||Network embedding has numerous practical applications and has received extensive attention in graph learning, which aims at mapping vertices into a low-dimensional and continuous dense vector space by preserving the underlying structural properties of the graph. Many network embedding methods have been proposed, among which factorization of the Personalized PageRank (PPR for short) matrix has been empirically and theoretically well supported recently. However, several fundamental issues cannot be addressed. (1) Existing methods invoke a seminal Local Push subroutine to approximate \textit{a single} row or column of the PPR matrix. Thus, they have to execute $n$ ($n$ is the number of nodes) Local Push subroutines to obtain a provable PPR matrix, resulting in prohibitively high computational costs for large $n$. (2) The PPR matrix has limited power in capturing the structural similarity between vertices, leading to performance degradation. To overcome these dilemmas, we propose PSNE, an efficient spectral s\textbf{P}arsification method for \textbf{S}caling \textbf{N}etwork \textbf{E}mbedding, which can fast obtain the embedding vectors that retain strong structural similarities. Specifically, PSNE first designs a matrix polynomial sparser to accelerate the calculation of the PPR matrix, which has a theoretical guarantee in terms of the Frobenius norm. Subsequently, PSNE proposes a simple but effective multiple-perspective strategy to enhance further the representation power of the obtained approximate PPR matrix. Finally, PSNE applies a randomized singular value decomposition algorithm on the sparse and multiple-perspective PPR matrix to get the target embedding vectors. Experimental evaluation of real-world and synthetic datasets shows that our solutions are indeed more efficient, effective, and scalable compared with ten competitors.|网络嵌入在图学习领域具有众多实际应用，并受到了广泛关注。其目标是将顶点映射到一个低维且连续的密集向量空间，同时保留图的底层结构特性。已有多种网络嵌入方法被提出，其中个性化PageRank（简称PPR）矩阵的分解方法近期在实践和理论上都得到了良好的支持。然而，仍存在几个基本问题无法解决。（1）现有方法调用一个开创性的Local Push子程序来近似PPR矩阵的单行或单列。因此，它们需要执行n（n为节点数量）次Local Push子程序以获得可证明的PPR矩阵，这对于大规模n来说计算成本极高。（2）PPR矩阵在捕捉顶点间结构相似性方面能力有限，导致性能下降。为解决这些问题，我们提出了PSNE，这是一种高效的谱稀疏化方法，用于扩展网络嵌入，能够快速获取保留强结构相似性的嵌入向量。具体而言，PSNE首先设计了一种矩阵多项式稀疏化方法，以加速PPR矩阵的计算，该方法在Frobenius范数方面具有理论保证。随后，PSNE提出了一种简单但有效的多视角策略，进一步增强所获得的近似PPR矩阵的表示能力。最后，PSNE对稀疏且多视角的PPR矩阵应用随机奇异值分解算法，以获取目标嵌入向量。对真实世界和合成数据集的实验评估表明，与十个竞争对手相比，我们的解决方案确实更加高效、有效且可扩展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PSNE:+Efficient+Spectral+Sparsification+Algorithms+for+Scaling+Network+Embedding)|0|
|[UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential Recommendations](https://doi.org/10.1145/3627673.3679689)|Yang Liu, Yitong Wang, Chenyue Feng||Representation learning in sequential recommendation is critical for accurately modeling user interaction patterns and improving recommendation precision. However, existing approaches predominantly emphasize item-to-item transitions, often neglecting the time intervals between interactions, which are closely related to behavior pattern changes. Additionally, broader interaction attributes, such as item frequency, are frequently overlooked. We found that both sequences with more uniform time intervals and items with higher frequency yield better prediction performance. Conversely, non-uniform sequences exacerbate user interest drift and less-frequent items are difficult to model due to sparse sampling, presenting unique challenges inadequately addressed by current methods. In this paper, we propose UniRec, a novel bidirectional enhancement sequential recommendation method. UniRec leverages sequence uniformity and item frequency to enhance performance, particularly improving the representation of non-uniform sequences and less-frequent items. These two branches mutually reinforce each other, driving comprehensive performance optimization in complex sequential recommendation scenarios. Additionally, we present a multidimensional time module to further enhance adaptability. To the best of our knowledge, UniRec is the first method to utilize the characteristics of uniformity and frequency for feature augmentation. Comparing with eleven advanced models across four datasets, we demonstrate that UniRec outperforms SOTA models significantly. The code is available at https://github.com/Linxi000/UniRec.|在序列推荐中的表示学习对于准确建模用户交互模式和提升推荐精度至关重要。然而，现有方法主要侧重于项目间的转换，往往忽视了交互之间的时间间隔，这些时间间隔与行为模式的变化密切相关。此外，更广泛的交互属性，如项目频率，也经常被忽略。我们发现，时间间隔更均匀的序列和频率更高的项目能带来更好的预测性能。相反，时间间隔不均匀的序列会加剧用户兴趣的漂移，而采样稀疏的低频项目则难以建模，这为当前方法带来了独特的挑战。在本文中，我们提出了UniRec，一种新颖的双向增强序列推荐方法。UniRec利用序列均匀性和项目频率来提升性能，特别是在改进非均匀序列和低频项目的表示方面。这两个分支相互强化，推动在复杂序列推荐场景中的全面性能优化。此外，我们还引入了一个多维度时间模块，以进一步增强适应性。据我们所知，UniRec是首个利用均匀性和频率特性进行特征增强的方法。通过与四个数据集上的十一种先进模型进行比较，我们展示了UniRec显著优于现有的最先进模型。代码已公开在https://github.com/Linxi000/UniRec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniRec:+A+Dual+Enhancement+of+Uniformity+and+Frequency+in+Sequential+Recommendations)|0|
|[Collaborative Cross-modal Fusion with Large Language Model for Recommendation](https://doi.org/10.1145/3627673.3679596)|Zhongzhou Liu, Hao Zhang, Kuicai Dong, Yuan Fang||Despite the success of conventional collaborative filtering (CF) approaches for recommendation systems, they exhibit limitations in leveraging semantic knowledge within the textual attributes of users and items. Recent focus on the application of large language models for recommendation (LLM4Rec) has highlighted their capability for effective semantic knowledge capture. However, these methods often overlook the collaborative signals in user behaviors. Some simply instruct-tune a language model, while others directly inject the embeddings of a CF-based model, lacking a synergistic fusion of different modalities. To address these issues, we propose a framework of Collaborative Cross-modal Fusion with Large Language Models, termed CCF-LLM, for recommendation. In this framework, we translate the user-item interactions into a hybrid prompt to encode both semantic knowledge and collaborative signals, and then employ an attentive cross-modal fusion strategy to effectively fuse latent embeddings of both modalities. Extensive experiments demonstrate that CCF-LLM outperforms existing methods by effectively utilizing semantic and collaborative signals in the LLM4Rec context.|尽管传统的协同过滤（CF）方法在推荐系统中取得了成功，但它们在利用用户和项目文本属性中的语义知识方面存在局限性。最近，大语言模型在推荐系统中的应用（LLM4Rec）强调了其在有效捕捉语义知识方面的能力。然而，这些方法往往忽略了用户行为中的协同信号。有些方法仅仅是通过指令调整语言模型，而另一些方法则直接注入基于协同过滤模型的嵌入，缺乏不同模态之间的协同融合。为了解决这些问题，我们提出了一种名为CCF-LLM的大语言模型协同跨模态融合框架，用于推荐系统。在该框架中，我们将用户-项目交互转换为混合提示，以编码语义知识和协同信号，然后采用一种注意力跨模态融合策略，有效地融合两种模态的潜在嵌入。广泛的实验表明，CCF-LLM在LLM4Rec背景下，通过有效利用语义和协同信号，优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Cross-modal+Fusion+with+Large+Language+Model+for+Recommendation)|0|
|[Re-evaluating the Command-and-Control Paradigm in Conversational Search Interactions](https://doi.org/10.1145/3627673.3679588)|Johanne R. Trippas, Luke Gallagher, Joel Mackenzie|RMIT University, Melbourne, Australia; The University of Melbourne, Melbourne, Australia; The University of Queensland, Brisbane, Australia|Conversational assistants are becoming prevalent among the wider population due to their simplicity and increasing utility. However, the shortcomings of these tools are as renowned as their benefits. In this work, we present a "first look" at an extensive collection of conversational queries, aiming to identify limitations and improvement opportunities specifically related to information access (i.e., search interactions). We explore over 600,000 Google Assistant interactions from 173 unique users, examining usage trends and the resulting deficiencies and strengths of these assistants. We aim to provide a balanced assessment, highlighting the assistant's shortcomings in supporting users and delivering relevant information to user needs and areas where it demonstrates a reasonable response to user inputs. Our analysis shows that, although most users conduct information-seeking tasks, there is little evidence of complex information-seeking behaviour, with most interactions consisting of simple, imperative instructions. Finally, we find that conversational devices allow users to benefit from increased naturalistic interactions and the ability to apply acquired information in situ, a novel observation for conversational information seeking.|对话助手因其简便性和日益增加的实用性，在更广泛的人群中变得普及。然而，这些工具的缺点与其优点同样为人所知。在这项工作中，我们首次对大量对话查询进行了深入分析，旨在识别与信息访问（即搜索交互）相关的局限性和改进机会。我们研究了来自173名独特用户的超过600,000次Google Assistant交互，考察了使用趋势以及这些助手的缺陷和优势。我们的目标是提供一个平衡的评估，突出助手在支持用户和传递相关信息以满足用户需求方面的不足，以及在合理响应用户输入的领域。我们的分析显示，尽管大多数用户进行信息检索任务，但几乎没有证据表明存在复杂的信息检索行为，大多数交互由简单的、命令式的指令组成。最后，我们发现对话设备使用户能够受益于更加自然的交互，并能够在现场应用所获取的信息，这是对话信息检索的一个新颖观察。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Re-evaluating+the+Command-and-Control+Paradigm+in+Conversational+Search+Interactions)|0|
|[Collaborative Alignment for Recommendation](https://doi.org/10.1145/3627673.3679535)|Chen Wang, Liangwei Yang, Zhiwei Liu, Xiaolong Liu, Mingdai Yang, Yueqing Liang, Philip S. Yu|Salesforce AI Research, Palo Alto, CA, USA; University of Illinois Chicago, Chicgao, IL, USA; Illinois Institute of Technology, Chicago, IL, USA; University of Illinois Chicago, Chicago, IL, USA|Traditional recommender systems have primarily relied on identity representations (IDs) to model users and items. Recently, the integration of pre-trained language models (PLMs) has enhanced the capability to capture semantic descriptions of items. However, while PLMs excel in few-shot, zero-shot, and unified modeling scenarios, they often overlook the crucial signals from collaborative filtering (CF), resulting in suboptimal performance when sufficient training data is available. To effectively combine semantic representations with the CF signal and enhance recommender system performance in both warm and cold settings, two major challenges must be addressed: (1) bridging the gap between semantic and collaborative representation spaces, and (2) refining while preserving the integrity of semantic representations. In this paper, we introduce CARec, a novel model that adeptly integrates collaborative filtering signals with semantic representations, ensuring alignment within the semantic space while maintaining essential semantics. We present experimental results from four real-world datasets, which demonstrate significant improvements. By leveraging collaborative alignment, CARec also shows remarkable effectiveness in cold-start scenarios, achieving notable enhancements in recommendation performance. The code is available at https://github.com/ChenMetanoia/CARec **REMOVE 2nd URL**://github.com/ChenMetanoia/CARec.|传统的推荐系统主要依赖于身份表示（IDs）来建模用户和物品。近年来，预训练语言模型（PLMs）的引入增强了捕捉物品语义描述的能力。然而，尽管PLMs在少样本、零样本和统一建模场景中表现出色，但它们往往忽略了协同过滤（CF）中的关键信号，导致在有足够训练数据时性能不佳。为了有效结合语义表示与CF信号，并在冷启动和热启动场景中提升推荐系统性能，必须解决两个主要挑战：（1）弥合语义与协同表示空间之间的差距，（2）在保持语义表示完整性的同时进行优化。本文介绍了CARec，这是一种新型模型，能够巧妙地将协同过滤信号与语义表示相结合，确保在语义空间内的对齐同时保持基本语义。我们在四个真实世界数据集上进行了实验，结果显示了显著的改进。通过利用协同对齐，CARec在冷启动场景中也表现出显著的有效性，实现了推荐性能的显著提升。代码可在https://github.com/ChenMetanoia/CARec获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Alignment+for+Recommendation)|0|
|[Sparks of Surprise: Multi-objective Recommendations with Hierarchical Decision Transformers for Diversity, Novelty, and Serendipity](https://doi.org/10.1145/3627673.3679533)|Jie Wang, Alexandros Karatzoglou, Ioannis Arapakis, Xin Xin, Xuri Ge, Joemon M. Jose|University of Glasgow, Glasgow, United Kingdom; ShanDong University, Qingdao, China; Telefonica Research, BARCELONA, Spain; Amazon, BARCELONA, Spain|Personalized Session-based Recommendation (PSR) extends the traditional sequential recommendation models-which typically recommends the next item based on a recent active session-to leverage historical sessions of a user for short-term recommendations in current session. However, existing PSR methods face two limitations: (1) treating offline sessions uniformly as static data and relying on user embeddings to represent personalized information overlook the dynamic evolution of interests over time, which can change significantly as sessions progress in practical application. (2) focusing on accuracy, i.e., recommending items relevant to recent interactions, ignores the balance of multi-faceted requirements for user satisfaction, i.e., diversity, novelty, and serendipity. Therefore, we introduce Multi-objective PSR (MOPSR) task and propose Hierarchical Decision Transformers (HDT) framework, which models strictly sequential preference transitions of users across and within sessions to balance recommendation accuracy with the mentioned objectives. To address the first problem, Inter-session DT dynamically tracks the user's long-term preference across sessions by maintaining a goal state. This goal state serves as personalized information to collaboratively make recommendations with short-term state via the Intra-session DT. To tackle the second limitation, we propose inter-session and intra-session unexpected returns to trade off relevant recommendations and user preferences on diversity, novelty, and serendipity. The hierarchical returns help the recommender accurately identify signals of the user's expectations and changes in multi-objective preferences. To verify the effectiveness of our method on the MOPSR, we apply HDT to four state-of-the-art sequential recommendation models and conduct experiments on two publicly available datasets. Experimental results demonstrate that (1) HDT can widely generalize sequential models to solve the MOPSR task in scenarios with incrementally generated sessions, and (2) our method can balance multi-objectives by maintaining and even enhancing accuracy while effectively improving the diversity, novelty, and serendipity objectives.|个性化会话推荐（PSR）扩展了传统的序列推荐模型——这些模型通常根据最近的活动会话推荐下一个项目——以利用用户的历史会话为当前会话提供短期推荐。然而，现有的PSR方法存在两个局限性：（1）将离线会话统一视为静态数据，并依赖用户嵌入来表示个性化信息，忽略了兴趣随时间的动态演变，这在实际应用中随着会话的进展可能会发生显著变化。（2）专注于准确性，即推荐与最近交互相关的项目，忽略了用户满意度的多方面需求平衡，即多样性、新颖性和意外性。因此，我们引入了多目标PSR（MOPSR）任务，并提出了层次决策变换器（HDT）框架，该框架对用户在会话内外严格顺序的偏好转移进行建模，以平衡推荐准确性与上述目标。为解决第一个问题，会话间DT通过维护一个目标状态来动态追踪用户在会话间的长期偏好。该目标状态作为个性化信息，通过会话内DT与短期状态协作进行推荐。为应对第二个局限性，我们提出了会话间和会话内的意外回报，以权衡相关推荐与用户对多样性、新颖性和意外性的偏好。层次回报有助于推荐系统准确识别用户期望的信号和多目标偏好的变化。为验证我们的方法在MOPSR上的有效性，我们将HDT应用于四种最先进的序列推荐模型，并在两个公开数据集上进行实验。实验结果表明：（1）HDT能够广泛推广序列模型，以解决在会话增量生成场景下的MOPSR任务；（2）我们的方法能够在保持甚至提高准确性的同时，有效提升多样性、新颖性和意外性目标，从而平衡多目标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sparks+of+Surprise:+Multi-objective+Recommendations+with+Hierarchical+Decision+Transformers+for+Diversity,+Novelty,+and+Serendipity)|0|
|[Content-Based Collaborative Generation for Recommender Systems](https://doi.org/10.1145/3627673.3679692)|Yidan Wang, Zhaochun Ren, Weiwei Sun, Jiyuan Yang, Zhixiang Liang, Xin Chen, Ruobing Xie, Su Yan, Xu Zhang, Pengjie Ren, Zhumin Chen, Xin Xin|Zhejiang University, Hangzhou, China; Tencent, Beijing, China; Shandong University, Qingdao, China; WeChat, Tencent, Beijing, China; Leiden University, Leiden, Netherlands|Generative models have emerged as a promising utility to enhance recommender systems. It is essential to model both item content and user-item collaborative interactions in a unified generative framework for better recommendation. Although some existing large language model (LLM)-based methods contribute to fusing content information and collaborative signals, they fundamentally rely on textual language generation, which is not fully aligned with the recommendation task. How to integrate content knowledge and collaborative interaction signals in a generative framework tailored for item recommendation is still an open research challenge. In this paper, we propose co ntent-based col la borative generation for rec ommender systems, namely ColaRec. ColaRec is a sequence-to-sequence framework which is tailored for directly generating the recommended item identifier. Precisely, the input sequence comprises data pertaining to the user's interacted items, and the output sequence represents the generative identifier (GID) for the suggested item. To model collaborative signals, the GIDs are constructed from a pretrained collaborative filtering model, and the user is represented as the content aggregation of interacted items. To this end, ColaRec captures both collaborative signals and content information in a unified framework. Then an item indexing task is proposed to conduct the alignment between the content-based semantic space and the interaction-based collaborative space. Besides, a contrastive loss is further introduced to ensure that items with similar collaborative GIDs have similar content representations. To verify the effectiveness of ColaRec, we conduct experiments on four benchmark datasets. Empirical results demonstrate the superior performance of ColaRec.|生成模型已成为增强推荐系统的有力工具。为了实现更好的推荐效果，在一个统一的生成框架中同时建模项目内容和用户-项目协同交互是至关重要的。尽管一些现有的基于大型语言模型（LLM）的方法有助于融合内容信息和协同信号，但它们本质上依赖于文本语言生成，这并未完全适应推荐任务的需求。如何在专为项目推荐设计的生成框架中整合内容知识和协同交互信号，仍然是一个开放的研究挑战。本文提出了一种基于内容的协同生成推荐系统方法，命名为ColaRec。ColaRec是一个序列到序列框架，专门用于直接生成推荐项目的标识符。具体而言，输入序列包含用户交互过的项目数据，输出序列表示推荐项目的生成标识符（GID）。为了建模协同信号，GID由预训练的协同过滤模型构建，用户则表示为交互项目的聚合内容。通过这种方式，ColaRec在一个统一的框架中捕捉了协同信号和内容信息。随后，提出了一项项目索引任务，以实现基于内容语义空间与基于交互的协同空间之间的对齐。此外，引入对比损失以确保具有相似协同GID的项目具有相似的内容表示。为了验证ColaRec的有效性，我们在四个基准数据集上进行了实验。实证结果表明，ColaRec具有优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Content-Based+Collaborative+Generation+for+Recommender+Systems)|0|
|[Multi-Task Recommendation with Task Information Decoupling](https://doi.org/10.1145/3627673.3679621)|Ruiran Yan, Rui Fan, Defu Lian||Multi-task learning (MTL) has become increasingly prevalent in e-commerce recommender systems. However, existing MTL methods, particularly those utilizing the Multi-gate Mixture-of-Experts (MMoE) architecture, face challenges due to their implicit routing mechanisms. These mechanisms can inadvertently lead to negative knowledge transfer, failing to resolve conflicts among tasks and resulting in gradient contradictions on shared parameters. Such issues undermine the generalization capability of MTL models across various tasks. To address these limitations, we introduce the Task Information Decoupling Model (TIDM), designed to alleviate negative transfer by decoupling task knowledge. TIDM incorporates two innovative modules following the expert layer: the Maximize Information Aggregation Module (MIA) and the Automatic Information Selection Module (AIS). The MIA module employs an auxiliary loss to filter out irrelevant task information and aggregates task-specific knowledge using a dissimilar self-attention network. Subsequently, the AIS module automatically selects the most pertinent task-specific information to facilitate task tower learning. Our experiments demonstrate that TIDM outperforms five contemporary MTL models across two datasets, showcasing its effectiveness in extracting task-specific information. This advancement is crucial for enhancing the performance of recommender systems in e-commerce and other complex domains.|多任务学习（MTL）在电子商务推荐系统中变得越来越普遍。然而，现有的MTL方法，特别是那些采用多门混合专家（MMoE）架构的方法，面临着由于其隐式路由机制带来的挑战。这些机制可能会无意中导致负知识转移，无法解决任务间的冲突，并在共享参数上产生梯度矛盾。这些问题削弱了MTL模型在各种任务中的泛化能力。为了解决这些局限性，我们引入了任务信息解耦模型（TIDM），旨在通过解耦任务知识来减轻负转移。TIDM在专家层之后包含了两个创新模块：最大化信息聚合模块（MIA）和自动信息选择模块（AIS）。MIA模块采用辅助损失来过滤无关任务信息，并使用不相似的自注意力网络聚合任务特定知识。随后，AIS模块自动选择最相关的任务特定信息，以促进任务塔的学习。我们的实验表明，TIDM在两个数据集上优于五种当代MTL模型，展示了其在提取任务特定信息方面的有效性。这一进展对于提升电子商务及其他复杂领域中推荐系统的性能至关重要。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Recommendation+with+Task+Information+Decoupling)|0|
|[MMLRec: A Unified Multi-Task and Multi-Scenario Learning Benchmark for Recommendation](https://doi.org/10.1145/3627673.3679691)|Guanghu Yuan, Jieyu Yang, Shujie Li, Mingjie Zhong, Ang Li, Ke Ding, Yong He, Min Yang, Liang Zhang, Xiaolu Zhang, Linjian Mo|Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Ant Group, Hangzhou, China|In recent years, there has been a trend in the field of recommender systems towards multi-task modeling and multi-scenario modeling. The aim is to enhance the performance of various tasks and scenarios by jointly training on multiple tasks or scenarios to learn common patterns and features. Joint modeling of tasks and scenarios has also received widespread attention recently. However, despite the rich proposals of methods for Multi-Task Learning (MTL), Multi-Scenario Learning (MSL), and Multi-Task-Multi-Scenario Learning (MTMSL) in recent years, there still lacks a comprehensive benchmark to evaluate these methods. Previous studies often employed different datasets, data processing techniques, data partitioning strategies, and hyperparameter settings, making replication of existing research and fair comparison of experimental results challenging. To address this challenge, we introduce MMLRec, the first unified comprehensive benchmark for evaluating MTL, MSL and MTMSL, featuring consistent dataset processing and identical parameter settings. This benchmark implements a range of MTL, MSL, and MTMSL algorithms, and evaluates them on multiple commonly used recommender systems datasets. Through fair comparative experiments, we find that some structurally simplistic recommendation algorithms are underestimated, as they can achieve comparable results to more complex algorithms while maintaining lower complexity. Furthermore, our experimental analysis indicates that more complex methods exhibit better robustness when there are significant differences between tasks or scenarios. By providing a unified framework (MMLRec), our goal is to promote rapid evaluation and inspire innovative research in this continuously evolving field. We hope that our open-source benchmark can facilitate swift, equitable evaluations, while also fostering further breakthrough research in the domains of MTL, MSL, and MTMSL.|近年来，推荐系统领域出现了一种趋势，即向多任务建模和多场景建模发展。其目的是通过联合训练多个任务或场景，以学习共同的模型和特征，从而提升各个任务和场景的性能。任务和场景的联合建模也近来受到了广泛关注。然而，尽管近年来针对多任务学习（MTL）、多场景学习（MSL）以及多任务多场景学习（MTMSL）的方法提出了丰富的建议，但仍缺乏一个全面的基准来评估这些方法。以往的研究往往采用不同的数据集、数据处理技术、数据划分策略和超参数设置，这使得现有研究的复现和实验结果的公平比较变得困难。为了应对这一挑战，我们引入了MMLRec，这是首个用于评估MTL、MSL和MTMSL的统一综合性基准，具有一致的数据集处理和相同的参数设置。该基准实现了一系列MTL、MSL和MTMSL算法，并在多个常用的推荐系统数据集上对其进行了评估。通过公平的比较实验，我们发现一些结构上较为简单的推荐算法被低估了，因为它们能够在保持较低复杂度的同时，取得与更复杂算法相当的结果。此外，我们的实验分析表明，当任务或场景之间存在显著差异时，更复杂的方法表现出更好的鲁棒性。通过提供一个统一的框架（MMLRec），我们的目标是促进该领域的快速评估，并激发创新研究。我们希望我们的开源基准能够促进快速、公平的评估，同时也推动MTL、MSL和MTMSL领域的进一步突破性研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMLRec:+A+Unified+Multi-Task+and+Multi-Scenario+Learning+Benchmark+for+Recommendation)|0|
|[Reformulating Conversational Recommender Systems as Tri-Phase Offline Policy Learning](https://doi.org/10.1145/3627673.3679792)|Gangyi Zhang, Chongming Gao, Hang Pan, Runzhe Teng, Ruizhe Li||Existing Conversational Recommender Systems (CRS) predominantly utilize user simulators for training and evaluating recommendation policies. These simulators often oversimplify the complexity of user interactions by focusing solely on static item attributes, neglecting the rich, evolving preferences that characterize real-world user behavior. This limitation frequently leads to models that perform well in simulated environments but falter in actual deployment. Addressing these challenges, this paper introduces the Tri-Phase Offline Policy Learning-based Conversational Recommender System (TPCRS), which significantly reduces dependency on real-time interactions and mitigates overfitting issues prevalent in traditional approaches. TPCRS integrates a model-based offline learning strategy with a controllable user simulation that dynamically aligns with both personalized and evolving user preferences. Through comprehensive experiments, TPCRS demonstrates enhanced robustness, adaptability, and accuracy in recommendations, outperforming traditional CRS models in diverse user scenarios. This approach not only provides a more realistic evaluation environment but also facilitates a deeper understanding of user behavior dynamics, thereby refining the recommendation process.|现有的对话推荐系统（CRS）主要依赖用户模拟器进行推荐策略的训练和评估。这些模拟器通常过于简化用户交互的复杂性，仅关注静态的物品属性，而忽略了现实世界中用户行为所具有的丰富且不断演变的偏好。这一局限性往往导致模型在模拟环境中表现良好，但在实际应用中却表现不佳。为了应对这些挑战，本文提出了基于三阶段离线策略学习的对话推荐系统（TPCRS），该系统显著减少了对实时交互的依赖，并缓解了传统方法中常见的过拟合问题。TPCRS结合了基于模型的离线学习策略与可控的用户模拟器，后者能够动态地与个性化且不断演变的用户偏好相匹配。通过全面的实验，TPCRS在推荐系统的鲁棒性、适应性和准确性方面表现出色，在多种用户场景下均优于传统的CRS模型。这种方法不仅提供了一个更为真实的评估环境，还促进了对于用户行为动态的深入理解，从而优化了推荐过程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reformulating+Conversational+Recommender+Systems+as+Tri-Phase+Offline+Policy+Learning)|0|
|[HGCH: A Hyperbolic Graph Convolution Network Model for Heterogeneous Collaborative Graph Recommendation](https://doi.org/10.1145/3627673.3679701)|Lu Zhang, Ning Wu|Huazhong University of Science and Technology, Wuhan, China; Beihang University, Beijing, China|User-item interaction data in collaborative filtering and graph modeling tasks often exhibit power-law characteristics, which suggest the suitability of hyperbolic space modeling. Hyperbolic Graph Convolution Neural Networks (HGCNs) are a novel technique that leverages the advantages of GCN and hyperbolic space, and then achieves remarkable results. However, existing HGCN methods have several drawbacks: they fail to fully leverage hyperbolic space properties due to arbitrary embedding initialization and imprecise tangent space aggregation; they overlook auxiliary information that could enrich the collaborative graph; and their training convergence is slow due to margin ranking loss and random negative sampling. To overcome these challenges, we propose Hyperbolic Graph Collaborative for Heterogeneous Recommendation (HGCH), an enhanced HGCN-based model for collaborative filtering that integrates diverse side information into a heterogeneous collaborative graph and improves training convergence speed. HGCH first preserves the long-tailed nature of the graph by initializing node embeddings with power law prior; then it aggregates neighbors in hyperbolic space using the gyromidpoint method for accurate computation; finally, it fuses multiple embeddings from different hyperbolic spaces by the gate fusion with prior. Moreover, HGCH employs a hyperbolic user-specific negative sampling to speed up convergence. We evaluate HGCH on four real datasets, and the results show that HGCH achieves competitive results and outperforms leading baselines, including HGCNs. Extensive ablation studies further confirm its effectiveness.|在协同过滤和图建模任务中的用户-物品交互数据往往呈现出幂律分布特征，这表明双曲空间建模的适用性。双曲图卷积神经网络（HGCNs）是一种利用GCN和双曲空间优势的新技术，并取得了显著成果。然而，现有的HGCN方法存在几个缺点：由于任意嵌入初始化和不精确的切空间聚合，未能充分利用双曲空间特性；忽略了可以丰富协同图的辅助信息；由于边缘排序损失和随机负采样，训练收敛速度慢。为了克服这些挑战，我们提出了异构推荐的双曲图协同（HGCH），这是一个基于HGCN的协同过滤增强模型，它将多样化的辅助信息整合到异构协同图中，并提高了训练收敛速度。HGCH首先通过使用幂律先验初始化节点嵌入来保留图的长尾特性；然后使用双曲空间中的中点方法聚合邻居以进行精确计算；最后，通过带先验的门融合方法融合来自不同双曲空间的多个嵌入。此外，HGCH采用双曲用户特定的负采样来加速收敛。我们在四个真实数据集上评估了HGCH，结果显示HGCH取得了竞争性的结果，并优于包括HGCNs在内的领先基线。广泛的消融研究进一步证实了其有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HGCH:+A+Hyperbolic+Graph+Convolution+Network+Model+for+Heterogeneous+Collaborative+Graph+Recommendation)|0|
|[EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation](https://doi.org/10.1145/3627673.3679582)|Yinghao Zhu, Changyu Ren, Zixiang Wang, Xiaochen Zheng, Shiyun Xie, Junlan Feng, Xi Zhu, Zhoujun Li, Liantao Ma, Chengwei Pan|Beihang University & Zhongguancun Laboratory, Beijing, China; ETH Zürich, Zürich, Switzerland; China Mobile Research Institute, Beijing, China; Peking University, Beijing, China; Beihang University, Beijing, China; Beihang University & Peking University, Beijing, China|The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary medical context for accurate clinical tasks, while previous approaches with knowledge graphs (KGs) primarily focus on structured knowledge extraction. In response, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR predictive modeling. We extract entities from both time-series data and clinical notes by prompting Large Language Models (LLMs) and align them with professional PrimeKG, ensuring consistency. In addition to triplet relationships, we incorporate entities' definitions and descriptions for richer semantics. The extracted knowledge is then used to generate task-relevant summaries of patients' health statuses. Finally, we fuse the summary with other modalities using an adaptive multimodal fusion network with cross-attention. Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital mortality and 30-day readmission tasks demonstrate the superior performance of the EMERGE framework over baseline models. Comprehensive ablation studies and analysis highlight the efficacy of each designed module and robustness to data sparsity. EMERGE contributes to refining the utilization of multimodal EHR data in healthcare, bridging the gap with nuanced medical contexts essential for informed clinical predictions. We have publicly released the code at https://github.com/yhzhu99/EMERGE.|多模态电子健康记录（EHR）数据的整合显著提升了临床预测能力。现有的模型，尽管利用了临床笔记和多元时间序列EHR数据，但往往未能充分纳入必要的医学背景信息，以实现精准的临床任务；而先前基于知识图谱（KGs）的方法则主要集中在结构化知识的提取上。为此，我们提出了EMERGE，一个由检索增强生成（RAG）驱动框架，旨在提升多模态EHR预测建模。我们通过提示大型语言模型（LLMs）从时间序列数据和临床笔记中提取实体，并将其与专业的PrimeKG对齐，以确保一致性。除了三元组关系外，我们还纳入了实体的定义和描述，以丰富语义。提取的知识随后用于生成与任务相关的患者健康状况摘要。最后，我们利用具有交叉注意力的自适应多模态融合网络将该摘要与其他模态数据融合。在MIMIC-III和MIMIC-IV数据集上的住院死亡率和30天再入院任务的广泛实验表明，EMERGE框架优于基线模型。全面的消融研究和分析突显了每个设计模块的有效性及其对数据稀疏性的稳健性。EMERGE有助于优化多模态EHR数据在医疗领域的应用，弥合了与精细医学背景之间的差距，这对于精准的临床预测至关重要。我们已经公开发布了代码，地址为https://github.com/yhzhu99/EMERGE。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EMERGE:+Enhancing+Multimodal+Electronic+Health+Records+Predictive+Modeling+with+Retrieval-Augmented+Generation)|0|
|[Pairing Clustered Inverted Indexes with κ-NN Graphs for Fast Approximate Retrieval over Learned Sparse Representations](https://doi.org/10.1145/3627673.3679977)|Sebastian Bruch, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pairing+Clustered+Inverted+Indexes+with+κ-NN+Graphs+for+Fast+Approximate+Retrieval+over+Learned+Sparse+Representations)|0|
|[PP4RNR: Popularity- and Position-Aware Contrastive Learning for Retrieval-Driven News Recommendation](https://doi.org/10.1145/3627673.3679979)|Wenwei Chen, Yewang Chen|College of Computer Science and Technology, Huaqiao University, Xiamen, China|Existing news recommendation systems often overlook the diversity of recommended content and exhibit popularity bias, resulting in suboptimal performance. To address this issue, this paper introduces a novel news recommendation approach, Popularity- and Position-Aware Contrastive Learning for Retrieval-Driven News Recommendation (PP4RNR). It consists of two modules: Entity-Level Retrieval Augmentation (ERA) and Popularity- and Position-Aware Contrastive Learning (PPCL). The ERA module utilizes both entities and titles to retrieve relevant news. Subsequently, retrieval-augmented news is fused with candidate news using our innovative cascaded attention network, leading to richer and more diverse news semantics. The PPCL module introduces perturbations in the news representation using a Gaussian perturbation vector based on the popularity and position information and then employs contrastive learning to regularize the representation space. Hence, this approach not only deepens the understanding of content diversity but also implicitly mitigates the popularity bias prevalent in current models. Rigorous testing on benchmark datasets demonstrates that our method significantly outperforms a range of state-of-the-art techniques.|现有的新闻推荐系统往往忽视推荐内容的多样性，并表现出流行度偏差，导致推荐效果不佳。为解决这一问题，本文提出了一种新颖的新闻推荐方法——基于检索的新闻推荐的流行度和位置感知对比学习（PP4RNR）。该方法包含两个模块：实体级检索增强（ERA）和流行度与位置感知的对比学习（PPCL）。ERA模块利用实体和标题来检索相关新闻。随后，通过我们创新的级联注意力网络将检索增强的新闻与候选新闻融合，从而丰富和多样化新闻语义。PPCL模块基于新闻的流行度和位置信息引入高斯扰动向量，对新闻表示进行扰动，然后利用对比学习来规范化表示空间。因此，这种方法不仅加深了对内容多样性的理解，还隐式地缓解了当前模型中普遍存在的流行度偏差。在基准数据集上的严格测试表明，我们的方法显著优于一系列最先进的技术。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PP4RNR:+Popularity-+and+Position-Aware+Contrastive+Learning+for+Retrieval-Driven+News+Recommendation)|0|
|[Exploiting Preferences in Loss Functions for Sequential Recommendation via Weak Transitivity](https://doi.org/10.1145/3627673.3679920)|Hyunsoo Chung, Jungtaek Kim, Hyungeun Jo, Hyungwon Choi||A choice of optimization objective is immensely pivotal in the design of a recommender system as it affects the general modeling process of a user's intent from previous interactions. Existing approaches mainly adhere to three categories of loss functions: pairwise, pointwise, and setwise loss functions. Despite their effectiveness, a critical and common drawback of such objectives is viewing the next observed item as a unique positive while considering all remaining items equally negative. Such a binary label assignment is generally limited to assuring a higher recommendation score of the positive item, neglecting potential structures induced by varying preferences between other unobserved items. To alleviate this issue, we propose a novel method that extends original objectives to explicitly leverage the different levels of preferences as relative orders between their scores. Finally, we demonstrate the superior performance of our method compared to baseline objectives.|优化目标的选择在推荐系统设计中极为关键，因为它影响从用户先前交互中对用户意图的一般建模过程。现有方法主要遵循三类损失函数：成对损失、逐点损失和集合损失函数。尽管这些方法有效，但它们的一个关键且普遍的缺点是将下一个观察到的项目视为唯一的正样本，而将所有剩余项目视为等同的负样本。这种二元标签分配通常仅限于确保正样本的推荐得分更高，而忽略了其他未观察项目之间因偏好差异所诱导的潜在结构。为解决这一问题，我们提出了一种新方法，将原始目标扩展为显式利用其得分之间的相对顺序来表示不同级别的偏好。最后，我们展示了我们的方法相对于基线目标的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Preferences+in+Loss+Functions+for+Sequential+Recommendation+via+Weak+Transitivity)|0|
|[RECE: Reduced Cross-Entropy Loss for Large-Catalogue Sequential Recommenders](https://doi.org/10.1145/3627673.3679986)|Danil Gusak, Gleb Mezentsev, Ivan V. Oseledets, Evgeny Frolov||Scalability is a major challenge in modern recommender systems. In sequential recommendations, full Cross-Entropy (CE) loss achieves state-of-the-art recommendation quality but consumes excessive GPU memory with large item catalogs, limiting its practicality. Using a GPU-efficient locality-sensitive hashing-like algorithm for approximating large tensor of logits, this paper introduces a novel RECE (REduced Cross-Entropy) loss. RECE significantly reduces memory consumption while allowing one to enjoy the state-of-the-art performance of full CE loss. Experimental results on various datasets show that RECE cuts training peak memory usage by up to 12 times compared to existing methods while retaining or exceeding performance metrics of CE loss. The approach also opens up new possibilities for large-scale applications in other domains.|可扩展性是现代推荐系统面临的主要挑战之一。在序列推荐中，全交叉熵（CE）损失实现了最先进的推荐质量，但在处理大型物品目录时会消耗过多的GPU内存，限制了其实用性。本文介绍了一种新的RECE（缩减交叉熵）损失，通过使用GPU高效的类似局部敏感哈希算法来近似大的logits张量。RECE显著减少了内存消耗，同时允许用户享受到全CE损失的最先进性能。在各种数据集上的实验结果表明，与现有方法相比，RECE将训练峰值内存使用量减少了高达12倍，同时保持或超过了CE损失的性能指标。该方法还为其他领域的大规模应用开辟了新的可能性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RECE:+Reduced+Cross-Entropy+Loss+for+Large-Catalogue+Sequential+Recommenders)|0|
|[Enhanced Retrieval Effectiveness through Selective Query Generation](https://doi.org/10.1145/3627673.3679912)|Seyed Mohammad Hosseini, Negar Arabzadeh, Morteza Zihayat, Ebrahim Bagheri|University of Waterloo, Waterloo, Ontario, Canada; Toronto Metropolitan University, Toronto, Ontario, Canada|Prior research has demonstrated that reformulation of queries can significantly enhance retrieval effectiveness. Despite notable successes in neural-based query reformulation methods, identifying optimal reformulations that cover the same information need while enhancing retrieval effectiveness is still challenging. This paper introduces a two-step query reformulation framework for generating and selecting optimal target query variants which not only achieve higher retrieval performance but also preserve the original query's information need. Our comprehensive evaluations on the MS MARCO dataset and TREC Deep Learning tracks demonstrate substantial improvements over original query's performance.|先前研究表明，查询的重构可以显著提升检索效果。尽管基于神经网络的查询重构方法取得了显著成功，但识别出既能覆盖相同信息需求又能增强检索效果的最佳重构查询仍然具有挑战性。本文提出了一种两步走的查询重构框架，用于生成和选择最优的目标查询变体，这些变体不仅实现了更高的检索性能，还保留了原始查询的信息需求。我们在MS MARCO数据集和TREC深度学习赛道上的全面评估显示，相较于原始查询，性能有显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhanced+Retrieval+Effectiveness+through+Selective+Query+Generation)|0|
|[Post-Training Embedding Enhancement for Long-Tail Recommendation](https://doi.org/10.1145/3627673.3679978)|Geon Lee, Kyungho Kim, Kijung Shin|KAIST, Seoul, Republic of Korea|Item popularity in real-world data follows a long-tail distribution, where a few items attract most of the attention, while the majority receive much less. This disparity results in high-quality embeddings for popular (head) items, but lower-quality embeddings for unpopular (tail) items, leading to less accurate recommendations for the latter. Our observations confirm that embeddings of tail items often exhibit (1) magnitudes (i.e., norms) that are less reflective of actual popularity and (2) directions that are less effective in capturing user preferences, compared to those of head items. To address this issue, we propose EDGE, a post-training embedding enhancement method for long-tail recommendations. EDGE employs two key strategies: (1) refining embedding magnitudes to better reflect item popularity and (2) adjusting embedding directions by leveraging knowledge from head items. Importantly, EDGE is model-agnostic and can be applied to embeddings learned from any trained recommender system. Experimental results show that EDGE significantly improves tail item recommendation performance and overall system performance, achieving up to an improvement of 211.23% in NDCG@20 over the state-of-the-art method. Our code and datasets are available at https://github.com/geon0325/EDGE.|现实世界数据中的物品流行度遵循长尾分布，其中少数物品吸引了大部分关注，而大多数物品则受到较少的关注。这种差异导致流行（头部）物品的嵌入质量较高，但不流行（尾部）物品的嵌入质量较低，从而使得后者的推荐准确性降低。我们的观察证实了尾部物品的嵌入通常表现出（1）范数（即模）不太能反映实际流行度，以及（2）方向不太能有效捕捉用户偏好，相比头部物品的嵌入。为了解决这一问题，我们提出了EDGE，一种用于长尾推荐的后训练嵌入增强方法。EDGE采用两种关键策略：（1）优化嵌入范数以更好地反映物品流行度，以及（2）通过利用头部物品的知识来调整嵌入方向。重要的是，EDGE与模型无关，可以应用于从任何训练好的推荐系统中学习到的嵌入。实验结果表明，EDGE显著提升了尾部物品的推荐性能和整体系统性能，在NDCG@20指标上相比最先进的方法提升了高达211.23%。我们的代码和数据集可在https://github.com/geon0325/EDGE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post-Training+Embedding+Enhancement+for+Long-Tail+Recommendation)|0|
|[Scalable and Adaptive Spectral Embedding for Attributed Graph Clustering](https://doi.org/10.1145/3627673.3679992)|Yunhui Liu, Tieke He, Qing Wu, Tao Zheng, Jianhua Zhao||Attributed graph clustering, which aims to group the nodes of an attributed graph into disjoint clusters, has made promising advancements in recent years. However, most existing methods face challenges when applied to large graphs due to the expensive computational cost and high memory usage. In this paper, we introduce Scalable and Adaptive Spectral Embedding (SASE), a simple attributed graph clustering method devoid of parameter learning. SASE comprises three main components: node features smoothing via $k$-order simple graph convolution, scalable spectral clustering using random Fourier features, and adaptive order selection. With these designs, SASE not only effectively captures global cluster structures but also exhibits linear time and space complexity relative to the graph size. Empirical results demonstrate the superiority of SASE. For example, on the ArXiv dataset with 169K nodes and 1.17M edges, SASE achieves a 6.9\% improvement in ACC and a $5.87\times$ speedup compared to the runner-up, S3GC.|属性图聚类旨在将属性图的节点分组为不相交的集群，近年来取得了显著进展。然而，大多数现有方法在应用于大规模图时面临挑战，主要是因为计算成本高且内存使用量大。本文提出了一种名为可扩展自适应谱嵌入（SASE）的简单属性图聚类方法，该方法无需参数学习。SASE包含三个主要组件：通过$k$阶简单图卷积进行节点特征平滑、使用随机傅里叶特征的可扩展谱聚类以及自适应阶数选择。这些设计使得SASE不仅能够有效捕捉全局聚类结构，而且相对于图的大小表现出线性的时间和空间复杂度。实证结果表明，SASE具有优越性。例如，在拥有169K节点和1.17M边的ArXiv数据集上，SASE在ACC上比次优的S3GC提高了6.9%，并且速度提升了$5.87$倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+and+Adaptive+Spectral+Embedding+for+Attributed+Graph+Clustering)|0|
|[P-Rank+: A Scalable Efficient P-Rank Search Algorithm](https://doi.org/10.1145/3627673.3679976)|Maoyin Zhang, Weiren Yu|Nanjing University of Sci. & Tech., Jiangsu, China; Warwick University, Coventry, United Kingdom|P-Rank (Penetrating-Rank) is a charming measure of structural similarity between objects based on graph topology. It recursively follows the principle that "two objects are considered similar if (a) they are referenced by similar objects and (b) they reference similar objects''. The best-known algorithm for computing P-Rank employs two repeated Singular Value Decompositions (SVDs) coupled with the Woodbury matrix identity. However, this method does not scale well on billion-sized graphs. Worse yet, this algorithm only provides a linear approximation of the P-Rank model and cannot deliver accurate P-Rank values. In this paper, we propose P-Rank+, a fast and efficient algorithm for computing P-Rank similarities, which scales well on large graphs with billions of edges. P-Rank+ leverages dimensionality reduction techniques by performing only one SVD of the graph integrated with Hadamard products in the reduced subspace. Moreover, we provide provable error guarantees for P-Rank+ computation. Experiments on various datasets validate that P-Rank+ is 1--3 orders of magnitude faster than the best-known competitor while achieving excellent scalability on massive graphs.|P-Rank（渗透排序）是一种基于图拓扑结构的对象间结构相似性的迷人度量方法。它递归地遵循以下原则：“如果两个对象（a）被相似的对象引用，并且（b）引用相似的对象，则认为它们是相似的”。计算P-Rank最著名的算法采用了两个重复的奇异值分解（SVD），并与Woodbury矩阵恒等式相结合。然而，这种方法在处理十亿级大小的图时扩展性不佳。更糟糕的是，该算法仅提供了P-Rank模型的线性近似，无法提供精确的P-Rank值。在本文中，我们提出了P-Rank+，一种快速且高效的计算P-Rank相似性的算法，该算法在拥有数十亿条边的大型图上具有良好的扩展性。P-Rank+通过在降维子空间中执行一次图的SVD结合Hadamard积来利用降维技术。此外，我们为P-Rank+的计算提供了可证明的误差保证。在各种数据集上的实验验证了P-Rank+比已知的最优竞争对手快1到3个数量级，同时在大型图上表现出卓越的可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=P-Rank+:+A+Scalable+Efficient+P-Rank+Search+Algorithm)|0|
|[Learning the Dynamics in Sequential Recommendation by Exploiting Real-time Information](https://doi.org/10.1145/3627673.3679955)|Rujiao Zhang, Hao Zhang, Yucong Luo, Zhiding Liu, Mingyue Cheng, Qi Liu, Enhong Chen||Sequential recommender systems offer personalized suggestions by modeling users' interactions chronologically to capture dynamic user interest. Existing approaches typically fail to adequately describe the dynamics of the entire recommender system, including shifts in both user interest and item availability. To address this, we propose a simple yet effective framework with three key perspectives, tailored to the dynamics of recommender system by fully exploiting the time information. Firstly, we propose a dynamic candidate set construction approach to prevent the model from learning future interactions. Secondly, assuming that user behaviors remain consistent over short terms but may evolve over long terms, we employ a interval-weighted optimization target to model the correlation of users' historical interactions. Finally, we introduce a specialized time-aware attention module to enhance recommendations within specific temporal contexts. Extensive experiments demonstrate the effectiveness and generalizability of our framework. We make our codes publicly available.|顺序推荐系统通过按时间顺序建模用户的交互来捕捉动态用户兴趣，从而提供个性化建议。现有的方法通常未能充分描述整个推荐系统的动态变化，包括用户兴趣和物品可用性的变化。为了解决这一问题，我们提出了一个简单而有效的框架，该框架从三个关键角度出发，充分利用时间信息来适应推荐系统的动态变化。首先，我们提出了一种动态候选集构建方法，以防止模型学习未来的交互。其次，假设用户行为在短期内保持一致，但在长期内可能发生变化，我们采用了一种区间加权优化目标来建模用户历史交互的相关性。最后，我们引入了一个专门的时间感知注意力模块，以增强在特定时间上下文中的推荐效果。大量实验证明了我们框架的有效性和普适性。我们将代码公开发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+the+Dynamics+in+Sequential+Recommendation+by+Exploiting+Real-time+Information)|0|
|[VIER: Visual Imagination Enhanced Retrieval in Sponsored Search](https://doi.org/10.1145/3627673.3680005)|Yadong Zhang, Yuqing Song, Siyu Lu, Qiang Liu, Xingxing Wang|Meituan, Beijing, China|Embedding-based Retrieval (EBR) has been a fundamental component in sponsored-search systems, which retrieves high-quality products for the user's search query by encoding the information of the query, user and product into dense embeddings. However, due to the characteristic of location-based service, the user input queries suffer from two extremes: overly brief queries with vague intentions and lengthy queries with substantial noise, both of which make it challenging to discern the exact user search intent. In fact, the e-consumers typically have a mental imagery of the product they intend to search for, reflecting their specific purchasing intentions. In this paper, we propose a Visual Imagination Enhanced Retrieval model (VIER) to explore the implicit imagery of users. Specifically, we design a visual imagination network to reconstruct the imagery embeddings that capture both coarse-grained query commonalities and fine-grained user personalities. These pseudo-image representations are integrated with the query and user behavior to enhance the understanding of user search intentions for improved retrieval. According to online A/B tests on Meituan sponsored-search system, our method significantly outperforms baselines in terms of revenue, clicks and click-through rate.|基于嵌入的检索（EBR）已成为赞助搜索系统中的基础组件，通过将查询、用户和产品的信息编码为密集嵌入，检索出高质量的产品以满足用户的搜索需求。然而，由于基于位置服务的特性，用户输入的查询呈现出两种极端：过于简短且意图模糊的查询，以及冗长但包含大量噪音的查询，这两者都使得准确识别用户的搜索意图变得困难。实际上，电子消费者通常对其意图搜索的产品有一个心理意象，这反映了他们特定的购买意向。在本文中，我们提出了一种视觉想象力增强的检索模型（VIER），以探索用户的隐含意象。具体而言，我们设计了一个视觉想象力网络，用于重建捕捉粗粒度查询共性和细粒度用户个性的意象嵌入。这些伪图像表示与查询和用户行为相结合，以增强对用户搜索意图的理解，从而改进检索效果。根据在美团赞助搜索系统上的在线A/B测试结果，我们的方法在收入、点击量和点击率方面显著优于基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VIER:+Visual+Imagination+Enhanced+Retrieval+in+Sponsored+Search)|0|
|[Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning](https://doi.org/10.1145/3627673.3680089)|Dillon Davis, Huiji Gao, Thomas Legrand, Malay Haldar, Alex Deng, Han Zhao, Liwei He, Sanjeev Katariya||The Airbnb search system grapples with many unique challenges as it continues to evolve. We oversee a marketplace that is nuanced by geography, diversity of homes, and guests with a variety of preferences. Crafting an efficient search system that can accommodate diverse guest needs, while showcasing relevant homes lies at the heart of Airbnb's success. Airbnb search has many challenges that parallel other recommendation and search systems but it has a unique information retrieval problem, upstream of ranking, called location retrieval. It requires defining a topological map area that is relevant to the searched query for homes listing retrieval. The purpose of this paper is to demonstrate the methodology, challenges, and impact of building a machine learning based location retrieval product from the ground up. Despite the lack of suitable, prevalent machine learning based approaches, we tackle cold start, generalization, differentiation and algorithmic bias. We detail the efficacy of heuristics, statistics, machine learning, and reinforcement learning approaches to solve these challenges, particularly for systems that are often unexplored by current literature.|随着不断发展，Airbnb搜索系统面临着许多独特的挑战。我们管理着一个由地理位置、房屋多样性和具有各种偏好的客人所构成的复杂市场。打造一个能够满足不同客人需求的高效搜索系统，同时展示相关房屋，是Airbnb成功的核心。Airbnb搜索系统面临许多与其他推荐和搜索系统相似的挑战，但它有一个独特的信息检索问题，即在排序之前的位置检索。这需要定义一个与搜索查询相关的拓扑地图区域，以便进行房屋列表检索。本文旨在展示从头构建一个基于机器学习的位置检索产品的过程、挑战及其影响。尽管缺乏合适且普遍的基于机器学习的方法，我们解决了冷启动、泛化、差异化和算法偏差等问题。我们详细介绍了启发式、统计学、机器学习和强化学习方法在这些挑战中的有效性，特别是针对当前文献中较少探索的系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transforming+Location+Retrieval+at+Airbnb:+A+Journey+from+Heuristics+to+Reinforcement+Learning)|0|
|[Pareto-based Multi-Objective Recommender System with Forgetting Curve](https://doi.org/10.1145/3627673.3680080)|Jipeng Jin, Zhaoxiang Zhang, Zhiheng Li, Xiaofeng Gao, Xiongwen Yang, Lei Xiao, Jie Jiang|Shanghai Jiao Tong University; |Recommender systems with cascading architecture play an increasinglysignificant role in online recommendation platforms, where the approach todealing with negative feedback is a vital issue. For instance, in short videoplatforms, users tend to quickly slip away from candidates that they feelaversive, and recommender systems are expected to receive these explicitnegative feedbacks and make adjustments to avoid these recommendations.Considering recency effect in memories, we propose a forgetting model based onEbbinghaus Forgetting Curve to cope with negative feedback. In addition, weintroduce a Pareto optimization solver to guarantee a better trade-off betweenrecency and model performance. In conclusion, we propose Pareto-basedMulti-Objective Recommender System with forgetting curve (PMORS), which can beapplied to any multi-objective recommendation and show sufficiently superioritywhen facing explicit negative feedback. We have conducted evaluations of PMORSand achieved favorable outcomes in short-video scenarios on both public datasetand industrial dataset. After being deployed on an online short video platformnamed WeChat Channels in May, 2023, PMORS has not only demonstrated promisingresults for both consistency and recency but also achieved an improvement of upto +1.45|具有级联架构的推荐系统在在线推荐平台中扮演着越来越重要的角色，其中如何处理负面反馈是一个关键问题。例如，在短视频平台中，用户往往会对感到不喜欢的候选内容迅速失去兴趣，推荐系统需要接收这些明确的负面反馈并进行调整，以避免此类推荐。考虑到记忆中的时效性效应，我们提出了一种基于艾宾浩斯遗忘曲线的遗忘模型来处理负面反馈。此外，我们引入了一种帕累托优化求解器，以确保在时效性和模型性能之间取得更好的平衡。综上所述，我们提出了基于帕累托的多目标推荐系统（PMORS），该系统可以应用于任何多目标推荐，并且在面对明确的负面反馈时表现出足够的优越性。我们对PMORS进行了评估，并在公共数据集和工业数据集的短视频场景中取得了良好的结果。自2023年5月在名为微信视频号的在线短视频平台上部署以来，PMORS不仅在一致性和时效性方面展示了有前景的结果，还实现了高达+1.45的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto-based+Multi-Objective+Recommender+System+with+Forgetting+Curve)|0|
|[Ads Supply Personalization via Doubly Robust Learning](https://doi.org/10.1145/3627673.3680035)|Wei Shi, Chen Fu, Qi Xu, Sanjian Chen, Jizhe Zhang, Qinqin Zhu, Zhigang Hua, Shuang Yang|Meta Platforms, Inc., Menlo Park, CA, USA; Meta Platforms, Inc., Sunnyvale, CA, USA|Ads supply personalization aims to balance the revenue and user engagement, two long-term objectives in social media ads, by tailoring the ad quantity and density. In the industry-scale system, the challenge for ads supply lies in modeling the counterfactual effects of a conservative supply treatment (e.g., a small density change) over an extended duration. In this paper, we present a streamlined framework for personalized ad supply. This framework optimally utilizes information from data collection policies through the doubly robust learning. Consequently, it significantly improves the accuracy of long-term treatment effect estimates. Additionally, its low-complexity design not only results in computational cost savings compared to existing methods, but also makes it scalable for billion-scale applications. Through both offline experiments and online production tests, the framework consistently demonstrated significant improvements in top-line business metrics over months. The framework has been fully deployed to live traffic in one of the world's largest social media platforms.|广告供应个性化旨在通过调整广告数量和密度，平衡社交媒体广告中的两个长期目标：收入和用户参与度。在行业规模的系统中，广告供应的挑战在于对保守供应处理（例如，小幅密度变化）在长时间内的反事实效应进行建模。本文提出了一种简化的个性化广告供应框架。该框架通过双重稳健学习最优地利用数据收集策略中的信息，从而显著提高了长期处理效应估计的准确性。此外，其低复杂度的设计不仅在计算成本上优于现有方法，还使其适用于亿级规模的应用。通过离线实验和在线生产测试，该框架在数月内持续显示出对业务关键指标的显著改进。该框架已全面部署到全球最大社交媒体平台之一的实时流量中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ads+Supply+Personalization+via+Doubly+Robust+Learning)|0|
|[DivNet: Diversity-Aware Self-Correcting Sequential Recommendation Networks](https://doi.org/10.1145/3627673.3680059)|Shuai Xiao, Zaifan Jiang|Alibaba Group, Shanghai, China; Alibaba Group, Beijing, China|As the last stage of a typical recommendation system, collective recommendation aims to give the final touches to the recommended items and their layout so as to optimize overall objectives such as diversity and whole-page relevance. In practice, however, the interaction dynamics among the recommended items, their visual appearances and meta-data such as specifications are often too complex to be captured by experts' heuristics or simple models. To address this issue, we propose a div ersity-aware self-correcting sequential recommendation net works (DivNet) that is able to estimate utility by capturing the complex interactions among sequential items and diversify recommendations simultaneously. Experiments on both offline and online settings demonstrate that DivNet can achieve better results compared to baselines with or without collective recommendations.|在典型的推荐系统的最后一个阶段，集体推荐旨在对推荐项目及其布局进行最后的调整，以优化多样性和整个页面的相关性等总体目标。然而，在实践中，推荐项目之间的交互动态、它们的视觉外观和规格等元数据往往过于复杂，难以被专家的启发式方法或简单的模型捕捉。为了解决这个问题，我们提出了一种多样性感知的自校正序列推荐网络（DivNet），它能够通过捕捉序列项目之间的复杂交互来估计效用，并同时实现推荐项目的多样化。在离线和在线设置中的实验表明，与有无集体推荐的基线相比，DivNet能够取得更好的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DivNet:+Diversity-Aware+Self-Correcting+Sequential+Recommendation+Networks)|0|
|[Enhancing Playback Performance in Video Recommender Systems with an On-Device Gating and Ranking Framework](https://doi.org/10.1145/3627673.3680076)|Yunfei Yang, Zhenghao Qi, Honghuan Wu, Qi Song, Tieyao Zhang, Hao Li, Yimin Tu, Kaiqiao Zhan, Ben Wang||Video recommender systems (RSs) have gained increasing attention in recent years. Existing mainstream RSs focus on optimizing the matching function between users and items. However, we noticed that users frequently encounter playback issues such as slow loading or stuttering while browsing the videos, especially in weak network conditions, which will lead to a subpar browsing experience, and may cause users to leave, even when the video content and recommendations are superior. It is quite a serious issue, yet easily overlooked. To tackle this issue, we propose an on-device Gating and Ranking Framework (GRF) that cooperates with server-side RS. Specifically, we utilize a gate model to identify videos that may have playback issues in real-time, and then we employ a ranking model to select the optimal result from a locally-cached pool to replace the stuttering videos. Our solution has been fully deployed on Kwai, a large-scale short video platform with hundreds of millions of users globally. Moreover, it significantly enhances video playback performance and improves overall user experience and retention rates.|视频推荐系统（RSs）近年来受到了越来越多的关注。现有的主流RSs专注于优化用户与项目之间的匹配函数。然而，我们注意到用户在浏览视频时经常遇到播放问题，如加载缓慢或卡顿，尤其是在网络条件较差的情况下，这将导致浏览体验不佳，甚至可能使用户流失，即使视频内容和推荐本身是优质的。这是一个相当严重但容易被忽视的问题。为了解决这个问题，我们提出了一个设备端门控与排序框架（GRF），该框架与服务器端RS协同工作。具体来说，我们利用门控模型实时识别可能存在播放问题的视频，然后使用排序模型从本地缓存池中选择最佳结果来替换卡顿的视频。我们的解决方案已在快手这一全球拥有数亿用户的大型短视频平台上全面部署。此外，它显著提升了视频播放性能，并改善了整体用户体验和留存率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Playback+Performance+in+Video+Recommender+Systems+with+an+On-Device+Gating+and+Ranking+Framework)|0|
|[An Enhanced Batch Query Architecture in Real-time Recommendation](https://doi.org/10.1145/3627673.3680034)|Qiang Zhang, Zhipeng Teng, Disheng Wu, Jiayin Wang||In industrial recommendation systems on websites and apps, it is essential to recall and predict top-n results relevant to user interests from a content pool of billions within milliseconds. To cope with continuous data growth and improve real-time recommendation performance, we have designed and implemented a high-performance batch query architecture for real-time recommendation systems. Our contributions include optimizing hash structures with a cacheline-aware probing method to enhance coalesced hashing, as well as the implementation of a hybrid storage key-value service built upon it. Our experiments indicate this approach significantly surpasses conventional hash tables in batch query throughput, achieving up to 90 of random memory access when incorporating parallel optimization. The support for NVMe, integrating two-tier storage for hot and cold data, notably reduces resource consumption. Additionally, the system facilitates dynamic updates, automated sharding of attributes and feature embedding tables, and introduces innovative protocols for consistency in batch queries, thereby enhancing the effectiveness of real-time incremental learning updates. This architecture has been deployed and in use in the bilibili recommendation system for over a year, a video content community with hundreds of millions of users, supporting 10x increase in model computation with minimal resource growth, improving outcomes while preserving the system's real-time performance.|在网站和应用的工业推荐系统中，从数十亿内容库中毫秒级召回并预测与用户兴趣相关的前N个结果至关重要。为应对持续的数据增长并提升实时推荐性能，我们设计并实现了一种高性能的实时推荐系统批量查询架构。我们的贡献包括通过缓存行感知的探测方法优化哈希结构以增强聚合哈希，以及基于此构建的混合存储键值服务。实验表明，该方法在批量查询吞吐量方面显著超越传统哈希表，结合并行优化时随机内存访问可达90%。对NVMe的支持，结合冷热数据的两级存储，显著降低了资源消耗。此外，系统支持动态更新、属性和特征嵌入表的自动分片，并引入了创新的批量查询一致性协议，从而提升了实时增量学习更新的效果。该架构已在拥有数亿用户的视频内容社区bilibili推荐系统中部署并使用超过一年，支持模型计算量10倍增长的同时资源增长最小化，既提升了推荐效果又保持了系统的实时性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Enhanced+Batch+Query+Architecture+in+Real-time+Recommendation)|0|
|[Voting with Generative AI for German Compound Splitting in E-commerce Search](https://doi.org/10.1145/3627673.3679074)|Ümit Yilmaz, Kilian Merkelbach, Daniel Stein, Hasan Oezkan|eBay Inc., Dreilinden, Germany; eBay Inc., Aachen, Germany|Compound words are a grammatical structure that allows forming new words by composing existing words. For e-commerce search in German, it is essential to split these compounds into meaningful parts because item titles often use the joint form while search queries are often split. We propose a method for German compound splitting leveraging a large language model (LLM) with a voting mechanism and a hyperparameter search for automatically optimizing prompt and parameter combinations. Our evaluation of the proposed method on human-created gold standard data for e-commerce shows that it outperforms existing methods for compound splitting in this domain.|复合词是一种语法结构，通过组合现有词汇来形成新词。在德语的电子商务搜索中，将这些复合词拆分为有意义的组成部分至关重要，因为商品标题通常使用联合形式，而搜索查询则通常是拆分后的形式。我们提出了一种利用大型语言模型（LLM）进行德语复合词拆分的方法，该方法结合了投票机制和超参数搜索，以自动优化提示和参数组合。我们对所提出的方法在人工创建的电子商务金标准数据上的评估显示，它在复合词拆分方面优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Voting+with+Generative+AI+for+German+Compound+Splitting+in+E-commerce+Search)|0|
|[AI Agent for Information Retrieval: Generating and Ranking](https://doi.org/10.1145/3627673.3680120)|Yongfeng Zhang, Zhiwei Liu, Qingsong Wen, Linsey Pang, Wei Liu, Philip S. Yu|Salesforce AI Research, Palo Alto, CA, USA; Salesforce, San Francisco, CA, USA; Squirrel Ai Learning, Seattle, WA, USA; University of Technology Sydney, Sydney, NSW, Australia; Rutgers University, New Brunswick, NJ, USA; University of Illinois at Chicago, Chicago, IL, USA|The field of information retrieval has significantly transformed with the integration of AI technologies. AI agents, especially those leveraging LLMs and vast computational power, have revolutionized information retrieval, processing, and presentation. LLM agents, with advanced memory, reasoning, and planning capabilities, can perform complex tasks, engage in coherent conversations, and provide personalized responses. Despite these advancements, challenges such as ensuring relevance and accuracy, mitigating biases, providing real-time responses, and maintaining data security remain. This workshop aims to explore these challenges, share innovative solutions, and discuss future directions. It will provide a platform to bring together researchers, practitioners to discuss the latest theoretical advancements and practical implementations of AI agents in information retrieval. Topics include AI in search, recommendation, and personalization systems. By gathering a diverse group of experts, the workshop seeks to deepen the understanding of AI agents in information retrieval, advance the field, and enhance its societal impact. Participants will gain insights into cutting-edge research, emerging trends, and foster knowledge exchange and collaboration within the community.|信息检索领域随着AI技术的融合发生了显著变革。AI代理，尤其是那些利用大型语言模型（LLMs）和强大计算能力的代理，已经彻底改变了信息检索、处理和呈现的方式。具备先进记忆、推理和规划能力的LLM代理能够执行复杂任务、进行连贯对话并提供个性化响应。尽管取得了这些进展，但仍面临确保相关性和准确性、减轻偏见、提供实时响应以及维护数据安全等挑战。本次研讨会旨在探讨这些挑战，分享创新解决方案，并讨论未来的发展方向。研讨会将提供一个平台，让研究人员和从业者能够讨论AI代理在信息检索中最新的理论进展和实际应用。主题包括AI在搜索、推荐和个人化系统中的应用。通过汇集多元化的专家群体，研讨会旨在深化对信息检索中AI代理的理解，推动该领域的发展，并增强其社会影响力。参与者将获得关于尖端研究、新兴趋势的见解，并促进社区内的知识交流与合作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+Agent+for+Information+Retrieval:+Generating+and+Ranking)|0|
|[UniEmbedding: Learning Universal Multi-Modal Multi-Domain Item Embeddings via User-View Contrastive Learning](https://doi.org/10.1145/3627673.3680098)|Boqi Dai, Zhaocheng Du, Jieming Zhu, Jintao Xu, Deqing Zou, Quanyu Dai, Zhenhua Dong, Rui Zhang, HaiTao Zheng|Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University & Pengcheng Laboratory, Shenzhen, China; Huawei Noah's Ark Lab, Shenzhen, China; Huazhong University of Science and Technology, Shenzhen, China|Learning high-quality item embeddings is crucial for recommendation tasks such as matching and ranking. However, existing methods often rely on ID-based item embeddings learned end-to-end with downstream recommendation models, which may suffer from overfitting and limited generalizability. In this paper, we aim to learn universal item embeddings (dubbed UniEmbedding) that capture multi-modal semantics, generalize across multiple domains, and serve different downstream tasks. To achieve this goal, we introduce the UniEmbedding pretraining framework, which includes three modules: a domain-aware multi-modal adapter, a user-view projection module, and contrastive learning objectives across domains. Compared to naive ID embeddings, UniEmbedding provides rich semantic information that generalizes more effectively across domains. Unlike multi-modal embeddings directly extracted from off-the-shelf pretrained models, UniEmbedding achieves better alignment between content semantics and behaviors. We evaluated UniEmbedding on both public and industrial datasets, demonstrating its effectiveness in matching and ranking tasks. Furthermore, UniEmbedding has been deployed in multiple recommendation applications at Huawei, resulting in significant gains in user engagement metrics.|学习高质量的物品嵌入对于匹配和排序等推荐任务至关重要。然而，现有方法通常依赖于基于ID的物品嵌入，这些嵌入与下游推荐模型端到端学习，可能会遭受过拟合和泛化能力有限的问题。本文旨在学习一种通用的物品嵌入（称为UniEmbedding），这种嵌入能够捕捉多模态语义，跨多个领域泛化，并服务于不同的下游任务。为实现这一目标，我们引入了UniEmbedding预训练框架，该框架包括三个模块：领域感知的多模态适配器、用户视角投影模块以及跨领域的对比学习目标。与简单的ID嵌入相比，UniEmbedding提供了更丰富的语义信息，能更有效地跨领域泛化。与直接从现成的预训练模型中提取的多模态嵌入不同，UniEmbedding在内容语义和行为之间实现了更好的对齐。我们在公共和工业数据集上评估了UniEmbedding，证明了其在匹配和排序任务中的有效性。此外，UniEmbedding已在华为的多个推荐应用中部署，显著提升了用户参与度指标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniEmbedding:+Learning+Universal+Multi-Modal+Multi-Domain+Item+Embeddings+via+User-View+Contrastive+Learning)|0|
|[Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation](https://doi.org/10.1145/3627673.3680065)|Jianxing Ma, Zhibo Xiao, Luwei Yang, Hansheng Xue, Xuanzhou Liu, Wen Jiang, Wei Ning, Guannan Zhang||To cater to users' desire for an immersive browsing experience, numerous e-commerce platforms provide various recommendation scenarios, with a focus on Trigger-Induced Recommendation (TIR) tasks. However, the majority of current TIR methods heavily rely on the trigger item to understand user intent, lacking a higher-level exploration and exploitation of user intent (e.g., popular items and complementary items), which may result in an overly convergent understanding of users' short-term intent and can be detrimental to users' long-term purchasing experiences. Moreover, users' short-term intent shows uncertainty and is affected by various factors such as browsing context and historical behaviors, which poses challenges to user intent modeling. To address these challenges, we propose a novel model called Deep Uncertainty Intent Network (DUIN), comprising three essential modules: i) Explicit Intent Exploit Module extracting explicit user intent using the contrastive learning paradigm; ii) Latent Intent Explore Module exploring latent user intent by leveraging the multi-view relationships between items; iii) Intent Uncertainty Measurement Module offering a distributional estimation and capturing the uncertainty associated with user intent. Experiments on three real-world datasets demonstrate the superior performance of DUIN compared to existing baselines. Notably, DUIN has been deployed across all TIR scenarios in our e-commerce platform, with online A/B testing results conclusively validating its superiority.|为了满足用户对沉浸式浏览体验的需求，众多电商平台提供了多种推荐场景，着重于触发式推荐（Trigger-Induced Recommendation, TIR）任务。然而，当前大多数TIR方法过于依赖触发项来理解用户意图，缺乏对用户意图的高层次探索和利用（例如，流行商品和互补商品），这可能导致对用户短期意图的理解过于集中，从而对用户的长期购买体验产生不利影响。此外，用户的短期意图表现出不确定性，并受到浏览上下文和历史行为等多种因素的影响，这对用户意图建模提出了挑战。为了应对这些挑战，我们提出了一种名为深度不确定性意图网络（Deep Uncertainty Intent Network, DUIN）的新模型，该模型包含三个核心模块：i) 显式意图利用模块，通过对比学习范式提取显式用户意图；ii) 潜在意图探索模块，利用商品之间的多视角关系来探索潜在用户意图；iii) 意图不确定性度量模块，提供分布估计并捕捉用户意图的不确定性。在三个真实世界数据集上的实验表明，DUIN相比现有基线方法表现出优越的性能。值得注意的是，DUIN已在我们电商平台的所有TIR场景中部署，在线A/B测试结果有力地验证了其优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+User+Intent+Beyond+Trigger:+Incorporating+Uncertainty+for+Trigger-Induced+Recommendation)|0|
|[Confidence-aware Self-Semantic Distillation on Knowledge Graph Embedding](https://doi.org/10.1145/3627673.3679683)|Yichen Liu, Jiawei Chen, Defang Chen, Zhehui Zhou, Yan Feng, Can Wang||Knowledge Graph Embedding (KGE), which projects entities and relations intocontinuous vector spaces, have garnered significant attention. Althoughhigh-dimensional KGE methods offer better performance, they come at the expenseof significant computation and memory overheads. Decreasing embeddingdimensions significantly deteriorates model performance. While several recentefforts utilize knowledge distillation or non-Euclidean representation learningto augment the effectiveness of low-dimensional KGE, they either necessitate apre-trained high-dimensional teacher model or involve complex non-Euclideanoperations, thereby incurring considerable additional computational costs. Toaddress this, this work proposes Confidence-aware Self-Knowledge Distillation(CSD) that learns from model itself to enhance KGE in a low-dimensional space.Specifically, CSD extracts knowledge from embeddings in previous iterations,which would be utilized to supervise the learning of the model in the nextiterations. Moreover, a specific semantic module is developed to filterreliable knowledge by estimating the confidence of previously learnedembeddings. This straightforward strategy bypasses the need for time-consumingpre-training of teacher models and can be integrated into various KGE methodsto improve their performance. Our comprehensive experiments on six KGEbackbones and four datasets underscore the effectiveness of the proposed CSD.|知识图谱嵌入（KGE）将实体和关系投影到连续的向量空间中，引起了广泛关注。尽管高维KGE方法提供了更好的性能，但它们也带来了显著的计算和内存开销。降低嵌入维度会显著降低模型性能。虽然最近的一些研究利用知识蒸馏或非欧几里得表示学习来增强低维KGE的有效性，但它们要么需要预训练的高维教师模型，要么涉及复杂的非欧几里得操作，从而产生了大量的额外计算成本。为了解决这一问题，本文提出了置信度感知的自知识蒸馏（CSD），该方法通过从模型自身学习来增强低维空间的KGE。具体而言，CSD从先前迭代中的嵌入中提取知识，这些知识将被用于监督模型在后续迭代中的学习。此外，本文还开发了一个特定的语义模块，通过估计先前学习嵌入的置信度来过滤可靠的知识。这种直接的策略避免了耗时的教师模型预训练，并且可以集成到各种KGE方法中以提高其性能。我们在六个KGE基线和四个数据集上的综合实验验证了所提出CSD的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Confidence-aware+Self-Semantic+Distillation+on+Knowledge+Graph+Embedding)|0|
|[SAQRec: Aligning Recommender Systems to User Satisfaction via Questionnaire Feedback](https://doi.org/10.1145/3627673.3679643)|Kepu Zhang, Teng Shi, Sunhao Dai, Xiao Zhang, Yinfeng Li, Jing Lu, Xiaoxue Zang, Yang Song, Jun Xu|Kuaishou Technology Co., Ltd., Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China|In real-world recommender systems, user engagement and subjective feedback play pivotal roles in shaping the content distribution mechanism of the platform. When platforms reach a certain scale, they often gather valuable questionnaire feedback data from users to evaluate their satisfaction with recommended items. Compared to traditional user feedback such as likes, questionnaires explicitly capture both satisfaction and dissatisfaction and are unaffected by other users' questionnaires, thus better expressing users' true preferences. In this paper, we aim to leverage the questionnaire feedback to align the recommendation model with users' true preferences. However, due to the platform distribution mechanism and divergent user attitudes toward questionnaires, the questionnaire feedback data frequently becomes sparse and exhibits selection biases, resulting in challenges in feature integration and training process. To address these issues, we introduce a novel user Satisfaction Alignment framework that effectively leverages Questionnaire feedback to enhance Recommendation, named SAQRec. SAQRec begins by training an unbiased satisfaction model to impute satisfaction, addressing selection bias and data sparsity. Then, SAQRec aligns features with users' true preferences by disentangling satisfaction and dissatisfaction from click history and categorizing clicked items into multiple satisfaction levels through the imputed satisfactions. Additionally, the imputed satisfactions from the pre-trained unbiased satisfaction model serve as pseudo-labels to align the model's outputs with users' true preferences. Extensive experiments on both public and commercial datasets demonstrate SAQRec's superior integration of questionnaire feedback in recommendation models. Online A/B testing on a short video platform confirms its effectiveness in boosting user watch time and positive-to-negative feedback ratio, enhancing overall performance and user satisfaction.|在实际的推荐系统中，用户参与度和主观反馈在塑造平台内容分发机制方面起着关键作用。当平台达到一定规模时，通常会收集用户对推荐项目的满意度问卷反馈数据，以评估用户的满意度。与传统的用户反馈（如点赞）相比，问卷能够明确捕捉用户的满意和不满意情况，并且不受其他用户问卷的影响，因此更能表达用户的真实偏好。本文旨在利用问卷反馈来使推荐模型与用户的真实偏好相一致。然而，由于平台分发机制和用户对问卷的不同态度，问卷反馈数据往往变得稀疏并存在选择偏差，导致特征整合和训练过程面临挑战。为解决这些问题，我们提出了一种新的用户满意度对齐框架，该框架有效利用问卷反馈来增强推荐，命名为SAQRec。SAQRec首先训练一个无偏的满意度模型来填补满意度，解决选择偏差和数据稀疏问题。然后，SAQRec通过对点击历史进行解耦，将满意和不满意分离，并通过填补的满意度将点击项目分类为多个满意度级别，从而使特征与用户的真实偏好对齐。此外，预训练的无偏满意度模型产生的填补满意度作为伪标签，用于使模型的输出与用户的真实偏好对齐。在公共和商业数据集上的广泛实验表明，SAQRec在推荐模型中对问卷反馈的整合具有优越性。在一个短视频平台上的在线A/B测试证实了其在提升用户观看时间和正面反馈与负面反馈比例方面的有效性，从而提高了整体性能和用户满意度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAQRec:+Aligning+Recommender+Systems+to+User+Satisfaction+via+Questionnaire+Feedback)|0|
|[CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment](https://doi.org/10.1145/3627673.3679894)|Akira Kasuga, Ryo Yonetani||This paper presents the Customer Experience (CX) Simulator, a novel framework designed to assess the effects of untested web-marketing campaigns through user behavior simulations. The proposed framework leverages large language models (LLMs) to represent various events in a user's behavioral history, such as viewing an item, applying a coupon, or purchasing an item, as semantic embedding vectors. We train a model to predict transitions between events from their LLM embeddings, which can even generalize to unseen events by learning from diverse training data. In web-marketing applications, we leverage this transition prediction model to simulate how users might react differently when new campaigns or products are presented to them. This allows us to eliminate the need for costly online testing and enhance the marketers' abilities to reveal insights. Our numerical evaluation and user study, utilizing BigQuery Public Datasets from the Google Merchandise Store, demonstrate the effectiveness of our framework.|本文介绍了客户体验（CX）模拟器，这是一个新颖的框架，旨在通过用户行为模拟来评估未经测试的网络营销活动的效果。该框架利用大型语言模型（LLMs）将用户行为历史中的各种事件，如查看商品、使用优惠券或购买商品，表示为语义嵌入向量。我们训练了一个模型，从这些LLM嵌入中预测事件之间的转换，该模型甚至可以通过从多样化的训练数据中学习来泛化到未见过的事件。在网络营销应用中，我们利用这种转换预测模型来模拟用户在新活动或新产品呈现给他们时可能产生的不同反应。这使我们能够消除昂贵的在线测试需求，并增强营销人员揭示洞察的能力。我们的数值评估和用户研究，利用了Google商品商店的BigQuery公共数据集，证明了我们框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CXSimulator:+A+User+Behavior+Simulation+using+LLM+Embeddings+for+Web-Marketing+Campaign+Assessment)|0|
|[Exploring High-Order User Preference with Knowledge Graph for Recommendation](https://doi.org/10.1145/3627673.3679921)|Caijun Xu, Fuwei Zhang, Zhao Zhang, Fuzhen Zhuang, Rui Liu|Institute of Artificial Intelligence, Beihang University, Beijing, China; Institute of Artificial Intelligence, Beihang University & Zhongguancun Laboratory, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Computer Science, Beihang University, Beijing, China|Knowledge Graph (KG) has proven its effectiveness in recommendation systems. Recent knowledge-aware recommendation methods, which utilize graph neural networks and contrastive learning, underestimate two issues: 1) The neglect of modeling the latent relationships between users and entities; 2) The insufficiency of traditional cross-view contrastive learning whose domain is incapable of covering all nodes in a graph. To address these issues, we propose a novel model named Knowledge-aware User Preference Network (KUPN). Specifically, KUPN first constructs the relational preference view containing a new graph named User Preference Graph (UPG) to model the potential relationships between users and entities. Then, we adopt a novel attentive information aggregation to learn the UPG. In addition, we obtain semantic information of users and entities from collaborative knowledge view which consists of KG and Interaction Graph (IG) as supplementary. Finally, we apply a cross-view contrastive learning for complete domains between dynamic relational preference view and collaborative knowledge view. Extensive experiments on three real-world datasets demonstrate the superiority of KUPN against the state-of-the-art methods.|知识图谱（KG）在推荐系统中已证明其有效性。近年来，利用图神经网络和对比学习的知识感知推荐方法低估了两个问题：1）忽视了用户与实体之间潜在关系的建模；2）传统跨视图对比学习的领域不足以覆盖图中的所有节点。为解决这些问题，我们提出了一种名为知识感知用户偏好网络（KUPN）的新模型。具体而言，KUPN首先构建了包含用户偏好图（UPG）的关系偏好视图，以建模用户与实体之间的潜在关系。接着，我们采用了一种新颖的注意力信息聚合方法来学习UPG。此外，我们从协同知识视图中获取用户和实体的语义信息，该视图由KG和交互图（IG）组成，作为补充。最后，我们在动态关系偏好视图和协同知识视图之间应用了跨视图对比学习，以实现完整领域的覆盖。在三个真实世界数据集上的广泛实验表明，KUPN相较于最先进的方法具有优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+High-Order+User+Preference+with+Knowledge+Graph+for+Recommendation)|0|
|[EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3680055)|Lei Huang, Weitao Li, Chenrui Zhang, Jinpeng Wang, Xianchun Yi, Sheng Chen||Cross-domain recommendation has attracted substantial interest in industrial apps such as Meituan, which serves multiple business domains via knowledge transfer and meets the diverse interests of users. However, existing methods typically follow an implicit modeling paradigm that blends the knowledge from both the source and target domains, and design intricate network structures to share learned embeddings or patterns between domains to improve recommendation accuracy. Since the transfer of interest signals is unsupervised, these implicit paradigms often struggle with the negative transfer resulting from differences in service functions and presentation forms across different domains. In this paper, we propose a simple and effective EXplicit Interest Transfer framework named EXIT to address the stated challenge. Specifically, we propose a novel label combination approach that enables the model to directly learn beneficial source domain interests through supervised learning, while excluding inappropriate interest signals. Moreover, we introduce a scene selector network to model the interest transfer intensity under fine-grained scenes. Offline experiments conducted on the industrial production dataset and online A/B tests validate the superiority and effectiveness of our proposed framework. Without complex network structures or training processes, EXIT can be easily deployed in the industrial recommendation system. EXIT has been successfully deployed in the online homepage recommendation system of Meituan App, serving the main traffic.|跨领域推荐在美团等工业应用中引起了广泛关注，通过知识转移服务于多个业务领域，满足用户的多样化兴趣。然而，现有方法通常采用隐式建模范式，将源域和目标域的知识混合，设计复杂的网络结构以在域间共享学习到的嵌入或模式，从而提高推荐准确性。由于兴趣信号的转移是无监督的，这些隐式范式往往因不同域间服务功能和呈现形式的差异而遭遇负迁移问题。本文提出了一种简单而有效的显式兴趣转移框架，名为EXIT，以应对上述挑战。具体而言，我们提出了一种新颖的标签组合方法，使模型能够通过监督学习直接学习有益的源域兴趣，同时排除不适当的兴趣信号。此外，我们引入了一个场景选择器网络，以在细粒度场景下建模兴趣转移强度。在工业生产数据集上的离线实验和在线A/B测试验证了我们提出的框架的优越性和有效性。EXIT无需复杂的网络结构或训练过程，可以轻松部署在工业推荐系统中。EXIT已成功部署在美团App的在线首页推荐系统中，服务于主要流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EXIT:+An+EXplicit+Interest+Transfer+Framework+for+Cross-Domain+Recommendation)|0|
|[To Explore or Exploit? A Gradient-informed Framework to Address the Feedback Loop for Graph based Recommendation](https://doi.org/10.1145/3627673.3680061)|Zhigang Huangfu, Binbin Hu, Zhengwei Wu, Fengyu Han, GongDuo Zhang, Lihong Gu, Zhiqiang Zhang|Ant Group, Hangzhou, China; Ant Group, Hang Zhou, China|Graph-based Recommendation Systems (GRSs) have gained prominence for their ability to enhance the accuracy and effectiveness of recommender systems by exploiting structural relationships in user-item interaction data. Despite their advanced capabilities, we find GRSs are susceptible to feedback-loop phenomena that disproportionately diminish the visibility of new and long-tail items, leading to a homogenization of recommendations and the potential emergence of echo chambers. To mitigate this feedback-loop issue, exploration and exploitation (E&E) strategies have been extensively researched. However, conventional E&E methods rest on the assumption that recommendations are independent and identically distributed-an assumption that is not valid for GRSs. To forge an effective E&E approach tailored to GRSs, we introduce a novel framework, the GRADient-informed Exploration and Exploitation (GRADE), designed to adaptively seek out underrepresented or new items with promising rewards. Our method evaluates the potential benefit of exploring an item by assessing the change in the system's empirical risk error pre- and post-exposure. For practical implementation, we approximate this measure using the gradients of potential edges and model parameters, alongside their associated uncertainties. We then orchestrate the balance between exploration and exploitation utilizing Thompson sampling and the Upper Confidence Bound (UCB) strategy. Empirical tests on datasets from two industrial environments demonstrate that GRADE consistently outperforms existing state-of-the-art methods. Additionally, our approach has been successfully integrated into actual industrial systems.|基于图的推荐系统（GRSs）因其能够通过利用用户-项目交互数据中的结构关系来提高推荐系统的准确性和有效性而备受关注。尽管其功能强大，我们发现GRSs易受反馈循环现象的影响，这种现象不均衡地降低了新项目和长尾项目的可见性，导致推荐内容的同质化，并可能催生回音壁效应。为缓解这一反馈循环问题，探索与利用（E&E）策略得到了广泛研究。然而，传统的E&E方法基于推荐是独立同分布的假设，这一假设对于GRSs并不成立。为了针对GRSs开发一种有效的E&E方法，我们引入了一个新的框架——基于梯度的探索与利用（GRADE），该框架旨在自适应地发掘具有潜在回报的未充分代表或新项目。我们的方法通过评估系统在项目曝光前后的经验风险误差变化，来评估探索某一项目的潜在收益。在实际应用中，我们利用潜在边的梯度和模型参数及其相关的不确定性来近似这一度量。随后，我们利用汤普森采样和上置信界（UCB）策略来协调探索与利用之间的平衡。在两个工业环境数据集上的实证测试表明，GRADE始终优于现有的最先进方法。此外，我们的方法已成功集成到实际的工业系统中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=To+Explore+or+Exploit?+A+Gradient-informed+Framework+to+Address+the+Feedback+Loop+for+Graph+based+Recommendation)|0|
|[Sequential Optimum Test with Multi-armed Bandits for Online Experimentation](https://doi.org/10.1145/3627673.3680040)|Fang Kong, Penglei Zhao, Shichao Han, Yong Wang, Shuai Li|Shanghai Jiao Tong University, Shanghai, China; Tencent Inc., Shenzhen, China|In large-scale online experimentation platforms, experimenters aim to discover the best treatment (arm) among multiple candidates. Traditional A/B testing and multi-armed bandits (MAB) algorithms are two popular designs. The former usually achieves a higher power but may hurt the customers' satisfaction when always recommending a poor arm, while the latter aims at improving the customers' experience (collecting more rewards) but faces the loss of testing power. Recently, [26] combine the advantage of A/B testing and MAB algorithms to maximize the testing power while maintaining more rewards for experiments with two-arm and Bernoulli rewards. However, in practice, the number of arms is usually larger than two and the reward type also varies. In multi-arm experiments, the required sample size to find the optimal arm blows up to guarantee a false discovery rate with the increase of arm numbers, bringing high opportunity costs to experimenters. To save the cost during the long experimental process, we propose a more efficient sequential test framework named Soptima that can work with general reward types. Inspired by the design of traditional MAB algorithms in chasing rewards and A/B testing in maximizing power, we propose an Elimination-type strategy adapted to this framework to dynamically adjust the traffic split on arms. This strategy cooperating with Soptima simultaneously maintains the advantage of the A/B testing in maximizing the testing power, the sequential test methods in saving the sample size, and the MAB algorithms in collecting rewards. The theoretical analysis gives guarantees on the Type-I, Type-II, and optimality error rates of the proposed approach. A series of experiments from both simulation and industrial historical data sets are conducted to verify the superiority of our approach compared with available baselines.|在大规模在线实验平台中，实验者的目标是从多个候选方案（臂）中找出最佳方案。传统的A/B测试和多臂老虎机（MAB）算法是两种流行的设计方案。前者通常具有更高的测试效能，但当总是推荐效果不佳的方案时，可能会损害客户的满意度；而后者旨在提升客户体验（收集更多奖励），但面临测试效能的损失。最近，[26]结合了A/B测试和MAB算法的优势，以最大化测试效能，同时在两臂和伯努利奖励的实验中保持更多的奖励。然而，在实践中，臂的数量通常大于两个，且奖励类型也多种多样。在多臂实验中，随着臂数量的增加，为了保证错误发现率，找到最佳臂所需的样本量会急剧增加，这给实验者带来了高昂的机会成本。为了在漫长的实验过程中节省成本，我们提出了一种名为Soptima的高效序列测试框架，该框架适用于一般的奖励类型。受传统MAB算法在追逐奖励和A/B测试在最大化效能的设计启发，我们提出了一种适应此框架的淘汰型策略，以动态调整对各臂的流量分配。这种策略与Soptima合作，同时保持了A/B测试在最大化测试效能、序列测试方法在节省样本量以及MAB算法在收集奖励方面的优势。理论分析为所提出方法的I类错误率、II类错误率和最优性错误率提供了保障。通过一系列来自模拟和工业历史数据集的实验，验证了我们的方法相对于现有基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential+Optimum+Test+with+Multi-armed+Bandits+for+Online+Experimentation)|0|
|[TWIN V2: Scaling Ultra-Long User Behavior Sequence Modeling for Enhanced CTR Prediction at Kuaishou](https://doi.org/10.1145/3627673.3680030)|Zihua Si, Lin Guan, Zhongxiang Sun, Xiaoxue Zang, Jing Lu, Yiqun Hui, Xingchao Cao, Zeyu Yang, Yichen Zheng, Dewei Leng, Kai Zheng, Chenbin Zhang, Yanan Niu, Yang Song, Kun Gai||The significance of modeling long-term user interests for CTR prediction tasks in large-scale recommendation systems is progressively gaining attention among researchers and practitioners. Existing work, such as SIM and TWIN, typically employs a two-stage approach to model long-term user behavior sequences for efficiency concerns. The first stage rapidly retrieves a subset of sequences related to the target item from a long sequence using a search-based mechanism namely the General Search Unit (GSU), while the second stage calculates the interest scores using the Exact Search Unit (ESU) on the retrieved results. Given the extensive length of user behavior sequences spanning the entire life cycle, potentially reaching up to 10^6 in scale, there is currently no effective solution for fully modeling such expansive user interests. To overcome this issue, we introduced TWIN-V2, an enhancement of TWIN, where a divide-and-conquer approach is applied to compress life-cycle behaviors and uncover more accurate and diverse user interests. Specifically, a hierarchical clustering method groups items with similar characteristics in life-cycle behaviors into a single cluster during the offline phase. By limiting the size of clusters, we can compress behavior sequences well beyond the magnitude of 10^5 to a length manageable for online inference in GSU retrieval. Cluster-aware target attention extracts comprehensive and multi-faceted long-term interests of users, thereby making the final recommendation results more accurate and diverse. Extensive offline experiments on a multi-billion-scale industrial dataset and online A/B tests have demonstrated the effectiveness of TWIN-V2. Under an efficient deployment framework, TWIN-V2 has been successfully deployed to the primary traffic that serves hundreds of millions of daily active users at Kuaishou.|在大规模推荐系统中，建模长期用户兴趣对点击率（CTR）预测任务的重要性正逐渐受到研究者和从业者的关注。现有的研究工作，如SIM和TWIN，通常采用两阶段方法来高效地建模长期用户行为序列。第一阶段通过基于搜索的机制，即通用搜索单元（GSU），从长序列中快速检索与目标项目相关的子集序列；第二阶段则使用精确搜索单元（ESU）对检索结果计算兴趣分数。鉴于用户行为序列的广泛长度可能跨越整个生命周期，规模可达10^6，目前尚无有效解决方案来全面建模如此广泛的用户兴趣。为解决这一问题，我们引入了TWIN-V2，即TWIN的增强版本，采用分而治之的方法来压缩生命周期行为并揭示更准确和多样的用户兴趣。具体而言，层次聚类方法在离线阶段将具有相似特征的生命周期行为项目分组为一个集群。通过限制集群大小，我们可以将行为序列压缩到远超10^5的规模，使其适合在线推理中的GSU检索。集群感知的目标注意力机制提取了用户全面且多方面的长期兴趣，从而使最终的推荐结果更加准确和多样化。在多十亿规模工业数据集上的广泛离线实验和在线A/B测试证明了TWIN-V2的有效性。在高效部署框架下，TWIN-V2已成功部署到快手的主要流量中，服务数亿日活用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TWIN+V2:+Scaling+Ultra-Long+User+Behavior+Sequence+Modeling+for+Enhanced+CTR+Prediction+at+Kuaishou)|0|
|[Understanding the User: An Intent-Based Ranking Dataset](https://doi.org/10.1145/3627673.3679166)|Abhijit Anand, Jurek Leonhardt, Venktesh V, Avishek Anand||As information retrieval systems continue to evolve, accurate evaluation and benchmarking of these systems become pivotal. Web search datasets, such as MS MARCO, primarily provide short keyword queries without accompanying intent or descriptions, posing a challenge in comprehending the underlying information need. This paper proposes an approach to augmenting such datasets to annotate informative query descriptions, with a focus on two prominent benchmark datasets: TREC-DL-21 and TREC-DL-22. Our methodology involves utilizing state-of-the-art LLMs to analyze and comprehend the implicit intent within individual queries from benchmark datasets. By extracting key semantic elements, we construct detailed and contextually rich descriptions for these queries. To validate the generated query descriptions, we employ crowdsourcing as a reliable means of obtaining diverse human perspectives on the accuracy and informativeness of the descriptions. This information can be used as an evaluation set for tasks such as ranking, query rewriting, or others.|随着信息检索系统不断演进，对其进行准确的评估和基准测试变得至关重要。诸如MS MARCO等网络搜索数据集主要提供简短的关键词查询，缺乏伴随的意图或描述，这给理解背后的信息需求带来了挑战。本文提出了一种增强此类数据集的方法，旨在为查询添加信息丰富的描述，重点关注两个著名的基准数据集：TREC-DL-21和TREC-DL-22。我们的方法涉及利用最先进的LLMs（大型语言模型）来分析和理解基准数据集中各个查询的隐含意图。通过提取关键的语义元素，我们为这些查询构建了详细且上下文丰富的描述。为了验证生成的查询描述，我们采用众包作为获取多样化人类视角的可靠手段，以评估描述的准确性和信息量。这些信息可以作为排序、查询重写等任务的评估集使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+User:+An+Intent-Based+Ranking+Dataset)|0|
|[Domain Alignment with Large Vision-language Models for Cross-domain Remote Sensing Image Retrieval](https://doi.org/10.1145/3627673.3679612)|Yan Chen, Guocan Cai, Fufang Li, Yangtao Wang, Xin Tan, Xiaocui Li|East China Normal University, Shanghai, China; School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, China; Hunan University of Technology and Business, Changsha, China|Cross-domain remote sensing image retrieval has been a hotspot in the past few years. Most of the existing methods focus on combining semantic learning with domain adaptation on well-labeled source domain and unlabeled target domain. However, they face two serious challenges. (1) They cannot deal with practical scenarios where the source domain lacks sufficient label supervision. (2) They suffer from severe performance degradation when the data distribution between the source domain and target domain becomes highly inconsistent. To address these challenges, we propose D omain A lignment with L arge V ision-language models for cross-domain remote sensing image retrieval (termed as DALV). First, we design a dual-modality prototype guided pseudo-labeling mechanism, which leverages the pre-trained large vision-language model (i.e., CLIP) to assign pseudo-labels for all unlabeled source domain images and target domain images. Second, we compute the confidence scores for these pseudo-labels to distinguish their reliability. Next, we devise a loss reweighting strategy, which incorporates the confidence scores as weight values into the contrastive loss to mitigate the impact of noisy pseudo-labels. Finally, the low-rank adaptation fine-tuning means is adapted to update our model and achieve domain alignment to obtain class discriminative features. Extensive experiments on 12 cross-domain remote sensing image retrieval tasks show that our proposed DALV outperforms the state-of-the-art approaches. The source code is available at https://github.com/ptyy01/DALV.|跨领域遥感图像检索近年来成为研究热点。现有方法大多集中在结合语义学习和领域适应于标签丰富的源域和无标签的目标域。然而，这些方法面临两个严重挑战：（1）无法处理源域缺乏足够标签监督的实际场景；（2）当源域和目标域的数据分布高度不一致时，性能严重下降。为应对这些挑战，我们提出了基于大规模视觉语言模型的跨领域遥感图像检索的领域对齐方法（简称DALV）。首先，我们设计了一种双模态原型引导的伪标签机制，利用预训练的大规模视觉语言模型（如CLIP）为所有无标签的源域图像和目标域图像分配伪标签。其次，我们计算这些伪标签的置信度分数以区分其可靠性。接着，我们设计了一种损失重加权策略，将置信度分数作为权重值融入对比损失，以减轻噪声伪标签的影响。最后，采用低秩适应微调方法更新模型，实现领域对齐，获取具有类别区分性的特征。在12个跨领域遥感图像检索任务上的广泛实验表明，我们提出的DALV方法优于现有最先进的方法。源代码可在https://github.com/ptyy01/DALV获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain+Alignment+with+Large+Vision-language+Models+for+Cross-domain+Remote+Sensing+Image+Retrieval)|0|
|[DIIT: A Domain-Invariant Information Transfer Method for Industrial Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3679782)|Heyuan Huang, Xingyu Lou, Chaochao Chen, Pengxiang Cheng, Yue Xin, Chengwei He, Xiang Liu, Jun Wang||Cross-Domain Recommendation (CDR) have received widespread attention due to their ability to utilize rich information across domains. However, most existing CDR methods assume an ideal static condition that is not practical in industrial recommendation systems (RS). Therefore, simply applying existing CDR methods in the industrial RS environment may lead to low effectiveness and efficiency. To fill this gap, we propose DIIT, an end-to-end Domain-Invariant Information Transfer method for industrial cross-domain recommendation. Specifically, We first simulate the industrial RS environment that maintains respective models in multiple domains, each of them is trained in the incremental mode. Then, for improving the effectiveness, we design two extractors to fully extract domain-invariant information from the latest source domain models at the domain level and the representation level respectively. Finally, for improving the efficiency, we design a migrator to transfer the extracted information to the latest target domain model, which only need the target domain model for inference. Experiments conducted on one production dataset and two public datasets verify the effectiveness and efficiency of DIIT.|跨域推荐（CDR）因其能够利用跨领域的丰富信息而受到广泛关注。然而，大多数现有的CDR方法假设了一个理想的静态条件，这在工业推荐系统（RS）中并不实际。因此，简单地将现有的CDR方法应用于工业RS环境中可能导致效果和效率低下。为了填补这一空白，我们提出了DIIT，一种用于工业跨域推荐的端到端领域不变信息传递方法。具体而言，我们首先模拟了工业RS环境，该环境在多个领域中维护各自的模型，每个模型都以增量模式进行训练。然后，为了提高效果，我们设计了两个提取器，分别从领域级别和表示级别充分提取最新源域模型中的领域不变信息。最后，为了提高效率，我们设计了一个迁移器，将提取的信息传递到最新的目标域模型，该模型仅需要进行目标域模型的推理。在一个生产数据集和两个公共数据集上进行的实验验证了DIIT的有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIIT:+A+Domain-Invariant+Information+Transfer+Method+for+Industrial+Cross-Domain+Recommendation)|0|
|[The Devil is in the Sources! Knowledge Enhanced Cross-Domain Recommendation in an Information Bottleneck Perspective](https://doi.org/10.1145/3627673.3679595)|Binbin Hu, Weifan Wang, Shuhan Wang, Ziqi Liu, Bin Shen, Yong He, Jiawei Chen||Cross-domain Recommendation (CDR) aims to alleviate the data sparsity and the cold-start problems in traditional recommender systems by leveraging knowledge from an informative source domain. However, previously proposed CDR models pursue an imprudent assumption that the entire information from the source domain is equally contributed to the target domain, neglecting the evil part that is completely irrelevant to users' intrinsic interest. To address this concern, in this paper, we propose a novel knowledge enhanced cross-domain recommendation framework named CoTrans, which remolds the core procedures of CDR models with: Compression on the knowledge from the source domain and Transfer of the purity to the target domain. Specifically, following the theory of Graph Information Bottleneck, CoTrans first compresses the source behaviors with the perception of information from the target domain. Then to preserve all the important information for the CDR task, the feedback signals from both domains are utilized to promote the effectiveness of the transfer procedure. Additionally, a knowledge-enhanced encoder is employed to narrow gaps caused by the non-overlapped items across separate domains. Comprehensive experiments on three widely used cross-domain datasets demonstrate that CoTrans significantly outperforms both single-domain and state-of-the-art cross-domain recommendation approaches.|跨域推荐（CDR）旨在通过利用信息丰富的源域知识，缓解传统推荐系统中的数据稀疏性和冷启动问题。然而，先前提出的CDR模型追求一个不谨慎的假设，即源域的全部信息对目标域的贡献是均等的，忽视了与用户内在兴趣完全无关的有害部分。为了解决这一问题，本文提出了一种名为CoTrans的新型知识增强跨域推荐框架，该框架通过以下核心步骤重构了CDR模型的流程：源域知识的压缩和目标域纯净信息的转移。具体而言，遵循图信息瓶颈理论，CoTrans首先根据目标域的信息感知压缩源域行为。然后，为了保留CDR任务的所有重要信息，利用来自两个域的反馈信号来提升转移过程的有效性。此外，采用知识增强编码器来缩小各域之间非重叠项目造成的差距。在三个广泛使用的跨域数据集上的综合实验表明，CoTrans显著优于单一域和最先进的跨域推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Devil+is+in+the+Sources!+Knowledge+Enhanced+Cross-Domain+Recommendation+in+an+Information+Bottleneck+Perspective)|0|
|[MuLe: Multi-Grained Graph Learning for Multi-Behavior Recommendation](https://doi.org/10.1145/3627673.3679709)|Seunghan Lee, Geonwoo Ko, HyunJe Song, Jinhong Jung|School of Software, Soongsil University, Seoul, Republic of Korea; Dept. of CSAI, Jeonbuk Nat'l Univ., Jeonju, Republic of Korea|Multi-behavior recommender systems, rapidly advancing across various domains, utilize plentiful auxiliary interactions on a variety of user behaviors to enhance recommendations for the target behavior, such as purchases. While previous methods have made strides in leveraging such interactions with advanced machine learning methods, they still face challenges in adequately using multi-faceted relationships among behaviors and handling uncertain auxiliary interactions that could potentially lead to purchases or not. In this paper, we propose MuLe (Multi-Grained Graph Learning), a novel graph-based model designed to address these limitations. We design a multi-grained graph learning strategy to capture diverse aspects of behaviors, ranging from unified to specific, and then to target-related behavior interactions. To handle uncertain interactions, we use graph attention, weighting the importance of those interactions related to the target behavior. Afterward, we use an attention mechanism to effectively aggregate diverse behavior embeddings obtained from the multi-grained graph encoders. Extensive experiments show that MuLe significantly outperforms the state-of-the-art methods, achieving improvements of up to 44.6% in HR@10 and 52.9% in NDCG@10, respectively. Our code and datasets are available at https://github.com/geonwooko/MULE.|多行为推荐系统在各个领域迅速发展，利用丰富的用户行为辅助交互来增强对目标行为（如购买）的推荐。尽管先前的方法通过先进的机器学习方法在这一领域取得了进展，但它们在充分使用行为之间的多方面关系以及处理可能导致或不导致购买的模糊辅助交互方面仍面临挑战。本文提出了MuLe（多粒度图学习），这是一种新颖的基于图的模型，旨在解决这些局限性。我们设计了一种多粒度图学习策略，以捕捉从统一到具体再到与目标相关的行为交互的多样性。为了处理不确定的交互，我们使用图注意力机制，对与目标行为相关的交互进行重要性加权。随后，我们采用注意力机制，有效地聚合从多粒度图编码器获得的各种行为嵌入。广泛的实验表明，MuLe显著优于最先进的方法，HR@10和NDCG@10分别提高了44.6%和52.9%。我们的代码和数据集可在https://github.com/geonwooko/MULE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MuLe:+Multi-Grained+Graph+Learning+for+Multi-Behavior+Recommendation)|0|
|[Inferring Visualization Intent from Conversation](https://doi.org/10.1145/3627673.3679589)|Haotian Li, Nithin Chalapathi, Huamin Qu, Alvin Cheung, Aditya G. Parameswaran|HKUST, Hong Kong, China; UC Berkeley, Berkeley, CA, USA|During visual data analysis, users often explore visualizations one at a time, with each visualization leading to new directions of exploration. We consider a conversational approach to visualization, where users specify their needs at each step in natural language, with a visualization being returned in turn. Prior work has shown that visualization generation can be boiled down to the identification of visualization intent and visual encodings. Recognizing that the latter is a well-studied problem with standard solutions, we focus on the former, i.e., identifying visualization intent during conversation. We develop Luna, a framework that comprises a novel combination of language models adapted from BERT and rule-based inference, that together predict various aspects of visualization intent. We compare Luna with other conversational NL-to-visualization and NL-to-SQL approaches (adapted to visualization intent), including GPT-3.5 and GPT-4, and demonstrate that Luna has 14.3% higher accuracy than the state-of-the-art. We also apply Luna to a usage scenario on a dataset of police misconduct, showcasing its benefits relative to other approaches.|在视觉数据分析过程中，用户通常一次只探索一个可视化图表，每个图表都引导出新的探索方向。我们考虑了一种对话式的可视化方法，用户在每一步以自然语言指定其需求，并依次返回一个可视化图表。先前的研究表明，可视化生成可以简化为可视化意图和视觉编码的识别。鉴于后者是一个已有标准解决方案的成熟问题，我们将重点放在前者，即在对话过程中识别可视化意图。我们开发了Luna框架，该框架结合了从BERT改编的语言模型和基于规则的推理，共同预测可视化意图的各个方面。我们将Luna与其他对话式自然语言到可视化和自然语言到SQL的方法（适配于可视化意图）进行了比较，包括GPT-3.5和GPT-4，并展示了Luna比现有技术高出14.3%的准确性。我们还应用Luna到一个关于警察不当行为的实际数据集场景中，展示了其相对于其他方法的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inferring+Visualization+Intent+from+Conversation)|0|
|[GUME: Graphs and User Modalities Enhancement for Long-Tail Multimodal Recommendation](https://doi.org/10.1145/3627673.3679620)|Guojiao Lin, Zhen Meng, Dongjie Wang, Qingqing Long, Yuanchun Zhou, Meng Xiao||Multimodal recommendation systems (MMRS) have received considerable attention from the research community due to their ability to jointly utilize information from user behavior and product images and text. Previous research has two main issues. First, many long-tail items in recommendation systems have limited interaction data, making it difficult to learn comprehensive and informative representations. However, past MMRS studies have overlooked this issue. Secondly, users' modality preferences are crucial to their behavior. However, previous research has primarily focused on learning item modality representations, while user modality representations have remained relatively simplistic.To address these challenges, we propose a novel Graphs and User Modalities Enhancement (GUME) for long-tail multimodal recommendation. Specifically, we first enhance the user-item graph using multimodal similarity between items. This improves the connectivity of long-tail items and helps them learn high-quality representations through graph propagation. Then, we construct two types of user modalities: explicit interaction features and extended interest features. By using the user modality enhancement strategy to maximize mutual information between these two features, we improve the generalization ability of user modality representations. Additionally, we design an alignment strategy for modality data to remove noise from both internal and external perspectives. Extensive experiments on four publicly available datasets demonstrate the effectiveness of our approach.|多模态推荐系统（MMRS）因其能够联合利用用户行为、产品图像和文本信息而受到研究界的广泛关注。以往的研究存在两个主要问题。首先，推荐系统中许多长尾项目（long-tail items）的交互数据有限，这使得学习全面且信息丰富的表示变得困难。然而，过去的MMRS研究忽视了这一问题。其次，用户的模态偏好对其行为至关重要。然而，以往的研究主要集中在学习项目模态表示上，而用户模态表示则相对简单。为了解决这些挑战，我们提出了一种新的针对长尾多模态推荐的图与用户模态增强（GUME）方法。具体来说，我们首先通过项目间的多模态相似性来增强用户-项目图，这提高了长尾项目的连通性，并帮助它们通过图传播学习高质量的表示。然后，我们构建了两种用户模态：显式交互特征和扩展兴趣特征。通过使用用户模态增强策略来最大化这两种特征之间的互信息，我们提高了用户模态表示的泛化能力。此外，我们还设计了一种模态数据对齐策略，以从内部和外部角度去除噪声。在四个公开可用的数据集上进行的广泛实验证明了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GUME:+Graphs+and+User+Modalities+Enhancement+for+Long-Tail+Multimodal+Recommendation)|0|
|[Multi-Behavior Generative Recommendation](https://doi.org/10.1145/3627673.3679730)|Zihan Liu, Yupeng Hou, Julian J. McAuley|University of California, San Diego, San Diego, CA, USA|Multi-behavior sequential recommendation (MBSR) aims to incorporate behaviortypes of interactions for better recommendations. Existing approaches focus onthe next-item prediction objective, neglecting the value of integrating thetarget behavior type into the learning objective. In this paper, we proposeMBGen, a novel Multi-Behavior sequential Generative recommendation framework.We formulate the MBSR task into a consecutive two-step process: (1) given itemsequences, MBGen first predicts the next behavior type to frame the userintention, (2) given item sequences and a target behavior type, MBGen thenpredicts the next items. To model such a two-step process, we tokenize bothbehaviors and items into tokens and construct one single token sequence withboth behaviors and items placed interleaved. Furthermore, MBGen learns toautoregressively generate the next behavior and item tokens in a unifiedgenerative recommendation paradigm, naturally enabling a multi-task capability.Additionally, we exploit the heterogeneous nature of token sequences in thegenerative recommendation and propose a position-routed sparse architecture toefficiently and effectively scale up models. Extensive experiments on publicdatasets demonstrate that MBGen significantly outperforms existing MBSR modelsacross multiple tasks.|多行为序列推荐（MBSR）旨在整合交互行为类型以实现更佳的推荐效果。现有方法主要聚焦于下一项预测目标，忽略了将目标行为类型整合到学习目标中的价值。本文提出了一种名为MBGen的新型多行为序列生成推荐框架。我们将MBSR任务构建成一个连续的两步过程：（1）在给定项目序列的情况下，MBGen首先预测下一行为类型以构建用户意图；（2）在给定项目序列和目标行为类型的基础上，MBGen随后预测下一项目。为模拟这一两步过程，我们将行为和项目都标记化为令牌，并构建一个包含交错放置的行为和项目的单一令牌序列。此外，MBGen在统一的生成推荐范式中自回归地生成下一行为和项目令牌，自然地实现了多任务能力。我们还利用生成推荐中令牌序列的异构性，提出了一种位置路由稀疏架构，以高效且有效地扩展模型规模。在公共数据集上的广泛实验表明，MBGen在多个任务中显著优于现有的MBSR模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavior+Generative+Recommendation)|0|
|[Veracity Estimation for Entity-Oriented Search with Knowledge Graphs](https://doi.org/10.1145/3627673.3679561)|Stefano Marchesin, Gianmaria Silvello, Omar Alonso|University of Padua, Padua, Italy; Amazon, Palo Alto, California, USA|In this paper, we discuss the potential costs that emerge from using a Knowledge Graph (KG) in entity-oriented search without considering its data veracity. We argue for the need for KG veracity analysis to gain insights and propose a scalable assessment framework. Previous assessments focused on relevance, assuming correct KGs, and overlooking the potential risks of misinformation. Our approach strategically allocates annotation resources, optimizing utility and revealing the significant impact of veracity on entity search and card generation. Contributions include a fresh perspective on entity-oriented search extending beyond the conventional focus on relevance, a scalable assessment framework, exploratory experiments highlighting the impact of veracity on ranking and user experience, as well as outlining associated challenges and opportunities.|本文探讨了在面向实体的搜索中使用知识图谱（KG）而不考虑其数据真实性所可能产生的潜在成本。我们主张进行知识图谱真实性分析以获取洞察，并提出一个可扩展的评估框架。以往的评估主要集中在相关性上，假设知识图谱是正确的，而忽视了错误信息可能带来的潜在风险。我们的方法策略性地分配标注资源，优化效用并揭示真实性对实体搜索和卡片生成的重要影响。主要贡献包括：对面向实体的搜索提出了超越传统相关性关注的新视角，一个可扩展的评估框架，探索性实验突显了真实性对排名和用户体验的影响，以及概述了相关的挑战和机遇。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Veracity+Estimation+for+Entity-Oriented+Search+with+Knowledge+Graphs)|0|
|[Inductive Knowledge Graph Embedding via Exploring Interaction Patterns of Relations](https://doi.org/10.1145/3627673.3679667)|Chong Mu, Lizong Zhang, Jinchuan Zhang, Qian Huang, Zhiguo Wang||Recent research in inductive reasoning has focused on predicting missing links between entities that are not observed during training. However, most approaches usually require that the relations are known at the inference time. In the real world, new entities and new relations usually emerge concurrently, which greatly challenges the model's generalization ability. In this paper, we propose a novel inductive knowledge graph embedding model that effectively handles unknown entities and relations by capturing their local structural features. Specifically, a relation graph is constructed to learn relation representations. In the relation graph, we employ a four-dimensional vector to represent the interaction patterns between nodes (relations), where each dimension corresponds to a specific type of interaction. For entity representations, our model dynamically initializes entity features using relation features and attentively aggregates neighboring features of entities to update entity features. By modeling interaction patterns between relations and incorporating structural information of entities, our model learns how to aggregate neighboring embeddings using attention mechanisms, thus generating high-quality embeddings for new entities and relations. Extensive experiments on benchmark datasets demonstrate that our model outperforms state-of-the-art methods, particularly in scenarios involving completely new relations.|最近的研究集中在归纳推理，即预测训练过程中未观察到的实体之间的缺失链接。然而，大多数方法通常要求在推理时已知关系。在现实世界中，新实体和新关系通常同时出现，这对模型的泛化能力提出了巨大挑战。在本文中，我们提出了一种新颖的归纳知识图谱嵌入模型，该模型通过捕捉实体和关系的局部结构特征，有效处理未知实体和关系。具体来说，我们构建了一个关系图来学习关系表示。在关系图中，我们使用一个四维向量来表示节点（关系）之间的交互模式，其中每个维度对应一种特定的交互类型。对于实体表示，我们的模型使用关系特征动态初始化实体特征，并注意聚合实体的邻居特征以更新实体特征。通过建模关系之间的交互模式并结合实体的结构信息，我们的模型学习如何使用注意力机制聚合邻居嵌入，从而生成新实体和关系的高质量嵌入。在基准数据集上的广泛实验表明，我们的模型优于最先进的方法，特别是在涉及完全新关系的场景中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inductive+Knowledge+Graph+Embedding+via+Exploring+Interaction+Patterns+of+Relations)|0|
|[When LLM Meets Hypergraph: A Sociological Analysis on Personality via Online Social Networks](https://doi.org/10.1145/3627673.3679646)|Zhiyao Shu, Xiangguo Sun, Hong Cheng||Individual personalities significantly influence our perceptions, decisions, and social interactions, which is particularly crucial for gaining insights into human behavior patterns in online social network analysis. Many psychological studies have observed that personalities are strongly reflected in their social behaviors and social environments. In light of these problems, this paper proposes a sociological analysis framework for one's personality in an environment-based view instead of individual-level data mining. Specifically, to comprehensively understand an individual's behavior from low-quality records, we leverage the powerful associative ability of LLMs by designing an effective prompt. In this way, LLMs can integrate various scattered information with their external knowledge to generate higher-quality profiles, which can significantly improve the personality analysis performance. To explore the interactive mechanism behind the users and their online environments, we design an effective hypergraph neural network where the hypergraph nodes are users and the hyperedges in the hypergraph are social environments. We offer a useful dataset with user profile data, personality traits, and several detected environments from the real-world social platform. To the best of our knowledge, this is the first network-based dataset containing both hypergraph structure and social information, which could push forward future research in this area further. By employing the framework on this dataset, we can effectively capture the nuances of individual personalities and their online behaviors, leading to a deeper understanding of human interactions in the digital world.|个体性格显著影响我们的感知、决策和社会互动，这对于深入理解在线社交网络分析中的人类行为模式尤为关键。许多心理学研究观察到，性格在其社会行为和社会环境中得到了强烈体现。鉴于这些问题，本文提出了一种基于环境视角而非个体层面数据挖掘的社会学分析框架，用于分析个体性格。具体而言，为了从低质量记录中全面理解个体行为，我们利用大型语言模型（LLMs）强大的关联能力，通过设计有效的提示词，使LLMs能够整合各种分散的信息与其外部知识，生成更高质量的个体画像，从而显著提升性格分析的性能。为了探索用户与其在线环境之间的交互机制，我们设计了一种有效的超图神经网络，其中超图节点为用户，超图的超边为社会环境。我们提供了一个包含用户画像数据、性格特征及从真实社交平台检测到的多种环境的实用数据集。据我们所知，这是首个同时包含超图结构和社会信息的网络数据集，有望推动该领域的未来研究。通过在该数据集上应用该框架，我们能够有效捕捉个体性格及其在线行为的细微差别，从而更深入地理解数字世界中的人类互动。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+LLM+Meets+Hypergraph:+A+Sociological+Analysis+on+Personality+via+Online+Social+Networks)|0|
|[FABLE: Approximate Butterfly Counting in Bipartite Graph Stream with Duplicate Edges](https://doi.org/10.1145/3627673.3679812)|Guozhang Sun, Yuhai Zhao, Yuan Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FABLE:+Approximate+Butterfly+Counting+in+Bipartite+Graph+Stream+with+Duplicate+Edges)|0|
|[Learnable Item Tokenization for Generative Recommendation](https://doi.org/10.1145/3627673.3679569)|Wenjie Wang, Honghui Bao, Xinyu Lin, Jizhi Zhang, Yongqi Li, Fuli Feng, SeeKiong Ng, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learnable+Item+Tokenization+for+Generative+Recommendation)|0|
|[Improving Adversarial Transferability via Frequency-Guided Sample Relevance Attack](https://doi.org/10.1145/3627673.3679858)|Xinyi Wang, Zhibo Jin, Zhiyu Zhu, Jiayu Zhang, Huaming Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Adversarial+Transferability+via+Frequency-Guided+Sample+Relevance+Attack)|0|
|[Image-text Retrieval with Main Semantics Consistency](https://doi.org/10.1145/3627673.3679619)|Yi Xie, Yangtao Wang, Yanzhao Xie, Xin Tan, Jingjing Li, Xiaocui Li, Weilong Peng, Maobin Tang, Meie Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Image-text+Retrieval+with+Main+Semantics+Consistency)|0|
|[Post-Quantum Searchable Encryption Supporting User-Authorization for Outsourced Data Management](https://doi.org/10.1145/3627673.3679522)|Shiyuan Xu, Yibo Cao, Xue Chen, Yu Guo, Yuer Yang, Fangda Guo, SiuMing Yiu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post-Quantum+Searchable+Encryption+Supporting+User-Authorization+for+Outsourced+Data+Management)|0|
|[Decoupled Behavior-based Contrastive Recommendation](https://doi.org/10.1145/3627673.3679636)|Mengduo Yang, Jie Zhou, Meng Xi, Xiaohua Pan, Yi Yuan, Ying Li, Yangyang Wu, Jinshan Zhang, Jianwei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Behavior-based+Contrastive+Recommendation)|0|
|[Hyperbolic Contrastive Learning for Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3679572)|Xin Yang, Heng Chang, Zhijian Lai, Jinze Yang, Xingrun Li, Yu Lu, Shuaiqiang Wang, Dawei Yin, Erxue Min||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperbolic+Contrastive+Learning+for+Cross-Domain+Recommendation)|0|
|[Guaranteeing Accuracy and Fairness under Fluctuating User Traffic: A Bankruptcy-Inspired Re-ranking Approach](https://doi.org/10.1145/3627673.3679590)|Xiaopeng Ye, Chen Xu, Jun Xu, Xuyang Xie, Gang Wang, Zhenhua Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Guaranteeing+Accuracy+and+Fairness+under+Fluctuating+User+Traffic:+A+Bankruptcy-Inspired+Re-ranking+Approach)|0|
|[EFVAE: Efficient Federated Variational Autoencoder for Collaborative Filtering](https://doi.org/10.1145/3627673.3679818)|Lu Zhang, Qian Rong, Xuanang Ding, Guohui Li, Ling Yuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFVAE:+Efficient+Federated+Variational+Autoencoder+for+Collaborative+Filtering)|0|
|[MSKR: Advancing Multi-modal Structured Knowledge Representation with Synergistic Hard Negative Samples](https://doi.org/10.1145/3627673.3679680)|Shuili Zhang, Hongzhang Mu, Tingwen Liu, Qianqian Tong, Jiawei Sheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSKR:+Advancing+Multi-modal+Structured+Knowledge+Representation+with+Synergistic+Hard+Negative+Samples)|0|
|[Watermarking Recommender Systems](https://doi.org/10.1145/3627673.3679617)|Sixiao Zhang, Cheng Long, Wei Yuan, Hongxu Chen, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Watermarking+Recommender+Systems)|0|
|[Multi-modal Food Recommendation with Health-aware Knowledge Distillation](https://doi.org/10.1145/3627673.3679580)|Yixin Zhang, Xin Zhou, Fanglin Zhu, Ning Liu, Wei Guo, Yonghui Xu, Zhiqi Shen, Lizhen Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Food+Recommendation+with+Health-aware+Knowledge+Distillation)|0|
|[Preference Prototype-Aware Learning for Universal Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3679774)|Yuxi Zhang, Ji Zhang, Feiyang Xu, Lvying Chen, Bohan Li, Lei Guo, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preference+Prototype-Aware+Learning+for+Universal+Cross-Domain+Recommendation)|0|
|[Multi-Task Modeling of Student Knowledge and Behavior](https://doi.org/10.1145/3627673.3679823)|Siqian Zhao, Sherry Sahebi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Modeling+of+Student+Knowledge+and+Behavior)|0|
|[Accurate Embedding-based Log Determinant Optimization](https://doi.org/10.1145/3627673.3679871)|Daye Eun, Byungkon Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accurate+Embedding-based+Log+Determinant+Optimization)|0|
|[Knowledge-enhanced Dynamic Modeling framework for Multi-Behavior Recommendation](https://doi.org/10.1145/3627673.3679949)|Xiujuan Li, Nan Wang, Jin Zeng, Yingli Zhong, Zhonghui Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-enhanced+Dynamic+Modeling+framework+for+Multi-Behavior+Recommendation)|0|
|[Multi-DSI: Non-deterministic Identifier and Concept Alignment for Differentiable Search Index](https://doi.org/10.1145/3627673.3679971)|YuZe Liu, JyunYu Jiang, PuJen Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-DSI:+Non-deterministic+Identifier+and+Concept+Alignment+for+Differentiable+Search+Index)|0|
|[Do We Really Need to Drop Items with Missing Modalities in Multimodal Recommendation?](https://doi.org/10.1145/3627673.3679898)|Daniele Malitesta, Emanuele Rossi, Claudio Pomo, Tommaso Di Noia, Fragkiskos D. Malliaros||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+We+Really+Need+to+Drop+Items+with+Missing+Modalities+in+Multimodal+Recommendation?)|0|
|[SOUP: A Unified Shopping Query Suggestion Framework to Optimize Language Model with User Preference](https://doi.org/10.1145/3627673.3679995)|Xu Meng, Zhaohui Luo, Xinxin Wang, Wen Jiang, Wei Ning, Shuhan Qi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SOUP:+A+Unified+Shopping+Query+Suggestion+Framework+to+Optimize+Language+Model+with+User+Preference)|0|
|[LayerPlexRank: Exploring Node Centrality and Layer Influence through Algebraic Connectivity in Multiplex Networks](https://doi.org/10.1145/3627673.3679950)|Hao Ren, Jiaojiao Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LayerPlexRank:+Exploring+Node+Centrality+and+Layer+Influence+through+Algebraic+Connectivity+in+Multiplex+Networks)|0|
|[Osprey 🪶: A Reference Framework for Online Grooming Detection via Neural Models and Conversation Features](https://doi.org/10.1145/3627673.3679974)|Hamed Waezi, Reza Barzegar, Hossein Fani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Osprey+🪶:+A+Reference+Framework+for+Online+Grooming+Detection+via+Neural+Models+and+Conversation+Features)|0|
|[The Effect of Icon Semantic Distance on Preschool Children's Information Search: Evidence from an Eye-Tracking Study](https://doi.org/10.1145/3627673.3680001)|Jiaqi Yang, Pianran Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Effect+of+Icon+Semantic+Distance+on+Preschool+Children's+Information+Search:+Evidence+from+an+Eye-Tracking+Study)|0|
|[Contrastive Disentangled Representation Learning for Debiasing Recommendation with Uniform Data](https://doi.org/10.1145/3627673.3679889)|Xinxin Yang, Zhen Liu, Xiaoman Lu, Yafan Yuan, Sibo Lu, Yibo Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Disentangled+Representation+Learning+for+Debiasing+Recommendation+with+Uniform+Data)|0|
|[Dual-level Intents Modeling for Knowledge-aware Recommendation](https://doi.org/10.1145/3627673.3679902)|Jin Zeng, Nan Wang, Jinbao Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-level+Intents+Modeling+for+Knowledge-aware+Recommendation)|0|
|[Distilling Knowledge Based on Curriculum Learning for Temporal Knowledge Graph Embeddings](https://doi.org/10.1145/3627673.3679896)|Bin Zhang, Jiayin Li, Yuanfei Dai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Knowledge+Based+on+Curriculum+Learning+for+Temporal+Knowledge+Graph+Embeddings)|0|
|[Feedback Reciprocal Graph Collaborative Filtering](https://doi.org/10.1145/3627673.3680015)|Weijun Chen, Yuanchen Bei, Qijie Shen, Hao Chen, Xiao Huang, Feiran Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Feedback+Reciprocal+Graph+Collaborative+Filtering)|0|
|[DIFN: A Dual Intention-aware Network for Repurchase Recommendation with Hierarchical Spatio-temporal Fusion](https://doi.org/10.1145/3627673.3680071)|Li Lin, Xin Xu, Hai Wang, Tian He, Desheng Zhang, Shuai Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIFN:+A+Dual+Intention-aware+Network+for+Repurchase+Recommendation+with+Hierarchical+Spatio-temporal+Fusion)|0|
|[Building Natural Language Interface for Product Search](https://doi.org/10.1145/3627673.3680070)|Vijit Malik, Vinayak Puranik, Anirban Majumder, Vivek Sembium||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Building+Natural+Language+Interface+for+Product+Search)|0|
|[EASE: Learning Lightweight Semantic Feature Adapters from Large Language Models for CTR Prediction](https://doi.org/10.1145/3627673.3680048)|Zexuan Qiu, Jieming Zhu, Yankai Chen, Guohao Cai, Weiwen Liu, Zhenhua Dong, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EASE:+Learning+Lightweight+Semantic+Feature+Adapters+from+Large+Language+Models+for+CTR+Prediction)|0|
|[Mitigating Extreme Cold Start in Graph-based RecSys through Re-ranking](https://doi.org/10.1145/3627673.3680069)|Alessandro Sbandi, Federico Siciliano, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Extreme+Cold+Start+in+Graph-based+RecSys+through+Re-ranking)|0|
|[Sequence-level Semantic Representation Fusion for Recommender Systems](https://doi.org/10.1145/3627673.3680037)|Lanling Xu, Zhen Tian, Bingqian Li, Junjie Zhang, Daoyuan Wang, Hongyu Wang, Jinpeng Wang, Sheng Chen, Wayne Xin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequence-level+Semantic+Representation+Fusion+for+Recommender+Systems)|0|
|[Effective Utilization of Large-scale Unobserved Data in Recommendation Systems](https://doi.org/10.1145/3627673.3680067)|Feng Zhang, Yulin Xu, Hongjie Chen, Xu Yuan, Qingwen Liu, Yuning Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Utilization+of+Large-scale+Unobserved+Data+in+Recommendation+Systems)|0|
|[ECRT: Flexible Sequence Enhancement Framework for Cross-Domain Information Reuse in Recommendation](https://doi.org/10.1145/3627673.3680038)|Weiqiang Zhao, ZiYuan Wu, Yatao Yang, Lifeng Hua, Hao Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ECRT:+Flexible+Sequence+Enhancement+Framework+for+Cross-Domain+Information+Reuse+in+Recommendation)|0|
|[Collaborative Scope: Encountering the Substitution Effect within the Delivery Scope in Online Food Delivery Platform](https://doi.org/10.1145/3627673.3680029)|Yida Zhu, Liying Chen, Chen Zheng, Jia Shi, Daping Xiong, Zewen Huang, Shihao Ren, Shuiping Chen, Jinghua Hao, Renqing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Scope:+Encountering+the+Substitution+Effect+within+the+Delivery+Scope+in+Online+Food+Delivery+Platform)|0|
|[EDGE: A Conversational Interface driven by Large Language Models for Educational Knowledge Graphs Exploration](https://doi.org/10.1145/3627673.3679231)|Neda Afreen, Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Francesca Maridina Malloci, Mirko Marras, Andrea Giovanni Martis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EDGE:+A+Conversational+Interface+driven+by+Large+Language+Models+for+Educational+Knowledge+Graphs+Exploration)|0|
|[A Supervised BERT Model for Identifying Core-Intent Bearing Phrases in e-Commerce Queries](https://doi.org/10.1145/3627673.3679072)|Abhishek Sudhakar Deshmukh, Arnab Dutta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Supervised+BERT+Model+for+Identifying+Core-Intent+Bearing+Phrases+in+e-Commerce+Queries)|0|
|[Traversing the Journey of Data and AI: From Convergence to Translation](https://doi.org/10.1145/3627673.3679026)|Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Traversing+the+Journey+of+Data+and+AI:+From+Convergence+to+Translation)|0|
|[Is the Search Engine of the Future a Chatbot?](https://doi.org/10.1145/3627673.3679059)|Suzan Verberne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+the+Search+Engine+of+the+Future+a+Chatbot?)|0|
|[Navigating the Landscape of Reproducible Research: A Predictive Modeling Approach](https://doi.org/10.1145/3627673.3679831)|Akhil Pandey Akella, Sagnik Ray Choudhury, David Koop, Hamed Alhoori||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Navigating+the+Landscape+of+Reproducible+Research:+A+Predictive+Modeling+Approach)|0|
|[Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation](https://doi.org/10.1145/3627673.3679611)|Zhuoxi Bai, Ning Wu, Fengyu Cai, Xinyi Zhu, Yun Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Large+Language+Model+with+Direct+Multi-Preference+Optimization+for+Recommendation)|0|
|[Wise Fusion: Group Fairness Enhanced Rank Fusion](https://doi.org/10.1145/3627673.3679649)|Kathleen Cachel, Elke A. Rundensteiner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wise+Fusion:+Group+Fairness+Enhanced+Rank+Fusion)|0|
|[FCS-HGNN: Flexible Multi-type Community Search in Heterogeneous Information Networks](https://doi.org/10.1145/3627673.3679696)|Guoxin Chen, Fangda Guo, Yongqing Wang, Yanghao Liu, Peiying Yu, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FCS-HGNN:+Flexible+Multi-type+Community+Search+in+Heterogeneous+Information+Networks)|0|
|[ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation](https://doi.org/10.1145/3627673.3679789)|Jizheng Chen, Kounianhua Du, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELCoRec:+Enhance+Language+Understanding+with+Co-Propagation+of+Numerical+and+Categorical+Features+for+Recommendation)|0|
|[Social Influence Learning for Recommendation Systems](https://doi.org/10.1145/3627673.3679598)|Ximing Chen, Pui Ieng Lei, Yijun Sheng, Yanyan Liu, Zhiguo Gong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Social+Influence+Learning+for+Recommendation+Systems)|0|
|[Enhancing Deep Entity Resolution with Integrated Blocker-Matcher Training: Balancing Consensus and Discrepancy](https://doi.org/10.1145/3627673.3679843)|Wenzhou Dou, Derong Shen, Xiangmin Zhou, Hui Bai, Yue Kou, Tiezheng Nie, Hang Cui, Ge Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Deep+Entity+Resolution+with+Integrated+Blocker-Matcher+Training:+Balancing+Consensus+and+Discrepancy)|0|
|[CHDAER: Consistent Hashing-based Data Allocation for Efficient Recommendation in Edge Environment](https://doi.org/10.1145/3627673.3679809)|Zhikang Feng, Chao Yan, Rong Jiang, Xiaolong Xu, Xuyun Zhang, Xiaokang Zhou, Wanchun Dou, Lianyong Qi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CHDAER:+Consistent+Hashing-based+Data+Allocation+for+Efficient+Recommendation+in+Edge+Environment)|0|
|[HierRec: Scenario-Aware Hierarchical Modeling for Multi-scenario Recommendations](https://doi.org/10.1145/3627673.3679615)|Jingtong Gao, Bo Chen, Menghui Zhu, Xiangyu Zhao, Xiaopeng Li, Yuhao Wang, Yichao Wang, Huifeng Guo, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HierRec:+Scenario-Aware+Hierarchical+Modeling+for+Multi-scenario+Recommendations)|0|
|[Information Retrieval Optimization for Non-Exemplar Class Incremental Learning](https://doi.org/10.1145/3627673.3679631)|Shuai Guo, Yang Gu, Yuan Ma, Yingwei Zhang, Weining Weng, Jun Liu, Weiwei Dai, Yiqiang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Retrieval+Optimization+for+Non-Exemplar+Class+Incremental+Learning)|0|
|[Fragment Allocations for Partially Replicated Databases Considering Data Modifications and Changing Workloads](https://doi.org/10.1145/3627673.3679767)|Stefan Halfpap, Rainer Schlosser||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragment+Allocations+for+Partially+Replicated+Databases+Considering+Data+Modifications+and+Changing+Workloads)|0|
|[Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank](https://doi.org/10.1145/3627673.3679531)|Shashank Gupta, Harrie Oosterhuis, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+and+Robust+Safety+Guarantees+for+Advanced+Counterfactual+Learning+to+Rank)|0|
|[Quantum Cognition-Inspired EEG-based Recommendation via Graph Neural Networks](https://doi.org/10.1145/3627673.3679564)|Jinkun Han, Wei Li, Yingshu Li, Zhipeng Cai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantum+Cognition-Inspired+EEG-based+Recommendation+via+Graph+Neural+Networks)|0|
|[From Retrieval to Generation: Efficient and Effective Entity Set Expansion](https://doi.org/10.1145/3627673.3679837)|Shulin Huang, Shirong Ma, Yangning Li, Yinghui Li, HaiTao Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Retrieval+to+Generation:+Efficient+and+Effective+Entity+Set+Expansion)|0|
|[RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs](https://doi.org/10.1145/3627673.3679659)|Yubo Huang, Guosun Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RD-P:+A+Trustworthy+Retrieval-Augmented+Prompter+with+Knowledge+Graphs+for+LLMs)|0|
|[Understanding GNNs for Boolean Satisfiability through Approximation Algorithms](https://doi.org/10.1145/3627673.3679813)|Jan Hula, David Mojzísek, Mikolás Janota||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+GNNs+for+Boolean+Satisfiability+through+Approximation+Algorithms)|0|
|[HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection](https://doi.org/10.1145/3627673.3679797)|Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiQuE:+Hierarchical+Question+Embedding+Network+for+Multimodal+Depression+Detection)|0|
|[Embedding Knowledge Graphs in Function Spaces](https://doi.org/10.1145/3627673.3679819)|Louis Mozart Kamdem Teyou, Caglar Demir, AxelCyrille Ngonga Ngomo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+Knowledge+Graphs+in+Function+Spaces)|0|
|[Federated Deep Equilibrium Learning: Harnessing Compact Global Representations to Enhance Personalization](https://doi.org/10.1145/3627673.3679752)|Long Tan Le, Tuan Dung Nguyen, TungAnh Nguyen, Choong Seon Hong, Suranga Seneviratne, Wei Bao, Nguyen H. Tran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Deep+Equilibrium+Learning:+Harnessing+Compact+Global+Representations+to+Enhance+Personalization)|0|
|[Privacy-preserving Spatial Dataset Search in Cloud](https://doi.org/10.1145/3627673.3679733)|Pengyue Li, Hua Dai, Sheng Wang, Wenzhe Yang, Geng Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-preserving+Spatial+Dataset+Search+in+Cloud)|0|
|[Privacy-Preserving Graph Embedding based on Local Differential Privacy](https://doi.org/10.1145/3627673.3679759)|Zening Li, RongHua Li, Meihao Liao, Fusheng Jin, Guoren Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Graph+Embedding+based+on+Local+Differential+Privacy)|0|
|[On Evaluation Metrics for Diversity-enhanced Recommendations](https://doi.org/10.1145/3627673.3679629)|Xueqi Li, Gao Cong, Guoqing Xiao, Yang Xu, Wenjun Jiang, Kenli Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Evaluation+Metrics+for+Diversity-enhanced+Recommendations)|0|
|[RecDiff: Diffusion Model for Social Recommendation](https://doi.org/10.1145/3627673.3679630)|Zongwei Li, Lianghao Xia, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecDiff:+Diffusion+Model+for+Social+Recommendation)|0|
|[Efficient and Robust Regularized Federated Recommendation](https://doi.org/10.1145/3627673.3679682)|Langming Liu, Wanyu Wang, Xiangyu Zhao, Zijian Zhang, Chunxu Zhang, Shanru Lin, Yiqi Wang, Lixin Zou, Zitao Liu, Xuetao Wei, Hongzhi Yin, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Robust+Regularized+Federated+Recommendation)|0|
|[Two Heads are Better than One: Zero-shot Cognitive Reasoning via Multi-LLM Knowledge Fusion](https://doi.org/10.1145/3627673.3679744)|Liang Liu, Dong Zhang, Shoushan Li, Guodong Zhou, Erik Cambria||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Two+Heads+are+Better+than+One:+Zero-shot+Cognitive+Reasoning+via+Multi-LLM+Knowledge+Fusion)|0|
|[Collaborative Fraud Detection on Large Scale Graph Using Secure Multi-Party Computation](https://doi.org/10.1145/3627673.3679863)|Xin Liu, Xiaoyu Fan, Rong Ma, Kun Chen, Yi Li, Guosai Wang, Wei Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Fraud+Detection+on+Large+Scale+Graph+Using+Secure+Multi-Party+Computation)|0|
|[AlignRec: Aligning and Training in Multimodal Recommendations](https://doi.org/10.1145/3627673.3679626)|Yifan Liu, Kangning Zhang, Xiangyuan Ren, Yanhua Huang, Jiarui Jin, Yingjie Qin, Ruilong Su, Ruiwen Xu, Yong Yu, Weinan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AlignRec:+Aligning+and+Training+in+Multimodal+Recommendations)|0|
|[A Universal Sets-level Optimization Framework for Next Set Recommendation](https://doi.org/10.1145/3627673.3679610)|Yuli Liu, Min Liu, Christian Walder, Lexing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Universal+Sets-level+Optimization+Framework+for+Next+Set+Recommendation)|0|
|[Adversarial Text Rewriting for Text-aware Recommender Systems](https://doi.org/10.1145/3627673.3679592)|Sejoon Oh, Gaurav Verma, Srijan Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Text+Rewriting+for+Text-aware+Recommender+Systems)|0|
|[Towards Completeness-Oriented Tool Retrieval for Large Language Models](https://doi.org/10.1145/3627673.3679847)|Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Completeness-Oriented+Tool+Retrieval+for+Large+Language+Models)|0|
|[No Query Left Behind: Query Refinement via Backtranslation](https://doi.org/10.1145/3627673.3679729)|Delaram Rajaei, Zahra Taheri, Hossein Fani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=No+Query+Left+Behind:+Query+Refinement+via+Backtranslation)|0|
|[Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering](https://doi.org/10.1145/3627673.3679722)|Yucheng Shi, Qiaoyu Tan, Xuansheng Wu, Shaochen Zhong, Kaixiong Zhou, Ninghao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-enhanced+Knowledge+Editing+in+Language+Models+for+Multi-Hop+Question+Answering)|0|
|[Large Language Models Enhanced Collaborative Filtering](https://doi.org/10.1145/3627673.3679558)|Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Kai Zheng, Yang Song, Xiao Zhang, Jun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+Enhanced+Collaborative+Filtering)|0|
|[Natural Language-Assisted Multi-modal Medication Recommendation](https://doi.org/10.1145/3627673.3679529)|Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Natural+Language-Assisted+Multi-modal+Medication+Recommendation)|0|
|[LAMRec: Label-aware Multi-view Drug Recommendation](https://doi.org/10.1145/3627673.3679656)|Yunsen Tang, Ning Liu, Haitao Yuan, Yonghe Yan, Lei Liu, Weixing Tan, Lizhen Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LAMRec:+Label-aware+Multi-view+Drug+Recommendation)|0|
|[Retrieval Augmented Deep Anomaly Detection for Tabular Data](https://doi.org/10.1145/3627673.3679559)|Hugo Thimonier, Fabrice Popineau, Arpad Rimmel, BichLiên Doan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval+Augmented+Deep+Anomaly+Detection+for+Tabular+Data)|0|
|[On Causally Disentangled State Representation Learning for Reinforcement Learning based Recommender Systems](https://doi.org/10.1145/3627673.3679674)|Siyu Wang, Xiaocong Chen, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Causally+Disentangled+State+Representation+Learning+for+Reinforcement+Learning+based+Recommender+Systems)|0|
|[Topology-aware Retrieval Augmentation for Text Generation](https://doi.org/10.1145/3627673.3679746)|Yu Wang, Nedim Lipka, Ruiyi Zhang, Alexa F. Siu, Yuying Zhao, Bo Ni, Xin Wang, Ryan A. Rossi, Tyler Derr||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topology-aware+Retrieval+Augmentation+for+Text+Generation)|0|
|[LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation](https://doi.org/10.1145/3627673.3679743)|Yuhao Wang, Yichao Wang, Zichuan Fu, Xiangyang Li, Wanyu Wang, Yuyang Ye, Xiangyu Zhao, Huifeng Guo, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM4MSR:+An+LLM-Enhanced+Paradigm+for+Multi-Scenario+Recommendation)|0|
|[Time-Sensitve Retrieval-Augmented Generation for Question Answering](https://doi.org/10.1145/3627673.3679800)|Feifan Wu, Lingyuan Liu, Wentao He, Ziqi Liu, Zhiqiang Zhang, Haofen Wang, Meng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-Sensitve+Retrieval-Augmented+Generation+for+Question+Answering)|0|
|[Bridge the Gap between Past and Future: Siamese Model Optimization for Context-Aware Document Ranking](https://doi.org/10.1145/3627673.3679661)|Songhao Wu, Quan Tu, Mingjie Zhong, Hong Liu, Jia Xu, Jinjie Gu, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridge+the+Gap+between+Past+and+Future:+Siamese+Model+Optimization+for+Context-Aware+Document+Ranking)|0|
|[Federated Node Classification over Distributed Ego-Networks with Secure Contrastive Embedding Sharing](https://doi.org/10.1145/3627673.3679834)|Han Xie, Li Xiong, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Node+Classification+over+Distributed+Ego-Networks+with+Secure+Contrastive+Embedding+Sharing)|0|
|[UniMPC: Towards a Unified Framework for Multi-Party Conversations](https://doi.org/10.1145/3627673.3679864)|Yunhe Xie, Chengjie Sun, Yifan Liu, Zhenzhou Ji, Bingquan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniMPC:+Towards+a+Unified+Framework+for+Multi-Party+Conversations)|0|
|[AlignGroup: Learning and Aligning Group Consensus with Member Preferences for Group Recommendation](https://doi.org/10.1145/3627673.3679697)|Jinfeng Xu, Zheyu Chen, Jinze Li, Shuo Yang, Hewei Wang, Edith C. H. Ngai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AlignGroup:+Learning+and+Aligning+Group+Consensus+with+Member+Preferences+for+Group+Recommendation)|0|
|[Shape-aware Graph Spectral Learning](https://doi.org/10.1145/3627673.3679604)|Junjie Xu, Enyan Dai, Dongsheng Luo, Xiang Zhang, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shape-aware+Graph+Spectral+Learning)|0|
|[Topological Anonymous Walk Embedding: A New Structural Node Embedding Approach](https://doi.org/10.1145/3627673.3679565)|Yuchen Yan, Yongyi Hu, Qinghai Zhou, Shurang Wu, Dingsu Wang, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topological+Anonymous+Walk+Embedding:+A+New+Structural+Node+Embedding+Approach)|0|
|[Spectral-Aware Augmentation for Enhanced Graph Representation Learning](https://doi.org/10.1145/3627673.3679762)|Kaiqi Yang, Haoyu Han, Wei Jin, Hui Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spectral-Aware+Augmentation+for+Enhanced+Graph+Representation+Learning)|0|
|[Efficient Pruned Top-K Subgraph Matching with Topology-Aware Bounds](https://doi.org/10.1145/3627673.3679790)|Linglin Yang, Yuqi Zhou, Yue Pang, Lei Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Pruned+Top-K+Subgraph+Matching+with+Topology-Aware+Bounds)|0|
|[A New Framework for Evaluating Faithfulness of Video Moment Retrieval against Multiple Distractors](https://doi.org/10.1145/3627673.3679838)|Nakyeong Yang, Minsung Kim, Seunghyun Yoon, Joongbo Shin, Kyomin Jung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Framework+for+Evaluating+Faithfulness+of+Video+Moment+Retrieval+against+Multiple+Distractors)|0|
|[Attacking Visually-aware Recommender Systems with Transferable and Imperceptible Adversarial Styles](https://doi.org/10.1145/3627673.3679828)|Shiyi Yang, Chen Wang, Xiwei Xu, Liming Zhu, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attacking+Visually-aware+Recommender+Systems+with+Transferable+and+Imperceptible+Adversarial+Styles)|0|
|[A Cause-Focused Query Optimizer Alert System](https://doi.org/10.1145/3627673.3679771)|Runfan Ye, Zibo Liang, Xu Chen, Shuncheng Liu, Kai Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Cause-Focused+Query+Optimizer+Alert+System)|0|
|[DAMe: Personalized Federated Social Event Detection with Dual Aggregation Mechanism](https://doi.org/10.1145/3627673.3679551)|Xiaoyan Yu, Yifan Wei, Pu Li, Shuaishuai Zhou, Hao Peng, Li Sun, Liehuang Zhu, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAMe:+Personalized+Federated+Social+Event+Detection+with+Dual+Aggregation+Mechanism)|0|
|[Transformer Based Bayesian Network Embedding for Efficient Multiple Probabilistic Inferences](https://doi.org/10.1145/3627673.3679860)|Kun Yue, Zhiwei Qi, Liang Duan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transformer+Based+Bayesian+Network+Embedding+for+Efficient+Multiple+Probabilistic+Inferences)|0|
|[Do We Really Need Graph Convolution During Training? Light Post-Training Graph-ODE for Efficient Recommendation](https://doi.org/10.1145/3627673.3679773)|Weizhi Zhang, Liangwei Yang, Zihe Song, Henry Peng Zou, Ke Xu, Liancheng Fang, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+We+Really+Need+Graph+Convolution+During+Training?+Light+Post-Training+Graph-ODE+for+Efficient+Recommendation)|0|
|[ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems](https://doi.org/10.1145/3627673.3679633)|Yi Zhang, Ruihong Qiu, Jiajun Liu, Sen Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ROLeR:+Effective+Reward+Shaping+in+Offline+Reinforcement+Learning+for+Recommender+Systems)|0|
|[Aligning Explanations for Recommendation with Rating and Feature via Maximizing Mutual Information](https://doi.org/10.1145/3627673.3679663)|Yurou Zhao, Yiding Sun, Ruidong Han, Fei Jiang, Lu Guan, Xiang Li, Wei Lin, Weizhi Ma, Jiaxin Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Explanations+for+Recommendation+with+Rating+and+Feature+via+Maximizing+Mutual+Information)|0|
|[Interaction-level Membership Inference Attack against Recommender Systems with Long-tailed Distribution](https://doi.org/10.1145/3627673.3679804)|Da Zhong, Xiuling Wang, Zhichao Xu, Jun Xu, Wendy Hui Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interaction-level+Membership+Inference+Attack+against+Recommender+Systems+with+Long-tailed+Distribution)|0|
|[A Power Method to Alleviate Over-smoothing for Recommendation](https://doi.org/10.1145/3627673.3679553)|Peng Zhou, Yachao Cui, Han Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Power+Method+to+Alleviate+Over-smoothing+for+Recommendation)|0|
|[Not All Negatives are Equally Negative: Soft Contrastive Learning for Unsupervised Sentence Representations](https://doi.org/10.1145/3627673.3679745)|Haojie Zhuang, Wei Emma Zhang, Jian Yang, Weitong Chen, Quan Z. Sheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Negatives+are+Equally+Negative:+Soft+Contrastive+Learning+for+Unsupervised+Sentence+Representations)|0|
|[Professionalism-Aware Pre-Finetuning for Profitability Ranking](https://doi.org/10.1145/3627673.3679981)|ChungChi Chen, Hiroya Takamura, Ichiro Kobayashi, Yusuke Miyao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Professionalism-Aware+Pre-Finetuning+for+Profitability+Ranking)|0|
|[Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching](https://doi.org/10.1145/3627673.3679881)|Yuyang Ding, Hanglei Hu, Jie Zhou, Qin Chen, Bo Jiang, Liang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Large+Language+Models+with+Socratic+Method+for+Conversational+Mathematics+Teaching)|0|
|[Towards Better Utilization of Multiple Views for Bundle Recommendation](https://doi.org/10.1145/3627673.3680003)|Kyungho Kim, Sunwoo Kim, Geon Lee, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Better+Utilization+of+Multiple+Views+for+Bundle+Recommendation)|0|
|[Improving Prompt-based News Recommendation with Individual Template and Customized Answer](https://doi.org/10.1145/3627673.3679945)|Yijiang Li, Jun Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Prompt-based+News+Recommendation+with+Individual+Template+and+Customized+Answer)|0|
|[RecPrompt: A Self-tuning Prompting Framework for News Recommendation Using Large Language Models](https://doi.org/10.1145/3627673.3679987)|Dairui Liu, Boming Yang, Honghui Du, Derek Greene, Neil Hurley, Aonghus Lawlor, Ruihai Dong, Irene Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecPrompt:+A+Self-tuning+Prompting+Framework+for+News+Recommendation+Using+Large+Language+Models)|0|
|[Enhanced Privacy Bound for Shuffle Model with Personalized Privacy](https://doi.org/10.1145/3627673.3679911)|Yixuan Liu, Yuhan Liu, Li Xiong, Yujie Gu, Hong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhanced+Privacy+Bound+for+Shuffle+Model+with+Personalized+Privacy)|0|
|[Channel-Aware Low-Rank Adaptation in Time Series Forecasting](https://doi.org/10.1145/3627673.3679884)|Tong Nie, Yuewen Mei, Guoyang Qin, Jian Sun, Wei Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Channel-Aware+Low-Rank+Adaptation+in+Time+Series+Forecasting)|0|
|[Learning Links for Adaptable and Explainable Retrieval](https://doi.org/10.1145/3627673.3679953)|Jianqiang Shen, Yuchin Juan, Ping Liu, Wen Pu, Shaobo Zhang, Qianqi Shen, Liangjie Hong, Wenjing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Links+for+Adaptable+and+Explainable+Retrieval)|0|
|[Preliminary Study on Incremental Learning for Large Language Model-based Recommender Systems](https://doi.org/10.1145/3627673.3679922)|Tianhao Shi, Yang Zhang, Zhijian Xu, Chong Chen, Fuli Feng, Xiangnan He, Qi Tian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preliminary+Study+on+Incremental+Learning+for+Large+Language+Model-based+Recommender+Systems)|0|
|[ Tabularis Revilio:  Converting Text to Tables](https://doi.org/10.1145/3627673.3680000)|Mukul Singh, Gust Verbruggen, Vu Le, Sumit Gulwani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=+Tabularis+Revilio:++Converting+Text+to+Tables)|0|
|[STAR: Sparse Text Approach for Recommendation](https://doi.org/10.1145/3627673.3679999)|Anna Tigunova, Ghazaleh Haratinezhad Torbati, Andrew Yates, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STAR:+Sparse+Text+Approach+for+Recommendation)|0|
|[Harnessing Empathy and Ethics for Relevance Detection and Information Categorization in Climate and COVID-19 Tweets](https://doi.org/10.1145/3627673.3679937)|Apoorva Upadhyaya, Wolfgang Nejdl, Marco Fisichella||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+Empathy+and+Ethics+for+Relevance+Detection+and+Information+Categorization+in+Climate+and+COVID-19+Tweets)|0|
|[FashionLOGO: Prompting Multimodal Large Language Models for Fashion Logo Embeddings](https://doi.org/10.1145/3627673.3679926)|Zhen Wang, Da Li, Yulin Su, Min Yang, Minghui Qiu, Walton Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FashionLOGO:+Prompting+Multimodal+Large+Language+Models+for+Fashion+Logo+Embeddings)|0|
|[CrossPred: A Cross-City Mobility Prediction Framework for Long-Distance Travelers via POI Feature Matching](https://doi.org/10.1145/3627673.3679893)|Shuai Xu, Donghai Guan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CrossPred:+A+Cross-City+Mobility+Prediction+Framework+for+Long-Distance+Travelers+via+POI+Feature+Matching)|0|
|[Enhancing Content-based Recommendation via Large Language Model](https://doi.org/10.1145/3627673.3679913)|Wentao Xu, Qianqian Xie, Shuo Yang, Jiangxia Cao, Shuchao Pang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Content-based+Recommendation+via+Large+Language+Model)|0|
|[Learn From Mistakes: Guidance on Zero-shot Conversational Text-to-SQL](https://doi.org/10.1145/3627673.3679951)|Wenshuo Zhai, Xiang Zhao, Jinzhi Liao, Ziyang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learn+From+Mistakes:+Guidance+on+Zero-shot+Conversational+Text-to-SQL)|0|
|[Mamba Retriever: Utilizing Mamba for Effective and Efficient Dense Retrieval](https://doi.org/10.1145/3627673.3679959)|Hanqi Zhang, Chong Chen, Lang Mei, Qi Liu, Jiaxin Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mamba+Retriever:+Utilizing+Mamba+for+Effective+and+Efficient+Dense+Retrieval)|0|
|[Generating Cross-model Analytics Workloads Using LLMs](https://doi.org/10.1145/3627673.3679932)|Xiuwen Zheng, Arun Kumar, Amarnath Gupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Cross-model+Analytics+Workloads+Using+LLMs)|0|
|[Deep Journey Hierarchical Attention Networks for Conversion Predictions in Digital Marketing](https://doi.org/10.1145/3627673.3680066)|Girim Ban, Hyeonseok Yun, Banseok Lee, David Sung, Simon S. Woo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Journey+Hierarchical+Attention+Networks+for+Conversion+Predictions+in+Digital+Marketing)|0|
|[LiNR: Model Based Neural Retrieval on GPUs at LinkedIn](https://doi.org/10.1145/3627673.3680091)|Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran, Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, KuangHsuan Lee, Lu Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LiNR:+Model+Based+Neural+Retrieval+on+GPUs+at+LinkedIn)|0|
|[Personalized Video Summarization by Multimodal Video Understanding](https://doi.org/10.1145/3627673.3680011)|Brian Y. Chen, Xiangyuan Zhao, Yingnan Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Video+Summarization+by+Multimodal+Video+Understanding)|0|
|[Blind-Match:  Efficient Homomorphic Encryption-Based 1: N Matching for Privacy-Preserving Biometric Identification](https://doi.org/10.1145/3627673.3680017)|Hyunmin Choi, Jiwon Kim, Chiyoung Song, Simon S. Woo, Hyoungshick Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Blind-Match:++Efficient+Homomorphic+Encryption-Based+1:+N+Matching+for+Privacy-Preserving+Biometric+Identification)|0|
|[Automated Contrastive Learning Strategy Search for Time Series](https://doi.org/10.1145/3627673.3680086)|Baoyu Jing, Yansen Wang, Guoxin Sui, Jing Hong, Jingrui He, Yuqing Yang, Dongsheng Li, Kan Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Contrastive+Learning+Strategy+Search+for+Time+Series)|0|
|[REAPER: Reasoning based Retrieval Planning for Complex RAG Systems](https://doi.org/10.1145/3627673.3680087)|Ashutosh Joshi, Sheikh Muhammad Sarwar, Samarth Varshney, Sreyashi Nag, Shrivats Agrawal, Juhi Naik||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REAPER:+Reasoning+based+Retrieval+Planning+for+Complex+RAG+Systems)|0|
|[RL-ISLAP: A Reinforcement Learning Framework for Industrial-Scale Linear Assignment Problems at Alipay](https://doi.org/10.1145/3627673.3680108)|Hanjie Li, Yue Ning, Yang Bao, Changsheng Li, Boxiao Chen, Xingyu Lu, Ye Yuan, Guoren Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RL-ISLAP:+A+Reinforcement+Learning+Framework+for+Industrial-Scale+Linear+Assignment+Problems+at+Alipay)|0|
|[Explainable and Coherent Complement Recommendation Based on Large Language Models](https://doi.org/10.1145/3627673.3680028)|Zelong Li, Yan Liang, Ming Wang, Sungro Yoon, Jiaying Shi, Xin Shen, Xiang He, Chenwei Zhang, Wenyi Wu, Hanbo Wang, Jin Li, Jim Chan, Yongfeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+and+Coherent+Complement+Recommendation+Based+on+Large+Language+Models)|0|
|[Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning](https://doi.org/10.1145/3627673.3680052)|Hong Liu, Saisai Gong, Yixin Ji, Kaixin Wu, Jia Xu, Jinjie Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+LLM-based+Relevance+Modeling+with+Distribution-Aware+Robust+Learning)|0|
|[A Self-Adaptive Fairness Constraint Framework for Industrial Recommender System](https://doi.org/10.1145/3627673.3680099)|Zhiqiang Liu, Xiaoxiao Xu, Jiaqi Yu, Han Xu, Lantao Hu, Han Li, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Self-Adaptive+Fairness+Constraint+Framework+for+Industrial+Recommender+System)|0|
|[GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices](https://doi.org/10.1145/3627673.3680103)|Thao Nguyen, Tiara TorresFlores, Changhyun Hwang, Carl Edwards, Ying Diao, Heng Ji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GLaD:+Synergizing+Molecular+Graphs+and+Language+Descriptors+for+Enhanced+Power+Conversion+Efficiency+Prediction+in+Organic+Photovoltaic+Devices)|0|
|[Cross-contextual Sequential Optimization via Deep Reinforcement Learning for Algorithmic Trading](https://doi.org/10.1145/3627673.3680101)|Kaiming Pan, Yifan Hu, Li Han, Haoyu Sun, Dawei Cheng, Yuqi Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-contextual+Sequential+Optimization+via+Deep+Reinforcement+Learning+for+Algorithmic+Trading)|0|
|[STIR: Siamese Transformer for Image Retrieval Postprocessing](https://doi.org/10.1145/3627673.3680075)|Aleksei Shabanov, Aleksei Tarasov, Sergey I. Nikolenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STIR:+Siamese+Transformer+for+Image+Retrieval+Postprocessing)|0|
|[Enhancing Taobao Display Advertising with Multimodal Representations: Challenges, Approaches and Insights](https://doi.org/10.1145/3627673.3680068)|XiangRong Sheng, Feifan Yang, Litong Gong, Biao Wang, Zhangming Chan, Yujing Zhang, Yueyao Cheng, YongNan Zhu, Tiezheng Ge, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Taobao+Display+Advertising+with+Multimodal+Representations:+Challenges,+Approaches+and+Insights)|0|
|[LLM-based Automated Web Retrieval and Text Classification of Food Sharing Initiatives](https://doi.org/10.1145/3627673.3680090)|Hao Wu, Hyunji Cho, Anna R. Davies, Gareth J. F. Jones||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-based+Automated+Web+Retrieval+and+Text+Classification+of+Food+Sharing+Initiatives)|0|
|[Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph](https://doi.org/10.1145/3627673.3680022)|Qian Zhao, Hao Qian, Ziqi Liu, GongDuo Zhang, Lihong Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+the+Barrier:+Utilizing+Large+Language+Models+for+Industrial+Recommendation+Systems+through+an+Inferential+Knowledge+Graph)|0|
|[STaR: Space and Time-aware Statistic Query Answering](https://doi.org/10.1145/3627673.3679209)|Oana Balalau, Simon Ebel, Helena Galhardas, Théo Galizzi, Ioana Manolescu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STaR:+Space+and+Time-aware+Statistic+Query+Answering)|0|
|[FairRankTune: A Python Toolkit for Fair Ranking Tasks](https://doi.org/10.1145/3627673.3679238)|Kathleen Cachel, Elke A. Rundensteiner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairRankTune:+A+Python+Toolkit+for+Fair+Ranking+Tasks)|0|
|[LLM-PQA: LLM-enhanced Prediction Query Answering](https://doi.org/10.1145/3627673.3679210)|Ziyu Li, Wenjie Zhao, Asterios Katsifodimos, Rihan Hai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-PQA:+LLM-enhanced+Prediction+Query+Answering)|0|
|[Unified Argument Retrieval System from German News Articles Using Large Language Models](https://doi.org/10.1145/3627673.3679232)|Piriyakorn Piriyatamwong, Saikishore Kalloori, Fabio Zünd||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Argument+Retrieval+System+from+German+News+Articles+Using+Large+Language+Models)|0|
|[Empowering Shoppers with Event-focused Search](https://doi.org/10.1145/3627673.3679235)|Austin R. Ward, Omar Alonso||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Shoppers+with+Event-focused+Search)|0|
|[Multi-turn Classroom Dialogue Dataset: Assessing Student Performance from One-on-one Conversations](https://doi.org/10.1145/3627673.3679108)|Jiahao Chen, Zitao Liu, Mingliang Hou, Xiangyu Zhao, Weiqi Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-turn+Classroom+Dialogue+Dataset:+Assessing+Student+Performance+from+One-on-one+Conversations)|0|
|[An Evaluation Framework for Attributed Information Retrieval using Large Language Models](https://doi.org/10.1145/3627673.3679172)|Hanane Djeddal, Pierre Erbacher, Raouf Toukal, Laure Soulier, Karen PinelSauvagnat, Sophia Katrenko, Lynda Tamine||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Evaluation+Framework+for+Attributed+Information+Retrieval+using+Large+Language+Models)|0|
|[AnnoRank: A Comprehensive Web-Based Framework for Collecting Annotations and Assessing Rankings](https://doi.org/10.1145/3627673.3679174)|Clara Rus, Gabrielle Poerwawinata, Andrew Yates, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AnnoRank:+A+Comprehensive+Web-Based+Framework+for+Collecting+Annotations+and+Assessing+Rankings)|0|
|[Advancing Misinformation Awareness in Recommender Systems for Social Media Information Integrity](https://doi.org/10.1145/3627673.3680259)|Royal Pathak||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Misinformation+Awareness+in+Recommender+Systems+for+Social+Media+Information+Integrity)|0|
|[Multi-Granularity Modeling in Recommendation: from the Multi-Scenario Perspective](https://doi.org/10.1145/3627673.3680264)|Yuhao Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granularity+Modeling+in+Recommendation:+from+the+Multi-Scenario+Perspective)|0|
|[Unifying Spectral and Spatial Graph Neural Networks](https://doi.org/10.1145/3627673.3679088)|Zhiqian Chen, Lei Zhang, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+Spectral+and+Spatial+Graph+Neural+Networks)|0|
|[Tutorial on Landing Generative AI in Industrial Social and E-commerce Recsys](https://doi.org/10.1145/3627673.3679099)|Da Xu, Danqing Zhang, Lingling Zheng, Bo Yang, Guangyu Yang, Shuyuan Xu, Cindy Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tutorial+on+Landing+Generative+AI+in+Industrial+Social+and+E-commerce+Recsys)|0|
|[Reviewerly: Modeling the Reviewer Assignment Task as an Information Retrieval Problem](https://doi.org/10.1145/3627673.3679081)|Negar Arabzadeh, Sajad Ebrahimi, Sara Salamat, Mahdi Bashari, Ebrahim Bagheri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reviewerly:+Modeling+the+Reviewer+Assignment+Task+as+an+Information+Retrieval+Problem)|0|
|[AI-safe Autocompletion with RAG and Relevance Curation](https://doi.org/10.1145/3627673.3679078)|Kilian Merkelbach, Ksenia Riabinova, Arnab Dutta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI-safe+Autocompletion+with+RAG+and+Relevance+Curation)|0|
|[Towards Real-Time and Personalized Code Generation](https://doi.org/10.1145/3627673.3679071)|Han Xu, Xingyuan Wang, Haipeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Real-Time+and+Personalized+Code+Generation)|0|
|[Advertiser Content Understanding via LLMs for Google Ads Safety](https://doi.org/10.1145/3627673.3679077)|Joseph Wallace, Tushar Dogra, Wei Qiao, Yuan Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advertiser+Content+Understanding+via+LLMs+for+Google+Ads+Safety)|0|
|[Generative AI and Retrieval-Augmented Generation (RAG) Systems for Enterprise](https://doi.org/10.1145/3627673.3680117)|Anbang Xu, Tan Yu, Min Du, Pritam Gundecha, Yufan Guo, Xinliang Zhu, May Wang, Ping Li, Xinyun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+and+Retrieval-Augmented+Generation+(RAG)+Systems+for+Enterprise)|0|
|[A Bayesian Multi-Armed Bandit Algorithm for Bid Shading in Online Display Advertising](https://doi.org/10.1145/3627673.3680107)|Mengzhuo Guo, Wuqi Zhang, Congde Yuan, Binfeng Jia, Guoqing Song, Hua Hua, Shuangyang Wang, Qingpeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Bayesian+Multi-Armed+Bandit+Algorithm+for+Bid+Shading+in+Online+Display+Advertising)|0|
|[SGFL-Attack: A Similarity-Guidance Strategy for Hard-Label Textual Adversarial Attack Based on Feedback Learning](https://doi.org/10.1145/3627673.3679639)|Panjia Qiu, Guanghao Zhou, Mingyuan Fan, Cen Chen, Yaliang Li, Wenming Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGFL-Attack:+A+Similarity-Guidance+Strategy+for+Hard-Label+Textual+Adversarial+Attack+Based+on+Feedback+Learning)|0|
|[Factor Model-Based Large Covariance Estimation from Streaming Data Using a Knowledge-Based Sketch Matrix](https://doi.org/10.1145/3627673.3679820)|Xiao Tan, Zhaoyang Wang, Hao Qian, Jun Zhou, Peibo Duan, Dian Shen, Meng Wang, Beilun Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Factor+Model-Based+Large+Covariance+Estimation+from+Streaming+Data+Using+a+Knowledge-Based+Sketch+Matrix)|0|
|[Teach Harder, Learn Poorer: Rethinking Hard Sample Distillation for GNN-to-MLP Knowledge Distillation](https://doi.org/10.1145/3627673.3679586)|Lirong Wu, Yunfan Liu, Haitao Lin, Yufei Huang, Stan Z. Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Teach+Harder,+Learn+Poorer:+Rethinking+Hard+Sample+Distillation+for+GNN-to-MLP+Knowledge+Distillation)|0|
|[Correcting Biases of Shapley Value Attributions for Informative Machine Learning Model Explanations](https://doi.org/10.1145/3627673.3679846)|Ningsheng Zhao, Jia Yuan Yu, Trang Bui, Krzysztof Dzieciolowski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Correcting+Biases+of+Shapley+Value+Attributions+for+Informative+Machine+Learning+Model+Explanations)|0|
|[HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling with Self-Distillation for Long-Term Forecasting](https://doi.org/10.1145/3627673.3679741)|Shubao Zhao, Ming Jin, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Qingsong Wen, Yi Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiMTM:+Hierarchical+Multi-Scale+Masked+Time+Series+Modeling+with+Self-Distillation+for+Long-Term+Forecasting)|0|
|[GLFNet: Global and Local Frequency-domain Network for Long-term Time Series Forecasting](https://doi.org/10.1145/3627673.3679579)|Xucheng Zhou, Yuwen Liu, Lianyong Qi, Xiaolong Xu, Wanchun Dou, Xuyun Zhang, Yang Zhang, Xiaokang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GLFNet:+Global+and+Local+Frequency-domain+Network+for+Long-term+Time+Series+Forecasting)|0|
|[Facets of Disparate Impact: Evaluating Legally Consistent Bias in Machine Learning](https://doi.org/10.1145/3627673.3679925)|Jarren Briscoe, Assefaw H. Gebremedhin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Facets+of+Disparate+Impact:+Evaluating+Legally+Consistent+Bias+in+Machine+Learning)|0|
|[Bubble Sketch: A High-performance and Memory-efficient Sketch for Finding Top-k Items in Data Streams](https://doi.org/10.1145/3627673.3679882)|Lu Cao, Qilong Shi, Yuxi Liu, Hanyue Zheng, Yao Xin, Wenjun Li, Tong Yang, Yangyang Wang, Yang Xu, Weizhe Zhang, Mingwei Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bubble+Sketch:+A+High-performance+and+Memory-efficient+Sketch+for+Finding+Top-k+Items+in+Data+Streams)|0|
|[Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models](https://doi.org/10.1145/3627673.3680025)|JiaHong Huang, ChaoChun Yang, Yixian Shen, Alessio M. Pacces, Evangelos Kanoulas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Numerical+Estimation+and+Operational+Efficiency+in+the+Legal+Domain+through+Large+Language+Models)|0|
|[A Multi-Node Multi-GPU Distributed GNN Training Framework for Large-Scale Online Advertising](https://doi.org/10.1145/3627673.3680018)|Xuewu Jiao, Xinsheng Luo, Miao Li, Jiang Bian, Junchao Yang, Wei Hu, Mingqing Hu, Weipeng Lu, Shikun Feng, Danlei Feng, Dongxu Yang, Haoyi Xiong, Shuanglong Li, Lin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Node+Multi-GPU+Distributed+GNN+Training+Framework+for+Large-Scale+Online+Advertising)|0|
|[3M-Health: Multimodal Multi-Teacher Knowledge Distillation for Mental Health Detection](https://doi.org/10.1145/3627673.3679635)|Rina Carines Cabral, Siwen Luo, Josiah Poon, Soyeon Caren Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3M-Health:+Multimodal+Multi-Teacher+Knowledge+Distillation+for+Mental+Health+Detection)|0|
|[Hypergraph Hash Learning for Efficient Trajectory Similarity Computation](https://doi.org/10.1145/3627673.3679555)|Yuan Cao, Lei Li, Xiangru Chen, Xue Xu, Zuojin Huang, Yanwei Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hypergraph+Hash+Learning+for+Efficient+Trajectory+Similarity+Computation)|0|
|[Towards Online and Safe Configuration Tuning with Semi-supervised Anomaly Detection](https://doi.org/10.1145/3627673.3679700)|Haitian Chen, Xu Chen, Zibo Liang, Xiushi Feng, Jiandong Xie, Han Su, Kai Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Online+and+Safe+Configuration+Tuning+with+Semi-supervised+Anomaly+Detection)|0|
|[Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity](https://doi.org/10.1145/3627673.3679567)|Minxiao Chen, Haitao Yuan, Nan Jiang, Zhifeng Bao, Shangguang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Urban+Traffic+Accident+Risk+Prediction+Revisited:+Regionality,+Proximity,+Similarity+and+Sparsity)|0|
|[Hyperedge Importance Estimation via Identity-aware Hypergraph Attention Network](https://doi.org/10.1145/3627673.3679685)|Yin Chen, Xiaoyang Wang, Chen Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperedge+Importance+Estimation+via+Identity-aware+Hypergraph+Attention+Network)|0|
|[PIXEL: Prompt-based Zero-shot Hashing via Visual and Textual Semantic Alignment](https://doi.org/10.1145/3627673.3679747)|Zeyu Dong, Qingqing Long, Yihang Zhou, Pengfei Wang, Zhihong Zhu, Xiao Luo, Yidong Wang, Pengyang Wang, Yuanchun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIXEL:+Prompt-based+Zero-shot+Hashing+via+Visual+and+Textual+Semantic+Alignment)|0|
|[Progressive Multimodal Pivot Learning: Towards Semantic Discordance Understanding as Humans](https://doi.org/10.1145/3627673.3679524)|Junlin Fang, Wenya Wang, Tianze Luo, Yanyong Huang, Fengmao Lv||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Multimodal+Pivot+Learning:+Towards+Semantic+Discordance+Understanding+as+Humans)|0|
|[Precision Meets Resilience: Cross-Database Generalization with Uncertainty Quantification for Robust Cost Estimation](https://doi.org/10.1145/3627673.3679632)|Shuhuan Fan, Mengshu Hou, Rui Xi, Wenwen Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Precision+Meets+Resilience:+Cross-Database+Generalization+with+Uncertainty+Quantification+for+Robust+Cost+Estimation)|0|
|[ACDM: An Effective and Scalable Active Clustering with Pairwise Constraint](https://doi.org/10.1145/3627673.3679601)|Xun Fu, WenBo Xie, Bin Chen, Tao Deng, Tian Zou, Xin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACDM:+An+Effective+and+Scalable+Active+Clustering+with+Pairwise+Constraint)|0|
|[Compositional and Hierarchical Semantic Learning Model for Hospital Readmission Prediction](https://doi.org/10.1145/3627673.3679814)|Weiting Gao, Xiangyu Gao, Yi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compositional+and+Hierarchical+Semantic+Learning+Model+for+Hospital+Readmission+Prediction)|0|
|[Mitigating Cold-Start Problems in Knowledge Tracing with Large Language Models: An Attribute-aware Approach](https://doi.org/10.1145/3627673.3679664)|Yuxiang Guo, Shuanghong Shen, Qi Liu, Zhenya Huang, Linbo Zhu, Yu Su, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Cold-Start+Problems+in+Knowledge+Tracing+with+Large+Language+Models:+An+Attribute-aware+Approach)|0|
|[HeckmanCD: Exploiting Selection Bias in Cognitive Diagnosis](https://doi.org/10.1145/3627673.3679648)|Dongxuan Han, Qi Liu, Siqi Lei, Shiwei Tong, Wei Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HeckmanCD:+Exploiting+Selection+Bias+in+Cognitive+Diagnosis)|0|
|[Spatio-Temporal Transformer Network with Physical Knowledge Distillation for Weather Forecasting](https://doi.org/10.1145/3627673.3679841)|Jing He, Junzhong Ji, Minglong Lei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Transformer+Network+with+Physical+Knowledge+Distillation+for+Weather+Forecasting)|0|
|[New Localization Frameworks: User-centric Approaches to Source Localization in Real-world Propagation Scenarios](https://doi.org/10.1145/3627673.3679796)|Dongpeng Hou, Yuchen Wang, Chao Gao, Xianghua Li, Zhen Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=New+Localization+Frameworks:+User-centric+Approaches+to+Source+Localization+in+Real-world+Propagation+Scenarios)|0|
|[Physics-guided Active Sample Reweighting for Urban Flow Prediction](https://doi.org/10.1145/3627673.3679738)|Wei Jiang, Tong Chen, Guanhua Ye, Wentao Zhang, Lizhen Cui, Zi Huang, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Physics-guided+Active+Sample+Reweighting+for+Urban+Flow+Prediction)|0|
|[Federated Heterogeneous Contrastive Distillation for Molecular Representation Learning](https://doi.org/10.1145/3627673.3679725)|Jinjia Feng, Zhen Wang, Zhewei Wei, Yaliang Li, Bolin Ding, Hongteng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Heterogeneous+Contrastive+Distillation+for+Molecular+Representation+Learning)|0|
|[Discrepancy-guided Channel Dropout for Domain Generalization](https://doi.org/10.1145/3627673.3679539)|Seonggyeom Kim, Byeongtae Park, Harim Lee, DongKyu Chae||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discrepancy-guided+Channel+Dropout+for+Domain+Generalization)|0|
|[Efficient and Secure Contribution Estimation in Vertical Federated Learning](https://doi.org/10.1145/3627673.3679613)|Juan Li, Rui Deng, Tianzi Zang, Mingqi Kong, Kun Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Secure+Contribution+Estimation+in+Vertical+Federated+Learning)|0|
|[MoTTo: Scalable Motif Counting with Time-aware Topology Constraint for Large-scale Temporal Graphs](https://doi.org/10.1145/3627673.3679694)|Jiantao Li, Jianpeng Qi, Yueling Huang, Lei Cao, Yanwei Yu, Junyu Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoTTo:+Scalable+Motif+Counting+with+Time-aware+Topology+Constraint+for+Large-scale+Temporal+Graphs)|0|
|[LagCNN: A Fast yet Effective Model for Multivariate Long-term Time Series Forecasting](https://doi.org/10.1145/3627673.3679672)|Linsen Li, Chunfei Jian, Feng Wan, Dongdong Geng, Ziquan Fang, Lu Chen, Yunjun Gao, Weihao Jiang, Jiang Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LagCNN:+A+Fast+yet+Effective+Model+for+Multivariate+Long-term+Time+Series+Forecasting)|0|
|[Noise-Resilient Unsupervised Graph Representation Learning via Multi-Hop Feature Quality Estimation](https://doi.org/10.1145/3627673.3679758)|Shiyuan Li, Yixin Liu, Qingfeng Chen, Geoffrey I. Webb, Shirui Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Noise-Resilient+Unsupervised+Graph+Representation+Learning+via+Multi-Hop+Feature+Quality+Estimation)|0|
|[Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL](https://doi.org/10.1145/3627673.3679713)|Yuanyuan Liang, Keren Tan, Tingyu Xie, Wenbiao Tao, Siyuan Wang, Yunshi Lan, Weining Qian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Large+Language+Models+to+a+Domain-specific+Graph+Database+for+NL2GQL)|0|
|[ITIU: Intention Understanding via Interactive Table in Large Language Models](https://doi.org/10.1145/3627673.3679688)|Zenghua Liao, Jinzhi Liao, Xiang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ITIU:+Intention+Understanding+via+Interactive+Table+in+Large+Language+Models)|0|
|[Unveiling Intellectual Property Vulnerabilities of GAN-Based Distributed Machine Learning through Model Extraction Attacks](https://doi.org/10.1145/3627673.3679850)|Mengyao Ma, Shuofeng Liu, M. A. P. Chamikara, Mohan Baruwal Chhetri, Guangdong Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Intellectual+Property+Vulnerabilities+of+GAN-Based+Distributed+Machine+Learning+through+Model+Extraction+Attacks)|0|
|[Semantic Prototypes: Enhancing Transparency without Black Boxes](https://doi.org/10.1145/3627673.3679795)|Orfeas MenisMastromichalakis, Giorgos Filandrianos, Jason Liartis, Edmund Dervakos, Giorgos Stamou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+Prototypes:+Enhancing+Transparency+without+Black+Boxes)|0|
|[Revisiting Optimal Window Aggregation in Data Streams: The Prefix-Sum Approach](https://doi.org/10.1145/3627673.3679573)|José Martinez, Guillaume Raschia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Optimal+Window+Aggregation+in+Data+Streams:+The+Prefix-Sum+Approach)|0|
|[Adaptive Cascading Network for Continual Test-Time Adaptation](https://doi.org/10.1145/3627673.3679801)|Kien X. Nguyen, Fengchun Qiao, Xi Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Cascading+Network+for+Continual+Test-Time+Adaptation)|0|
|[Exploring Robustness of GNN against Universal Injection Attack from a Worst-case Perspective](https://doi.org/10.1145/3627673.3679862)|Dandan Ni, Sheng Zhang, Cong Deng, Han Liu, Gang Chen, Minhao Cheng, Hongyang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Robustness+of+GNN+against+Universal+Injection+Attack+from+a+Worst-case+Perspective)|0|
|[CADIF-OSN: Detecting Cloned Accounts with Missing Profile Attributes on Online Social Networks](https://doi.org/10.1145/3627673.3679761)|Dewei Ning, YongFeng Ge, Hua Wang, Changjun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CADIF-OSN:+Detecting+Cloned+Accounts+with+Missing+Profile+Attributes+on+Online+Social+Networks)|0|
|[Distilling Large Language Models for Text-Attributed Graph Learning](https://doi.org/10.1145/3627673.3679830)|Bo Pan, Zheng Zhang, Yifei Zhang, Yuntong Hu, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Large+Language+Models+for+Text-Attributed+Graph+Learning)|0|
|[Table-Filling via Mean Teacher for Cross-domain Aspect Sentiment Triplet Extraction](https://doi.org/10.1145/3627673.3679543)|Kun Peng, Lei Jiang, Qian Li, Haoran Li, Xiaoyan Yu, Li Sun, Shuo Sun, Yanxian Bi, Hao Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Table-Filling+via+Mean+Teacher+for+Cross-domain+Aspect+Sentiment+Triplet+Extraction)|0|
|[Periormer: Periodic Transformer for Seasonal and Irregularly Sampled Time Series](https://doi.org/10.1145/3627673.3679720)|Xiaobin Ren, Kaiqi Zhao, Katerina Taskova, Patricia Riddle, Lianyan Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Periormer:+Periodic+Transformer+for+Seasonal+and+Irregularly+Sampled+Time+Series)|0|
|[Self-supervised One-Stage Learning for RF-based Multi-Person Pose Estimation](https://doi.org/10.1145/3627673.3679609)|Seunghwan Shin, Yusung Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+One-Stage+Learning+for+RF-based+Multi-Person+Pose+Estimation)|0|
|[DFLStar: A Decentralized Federated Learning Framework with Self-Knowledge Distillation and Participant Selection](https://doi.org/10.1145/3627673.3679853)|Behnaz Soltani, Venus Haghighi, Yipeng Zhou, Quan Z. Sheng, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DFLStar:+A+Decentralized+Federated+Learning+Framework+with+Self-Knowledge+Distillation+and+Participant+Selection)|0|
|[TEXT CAN BE FAIR: Mitigating Popularity Bias with PLMs by Learning Relative Preference](https://doi.org/10.1145/3627673.3679581)|Zuoli Tang, Zhaoxin Huan, Zihao Li, Shirui Hu, Xiaolu Zhang, Jun Zhou, Lixin Zou, Chenliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TEXT+CAN+BE+FAIR:+Mitigating+Popularity+Bias+with+PLMs+by+Learning+Relative+Preference)|0|
|[LTBoost: Boosted Hybrids of Ensemble Linear and Gradient Algorithms for the Long-term Time Series Forecasting](https://doi.org/10.1145/3627673.3679527)|Hubert Truchan, Christian Kalfar, Zahra Ahmadi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LTBoost:+Boosted+Hybrids+of+Ensemble+Linear+and+Gradient+Algorithms+for+the+Long-term+Time+Series+Forecasting)|0|
|[Why Misinformation is Created? Detecting them by Integrating Intent Features](https://doi.org/10.1145/3627673.3679799)|Bing Wang, Ximing Li, Changchun Li, Bo Fu, Songwen Pei, Shengsheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+Misinformation+is+Created?+Detecting+them+by+Integrating+Intent+Features)|0|
|[Bots Shield Fake News: Adversarial Attack on User Engagement based Fake News Detection](https://doi.org/10.1145/3627673.3679583)|Lanjun Wang, Zehao Wang, Le Wu, AnAn Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bots+Shield+Fake+News:+Adversarial+Attack+on+User+Engagement+based+Fake+News+Detection)|0|
|[Learning to Differentiate Pairwise-Argument Representations for Implicit Discourse Relation Recognition](https://doi.org/10.1145/3627673.3679584)|Zhipang Wang, Yu Hong, Yuxiang Lu, Xiabing Zhou, Jianmin Yao, Guodong Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Differentiate+Pairwise-Argument+Representations+for+Implicit+Discourse+Relation+Recognition)|0|
|[Identifying Disinformation from Online Social Media via Dynamic Modeling across Propagation Stages](https://doi.org/10.1145/3627673.3679788)|Shuai Xu, Jianqiu Xu, Shuo Yu, Bohan Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Disinformation+from+Online+Social+Media+via+Dynamic+Modeling+across+Propagation+Stages)|0|
|[SGES: A General and Space-efficient Framework for Graphlet Counting in Graph Streams](https://doi.org/10.1145/3627673.3679739)|Chen Yang, Lailong Luo, Yuliang Lu, Chu Huang, Qianzhen Zhang, Guozheng Yang, Deke Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGES:+A+General+and+Space-efficient+Framework+for+Graphlet+Counting+in+Graph+Streams)|0|
|[Behavior-Aware Hypergraph Convolutional Network for Illegal Parking Prediction with Multi-Source Contextual Information](https://doi.org/10.1145/3627673.3679563)|Guang Yang, Meiqi Tu, Zelong Li, Jinquan Hang, Taichi Liu, Ruofeng Liu, Yi Ding, Yu Yang, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Behavior-Aware+Hypergraph+Convolutional+Network+for+Illegal+Parking+Prediction+with+Multi-Source+Contextual+Information)|0|
|[Distilling Multi-Scale Knowledge for Event Temporal Relation Extraction](https://doi.org/10.1145/3627673.3679520)|HaoRen Yao, Luke Breitfeller, Aakanksha Naik, Chunxiao Zhou, Carolyn P. Rosé||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Multi-Scale+Knowledge+for+Event+Temporal+Relation+Extraction)|0|
|[Debiased Graph Poisoning Attack via Contrastive Surrogate Objective](https://doi.org/10.1145/3627673.3679686)|Kanghoon Yoon, Yeonjun In, Namkyeong Lee, Kibum Kim, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiased+Graph+Poisoning+Attack+via+Contrastive+Surrogate+Objective)|0|
|[Language Models-enhanced Semantic Topology Representation Learning For Temporal Knowledge Graph Extrapolation](https://doi.org/10.1145/3627673.3679602)|Tianli Zhang, Tongya Zheng, Zhenbang Xiao, Zulong Chen, Liangyue Li, Zunlei Feng, Dongxiang Zhang, Mingli Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Language+Models-enhanced+Semantic+Topology+Representation+Learning+For+Temporal+Knowledge+Graph+Extrapolation)|0|
|[SaLa: Scenario-aware Label Graph Interaction for Multi-intent Spoken Language Understanding](https://doi.org/10.1145/3627673.3679676)|Zhihong Zhu, Xuxin Cheng, Zhanpeng Chen, Zhichang Wang, Zhiqi Huang, Yuexian Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SaLa:+Scenario-aware+Label+Graph+Interaction+for+Multi-intent+Spoken+Language+Understanding)|0|
|[Distributed Boosting: An Enhancing Method on Dataset Distillation](https://doi.org/10.1145/3627673.3679897)|Xuechao Chen, Wenchao Meng, Peiran Wang, Qihang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Boosting:+An+Enhancing+Method+on+Dataset+Distillation)|0|
|[The Factuality of Large Language Models in the Legal Domain](https://doi.org/10.1145/3627673.3679961)|Rajaa El Hamdani, Thomas Bonald, Fragkiskos D. Malliaros, Nils Holzenberger, Fabian M. Suchanek||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Factuality+of+Large+Language+Models+in+the+Legal+Domain)|0|
|[Beyond Language Bias: Overcoming Multimodal Shortcut and Distribution Biases for Robust Visual Question Answering](https://doi.org/10.1145/3627673.3679880)|Jingliang Gu, Zhixin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Language+Bias:+Overcoming+Multimodal+Shortcut+and+Distribution+Biases+for+Robust+Visual+Question+Answering)|0|
|[A Contextual Combinatorial Semi-Bandit Approach to Network Bottleneck Identification](https://doi.org/10.1145/3627673.3679867)|Fazeleh Sadat Hoseini, Niklas Åkerblom, Morteza Haghir Chehreghani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Contextual+Combinatorial+Semi-Bandit+Approach+to+Network+Bottleneck+Identification)|0|
|[Nonparametric Estimation of Non-Smooth Divergences](https://doi.org/10.1145/3627673.3679972)|M. Mahbub Hossain, Alan Wisler, Kevin R. Moon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nonparametric+Estimation+of+Non-Smooth+Divergences)|0|
|[LEX-GNN: Label-Exploring Graph Neural Network for Accurate Fraud Detection](https://doi.org/10.1145/3627673.3679956)|Woochang Hyun, Insoo Lee, Bongwon Suh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEX-GNN:+Label-Exploring+Graph+Neural+Network+for+Accurate+Fraud+Detection)|0|
|[GraphVAE: Unveiling Dynamic Stock Relationships with Variational Autoencoder-based Factor Modeling](https://doi.org/10.1145/3627673.3679935)|Yulong Jia, Guanxing Li, Ganlong Zhao, Xiangru Lin, Guanbin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphVAE:+Unveiling+Dynamic+Stock+Relationships+with+Variational+Autoencoder-based+Factor+Modeling)|0|
|[Covariate Ordered Systematic Sampling as an Improvement to Randomized Controlled Trials](https://doi.org/10.1145/3627673.3679892)|Deddy Jobson, Yilin Li, Naoki Nishimura, Koya Ohashi, Jie Yang, Takeshi Matsumoto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Covariate+Ordered+Systematic+Sampling+as+an+Improvement+to+Randomized+Controlled+Trials)|0|
|[Flexi-clique: Exploring Flexible and Sub-linear Clique Structures](https://doi.org/10.1145/3627673.3679927)|Song Kim, Junghoon Kim, Susik Yoon, Jungeun Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flexi-clique:+Exploring+Flexible+and+Sub-linear+Clique+Structures)|0|
|[Intricate Object Detection in Self Driving Environments with Edge-Adaptive Depth Estimation(EADE)](https://doi.org/10.1145/3627673.3679948)|SuBi Kim, Jieun Kang, Yongik Yoon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intricate+Object+Detection+in+Self+Driving+Environments+with+Edge-Adaptive+Depth+Estimation(EADE))|0|
|[Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models](https://doi.org/10.1145/3627673.3679973)|Zhe Li, Ronghui Xu, Jilin Hu, Zhong Peng, Xi Lu, Chenjuan Guo, Bin Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ocean+Significant+Wave+Height+Estimation+with+Spatio-temporally+Aware+Large+Language+Models)|0|
|[The Elusiveness of Detecting Political Bias in Language Models](https://doi.org/10.1145/3627673.3680002)|Riccardo Lunardi, David La Barbera, Kevin Roitero||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Elusiveness+of+Detecting+Political+Bias+in+Language+Models)|0|
|[ILTS: Inducing Intention Propagation in Decentralized Multi-Agent Tasks with Large Language Models](https://doi.org/10.1145/3627673.3679942)|Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ILTS:+Inducing+Intention+Propagation+in+Decentralized+Multi-Agent+Tasks+with+Large+Language+Models)|0|
|[Automation of Text-Based Economic Indicator Construction: A Pilot Exploration on Economic Policy Uncertainty Index](https://doi.org/10.1145/3627673.3679877)|HsiuHsuan Yeh, YuLieh Huang, Ziho Park, ChungChi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automation+of+Text-Based+Economic+Indicator+Construction:+A+Pilot+Exploration+on+Economic+Policy+Uncertainty+Index)|0|
|[Prioritized Binary Transformation Method for Efficient Multi-label Classification of Data Streams with Many Labels](https://doi.org/10.1145/3627673.3679980)|Onur Yildirim, Sepehr Bakhshi, Fazli Can||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prioritized+Binary+Transformation+Method+for+Efficient+Multi-label+Classification+of+Data+Streams+with+Many+Labels)|0|
|[Forecasting Live Chat Intent from Browsing History](https://doi.org/10.1145/3627673.3679928)|Seeun Yoon, Ahmad Bin Rabiah, Zaid Alibadi, Surya Kallumadi, Julian J. McAuley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forecasting+Live+Chat+Intent+from+Browsing+History)|0|
|[XRDMamba: Large-scale Crystal Material Space Group Identification with Selective State Space Model](https://doi.org/10.1145/3627673.3680006)|Liheng Yu, Pengkun Wang, Zhe Zhao, Zhongchao Yi, Sun Nan, Di Wu, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XRDMamba:+Large-scale+Crystal+Material+Space+Group+Identification+with+Selective+State+Space+Model)|0|
|[Long-Term Hydrologic Time Series Prediction with LSPM](https://doi.org/10.1145/3627673.3679957)|Sicheng Zhou, David C. Anastasiu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long-Term+Hydrologic+Time+Series+Prediction+with+LSPM)|0|
|[Boosting Entity Recognition by leveraging Cross-task Domain Models for Weak Supervision](https://doi.org/10.1145/3627673.3680009)|Sanjay Agrawal, Srujana Merugu, Vivek Sembium||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Entity+Recognition+by+leveraging+Cross-task+Domain+Models+for+Weak+Supervision)|0|
|[PlayBest: Professional Basketball Player Behavior Synthesis via Planning with Diffusion](https://doi.org/10.1145/3627673.3680092)|Xiusi Chen, WeiYao Wang, Ziniu Hu, David Reynoso, Kun Jin, Mingyan Liu, P. Jeffrey Brantingham, Wei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PlayBest:+Professional+Basketball+Player+Behavior+Synthesis+via+Planning+with+Diffusion)|0|
|[GraphScale: A Framework to Enable Machine Learning over Billion-node Graphs](https://doi.org/10.1145/3627673.3680021)|Vipul Gupta, Xin Chen, Ruoyun Huang, Fanlong Meng, Jianjun Chen, Yujun Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphScale:+A+Framework+to+Enable+Machine+Learning+over+Billion-node+Graphs)|0|
|[Cryptocurrency Price Forecasting using Variational Autoencoder with Versatile Quantile Modeling](https://doi.org/10.1145/3627673.3680027)|Sungchul Hong, SeungHwan An, JongJune Jeon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cryptocurrency+Price+Forecasting+using+Variational+Autoencoder+with+Versatile+Quantile+Modeling)|0|
|[DAMOCRO: A Data Migration Framework Using Online Classification and Reordering](https://doi.org/10.1145/3627673.3680097)|Zhongxin Hu, Kaiyu Li, Xingjian Mao, Jingfeng Pan, Yunfei Peng, Aijun An, Xiaohui Yu, Dariusz Jania||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAMOCRO:+A+Data+Migration+Framework+Using+Online+Classification+and+Reordering)|0|
|[XCapsUTL: Cross-domain Unsupervised Transfer Learning Framework using a Capsule Neural Network](https://doi.org/10.1145/3627673.3680053)|Naman Khetan, Sanyog Dewani, Gokul Swamy, Vikalp Gajbhiye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XCapsUTL:+Cross-domain+Unsupervised+Transfer+Learning+Framework+using+a+Capsule+Neural+Network)|0|
|[EFfECT-RL: Enabling Framework for Establishing Causality and Triggering engagement through RL](https://doi.org/10.1145/3627673.3680058)|Debanjan Sadhukhan, Deepanshi Seth, Sanjay Agrawal, Tridib Mukherjee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFfECT-RL:+Enabling+Framework+for+Establishing+Causality+and+Triggering+engagement+through+RL)|0|
|[CPFD: Confidence-aware Privileged Feature Distillation for Short Video Classification](https://doi.org/10.1145/3627673.3680045)|Jinghao Shi, Xiang Shen, Kaili Zhao, Xuedong Wang, Vera Wen, Zixuan Wang, Yifan Wu, Zhixin Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CPFD:+Confidence-aware+Privileged+Feature+Distillation+for+Short+Video+Classification)|0|
|[Dynamic Graph-based Deep Reinforcement Learning with Long and Short-term Relation Modeling for Portfolio Optimization](https://doi.org/10.1145/3627673.3680039)|Haoyu Sun, Yuxuan Bian, Li Han, Peng Zhu, Dawei Cheng, Yuqi Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Graph-based+Deep+Reinforcement+Learning+with+Long+and+Short-term+Relation+Modeling+for+Portfolio+Optimization)|0|
|[Behavior-aware Sparse Trajectory Recovery in Last-mile Delivery with Multi-scale Attention Fusion](https://doi.org/10.1145/3627673.3680079)|Hai Wang, Shuai Wang, Li Lin, Yu Yang, Shuai Wang, Hongkai Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Behavior-aware+Sparse+Trajectory+Recovery+in+Last-mile+Delivery+with+Multi-scale+Attention+Fusion)|0|
|[CourIRL: Predicting Couriers' Behavior in Last-Mile Delivery Using Crossed-Attention Inverse Reinforcement Learning](https://doi.org/10.1145/3627673.3680046)|Shuai Wang, Tongtong Kong, Baoshen Guo, Li Lin, Haotian Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CourIRL:+Predicting+Couriers'+Behavior+in+Last-Mile+Delivery+Using+Crossed-Attention+Inverse+Reinforcement+Learning)|0|
|[Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting](https://doi.org/10.1145/3627673.3680072)|Shiyu Wang, Zhixuan Chu, Yinbo Sun, Yu Liu, Yuliang Guo, Yang Chen, Huiyang Jian, Lintao Ma, Xingyu Lu, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiscale+Representation+Enhanced+Temporal+Flow+Fusion+Model+for+Long-Term+Workload+Forecasting)|0|
|[Revolutionizing Biomarker Discovery: Leveraging Generative AI for Bio-Knowledge-Embedded Continuous Space Exploration](https://doi.org/10.1145/3627673.3680041)|Wangyang Ying, Dongjie Wang, Xuanming Hu, Ji Qiu, Jin Park, Yanjie Fu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revolutionizing+Biomarker+Discovery:+Leveraging+Generative+AI+for+Bio-Knowledge-Embedded+Continuous+Space+Exploration)|0|
|[A Behavior-aware Cause Identification Framework for Order Cancellation in Logistics Service](https://doi.org/10.1145/3627673.3680051)|Shuxin Zhong, Yahan Gu, Wenjun Lyu, Hongyu Lin, Guang Yang, Yao Lu, Guang Wang, Yu Yang, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Behavior-aware+Cause+Identification+Framework+for+Order+Cancellation+in+Logistics+Service)|0|
|[LSR-IGRU: Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU](https://doi.org/10.1145/3627673.3680012)|Peng Zhu, Yuante Li, Yifan Hu, Qinyuan Liu, Dawei Cheng, Yuqi Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LSR-IGRU:+Stock+Trend+Prediction+Based+on+Long+Short-Term+Relationships+and+Improved+GRU)|0|
|[RevEx: An Online Consumer Reviews Extraction Tool](https://doi.org/10.1145/3627673.3679214)|Julián Alarte, Carlos Galindo, Carlos Martín, Josep Silva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RevEx:+An+Online+Consumer+Reviews+Extraction+Tool)|0|
|[Introducing CausalBench: A Flexible Benchmark Framework for Causal Analysis and Machine Learning](https://doi.org/10.1145/3627673.3679218)|Ahmet Kapkiç, Pratanu Mandal, Shu Wan, Paras Sheth, Abhinav Gorantla, Yoonhyuk Choi, Huan Liu, K. Selçuk Candan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Introducing+CausalBench:+A+Flexible+Benchmark+Framework+for+Causal+Analysis+and+Machine+Learning)|0|
|[Multi-Graph Explorer: A Framework for Advanced Multi-Graph Analysis and Method Development](https://doi.org/10.1145/3627673.3679213)|Yorgos Tsitsikas, Evangelos E. Papalexakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Graph+Explorer:+A+Framework+for+Advanced+Multi-Graph+Analysis+and+Method+Development)|0|
|[GongBu: Easily Fine-tuning LLMs for Domain-specific Adaptation](https://doi.org/10.1145/3627673.3679233)|Bolin Zhang, Yimin Tian, Shengwei Wang, Zhiying Tu, Dianhui Chu, Zhiqi Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GongBu:+Easily+Fine-tuning+LLMs+for+Domain-specific+Adaptation)|0|
|[Covid19-twitter: A Twitter-based Dataset for Discourse Analysis in Sentence-level Sentiment Classification](https://doi.org/10.1145/3627673.3679120)|Shashank Gupta, Mohamed Reda Bouadjenek, Antonio RoblesKelly, TszKwan Lee, Thanh Thi Nguyen, Asef Nazari, Dhananjay R. Thiruvady||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Covid19-twitter:+A+Twitter-based+Dataset+for+Discourse+Analysis+in+Sentence-level+Sentiment+Classification)|0|
|[CH-Mits: A Cross-Modal Dataset for User Sentiment Analysis on Chinese Social Media](https://doi.org/10.1145/3627673.3679125)|Juhao Ma, Shuai Xu, Yilin Liu, Xiaoming Fu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CH-Mits:+A+Cross-Modal+Dataset+for+User+Sentiment+Analysis+on+Chinese+Social+Media)|0|
|[The Veracity Problem: Detecting False Information and its Propagation on Online Social Media Networks](https://doi.org/10.1145/3627673.3680265)|Sarah Condran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Veracity+Problem:+Detecting+False+Information+and+its+Propagation+on+Online+Social+Media+Networks)|0|
|[Evaluating Social Media Reach via Mainstream Media Discourse](https://doi.org/10.1145/3627673.3680260)|Himarsha R. Jayanetti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+Social+Media+Reach+via+Mainstream+Media+Discourse)|0|
|[PTM-Mamba: A PTM-Aware Protein Language Model with Bidirectional Gated Mamba Blocks](https://doi.org/10.1145/3627673.3680276)|Zhangzhi Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PTM-Mamba:+A+PTM-Aware+Protein+Language+Model+with+Bidirectional+Gated+Mamba+Blocks)|0|
|[Towards Making Effective Machine Learning Decisions Against Out-of-Distribution Data](https://doi.org/10.1145/3627673.3680272)|Lakpa Dorje Tamang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Making+Effective+Machine+Learning+Decisions+Against+Out-of-Distribution+Data)|0|
|[The 'Path' to Clarity: Identifying False Claims Through a Knowledge Graph Exploration](https://doi.org/10.1145/3627673.3680262)|Wenbo Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+'Path'+to+Clarity:+Identifying+False+Claims+Through+a+Knowledge+Graph+Exploration)|0|
|[Hands-On Introduction to Quantum Machine Learning](https://doi.org/10.1145/3627673.3679103)|Samuel YenChi Chen, Joongheon Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hands-On+Introduction+to+Quantum+Machine+Learning)|0|
|[Data Quality-aware Graph Machine Learning](https://doi.org/10.1145/3627673.3679095)|Yu Wang, Kaize Ding, Xiaorui Liu, Jian Kang, Ryan A. Rossi, Tyler Derr||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Quality-aware+Graph+Machine+Learning)|0|
|[Systems for Scalable Graph Analytics and Machine Learning: Trends and Methods](https://doi.org/10.1145/3627673.3679101)|Da Yan, Lyuheng Yuan, Akhlaque Ahmad, Saugat Adhikari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Systems+for+Scalable+Graph+Analytics+and+Machine+Learning:+Trends+and+Methods)|0|
|[Neural Additive Tensor Decomposition for Sparse Tensors](https://doi.org/10.1145/3627673.3679833)|Dawon Ahn, Uday Singh Saini, Evangelos E. Papalexakis, Ali Payani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Additive+Tensor+Decomposition+for+Sparse+Tensors)|0|
|[A Geometric Perspective for High-Dimensional Multiplex Graphs](https://doi.org/10.1145/3627673.3679541)|Kamel Abdous, Nairouz Mrabah, Mohamed Bouguessa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Geometric+Perspective+for+High-Dimensional+Multiplex+Graphs)|0|
|[Ensembles for Outlier Detection and Evaluation](https://doi.org/10.1145/3627673.3679060)|Charu C. Aggarwal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ensembles+for+Outlier+Detection+and+Evaluation)|0|
|[Out-of-Distribution Aware Classification for Tabular Data](https://doi.org/10.1145/3627673.3679755)|Amirhossein Ansari, Ke Wang, Pulei Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Out-of-Distribution+Aware+Classification+for+Tabular+Data)|0|
|[Spatio-temporal Graph Normalizing Flow for Probabilistic Traffic Prediction](https://doi.org/10.1145/3627673.3679705)|Yang An, Zhibin Li, Wei Liu, Haoliang Sun, Meng Chen, Wenpeng Lu, Yongshun Gong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-temporal+Graph+Normalizing+Flow+for+Probabilistic+Traffic+Prediction)|0|
|[Can LLMs Reason Like Humans? Assessing Theory of Mind Reasoning in LLMs for Open-Ended Questions](https://doi.org/10.1145/3627673.3679832)|Maryam Amirizaniani, Elias Martin, Maryna Sivachenko, Afra Mashhadi, Chirag Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+LLMs+Reason+Like+Humans?+Assessing+Theory+of+Mind+Reasoning+in+LLMs+for+Open-Ended+Questions)|0|
|[Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models](https://doi.org/10.1145/3627673.3679783)|Avinash Anand, Ashwin R. Nair, Kritarth Prasad, Vrinda Narayan, Naman Lal, Debanjan Mahata, Yaman Singla, Rajiv Ratn Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advances+in+Citation+Text+Generation:+Leveraging+Multi-Source+Seq2Seq+Models+and+Large+Language+Models)|0|
|[City Foundation Models for Learning General Purpose Representations from OpenStreetMap](https://doi.org/10.1145/3627673.3679662)|Pasquale Balsebre, Weiming Huang, Gao Cong, Yi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=City+Foundation+Models+for+Learning+General+Purpose+Representations+from+OpenStreetMap)|0|
|[A Learning-based Approach for Explaining Language Models](https://doi.org/10.1145/3627673.3679548)|Oren Barkan, Yonatan Toib, Yehonatan Elisha, Noam Koenigstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Learning-based+Approach+for+Explaining+Language+Models)|0|
|[Discovering Denial Constraints Based on Deep Reinforcement Learning](https://doi.org/10.1145/3627673.3679714)|Lingfeng Bian, Weidong Yang, Jingyi Xu, Zijing Tan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Denial+Constraints+Based+on+Deep+Reinforcement+Learning)|0|
|[Covering a Graph with Dense Subgraph Families, via Triangle-Rich Sets](https://doi.org/10.1145/3627673.3679578)|Sabyasachi Basu, Daniel PaulPena, Kun Qian, C. Seshadhri, Edward W. Huang, Karthik Subbian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Covering+a+Graph+with+Dense+Subgraph+Families,+via+Triangle-Rich+Sets)|0|
|[Hierarchical Graph Latent Diffusion Model for Conditional Molecule Generation](https://doi.org/10.1145/3627673.3679547)|Tian Bian, Yifan Niu, Heng Chang, Divin Yan, Junzhou Huang, Yu Rong, Tingyang Xu, Jia Li, Hong Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Graph+Latent+Diffusion+Model+for+Conditional+Molecule+Generation)|0|
|[Finding MIDDLE Ground: Scalable and Secure Distributed Learning](https://doi.org/10.1145/3627673.3679587)|Marco Bornstein, Nawaf Nazir, Ján Drgona, Soumya Kundu, Veronica Adetola||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Finding+MIDDLE+Ground:+Scalable+and+Secure+Distributed+Learning)|0|
|[MATCC: A Novel Approach for Robust Stock Price Prediction Incorporating Market Trends and Cross-time Correlations](https://doi.org/10.1145/3627673.3679715)|Zhiyuan Cao, Jiayu Xu, Chengqi Dong, Peiwen Yu, Tian Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MATCC:+A+Novel+Approach+for+Robust+Stock+Price+Prediction+Incorporating+Market+Trends+and+Cross-time+Correlations)|0|
|[DiHAN: A Novel Dynamic Hierarchical Graph Attention Network for Fake News Detection](https://doi.org/10.1145/3627673.3679675)|YaTing Chang, Zhibo Hu, Xiaoyu Li, Shuiqiao Yang, Jiaojiao Jiang, Nan Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiHAN:+A+Novel+Dynamic+Hierarchical+Graph+Attention+Network+for+Fake+News+Detection)|0|
|[Improving Message-Passing GNNs by Asynchronous Aggregation](https://doi.org/10.1145/3627673.3679778)|Jialong Chen, Tianchi Liao, Chuan Chen, Zibin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Message-Passing+GNNs+by+Asynchronous+Aggregation)|0|
|[ERASE: Error-Resilient Representation Learning on Graphs for Label Noise Tolerance](https://doi.org/10.1145/3627673.3679552)|LingHao Chen, Yuanshuo Zhang, Taohua Huang, Liangcai Su, Zeyi Lin, Xi Xiao, Xiaobo Xia, Tongliang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ERASE:+Error-Resilient+Representation+Learning+on+Graphs+for+Label+Noise+Tolerance)|0|
|[Assessing Image Inpainting via Re-Inpainting Self-Consistency Evaluation](https://doi.org/10.1145/3627673.3679693)|Tianyi Chen, Jianfu Zhang, Yan Hong, Yiyi Zhang, Liqing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Image+Inpainting+via+Re-Inpainting+Self-Consistency+Evaluation)|0|
|[DTFormer: A Transformer-Based Method for Discrete-Time Dynamic Graph Representation Learning](https://doi.org/10.1145/3627673.3679568)|Xi Chen, Yun Xiong, Siwei Zhang, Jiawei Zhang, Yao Zhang, Shiyang Zhou, Xixi Wu, Mingyang Zhang, Tengfei Liu, Weiqiang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DTFormer:+A+Transformer-Based+Method+for+Discrete-Time+Dynamic+Graph+Representation+Learning)|0|
|[Honest-Majority Maliciously Secure Skyline Queries on Outsourced Data](https://doi.org/10.1145/3627673.3679666)|Yu Chen, Lin Liu, Rongmao Chen, Shaojing Fu, Yuexiang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Honest-Majority+Maliciously+Secure+Skyline+Queries+on+Outsourced+Data)|0|
|[SVIPTR: Fast and Efficient Scene Text Recognition with Vision Permutable Extractor](https://doi.org/10.1145/3627673.3679618)|Xianfu Cheng, Weixiao Zhou, Xiang Li, Jian Yang, Hang Zhang, Tao Sun, Wei Zhang, Yuying Mai, Tongliang Li, Xiaoming Chen, Zhoujun Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SVIPTR:+Fast+and+Efficient+Scene+Text+Recognition+with+Vision+Permutable+Extractor)|0|
|[TESSM: Tree-based Selective State Space Models for Efficient Join Order Selection Learning](https://doi.org/10.1145/3627673.3679742)|Yaohui Chu, Yizhe Liu, Yue Zhang, Xuan Hou, Longfei Yu, Zhaohui Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TESSM:+Tree-based+Selective+State+Space+Models+for+Efficient+Join+Order+Selection+Learning)|0|
|[Automatic Large Language Model Evaluation via Peer Review](https://doi.org/10.1145/3627673.3679677)|Zhumin Chu, Qingyao Ai, Yiteng Tu, Haitao Li, Yiqun Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Large+Language+Model+Evaluation+via+Peer+Review)|0|
|[Empowering Private Tutoring by Chaining Large Language Models](https://doi.org/10.1145/3627673.3679665)|Yulin Chen, Ning Ding, HaiTao Zheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Private+Tutoring+by+Chaining+Large+Language+Models)|0|
|[Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models](https://doi.org/10.1145/3627673.3679844)|Hyunseung Chung, Sumin Jo, Yeonsu Kwon, Edward Choi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time+is+Not+Enough:+Time-Frequency+based+Explanation+for+Time-Series+Black-Box+Models)|0|
|[PROSPECT: Learn MLPs on Graphs Robust against Adversarial Structure Attacks](https://doi.org/10.1145/3627673.3679857)|Bowen Deng, Jialong Chen, Yanming Hu, Zhiyong Xu, Chuan Chen, Tao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PROSPECT:+Learn+MLPs+on+Graphs+Robust+against+Adversarial+Structure+Attacks)|0|
|[ByGCN: Spatial Temporal Byroad-Aware Graph Convolution Network for Traffic Flow Prediction in Road Networks](https://doi.org/10.1145/3627673.3679690)|Tangpeng Dan, Xiao Pan, Bolong Zheng, Xiaofeng Meng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ByGCN:+Spatial+Temporal+Byroad-Aware+Graph+Convolution+Network+for+Traffic+Flow+Prediction+in+Road+Networks)|0|
|[ALDF: An Adaptive Logical Decision Framework for Multimodal Named Entity Recognition](https://doi.org/10.1145/3627673.3679706)|Guohui Ding, Tianhao Jiang, Rui Zhou, Qian Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ALDF:+An+Adaptive+Logical+Decision+Framework+for+Multimodal+Named+Entity+Recognition)|0|
|[DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting](https://doi.org/10.1145/3627673.3679724)|Ruixin Ding, Yuqi Chen, YuTing Lan, Wei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DRFormer:+Multi-Scale+Transformer+Utilizing+Diverse+Receptive+Fields+for+Long+Time-Series+Forecasting)|0|
|[Effective Illicit Account Detection on Large Cryptocurrency MultiGraphs](https://doi.org/10.1145/3627673.3679707)|Zhihao Ding, Jieming Shi, Qing Li, Jiannong Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Illicit+Account+Detection+on+Large+Cryptocurrency+MultiGraphs)|0|
|[SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection](https://doi.org/10.1145/3627673.3679710)|Zhihao Ding, Jieming Shi, Shiqi Shen, Xuequn Shang, Jiannong Cao, Zhipeng Wang, Zhi Gong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGOOD:+Substructure-enhanced+Graph-Level+Out-of-Distribution+Detection)|0|
|[Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble](https://doi.org/10.1145/3627673.3679748)|Chang George Dong, Zhengyang David Li, Liangwei Nathan Zheng, Weitong Chen, Wei Emma Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Certificate+Robustness+for+Time+Series+Classification+with+Efficient+Self-Ensemble)|0|
|[FZR: Enhancing Knowledge Transfer via Shared Factors Composition in Zero-Shot Relational Learning](https://doi.org/10.1145/3627673.3679770)|Zhijun Dong, Likang Wu, Kai Zhang, Ye Liu, Yanghai Zhang, Zhi Li, Hongke Zhao, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FZR:+Enhancing+Knowledge+Transfer+via+Shared+Factors+Composition+in+Zero-Shot+Relational+Learning)|0|
|[Explainable Stock Price Movement Prediction using Contrastive Learning](https://doi.org/10.1145/3627673.3679544)|Kelvin Du, Rui Mao, Frank Xing, Erik Cambria||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Stock+Price+Movement+Prediction+using+Contrastive+Learning)|0|
|[Towards Uncertainty Quantification for Time Series Segmentation](https://doi.org/10.1145/3627673.3679652)|Erick Draayer, Huiping Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Uncertainty+Quantification+for+Time+Series+Segmentation)|0|
|[iMIRACLE: An Iterative Multi-View Graph Neural Network to Model Intercellular Gene Regulation From Spatial Transcriptomic Data](https://doi.org/10.1145/3627673.3679574)|Ziheng Duan, Siwei Xu, Cheyu Lee, Dylan Riffle, Jing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iMIRACLE:+An+Iterative+Multi-View+Graph+Neural+Network+to+Model+Intercellular+Gene+Regulation+From+Spatial+Transcriptomic+Data)|0|
|[Low Carbon Footprint Training for 1D-CNNs with Temporal Max-Pooling](https://doi.org/10.1145/3627673.3679678)|Anandharaju Durai Raju, Ke Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low+Carbon+Footprint+Training+for+1D-CNNs+with+Temporal+Max-Pooling)|0|
|[Integrating Fair Representation Learning with Fairness Regularization for Intersectional Group Fairness](https://doi.org/10.1145/3627673.3679802)|David Quashigah Dzakpasu, Jixue Liu, Jiuyong Li, Lin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Fair+Representation+Learning+with+Fairness+Regularization+for+Intersectional+Group+Fairness)|0|
|[Probabilistic Path Integration with Mixture of Baseline Distributions](https://doi.org/10.1145/3627673.3679641)|Yehonatan Elisha, Oren Barkan, Noam Koenigstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Probabilistic+Path+Integration+with+Mixture+of+Baseline+Distributions)|0|
|[A Spatio-Temporal Diffusion Model for Missing and Real-Time Financial Data Inference](https://doi.org/10.1145/3627673.3679806)|Yupeng Fang, Ruirui Liu, Huichou Huang, Peilin Zhao, Qingyao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Spatio-Temporal+Diffusion+Model+for+Missing+and+Real-Time+Financial+Data+Inference)|0|
|[PARs: Predicate-based Association Rules for Efficient and Accurate Anomaly Explanation](https://doi.org/10.1145/3627673.3679625)|Cheng Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PARs:+Predicate-based+Association+Rules+for+Efficient+and+Accurate+Anomaly+Explanation)|0|
|[SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model](https://doi.org/10.1145/3627673.3679760)|Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SINKT:+A+Structure-Aware+Inductive+Knowledge+Tracing+Model+with+Large+Language+Model)|0|
|[Graph Local Homophily Network for Anomaly Detection](https://doi.org/10.1145/3627673.3679785)|Ronghui Guo, Minghui Zou, Sai Zhang, Xiaowang Zhang, Zhizhi Yu, Zhiyong Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Local+Homophily+Network+for+Anomaly+Detection)|0|
|[Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge Graphs](https://doi.org/10.1145/3627673.3679845)|Saiping Guan, Jiyao Wei, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Look+Globally+and+Reason:+Two-stage+Path+Reasoning+over+Sparse+Knowledge+Graphs)|0|
|[Tiled Bit Networks: Sub-Bit Neural Network Compression Through Reuse of Learnable Binary Vectors](https://doi.org/10.1145/3627673.3679603)|Matt Gorbett, Hossein Shirazi, Indrakshi Ray||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tiled+Bit+Networks:+Sub-Bit+Neural+Network+Compression+Through+Reuse+of+Learnable+Binary+Vectors)|0|
|[MSTEM: Masked Spatiotemporal Event Series Modeling for Urban Undisciplined Events Forecasting](https://doi.org/10.1145/3627673.3679810)|Zehao Gu, Shiyang Zhou, Yun Xiong, Yang Luo, Hongrun Ren, Qiang Wang, Xiaofeng Gao, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSTEM:+Masked+Spatiotemporal+Event+Series+Modeling+for+Urban+Undisciplined+Events+Forecasting)|0|
|[Multi-Modal Sarcasm Detection via Graph Convolutional Network and Dynamic Network](https://doi.org/10.1145/3627673.3679703)|Jiaqi Hao, Junfeng Zhao, Zhigang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Modal+Sarcasm+Detection+via+Graph+Convolutional+Network+and+Dynamic+Network)|0|
|[On the Sensitivity of Individual Fairness: Measures and Robust Algorithms](https://doi.org/10.1145/3627673.3679721)|Xinyu He, Jian Kang, Ruizhong Qiu, Fei Wang, Jose Sepulveda, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Sensitivity+of+Individual+Fairness:+Measures+and+Robust+Algorithms)|0|
|[NC2D: Novel Class Discovery for Node Classification](https://doi.org/10.1145/3627673.3679779)|Yue Hou, Xueyuan Chen, He Zhu, Ruomei Liu, Bowen Shi, Jiaheng Liu, Junran Wu, Ke Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NC2D:+Novel+Class+Discovery+for+Node+Classification)|0|
|[Accurate Neural Network Option Pricing Methods with Control Variate Techniques and Data Synthesis/Cleaning with Financial Rationality](https://doi.org/10.1145/3627673.3679530)|ChiaWei Hsu, TianShyr Dai, ChuanJu Wang, YingPing Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accurate+Neural+Network+Option+Pricing+Methods+with+Control+Variate+Techniques+and+Data+Synthesis/Cleaning+with+Financial+Rationality)|0|
|[PIECE: Protagonist Identification and Event Chronology Extraction for Enhanced Timeline Summarization](https://doi.org/10.1145/3627673.3679723)|TzHuan Hsu, LiHsuan Chin, YenHao Huang, YiShin Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIECE:+Protagonist+Identification+and+Event+Chronology+Extraction+for+Enhanced+Timeline+Summarization)|0|
|[Prompt-Based Spatio-Temporal Graph Transfer Learning](https://doi.org/10.1145/3627673.3679554)|Junfeng Hu, Xu Liu, Zhencheng Fan, Yifang Yin, Shili Xiang, Savitha Ramasamy, Roger Zimmermann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-Based+Spatio-Temporal+Graph+Transfer+Learning)|0|
|[APTNESS: Incorporating Appraisal Theory and Emotion Support Strategies for Empathetic Response Generation](https://doi.org/10.1145/3627673.3679687)|Yuxuan Hu, Minghuan Tan, Chenwei Zhang, Zixuan Li, Xiaodan Liang, Min Yang, Chengming Li, Xiping Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=APTNESS:+Incorporating+Appraisal+Theory+and+Emotion+Support+Strategies+for+Empathetic+Response+Generation)|0|
|[A Payment Transaction Pre-training Model for Fraud Transaction Detection](https://doi.org/10.1145/3627673.3679670)|Wenxi Huang, Zhangyi Zhao, Xiaojun Chen, Qin Zhang, Mark Junjie Li, Hanjing Su, Qingyao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Payment+Transaction+Pre-training+Model+for+Fraud+Transaction+Detection)|0|
|[Fast and Accurate PARAFAC2 Decomposition for Time Range Queries on Irregular Tensors](https://doi.org/10.1145/3627673.3679735)|JunGi Jang, Yongchan Park, U Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+and+Accurate+PARAFAC2+Decomposition+for+Time+Range+Queries+on+Irregular+Tensors)|0|
|[HiLite: Hierarchical Level-implemented Architecture Attaining Part-Whole Interpretability](https://doi.org/10.1145/3627673.3679538)|Yoo Hyun Jeong, Sunghyun Hwang, DongKyu Chae||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiLite:+Hierarchical+Level-implemented+Architecture+Attaining+Part-Whole+Interpretability)|0|
|[GameTrail: Probabilistic Lifecycle Process Model for Deep Game Understanding](https://doi.org/10.1145/3627673.3679736)|Shanyang Jiang, Lan Zhang, Hui Xu, Jiahui Huang, Qi He, Xing Zhou, Lei Huang, Jie Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GameTrail:+Probabilistic+Lifecycle+Process+Model+for+Deep+Game+Understanding)|0|
|[Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation](https://doi.org/10.1145/3627673.3679642)|Baoyu Jing, Dawei Zhou, Kan Ren, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality-Aware+Spatiotemporal+Graph+Neural+Networks+for+Spatiotemporal+Time+Series+Imputation)|0|
|[Tackling Noisy Clients in Federated Learning with End-to-end Label Correction](https://doi.org/10.1145/3627673.3679550)|Xuefeng Jiang, Sheng Sun, Jia Li, Jingjing Xue, Runhan Li, Zhiyuan Wu, Gang Xu, Yuwei Wang, Min Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tackling+Noisy+Clients+in+Federated+Learning+with+End-to-end+Label+Correction)|0|
|[Effectively Capturing Label Correlation for Tabular Multi-Label Classification](https://doi.org/10.1145/3627673.3679772)|Sajjad Kamali Siahroudi, Zahra Ahmadi, Daniel Kudenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effectively+Capturing+Label+Correlation+for+Tabular+Multi-Label+Classification)|0|
|[Transformer for Point Anomaly Detection](https://doi.org/10.1145/3627673.3679859)|Harim Kim, Chang Ha Lee, Charmgil Hong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transformer+for+Point+Anomaly+Detection)|0|
|[PolarDSN: An Inductive Approach to Learning the Evolution of Network Polarization in Dynamic Signed Networks](https://doi.org/10.1145/3627673.3679654)|MinJeong Kim, YeonChang Lee, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PolarDSN:+An+Inductive+Approach+to+Learning+the+Evolution+of+Network+Polarization+in+Dynamic+Signed+Networks)|0|
|[Enhancing Anomaly Detection via Generating Diversified and Hard-to-distinguish Synthetic Anomalies](https://doi.org/10.1145/3627673.3679623)|Hyuntae Kim, Changhee Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Anomaly+Detection+via+Generating+Diversified+and+Hard-to-distinguish+Synthetic+Anomalies)|0|
|[FaDE: A Face Segment Driven Identity Anonymization Framework For Fair Face Recognition](https://doi.org/10.1145/3627673.3679737)|Ziyi Kou, Yijun Tian, Meng Jiang, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FaDE:+A+Face+Segment+Driven+Identity+Anonymization+Framework+For+Fair+Face+Recognition)|0|
|[Vision Language Model is NOT All You Need: Augmentation Strategies for Molecule Language Models](https://doi.org/10.1145/3627673.3679607)|Namkyeong Lee, Siddhartha Laghuvarapu, Chanyoung Park, Jimeng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Vision+Language+Model+is+NOT+All+You+Need:+Augmentation+Strategies+for+Molecule+Language+Models)|0|
|[FastSimiFeat: A Fast and Generalized Approach Utilizing k-NN for Noisy Data Handling](https://doi.org/10.1145/3627673.3679591)|Jungi Lee, Hwiwoo Park, Myounghwan Kim, Jiseong Yoon, Kwangsun Yoo, SeokJoo Byun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FastSimiFeat:+A+Fast+and+Generalized+Approach+Utilizing+k-NN+for+Noisy+Data+Handling)|0|
|[Learning Fair Invariant Representations under Covariate and Correlation Shifts Simultaneously](https://doi.org/10.1145/3627673.3679727)|Dong Li, Chen Zhao, Minglai Shao, Wenjun Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Fair+Invariant+Representations+under+Covariate+and+Correlation+Shifts+Simultaneously)|0|
|[Dynamic Neural Control Flow Execution: an Agent-Based Deep Equilibrium Approach for Binary Vulnerability Detection](https://doi.org/10.1145/3627673.3679726)|Li Tao Li, Steven H. H. Ding, Andrew Walenstein, Philippe Charland, Benjamin C. M. Fung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Neural+Control+Flow+Execution:+an+Agent-Based+Deep+Equilibrium+Approach+for+Binary+Vulnerability+Detection)|0|
|[Integrating Structure and Text for Enhancing Hyper-relational Knowledge Graph Representation via Structure Soft Prompt Tuning](https://doi.org/10.1145/3627673.3679698)|Lijie Li, Hui Wang, Jiahang Li, Xiaodi Xu, Ye Wang, Tao Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Structure+and+Text+for+Enhancing+Hyper-relational+Knowledge+Graph+Representation+via+Structure+Soft+Prompt+Tuning)|0|
|[Seeing the Forest for the Trees: Road-Level Insights Assisted Lane-Level Traffic Prediction](https://doi.org/10.1145/3627673.3679600)|Shuhao Li, Yue Cui, Jingyi Xu, Jing Zhao, Fan Zhang, Weidong Yang, Xiaofang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Seeing+the+Forest+for+the+Trees:+Road-Level+Insights+Assisted+Lane-Level+Traffic+Prediction)|0|
|[LLM-Empowered Few-Shot Node Classification on Incomplete Graphs with Real Node Degrees](https://doi.org/10.1145/3627673.3679861)|Yun Li, Yi Yang, Jiaqi Zhu, Hui Chen, Hongan Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-Empowered+Few-Shot+Node+Classification+on+Incomplete+Graphs+with+Real+Node+Degrees)|0|
|[Design Element Aware Poster Layout Generation](https://doi.org/10.1145/3627673.3679557)|Yinan Li, Jia Chen, Yin Bai, Jia Cheng, Jun Lei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Design+Element+Aware+Poster+Layout+Generation)|0|
|[Learning from Novel Knowledge: Continual Few-shot Knowledge Graph Completion](https://doi.org/10.1145/3627673.3679734)|Zhuofeng Li, Haoxiang Zhang, Qiannan Zhang, Ziyi Kou, Shichao Pei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+from+Novel+Knowledge:+Continual+Few-shot+Knowledge+Graph+Completion)|0|
|[Higher-order Spatio-temporal Physics-incorporated Graph Neural Network for Multivariate Time Series Imputation](https://doi.org/10.1145/3627673.3679775)|Guojun Liang, Prayag Tiwari, Slawomir Nowaczyk, Stefan Byttner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Higher-order+Spatio-temporal+Physics-incorporated+Graph+Neural+Network+for+Multivariate+Time+Series+Imputation)|0|
|[Towards Robust Vision Transformer via Masked Adaptive Ensemble](https://doi.org/10.1145/3627673.3679750)|Fudong Lin, Jiadong Lou, Xu Yuan, NianFeng Tzeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Robust+Vision+Transformer+via+Masked+Adaptive+Ensemble)|0|
|[Hierarchical Spatio-Temporal Graph Learning Based on Metapath Aggregation for Emergency Supply Forecasting](https://doi.org/10.1145/3627673.3679854)|Li Lin, Kaiwen Xia, Anqi Zheng, Shijie Hu, Shuai Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Spatio-Temporal+Graph+Learning+Based+on+Metapath+Aggregation+for+Emergency+Supply+Forecasting)|0|
|[Self-Supervision Improves Diffusion Models for Tabular Data Imputation](https://doi.org/10.1145/3627673.3679829)|Yixin Liu, Thalaiyasingam Ajanthan, Hisham Husain, Vu Nguyen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervision+Improves+Diffusion+Models+for+Tabular+Data+Imputation)|0|
|[KMCT: k-Means Clustering of Trajectories Efficiently in Location-Based Services](https://doi.org/10.1145/3627673.3679848)|Yuanjun Liu, Guanfeng Liu, Qingzhi Ma, Zhixu Li, Shiting Wen, Lei Zhao, An Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KMCT:+k-Means+Clustering+of+Trajectories+Efficiently+in+Location-Based+Services)|0|
|[A Universal and Interpretable Method for Enhancing Stock Price Prediction](https://doi.org/10.1145/3627673.3679731)|Yuchen Liu, Shimin Di, Lei Chen, Xiaofang Zhou, Fei Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Universal+and+Interpretable+Method+for+Enhancing+Stock+Price+Prediction)|0|
|[Multivariate Time-Series Anomaly Detection based on Enhancing Graph Attention Networks with Topological Analysis](https://doi.org/10.1145/3627673.3679614)|Zhe Liu, Xiang Huang, Jingyun Zhang, Zhifeng Hao, Li Sun, Hao Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multivariate+Time-Series+Anomaly+Detection+based+on+Enhancing+Graph+Attention+Networks+with+Topological+Analysis)|0|
|[MOAT: Graph Prompting for 3D Molecular Graphs](https://doi.org/10.1145/3627673.3679628)|Qingqing Long, Yuchen Yan, Wentao Cui, Wei Ju, Zhihong Zhu, Yuanchun Zhou, Xuezhi Wang, Meng Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MOAT:+Graph+Prompting+for+3D+Molecular+Graphs)|0|
|[A Knowledge-Enhanced Transformer-FL Method for Fault Root Cause Localization](https://doi.org/10.1145/3627673.3679816)|Zhe Lv, Yaqiong Liu, Xidian Wang, Peng Gao, Zhouyuan Li, Yuanzhen Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Knowledge-Enhanced+Transformer-FL+Method+for+Fault+Root+Cause+Localization)|0|
|[Hierarchical Structure Construction on Hypergraphs](https://doi.org/10.1145/3627673.3679765)|Qi Luo, Wenjie Zhang, Zhengyi Yang, Dong Wen, Xiaoyang Wang, Dongxiao Yu, Xuemin Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Structure+Construction+on+Hypergraphs)|0|
|[Data Void Exploits: Tracking & Mitigation Strategies](https://doi.org/10.1145/3627673.3679781)|Miro Mannino, Junior Garcia, Reem Hazim, Azza Abouzied, Paolo Papotti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Void+Exploits:+Tracking+&+Mitigation+Strategies)|0|
|[PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning](https://doi.org/10.1145/3627673.3679794)|Muhammad Anwar Ma'sum, Mahardhika Pratama, Savitha Ramasamy, Lin Liu, Habibullah Habibullah, Ryszard Kowalczyk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIP:+Prototypes-Injected+Prompt+for+Federated+Class+Incremental+Learning)|0|
|[Link Polarity Prediction from Sparse and Noisy Labels via Multiscale Social Balance](https://doi.org/10.1145/3627673.3679786)|Marco Minici, Federico Cinus, Francesco Bonchi, Giuseppe Manco||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Link+Polarity+Prediction+from+Sparse+and+Noisy+Labels+via+Multiscale+Social+Balance)|0|
|[LLaVA-Chef: A Multi-modal Generative Model for Food Recipes](https://doi.org/10.1145/3627673.3679562)|Fnu Mohbat, Mohammed J. Zaki||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLaVA-Chef:+A+Multi-modal+Generative+Model+for+Food+Recipes)|0|
|[Let Silence Speak: Enhancing Fake News Detection with Generated Comments from Large Language Models](https://doi.org/10.1145/3627673.3679519)|Qiong Nan, Qiang Sheng, Juan Cao, Beizhe Hu, Danding Wang, Jintao Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Let+Silence+Speak:+Enhancing+Fake+News+Detection+with+Generated+Comments+from+Large+Language+Models)|0|
|[Saliency Detection in Educational Videos: Analyzing the Performance of Current Models, Identifying Limitations and Advancement Directions](https://doi.org/10.1145/3627673.3679825)|Evelyn Navarrete, Ralph Ewerth, Anett Hoppe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Saliency+Detection+in+Educational+Videos:+Analyzing+the+Performance+of+Current+Models,+Identifying+Limitations+and+Advancement+Directions)|0|
|[Towards Fair Graph Anomaly Detection: Problem, Benchmark Datasets, and Evaluation](https://doi.org/10.1145/3627673.3679754)|Neng Kai Nigel Neo, YeonChang Lee, Yiqiao Jin, SangWook Kim, Srijan Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Graph+Anomaly+Detection:+Problem,+Benchmark+Datasets,+and+Evaluation)|0|
|[Cultural Commonsense Knowledge for Intercultural Dialogues](https://doi.org/10.1145/3627673.3679768)|TuanPhong Nguyen, Simon Razniewski, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cultural+Commonsense+Knowledge+for+Intercultural+Dialogues)|0|
|[Reviving the Context: Camera Trap Species Classification as Link Prediction on Multimodal Knowledge Graphs](https://doi.org/10.1145/3627673.3679545)|Vardaan Pahuja, Weidi Luo, Yu Gu, ChengHao Tu, HongYou Chen, Tanya Y. BergerWolf, Charles V. Stewart, Song Gao, WeiLun Chao, Yu Su||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reviving+the+Context:+Camera+Trap+Species+Classification+as+Link+Prediction+on+Multimodal+Knowledge+Graphs)|0|
|[The Impact of External Sources on the Friedkin-Johnsen Model](https://doi.org/10.1145/3627673.3679780)|Charlotte Out, Sijing Tu, Stefan Neumann, Ahad N. Zehmakan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Impact+of+External+Sources+on+the+Friedkin-Johnsen+Model)|0|
|[Novelty-aware Graph Traversal and Expansion for Hierarchical Reinforcement Learning](https://doi.org/10.1145/3627673.3679523)|Jongchan Park, Seungjun Oh, Yusung Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Novelty-aware+Graph+Traversal+and+Expansion+for+Hierarchical+Reinforcement+Learning)|0|
|[Exploiting Pre-trained Models for Drug Target Affinity Prediction with Nearest Neighbors](https://doi.org/10.1145/3627673.3679704)|Qizhi Pei, Lijun Wu, Zhenyu He, Jinhua Zhu, Yingce Xia, Shufang Xie, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Pre-trained+Models+for+Drug+Target+Affinity+Prediction+with+Nearest+Neighbors)|0|
|[Towards Deconfounded Visual Question Answering via Dual-causal Intervention](https://doi.org/10.1145/3627673.3679594)|Daowan Peng, Wei Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Deconfounded+Visual+Question+Answering+via+Dual-causal+Intervention)|0|
|[Beyond Over-smoothing: Uncovering the Trainability Challenges in Deep Graph Neural Networks](https://doi.org/10.1145/3627673.3679776)|Jie Peng, Runlin Lei, Zhewei Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Over-smoothing:+Uncovering+the+Trainability+Challenges+in+Deep+Graph+Neural+Networks)|0|
|[Bi-directional Learning of Logical Rules with Type Constraints for Knowledge Graph Completion](https://doi.org/10.1145/3627673.3679695)|Kunxun Qi, Jianfeng Du, Hai Wan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bi-directional+Learning+of+Logical+Rules+with+Type+Constraints+for+Knowledge+Graph+Completion)|0|
|[UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models](https://doi.org/10.1145/3627673.3679793)|Qi Liu, Yongyi He, Tong Xu, Defu Lian, Che Liu, Zhi Zheng, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniMEL:+A+Unified+Framework+for+Multimodal+Entity+Linking+with+Large+Language+Models)|0|
|[PISeL: Pipelining DNN Inference for Serverless Computing](https://doi.org/10.1145/3627673.3679824)|Masoud Rahimi Jafari, Jianchang Su, Yifan Zhang, Oliver Wang, Wei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PISeL:+Pipelining+DNN+Inference+for+Serverless+Computing)|0|
|[SmartHash: Perceptual Hashing for Image Tampering Detection and Authentication](https://doi.org/10.1145/3627673.3679827)|Priyanka Samanta, Shweta Jain||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SmartHash:+Perceptual+Hashing+for+Image+Tampering+Detection+and+Authentication)|0|
|[Mining Path Association Rules in Large Property Graphs](https://doi.org/10.1145/3627673.3679525)|Yuya Sasaki, Panagiotis Karras||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Path+Association+Rules+in+Large+Property+Graphs)|0|
|[Leveraging Trustworthy Node Attributes for Effective Network Alignment](https://doi.org/10.1145/3627673.3679658)|DongHyuk Seo, JaeHwan Lim, WonYong Shin, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Trustworthy+Node+Attributes+for+Effective+Network+Alignment)|0|
|[Structural Representation Learning and Disentanglement for Evidential Chinese Patent Approval Prediction](https://doi.org/10.1145/3627673.3679766)|Jinzhi Shan, Qi Zhang, Chongyang Shi, Mengting Gui, Shoujin Wang, Usman Naseem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structural+Representation+Learning+and+Disentanglement+for+Evidential+Chinese+Patent+Approval+Prediction)|0|
|[Fast Human Action Recognition via Millimeter Wave Radar Point Cloud Sequences Learning](https://doi.org/10.1145/3627673.3679787)|Tongfei Shao, Zheyu Du, Chuanyou Li, Tianxing Wu, Meng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Human+Action+Recognition+via+Millimeter+Wave+Radar+Point+Cloud+Sequences+Learning)|0|
|[Robust Federated Unlearning](https://doi.org/10.1145/3627673.3679817)|Xinyi Sheng, Wei Bao, Liming Ge||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Federated+Unlearning)|0|
|[AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction](https://doi.org/10.1145/3627673.3679791)|Yuchen Shi, Guochao Jiang, Tian Qiu, Deqing Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AgentRE:+An+Agent-Based+Framework+for+Navigating+Complex+Information+Landscapes+in+Relation+Extraction)|0|
|[Discovering Graph Generating Dependencies for Property Graph Profiling](https://doi.org/10.1145/3627673.3679764)|Larissa Capobianco Shimomura, Nikolay Yakovets, George Fletcher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Graph+Generating+Dependencies+for+Property+Graph+Profiling)|0|
|[XCrowd: Combining Explainability and Crowdsourcing to Diagnose Models in Relation Extraction](https://doi.org/10.1145/3627673.3679777)|Alisa Smirnova, Jie Yang, Philippe CudréMauroux||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XCrowd:+Combining+Explainability+and+Crowdsourcing+to+Diagnose+Models+in+Relation+Extraction)|0|
|[HTFabric: A Fast Re-ordering and Parallel Re-execution Method for a High-Throughput Blockchain](https://doi.org/10.1145/3627673.3679606)|Jaeyub Song, Juyeong Jeong, Jemin Lee, Inju Na, MinSoo Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HTFabric:+A+Fast+Re-ordering+and+Parallel+Re-execution+Method+for+a+High-Throughput+Blockchain)|0|
|[How Much Do Prompting Methods Help LLMs on Quantitative Reasoning with Irrelevant Information?](https://doi.org/10.1145/3627673.3679840)|Seok Hwan Song, Wallapak Tavanapong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Much+Do+Prompting+Methods+Help+LLMs+on+Quantitative+Reasoning+with+Irrelevant+Information?)|0|
|[Breaking the Bottleneck on Graphs with Structured State Spaces](https://doi.org/10.1145/3627673.3679866)|Yunchong Song, Siyuan Huang, Jiacheng Cai, Xinbing Wang, Chenghu Zhou, Zhouhan Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+the+Bottleneck+on+Graphs+with+Structured+State+Spaces)|0|
|[A Learning-path based Supervised Method for Concept Prerequisite Relations Extraction in Educational Data](https://doi.org/10.1145/3627673.3679597)|Jingwen Sun, Yu He, Yiyu Xu, Jingwei Sun, Guangzhong Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Learning-path+based+Supervised+Method+for+Concept+Prerequisite+Relations+Extraction+in+Educational+Data)|0|
|[Multimodal Misinformation Detection using Large Vision-Language Models](https://doi.org/10.1145/3627673.3679826)|Sahar Tahmasebi, Eric MüllerBudack, Ralph Ewerth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Misinformation+Detection+using+Large+Vision-Language+Models)|0|
|[EasyST: A Simple Framework for Spatio-Temporal Prediction](https://doi.org/10.1145/3627673.3679749)|Jiabin Tang, Wei Wei, Lianghao Xia, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EasyST:+A+Simple+Framework+for+Spatio-Temporal+Prediction)|0|
|[GAS-Norm: Score-Driven Adaptive Normalization for Non-Stationary Time Series Forecasting in Deep Learning](https://doi.org/10.1145/3627673.3679822)|Edoardo Urettini, Daniele Atzeni, Reshawn Ramjattan, Antonio Carta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAS-Norm:+Score-Driven+Adaptive+Normalization+for+Non-Stationary+Time+Series+Forecasting+in+Deep+Learning)|0|
|[Causal Probing for Dual Encoders](https://doi.org/10.1145/3627673.3679556)|Jonas Wallat, Hauke Hinrichs, Avishek Anand||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Probing+for+Dual+Encoders)|0|
|[HC-GST: Heterophily-aware Distribution Consistency based Graph Self-training](https://doi.org/10.1145/3627673.3679622)|Fali Wang, Tianxiang Zhao, Junjie Xu, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HC-GST:+Heterophily-aware+Distribution+Consistency+based+Graph+Self-training)|0|
|[MMPolymer: A Multimodal Multitask Pretraining Framework for Polymer Property Prediction](https://doi.org/10.1145/3627673.3679684)|Fanmeng Wang, Wentao Guo, Minjie Cheng, Shen Yuan, Hongteng Xu, Zhifeng Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMPolymer:+A+Multimodal+Multitask+Pretraining+Framework+for+Polymer+Property+Prediction)|0|
|[Trojan Activation Attack: Red-Teaming Large Language Models using Steering Vectors for Safety-Alignment](https://doi.org/10.1145/3627673.3679821)|Haoran Wang, Kai Shu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trojan+Activation+Attack:+Red-Teaming+Large+Language+Models+using+Steering+Vectors+for+Safety-Alignment)|0|
|[MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction](https://doi.org/10.1145/3627673.3679653)|Mengyu Wang, Tiejun Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MANA-Net:+Mitigating+Aggregated+Sentiment+Homogenization+with+News+Weighting+for+Enhanced+Market+Prediction)|0|
|[DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning](https://doi.org/10.1145/3627673.3679645)|Yingying Wang, Yun Xiong, Xixi Wu, Xiangguo Sun, Jiawei Zhang, Guangyong Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DDIPrompt:+Drug-Drug+Interaction+Event+Prediction+based+on+Graph+Prompt+Learning)|0|
|[Inferring Information Diffusion Networks without Timestamps](https://doi.org/10.1145/3627673.3679798)|Yuchen Wang, Dongpeng Hou, Chao Gao, Xianghua Li, Zhen Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inferring+Information+Diffusion+Networks+without+Timestamps)|0|
|[A Mixed-Curvature Graph Diffusion Model](https://doi.org/10.1145/3627673.3679708)|Yujie Wang, Shuo Zhang, Junda Ye, Hao Peng, Li Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Mixed-Curvature+Graph+Diffusion+Model)|0|
|[GAD: A Generalized Framework for Anomaly Detection at Different Risk Levels](https://doi.org/10.1145/3627673.3679634)|Rulan Wei, Zewei He, Martin Pavlovski, Fang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAD:+A+Generalized+Framework+for+Anomaly+Detection+at+Different+Risk+Levels)|0|
|[OptDist: Learning Optimal Distribution for Customer Lifetime Value Prediction](https://doi.org/10.1145/3627673.3679712)|Yunpeng Weng, Xing Tang, Zhenhao Xu, Fuyuan Lyu, Dugang Liu, Zexu Sun, Xiuqiang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OptDist:+Learning+Optimal+Distribution+for+Customer+Lifetime+Value+Prediction)|0|
|[Identifying Contemporaneous and Lagged Dependence Structures by Promoting Sparsity in Continuous-time Neural Networks](https://doi.org/10.1145/3627673.3679751)|Fan Wu, Woojin Cho, David Korotky, Sanghyun Hong, Donsub Rim, Noseong Park, Kookjin Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Contemporaneous+and+Lagged+Dependence+Structures+by+Promoting+Sparsity+in+Continuous-time+Neural+Networks)|0|
|[StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast](https://doi.org/10.1145/3627673.3679732)|Yu Yvonne Wu, Ting Dang, Dimitris Spathis, Hong Jia, Cecilia Mascolo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=StatioCL:+Contrastive+Learning+for+Time+Series+via+Non-Stationary+and+Temporal+Contrast)|0|
|[Advancing Certified Robustness of Explanation via Gradient Quantization](https://doi.org/10.1145/3627673.3679650)|Yang Xiao, Zijie Zhang, Yuchen Fang, Da Yan, Yang Zhou, WeiShinn Ku, Bo Hui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Certified+Robustness+of+Explanation+via+Gradient+Quantization)|0|
|[GetCom: An Efficient and Generalizable Framework for Community Detection](https://doi.org/10.1145/3627673.3679865)|Kaiyu Xiong, Yucheng Jin, Yun Xiong, Jiawei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GetCom:+An+Efficient+and+Generalizable+Framework+for+Community+Detection)|0|
|[Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models](https://doi.org/10.1145/3627673.3679673)|Derong Xu, Ziheng Zhang, Zhihong Zhu, Zhenxi Lin, Qidong Liu, Xian Wu, Tong Xu, Wanyu Wang, Yuyang Ye, Xiangyu Zhao, Enhong Chen, Yefeng Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Editing+Factual+Knowledge+and+Explanatory+Ability+of+Medical+Large+Language+Models)|0|
|[Contrasformer: A Brain Network Contrastive Transformer for Neurodegenerative Condition Identification](https://doi.org/10.1145/3627673.3679560)|Jiaxing Xu, Kai He, Mengcheng Lan, Qingtian Bian, Wei Li, Tieying Li, Yiping Ke, Miao Qiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrasformer:+A+Brain+Network+Contrastive+Transformer+for+Neurodegenerative+Condition+Identification)|0|
|[scACT: Accurate Cross-modality Translation via Cycle-consistent Training from Unpaired Single-cell Data](https://doi.org/10.1145/3627673.3679576)|Siwei Xu, Junhao Liu, Jing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=scACT:+Accurate+Cross-modality+Translation+via+Cycle-consistent+Training+from+Unpaired+Single-cell+Data)|0|
|[Source Prompt: Coordinated Pre-training of Language Models on Diverse Corpora from Multiple Sources](https://doi.org/10.1145/3627673.3679835)|Yipei Xu, Dakuan Lu, Jiaqing Liang, Jin Zhao, Xintao Wang, Hengkui Wu, Ken Chen, Liujiang Liu, Yingsi Xin, Xuepeng Liu, Yanghua Xiao, Zhixu Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Source+Prompt:+Coordinated+Pre-training+of+Language+Models+on+Diverse+Corpora+from+Multiple+Sources)|0|
|[CLR2G: Cross modal Contrastive Learning on Radiology Report Generation](https://doi.org/10.1145/3627673.3679668)|Hongchen Xue, Qingzhi Ma, Guanfeng Liu, Jianfeng Qu, Yuanjun Liu, An Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLR2G:+Cross+modal+Contrastive+Learning+on+Radiology+Report+Generation)|0|
|[Enhancing the Completeness of Rationales for Multi-Step Question Answering](https://doi.org/10.1145/3627673.3679660)|Shangzi Xue, Zhenya Huang, Xin Lin, Jiayu Liu, Longhu Qin, Tianhuang Su, Haifeng Liu, Qi Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+the+Completeness+of+Rationales+for+Multi-Step+Question+Answering)|0|
|[Predicting Scientific Impact Through Diffusion, Conformity, and Contribution Disentanglement](https://doi.org/10.1145/3627673.3679546)|Zhikai Xue, Guoxiu He, Zhuoren Jiang, Sichen Gu, Yangyang Kang, Star Zhao, Wei Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Scientific+Impact+Through+Diffusion,+Conformity,+and+Contribution+Disentanglement)|0|
|[Buffalo: Biomedical Vision-Language Understanding with Cross-Modal Prototype and Federated Foundation Model Collaboration](https://doi.org/10.1145/3627673.3679627)|Bingjie Yan, Qian Chen, Yiqiang Chen, Xinlong Jiang, Wuliang Huang, Bingyu Wang, Zhirui Wang, Chenlong Gao, Teng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Buffalo:+Biomedical+Vision-Language+Understanding+with+Cross-Modal+Prototype+and+Federated+Foundation+Model+Collaboration)|0|
|[ST-ECP: A Novel Spatial-Temporal Framework for Energy Consumption Prediction of Vehicle Trajectory](https://doi.org/10.1145/3627673.3679807)|Biao Yang, Yun Xiong, Xi Chen, Xuejing Feng, Meng Wang, Jun Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ST-ECP:+A+Novel+Spatial-Temporal+Framework+for+Energy+Consumption+Prediction+of+Vehicle+Trajectory)|0|
|[MalLight: Influence-Aware Coordinated Traffic Signal Control for Traffic Signal Malfunctions](https://doi.org/10.1145/3627673.3679605)|Qinchen Yang, Zejun Xie, Hua Wei, Desheng Zhang, Yu Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MalLight:+Influence-Aware+Coordinated+Traffic+Signal+Control+for+Traffic+Signal+Malfunctions)|0|
|[Leveraging Local Structure for Improving Model Explanations: An Information Propagation Approach](https://doi.org/10.1145/3627673.3679575)|Ruo Yang, Binghui Wang, Mustafa Bilgic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Local+Structure+for+Improving+Model+Explanations:+An+Information+Propagation+Approach)|0|
|[TrafCL: Robust Encrypted Malicious Traffic Detection via Contrastive Learning](https://doi.org/10.1145/3627673.3679839)|Xiaodu Yang, Sijie Ruan, Jinyu Li, Yinliang Yue, Bo Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrafCL:+Robust+Encrypted+Malicious+Traffic+Detection+via+Contrastive+Learning)|0|
|[Breaking State-of-the-Art Poisoning Defenses to Federated Learning: An Optimization-Based Attack Framework](https://doi.org/10.1145/3627673.3679566)|Yuxin Yang, Qiang Li, Chenfei Nie, Yuan Hong, Binghui Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+State-of-the-Art+Poisoning+Defenses+to+Federated+Learning:+An+Optimization-Based+Attack+Framework)|0|
|[What a Surprise! Computing Rewritten Modules Can Be as Efficient as Computing Subset Modules](https://doi.org/10.1145/3627673.3679528)|Zhihao Yang, Yizheng Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+a+Surprise!+Computing+Rewritten+Modules+Can+Be+as+Efficient+as+Computing+Subset+Modules)|0|
|[Adaptive Differentially Private Structural Entropy Minimization for Unsupervised Social Event Detection](https://doi.org/10.1145/3627673.3679537)|Zhiwei Yang, Yuecen Wei, Haoran Li, Qian Li, Lei Jiang, Li Sun, Xiaoyan Yu, Chunming Hu, Hao Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Differentially+Private+Structural+Entropy+Minimization+for+Unsupervised+Social+Event+Detection)|0|
|[Combining Incomplete Observational and Randomized Data for Heterogeneous Treatment Effects](https://doi.org/10.1145/3627673.3679593)|Dong Yao, Caizhi Tang, Qing Cui, Longfei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combining+Incomplete+Observational+and+Randomized+Data+for+Heterogeneous+Treatment+Effects)|0|
|[CKNN: Cleansed k-Nearest Neighbor for Unsupervised Video Anomaly Detection](https://doi.org/10.1145/3627673.3679526)|Jihun Yi, Sungroh Yoon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CKNN:+Cleansed+k-Nearest+Neighbor+for+Unsupervised+Video+Anomaly+Detection)|0|
|[GraphCBAL: Class-Balanced Active Learning for Graph Neural Networks via Reinforcement Learning](https://doi.org/10.1145/3627673.3679624)|Chengcheng Yu, Jiapeng Zhu, Xiang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphCBAL:+Class-Balanced+Active+Learning+for+Graph+Neural+Networks+via+Reinforcement+Learning)|0|
|[Rethinking Attention Mechanism for Spatio-Temporal Modeling: A Decoupling Perspective in Traffic Flow Prediction](https://doi.org/10.1145/3627673.3679571)|Qi Yu, Weilong Ding, Hao Zhang, Yang Yang, Tianpu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Attention+Mechanism+for+Spatio-Temporal+Modeling:+A+Decoupling+Perspective+in+Traffic+Flow+Prediction)|0|
|[Time-Series Representation Learning via Dual Reference Contrasting](https://doi.org/10.1145/3627673.3679699)|Rui Yu, Yongshun Gong, Shoujin Wang, Jiasheng Si, Xueping Peng, Bing Xu, Wenpeng Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-Series+Representation+Learning+via+Dual+Reference+Contrasting)|0|
|[Using Distributed Ledgers To Build Knowledge Graphs For Decentralized Computing Ecosystems](https://doi.org/10.1145/3627673.3679644)|Tarek Zaarour, Ahmed Khalid, Preeja Pradeep, Ahmed H. Zahran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+Distributed+Ledgers+To+Build+Knowledge+Graphs+For+Decentralized+Computing+Ecosystems)|0|
|[Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy Induction from Limited Examples](https://doi.org/10.1145/3627673.3679608)|Qingkai Zeng, Yuyang Bai, Zhaoxuan Tan, Shangbin Feng, Zhenwen Liang, Zhihan Zhang, Meng Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Chain-of-Layer:+Iteratively+Prompting+Large+Language+Models+for+Taxonomy+Induction+from+Limited+Examples)|0|
|[Benchmarking Challenges for Temporal Knowledge Graph Alignment](https://doi.org/10.1145/3627673.3679784)|Weixin Zeng, Jie Zhou, Xiang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Benchmarking+Challenges+for+Temporal+Knowledge+Graph+Alignment)|0|
|[M2ConceptBase: A Fine-Grained Aligned Concept-Centric Multimodal Knowledge Base](https://doi.org/10.1145/3627673.3679852)|Zhiwei Zha, Jiaan Wang, Zhixu Li, Xiangru Zhu, Wei Song, Yanghua Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M2ConceptBase:+A+Fine-Grained+Aligned+Concept-Centric+Multimodal+Knowledge+Base)|0|
|[Cost-Effective Framework with Optimized Task Decomposition and Batch Prompting for Medical Dialogue Summary](https://doi.org/10.1145/3627673.3679671)|Chi Zhang, Tao Chen, Jiehao Chen, Hao Wang, Jiyun Shi, Zhaojing Luo, Meihui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cost-Effective+Framework+with+Optimized+Task+Decomposition+and+Batch+Prompting+for+Medical+Dialogue+Summary)|0|
|[InfoMLP: Unlocking the Potential of MLPs for Semi-Supervised Learning with Structured Data](https://doi.org/10.1145/3627673.3679679)|Hengrui Zhang, Qitian Wu, Chenxiao Yang, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InfoMLP:+Unlocking+the+Potential+of+MLPs+for+Semi-Supervised+Learning+with+Structured+Data)|0|
|[Revisit Orthogonality in Graph-Regularized MLPs](https://doi.org/10.1145/3627673.3679811)|Hengrui Zhang, Shen Wang, Vassilis N. Ioannidis, Soji Adeshina, Jiani Zhang, Xiao Qin, Christos Faloutsos, Da Zheng, George Karypis, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisit+Orthogonality+in+Graph-Regularized+MLPs)|0|
|[CYCLE: Cross-Year Contrastive Learning in Entity-Linking](https://doi.org/10.1145/3627673.3679702)|Pengyu Zhang, Congfeng Cao, Klim Zaporojets, Paul Groth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CYCLE:+Cross-Year+Contrastive+Learning+in+Entity-Linking)|0|
|[Data Imputation from the Perspective of Graph Dirichlet Energy](https://doi.org/10.1145/3627673.3679669)|Weiqi Zhang, Guanlue Li, Jianheng Tang, Jia Li, Fugee Tsung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Imputation+from+the+Perspective+of+Graph+Dirichlet+Energy)|0|
|[DPCAG: A Community Affiliation Graph Generation Model for Preserving Group Relationships](https://doi.org/10.1145/3627673.3679657)|Xinjian Zhang, Bo Ning, Chengfei Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPCAG:+A+Community+Affiliation+Graph+Generation+Model+for+Preserving+Group+Relationships)|0|
|[A GAIL Fine-Tuned LLM Enhanced Framework for Low-Resource Knowledge Graph Question Answering](https://doi.org/10.1145/3627673.3679753)|Zhiqiang Zhang, Liqiang Wen, Wen Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+GAIL+Fine-Tuned+LLM+Enhanced+Framework+for+Low-Resource+Knowledge+Graph+Question+Answering)|0|
|[NeutronCache: An Efficient Cache-Enhanced Distributed Graph Neural Network Training System](https://doi.org/10.1145/3627673.3679815)|Chu Zhao, Shengjie Dong, Yuhai Zhao, Yuan Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeutronCache:+An+Efficient+Cache-Enhanced+Distributed+Graph+Neural+Network+Training+System)|0|
|[Towards Coarse-grained Visual Language Navigation Task Planning Enhanced by Event Knowledge Graph](https://doi.org/10.1145/3627673.3679711)|Kaichen Zhao, Yaoxian Song, Haiquan Zhao, Haoyu Liu, Tiefeng Li, Zhixu Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Coarse-grained+Visual+Language+Navigation+Task+Planning+Enhanced+by+Event+Knowledge+Graph)|0|
|[Zero-shot Knowledge Graph Question Generation via Multi-agent LLMs and Small Models Synthesis](https://doi.org/10.1145/3627673.3679805)|Runhao Zhao, Jiuyang Tang, Weixin Zeng, Ziyang Chen, Xiang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Knowledge+Graph+Question+Generation+via+Multi-agent+LLMs+and+Small+Models+Synthesis)|0|
|[Devil in the Tail: A Multi-Modal Framework for Drug-Drug Interaction Prediction in Long Tail Distinction](https://doi.org/10.1145/3627673.3679719)|Liangwei Nathan Zheng, Chang George Dong, Wei Emma Zhang, Xin Chen, Lin Yue, Weitong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Devil+in+the+Tail:+A+Multi-Modal+Framework+for+Drug-Drug+Interaction+Prediction+in+Long+Tail+Distinction)|0|
|[Irregularity-Informed Time Series Analysis: Adaptive Modelling of Spatial and Temporal Dynamics](https://doi.org/10.1145/3627673.3679716)|Liangwei Nathan Zheng, Zhengyang Li, Chang George Dong, Wei Emma Zhang, Lin Yue, Miao Xu, Olaf Maennel, Weitong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Irregularity-Informed+Time+Series+Analysis:+Adaptive+Modelling+of+Spatial+and+Temporal+Dynamics)|0|
|[FGITrans: Cross-City Transformer for Fine-grained Urban Flow Inference](https://doi.org/10.1145/3627673.3679855)|Yuhao Zheng, Yishuo Cai, Zihao Cai, Changjun Fan, Senzhang Wang, Jianxin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FGITrans:+Cross-City+Transformer+for+Fine-grained+Urban+Flow+Inference)|0|
|[AdaTM: Fine-grained Urban Flow Inference with Adaptive Knowledge Transfer across Multiple Cities](https://doi.org/10.1145/3627673.3679856)|Yuhao Zheng, Jinyang Wu, Zihao Cai, Senzhang Wang, Jianxin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaTM:+Fine-grained+Urban+Flow+Inference+with+Adaptive+Knowledge+Transfer+across+Multiple+Cities)|0|
|[AdaTrans: Adaptive Transfer Time Prediction for Multi-modal Transportation Modes](https://doi.org/10.1145/3627673.3679585)|Shuxin Zhong, Hua Wei, Wenjun Lyu, Guang Yang, Zhiqing Hong, Guang Wang, Yu Yang, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaTrans:+Adaptive+Transfer+Time+Prediction+for+Multi-modal+Transportation+Modes)|0|
|[Learning Cross-modal Knowledge Reasoning and Heuristic-prompt for Visual-language Navigation](https://doi.org/10.1145/3627673.3679740)|Dongming Zhou, Zhengbin Pang, Wei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Cross-modal+Knowledge+Reasoning+and+Heuristic-prompt+for+Visual-language+Navigation)|0|
|[LST2A: Lexical-Syntactic Targeted Adversarial Attack for Texts](https://doi.org/10.1145/3627673.3679640)|Guanghao Zhou, Panjia Qiu, Mingyuan Fan, Cen Chen, Yaliang Li, Wenmeng Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LST2A:+Lexical-Syntactic+Targeted+Adversarial+Attack+for+Texts)|0|
|[MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation](https://doi.org/10.1145/3627673.3679532)|Jianping Zhou, Junhao Li, Guanjie Zheng, Xinbing Wang, Chenghu Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MTSCI:+A+Conditional+Diffusion+Model+for+Multivariate+Time+Series+Consistent+Imputation)|0|
|[Graph Anomaly Detection with Adaptive Node Mixup](https://doi.org/10.1145/3627673.3679577)|Qinghai Zhou, Yuzhong Chen, Zhe Xu, Yuhang Wu, Menghai Pan, Mahashweta Das, Hao Yang, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Anomaly+Detection+with+Adaptive+Node+Mixup)|0|
|[REDI: Recurrent Diffusion Model for Probabilistic Time Series Forecasting](https://doi.org/10.1145/3627673.3679808)|Shiyang Zhou, Zehao Gu, Yun Xiong, Yang Luo, Qiang Wang, Xiaofeng Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REDI:+Recurrent+Diffusion+Model+for+Probabilistic+Time+Series+Forecasting)|0|
|[Scalable Transformer for High Dimensional Multivariate Time Series Forecasting](https://doi.org/10.1145/3627673.3679757)|Xin Zhou, Weiqing Wang, Wray L. Buntine, Shilin Qu, Abishek Sriramulu, Weicong Tan, Christoph Bergmeir||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Transformer+for+High+Dimensional+Multivariate+Time+Series+Forecasting)|0|
|[Regularized Unconstrained Weakly Submodular Maximization](https://doi.org/10.1145/3627673.3679651)|Yanhui Zhu, Samik Basu, A. Pavan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regularized+Unconstrained+Weakly+Submodular+Maximization)|0|
|[PRISM: Mitigating EHR Data Sparsity via Learning from Missing Feature Calibrated Prototype Patient Representations](https://doi.org/10.1145/3627673.3679521)|Yinghao Zhu, Zixiang Wang, Long He, Shiyun Xie, Xiaochen Zheng, Liantao Ma, Chengwei Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PRISM:+Mitigating+EHR+Data+Sparsity+via+Learning+from+Missing+Feature+Calibrated+Prototype+Patient+Representations)|0|
|[L-APPLE: Language-agnostic Prototype Prefix Learning for Cross-lingual Event Detection](https://doi.org/10.1145/3627673.3679769)|Ziqin Zhu, Xutan Peng, Qian Li, Cheng Ji, Qingyun Sun, Jianxin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=L-APPLE:+Language-agnostic+Prototype+Prefix+Learning+for+Cross-lingual+Event+Detection)|0|
|[MV-BART: Multi-view BART for Multi-modal Sarcasm Detection](https://doi.org/10.1145/3627673.3679570)|Xingjie Zhuang, Fengling Zhou, Zhixin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MV-BART:+Multi-view+BART+for+Multi-modal+Sarcasm+Detection)|0|
|[Enhancing Event Detection with Inter-Event Dependencies in Large Ontologies](https://doi.org/10.1145/3627673.3679915)|Samireh Abdi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Event+Detection+with+Inter-Event+Dependencies+in+Large+Ontologies)|0|
|[COSCO: A Sharpness-Aware Training Framework for Few-shot Multivariate Time Series Classification](https://doi.org/10.1145/3627673.3679891)|Jesus Barreda, Ashley Gomez, Ruben Puga, Kaixiong Zhou, Li Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COSCO:+A+Sharpness-Aware+Training+Framework+for+Few-shot+Multivariate+Time+Series+Classification)|0|
|[Accurate Path Prediction of Provenance Traces](https://doi.org/10.1145/3627673.3679872)|Raza Ahmad, HeeYoung Jung, Yuta Nakamura, Tanu Malik||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accurate+Path+Prediction+of+Provenance+Traces)|0|
|[Fractional Budget Allocation for Influence Maximization under General Marketing Strategies](https://doi.org/10.1145/3627673.3679929)|Akhil Bhimaraju, Eliot W. Robson, Lav R. Varshney, Abhishek K. Umrawal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fractional+Budget+Allocation+for+Influence+Maximization+under+General+Marketing+Strategies)|0|
|[IEcons: A New Consensus Approach Using Multi-Text Representations for Clustering Task](https://doi.org/10.1145/3627673.3679941)|Karima Boutalbi, Rafika Boutalbi, Hervé Verjus, Kavé Salamatian, David Telisson, Olivier Le Van||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IEcons:+A+New+Consensus+Approach+Using+Multi-Text+Representations+for+Clustering+Task)|0|
|[Scalable Unsupervised Feature Selection with Reconstruction Error Guarantees via QMR Decomposition](https://doi.org/10.1145/3627673.3679994)|Ciwan Ceylan, Kambiz Ghoorchian, Danica Kragic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Unsupervised+Feature+Selection+with+Reconstruction+Error+Guarantees+via+QMR+Decomposition)|0|
|[End-to-End Aspect Based Sentiment Analysis Using Graph Attention Network](https://doi.org/10.1145/3627673.3679910)|Abir Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Aspect+Based+Sentiment+Analysis+Using+Graph+Attention+Network)|0|
|[Deep Noise-Aware Quality Loss for Speaker Verification](https://doi.org/10.1145/3627673.3679895)|Pantid Chantangphol, Theerat Sakdejayont, Monchai Lertsutthiwong, Tawunrat Chalothorn||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Noise-Aware+Quality+Loss+for+Speaker+Verification)|0|
|[Empowering LLMs for Multi-Page Layout Generation via Consistency-Oriented In-Context Learning](https://doi.org/10.1145/3627673.3679908)|Mengyao Chen, Xinghua Zhang, Junhao Zhang, Quangang Li, Tingwen Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+LLMs+for+Multi-Page+Layout+Generation+via+Consistency-Oriented+In-Context+Learning)|0|
|[CMG: A Causality-enhanced Multi-view Graph Model for Stock Trend Prediction](https://doi.org/10.1145/3627673.3679886)|Xi Cheng, Liang Wang, Yunan Zeng, Qiang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CMG:+A+Causality-enhanced+Multi-view+Graph+Model+for+Stock+Trend+Prediction)|0|
|[MSG-Chart: Multimodal Scene Graph for ChartQA](https://doi.org/10.1145/3627673.3679967)|Yue Dai, Soyeon Caren Han, Wei Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSG-Chart:+Multimodal+Scene+Graph+for+ChartQA)|0|
|[Quantifying Uncertainty in Neural Networks through Residuals](https://doi.org/10.1145/3627673.3679983)|Dalavai Udbhav Mallanna, Rini Smita Thakur, Rajeev Ranjan Dwivedi, Vinod K. Kurmi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+Uncertainty+in+Neural+Networks+through+Residuals)|0|
|[A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining](https://doi.org/10.1145/3627673.3679870)|Audrey Der, ChinChia Michael Yeh, Xin Dai, Huiyuan Chen, Yan Zheng, Yujie Fan, Zhongfang Zhuang, Vivian Lai, Junpeng Wang, Liang Wang, Wei Zhang, Eamonn J. Keogh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Systematic+Evaluation+of+Generated+Time+Series+and+Their+Effects+in+Self-Supervised+Pretraining)|0|
|[Quantum Inverse Contextual Vision Transformers (Q-ICVT): A New Frontier in 3D Object Detection for AVs](https://doi.org/10.1145/3627673.3679984)|Sanjay Bhargav Dharavath, Tanmoy Dam, Supriyo Chakraborty, Prithwiraj Roy, Aniruddha Maiti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantum+Inverse+Contextual+Vision+Transformers+(Q-ICVT):+A+New+Frontier+in+3D+Object+Detection+for+AVs)|0|
|[Efficient Global Message Passing for Heterophilous Graphs](https://doi.org/10.1145/3627673.3679907)|Yanfei Dong, Mohammed Haroon Dupty, Lambert Deng, Yong Liang Goh, Wee Sun Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Global+Message+Passing+for+Heterophilous+Graphs)|0|
|[General Time Transformer: an Encoder-only Foundation Model for Zero-Shot Multivariate Time Series Forecasting](https://doi.org/10.1145/3627673.3679931)|Cheng Feng, Long Huang, Denis Krompass||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=General+Time+Transformer:+an+Encoder-only+Foundation+Model+for+Zero-Shot+Multivariate+Time+Series+Forecasting)|0|
|[Effective Clean-Label Backdoor Attacks on Graph Neural Networks](https://doi.org/10.1145/3627673.3679905)|Xuanhao Fan, Enyan Dai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Clean-Label+Backdoor+Attacks+on+Graph+Neural+Networks)|0|
|[Retrogressive Document Manipulation of US Federal Environmental Websites](https://doi.org/10.1145/3627673.3679988)|Lesley Frew, Michael L. Nelson, Michele C. Weigle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrogressive+Document+Manipulation+of+US+Federal+Environmental+Websites)|0|
|[Application of Large Language Models in Chemistry Reaction Data Extraction and Cleaning](https://doi.org/10.1145/3627673.3679874)|Xiaobao Huang, Mihir Surve, Yuhan Liu, Tengfei Luo, Olaf Wiest, Xiangliang Zhang, Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Application+of+Large+Language+Models+in+Chemistry+Reaction+Data+Extraction+and+Cleaning)|0|
|[Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge](https://doi.org/10.1145/3627673.3679918)|Joshua Shay Kricheli, Khoa Vo, Aniruddha Datta, Spencer Ozgur, Paulo Shakarian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Error+Detection+and+Constraint+Recovery+in+Hierarchical+Multi-Label+Classification+without+Prior+Knowledge)|0|
|[Learning Prompt-Level Quality Variance for Cost-Effective Text-to-Image Generation](https://doi.org/10.1145/3627673.3679954)|Dongkeun Lee, Wonjun Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Prompt-Level+Quality+Variance+for+Cost-Effective+Text-to-Image+Generation)|0|
|[HypMix: Hyperbolic Representation Learning for Graphs with Mixed Hierarchical and Non-hierarchical Structures](https://doi.org/10.1145/3627673.3679940)|Eric Wonhee Lee, Bo Xiong, Carl Yang, Joyce C. Ho||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HypMix:+Hyperbolic+Representation+Learning+for+Graphs+with+Mixed+Hierarchical+and+Non-hierarchical+Structures)|0|
|[Document-Level Relation Extraction Based on Heterogeneous Graph Reasoning](https://doi.org/10.1145/3627673.3679899)|Dong Li, Miao Li, ZhiLei Lei, Baoyan Song, Xiaohuan Shan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Document-Level+Relation+Extraction+Based+on+Heterogeneous+Graph+Reasoning)|0|
|[Beyond Aggregation: Efficient Federated Model Consolidation with Heterogeneity-Adaptive Weights Diffusion](https://doi.org/10.1145/3627673.3679879)|Jiaqi Li, Xiaoyang Qu, Wenbo Ding, Zihao Zhao, Jianzong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Aggregation:+Efficient+Federated+Model+Consolidation+with+Heterogeneity-Adaptive+Weights+Diffusion)|0|
|[ChefFusion: Multimodal Foundation Model Integrating Recipe and Food Image Generation](https://doi.org/10.1145/3627673.3679885)|Peiyu Li, Xiaobao Huang, Yijun Tian, Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ChefFusion:+Multimodal+Foundation+Model+Integrating+Recipe+and+Food+Image+Generation)|0|
|[Coresets for Deletion-Robust k-Center Clustering](https://doi.org/10.1145/3627673.3679890)|Ruien Li, Yanhao Wang, Michael Mathioudakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Coresets+for+Deletion-Robust+k-Center+Clustering)|0|
|[Effective Job-market Mobility Prediction with Attentive Heterogeneous Knowledge Learning and Synergy](https://doi.org/10.1145/3627673.3679906)|Sida Lin, Zhouyi Zhang, Yankai Chen, Chenhao Ma, Yixiang Fang, Shan Dai, Guangli Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Job-market+Mobility+Prediction+with+Attentive+Heterogeneous+Knowledge+Learning+and+Synergy)|0|
|[An Explainable Multi-atlas Fusion Model based on Spatial Overlap for ASD Diagnosis](https://doi.org/10.1145/3627673.3679873)|Yuefeng Ma, Xiaochen Mu, Tengfei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Explainable+Multi-atlas+Fusion+Model+based+on+Spatial+Overlap+for+ASD+Diagnosis)|0|
|[ToxVI: a Multimodal LLM-based Framework for Generating Intervention in Toxic Code-Mixed Videos](https://doi.org/10.1145/3627673.3680004)|Krishanu Maity, A. S. Poornash, Sriparna Saha, Kitsuchart Pasupa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ToxVI:+a+Multimodal+LLM-based+Framework+for+Generating+Intervention+in+Toxic+Code-Mixed+Videos)|0|
|[Extended Japanese Commonsense Morality Dataset with Masked Token and Label Enhancement](https://doi.org/10.1145/3627673.3679924)|Takumi Ohashi, Tsubasa Nakagawa, Hitoshi Iyatomi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extended+Japanese+Commonsense+Morality+Dataset+with+Masked+Token+and+Label+Enhancement)|0|
|[Progressive Label Disambiguation for Partial Label Learning in Homogeneous Graphs](https://doi.org/10.1145/3627673.3679982)|Rajat Patel, Aakarsh Malhotra, Sudipta Modak, Siddharth Yerramsetty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Label+Disambiguation+for+Partial+Label+Learning+in+Homogeneous+Graphs)|0|
|[MEDFuse: Multimodal EHR Data Fusion with Masked Lab-Test Modeling and Large Language Models](https://doi.org/10.1145/3627673.3679962)|Phan Nguyen Minh Thao, CongTinh Dao, Chenwei Wu, JianZhe Wang, Shun Liu, JunEn Ding, David S. Restrepo, Feng Liu, FangMing Hung, WenChih Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MEDFuse:+Multimodal+EHR+Data+Fusion+with+Masked+Lab-Test+Modeling+and+Large+Language+Models)|0|
|[Improving German News Clustering with Contrastive Learning](https://doi.org/10.1145/3627673.3679944)|Piriyakorn Piriyatamwong, Saikishore Kalloori, Fabio Zünd||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+German+News+Clustering+with+Contrastive+Learning)|0|
|[Hol-Light: A Holistic framework for Efficient and Dynamic Traffic Signal Management](https://doi.org/10.1145/3627673.3679938)|Siyao Qiao, Jia Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hol-Light:+A+Holistic+framework+for+Efficient+and+Dynamic+Traffic+Signal+Management)|0|
|[ExPrompt: Augmenting Prompts Using Examples as Modern Baseline for Stance Classification](https://doi.org/10.1145/3627673.3679923)|Umair Qudus, Michael Röder, Daniel Vollmers, AxelCyrille Ngonga Ngomo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ExPrompt:+Augmenting+Prompts+Using+Examples+as+Modern+Baseline+for+Stance+Classification)|0|
|[A Mixture of Experts in Forecasting Student Performance in Classroom Programming Activities](https://doi.org/10.1145/3627673.3679868)|Moqsadur Rahman, Monika Akbar, Justice T. Walker, Mahmud Shahriar Hossain||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Mixture+of+Experts+in+Forecasting+Student+Performance+in+Classroom+Programming+Activities)|0|
|[Compressed Models are NOT Miniature Versions of Large Models](https://doi.org/10.1145/3627673.3679888)|Rohit Raj Rai, Rishant Pal, Amit Awekar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compressed+Models+are+NOT+Miniature+Versions+of+Large+Models)|0|
|[Generative AI for Energy: Multi-Horizon Power Consumption Forecasting using Large Language Models](https://doi.org/10.1145/3627673.3679933)|Kevin Roitero, Gianluca D'Abrosca, Andrea Zancola, Vincenzo Della Mea, Stefano Mizzaro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+for+Energy:+Multi-Horizon+Power+Consumption+Forecasting+using+Large+Language+Models)|0|
|[Scalable Expressiveness through Preprocessed Graph Perturbations](https://doi.org/10.1145/3627673.3679993)|Danial Saber, Amirali SalehiAbari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Expressiveness+through+Preprocessed+Graph+Perturbations)|0|
|[EDGE: Evaluation Framework for Logical vs. Subgraph Explanations for Node Classifiers on Knowledge Graphs](https://doi.org/10.1145/3627673.3679904)|Rupesh Sapkota, Dominik Köhler, Stefan Heindorf||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EDGE:+Evaluation+Framework+for+Logical+vs.+Subgraph+Explanations+for+Node+Classifiers+on+Knowledge+Graphs)|0|
|[Empowering Traffic Speed Prediction with Auxiliary Feature-Aided Dependency Learning](https://doi.org/10.1145/3627673.3679909)|DongHyuk Seo, Jiwon Son, Namhyuk Kim, WonYong Shin, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Traffic+Speed+Prediction+with+Auxiliary+Feature-Aided+Dependency+Learning)|0|
|[QuestGen: Effectiveness of Question Generation Methods for Fact-Checking Applications](https://doi.org/10.1145/3627673.3679985)|Ritvik Setty, Vinay Setty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QuestGen:+Effectiveness+of+Question+Generation+Methods+for+Fact-Checking+Applications)|0|
|[M2IoU: A Min-Max Distance-based Loss Function for Bounding Box Regression in Medical Imaging](https://doi.org/10.1145/3627673.3679958)|Anurag Shandilya, Kalash Shah, Bhavik Kanekar, Akshat Gautam, Pavni Tandon, Ganesh Ramakrishnan, Kshitij S. Jadhav||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M2IoU:+A+Min-Max+Distance-based+Loss+Function+for+Bounding+Box+Regression+in+Medical+Imaging)|0|
|[Enhancing SPARQL Generation by Triplet-order-sensitive Pre-training](https://doi.org/10.1145/3627673.3679916)|Chang Su, Jiexing Qi, He Yan, Kai Zou, Zhouhan Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+SPARQL+Generation+by+Triplet-order-sensitive+Pre-training)|0|
|[Revealing the Power of Masked Autoencoders in Traffic Forecasting](https://doi.org/10.1145/3627673.3679989)|Jiarui Sun, Yujie Fan, ChinChia Michael Yeh, Wei Zhang, Girish Chowdhary||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revealing+the+Power+of+Masked+Autoencoders+in+Traffic+Forecasting)|0|
|[Spatio-Temporal Sequence Modeling for Traffic Signal Control](https://doi.org/10.1145/3627673.3679998)|Qian Sun, Le Zhang, Jingbo Zhou, Rui Zha, Yu Mei, Chujie Tian, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Sequence+Modeling+for+Traffic+Signal+Control)|0|
|[SurvReLU: Inherently Interpretable Survival Analysis via Deep ReLU Networks](https://doi.org/10.1145/3627673.3679947)|Xiaotong Sun, Peijie Qiu, Shengfan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SurvReLU:+Inherently+Interpretable+Survival+Analysis+via+Deep+ReLU+Networks)|0|
|[Over-penalization for Extra Information in Neural IR Models](https://doi.org/10.1145/3627673.3679975)|Kota Usuha, Makoto P. Kato, Sumio Fujita||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Over-penalization+for+Extra+Information+in+Neural+IR+Models)|0|
|[Enhancing Temporal and Geographical Named Entity Recognition in Chinese Ancient Texts with External Time-series Knowledge Bases](https://doi.org/10.1145/3627673.3679917)|Xiaotong Wang, Xuanning Liu, Shuai Zhong, Xinming Chen, Bin Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Temporal+and+Geographical+Named+Entity+Recognition+in+Chinese+Ancient+Texts+with+External+Time-series+Knowledge+Bases)|0|
|[Does Knowledge Localization Hold True? Surprising Differences Between Entity and Relation Perspectives in Language Models](https://doi.org/10.1145/3627673.3679900)|Yifan Wei, Xiaoyan Yu, Yixuan Weng, Huanhuan Ma, Yuanzhe Zhang, Jun Zhao, Kang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Does+Knowledge+Localization+Hold+True?+Surprising+Differences+Between+Entity+and+Relation+Perspectives+in+Language+Models)|0|
|[DP-FedFace: Privacy-Preserving Facial Recognition in Real Federated Scenarios](https://doi.org/10.1145/3627673.3679901)|Wenjing Wang, Si Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DP-FedFace:+Privacy-Preserving+Facial+Recognition+in+Real+Federated+Scenarios)|0|
|[Attentional Neural Integral Equation for Temporal Knowledge Graph Forecasting](https://doi.org/10.1145/3627673.3679876)|Likang Xiao, Zijie Chen, Richong Zhang, Junfan Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attentional+Neural+Integral+Equation+for+Temporal+Knowledge+Graph+Forecasting)|0|
|[MPHDetect: Multi-View Prompting and Hypergraph Fusion for Malevolence Detection in Dialogues](https://doi.org/10.1145/3627673.3679966)|Bo Xu, Xuening Qiao, Hongfei Lin, Linlin Zong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MPHDetect:+Multi-View+Prompting+and+Hypergraph+Fusion+for+Malevolence+Detection+in+Dialogues)|0|
|[SparseBF: Enhancing Scalability and Efficiency for Sparsely Filled Privacy-Preserving Record Linkage](https://doi.org/10.1145/3627673.3679997)|Han Xu, Yuhong Shao, Kareem Benaissa, Yutong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SparseBF:+Enhancing+Scalability+and+Efficiency+for+Sparsely+Filled+Privacy-Preserving+Record+Linkage)|0|
|[Learning Counterfactual Explanations with Intervals for Time-series Classification](https://doi.org/10.1145/3627673.3679952)|Akihiro Yamaguchi, Ken Ueno, Ryusei Shingaki, Hisashi Kashima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Counterfactual+Explanations+with+Intervals+for+Time-series+Classification)|0|
|[GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding](https://doi.org/10.1145/3627673.3679934)|Yibo Yan, Joey Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GeoReasoner:+Reasoning+On+Geospatially+Grounded+Context+For+Natural+Language+Understanding)|0|
|[Multi-Scale Contrastive Attention Representation Learning for Encrypted Traffic Classification](https://doi.org/10.1145/3627673.3679968)|Shuo Yang, Xinran Zheng, Jinze Li, Jinfeng Xu, Edith C. H. Ngai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Scale+Contrastive+Attention+Representation+Learning+for+Encrypted+Traffic+Classification)|0|
|[You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning](https://doi.org/10.1145/3627673.3680007)|Tianmeng Yang, Jiahao Meng, Min Zhou, Yaming Yang, Yujing Wang, Xiangtai Li, Yunhai Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Can't+Ignore+Either:+Unifying+Structure+and+Feature+Denoising+for+Robust+Graph+Learning)|0|
|[CAG: A Consistency-Adaptive Text-Image Alignment Generation for Joint Multimodal Entity-Relation Extraction](https://doi.org/10.1145/3627673.3679883)|Xinjie Yang, Xiaocheng Gong, Binghao Tang, Yang Lei, Yayue Deng, Huan Ouyang, Gang Zhao, Lei Luo, Yunling Feng, Bin Duan, Si Li, Yajing Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAG:+A+Consistency-Adaptive+Text-Image+Alignment+Generation+for+Joint+Multimodal+Entity-Relation+Extraction)|0|
|[Robust Heterophily Graph Learning via Uniformity Augmentation](https://doi.org/10.1145/3627673.3679991)|Xusheng Yang, Zhengyu Chen, Yuexian Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Heterophily+Graph+Learning+via+Uniformity+Augmentation)|0|
|[Multi-Stage Refined Visual Captioning for Baidu Ad Creatives Generation](https://doi.org/10.1145/3627673.3679969)|Yi Yang, Xinyu Zhao, Kang Zhao, Zhipeng Jin, Wen Tao, Lin Liu, Shuanglong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Stage+Refined+Visual+Captioning+for+Baidu+Ad+Creatives+Generation)|0|
|[BART-based Hierarchical Attentional Network for Sentence Ordering](https://doi.org/10.1145/3627673.3679878)|Yiping Yang, Baiyun Cui, Yingming Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BART-based+Hierarchical+Attentional+Network+for+Sentence+Ordering)|0|
|[Span Confusion is All You Need for Chinese Spelling Correction](https://doi.org/10.1145/3627673.3679996)|Dezhi Ye, Haomei Jia, Bowen Tian, Jie Liu, Haijin Liang, Jin Ma, Wenmin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Span+Confusion+is+All+You+Need+for+Chinese+Spelling+Correction)|0|
|[GaQR: An Efficient Generation-augmented Question Rewriter](https://doi.org/10.1145/3627673.3679930)|Oliver Young, Yixing Fan, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GaQR:+An+Efficient+Generation-augmented+Question+Rewriter)|0|
|[Meta-Prompt Tuning Vision-Language Model for Multi-Label Few-Shot Image Recognition](https://doi.org/10.1145/3627673.3679963)|Feng Zhang, Wei Chen, Fei Ding, Tengjiao Wang, Dawei Lu, Jiabin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Prompt+Tuning+Vision-Language+Model+for+Multi-Label+Few-Shot+Image+Recognition)|0|
|[Multi-view Temporal Knowledge Graph Reasoning](https://doi.org/10.1145/3627673.3679970)|Fuwei Zhang, Zhao Zhang, Fuzhen Zhuang, Zhiqiang Zhang, Jun Zhou, Deqing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-view+Temporal+Knowledge+Graph+Reasoning)|0|
|[Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media](https://doi.org/10.1145/3627673.3679919)|Jiajun Zhang, Zhixun Li, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evolving+to+the+Future:+Unseen+Event+Adaptive+Fake+News+Detection+on+Social+Media)|0|
|[H2D: Hierarchical Heterogeneous Graph Learning Framework for Drug-Drug Interaction Prediction](https://doi.org/10.1145/3627673.3679936)|Ran Zhang, Xuezhi Wang, Sheng Wang, Kunpeng Liu, Yuanchun Zhou, Pengfei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=H2D:+Hierarchical+Heterogeneous+Graph+Learning+Framework+for+Drug-Drug+Interaction+Prediction)|0|
|[In Situ Answer Sentence Selection at Web-scale](https://doi.org/10.1145/3627673.3679946)|Zeyu Zhang, Thuy Vu, Alessandro Moschitti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=In+Situ+Answer+Sentence+Selection+at+Web-scale)|0|
|[CNN to GNN: Unsupervised Multi-level Knowledge Learning](https://doi.org/10.1145/3627673.3679887)|Ziheng Jiao, Hongyuan Zhang, Xuelong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CNN+to+GNN:+Unsupervised+Multi-level+Knowledge+Learning)|0|
|[A Structural Information Guided Hierarchical Reconstruction for Graph Anomaly Detection](https://doi.org/10.1145/3627673.3679869)|Dongcheng Zou, Hao Peng, Chunyang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Structural+Information+Guided+Hierarchical+Reconstruction+for+Graph+Anomaly+Detection)|0|
|[UGAD: Universal Generative AI Detector utilizing Frequency Fingerprints](https://doi.org/10.1145/3627673.3680085)|Inzamamul Alam, Muhammad Shahid Muneer, Simon S. Woo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UGAD:+Universal+Generative+AI+Detector+utilizing+Frequency+Fingerprints)|0|
|[iRAG: Advancing RAG for Videos with an Incremental Approach](https://doi.org/10.1145/3627673.3680088)|Md. Adnan Arefeen, Biplob Debnath, Md. Yusuf Sarwar Uddin, Srimat Chakradhar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iRAG:+Advancing+RAG+for+Videos+with+an+Incremental+Approach)|0|
|[Leveraging Large Language Models for Improving Keyphrase Generation for Contextual Targeting](https://doi.org/10.1145/3627673.3680093)|Xiao Bai, Xue Wu, Ivan Stojkovic, Kostas Tsioutsiouliklis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Large+Language+Models+for+Improving+Keyphrase+Generation+for+Contextual+Targeting)|0|
|[LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions](https://doi.org/10.1145/3627673.3680032)|Anand Brahmbhatt, Mohith Pokala, Rishi Saket, Aravindan Raghuveer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLP-Bench:+A+Large+Scale+Tabular+Benchmark+for+Learning+from+Label+Proportions)|0|
|[DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection](https://doi.org/10.1145/3627673.3680008)|Donghee Choi, Jinkyu Kim, Mogan Gim, Jinho Lee, Jaewoo Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeepClair:+Utilizing+Market+Forecasts+for+Effective+Portfolio+Selection)|0|
|[Causal Interventional Prediction System for Robust and Explainable Effect Forecasting](https://doi.org/10.1145/3627673.3680073)|Zhixuan Chu, Hui Ding, Guang Zeng, Shiyu Wang, Yiming Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Interventional+Prediction+System+for+Robust+and+Explainable+Effect+Forecasting)|0|
|[Automated Nanoparticle Image Processing Pipeline for AI-Driven Materials Characterization](https://doi.org/10.1145/3627673.3680100)|Alexandra L. Day, Carolin B. Wahl, Roberto dos Reis, Weikeng Liao, Vinayak P. Dravid, Alok N. Choudhary, Ankit Agrawal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Nanoparticle+Image+Processing+Pipeline+for+AI-Driven+Materials+Characterization)|0|
|[Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic Degradation Analysis at Scale](https://doi.org/10.1145/3627673.3680026)|Yangxin Fan, Raymond Wieser, Laura S. Bruckman, Roger H. French, Yinghui Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Parallel-friendly+Spatio-Temporal+Graph+Learning+for+Photovoltaic+Degradation+Analysis+at+Scale)|0|
|[GraphWeaver: Billion-Scale Cybersecurity Incident Correlation](https://doi.org/10.1145/3627673.3680057)|Scott Freitas, Amir Gharib||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphWeaver:+Billion-Scale+Cybersecurity+Incident+Correlation)|0|
|[PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters](https://doi.org/10.1145/3627673.3680081)|Azin Ghazimatin, Ekaterina Garmash, Gustavo Penha, Kristen Sheets, Martin Achenbach, Oguz Semerci, Remi Galvez, Marcus Tannenberg, Sahitya Mantravadi, Divya Narayanan, Ofeliya Kalaydzhyan, Douglas Cole, Ben Carterette, Ann Clifton, Paul N. Bennett, Claudia Hauff, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PODTILE:+Facilitating+Podcast+Episode+Browsing+with+Auto-generated+Chapters)|0|
|[CancerKG.ORG - A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care](https://doi.org/10.1145/3627673.3680094)|Michael N. Gubanov, Anna Pyayt, Aleksandra Karolak||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CancerKG.ORG+-+A+Web-scale,+Interactive,+Verifiable+Knowledge+Graph-LLM+Hybrid+for+Assisting+with+Optimal+Cancer+Treatment+and+Care)|0|
|[Quality Prediction in Arc Welding: Leveraging Transformer Models and Discrete Representations from Vector Quantised-VAE](https://doi.org/10.1145/3627673.3680031)|Yannik Hahn, Robert F. Maack, Hasan Tercan, Tobias Meisen, Marion Purrio, Guido Buchholz, Matthias Angerhausen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quality+Prediction+in+Arc+Welding:+Leveraging+Transformer+Models+and+Discrete+Representations+from+Vector+Quantised-VAE)|0|
|[Reinforcement Feature Transformation for Polymer Property Performance Prediction](https://doi.org/10.1145/3627673.3680105)|Xuanming Hu, Dongjie Wang, Wangyang Ying, Yanjie Fu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Feature+Transformation+for+Polymer+Property+Performance+Prediction)|0|
|[Robust Sequence-Based Self-Supervised Representation Learning for Anti-Money Laundering](https://doi.org/10.1145/3627673.3680078)|Shuaibin Huang, Yun Xiong, Yi Xie, Tianyu Qiu, Guangzhong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Sequence-Based+Self-Supervised+Representation+Learning+for+Anti-Money+Laundering)|0|
|[LAPIS: Language Model-Augmented Police Investigation System](https://doi.org/10.1145/3627673.3680044)|Heedou Kim, Dain Kim, Jiwoo Lee, Chanwoong Yoon, Donghee Choi, Mogan Gim, Jaewoo Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LAPIS:+Language+Model-Augmented+Police+Investigation+System)|0|
|[XploitSQL: Advancing Adversarial SQL Injection Attack Generation with Language Models and Reinforcement Learning](https://doi.org/10.1145/3627673.3680102)|Daniel Leung, Omar Tsai, Kourosh Hashemi, Bardia Tayebi, Mohammad A. Tayebi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XploitSQL:+Advancing+Adversarial+SQL+Injection+Attack+Generation+with+Language+Models+and+Reinforcement+Learning)|0|
|[RealTCD: Temporal Causal Discovery from Interventional Data with Large Language Model](https://doi.org/10.1145/3627673.3680042)|Peiwen Li, Xin Wang, Zeyang Zhang, Yuan Meng, Fang Shen, Yue Li, Jialong Wang, Yang Li, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RealTCD:+Temporal+Causal+Discovery+from+Interventional+Data+with+Large+Language+Model)|0|
|[Bridging Dynamic Factor Models and Neural Controlled Differential Equations for Nowcasting GDP](https://doi.org/10.1145/3627673.3680074)|Seonkyu Lim, Jeongwhan Choi, Noseong Park, SangHa Yoon, ShinHyuck Kang, YoungMin Kim, Hyunjoong Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Dynamic+Factor+Models+and+Neural+Controlled+Differential+Equations+for+Nowcasting+GDP)|0|
|[Hierarchical Information Propagation and Aggregation in Disentangled Graph Networks for Audience Expansion](https://doi.org/10.1145/3627673.3680062)|Li Lin, Xinyao Chen, Kaiwen Xia, Shuai Wang, Desheng Zhang, Tian He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Information+Propagation+and+Aggregation+in+Disentangled+Graph+Networks+for+Audience+Expansion)|0|
|[DECO: Cooperative Order Dispatching for On-Demand Delivery with Real-Time Encounter Detection](https://doi.org/10.1145/3627673.3680084)|Yao Lu, Shuai Wang, Yu Yang, Hai Wang, Baoshen Guo, Desheng Zhang, Shuai Wang, Tian He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DECO:+Cooperative+Order+Dispatching+for+On-Demand+Delivery+with+Real-Time+Encounter+Detection)|0|
|[Combat Greenwashing with GoalSpotter: Automatic Sustainability Objective Detection in Heterogeneous Reports](https://doi.org/10.1145/3627673.3680110)|Mohammad Mahdavi, Ramin Baghaei Mehr, Tom Debus||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combat+Greenwashing+with+GoalSpotter:+Automatic+Sustainability+Objective+Detection+in+Heterogeneous+Reports)|0|
|[Multi-view Causal Graph Fusion Based Anomaly Detection in Cyber-Physical Infrastructures](https://doi.org/10.1145/3627673.3680096)|Arun Vignesh Malarkkan, Dongjie Wang, Yanjie Fu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-view+Causal+Graph+Fusion+Based+Anomaly+Detection+in+Cyber-Physical+Infrastructures)|0|
|[Ericsogate: Advancing Analytics and Management of Data from Diverse Sources within Ericsson Using Knowledge Graphs](https://doi.org/10.1145/3627673.3680033)|Abdelghny Orogat, Sri Lakshmi Vadlamani, Dimple Thomas, Ahmed ElRoby||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ericsogate:+Advancing+Analytics+and+Management+of+Data+from+Diverse+Sources+within+Ericsson+Using+Knowledge+Graphs)|0|
|[COKE: Causal Discovery with Chronological Order and Expert Knowledge in High Proportion of Missing Manufacturing Data](https://doi.org/10.1145/3627673.3680083)|TingYun Ou, Ching Chang, WenChih Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COKE:+Causal+Discovery+with+Chronological+Order+and+Expert+Knowledge+in+High+Proportion+of+Missing+Manufacturing+Data)|0|
|[LawLLM: Law Large Language Model for the US Legal System](https://doi.org/10.1145/3627673.3680020)|Dong Shu, Haoran Zhao, Xukun Liu, David Demeter, Mengnan Du, Yongfeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LawLLM:+Law+Large+Language+Model+for+the+US+Legal+System)|0|
|["Reasoning before Responding": Towards Legal Long-form Question Answering with Interpretability](https://doi.org/10.1145/3627673.3680082)|Utkarsh Ujwal, Sai Sri Harsha Surampudi, Sayantan Mitra, Tulika Saha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="Reasoning+before+Responding":+Towards+Legal+Long-form+Question+Answering+with+Interpretability)|0|
|[COIN: Chance-Constrained Imitation Learning for Safe and Adaptive Resource Oversubscription under Uncertainty](https://doi.org/10.1145/3627673.3680060)|Lu Wang, Mayukh Das, Fangkai Yang, Chao Du, Bo Qiao, Hang Dong, Chetan Bansal, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COIN:+Chance-Constrained+Imitation+Learning+for+Safe+and+Adaptive+Resource+Oversubscription+under+Uncertainty)|0|
|[RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models](https://doi.org/10.1145/3627673.3680016)|Zefan Wang, Zichuan Liu, Yingying Zhang, Aoxiao Zhong, Jihong Wang, Fengbin Yin, Lunting Fan, Lingfei Wu, Qingsong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RCAgent:+Cloud+Root+Cause+Analysis+by+Autonomous+Agents+with+Tool-Augmented+Large+Language+Models)|0|
|[Process-Informed Deep Learning for Enhanced Order Fulfillment Cycle Time Prediction in On-Demand Grocery Retailing](https://doi.org/10.1145/3627673.3680056)|Jiawen Wei, Ziwen Ye, Chuan Yang, Chen Chen, Guangrui Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Process-Informed+Deep+Learning+for+Enhanced+Order+Fulfillment+Cycle+Time+Prediction+in+On-Demand+Grocery+Retailing)|0|
|[G2PTL: A Geography-Graph Pre-trained Model](https://doi.org/10.1145/3627673.3680023)|Lixia Wu, Jianlin Liu, Junhong Lou, Minhui Deng, Jianbin Zheng, Haomin Wen, Chao Song, Shu He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=G2PTL:+A+Geography-Graph+Pre-trained+Model)|0|
|[Deep Learning-Based Compressed Sensing for Mobile Device-Derived Sensor Data](https://doi.org/10.1145/3627673.3680050)|Liqiang Xu, Yuuki Nishiyama, Kota Tsubouchi, Kaoru Sezaki||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning-Based+Compressed+Sensing+for+Mobile+Device-Derived+Sensor+Data)|0|
|[Towards a Zero-Day Anomaly Detector in Cyber Physical Systems Using a Hybrid VAE-LSTM-OCSVM Model](https://doi.org/10.1145/3627673.3680064)|Romarick Yatagha, Betelhem Nebebe, Karl Waedt, Christoph Ruland||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Zero-Day+Anomaly+Detector+in+Cyber+Physical+Systems+Using+a+Hybrid+VAE-LSTM-OCSVM+Model)|0|
|[An End-to-End Reinforcement Learning Based Approach for Micro-View Order-Dispatching in Ride-Hailing](https://doi.org/10.1145/3627673.3680013)|Xinlang Yue, Yiran Liu, Fangzhou Shi, Sihong Luo, Chen Zhong, Min Lu, Zhe Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+End-to-End+Reinforcement+Learning+Based+Approach+for+Micro-View+Order-Dispatching+in+Ride-Hailing)|0|
|[On the Fly Detection of Root Causes from Observed Data with Application to IT Systems](https://doi.org/10.1145/3627673.3680010)|Lei Zan, Charles K. Assaad, Emilie Devijver, Éric Gaussier, Ali AïtBachir||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Fly+Detection+of+Root+Causes+from+Observed+Data+with+Application+to+IT+Systems)|0|
|[Scaling Vison-Language Foundation Model to 12 Billion Parameters in Baidu Dynamic Image Advertising](https://doi.org/10.1145/3627673.3680014)|Xinyu Zhao, Kang Zhao, Zhipeng Jin, Yi Yang, Wen Tao, Xiaodong Chen, Cong Han, Shuanglong Li, Lin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Vison-Language+Foundation+Model+to+12+Billion+Parameters+in+Baidu+Dynamic+Image+Advertising)|0|
|[Confidence-Aware Multi-Field Model Calibration](https://doi.org/10.1145/3627673.3680043)|Yuang Zhao, Chuhan Wu, Qinglin Jia, Hong Zhu, Jia Yan, Libin Zong, Linxuan Zhang, Zhenhua Dong, Muyu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Confidence-Aware+Multi-Field+Model+Calibration)|0|
|[Adaptive Cross-platform Transportation Time Prediction for Logistics](https://doi.org/10.1145/3627673.3680024)|Shuxin Zhong, Wenjun Lyu, Zhiqing Hong, Guang Yang, Weijian Zuo, Haotian Wang, Guang Wang, Yu Yang, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Cross-platform+Transportation+Time+Prediction+for+Logistics)|0|
|[Understanding and Modeling Job Marketplace with Pretrained Language Models](https://doi.org/10.1145/3627673.3680036)|Yaochen Zhu, Liang Wu, Binchi Zhang, Song Wang, Qi Guo, Liangjie Hong, Luke Simon, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+and+Modeling+Job+Marketplace+with+Pretrained+Language+Models)|0|
|[XplainScreen: Unveiling the Black Box of Graph Neural Network Drug Screening Models with a Unified XAI Framework](https://doi.org/10.1145/3627673.3679236)|Geonhee Ahn, Md. Mahim Anjum Haque, Subhashis Hazarika, Soo Kyung Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XplainScreen:+Unveiling+the+Black+Box+of+Graph+Neural+Network+Drug+Screening+Models+with+a+Unified+XAI+Framework)|0|
|[AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach](https://doi.org/10.1145/3627673.3679222)|Maryam Amirizaniani, Elias Martin, Tanya Roosta, Aman Chadha, Chirag Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AuditLLM:+A+Tool+for+Auditing+Large+Language+Models+Using+Multiprobe+Approach)|0|
|[Preserving Old Memories in Vivid Detail: Human-Interactive Photo Restoration Framework](https://doi.org/10.1145/3627673.3679215)|SeungYeon Back, Geonho Son, Dahye Jeong, Eunil Park, Simon S. Woo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preserving+Old+Memories+in+Vivid+Detail:+Human-Interactive+Photo+Restoration+Framework)|0|
|[FactCheckBureau: Build Your Own Fact-Check Analysis Pipeline](https://doi.org/10.1145/3627673.3679220)|Oana Balalau, Pablo BertaudVelten, Younes El Fraihi, Garima Gaur, Oana Goga, Samuel Guimaraes, Ioana Manolescu, Brahim Saadi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FactCheckBureau:+Build+Your+Own+Fact-Check+Analysis+Pipeline)|0|
|[Music2P: A Multi-Modal AI-Driven Tool for Simplifying Album Cover Design](https://doi.org/10.1145/3627673.3679223)|Joong Ho Choi, Geonyeong Choi, Ji Eun Han, Wonjin Yang, ZhiQi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Music2P:+A+Multi-Modal+AI-Driven+Tool+for+Simplifying+Album+Cover+Design)|0|
|[Shaded Route Planning Using Active Segmentation and Identification of Satellite Images](https://doi.org/10.1145/3627673.3679234)|Longchao Da, Rohan Chhibba, Rushabh Jaiswal, Ariane Middel, Hua Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shaded+Route+Planning+Using+Active+Segmentation+and+Identification+of+Satellite+Images)|0|
|[A Skill Proficiency Framework for Workforce Learning and Development](https://doi.org/10.1145/3627673.3679228)|Rebecca Dew, Mingzhao Li, Sandya Baratha Raj||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Skill+Proficiency+Framework+for+Workforce+Learning+and+Development)|0|
|[Human-in-the-Loop Feature Discovery for Tabular Data](https://doi.org/10.1145/3627673.3679211)|Andra Ionescu, Zeger Mouw, Efthimia Aivaloglou, Rihan Hai, Asterios Katsifodimos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human-in-the-Loop+Feature+Discovery+for+Tabular+Data)|0|
|[DirDense: A Tool for Mining Dense Subgraphs from a Big Directed Graph](https://doi.org/10.1145/3627673.3679207)|Jalal Khalil, Akhlaque Ahmad, Da Yan, Lyuheng Yuan, Saugat Adhikari, Yang Zhou, Zhe Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DirDense:+A+Tool+for+Mining+Dense+Subgraphs+from+a+Big+Directed+Graph)|0|
|[A One-Health Platform for Antimicrobial Resistance Data Analytics](https://doi.org/10.1145/3627673.3679237)|Benoit Lange, Reza Akbarinia, Florent Masseglia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+One-Health+Platform+for+Antimicrobial+Resistance+Data+Analytics)|0|
|[DiaKoP: Dialogue-based Knowledge-oriented Programming for Neural-symbolic Knowledge Base Question Answering](https://doi.org/10.1145/3627673.3679229)|Zhicheng Lee, Zhidian Huang, Zijun Yao, Jinxin Liu, Amy Xin, Lei Hou, Juanzi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiaKoP:+Dialogue-based+Knowledge-oriented+Programming+for+Neural-symbolic+Knowledge+Base+Question+Answering)|0|
|[EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models](https://doi.org/10.1145/3627673.3679227)|ChunChieh Liao, WeiTing Kuo, IHsuan Hu, YenChen Shih, JunEn Ding, Feng Liu, FangMing Hung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EHR-Based+Mobile+and+Web+Platform+for+Chronic+Disease+Risk+Prediction+Using+Large+Language+Multimodal+Models)|0|
|[Demonstrating PARS: A Decision Support System for Developing Vertical Partitioning Plans](https://doi.org/10.1145/3627673.3679224)|Pengju Liu, Kai Zhong, Cuiping Li, Hong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demonstrating+PARS:+A+Decision+Support+System+for+Developing+Vertical+Partitioning+Plans)|0|
|[OpenTOS: Open-source System for Transfer Learning Bayesian Optimization](https://doi.org/10.1145/3627673.3679225)|Peili Mao, Ke Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OpenTOS:+Open-source+System+for+Transfer+Learning+Bayesian+Optimization)|0|
|[GARF: A Self-supervised Data Cleaning System with SeqGAN](https://doi.org/10.1145/3627673.3679226)|Jinfeng Peng, Hanghai Cui, Derong Shen, Yue Kou, Tiezheng Nie, Tianlong Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GARF:+A+Self-supervised+Data+Cleaning+System+with+SeqGAN)|0|
|[CourtsightTV: An Interactive Visualization Software for Labeling Key Basketball Moments](https://doi.org/10.1145/3627673.3679230)|Alexander Russakoff, Kenny Miller, Vahid Mahzoon, Parsa Esmaeilkhani, Christine Cho, Jaffar Alzeidi, Sandro Hauri, Slobodan Vucetic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CourtsightTV:+An+Interactive+Visualization+Software+for+Labeling+Key+Basketball+Moments)|0|
|[A Scalable Tool for Democratizing Variant Calling on Human Genomes Using Commodity Clusters](https://doi.org/10.1145/3627673.3679221)|Khawar Shehzad, Ajay Kumar, Matthew Schutz, Chase Webb, Polycarp Nalela, Manas Jyoti Das, Praveen Rao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Scalable+Tool+for+Democratizing+Variant+Calling+on+Human+Genomes+Using+Commodity+Clusters)|0|
|[Demonstration of a Multi-agent Framework for Text to SQL Applications with Large Language Models](https://doi.org/10.1145/3627673.3679216)|Chen Shen, Jin Wang, Sajjadur Rahman, Eser Kandogan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demonstration+of+a+Multi-agent+Framework+for+Text+to+SQL+Applications+with+Large+Language+Models)|0|
|[LINKin-PARK: Land Valuation Information and Knowledge in Predictive Analysis and Reporting Kit via Dual Attention-DCCNN](https://doi.org/10.1145/3627673.3679239)|TengYuan Tsou, ShihYu Lai, HsuanChing Chen, JungTsang Yeh, PeiXuan Li, TzuChang Lee, HsunPing Hsieh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LINKin-PARK:+Land+Valuation+Information+and+Knowledge+in+Predictive+Analysis+and+Reporting+Kit+via+Dual+Attention-DCCNN)|0|
|[DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model](https://doi.org/10.1145/3627673.3679219)|Nan Xie, Yuelin Bai, Hengyuan Gao, Ziqiang Xue, Feiteng Fang, Qixuan Zhao, Zhijian Li, Liang Zhu, Shiwen Ni, Min Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeliLaw:+A+Chinese+Legal+Counselling+System+Based+on+a+Large+Language+Model)|0|
|[myCADI: my Contextual Anomaly Detection using Isolation](https://doi.org/10.1145/3627673.3679208)|Véronne Yepmo, Grégory Smits||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=myCADI:+my+Contextual+Anomaly+Detection+using+Isolation)|0|
|[Mastodoner: A Command-line Tool and Python Library for Public Data Collection from Mastodon](https://doi.org/10.1145/3627673.3679217)|Haris Bin Zia, Ignacio Castro, Gareth Tyson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mastodoner:+A+Command-line+Tool+and+Python+Library+for+Public+Data+Collection+from+Mastodon)|0|
|[DetCat: Detecting Categorical Outliers in Relational Datasets](https://doi.org/10.1145/3627673.3679212)|Arthur Zylinski, Abdulhakim Ali Qahtan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DetCat:+Detecting+Categorical+Outliers+in+Relational+Datasets)|0|
|[3DLNews: A Three-decade Dataset of US Local News Articles](https://doi.org/10.1145/3627673.3679165)|Gangani Ariyarathne, Alexander C. Nwala||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3DLNews:+A+Three-decade+Dataset+of+US+Local+News+Articles)|0|
|[BioMAISx: A Corpus for Aspect-Based Sentiment Analysis of Media Representations of Agricultural Biotechnologies in Africa](https://doi.org/10.1145/3627673.3679152)|Patricia Chiril, Trevor Spreadbury, Joeva Rock, Brian DowdUribe, David Uminsky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BioMAISx:+A+Corpus+for+Aspect-Based+Sentiment+Analysis+of+Media+Representations+of+Agricultural+Biotechnologies+in+Africa)|0|
|[Moving Region Representations on the Spread of a Forest Fire](https://doi.org/10.1145/3627673.3679111)|Henrique Macías da Silva, Tiago F. R. Ribeiro, Rogério Luís C. Costa, José Manuel Moreira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Moving+Region+Representations+on+the+Spread+of+a+Forest+Fire)|0|
|[pyPANTERA: A Python PAckage for Natural language obfuscaTion Enforcing pRivacy & Anonymization](https://doi.org/10.1145/3627673.3679173)|Francesco Luigi De Faveri, Guglielmo Faggioli, Nicola Ferro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=pyPANTERA:+A+Python+PAckage+for+Natural+language+obfuscaTion+Enforcing+pRivacy+&+Anonymization)|0|
|[VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities](https://doi.org/10.1145/3627673.3679175)|Shusaku Egami, Takanori Ugai, Swe Nwe Nwe Htun, Ken Fukuda||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VHAKG:+A+Multi-modal+Knowledge+Graph+Based+on+Synchronized+Multi-view+Videos+of+Daily+Activities)|0|
|[A Generative Benchmark Creation Framework for Detecting Common Data Table Versions](https://doi.org/10.1145/3627673.3679157)|Daniel C. Fox, Aamod Khatiwada, Roee Shraga||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Generative+Benchmark+Creation+Framework+for+Detecting+Common+Data+Table+Versions)|0|
|[Dataset Generation for Korean Urban Parks Analysis with Large Language Models](https://doi.org/10.1145/3627673.3679109)|Honggu Kim, Minwoo Kang, Hyeyoung Choi, YunGyung Cheong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dataset+Generation+for+Korean+Urban+Parks+Analysis+with+Large+Language+Models)|0|
|[EUvsDisinfo: A Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles](https://doi.org/10.1145/3627673.3679167)|João Augusto Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina Scarton||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EUvsDisinfo:+A+Dataset+for+Multilingual+Detection+of+Pro-Kremlin+Disinformation+in+News+Articles)|0|
|[LeDQA: A Chinese Legal Case Document-based Question Answering Dataset](https://doi.org/10.1145/3627673.3679154)|Bulou Liu, Zhenhao Zhu, Qingyao Ai, Yiqun Liu, Yueyue Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LeDQA:+A+Chinese+Legal+Case+Document-based+Question+Answering+Dataset)|0|
|[Refining Wikidata Taxonomy using Large Language Models](https://doi.org/10.1145/3627673.3679156)|Yiwen Peng, Thomas Bonald, Mehwish Alam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Refining+Wikidata+Taxonomy+using+Large+Language+Models)|0|
|[InfinityMath: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning](https://doi.org/10.1145/3627673.3679122)|BoWen Zhang, Yan Yan, Lin Li, Guang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InfinityMath:+A+Scalable+Instruction+Tuning+Dataset+in+Programmatic+Mathematical+Reasoning)|0|
|[Advancing Multivariate Time Series Anomaly Detection: A Comprehensive Benchmark with Real-World Data from Alibaba Cloud](https://doi.org/10.1145/3627673.3679128)|Chaoli Zhang, Yingying Zhang, Lanshu Peng, Qingsong Wen, Yiyuan Yang, ChongJiong Fan, Minqi Jiang, Lunting Fan, Liang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Multivariate+Time+Series+Anomaly+Detection:+A+Comprehensive+Benchmark+with+Real-World+Data+from+Alibaba+Cloud)|0|
|[ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction](https://doi.org/10.1145/3627673.3679153)|Yanlin Zhang, Ning Li, Quan Gan, Weinan Zhang, David Wipf, Minjie Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELF-Gym:+Evaluating+Large+Language+Models+Generated+Features+for+Tabular+Prediction)|0|
|[M3: A Multi-Image Multi-Modal Entity Alignment Dataset](https://doi.org/10.1145/3627673.3679126)|Shiqi Zhang, Weixin Zeng, Zhen Tan, Xiang Zhao, Weidong Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M3:+A+Multi-Image+Multi-Modal+Entity+Alignment+Dataset)|0|
|[CheckGuard: Advancing Stolen Check Detection with a Cross-Modal Image-Text Benchmark Dataset](https://doi.org/10.1145/3627673.3679155)|Fei Zhao, Jiawen Chen, Bin Huang, Chengcui Zhang, Gary Warner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CheckGuard:+Advancing+Stolen+Check+Detection+with+a+Cross-Modal+Image-Text+Benchmark+Dataset)|0|
|[GeoAI for Natural Disaster Assessment](https://doi.org/10.1145/3627673.3680257)|Saugat Adhikari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GeoAI+for+Natural+Disaster+Assessment)|0|
|[Assessing Human Viewpoints in Theory of Mind for Large Language Models in Open-Ended Questioning](https://doi.org/10.1145/3627673.3680273)|Maryam Amirizaniani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Human+Viewpoints+in+Theory+of+Mind+for+Large+Language+Models+in+Open-Ended+Questioning)|0|
|[Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems](https://doi.org/10.1145/3627673.3680268)|Andrea Colombo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Knowledge+Graphs+and+LLMs+to+Support+and+Monitor+Legislative+Systems)|0|
|[Realistic Synthetic Signed Network Generation and Analysis](https://doi.org/10.1145/3627673.3680274)|Aikta Arya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Realistic+Synthetic+Signed+Network+Generation+and+Analysis)|0|
|[Demystifying Financial Texts Using Natural Language Processing](https://doi.org/10.1145/3627673.3680258)|Sohom Ghosh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demystifying+Financial+Texts+Using+Natural+Language+Processing)|0|
|[Reliable Knowledge Graph Reasoning with Uncertainty Quantification](https://doi.org/10.1145/3627673.3680266)|Bo Ni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reliable+Knowledge+Graph+Reasoning+with+Uncertainty+Quantification)|0|
|[Graph-theoretical Approach to Enhance Accuracy of Financial Fraud Detection Using Synthetic Tabular Data Generation](https://doi.org/10.1145/3627673.3680267)|DaeYoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-theoretical+Approach+to+Enhance+Accuracy+of+Financial+Fraud+Detection+Using+Synthetic+Tabular+Data+Generation)|0|
|[Towards Effective Fusion and Forecasting of Multimodal Spatio-temporal Data for Smart Mobility](https://doi.org/10.1145/3627673.3680261)|Chenxing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Effective+Fusion+and+Forecasting+of+Multimodal+Spatio-temporal+Data+for+Smart+Mobility)|0|
|[Causal Discovery from Heterogenous Multivariate Time Series](https://doi.org/10.1145/3627673.3680269)|Lei Zan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Discovery+from+Heterogenous+Multivariate+Time+Series)|0|
|[Submodular Optimization: Variants, Theory and Applications](https://doi.org/10.1145/3627673.3680271)|Yanhui Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Submodular+Optimization:+Variants,+Theory+and+Applications)|0|
|[Fairness in Large Language Models in Three Hours](https://doi.org/10.1145/3627673.3679090)|Thang Viet Doan, Zichong Wang, Nhat Nguyen Minh Hoang, Wenbin Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+in+Large+Language+Models+in+Three+Hours)|0|
|[On the Use of Large Language Models for Table Tasks](https://doi.org/10.1145/3627673.3679100)|Yuyang Dong, Masafumi Oyamada, Chuan Xiao, Haochen Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Use+of+Large+Language+Models+for+Table+Tasks)|0|
|[Tabular Data-centric AI: Challenges, Techniques and Future Perspectives](https://doi.org/10.1145/3627673.3679102)|Yanjie Fu, Dongjie Wang, Hui Xiong, Kunpeng Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tabular+Data-centric+AI:+Challenges,+Techniques+and+Future+Perspectives)|0|
|[Frontiers of Large Language Model-Based Agentic Systems - Construction, Efficacy and Safety](https://doi.org/10.1145/3627673.3679105)|Jia He, Reshmi Ghosh, Kabir Walia, Jieqiu Chen, Tushar Dhadiwal, April Hazel, Chandra Inguva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Frontiers+of+Large+Language+Model-Based+Agentic+Systems+-+Construction,+Efficacy+and+Safety)|0|
|[Towards Efficient Temporal Graph Learning: Algorithms, Frameworks, and Tools](https://doi.org/10.1145/3627673.3679104)|Ruijie Wang, Wanyu Zhao, Dachun Sun, Charith Mendis, Tarek F. Abdelzaher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Efficient+Temporal+Graph+Learning:+Algorithms,+Frameworks,+and+Tools)|0|
|[Transforming Digital Forensics with Large Language Models: Unlocking Automation, Insights, and Justice](https://doi.org/10.1145/3627673.3679091)|Eric Xu, Wenbin Zhang, Weifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transforming+Digital+Forensics+with+Large+Language+Models:+Unlocking+Automation,+Insights,+and+Justice)|0|
|[Collecting and Analyzing Public Data from Mastodon](https://doi.org/10.1145/3627673.3679093)|Haris Bin Zia, Ignacio Castro, Gareth Tyson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collecting+and+Analyzing+Public+Data+from+Mastodon)|0|
|[Bridging Knowledge Gaps in LLMs via Function Calls](https://doi.org/10.1145/3627673.3679070)|Kinjal Basu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Knowledge+Gaps+in+LLMs+via+Function+Calls)|0|
|[Planes, Trains and Automobiles: Leverage Multimodal In-Mission Signals for Shopping Journeys](https://doi.org/10.1145/3627673.3679067)|Viet HaThuc, Shasha Li, Arnau Ramisa, Xinliang Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Planes,+Trains+and+Automobiles:+Leverage+Multimodal+In-Mission+Signals+for+Shopping+Journeys)|0|
|[Towards Energy-Efficient Llama2 Architecture on Embedded FPGAs](https://doi.org/10.1145/3627673.3679068)|Han Xu, Xingyuan Wang, Shihao Ji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Energy-Efficient+Llama2+Architecture+on+Embedded+FPGAs)|0|
|[Trustworthy and Responsible AI for Information and Knowledge Management System](https://doi.org/10.1145/3627673.3680111)|Huaming Chen, Jun Zhuang, Yu Yao, Wei Jin, Haohan Wang, Yong Xie, ChiHung Chi, KimKwang Raymond Choo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trustworthy+and+Responsible+AI+for+Information+and+Knowledge+Management+System)|0|
|[Knowledge Graphs for Responsible AI](https://doi.org/10.1145/3627673.3679085)|Edlira Vakaj, Nandana Mihindukulasooriya, Manas Gaur, Arijit Khan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graphs+for+Responsible+AI)|0|
