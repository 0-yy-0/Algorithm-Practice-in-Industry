# KDD2023 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[How Transitive Are Real-World Group Interactions? - Measurement and Reproduction](https://doi.org/10.1145/3580305.3599382)|Sunwoo Kim, Fanchen Bu, Minyoung Choe, Jaemin Yoo, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Transitive+Are+Real-World+Group+Interactions?+-+Measurement+and+Reproduction)|1|
|[Temporal Dynamics-Aware Adversarial Attacks on Discrete-Time Dynamic Graph Models](https://doi.org/10.1145/3580305.3599517)|Kartik Sharma, Rakshit Trivedi, Rohit Sridhar, Srijan Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Dynamics-Aware+Adversarial+Attacks+on+Discrete-Time+Dynamic+Graph+Models)|1|
|[Contrastive Cross-scale Graph Knowledge Synergy](https://doi.org/10.1145/3580305.3599286)|Yifei Zhang, Yankai Chen, Zixing Song, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Cross-scale+Graph+Knowledge+Synergy)|1|
|[FedMultimodal: A Benchmark for Multimodal Federated Learning](https://doi.org/10.1145/3580305.3599825)|Tiantian Feng, Digbalay Bose, Tuo Zhang, Rajat Hebbar, Anil Ramakrishna, Rahul Gupta, Mi Zhang, Salman Avestimehr, Shrikanth Narayanan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedMultimodal:+A+Benchmark+for+Multimodal+Federated+Learning)|1|
|[Querywise Fair Learning to Rank through Multi-Objective Optimization](https://doi.org/10.1145/3580305.3599482)|Debabrata Mahapatra, Chaosheng Dong, Michinari Momma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Querywise+Fair+Learning+to+Rank+through+Multi-Objective+Optimization)|0|
|[E-commerce Search via Content Collaborative Graph Neural Network](https://doi.org/10.1145/3580305.3599320)|Guipeng Xv, Chen Lin, Wanxian Guan, Jinping Gou, Xubin Li, Hongbo Deng, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=E-commerce+Search+via+Content+Collaborative+Graph+Neural+Network)|0|
|[Cognitive Evolutionary Search to Select Feature Interactions for Click-Through Rate Prediction](https://doi.org/10.1145/3580305.3599277)|Runlong Yu, Xiang Xu, Yuyang Ye, Qi Liu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cognitive+Evolutionary+Search+to+Select+Feature+Interactions+for+Click-Through+Rate+Prediction)|0|
|[Binary Embedding-based Retrieval at Tencent](https://doi.org/10.1145/3580305.3599782)|Yukang Gan, Yixiao Ge, Chang Zhou, Shupeng Su, Zhouchuan Xu, Xuyuan Xu, Quanchao Hui, Xiang Chen, Yexin Wang, Ying Shan|Tencent|Large-scale embedding-based retrieval (EBR) is the cornerstone of search-related industrial applications. Given a user query, the system of EBR aims to identify relevant information from a large corpus of documents that may be tens or hundreds of billions in size. The storage and computation turn out to be expensive and inefficient with massive documents and high concurrent queries, making it difficult to further scale up. To tackle the challenge, we propose a binary embedding-based retrieval (BEBR) engine equipped with a recurrent binarization algorithm that enables customized bits per dimension. Specifically, we compress the full-precision query and document embeddings, formulated as float vectors in general, into a composition of multiple binary vectors using a lightweight transformation model with residual multilayer perception (MLP) blocks. We can therefore tailor the number of bits for different applications to trade off accuracy loss and cost savings. Importantly, we enable task-agnostic efficient training of the binarization model using a new embedding-to-embedding strategy. We also exploit the compatible training of binary embeddings so that the BEBR engine can support indexing among multiple embedding versions within a unified system. To further realize efficient search, we propose Symmetric Distance Calculation (SDC) to achieve lower response time than Hamming codes. We successfully employed the introduced BEBR to Tencent products, including Sogou, Tencent Video, QQ World, etc. The binarization algorithm can be seamlessly generalized to various tasks with multiple modalities. Extensive experiments on offline benchmarks and online A/B tests demonstrate the efficiency and effectiveness of our method, significantly saving 30%~50% index costs with almost no loss of accuracy at the system level.|大规模嵌入式检索(EBR)是搜索相关工业应用的基石。给定一个用户查询，EBR 系统的目标是从大量文档中识别相关信息，这些文档的规模可能达到数百亿或数千亿。由于大量文档和高并发查询，存储和计算成本高、效率低，难以进一步扩展。为了解决这一问题，我们提出了一种基于二进制嵌入的检索引擎(BEBR) ，该引擎配备了一个循环二进制算法，可以实现每维定制位。具体地说，我们使用带有剩余多层感知(MLP)块的轻量级变换模型，将通常表示为浮点向量的全精度查询和文档嵌入压缩为多个二进制向量的组合。因此，我们可以为不同的应用程序量身定制位数，以权衡精度损失和成本节约。重要的是，我们使任务无关的二值化模型的有效训练使用一种新的嵌入到嵌入策略。我们还利用二进制嵌入的兼容性训练，使 BEBR 引擎能够在一个统一的系统中支持多个嵌入版本之间的索引。为了进一步实现有效的搜索，我们提出了对称距离计算(SDC)来实现比汉明码更低的响应时间。我们成功地将引进的 BEBR 引入腾讯产品，包括搜狗、腾讯视频、 QQ 世界等。二值化算法可以无缝地推广到具有多种模式的各种任务。对离线基准测试和在线 A/B 测试的大量实验证明了该方法的有效性和有效性，显著节省了30% ~ 50% 的指标成本，在系统级几乎没有准确性的损失。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Binary+Embedding-based+Retrieval+at+Tencent)|0|
|[Optimizing Airbnb Search Journey with Multi-task Learning](https://doi.org/10.1145/3580305.3599881)|Chun How Tan, Austin Chan, Malay Haldar, Jie Tang, Xin Liu, Mustafa Abdool, Huiji Gao, Liwei He, Sanjeev Katariya|Airbnb Inc.|At Airbnb, an online marketplace for stays and experiences, guests often spend weeks exploring and comparing multiple items before making a final reservation request. Each reservation request may then potentially be rejected or cancelled by the host prior to check-in. The long and exploratory nature of the search journey, as well as the need to balance both guest and host preferences, present unique challenges for Airbnb search ranking. In this paper, we present Journey Ranker, a new multi-task deep learning model architecture that addresses these challenges. Journey Ranker leverages intermediate guest actions as milestones, both positive and negative, to better progress the guest towards a successful booking. It also uses contextual information such as guest state and search query to balance guest and host preferences. Its modular and extensible design, consisting of four modules with clear separation of concerns, allows for easy application to use cases beyond the Airbnb search ranking context. We conducted offline and online testing of the Journey Ranker and successfully deployed it in production to four different Airbnb products with significant business metrics improvements.|Airbnb 是一家提供住宿和体验服务的在线市场，在提出最终预订请求之前，客人通常要花费数周时间来探索和比较多个项目。然后，主机可能会在签入之前拒绝或取消每个预订请求。漫长而探索性的搜索旅程，以及平衡客人和主人偏好的需要，为 Airbnb 的搜索排名提出了独特的挑战。在本文中，我们提出了一个新的多任务深度学习模型体系结构 Journey Ranker，以解决这些挑战。Journey Ranker 利用中间的客人行为作为里程碑，包括积极的和消极的，以更好地推动客人成功预订。它还使用上下文信息(如来宾状态和搜索查询)来平衡来宾和主机的首选项。它的模块化和可扩展的设计，由四个模块组成，具有明确的关注点分离，可以很容易地应用到 Airbnb 搜索排名上下文之外的用例。我们对 Journey Ranker 进行了离线和在线测试，并成功地将其部署到四个不同的 Airbnb 产品上，并对业务指标进行了重大改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Airbnb+Search+Journey+with+Multi-task+Learning)|0|
|[User-Regulation Deconfounded Conversational Recommender System with Bandit Feedback](https://doi.org/10.1145/3580305.3599539)|Yu Xia, Junda Wu, Tong Yu, Sungchul Kim, Ryan A. Rossi, Shuai Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-Regulation+Deconfounded+Conversational+Recommender+System+with+Bandit+Feedback)|0|
|[Contrastive Learning for User Sequence Representation in Personalized Product Search](https://doi.org/10.1145/3580305.3599287)|Shitong Dai, Jiongnan Liu, Zhicheng Dou, Haonan Wang, Lin Liu, Bo Long, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+for+User+Sequence+Representation+in+Personalized+Product+Search)|0|
|[LATTE: A Framework for Learning Item-Features to Make a Domain-Expert for Effective Conversational Recommendation](https://doi.org/10.1145/3580305.3599401)|Taeho Kim, Juwon Yu, WonYong Shin, Hyunyoung Lee, JiHui Im, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LATTE:+A+Framework+for+Learning+Item-Features+to+Make+a+Domain-Expert+for+Effective+Conversational+Recommendation)|0|
|[An Empirical Study of Selection Bias in Pinterest Ads Retrieval](https://doi.org/10.1145/3580305.3599771)|Yuan Wang, Peifeng Yin, Zhiqiang Tao, Hari Venkatesan, Jin Lai, Yi Fang, PJ Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Empirical+Study+of+Selection+Bias+in+Pinterest+Ads+Retrieval)|0|
|[PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework in E-commerce](https://doi.org/10.1145/3580305.3599886)|Xiaowen Shi, Fan Yang, Ze Wang, Xiaoxu Wu, Muzhi Guan, Guogang Liao, Yongkang Wang, Xingxing Wang, Dong Wang|Meituan|Re-ranking draws increased attention on both academics and industries, which rearranges the ranking list by modeling the mutual influence among items to better meet users' demands. Many existing re-ranking methods directly take the initial ranking list as input, and generate the optimal permutation through a well-designed context-wise model, which brings the evaluation-before-reranking problem. Meanwhile, evaluating all candidate permutations brings unacceptable computational costs in practice. Thus, to better balance efficiency and effectiveness, online systems usually use a two-stage architecture which uses some heuristic methods such as beam-search to generate a suitable amount of candidate permutations firstly, which are then fed into the evaluation model to get the optimal permutation. However, existing methods in both stages can be improved through the following aspects. As for generation stage, heuristic methods only use point-wise prediction scores and lack an effective judgment. As for evaluation stage, most existing context-wise evaluation models only consider the item context and lack more fine-grained feature context modeling. This paper presents a novel end-to-end re-ranking framework named PIER to tackle the above challenges which still follows the two-stage architecture and contains two mainly modules named FPSM and OCPM. We apply SimHash in FPSM to select top-K candidates from the full permutation based on user's permutation-level interest in an efficient way. Then we design a novel omnidirectional attention mechanism in OCPM to capture the context information in the permutation. Finally, we jointly train these two modules end-to-end by introducing a comparative learning loss. Offline experiment results demonstrate that PIER outperforms baseline models on both public and industrial datasets, and we have successfully deployed PIER on Meituan food delivery platform.|重新排名吸引了越来越多的学术界和行业的关注，它们通过建立项目之间的相互影响模型来重新排列排名列表，以更好地满足用户的需求。许多现有的重新排序方法直接以初始排序列表为输入，通过设计良好的上下文智能模型生成最优排序，从而产生重新排序前的评价问题。同时，评估所有候选排列在实践中带来不可接受的计算成本。因此，为了更好地平衡效率和有效性，在线系统通常采用两阶段的体系结构，使用一些启发式的方法，如束搜索，生成适当数量的候选排列，然后反馈到评估模型，以获得最优的排列。然而，这两个阶段的现有方法可以通过以下几个方面进行改进。对于生成阶段，启发式方法只使用逐点预测得分，缺乏有效的判断。在评价阶段，现有的基于上下文的评价模型大多只考虑项目上下文，缺乏更细粒度的特征上下文建模。本文提出了一种新的端到端重新排序框架 PIER，以解决上述挑战，该框架仍然遵循两阶段的体系结构，包含两个主要模块: FPSM 和 OCPM。将模拟哈希算法应用于基于用户兴趣排列的 FSM 中，有效地从完全排列中选择出最优 K 候选算法。然后在 OCPM 中设计了一种新的全方位注意机制来捕获排列中的上下文信息。最后，通过引入比较学习损失，对这两个模块进行了端到端的联合训练。离线实验结果显示 PIER 在公共和工业数据集上都优于基线模型，我们已经成功地在美团食品配送平台上部署 PIER。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIER:+Permutation-Level+Interest-Based+End-to-End+Re-ranking+Framework+in+E-commerce)|0|
|[Exploiting Intent Evolution in E-commercial Query Recommendation](https://doi.org/10.1145/3580305.3599821)|Yu Wang, Zhengyang Wang, Hengrui Zhang, Qingyu Yin, Xianfeng Tang, Yinghan Wang, Danqing Zhang, Limeng Cui, Monica Cheng, Bing Yin, Suhang Wang, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Intent+Evolution+in+E-commercial+Query+Recommendation)|0|
|[QUERT: Continual Pre-training of Language Model for Query Understanding in Travel Domain Search](https://doi.org/10.1145/3580305.3599891)|Jian Xie, Yidan Liang, Jingping Liu, Yanghua Xiao, Baohua Wu, Shenghua Ni|Alibaba Group; School of Information Science and Engineering, East China University of Science and Technology; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University|In light of the success of the pre-trained language models (PLMs), continual pre-training of generic PLMs has been the paradigm of domain adaption. In this paper, we propose QUERT, A Continual Pre-trained Language Model for QUERy Understanding in Travel Domain Search. QUERT is jointly trained on four tailored pre-training tasks to the characteristics of query in travel domain search: Geography-aware Mask Prediction, Geohash Code Prediction, User Click Behavior Learning, and Phrase and Token Order Prediction. Performance improvement of downstream tasks and ablation experiment demonstrate the effectiveness of our proposed pre-training tasks. To be specific, the average performance of downstream tasks increases by 2.02% and 30.93% in supervised and unsupervised settings, respectively. To check on the improvement of QUERT to online business, we deploy QUERT and perform A/B testing on Fliggy APP. The feedback results show that QUERT increases the Unique Click-Through Rate and Page Click-Through Rate by 0.89% and 1.03% when applying QUERT as the encoder. Our code and downstream task data will be released for future research.|鉴于预训练语言模型(PLM)的成功，通用 PLM 的连续预训练已经成为领域适应的范例。本文提出了一种连续预训练语言模型 QUERT，用于旅游领域搜索中的查询理解。QUERT 针对旅游领域搜索中查询的特点，共同接受了四项量身定制的预先培训任务: 地理感知掩码预测、 Geohash 代码预测、用户点击行为学习以及短语和令牌顺序预测。下游任务的性能改进和烧蚀实验验证了我们提出的预训练任务的有效性。具体来说，在监督和非监督环境下，下游任务的平均性能分别提高了2.02% 和30.93% 。为了检查 QUERT 对在线业务的改进，我们部署 QUERT 并在 Fliggy APP 上进行 A/B 测试。反馈结果显示，当应用 QUERT 作为编码器时，QUERT 增加了0.89% 和1.03% 的唯一点进率和页面点进率。我们的代码和下游任务数据将被公布，以供未来研究使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QUERT:+Continual+Pre-training+of+Language+Model+for+Query+Understanding+in+Travel+Domain+Search)|0|
|[A Collaborative Transfer Learning Framework for Cross-domain Recommendation](https://doi.org/10.1145/3580305.3599758)|Wei Zhang, Pengye Zhang, Bo Zhang, Xingxing Wang, Dong Wang|Meituan|In the recommendation systems, there are multiple business domains to meet the diverse interests and needs of users, and the click-through rate(CTR) of each domain can be quite different, which leads to the demand for CTR prediction modeling for different business domains. The industry solution is to use domain-specific models or transfer learning techniques for each domain. The disadvantage of the former is that the data from other domains is not utilized by a single domain model, while the latter leverage all the data from different domains, but the fine-tuned model of transfer learning may trap the model in a local optimum of the source domain, making it difficult to fit the target domain. Meanwhile, significant differences in data quantity and feature schemas between different domains, known as domain shift, may lead to negative transfer in the process of transferring. To overcome these challenges, we propose the Collaborative Cross-Domain Transfer Learning Framework (CCTL). CCTL evaluates the information gain of the source domain on the target domain using a symmetric companion network and adjusts the information transfer weight of each source domain sample using the information flow network. This approach enables full utilization of other domain data while avoiding negative migration. Additionally, a representation enhancement network is used as an auxiliary task to preserve domain-specific features. Comprehensive experiments on both public and real-world industrial datasets, CCTL achieved SOTA score on offline metrics. At the same time, the CCTL algorithm has been deployed in Meituan, bringing 4.37% CTR and 5.43% GMV lift, which is significant to the business.|在推荐系统中，有多个业务领域可以满足用户的不同兴趣和需求，而每个领域的点进率可能有很大差异，因此需要为不同的业务领域建立点击率预测模型。行业解决方案是对每个领域使用特定于领域的模型或转移学习技术。前者的缺点是其他领域的数据不能被单一的领域模型所利用，而后者则利用来自不同领域的所有数据，但是经过微调的迁移学习模型可能使模型陷入源领域的局部最优，从而难以适应目标领域。同时，不同领域间数据量和特征模式的显著差异，称为领域移位，可能导致传递过程中的负迁移。为了克服这些挑战，我们提出了协作跨域转移学习框架(CCTL)。CCTL 使用对称伴侣网络对源域在目标域上的信息增益进行评估，并使用信息流网络调整每个源域样本的信息传输权重。这种方法可以充分利用其他域数据，同时避免负迁移。此外，表示增强网络用作辅助任务，以保持特定领域的特征。CCTL 在公共和现实世界的工业数据集上进行了全面的实验，在离线指标上取得了 SOTA 评分。与此同时，CCTL 算法已经在美团中部署，带来了4.37% 的点击率和5.43% 的 GMV 提升，这对业务具有重要意义。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Collaborative+Transfer+Learning+Framework+for+Cross-domain+Recommendation)|0|
|[Towards Disentangling Relevance and Bias in Unbiased Learning to Rank](https://doi.org/10.1145/3580305.3599914)|Yunan Zhang, Le Yan, Zhen Qin, Honglei Zhuang, Jiaming Shen, Xuanhui Wang, Michael Bendersky, Marc Najork|University of Illinois at Urbana-Champaign; Google; Google Research|Unbiased learning to rank (ULTR) studies the problem of mitigating various biases from implicit user feedback data such as clicks, and has been receiving considerable attention recently. A popular ULTR approach for real-world applications uses a two-tower architecture, where click modeling is factorized into a relevance tower with regular input features, and a bias tower with bias-relevant inputs such as the position of a document. A successful factorization will allow the relevance tower to be exempt from biases. In this work, we identify a critical issue that existing ULTR methods ignored - the bias tower can be confounded with the relevance tower via the underlying true relevance. In particular, the positions were determined by the logging policy, i.e., the previous production model, which would possess relevance information. We give both theoretical analysis and empirical results to show the negative effects on relevance tower due to such a correlation. We then propose three methods to mitigate the negative confounding effects by better disentangling relevance and bias. Empirical results on both controlled public datasets and a large-scale industry dataset show the effectiveness of the proposed approaches.|无偏学习排序(ULTR)研究的是如何减轻隐性用户反馈数据(如点击)中的各种偏差，近年来受到了广泛的关注。一种流行的 ULTR 方法用于现实世界的应用程序使用一个双塔架构，其中点击建模被分解为一个具有常规输入特征的相关塔，以及一个具有偏倚相关输入(如文档的位置)的偏倚塔。一个成功的因子分解将使相关塔免于偏见。在这项工作中，我们确定了一个关键问题，现有的 ULTR 方法忽略-偏倚塔可以混淆与相关塔通过潜在的真实相关性。具体来说，位置是由测井策略决定的，即先前的生产模型，它将拥有相关信息。我们给出了理论分析和实证结果来说明这种相关性对关联塔的负面影响。然后，我们提出了三种方法，通过更好地分离相关性和偏倚来减轻负面混杂效应。对受控公共数据集和大规模行业数据集的实证结果表明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Disentangling+Relevance+and+Bias+in+Unbiased+Learning+to+Rank)|0|
|[M5: Multi-Modal Multi-Interest Multi-Scenario Matching for Over-the-Top Recommendation](https://doi.org/10.1145/3580305.3599863)|Pengyu Zhao, Xin Gao, Chunxu Xu, Liang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M5:+Multi-Modal+Multi-Interest+Multi-Scenario+Matching+for+Over-the-Top+Recommendation)|0|
|[Accelerating Personalized PageRank Vector Computation](https://doi.org/10.1145/3580305.3599251)|Zhen Chen, Xingzhi Guo, Baojian Zhou, Deqing Yang, Steven Skiena|Fudan University; State University of New York at Stony Brook|Personalized PageRank Vectors are widely used as fundamental graph-learning tools for detecting anomalous spammers, learning graph embeddings, and training graph neural networks. The well-known local FwdPush algorithm approximates PPVs and has a sublinear rate of $O\big(\frac{1}{\alpha\epsilon}\big)$. A recent study found that when high precision is required, FwdPush is similar to the power iteration method, and its run time is pessimistically bounded by $O\big(\frac{m}{\alpha} \log\frac{1}{\epsilon}\big)$. This paper looks closely at calculating PPVs for both directed and undirected graphs. By leveraging the linear invariant property, we show that FwdPush is a variant of Gauss-Seidel and propose a Successive Over-Relaxation based method, FwdPushSOR to speed it up by slightly modifying FwdPush. Additionally, we prove FwdPush has local linear convergence rate $O\big(\tfrac{\text{vol}(S)}{\alpha} \log\tfrac{1}{\epsilon}\big)$ enjoying advantages of two existing bounds. We also design a new local heuristic push method that reduces the number of operations by 10-50 percent compared to FwdPush. For undirected graphs, we propose two momentum-based acceleration methods that can be expressed as one-line updates and speed up non-acceleration methods by$\mathcal{O}\big(\tfrac{1}{\sqrt{\alpha}}\big)$. Our experiments on six real-world graph datasets confirm the efficiency of FwdPushSOR and the acceleration methods for directed and undirected graphs, respectively.|个性化 PageRank 向量广泛用作基本的图形学习工具，用于检测异常垃圾邮件发送者、学习图形嵌入和训练图形神经网络。著名的局部 FwdPush 算法近似于 PPV，其次线性速率为 $O big (frac {1}{ alpha epsilon } big) $。最近的一项研究发现，当需要高精度时，FwdPush 类似于幂迭代法，其运行时间悲观地受到 $O big (frac { m }{ alpha } log frac {1}{ epsilon } big) $的限制。本文主要研究有向图和无向图的 PPV 的计算。通过利用线性不变性，我们证明了 FwdPush 是 Gauss-Seidel 的一个变体，并提出了一个基于逐次超松驰法的方法，FwdPushSOR，通过稍微修改 FwdPush 来加速它。另外，我们证明了 FwdPush 具有局部线性收敛速度 $O big (tfrac { text { vol }(S)}{ alpha } log tfrac {1}{ epsilon } big) $具有两个现有界的优点。我们还设计了一种新的局部启发式推送方法，与 FwdPush 相比减少了10-50% 的操作次数。对于无向图，我们提出了两种基于动量的加速方法，它们可以表示为一行更新，并且可以通过 $mathcal { O } big (tfrac {1}{ sqrt { alpha }} big) $来加速非加速方法。我们在六个实际图形数据集上的实验分别证实了 FwdPushSOR 和有向图和无向图加速方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+Personalized+PageRank+Vector+Computation)|0|
|[Text Is All You Need: Learning Language Representations for Sequential Recommendation](https://doi.org/10.1145/3580305.3599519)|Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, Julian J. McAuley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text+Is+All+You+Need:+Learning+Language+Representations+for+Sequential+Recommendation)|0|
|[MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction](https://doi.org/10.1145/3580305.3599422)|Jianghao Lin, Yanru Qu, Wei Guo, Xinyi Dai, Ruiming Tang, Yong Yu, Weinan Zhang|Shanghai Jiao Tong University; Huawei NoahÊäØ Ark Lab|With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.|随着个性化网上服务的广泛应用，点进率预测越来越受到重视和研究。CTR 预测最突出的特点是它的多领域分类数据格式，以及海量和日益增长的数据量。神经模型的巨大容量有助于在监督式学习范式下消化如此大量的数据，但它们未能充分利用大量的数据，因为1位点击信号不足以指导模型学习特征和实例的能力表示。自监督学习范式为更好地利用大量的用户点击日志，学习更广泛和有效的表示提供了一种更有前途的预训练-微调解决方案。然而，自我监督学习的 CTR 预测仍然是一个悬而未决的问题，因为目前在这方面的工作只是初步和基础。为此，我们提出了一个模型无关预训练(model-agnotic pretraining，MAP)框架，该框架将特征损坏和恢复应用于多领域分类数据，更具体地说，我们推导出两种实用算法: 掩盖特征预测(mFP)和替换特征提取(RFD)。MFP 通过屏蔽和预测一小部分输入特征，深入挖掘每个实例中的特征交互，并引入噪声对比估计(NCE)来处理较大的特征空间。RFD 通过替换和检测输入特征的变化，进一步将 MFP 转化为二进制分类模式，使 CTR 预训练更加简单有效。我们在两个真实世界的大规模数据集(例如，Avazu，Criteo)上的广泛实验证明了这两种方法在几个强骨干(例如，dCNv2，DeepFM)上的优势，并在有效性和效率方面实现了新的最先进的 CTR 预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAP:+A+Model-agnostic+Pretraining+Framework+for+Click-through+Rate+Prediction)|0|
|[Learning to Relate to Previous Turns in Conversational Search](https://doi.org/10.1145/3580305.3599411)|Fengran Mo, JianYun Nie, Kaiyu Huang, Kelong Mao, Yutao Zhu, Peng Li, Yang Liu|University of Montreal; Tsinghua University; Renmin University of China|Conversational search allows a user to interact with a search system in multiple turns. A query is strongly dependent on the conversation context. An effective way to improve retrieval effectiveness is to expand the current query with historical queries. However, not all the previous queries are related to, and useful for expanding the current query. In this paper, we propose a new method to select relevant historical queries that are useful for the current query. To cope with the lack of labeled training data, we use a pseudo-labeling approach to annotate useful historical queries based on their impact on the retrieval results. The pseudo-labeled data are used to train a selection model. We further propose a multi-task learning framework to jointly train the selector and the retriever during fine-tuning, allowing us to mitigate the possible inconsistency between the pseudo labels and the changed retriever. Extensive experiments on four conversational search datasets demonstrate the effectiveness and broad applicability of our method compared with several strong baselines.|会话搜索允许用户多次与搜索系统交互。查询强烈依赖于会话上下文。提高检索效率的一个有效方法是使用历史查询扩展当前查询。但是，并非所有以前的查询都与之相关，并且对于展开当前查询非常有用。本文提出了一种新的方法来选择对当前查询有用的相关历史查询。为了解决缺乏标记训练数据的问题，我们使用伪标记方法根据有用的历史查询对检索结果的影响来注释它们。利用伪标记数据训练选择模型。我们进一步提出了一个多任务学习框架，在微调过程中联合训练选择器和检索器，使我们能够减轻伪标签和更改后的检索器之间可能的不一致性。通过对四个会话搜索数据集的大量实验，证明了该方法的有效性和广泛的适用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Relate+to+Previous+Turns+in+Conversational+Search)|0|
|[PSLOG: Pretraining with Search Logs for Document Ranking](https://doi.org/10.1145/3580305.3599477)|Zhan Su, Zhicheng Dou, Yujia Zhou, Ziyuan Zhao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PSLOG:+Pretraining+with+Search+Logs+for+Document+Ranking)|0|
|[Improving Conversational Recommendation Systems via Counterfactual Data Simulation](https://doi.org/10.1145/3580305.3599387)|Xiaolei Wang, Kun Zhou, Xinyu Tang, Wayne Xin Zhao, Fan Pan, Zhao Cao, JiRong Wen|Huawei Poisson Lab; Renmin University of China|Conversational recommender systems (CRSs) aim to provide recommendation services via natural language conversations. Although a number of approaches have been proposed for developing capable CRSs, they typically rely on sufficient training data for training. Since it is difficult to annotate recommendation-oriented dialogue datasets, existing CRS approaches often suffer from the issue of insufficient training due to the scarcity of training data. To address this issue, in this paper, we propose a CounterFactual data simulation approach for CRS, named CFCRS, to alleviate the issue of data scarcity in CRSs. Our approach is developed based on the framework of counterfactual data augmentation, which gradually incorporates the rewriting to the user preference from a real dialogue without interfering with the entire conversation flow. To develop our approach, we characterize user preference and organize the conversation flow by the entities involved in the dialogue, and design a multi-stage recommendation dialogue simulator based on a conversation flow language model. Under the guidance of the learned user preference and dialogue schema, the flow language model can produce reasonable, coherent conversation flows, which can be further realized into complete dialogues. Based on the simulator, we perform the intervention at the representations of the interacted entities of target users, and design an adversarial training method with a curriculum schedule that can gradually optimize the data augmentation strategy. Extensive experiments show that our approach can consistently boost the performance of several competitive CRSs, and outperform other data augmentation methods, especially when the training data is limited. Our code is publicly available at https://github.com/RUCAIBox/CFCRS.|会话推荐系统(CRS)旨在通过自然语言对话提供推荐服务。虽然已经提出了一些开发有能力的 CRS 的方法，但它们通常依赖于足够的培训数据进行培训。由于很难对面向建议的对话数据集进行注释，现有的 CRS 方法往往因缺乏培训数据而面临培训不足的问题。为了解决这一问题，本文提出了一种 CRS 的 CounterFact 数据模拟方法 CFCRS，以缓解 CRS 中的数据稀缺问题。我们的方法是在反事实数据增强框架的基础上发展起来的，该框架在不干扰整个会话流程的情况下，逐渐将真实对话中的用户偏好重写纳入其中。为了开发这种方法，我们描述了用户偏好的特征，并根据对话所涉及的实体组织了对话流程，设计了一个基于对话流程语言模型的多阶段推荐对话模拟器。在用户偏好和对话模式的指导下，流语言模型可以产生合理、连贯的会话流，进一步实现完整的对话。在该模拟器的基础上，对目标用户交互实体的表示进行干预，设计了一种基于课程表的对抗性训练方法，可以逐步优化数据增强策略。大量实验表明，该方法可以持续提高多个竞争性 CRS 的性能，并且优于其他数据增强方法，特别是在训练数据有限的情况下。我们的代码可以在 https://github.com/rucaibox/cfcrs 上公开获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Conversational+Recommendation+Systems+via+Counterfactual+Data+Simulation)|0|
|[Efficient and Joint Hyperparameter and Architecture Search for Collaborative Filtering](https://doi.org/10.1145/3580305.3599322)|Yan Wen, Chen Gao, Lingling Yi, Liwei Qiu, Yaqing Wang, Yong Li|Tsinghua University; Tencent Inc.; Baidu Inc.|Automated Machine Learning (AutoML) techniques have recently been introduced to design Collaborative Filtering (CF) models in a data-specific manner. However, existing works either search architectures or hyperparameters while ignoring the fact they are intrinsically related and should be considered together. This motivates us to consider a joint hyperparameter and architecture search method to design CF models. However, this is not easy because of the large search space and high evaluation cost. To solve these challenges, we reduce the space by screening out usefulness yperparameter choices through a comprehensive understanding of individual hyperparameters. Next, we propose a two-stage search algorithm to find proper configurations from the reduced space. In the first stage, we leverage knowledge from subsampled datasets to reduce evaluation costs; in the second stage, we efficiently fine-tune top candidate models on the whole dataset. Extensive experiments on real-world datasets show better performance can be achieved compared with both hand-designed and previous searched models. Besides, ablation and case studies demonstrate the effectiveness of our search framework.|自动机器学习(AutoML)技术最近被引入到设计特定数据的协同过滤模型(CF)中。然而，现有的工作要么搜索体系结构或超参数，而忽略了这些内在联系的事实，应该一起考虑。这促使我们考虑联合使用超参数和体系结构搜索方法来设计 CF 模型。然而，这并不容易，因为大搜索空间和高评价成本。为了解决这些挑战，我们通过全面理解各个超参数筛选出有用的超参数选择来减少空间。接下来，我们提出了一个两阶段的搜索算法，以找到适当的配置从缩减的空间。在第一阶段，我们利用次采样数据集的知识来降低评估成本; 在第二阶段，我们有效地微调整整个数据集上的顶级候选模型。在真实世界数据集上的大量实验表明，与手工设计和以前的搜索模型相比，该算法可以获得更好的性能。此外，消融和案例研究证明了我们的搜索框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Joint+Hyperparameter+and+Architecture+Search+for+Collaborative+Filtering)|0|
|[Efficient Single-Source SimRank Query by Path Aggregation](https://doi.org/10.1145/3580305.3599328)|Mingxi Zhang, Yanghua Xiao, Wei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Single-Source+SimRank+Query+by+Path+Aggregation)|0|
|[Adaptive Disentangled Transformer for Sequential Recommendation](https://doi.org/10.1145/3580305.3599253)|Yipeng Zhang, Xin Wang, Hong Chen, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Disentangled+Transformer+for+Sequential+Recommendation)|0|
|[CADENCE: Offline Category Constrained and Diverse Query Generation for E-commerce Autosuggest](https://doi.org/10.1145/3580305.3599787)|Abhinav Anand, Surender Kumar, Nandeesh Kumar, Samir Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CADENCE:+Offline+Category+Constrained+and+Diverse+Query+Generation+for+E-commerce+Autosuggest)|0|
|[PEPNet: Parameter and Embedding Personalized Network for Infusing with Personalized Prior Information](https://doi.org/10.1145/3580305.3599884)|Jianxin Chang, Chenbin Zhang, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song, Kun Gai|Unaffiliated; Kuaishou Technology|With the increase of content pages and display styles in online services such as online-shopping and video-watching websites, industrial-scale recommender systems face challenges in multi-domain and multi-task recommendations. The core of multi-task and multi-domain recommendation is to accurately capture user interests in different domains given different user behaviors. In this paper, we propose a plug-and-play \textit{\textbf{P}arameter and \textbf{E}mbedding \textbf{P}ersonalized \textbf{Net}work (\textbf{PEPNet})} for multi-task recommendation in the multi-domain setting. PEPNet takes features with strong biases as input and dynamically scales the bottom-layer embeddings and the top-layer DNN hidden units in the model through a gate mechanism. By mapping personalized priors to scaling weights ranging from 0 to 2, PEPNet introduces both parameter personalization and embedding personalization. Embedding Personalized Network (EPNet) selects and aligns embeddings with different semantics under multiple domains. Parameter Personalized Network (PPNet) influences DNN parameters to balance interdependent targets in multiple tasks. We have made a series of special engineering optimizations combining the Kuaishou training framework and the online deployment environment. We have deployed the model in Kuaishou apps, serving over 300 million daily users. Both online and offline experiments have demonstrated substantial improvements in multiple metrics. In particular, we have seen a more than 1\% online increase in three major scenarios.|随着在线购物和视频观看网站等在线服务内容页面和显示方式的增加，工业规模的推荐系统面临着多领域、多任务推荐的挑战。多任务、多领域推荐的核心是根据不同的用户行为准确捕获不同领域的用户兴趣。本文针对多领域环境下的多任务推荐问题，提出了一种即插即用的文本参数{ textbf { P }参数和 textbf { E }嵌入式 textbf { P }个性化 textbf { Net } work (textbf { PEPNet })}。PEPNet 以具有强偏差的特征作为输入，通过门机制动态扩展模型中的底层嵌入和顶层 DNN 隐藏单元。通过将个性化前期映射到0到2之间的权重，PEPNet 引入了参数个性化和嵌入个性化。嵌入式个性化网络(EPNet)在多个域下选择和对齐具有不同语义的嵌入式。参数个性化网络(PPNet)影响 DNN 参数以平衡多任务中相互依赖的目标。我们结合快手培训框架和在线部署环境，进行了一系列特殊的工程优化。我们在 Kuaishou 的应用程序中采用了这种模式，每天为超过3亿用户提供服务。这两个在线和离线的实验都显示了在多个指标方面的重大改进。特别是，我们已经看到在三种主要情况下在线增长超过1% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PEPNet:+Parameter+and+Embedding+Personalized+Network+for+Infusing+with+Personalized+Prior+Information)|0|
|[Controllable Multi-Objective Re-ranking with Policy Hypernetworks](https://doi.org/10.1145/3580305.3599796)|Sirui Chen, Yuan Wang, Zijing Wen, Zhiyu Li, Changshuo Zhang, Xiao Zhang, Quan Lin, Cheng Zhu, Jun Xu||Multi-stage ranking pipelines have become widely used strategies in modern recommender systems, where the final stage aims to return a ranked list of items that balances a number of requirements such as user preference, diversity, novelty etc. Linear scalarization is arguably the most widely used technique to merge multiple requirements into one optimization objective, by summing up the requirements with certain preference weights. Existing final-stage ranking methods often adopt a static model where the preference weights are determined during offline training and kept unchanged during online serving. Whenever a modification of the preference weights is needed, the model has to be re-trained, which is time and resources inefficient. Meanwhile, the most appropriate weights may vary greatly for different groups of targeting users or at different time periods (e.g., during holiday promotions). In this paper, we propose a framework called controllable multi-objective re-ranking (CMR) which incorporates a hypernetwork to generate parameters for a re-ranking model according to different preference weights. In this way, CMR is enabled to adapt the preference weights according to the environment changes in an online manner, without retraining the models. Moreover, we classify practical business-oriented tasks into four main categories and seamlessly incorporate them in a new proposed re-ranking model based on an Actor-Evaluator framework, which serves as a reliable real-world testbed for CMR. Offline experiments based on the dataset collected from Taobao App showed that CMR improved several popular re-ranking models by using them as underlying models. Online A/B tests also demonstrated the effectiveness and trustworthiness of CMR.|多阶段排名管道已经成为现代推荐系统中广泛使用的策略，最后阶段的目标是返回一个项目的排名列表，平衡用户偏好、多样性、新颖性等要求。线性标量可以说是最广泛使用的技术合并多个需求到一个优化目标，通过总结需求与一定的偏好权重。现有的最后阶段排序方法通常采用静态模型，在离线训练时确定偏好权重，在线服务时保持不变。当需要修改偏好权重时，模型必须重新训练，这是时间和资源效率低下的。与此同时，最合适的权重可能会因不同的目标用户群体或在不同的时间段(例如，在假日促销期间)而有很大差异。本文提出了一种可控的多目标重排序(CMR)框架，该框架结合了一个超网络，根据不同的偏好权重为重排序模型生成参数。通过这种方式，CMR 能够根据环境变化在线调整偏好权重，而不需要重新训练模型。此外，我们将面向业务的实际任务分为四个主要类别，并将它们无缝地纳入一个新提出的重新排序模型，该模型基于一个演员-评估者框架，作为一个可靠的现实世界的 CMR 测试平台。基于从淘宝应用收集的数据集的离线实验表明，CMR 通过使用它们作为基础模型改进了几个流行的重新排名模型。在线 A/B 测试也证明了 CMR 的有效性和可信性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Controllable+Multi-Objective+Re-ranking+with+Policy+Hypernetworks)|0|
|[CT4Rec: Simple yet Effective Consistency Training for Sequential Recommendation](https://doi.org/10.1145/3580305.3599798)|Liu Chong, Xiaoyang Liu, Rongqin Zheng, Lixin Zhang, Xiaobo Liang, Juntao Li, Lijun Wu, Min Zhang, Leyu Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CT4Rec:+Simple+yet+Effective+Consistency+Training+for+Sequential+Recommendation)|0|
|[S2phere: Semi-Supervised Pre-training for Web Search over Heterogeneous Learning to Rank Data](https://doi.org/10.1145/3580305.3599935)|Yuchen Li, Haoyi Xiong, Linghe Kong, Qingzhong Wang, Shuaiqiang Wang, Guihai Chen, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=S2phere:+Semi-Supervised+Pre-training+for+Web+Search+over+Heterogeneous+Learning+to+Rank+Data)|0|
|[Multi-Label Learning to Rank through Multi-Objective Optimization](https://doi.org/10.1145/3580305.3599870)|Debabrata Mahapatra, Chaosheng Dong, Yetian Chen, Michinari Momma||Learning to Rank (LTR) technique is ubiquitous in the Information Retrieval system nowadays, especially in the Search Ranking application. The query-item relevance labels typically used to train the ranking model are often noisy measurements of human behavior, e.g., product rating for product search. The coarse measurements make the ground truth ranking non-unique with respect to a single relevance criterion. To resolve ambiguity, it is desirable to train a model using many relevance criteria, giving rise to Multi-Label LTR (MLLTR). Moreover, it formulates multiple goals that may be conflicting yet important to optimize for simultaneously, e.g., in product search, a ranking model can be trained based on product quality and purchase likelihood to increase revenue. In this research, we leverage the Multi-Objective Optimization (MOO) aspect of the MLLTR problem and employ recently developed MOO algorithms to solve it. Specifically, we propose a general framework where the information from labels can be combined in a variety of ways to meaningfully characterize the trade-off among the goals. Our framework allows for any gradient based MOO algorithm to be used for solving the MLLTR problem. We test the proposed framework on two publicly available LTR datasets and one e-commerce dataset to show its efficacy.|学习排名(LTR)技术在当今的信息检索系统中无处不在，特别是在搜索排名应用程序中。通常用于训练排名模型的查询条目相关标签通常是对人类行为的嘈杂测量，例如，产品搜索的产品评级。粗测量使得地面真实度排序相对于单一的相关准则是非唯一的。为了解决模糊问题，需要使用多个相关准则来训练模型，从而产生多标签 LTR (MLLTR)。此外，它制定了多个目标，可能是冲突的，但重要的优化同时进行，例如，在产品搜索，排名模型可以训练基于产品质量和购买可能性，以增加收入。在这项研究中，我们利用多目标优化(MOO)方面的 MLLTR 问题，并采用最近开发的 MOO 算法来解决它。具体而言，我们提出了一个总体框架，在这个框架中，可以通过各种方式组合来自标签的信息，以有意义地描述目标之间的权衡。我们的框架允许使用任何基于梯度的 MOO 算法来解决 MLLTR 问题。我们在两个公开的 LTR 数据集和一个电子商务数据集上测试了该框架，以验证其有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Label+Learning+to+Rank+through+Multi-Objective+Optimization)|0|
|[Entity-aware Multi-task Learning for Query Understanding at Walmart](https://doi.org/10.1145/3580305.3599816)|Zhiyuan Peng, Vachik Dave, Nicole McNabb, Rahul Sharnagat, Alessandro Magnani, Ciya Liao, Yi Fang, Sravanthi Rajanala||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity-aware+Multi-task+Learning+for+Query+Understanding+at+Walmart)|0|
|[Improving Training Stability for Multitask Ranking Models in Recommender Systems](https://doi.org/10.1145/3580305.3599846)|Jiaxi Tang, Yoel Drori, Daryl Chang, Maheswaran Sathiamoorthy, Justin Gilmer, Li Wei, Xinyang Yi, Lichan Hong, Ed H. Chi|Google Research; Google Inc; Google Deepmind|Recommender systems play an important role in many content platforms. While most recommendation research is dedicated to designing better models to improve user experience, we found that research on stabilizing the training for such models is severely under-explored. As recommendation models become larger and more sophisticated, they are more susceptible to training instability issues, \emph{i.e.}, loss divergence, which can make the model unusable, waste significant resources and block model developments. In this paper, we share our findings and best practices we learned for improving the training stability of a real-world multitask ranking model for YouTube recommendations. We show some properties of the model that lead to unstable training and conjecture on the causes. Furthermore, based on our observations of training dynamics near the point of training instability, we hypothesize why existing solutions would fail, and propose a new algorithm to mitigate the limitations of existing solutions. Our experiments on YouTube production dataset show the proposed algorithm can significantly improve training stability while not compromising convergence, comparing with several commonly used baseline methods.|推荐系统在许多内容平台中发挥着重要作用。虽然大多数推荐研究致力于设计更好的模型来改善用户体验，但是我们发现，关于稳定此类模型的训练的研究严重不足。随着推荐模型的不断扩大和复杂化，它们更容易受到训练不稳定性问题的影响，如损失发散等，这些问题会导致模型无法使用，浪费大量资源和阻塞模型的发展。在本文中，我们分享了我们的发现和最佳实践，我们学到了提高训练的稳定性的一个真实世界的多任务排名模型 YouTube 的建议。我们给出了模型的一些性质，这些性质导致了训练的不稳定性和对原因的猜测。此外，基于我们对训练不稳定点附近的训练动力学的观察，我们假设为什么现有的解决方案会失败，并提出了一个新的算法来减轻现有解决方案的局限性。我们在 YouTube 生产数据集上的实验表明，与几种常用的基线方法相比，该算法能够在不影响收敛性的前提下显著提高训练的稳定性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Training+Stability+for+Multitask+Ranking+Models+in+Recommender+Systems)|0|
|[PASS: Personalized Advertiser-aware Sponsored Search](https://doi.org/10.1145/3580305.3599882)|Zhoujin Tian, Chaozhuo Li, Zhiqiang Zuo, Zengxuan Wen, Lichao Sun, Xinyue Hu, Wen Zhang, Haizhen Huang, Senzhang Wang, Weiwei Deng, Xing Xie, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PASS:+Personalized+Advertiser-aware+Sponsored+Search)|0|
|[Towards Fairness in Personalized Ads Using Impression Variance Aware Reinforcement Learning](https://doi.org/10.1145/3580305.3599916)|Aditya Srinivas Timmaraju, Mehdi Mashayekhi, Mingliang Chen, Qi Zeng, Quintin Fettes, Wesley Cheung, Yihan Xiao, Manojkumar Rangasamy Kannadasan, Pushkar Tripathi, Sean Gahagan, Miranda Bogen, Rob Roudani|Meta|Variances in ad impression outcomes across demographic groups are increasingly considered to be potentially indicative of algorithmic bias in personalized ads systems. While there are many definitions of fairness that could be applicable in the context of personalized systems, we present a framework which we call the Variance Reduction System (VRS) for achieving more equitable outcomes in Meta's ads systems. VRS seeks to achieve a distribution of impressions with respect to selected protected class (PC) attributes that more closely aligns the demographics of an ad's eligible audience (a function of advertiser targeting criteria) with the audience who sees that ad, in a privacy-preserving manner. We first define metrics to quantify fairness gaps in terms of ad impression variances with respect to PC attributes including gender and estimated race. We then present the VRS for re-ranking ads in an impression variance-aware manner. We evaluate VRS via extensive simulations over different parameter choices and study the effect of the VRS on the chosen fairness metric. We finally present online A/B testing results from applying VRS to Meta's ads systems, concluding with a discussion of future work. We have deployed the VRS to all users in the US for housing ads, resulting in significant improvement in our fairness metric. VRS is the first large-scale deployed framework for pursuing fairness for multiple PC attributes in online advertising.|不同人群的广告印象结果的差异越来越被认为是个性化广告系统中算法偏差的潜在指示。虽然有许多公平的定义，可以适用于个性化系统的背景下，我们提出了一个框架，我们称之为方差减少系统(VRS) ，以实现更公平的结果在元数据的广告系统。VRS 试图通过选定的受保护类别(PC)属性来实现印象的分布，从而以保护隐私的方式将广告合格受众的人口统计数据(广告客户定位标准的功能)与看到该广告的受众的人口统计数据更紧密地联系起来。我们首先定义指标来量化广告印象差异的公平性差距方面的个人电脑属性，包括性别和估计的种族。然后，我们提出了一个印象方差感知的方式重新排名广告的 VRS。我们通过对不同参数选择的大量仿真来评估 VRS，并研究 VRS 对选择的公平性度量的影响。最后给出了 VRS 应用于 Meta 广告系统的在线 A/B 测试结果，并对今后的工作进行了讨论。我们已在美国所有用户的住房广告中部署了 VRS，从而显著改善了我们的公平性指标。VRS 是第一个大规模部署的框架，以追求公平的多个个人电脑属性在网上广告。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fairness+in+Personalized+Ads+Using+Impression+Variance+Aware+Reinforcement+Learning)|0|
|[PlanRanker: Towards Personalized Ranking of Train Transfer Plans](https://doi.org/10.1145/3580305.3599887)|Jia Xu, Wanjie Tao, Zulong Chen, Jin Huang, Huihui Liu, Hong Wen, Shenghua Ni, Qun Dai, Yu Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PlanRanker:+Towards+Personalized+Ranking+of+Train+Transfer+Plans)|0|
|[Multi-factor Sequential Re-ranking with Perception-Aware Diversification](https://doi.org/10.1145/3580305.3599869)|Yue Xu, Hao Chen, Zefan Wang, Jianwen Yin, Qijie Shen, Dimin Wang, Feiran Huang, Lixiang Lai, Tao Zhuang, Junfeng Ge, Xia Hu|Alibaba Group; Rice University; Jinan University; The Hong Kong Polytechnic University|Feed recommendation systems, which recommend a sequence of items for users to browse and interact with, have gained significant popularity in practical applications. In feed products, users tend to browse a large number of items in succession, so the previously viewed items have a significant impact on users' behavior towards the following items. Therefore, traditional methods that mainly focus on improving the accuracy of recommended items are suboptimal for feed recommendations because they may recommend highly similar items. For feed recommendation, it is crucial to consider both the accuracy and diversity of the recommended item sequences in order to satisfy users' evolving interest when consecutively viewing items. To this end, this work proposes a general re-ranking framework named Multi-factor Sequential Re-ranking with Perception-Aware Diversification (MPAD) to jointly optimize accuracy and diversity for feed recommendation in a sequential manner. Specifically, MPAD first extracts users' different scales of interests from their behavior sequences through graph clustering-based aggregations. Then, MPAD proposes two sub-models to respectively evaluate the accuracy and diversity of a given item by capturing users' evolving interest due to the ever-changing context and users' personal perception of diversity from an item sequence perspective. This is consistent with the browsing nature of the feed scenario. Finally, MPAD generates the return list by sequentially selecting optimal items from the candidate set to maximize the joint benefits of accuracy and diversity of the entire list. MPAD has been implemented in Taobao's homepage feed to serve the main traffic and provide services to recommend billions of items to hundreds of millions of users every day.|提要推荐系统为用户推荐了一系列可供浏览和交互的条目，在实际应用中得到了广泛的应用。在提要产品中，用户倾向于连续浏览大量条目，因此以前查看的条目对用户对下列条目的行为有显著影响。因此，主要侧重于提高推荐项目准确性的传统方法对于饲料推荐是次优的，因为它们可能推荐高度相似的项目。为了满足用户在连续查看条目时不断变化的兴趣，对推荐条目序列的准确性和多样性进行考虑是至关重要的。为此，本文提出了一种基于感知多样化的多因素序贯推荐(MPAD)的通用推荐框架，该框架以序贯方式对推荐的准确性和多样性进行联合优化。具体来说，MPAD 首先通过基于图聚类的聚合从用户的行为序列中提取出用户不同尺度的兴趣。然后，MPAD 提出了两个子模型，分别从项目序列的角度通过捕获不断变化的用户兴趣和用户个人对多样性的感知来评价项目的准确性和多样性。这与提要场景的浏览特性一致。最后，MPAD 通过从候选集中依次选择最优项目来生成返回列表，以最大限度地提高整个列表的准确性和多样性。MPAD 已经在淘宝网的主页 feed 中实现，为主流流量提供服务，每天向数亿用户推荐数十亿个项目。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-factor+Sequential+Re-ranking+with+Perception-Aware+Diversification)|0|
|[TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou](https://doi.org/10.1145/3580305.3599922)|Jianxin Chang, Chenbin Zhang, Zhiyi Fu, Xiaoxue Zang, Lin Guan, Jing Lu, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song, Kun Gai|Unaffiliated; Kuaishou Technology|Life-long user behavior modeling, i.e., extracting a user's hidden interests from rich historical behaviors in months or even years, plays a central role in modern CTR prediction systems. Conventional algorithms mostly follow two cascading stages: a simple General Search Unit (GSU) for fast and coarse search over tens of thousands of long-term behaviors and an Exact Search Unit (ESU) for effective Target Attention (TA) over the small number of finalists from GSU. Although efficient, existing algorithms mostly suffer from a crucial limitation: the \textit{inconsistent} target-behavior relevance metrics between GSU and ESU. As a result, their GSU usually misses highly relevant behaviors but retrieves ones considered irrelevant by ESU. In such case, the TA in ESU, no matter how attention is allocated, mostly deviates from the real user interests and thus degrades the overall CTR prediction accuracy. To address such inconsistency, we propose \textbf{TWo-stage Interest Network (TWIN)}, where our Consistency-Preserved GSU (CP-GSU) adopts the identical target-behavior relevance metric as the TA in ESU, making the two stages twins. Specifically, to break TA's computational bottleneck and extend it from ESU to GSU, or namely from behavior length $10^2$ to length $10^4-10^5$, we build a novel attention mechanism by behavior feature splitting. For the video inherent features of a behavior, we calculate their linear projection by efficient pre-computing \& caching strategies. And for the user-item cross features, we compress each into a one-dimentional bias term in the attention score calculation to save the computational cost. The consistency between two stages, together with the effective TA-based relevance metric in CP-GSU, contributes to significant performance gain in CTR prediction.|终身用户行为建模，即在数月甚至数年内从丰富的历史行为中提取用户隐藏的兴趣，在现代 CTR 预测系统中起着核心作用。传统的算法大多遵循两个级联阶段: 一个简单的通用搜索单元(GSU)用于快速和粗略搜索成千上万的长期行为和一个精确搜索单元(ESU)用于有效的目标注意(TA)在少数决赛选手从 GSU。虽然有效，但现有的算法大多受到一个关键的限制: 文本{不一致}目标行为相关度量 GSU 和 ESU 之间。因此，他们的 GSU 通常会错过高度相关的行为，但检索被 ESU 认为无关的行为。在这种情况下，ESU 中的 TA，无论如何分配注意力，大多偏离了真实用户的兴趣，从而降低了整体 CTR 预测的准确性。为了解决这种不一致性，我们提出 textbf { TWo-stage Interest Network (TWIN)} ，其中我们的保持一致性的 GSU (CP-GSU)采用与 ESU 中的 TA 相同的目标行为相关度量，使两个阶段成为孪生的。具体来说，为了打破 TA 的计算瓶颈，将其从 ESU 扩展到 GSU，或者说从行为长度 $10 ^ 2 $扩展到长度 $10 ^ 4-10 ^ 5 $，我们通过行为特征分裂构建了一种新的注意机制。对于视频行为的固有特征，我们通过有效的预计算和缓存策略来计算它们的线性投影。对于用户-项目交叉特征，在注意得分计算中将每个特征压缩为一维偏差项，以节省计算成本。两个阶段之间的一致性，加上 CP-GSU 中有效的基于 TA 的相关度量，有助于提高 CTR 预测的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TWIN:+TWo-stage+Interest+Network+for+Lifelong+User+Behavior+Modeling+in+CTR+Prediction+at+Kuaishou)|0|
|[On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based Graph Collaborative Filtering](https://doi.org/10.1145/3580305.3599450)|Jiayan Guo, Lun Du, Xu Chen, Xiaojun Ma, Qiang Fu, Shi Han, Dongmei Zhang, Yan Zhang|Peking University; Microsoft|Collaborative filtering (CF) is an important research direction in recommender systems that aims to make recommendations given the information on user-item interactions. Graph CF has attracted more and more attention in recent years due to its effectiveness in leveraging high-order information in the user-item bipartite graph for better recommendations. Specifically, recent studies show the success of graph neural networks (GNN) for CF is attributed to its low-pass filtering effects. However, current researches lack a study of how different signal components contributes to recommendations, and how to design strategies to properly use them well. To this end, from the view of spectral transformation, we analyze the important factors that a graph filter should consider to achieve better performance. Based on the discoveries, we design JGCF, an efficient and effective method for CF based on Jacobi polynomial bases and frequency decomposition strategies. Extensive experiments on four widely used public datasets show the effectiveness and efficiency of the proposed methods, which brings at most 27.06% performance gain on Alibaba-iFashion. Besides, the experimental results also show that JGCF is better at handling sparse datasets, which shows potential in making recommendations for cold-start users.|协同过滤(CF)是推荐系统的一个重要研究方向，其目的是根据用户项目交互的信息提供推荐。近年来，Graph CF 由于能够有效地利用用户-项目双向图中的高阶信息来获得更好的建议而引起了越来越多的关注。具体来说，最近的研究表明，图神经网络(GNN)对 CF 的成功归功于其低通滤波效果。然而，目前的研究缺乏研究不同的信号成分如何有助于推荐，以及如何设计策略，以适当地使用它们。为此，本文从谱变换的角度出发，分析了图形滤波器要获得更好的性能所应考虑的重要因素。基于这些发现，我们设计了一种基于 Jacobi 多项式基和频率分解策略的高效率和有效的协同过滤方法。在四个广泛使用的公共数据集上进行的大量实验表明了该方法的有效性和效率，在阿里巴巴-iFashion 平台上最多获得27.06% 的性能增益。此外，实验结果还表明，JGCF 在处理稀疏数据集方面有较好的表现，可以为冷启动用户提供建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Manipulating+Signals+of+User-Item+Graph:+A+Jacobi+Polynomial-based+Graph+Collaborative+Filtering)|0|
|[Off-Policy Evaluation of Ranking Policies under Diverse User Behavior](https://doi.org/10.1145/3580305.3599447)|Haruka Kiyohara, Masatoshi Uehara, Yusuke Narita, Nobuyuki Shimizu, Yasuo Yamamoto, Yuta Saito|Yahoo Japan Corporation; Hanjuku-Kaso Co., Ltd.; Yale University; Cornell University|Ranking interfaces are everywhere in online platforms. There is thus an ever growing interest in their Off-Policy Evaluation (OPE), aiming towards an accurate performance evaluation of ranking policies using logged data. A de-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides an unbiased and consistent value estimate. However, it becomes extremely inaccurate in the ranking setup due to its high variance under large action spaces. To deal with this problem, previous studies assume either independent or cascade user behavior, resulting in some ranking versions of IPS. While these estimators are somewhat effective in reducing the variance, all existing estimators apply a single universal assumption to every user, causing excessive bias and variance. Therefore, this work explores a far more general formulation where user behavior is diverse and can vary depending on the user context. We show that the resulting estimator, which we call Adaptive IPS (AIPS), can be unbiased under any complex user behavior. Moreover, AIPS achieves the minimum variance among all unbiased estimators based on IPS. We further develop a procedure to identify the appropriate user behavior model to minimize the mean squared error (MSE) of AIPS in a data-driven fashion. Extensive experiments demonstrate that the empirical accuracy improvement can be significant, enabling effective OPE of ranking systems even under diverse user behavior.|在线平台中，排序界面无处不在。因此，人们对非策略评估(OPE)越来越感兴趣，其目标是使用日志数据对策略进行准确的性能评估。OPE 的一个事实上的方法是反倾向评分(IPS) ，它提供了一个无偏和一致的价值估计。然而，它变得非常不准确的排名设置，由于其高方差下的大行动空间。为了解决这个问题，以前的研究假设独立或级联用户行为，导致一些排名版本的 IPS。虽然这些估计量在减少方差方面有一定的效果，但是所有现有的估计量都对每个用户适用一个统一的假设，从而导致过度的偏差和方差。因此，这项工作探索了一个更一般的公式，其中用户行为是多样的，可以根据用户上下文而变化。我们证明了所得到的估计量，我们称之为自适应 IPS (AIPS) ，在任何复杂的用户行为下都是无偏的。此外，AIPS 在所有基于 IPS 的无偏估计量之间实现了最小方差。我们进一步开发了一个程序，以确定适当的用户行为模型，从而以数据驱动的方式最大限度地减少 AIPS 的均方差。大量的实验表明，经验的准确性改善可以是显着的，使有效的排名系统的 OPE 即使在不同的用户行为。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Evaluation+of+Ranking+Policies+under+Diverse+User+Behavior)|0|
|[Impatient Bandits: Optimizing Recommendations for the Long-Term Without Delay](https://doi.org/10.1145/3580305.3599386)|Thomas M. McDonald, Lucas Maystre, Mounia Lalmas, Daniel Russo, Kamil Ciosek||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Impatient+Bandits:+Optimizing+Recommendations+for+the+Long-Term+Without+Delay)|0|
|[Unbiased Delayed Feedback Label Correction for Conversion Rate Prediction](https://doi.org/10.1145/3580305.3599536)|Yifan Wang, Peijie Sun, Min Zhang, Qinglin Jia, Jingjie Li, Shaoping Ma|Tsinghua University; Noah’s Ark Lab, Huawei|Conversion rate prediction is critical to many online applications such as digital display advertising. To capture dynamic data distribution, industrial systems often require retraining models on recent data daily or weekly. However, the delay of conversion behavior usually leads to incorrect labeling, which is called delayed feedback problem. Existing work may fail to introduce the correct information about false negative samples due to data sparsity and dynamic data distribution. To directly introduce the correct feedback label information, we propose an Unbiased delayed feedback Label Correction framework (ULC), which uses an auxiliary model to correct labels for observed negative feedback samples. Firstly, we theoretically prove that the label-corrected loss is an unbiased estimate of the oracle loss using true labels. Then, as there are no ready training data for label correction, counterfactual labeling is used to construct artificial training data. Furthermore, since counterfactual labeling utilizes only partial training data, we design an embedding-based alternative training method to enhance performance. Comparative experiments on both public and private datasets and detailed analyses show that our proposed approach effectively alleviates the delayed feedback problem and consistently outperforms the previous state-of-the-art methods.|转化率预测是许多在线应用程序，如数字显示广告的关键。为了捕获动态数据分布，工业系统通常需要每天或每周对最近的数据进行再训练。然而，转换行为的延迟通常会导致不正确的标记，这就是所谓的延迟反馈问题。由于数据稀疏和数据分布的动态性，现有的工作可能无法引入正确的假阴性样本信息。为了直接引入正确的反馈标签信息，我们提出了一种无偏的延迟反馈标签校正框架(ULC) ，它使用一个辅助模型对观测到的负反馈样本进行标签校正。首先，我们从理论上证明了标签校正损失是使用真实标签对甲骨文损失进行的无偏估计。然后，由于没有现成的训练数据用于标签校正，采用反事实标注来构造人工训练数据。此外，由于反事实标注只利用部分训练数据，我们设计了一个基于嵌入的替代训练方法来提高性能。对公共和私人数据集的比较实验和详细的分析表明，我们提出的方法有效地缓解了延迟反馈问题，并始终优于以前的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unbiased+Delayed+Feedback+Label+Correction+for+Conversion+Rate+Prediction)|0|
|[PrefRec: Recommender Systems with Human Preferences for Reinforcing Long-term User Engagement](https://doi.org/10.1145/3580305.3599473)|Wanqi Xue, Qingpeng Cai, Zhenghai Xue, Shuo Sun, Shuchang Liu, Dong Zheng, Peng Jiang, Kun Gai, Bo An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PrefRec:+Recommender+Systems+with+Human+Preferences+for+Reinforcing+Long-term+User+Engagement)|0|
|[Sequence As Genes: An User Behavior Modeling Framework for Fraud Transaction Detection in E-commerce](https://doi.org/10.1145/3580305.3599905)|Ziming Wang, Qianru Wu, Baolin Zheng, Junjie Wang, Kaiyu Huang, Yanjie Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequence+As+Genes:+An+User+Behavior+Modeling+Framework+for+Fraud+Transaction+Detection+in+E-commerce)|0|
|[TransAct: Transformer-based Realtime User Action Model for Recommendation at Pinterest](https://doi.org/10.1145/3580305.3599918)|Xue Xia, Pong Eksombatchai, Nikil Pancha, Dhruvil Deven Badani, PoWei Wang, Neng Gu, Saurabh Vishwas Joshi, Nazanin Farahpour, Zhiyuan Zhang, Andrew Zhai|Pinterest|Sequential models that encode user activity for next action prediction have become a popular design choice for building web-scale personalized recommendation systems. Traditional methods of sequential recommendation either utilize end-to-end learning on realtime user actions, or learn user representations separately in an offline batch-generated manner. This paper (1) presents Pinterest's ranking architecture for Homefeed, our personalized recommendation product and the largest engagement surface; (2) proposes TransAct, a sequential model that extracts users' short-term preferences from their realtime activities; (3) describes our hybrid approach to ranking, which combines end-to-end sequential modeling via TransAct with batch-generated user embeddings. The hybrid approach allows us to combine the advantages of responsiveness from learning directly on realtime user activity with the cost-effectiveness of batch user representations learned over a longer time period. We describe the results of ablation studies, the challenges we faced during productionization, and the outcome of an online A/B experiment, which validates the effectiveness of our hybrid ranking model. We further demonstrate the effectiveness of TransAct on other surfaces such as contextual recommendations and search. Our model has been deployed to production in Homefeed, Related Pins, Notifications, and Search at Pinterest.|为下一步行动预测编码用户活动的序列模型已成为建立网络规模个性化推荐系统的流行设计选择。传统的顺序推荐方法要么利用实时用户操作的端到端学习，要么以离线批量生成的方式单独学习用户表示。本文(1)介绍了 Pinterest 针对 Homefeed 的排名体系结构，这是我们的个性化推荐产品，也是最大的参与表面; (2)提出了 TransAct，一个从用户的实时活动中提取用户短期偏好的顺序模型; (3)描述了我们的混合排名方法，它结合了通过 TransAct 的端到端顺序建模和批量生成的用户嵌入。这种混合方法使我们能够将直接学习实时用户活动的响应性优势与长期学习的批量用户表示的成本效益结合起来。我们描述了烧蚀研究的结果，我们在生产过程中面临的挑战，以及一个在线 A/B 实验的结果，它验证了我们的混合排序模型的有效性。我们进一步展示了 TransAct 在上下文推荐和搜索等其他表面上的有效性。我们的模型已经部署到 Homefeed 的生产环境中，相关的 Pins，通知，和在 Pinterest 上的搜索。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TransAct:+Transformer-based+Realtime+User+Action+Model+for+Recommendation+at+Pinterest)|0|
|[A Personalized Automated Bidding Framework for Fairness-aware Online Advertising](https://doi.org/10.1145/3580305.3599765)|Haoqi Zhang, Lvyin Niu, Zhenzhe Zheng, Zhilin Zhang, Shan Gu, Fan Wu, Chuan Yu, Jian Xu, Guihai Chen, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Personalized+Automated+Bidding+Framework+for+Fairness-aware+Online+Advertising)|0|
|[Privacy Matters: Vertical Federated Linear Contextual Bandits for Privacy Protected Recommendation](https://doi.org/10.1145/3580305.3599475)|Zeyu Cao, Zhipeng Liang, Bingzhe Wu, Shu Zhang, Hangyu Li, Ouyang Wen, Yu Rong, Peilin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy+Matters:+Vertical+Federated+Linear+Contextual+Bandits+for+Privacy+Protected+Recommendation)|0|
|[Approximation Algorithms for Size-Constrained Non-Monotone Submodular Maximization in Deterministic Linear Time](https://doi.org/10.1145/3580305.3599259)|Yixin Chen, Alan Kuhnle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Approximation+Algorithms+for+Size-Constrained+Non-Monotone+Submodular+Maximization+in+Deterministic+Linear+Time)|0|
|[Constraint-aware and Ranking-distilled Token Pruning for Efficient Transformer Inference](https://doi.org/10.1145/3580305.3599284)|Junyan Li, Li Lyna Zhang, Jiahang Xu, Yujing Wang, Shaoguang Yan, Yunqing Xia, Yuqing Yang, Ting Cao, Hao Sun, Weiwei Deng, Qi Zhang, Mao Yang|Microsoft Research; Microsoft; Zhejiang University|Deploying pre-trained transformer models like BERT on downstream tasks in resource-constrained scenarios is challenging due to their high inference cost, which grows rapidly with input sequence length. In this work, we propose a constraint-aware and ranking-distilled token pruning method ToP, which selectively removes unnecessary tokens as input sequence passes through layers, allowing the model to improve online inference speed while preserving accuracy. ToP overcomes the limitation of inaccurate token importance ranking in the conventional self-attention mechanism through a ranking-distilled token distillation technique, which distills effective token rankings from the final layer of unpruned models to early layers of pruned models. Then, ToP introduces a coarse-to-fine pruning approach that automatically selects the optimal subset of transformer layers and optimizes token pruning decisions within these layers through improved $L_0$ regularization. Extensive experiments on GLUE benchmark and SQuAD tasks demonstrate that ToP outperforms state-of-the-art token pruning and model compression methods with improved accuracy and speedups. ToP reduces the average FLOPs of BERT by 8.1x while achieving competitive accuracy on GLUE, and provides a real latency speedup of up to 7.4x on an Intel CPU.|在资源受限的情况下，在下游任务中部署像 BERT 这样的预先训练的变压器模型是具有挑战性的，因为它们的推理成本很高，并且随着输入序列长度的增长而迅速增长。本文提出了一种基于约束和排序的令牌剪枝方法 TOP，该方法在输入序列通过层的同时选择性地去除不必要的令牌，使模型在保持精度的同时提高了在线推理速度。TOP 通过排序-提取令牌精馏技术克服了传统自注意机制中不准确的令牌重要性排序的局限性，该技术将有效的令牌排序从未修剪模型的最后一层提取到修剪模型的早期层。然后，TOP 引入了一种从粗到精的剪枝方法，该方法自动选择变压器层的最优子集，并通过改进的 $L _ 0 $正则化来优化这些变压器层内的令牌剪枝决策。在 GLUE 基准测试和 SQuAD 任务上的大量实验表明，ToP 优于最先进的令牌剪枝和模型压缩方法，具有更高的准确性和加速性。在 GLUE 上，TOP 减少了 BERT 的平均 FLOP 8.1 x，同时实现了具有竞争力的准确性，并且在 Intel CPU 上提供了高达7.4 x 的实际延迟加速。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constraint-aware+and+Ranking-distilled+Token+Pruning+for+Efficient+Transformer+Inference)|0|
|[Learning Balanced Tree Indexes for Large-Scale Vector Retrieval](https://doi.org/10.1145/3580305.3599406)|Wuchao Li, Chao Feng, Defu Lian, Yuxin Xie, Haifeng Liu, Yong Ge, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Balanced+Tree+Indexes+for+Large-Scale+Vector+Retrieval)|0|
|[Generative Flow Network for Listwise Recommendation](https://doi.org/10.1145/3580305.3599364)|Shuchang Liu, Qingpeng Cai, Zhankui He, Bowen Sun, Julian J. McAuley, Dong Zheng, Peng Jiang, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Flow+Network+for+Listwise+Recommendation)|0|
|[Hyper-USS: Answering Subset Query Over Multi-Attribute Data Stream](https://doi.org/10.1145/3580305.3599383)|Ruijie Miao, Yiyao Zhang, Guanyu Qu, Kaicheng Yang, Tong Yang, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyper-USS:+Answering+Subset+Query+Over+Multi-Attribute+Data+Stream)|0|
|[Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective](https://doi.org/10.1145/3580305.3599487)|Teng Xiao, Zhengyu Chen, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reconsidering+Learning+Objectives+in+Unbiased+Recommendation:+A+Distribution+Shift+Perspective)|0|
|[VQNE: Variational Quantum Network Embedding with Application to Network Alignment](https://doi.org/10.1145/3580305.3599542)|Xinyu Ye, Ge Yan, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VQNE:+Variational+Quantum+Network+Embedding+with+Application+to+Network+Alignment)|0|
|[Debiasing Recommendation by Learning Identifiable Latent Confounders](https://doi.org/10.1145/3580305.3599296)|Qing Zhang, Xiaoying Zhang, Yang Liu, Hongning Wang, Min Gao, Jiheng Zhang, Ruocheng Guo|Hong Kong University of Science and Technology; ByteDance Research; University of Virginia; Chongqing University|Recommendation systems aim to predict users' feedback on items not exposed to them.   Confounding bias arises due to the presence of unmeasured variables (e.g., the socio-economic status of a user) that can affect both a user's exposure and feedback. Existing methods either (1) make untenable assumptions about these unmeasured variables or (2) directly infer latent confounders from users' exposure. However, they cannot guarantee the identification of counterfactual feedback, which can lead to biased predictions. In this work, we propose a novel method, i.e., identifiable deconfounder (iDCF), which leverages a set of proxy variables (e.g., observed user features) to resolve the aforementioned non-identification issue. The proposed iDCF is a general deconfounded recommendation framework that applies proximal causal inference to infer the unmeasured confounders and identify the counterfactual feedback with theoretical guarantees. Extensive experiments on various real-world and synthetic datasets verify the proposed method's effectiveness and robustness.|推荐系统旨在预测用户对未接触到的项目的反馈。由于存在不可测量的变量(例如，用户的社会经济地位) ，可以影响用户的曝光和反馈，混淆偏见就会产生。现有的方法要么(1)对这些未测量的变量做出不可靠的假设，要么(2)直接从用户的暴露中推断出潜在的混杂因素。然而，他们不能保证识别反事实反馈，这可能导致偏见的预测。在这项工作中，我们提出了一种新的方法，即可识别的解构者(iDCF) ，它利用一组代理变量(例如，观察到的用户特征)来解决上述非识别问题。提出的 iDCF 是一个通用的解构推荐框架，它应用近因推理来推断不可测量的混杂因素，并用理论保证来识别反事实反馈。在各种真实世界和合成数据集上的大量实验验证了该方法的有效性和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiasing+Recommendation+by+Learning+Identifiable+Latent+Confounders)|0|
|[Hierarchical Invariant Learning for Domain Generalization Recommendation](https://doi.org/10.1145/3580305.3599377)|Zeyu Zhang, Heyang Gao, Hao Yang, Xu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Invariant+Learning+for+Domain+Generalization+Recommendation)|0|
|[Narrow the Input Mismatch in Deep Graph Neural Network Distillation](https://doi.org/10.1145/3580305.3599442)|Qiqi Zhou, Yanyan Shen, Lei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Narrow+the+Input+Mismatch+in+Deep+Graph+Neural+Network+Distillation)|0|
|[Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction](https://doi.org/10.1145/3580305.3599491)|Zhangchi Zhu, Lu Wang, Pu Zhao, Chao Du, Wei Zhang, Hang Dong, Bo Qiao, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang|Microsoft Research; East China Normal University; Microsoft 365|Learning from positive and unlabeled data is known as positive-unlabeled (PU) learning in literature and has attracted much attention in recent years. One common approach in PU learning is to sample a set of pseudo-negatives from the unlabeled data using ad-hoc thresholds so that conventional supervised methods can be applied with both positive and negative samples. Owing to the label uncertainty among the unlabeled data, errors of misclassifying unlabeled positive samples as negative samples inevitably appear and may even accumulate during the training processes. Those errors often lead to performance degradation and model instability. To mitigate the impact of label uncertainty and improve the robustness of learning with positive and unlabeled data, we propose a new robust PU learning method with a training strategy motivated by the nature of human learning: easy cases should be learned first. Similar intuition has been utilized in curriculum learning to only use easier cases in the early stage of training before introducing more complex cases. Specifically, we utilize a novel ``hardness'' measure to distinguish unlabeled samples with a high chance of being negative from unlabeled samples with large label noise. An iterative training strategy is then implemented to fine-tune the selection of negative samples during the training process in an iterative manner to include more ``easy'' samples in the early stage of training. Extensive experimental validations over a wide range of learning tasks show that this approach can effectively improve the accuracy and stability of learning with positive and unlabeled data. Our code is available at https://github.com/woriazzc/Robust-PU|从阳性和未标记数据中学习被称为阳性-未标记(PU)学习，近年来引起了人们的广泛关注。PU 学习中常用的一种方法是使用自组织阈值从未标记的数据中抽取一组伪阴性样本，这样传统的监督方法就可以同时应用于正样本和负样本。由于未标记数据之间存在标记不确定性，训练过程中不可避免地会出现将未标记阳性样本错误分类为阴性样本的错误，甚至可能累积。这些错误经常导致性能下降和模型不稳定。为了减轻标签不确定性的影响，提高正数和未标签数据学习的鲁棒性，我们提出了一种新的鲁棒性 PU 学习方法，其训练策略受人类学习的本质驱动: 应该首先学习简单的情况。在课程学习中也使用了类似的直觉，即在培训的早期阶段只使用较容易的案例，然后再引入更复杂的案例。具体来说，我们利用一种新的“硬度”测量方法来区分未标记样品与具有较大标记噪声的未标记样品。然后采用迭代训练策略，以迭代的方式对训练过程中的负样本选择进行微调，以便在训练的早期阶段包含更多的“简单”样本。通过对大量学习任务的大量实验验证表明，该方法能够有效地提高正数和未标记数据学习的准确性和稳定性。我们的代码可以在 https://github.com/woriazzc/robust-pu 找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Positive-Unlabeled+Learning+via+Noise+Negative+Sample+Self-correction)|0|
|[RankFormer: Listwise Learning-to-Rank Using Listwide Labels](https://doi.org/10.1145/3580305.3599892)|Maarten Buyl, Paul Missault, PierreAntoine Sondag|Amazon|Web applications where users are presented with a limited selection of items have long employed ranking models to put the most relevant results first. Any feedback received from users is typically assumed to reflect a relative judgement on the utility of items, e.g. a user clicking on an item only implies it is better than items not clicked in the same ranked list. Hence, the objectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.   Yet, by only viewing feedback as relative, we neglect the user's absolute feedback on the list's overall quality, e.g. when no items in the selection are clicked. We thus reconsider the standard LTR paradigm and argue the benefits of learning from this listwide signal. To this end, we propose the RankFormer as an architecture that, with a Transformer at its core, can jointly optimize a novel listwide assessment objective and a traditional listwise LTR objective.   We simulate implicit feedback on public datasets and observe that the RankFormer succeeds in benefitting from listwide signals. Additionally, we conduct experiments in e-commerce on Amazon Search data and find the RankFormer to be superior to all baselines offline. An online experiment shows that knowledge distillation can be used to find immediate practical use for the RankFormer.|在 Web 应用程序中，用户只能看到有限的条目，这种情况长期以来一直采用排名模型，将最相关的结果放在第一位。从用户收到的任何反馈通常被认为反映了对项目效用的相对判断，例如，用户点击一个项目只意味着它比没有在同一排名列表中点击的项目要好。因此，学习排名(Learning-to-Rank，LTR)中优化的目标往往是成对的或列表的。然而，由于只把反馈看作是相对的，我们忽略了用户对列表总体质量的绝对反馈，例如，当选择中没有项被点击的时候。因此，我们重新考虑标准的 LTR 范式，并讨论从这个列表范围的信号中学习的好处。为此，我们提出 RankForm 作为一种体系结构，其核心是一个 Transformer，可以联合优化一个新的列表范围评估目标和一个传统的列表式 LTR 目标。我们模拟公共数据集上的隐式反馈，并观察到 RankForm 成功地从列表宽信号中受益。此外，我们在亚马逊搜索数据上进行电子商务实验，发现排名前优于所有离线基线。一个在线实验表明，知识提取可以用来找到直接的实际应用的秩次前。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RankFormer:+Listwise+Learning-to-Rank+Using+Listwide+Labels)|0|
|[Graph-Based Model-Agnostic Data Subsampling for Recommendation Systems](https://doi.org/10.1145/3580305.3599834)|Xiaohui Chen, Jiankai Sun, Taiqing Wang, Ruocheng Guo, LiPing Liu, Aonan Zhang|ByteDance Inc.; ByteDance Research; Tufts University; Apple Inc.|Data subsampling is widely used to speed up the training of large-scale recommendation systems. Most subsampling methods are model-based and often require a pre-trained pilot model to measure data importance via e.g. sample hardness. However, when the pilot model is misspecified, model-based subsampling methods deteriorate. Since model misspecification is persistent in real recommendation systems, we instead propose model-agnostic data subsampling methods by only exploring input data structure represented by graphs. Specifically, we study the topology of the user-item graph to estimate the importance of each user-item interaction (an edge in the user-item graph) via graph conductance, followed by a propagation step on the network to smooth out the estimated importance value.   Since our proposed method is model-agnostic, we can marry the merits of both model-agnostic and model-based subsampling methods. Empirically, we show that combing the two consistently improves over any single method on the used datasets.   Experimental results on KuaiRec and MIND datasets demonstrate that our proposed methods achieve superior results compared to baseline approaches.|数据子采样被广泛用于加速大规模推荐系统的训练。大多数次抽样方法是基于模型的，通常需要一个预先训练的试点模型来通过例如样本硬度来测量数据的重要性。然而，当导频模型被错误指定时，基于模型的子抽样方法就会变质。由于模型错误说明在实际推荐系统中一直存在，因此我们提出了模型无关的数据子抽样方法，只是探讨了用图表示的输入数据结构。具体来说，我们研究了用户项目图的拓扑结构，通过图电导来估计每个用户项目交互(用户项目图中的一条边)的重要性，然后通过网络上的传播步骤来平滑估计的重要性值。由于我们提出的方法是模型不可知的，我们可以结合模型不可知和基于模型的子抽样方法的优点。经验上，我们表明，结合使用这两种方法比使用的数据集上的任何单一方法都要好。在 KuaiRec 和 MIND 数据集上的实验结果表明，与基线方法相比，我们提出的方法取得了更好的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-Based+Model-Agnostic+Data+Subsampling+for+Recommendation+Systems)|0|
|[BOSS: A Bilateral Occupational-Suitability-Aware Recommender System for Online Recruitment](https://doi.org/10.1145/3580305.3599783)|Xiao Hu, Yuan Cheng, Zhi Zheng, Yue Wang, Xinxin Chi, Hengshu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BOSS:+A+Bilateral+Occupational-Suitability-Aware+Recommender+System+for+Online+Recruitment)|0|
|[Real Time Index and Search Across Large Quantities of GNN Experts for Low Latency Online Learning](https://doi.org/10.1145/3580305.3599893)|Johan Kok Zhi Kang, Sien Yi Tan, Bingsheng He, Zhen Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Real+Time+Index+and+Search+Across+Large+Quantities+of+GNN+Experts+for+Low+Latency+Online+Learning)|0|
|[A Preference-aware Meta-optimization Framework for Personalized Vehicle Energy Consumption Estimation](https://doi.org/10.1145/3580305.3599767)|Siqi Lai, Weijia Zhang, Hao Liu|The Hong Kong University of Science and Technology (Guangzhou)|Vehicle Energy Consumption (VEC) estimation aims to predict the total energy required for a given trip before it starts, which is of great importance to trip planning and transportation sustainability. Existing approaches mainly focus on extracting statistically significant factors from typical trips to improve the VEC estimation. However, the energy consumption of each vehicle may diverge widely due to the personalized driving behavior under varying travel contexts. To this end, this paper proposes a preference-aware meta-optimization framework Meta-Pec for personalized vehicle energy consumption estimation. Specifically, we first propose a spatiotemporal behavior learning module to capture the latent driver preference hidden in historical trips. Moreover, based on the memorization of driver preference, we devise a selection-based driving behavior prediction module to infer driver-specific driving patterns on a given route, which provides additional basis and supervision signals for VEC estimation. Besides, a driver-specific meta-optimization scheme is proposed to enable fast model adaption by learning and sharing transferable knowledge globally. Extensive experiments on two real-world datasets show the superiority of our proposed framework against ten numerical and data-driven machine learning baselines. The source code is available at https://github.com/usail-hkust/Meta-Pec.|车辆能耗(VEC)估算的目的是在出行前预测出行所需的总能量，这对出行规划和交通可持续性有重要意义。现有的方法主要集中在从典型行程中提取统计学显著因子，以改善 VEC 估计。然而，在不同的出行环境下，由于个性化驾驶行为的影响，每辆车的能源消耗可能会有很大的差异。为此，本文提出了一个基于偏好感知的元优化框架 Meta-Pec，用于个性化车辆能耗估算。具体来说，我们首先提出了一个时空行为学习模块来捕捉隐藏在历史行程中的潜在驱动偏好。此外，基于驾驶员偏好的记忆，我们设计了一个基于选择的驾驶行为预测模块，以推断特定路线上驾驶员的驾驶模式，为 VEC 估计提供额外的依据和监控信号。此外，提出了一种特定于驱动程序的元优化方案，通过全局学习和共享可转移知识来实现模型的快速自适应。在两个实际数据集上的大量实验表明，我们提出的框架对于十个数字和数据驱动的机器学习基线具有优越性。源代码可在 https://github.com/usail-hkust/meta-pec 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Preference-aware+Meta-optimization+Framework+for+Personalized+Vehicle+Energy+Consumption+Estimation)|0|
|[MUSER: A MUlti-Step Evidence Retrieval Enhancement Framework for Fake News Detection](https://doi.org/10.1145/3580305.3599873)|Hao Liao, Jiahao Peng, Zhanyi Huang, Wei Zhang, Guanghua Li, Kai Shu, Xing Xie|Microsoft Research Asia; Illinois Institute of Technology; Shenzhen University|The ease of spreading false information online enables individuals with malicious intent to manipulate public opinion and destabilize social stability. Recently, fake news detection based on evidence retrieval has gained popularity in an effort to identify fake news reliably and reduce its impact. Evidence retrieval-based methods can improve the reliability of fake news detection by computing the textual consistency between the evidence and the claim in the news. In this paper, we propose a framework for fake news detection based on MUlti-Step Evidence Retrieval enhancement (MUSER), which simulates the steps of human beings in the process of reading news, summarizing, consulting materials, and inferring whether the news is true or fake. Our model can explicitly model dependencies among multiple pieces of evidence, and perform multi-step associations for the evidence required for news verification through multi-step retrieval. In addition, our model is able to automatically collect existing evidence through paragraph retrieval and key evidence selection, which can save the tedious process of manual evidence collection. We conducted extensive experiments on real-world datasets in different languages, and the results demonstrate that our proposed model outperforms state-of-the-art baseline methods for detecting fake news by at least 3% in F1-Macro and 4% in F1-Micro. Furthermore, it provides interpretable evidence for end users.|在网上传播虚假信息的便利使得有恶意的个人能够操纵公众舆论，破坏社会稳定。近年来，基于证据检索的假新闻检测技术在可靠识别假新闻、减少假新闻影响等方面得到了广泛的应用。基于证据检索的方法通过计算新闻中证据与索赔之间的文本一致性，提高了假新闻检测的可靠性。本文提出了一种基于多步证据检索增强(MUSER)的假新闻检测框架，该框架模拟了人类在阅读新闻、总结新闻、查阅资料、推断新闻是真是假的过程中的步骤。该模型可以显式地对多个证据之间的依赖关系进行建模，并通过多步检索对新闻验证所需的证据进行多步关联。此外，该模型通过段落检索和关键证据选择，能够自动收集现有证据，节省了繁琐的人工证据收集过程。我们在不同语言的真实世界数据集上进行了广泛的实验，结果表明，我们提出的模型比最先进的基线方法在 F1-Macro 中检测假新闻的性能至少高出3% ，在 F1-Micro 中高出4% 。此外，它还为最终用户提供了可解释的证据。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MUSER:+A+MUlti-Step+Evidence+Retrieval+Enhancement+Framework+for+Fake+News+Detection)|0|
|[PrivateRec: Differentially Private Model Training and Online Serving for Federated News Recommendation](https://doi.org/10.1145/3580305.3599889)|Ruixuan Liu, Yang Cao, Yanlin Wang, Lingjuan Lyu, Yun Chen, Hong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PrivateRec:+Differentially+Private+Model+Training+and+Online+Serving+for+Federated+News+Recommendation)|0|
|[Hierarchical Projection Enhanced Multi-behavior Recommendation](https://doi.org/10.1145/3580305.3599838)|Chang Meng, Hengyu Zhang, Wei Guo, Huifeng Guo, Haotian Liu, Yingxue Zhang, Hongkun Zheng, Ruiming Tang, Xiu Li, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Projection+Enhanced+Multi-behavior+Recommendation)|0|
|[End-to-End Query Term Weighting](https://doi.org/10.1145/3580305.3599815)|Karan Samel, Cheng Li, Weize Kong, Tao Chen, Mingyang Zhang, Shaleen Kumar Gupta, Swaraj Khadanga, Wensong Xu, Xingyu Wang, Kashyap Kolipaka, Michael Bendersky, Marc Najork||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Query+Term+Weighting)|0|
|[UnifieR: A Unified Retriever for Large-Scale Retrieval](https://doi.org/10.1145/3580305.3599927)|Tao Shen, Xiubo Geng, Chongyang Tao, Can Xu, Guodong Long, Kai Zhang, Daxin Jiang||Large-scale retrieval is to recall relevant documents from a huge collection given a query. It relies on representation learning to embed documents and queries into a common semantic encoding space. According to the encoding space, recent retrieval methods based on pre-trained language models (PLM) can be coarsely categorized into either dense-vector or lexicon-based paradigms. These two paradigms unveil the PLMs' representation capability in different granularities, i.e., global sequence-level compression and local word-level contexts, respectively. Inspired by their complementary global-local contextualization and distinct representing views, we propose a new learning framework, UnifieR, which unifies dense-vector and lexicon-based retrieval in one model with a dual-representing capability. Experiments on passage retrieval benchmarks verify its effectiveness in both paradigms. A uni-retrieval scheme is further presented with even better retrieval quality. We lastly evaluate the model on BEIR benchmark to verify its transferability.|大规模检索是从给定查询的大量集合中回收相关文档。它依靠表示学习将文档和查询嵌入到一个公共的语义编码空间中。根据编码空间的不同，现有的基于预训练语言模型(PLM)的检索方法可以粗略地分为基于密集向量的检索方法和基于词典的检索方法。这两种范式分别揭示了 PLM 在不同粒度上的表示能力，即全局序列级压缩和局部词级上下文。受到它们互补的全局-局部上下文化和不同表示视图的启发，我们提出了一种新的学习框架 UnifieR，它将密集向量检索和基于词典的检索结合在一个具有双重表示能力的模型中。文章检索基准的实验结果验证了该方法在两种范式下的有效性。进一步提出了一种单一检索方案，检索效果更好。最后通过对 BEIR 基准测试模型的评估，验证了该模型的可推广性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UnifieR:+A+Unified+Retriever+for+Large-Scale+Retrieval)|0|
|[Counterfactual Video Recommendation for Duration Debiasing](https://doi.org/10.1145/3580305.3599797)|Shisong Tang, Qing Li, Dingmin Wang, Ci Gao, Wentao Xiao, Dan Zhao, Yong Jiang, Qian Ma, Aoyang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Video+Recommendation+for+Duration+Debiasing)|0|
|[Semantic-Enhanced Differentiable Search Index Inspired by Learning Strategies](https://doi.org/10.1145/3580305.3599903)|Yubao Tang, Ruqing Zhang, Jiafeng Guo, Jiangui Chen, Zuowei Zhu, Shuaiqiang Wang, Dawei Yin, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic-Enhanced+Differentiable+Search+Index+Inspired+by+Learning+Strategies)|0|
|[Doctor Specific Tag Recommendation for Online Medical Record Management](https://doi.org/10.1145/3580305.3599810)|Yejing Wang, Shen Ge, Xiangyu Zhao, Xian Wu, Tong Xu, Chen Ma, Zhi Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Doctor+Specific+Tag+Recommendation+for+Online+Medical+Record+Management)|0|
|[On-device Integrated Re-ranking with Heterogeneous Behavior Modeling](https://doi.org/10.1145/3580305.3599878)|Yunjia Xi, Weiwen Liu, Yang Wang, Ruiming Tang, Weinan Zhang, Yue Zhu, Rui Zhang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On-device+Integrated+Re-ranking+with+Heterogeneous+Behavior+Modeling)|0|
|[Empowering Long-tail Item Recommendation through Cross Decoupling Network (CDN)](https://doi.org/10.1145/3580305.3599814)|Yin Zhang, Ruoxi Wang, Derek Zhiyuan Cheng, Tiansheng Yao, Xinyang Yi, Lichan Hong, James Caverlee, Ed H. Chi|Google Research, Brain Team; Texas AM University|Recommenders provide personalized content recommendations to users. They often suffer from highly skewed long-tail item distributions, with a small fraction of the items receiving most of the user feedback. This hurts model quality especially for the slices without much supervision. Existing work in both academia and industry mainly focuses on re-balancing strategies (e.g., up-sampling and up-weighting), leveraging content features, and transfer learning. However, there still lacks of a deeper understanding of how the long-tail distribution influences the recommendation performance.   In this work, we theoretically demonstrate that the prediction of user preference is biased under the long-tail distributions. This bias comes from the discrepancy of both the prior and conditional probabilities between training data and test data. Most existing methods mainly attempt to reduce the bias from the prior perspective, which ignores the discrepancy in the conditional probability. This leads to a severe forgetting issue and results in suboptimal performance. To address the problem, we design a novel Cross Decoupling Network (CDN) to reduce the differences in both prior and conditional probabilities. Specifically, CDN (i) decouples the learning process of memorization and generalization on the item side through a mixture-of-expert structure; (ii) decouples the user samples from different distributions through a regularized bilateral branch network. Finally, a novel adapter is introduced to aggregate the decoupled vectors, and softly shift the training attention to tail items. Extensive experimental results show that CDN significantly outperforms state-of-the-art approaches on popular benchmark datasets, leading to an improvement in HR@50 (hit ratio) of 8.7\% for overall recommendation and 12.4\% for tail items.|推荐程序向用户提供个性化内容推荐。他们经常受到高度扭曲的长尾条目分布的影响，其中一小部分条目接受了大部分用户反馈。这会损害模型的质量，特别是对于没有很多监督的切片。学术界和业界现有的工作主要集中在重新平衡策略(例如，上调样本和上调权重)、利用内容特性和转移学习。然而，对于长尾分布是如何影响推荐性能的，目前还缺乏更深入的理解。本文从理论上证明了在长尾分布下，用户偏好的预测是有偏差的。这种偏差来自于训练数据和测试数据之间先验概率和条件概率的差异。大多数现有的方法主要试图从先验的角度减少偏差，而忽略了条件概率的差异。这会导致严重的遗忘问题，并导致次优性能。为了解决这一问题，我们设计了一种新的交叉解耦网络(CDN) ，以减少先验概率和条件概率的差异。具体来说，CDN (i)通过混合专家结构解耦项目侧记忆和概括的学习过程; (ii)通过正则化的双边分支网络解耦来自不同分布的用户样本。最后，引入一种新的适配器对解耦后的向量进行聚合，并将训练注意力柔和地转移到尾项上。广泛的实验结果表明，CDN 在流行的基准数据集上显着优于最先进的方法，导致总体推荐的 HR@50(命中率)改善为8.7% ，尾部项目的改善为12.4% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Long-tail+Item+Recommendation+through+Cross+Decoupling+Network+(CDN))|0|
|[PDAS: A Practical Distributed ADMM System for Large-Scale Linear Programming Problems at Alipay](https://doi.org/10.1145/3580305.3599883)|Jun Zhou, Yang Bao, Daohong Jian, Hua Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PDAS:+A+Practical+Distributed+ADMM+System+for+Large-Scale+Linear+Programming+Problems+at+Alipay)|0|
|[Practical Design of Performant Recommender Systems using Large-scale Linear Programming-based Global Inference](https://doi.org/10.1145/3580305.3599183)|Aman Gupta, S. Sathiya Keerthi, Ayan Acharya, Miao Cheng, Borja Ocejo Elizondo, Rohan Ramanath, Rahul Mazumder, Kinjal Basu, J. Kenneth Tay, Rupesh Gupta|Norton Healthcare, University of Kentucky, USA.; Burke Rehabilitation Hospital, USA.; Metro Orthopedics & Sports Therapy, USA.; Children's Hospital, Harvard Medical School, USA.; National Collegiate Athletic Association, USA.; University of Colorado at Denver, USA.; Safe Kids Worldwide, Inc., USA.; Stanford Center on Longevity, USA.; Alzheimer's Drug Discovery Foundation, 57 West 57th Street, Suite 904, New York, NY 10019, USA.; University of Virginia School of Medicine, USA.; George Washington School of Medicine, USA.; Alzheimer's Association, USA.; The Hastings Center, USA.; Baylor College of Medicine, USA.; Boston University Medical Center, USA.; CrowdOptic, Inc., USA.; Banyan Biomarkers, USA.; Novant Health Sports Medicine, USA.; University of California, USA.; Andrews Institute for Orthopaedics and Sports Medicine, USA.; Icahn School of Medicine at Mount Sinai, USA.|Sports-related concussions and repetitive subconcussive exposure are increasingly recognized as potential dangers to paediatric populations, but much remains unknown about the short-term and long-term consequences of these events, including potential cognitive impairment and risk of later-life dementia. This Expert Consensus Document is the result of a 1-day meeting convened by Safe Kids Worldwide, the Alzheimer's Drug Discovery Foundation, and the Andrews Institute for Orthopaedics and Sports Medicine. The goal is to highlight knowledge gaps and areas of critically needed research in the areas of concussion science, dementia, genetics, diagnostic and prognostic biomarkers, neuroimaging, sports injury surveillance, and information sharing. For each of these areas, we propose clear and achievable paths to improve the understanding, treatment and prevention of youth sports-related concussions. In 2009, around 250,000 nonfatal traumatic brain injuries (TBIs) were recorded among individuals aged <19 years in the USA.1 The Centers for Disease Control and Prevention estimate that young people aged 5–18 years sustain 65% of all sports-related concussions.2 Despite recent advances in diagnostic brain imaging and in our understanding of the physics of concussion, long-term cognitive outcomes remain poorly understood. As the physical, cognitive and emotional consequences of concussion gain wider public attention, our incomplete knowledge of how to prevent, diagnose and treat such injuries endangers the health of our children in general and the health of their brains in particular. This Expert Consensus Document is the result of a 1-day meeting of experts in the fields of paediatric and adult TBI, Alzheimer disease (AD) research, genetics, epidemiology, bioethics and sports medicine (Box 1), which was convened in November 2013 by Safe Kids Worldwide, the Alzheimer's Drug Discovery Foundation and the Andrews Institute for Orthopaedics and Sports Medicine. Our primary goal is to highlight critical gaps in our knowledge of child and adolescent concussion. We emphasize areas where research is needed, such as development of diagnostic and predictive biomarkers, elucidation of genetic risk factors, and prediction of short-term and long-term outcomes. In our conclusions, we suggest paths toward improving our understanding of the long-term consequences of sports-related paediatric concussion. The term 'concussion' is often used interchangeably with the term 'mild TBI' (mTBI), a potentially misleading practice considering the possible extent of brain damage and potential for chronic neuropsychological dysfunction following concussion. We should stress, however, that most concussions resolve without sequelae. The American Congress of Rehabilitative Medicine defines mTBI as a Glasgow Coma Scale3 score of 13–15, with loss of consciousness for <30 min and post-traumatic amnesia lasting <24 h.4 Concussion describes a heterogeneous mixture of injury phenotypes that depends on many factors, including the magnitude, location and direction of head impact. Despite a lack of macroscopic structural findings, concussive brain injury involves primary neuronal injury caused by linear and rotational shear forces that disrupt axonal and membrane function (diffuse axonal injury,5 ionic flux and glutamate excitotoxicity), followed by secondary pathophysiological effects including mitochondrial oxidative stress, disruption of cerebral blood flow, compromised blood–brain barrier (BBB) integrity, synaptic dysfunction, and neuroinflammation.6, 7 Lasting neuropsychological post-concussion symptoms (post-concussion syndrome) comprise mood disorders (for example, depression), difficulty concentrating, and memory problems (Box 2).8 Both physical and physiological components of concussive injury can damage the developing brain, putting youths engaged in impact sports at particular risk. The necks and torsos of young athletes are weaker than those of older individuals and, consequently, less force is required to cause brain injury. The developing brain might also be particularly vulnerable to axonal damage caused by the shearing forces of head trauma, which, in youth American football, can exceed linear acceleration forces of 100 g.9 However, the average forces sustained in youth sports will generally be smaller than at higher levels of sport. Proper synaptic development is critical to cognitive and behavioural health.10, 11, 12, 13, 14, 15 Processes such as neurogenesis, competitive synaptic elimination ('pruning'), myelination, and axonal and dendritic arborization continue from prenatal development throughout the lifespan.14 The frontal and temporal lobes are the last areas to mature, and humans experience pruning in these regions into their early 20s,16 so damage to these still-developing areas may have pathophysiological effects on the brain that increase the potential for neuropsychological problems later in life.17 Axonal myelination continues through adolescence into the early 20s, and is susceptible to disruption by injury.10, 18, 19, 20, 21, 22 Early results from the Professional Fighters Brain Health Study, a 5-year longitudinal study of boxers and mixed martial arts fighters, who experienced repetitive subconcussive injuries as well as concussions, indicate that earlier age of first exposure to competitive boxing correlates with greater loss of caudate volume and greater axonal damage in the frontal lobe.23, 24 The young brain also has features that contribute to its resilience. Increased neuroplasticity in this age group has been shown to contribute to better outcomes after focal injuries.25 In addition, developing animals display a shorter window of glucose metabolic impairment in response to repeat TBI than do adult animals.26 Overall, the developing brain shows both vulnerability and resilience after TBI. These interwoven factors are likely to account for differences in the effects of concussion and repeat mTBI on young versus adult brains. A conservative approach to concussion risk and greater efforts to investigate these developmental differences should be given high priority. Most people—both young and old—recover fully from concussions. In children, factors potentially influencing recovery include age and history of concussions.27, 28 In one study, approximately 90% of young adult male athletes experienced symptomatic recovery within 21 days.29 However, in an emergency department study of patients aged 11–22 years (including all causes of concussion, not just sports-related), 15% of the sample still exhibited post-concussion symptoms, including headache, dizziness, 'mental fogginess' and depression, 90 days after injury.30 Several studies suggest that high school American football players are slower to recover from concussion than are college31, 32 and professional players.33 No direct comparisons with adolescents below high school age have yet been published, although a recent study that included a pre-adolescent age group (11–12 years) suggested that post-concussion recovery duration may not exhibit a linear relationship with age,30 as adolescents in this sample took longer to recover than did the pre-adolescent children. These findings, taken together, imply a unique risk of lengthier recovery in the male adolescent age group. Further studies of younger children and females would add greatly to our ability to assess and mitigate risk across the full paediatric and adolescent age span. Youths who sustained one or more concussions within 1 year prior to a new concussion reported more-prolonged symptoms,30 suggesting a possible 'window of vulnerability', and placing previously injured youths at higher risk of protracted recovery. Adolescents aged 11–18 years were nearly 80% more likely to develop post-concussion syndrome after presenting in emergency rooms than were children aged 5–10 years; similarly, presentation with headache doubled the risk of post-concussion syndrome in both children and adolescents.34 Among children treated in an emergency room after mTBI, those aged >6 years reported higher rates of persistent symptoms 3 months post injury than did those aged <6 years.35 Of course, the ability to acquire accurate information about concussion symptoms in children <6 years of age may be limited by a lack of self-awareness of symptoms and the necessary verbal skills to effectively communicate those symptoms. Also, direct comparison of injury severity is not possible from these reports; in fact, the physical heterogeneity of various injuries, taken together with the individual's innate capacity to recover from concussion, makes such comparisons highly challenging. 'Smart helmets' are being used in some speciality research centres to standardize the physical force and angular acceleration that accompanies head hits, and the utility of these helmets to measure and predict impacts that may result in concussion is currently under investigation.36, 37 Young people recovering from concussion can experience important challenges, including altered social and academic development,38, 39, 40 lower scores on general intelligence tests, and decreased school performance (measured by grade-point average).39 Lower levels of parental education and child academic achievement both correlate with poorer concussion recovery.41 Personality traits also play a part; for example, pre-injury anxiety is a risk factor for prolonged recovery periods after sports-related concussion.42 Young athletes of both sexes are at risk of concussion, but girls report higher concussion rates than boys, particularly in high school and college soccer, basketball, and baseball or softball.28, 43, 44, 45 The factors that account for these differences remain uncertain, but might include quality of protective gear, recognition and reporting of concussion symptoms, and neck length and neck muscle strength.46 Differences in recovery trajectories between males and females are also poorly understood. However, one recent study suggested that progesterone levels in females influence post-concussion recovery.47 Hormonal changes during puberty that contribute to migraine headaches might also contribute to sex differences in concussion recovery. Migraine headaches are up to fourfold more common in females than in males after puberty,48, 49 and some evidence suggests that migraineurs recover more slowly after concussion.50, 51 Research is warranted to further delineate sex differences in concussion risk and recovery. In general, adult concussive brain injury is much better understood than its counterpart in children and adolescents. Several points are important to note. First, concussion has multiple, non-harmonized definitions. Second, concussion diagnosis is an imperfect art. Last, in the absence of rapid and inexpensive objective diagnostic measures, concussion remains a clinical diagnosis that is subject to variability—including different thresholds for diagnosis across various subspecialities and across individual physicians, neuropsychologists and athletic trainers—and under-reporting by coaches, parents and young athletes. Without validated diagnostics, concussion will remain a nebulous and under-reported entity, and the accuracy of incidence estimates will continue to be tainted by the differential application of inexact criteria. Repetitive subconcussive trauma can result in structural and functional brain changes.52 White matter abnormalities detected by diffusion tensor imaging (DTI) have been reported in professional soccer players even in the absence of any obvious history of concussions. Compared with swimmers, male professional soccer players showed DTI signal changes suggestive of decreased white matter integrity in several brain regions, which might indicate loss of axonal myelination, similar to changes seen in individuals with mTBI.53 Collegiate ice hockey players exhibited similar white matter changes over the course of a season.54, 55, 56, 57 In addition, repetitive subconcussive head impacts in collegiate American football players have been linked, in a dose-dependent manner, to deficits in BBB integrity, potential loss of white matter integrity, and cognitive dysfunction.58 These findings probably reflect some level of risk for youths who sustain repetitive subconcussive head impacts, although little research has been devoted specifically to this topic. A metric to track head impacts—that is, a 'hit count'—has been proposed,59 and could serve as one factor to determine cumulative risk exposure. One challenge of this approach is to accurately define the parameters of a 'hit', but improved biosensors show some promise in this regard. Similar to a 'pitch count' in baseball, this concept has also recently been proposed for boxers.24 No evidence is currently available to show a causal link between repetitive subconcussive head impacts in youth and dementia later in life, and such metrics could prove invaluable if validated by future studies correlating head impacts with subsequent neuropsychological dysfunction. In adults, TBI, including concussion,60, 61, 62 might increase an individual's risk of developing neurodegenerative disease,63, 64 including AD and chronic traumatic encephalopathy (CTE), a disease associated exclusively with repetitive head trauma.65, 66 TBI may also increase the risk of developing Parkinson disease (PD),67 although the relationship between mTBI and PD risk remains uncertain.68 In paediatric populations, particularly young athletes, the effects of single or repetitive concussions on the risk of later-life neurodegeneration and dementia are unknown. CTE was first described symptomatically in the late 1920s as 'punch-drunk' dementia in boxers,69 was later described as 'dementia pugilistica',70 and was first described pathologically in 1973.71 Since the identification of CTE in a former professional American football player in 2005,72 and additional intensive pathological studies, this condition has gained widespread public attention, and has now been identified in brains of former ice hockey, baseball, rugby and soccer players,73 wrestlers,74 and military veterans.75, 76 The prevalence and incidence of CTE in amateur and professional athletes is still unknown, adding to difficulties in discussing its epidemiology and population risks for athletes. Although CTE is primarily considered to be a neurodegenerative disease that sometimes results from a career of either collegiate or professional contact sports, cases of CTE have been reported in high school athletes.77 This finding suggests that long sporting careers are not required for CTE development, and that youth athletes represent an at-risk population. Emerging evidence suggests that clinical CTE symptoms can be grouped into two common presentations: cognitive and mood–behavioural.78, 79 Subjective memory complaints such as anterograde amnesia are common, as are mood disorders including anxiety or depression,79 and reduced executive function, which can result in disinhibition and impaired decision-making skills.80 These clinical symptoms define disease severity.81 The neurodegenerative pathophysiology of CTE is complex, and the neurological sequelae are poorly understood. In severe cases, the cerebral cortex and medial temporal lobes seem most profoundly affected,81, 82 with pathology characterized by neurofibrillary tangles composed of phosphorylated tau79 and, in some cases, TAR DNA-binding protein 43 pathology.83 CTE is also associated with marked atrophy, notably in the frontal cortex and medial temporal lobe, as well as in the mammillary bodies, thalamus and hypothalamus.79 Confirmed clinical diagnosis of CTE remains autopsy-based.84 Given the uncertainty over whether the tauopathy described in CTE is causative of the clinical phenotype, and the fact that most professional and collegiate athletes do not develop CTE, it is vital to understand whether early exposure to concussion is associated with other forms of neurodegeneration and cognitive dysfunction, including chronic neurocognitive impairment (CNI). Important clinical distinctions exist between CTE and CNI,28, 51 some of which make direct comparisons difficult. CTE is an emerging clinical and pathological condition that involves progressive deterioration of neurological and cognitive function in multiple domains, and is diagnosed primarily at autopsy. Conversely, the CNI phenotype is not necessarily progressive, and is characterized by functional decline from group averages or baseline functioning established before TBI. CNI can be diagnosed clinically through neuropsychological testing. No causal link between CNI and head trauma has yet been confirmed, but a dose-dependent risk has consistently been found in professional athletes.28 In addition, almost half of the studies conducted in amateur athletes have found an elevated risk of CNI.28 Whether similar risk associations are present in younger populations remains to be determined. One hypothesis is that CNI represents a prodromal—but not inevitable—step toward CTE, analogous to the relationship between mild cognitive impairment (MCI) and AD.85, 86 Alternatively, CNI may represent static impairment without degeneration. Our current lack of understanding of the basic biological underpinnings of CNI and CTE underscores the need for more research. Increased knowledge of the biology of both conditions, as well as early detection of CNI in athletes (in particular, youth athletes), may drive interventions to stem the development of further cognitive impairment, and could also aid validation of putative biomarkers. Assessment of CNI via tau imaging may help determine the likelihood of progression to CTE. The field of concussion genetics, especially in paediatric populations, is still in its infancy. Although repetitive head impacts seem necessary for the development of CTE, other factors, including genetics, are likely to have an important role, as most concussed athletes do not develop CTE.87 The genetic risk factors for CTE probably overlap with those that influence susceptibility to and recovery from concussion, and genetic risk factors for AD are providing important clues to the identity of these factors. The ε4 allele of apolipoprotein E (APOE ε4), the most important genetic risk factor for AD identified to date,88 critically affects the CNS injury response,89 in particular, amyloid-β (Aβ) clearance from the brain. The three alleles of APOE confer varying degrees of AD risk: APOE ε2 reduces the risk, APOE ε3, the most common allele, represents baseline risk with which other variants are compared, and APOE ε4 increases the risk.90, 91 Studies suggest an interaction between APOE ε4 and sex, such that APOE ε4-related risk of AD is more prominent in women than in men.92, 93 The APOE genotype acts synergistically with TBI in increasing the risk of AD,94 although its hypothesized risk association with CTE as an outcome of repetitive mTBI requires more study.95 No consensus has yet been reached on the effects of APOE isotype on the outcome of paediatric TBI, but data from adults suggest that APOE ε4 negatively influences concussion outcomes. Several studies indicate that possession of at least one APOE ε4 allele is associated with poorer cognition and lasting neuropsychological impairment after concussion in professional American football players,96 boxers95 and other adults,97, 98, 99, 100 although other studies found no such association.101, 102 Some evidence points to polymorphisms in both the APOE gene and its promoter as contributory factors to concussion risk in college athletes.103, 104 Another study did not identify a role for APOE ε4 in concussion risk,105 although this allele might increase the risk of dementia following midlife or late-life mTBI.106 Drawing conclusions from these conflicting studies is difficult, owing to small sample sizes and differing methodologies. In children, little is known about the relationship between APOE ε4 and neuropsychological outcomes after concussion, and APOE ε4 testing is not routine in paediatric TBI studies. In 2012, Kurowski reviewed the few existing studies and combined the results of three studies107, 108, 109 that used the Glasgow Outcome Scale.110 In the combined sample (252 children), the risk of poor clinical outcomes after 6–12 months was over twofold higher in APOE ε4 carriers than in noncarriers (19% versus 9%). However, these studies included a broad developmental range of children with heterogeneous injuries, and did not account for a possible interaction between age and genotype. In addition, the interaction between APOE and sex has not been studied in the context of concussion. Improved prospective studies are warranted to clarify these connections. Incorporation of genetics into paediatric concussion research is fraught with complicated challenges, including acquisition of parental consent and informed consent for a child, perceived stigmatization of clinical study participants, the actionability of the genetic knowledge obtained, and potential concerns regarding insurability (particularly long-term care insurance). Studies of adults who learn of their APOE ε4+ status demonstrate that many are willing to make lifestyle modifications, including increased exercise and improved medication management,111 as well as increased purchases of health and long-term care insurance.112, 113 Education about new genetic knowledge and corresponding disease risk is essential, as demonstrated by the substantial discordance between an individual's personal feelings about the implications of the acquired knowledge and the actual consequences of increased dementia risk.114 The effects of APOE genetic knowledge on children, their families and decision-making processes regarding participation in impact sports remain unclear. The influence of APOE genotype on concussion risk and recovery in this age group also needs further elucidation. If future studies find that, for any particular level of impact, children with APOE ε4+ status are at greater risk of concussion or poor recovery than are their APOE ε4− peers, consideration should be given to genetic testing of school-age athletes before participation in impact sports. Careful studies of high school and younger athletes are required to fully understand the nuances of genetic influences. Future research into youth concussion outcomes, including cognitive outcomes and risk of dementia, should include APOE genotyping wherever possible. New APOE studies should standardize research methodologies and reporting measures, including the collection of 'common data elements', to ensure valid comparison across studies.110, 115 The APOE genotype is not necessarily a non-modifiable risk factor for concussion recovery: therapies being developed for AD include drugs that modify the interaction between the ApoE4 protein and Aβ, which might also be applicable to paediatric concussion.116, 117 The Val66Met polymorphism in the gene encoding brain-derived neurotrophic factor has been linked to better outcomes after mTBI,118 but worse outcomes after focal penetrating brain injury.119 Polymorphisms in genes involved in dopaminergic signalling may also help to account for the wide range of TBI outcomes.120 In addition, the Rep1 polymorphism in the promoter region of the α-synuclein gene might increase the risk of PD after head injury.121 To advance our understanding of concussion risk and management, large, prospective, population-based genome-wide association studies (GWAS) and whole-genome sequencing studies should be conducted to identify other genetic variants—possibly of low frequency or low penetrance—that modify the risk of prolonged recovery, poor cognitive outcomes or dementia.122 Such studies will require large-scale data sharing, and must address issues of ethics, privacy, and potential implications for insurability and employability. Despite progress in identifying possible cerebrospinal fluid (CSF) and blood-based biomarkers that might be applied to adult TBI management, no clinically validated biomarkers are available for either the adult or the paediatric population. Paediatric concussions present with even greater clinical variability than do adult concussions; therefore, biomarkers have special potential for improving concussion diagnosis in children. Of note, most TBI biomarkers have been studied in the context of moderate to severe TBI, leaving us with obvious gaps in our knowledge of mTBI biomarkers, especially in children. Biomarker development has been critical to the advancement of AD therapeutics. CSF-based biomarkers are already being employed to identify at-risk patients and to improve the design of both epidemiological studies and clinical trials.123 New PET radioligands, such as amyloid-labelling agents (three of which are now FDA-approved), can be used both diagnostically and to improve neuropathology-based patient stratification for clinical trials. Several tau imaging agents are also in human trials, and their utility in tauopathies, including CTE, is rapidly being established. As with fluid-based biomarkers, there are currently no neuroimaging biomarkers sensitive or specific enough to diagnose concussion or CTE in either adults or children. No TBI diagnostic or therapeutic agents have yet been approved by the FDA, and validation of concussion biomarkers could accelerate the development of such agents. Efforts must be made, however, to ensure the cost-effectiveness and wide availability of clinical biomarker testing. Also, given the risks associated with lumbar puncture, ethical concerns regarding sampling of CSF from concussed youths for biomarker research should be addressed. Promising findings in adult fluid-based biomarker research must be explored in paediatric populations. Putative concussion biomarkers have emerged sporadically in the scientific literature over the past few decades, the most prominent being S100 calcium-binding protein B (S100B), a nonspecific marker of astrocyte activation. The presence of S100B in serum may indicate loss of BBB integrity. Elevated serum and CSF levels of S100B have been observed in adult boxers after matches, and correlate positively with the number and severity of head impacts.124, 125 Increased serum S100B levels have also been observed in concussed professional ice hockey players,126 with levels measured 1 h post-concussion predicting symptomatic recovery time. However, S100B levels were also raised after controlled play where no concussions occurred, indicating that this marker is not injury-specific.126 Indeed, S100B serum levels are elevated in adult trauma patients without head injury.127, 128, 129 Other research suggests that initial post-concussion S100B levels are poor predictors of recovery.130 As with all biomarkers, the role of S100B in TBI management in children is even less clear,131 with some arguing that this marker has little diagnostic or prognostic utility in paediatric populations.132 In a study of children with TBI aged ≤15 years, those <5 years or >9 years of age had higher serum levels of S100B than did those aged 5–9 years.133 S100B may, therefore, be an inadequate marker to distinguish between symptomatic and asymptomatic children with concussion,133 and the utility of S100B in diagnostics and outcome prognosis is questionable.134, 135, 136 Neuron-specific enolase (NSE) is a marker of neuronal injury, but its usefulness as a serum or CSF biomarker remains uncertain.133, 134, 135, 136, 137 Elevated serum NSE levels have been observed after head impacts in boxers,124 but were also seen in ice hockey players after a match where no concussions occurred.126 Serum NSE levels failed to predict recovery time after concussion,126 and might not correlate with injury severity in children.133 In children aged ≤15 years, serum NSE levels correlate inversely with age.133 Once released into the blood, NSE has slow elimination kinetics, making it difficult to distinguish primary from secondary neuronal injuries on the basis of NSE levels.138, 139 Neurofilament light chain and glial fibrillary acidic protein (GFAP) are CSF neuron-specific and glial-specific damage markers, respectively, and are both elevated in CSF in adult boxers after fights.125, 137, 140 Little is known about either marker in the context of paediatric concussion, but a preliminary study in children and young adults suggested that serum GFAP levels within 72 h after concussion correlate with symptom burden up to 1 month post injury.141 The neuron-specific protein UCH-L1 (ubiquitin carboxyl-terminal hydrolase isozyme L1) was first linked to neurodegenerative pathology through its involvement in PD,142 and its presence in serum was later identified as a biomarker for severe TBI.143, 144, 145 Serum levels of UCH-L1 may have diagnostic utility in concussion,146 but recent evidence suggests a lack of correlation between elevated serum levels and subconcussive hits.147 The clinical utility of UCH-L1 in paediatric populations warrants further study. Perhaps the most promising advances in adult fluid-based TBI biomarkers concern tau protein. Serum or CSF tau levels are thought to indicate axonal damage, as tau normally resides in axons, where it stabilizes microtubules. Serum tau is proteolytically cleaved,148 and in patients with AD, levels of cleaved tau in CSF might correlate with cognitive function.149 Tau levels in CSF and blood are elevated in boxers after a match, and CSF tau levels correlate with the quality and quantity of head impacts.125, 150 Recent evidence suggests that tau levels are elevated in the blood of ice hockey players after concussion, and may be useful in predicting recovery time.126 Questions remain, however, with several studies reporting little or no value of serum cleaved tau for predicting post-concussion syndrome or long-term outcomes.130, 151 The potential of tau as a biomarker in children remains unclear, with no studies conducted to date. In fact, the reliability of serum tau as a biomarker has not yet been established for any indication. The likelihood is that no single biomarker will suffice to diagnose paediatric concussion or predict outcomes. In addition, few studies have examined the interactions between genetic make-up and putative biomarkers. As our understanding of the relationships of biomarkers to injury severity and to each other increases, development of biomarker panels, perhaps incorporating inflammatory and oxidative markers,152 should be considered. Future studies should attempt to further define these relationships and establish the clinical value of biomarker panels, factoring in commercial cost and practical feasibility. Recent advances in metabolomics, lipidomics and proteomics—in particular, the search for metabolomic and lipidomic markers for AD—might inform future research into biomarkers for concussion and subconcussive injuries. Several recent studies propose altered metabolite and lipid profiles associated with MCI and AD.153, 154, 155, 156 Data from animal models suggest that lipid and metabolite changes accompany both acute and chronic post-concussion periods, and could be useful for predicting recovery trajectory,157, 158 but these findings have yet to be validated in humans. Expanding the biomarker search beyond blood and CSF to saliva and urine159 might improve the ability to obtain measurements rapidly and noninvasively, particularly from children. Sampling of CSF from children, particularly when rapid assessment is desirable, is largely impractical. Mondello et al. proposed a set of useful criteria for evaluating TBI biomarkers that should allow more-streamlined development and validation.137 Any validated biomarker panel must, inevitably, be a component of a larger, multimodal diagnostic suite that may include structural and functional imaging and neuropsychological testing. When designing future biomarker studies, the potential for FDA approval should be considered, in order to expedite approval for clinical use. Although concussion remains a clinical diagnosis, neuroimaging techniques are improving our understanding of the structural and functional consequences in adults. Neuroimaging in paediatric populations may be limited by several factors; for example, measurements of longitudinal changes after concussion are complicated by the background of a dynamic, immature brain. No imaging techniques have been validated as diagnostic tools for concussion, and the correlation between imaging findings and clinically measurable cognitive or behavioural functions is variable. Tools such as volumetric imaging, DTI and functional MRI (fMRI)—in particular, arterial spin labelling—are currently being explored.160, 161 Fractional anisotropy (FA), as measured by DTI, allows inference of the structural integrity of white matter tracts, which are commonly disrupted after TBI. The clinical implications of FA change remain controversial, as both increased and decreased FA has been observed in concussion studies.162, 163, 164, 165, 166 These discrepancies may be due, in part, to the considerable spatial heterogeneity in the brain areas examined,167 as well as differences in the post-injury interval. FA may still have prognostic value, with evidence suggesting that the direction and magnitude of change correlates with clinical outcomes;166, 168 however, this idea awaits validation in both paediatric and adult populations. FA might lack the necessary sensitivity to fully appreciate changes in white matter tract integrity following brain injury, and measures of diffusivity may be more appropriate.169 The DTI field would benefit greatly from the development of normative data sets against which to gauge observed changes. Pre-game versus post-game and season-long studies of young athletes could employ serial DTI imaging to establish normative data for a particular individual, but the utility of the data when pooled is unclear. The scarcity of normative paediatric data severely limits the clinical usefulness of neuroimaging techniques, including DTI. Studies of 'return-to-baseline' neuroimaging after paediatric concussion are also needed, as they could greatly improve prediction of recovery. Although automation has increased reproducibility, DTI measurements remain sensitive to the hardware and software specifics, acquisition parameters and analysis software, which limit reproducibility, standardization and comparison between centres and across studies. Efforts to standardize DTI across imaging centres are underway.170 MRI has been particularly successful in mapping the brain's 'connectome'—the collection of structural and functional neural connectivity networks and their respective focal nodes—and for studying how concussion affects these networks. Focal or diffuse TBI can disrupt the brain's functional connectivity, resulting in dysfunction of multiple networks including the default mode and salience networks, which have been implicated in memory, emotion and mood.171 Network dysfunction might have a stronger influence on recovery than does lesion location,171, 172, 173 but the long-term implications for brain development and cognitive function remain unclear.26, 174 Further studies of network connectivity dysfunction in children after concussion will be critical to improve injury prognostication and management. Radiotracers for PET imaging have the potential to advance the diagnosis and treatment of concussion and CTE, but their use in paediatric populations is purely investigational at present. Three FDA-approved radiolabelled imaging agents are currently available for detecting brain amyloid in patients with suspected AD.175 In adults, some cases of concussion are associated with acute Aβ pathology. PET scanning could enable paediatric patients to be monitored for the presence and persistence of acute post-concussion amyloid, and to determine whether scan positivity and negativity predict different outcomes.176, 177 Other PET imaging agents with potential utility in paediatric populations include new tracers that bind neurofibrillary tangles composed of tau. Early imaging results with 18F-T807, 18F-T808 and 18F-THK5105 are proving to be useful in confirming the presence of tauopathy in various clinical situations, including AD.178, 179, 180 In a recent AD study, the magnitude of tau tracer signal correlated positively with the stage of disease and severity of cognitive impairment.180 A third tau PET tracer, 11C-PBB3, has been tested in healthy individuals and patients with AD, and may be able to detect non-AD conformations of tau.181 In addition, a recent report contains the first description of tauopathy imaging in a living person with suspected sports-associated CTE.177 Given the extent of chronic tau pathology in concussion, repetitive subconcussive injury and CTE, tau tracers may be useful as diagnostic and prognostic biomarkers (for example, to distinguish CNI from CTE). Studies with these tracers in adults with CTE are underway, but their use in paediatric populations will depend on future research to determine whether tau pathology is present in young patients after TBI or concussion. A PET tracer for the microglial cholesterol transporter protein might be useful for imaging of neuroinflammation associated with TBI.182 New PET ligands to image brain microglia, which are being developed with potential utility in neurodegenerative diseases, may also prove useful in concussion and CTE management. Exploration of these PET ligands in paediatric populations with concussion and TBI would be informative, but risk–benefit analyses must be performed before embarking on studies involving radiotracers in this age group. The ultimate utility of any PET imaging agent will depend on its diagnostic and prognostic value as part of a multimodal panel of biomarkers and neuroimaging techniques. Noninvasive techniques such as transcranial magnetic stimulation (TMS) have also uncovered changes in synaptic plasticity following TBI and concussion,183 particularly in asymptomatic individuals.184, 185, 186 Several small TMS studies of young athletes in their early 20s with a history of concussion suggest imbalances in γ-aminobutyric acid and/or glutamate neurotransmission in the motor cortex that are associated with deficits in synaptic long-term potentiation and depression.184, 185, 187, 188 TMS has also revealed that concussion-related impairments in synaptic plasticity can impair aspects of motor learning,188 and that these deficits are detectable decades after an individual's last concussion.189 Another crucial noninvasive tool for detecting neurochemical dysfunction associated with concussion is proton magnetic resonance spectroscopy (MRS). Reports specifically addressing the use of spectroscopy following sports-related concussion suggest various abnormalities consistent with neurochemical alterations.190 In younger (high school) athletes, increased glutamate and glutamine levels were detected by MRS at post-season versus pre-season evaluation, even in players who had not experienced clinically significant concussion during the season.191 Such findings suggest that even subconcussive head impacts can result in the activation of glutamate pathways, implying cellular injury or neuronal death, despite the absence of symptoms. Levels of creatinine and myoinositol (an organic osmolyte located in astrocytes192, 193) were also significantly altered in a subset of the participants in the aforementioned study. In a rare longitudinal study utilizing MRS,194 individuals who sustained a single sports-related concussion exhibited significantly reduced levels of N-acetylaspartate (NAA, a marker of neuronal and axonal health, integrity and functioning195) in the brain 3 days after injury. Levels were increased at 15 days post injury, and reverted to control values at 30 days post injury. By contrast, participants who sustained a second concussion 10–13 days after their initial concussion displayed a prolonged reduction in NAA levels, which had not normalized even 45 days post injury. These results suggest that repeated injury within a short time frame increases the likelihood of protracted or incomplete recovery. In addition to the acute and subacute alterations detected by MRS, other studies of the long-term effects of concussion have disclosed increased myoinositol (associated with glial proliferation) and decreased choline (associated with membrane turnover195) levels in the medial temporal lobe in otherwise healthy former athletes who sustained their last concussion more than three decades prior to testing.196 Another recent study examined a cohort of symptomatic retired National Football League players, using an advanced MRS method called correlated spectroscopy (COSY), which can measure additional metabolites.197 The authors identified increased choline and glutamate–glutamine levels (indicative of diffuse axonal injury and excitotoxicity, respectively), consistent with previous mTBI MRS studies, as well as additional cerebral metabolites that were indicative of neuroinflammatory changes. These metabolic changes may provide insight into mechanisms of injury, such as excitotoxicity and/or inflammation, which could underlie the reported structural changes. Overall, the available data support the use of MRS as a research tool to identify altered neurophysiology and monitor recovery in adult athletes, even following resolution of post-concussive symptoms. At present, MRS-detected biochemical alterations may enhance our understanding of the underlying pathophysiology, but do not yet provide specific diagnostic information. Larger cross-sectional, prospective and longitudinal studies are needed to determine the sensitivity and prognostic value of MRS within the field of sports-related concussion.190 Because the interpretation of MRS in the immature brain requires certain developmental considerations, appropriate comparison samples will be needed for future work in children. MRS techniques with greater spectral resolution, including COSY, might provide additional biochemical specificity.197 Other advances in spatial resolution, such as 3D chemical shift imaging, may also provide greater specificity by allowing the investigation of metabolic alterations throughout the brain rather than in specific regions of interest. Finally, MRS could have a role in measurement of treatment effects, such as those induced by transcranial direct current stimulation198 and TMS.199 The mechanisms and surveillance infrastructure for sports-related injury measurement, reporting, tracking and data sharing are insufficient for current needs and objectives. Concussion research and clinical efforts are hindered by a lack of concussion data across sports and playing levels. A 2014 Institute of Medicine report identified only three national sports injury surveillance systems: the National Electronic Injury Surveillance System—All Injury Program (NEISS-AIP), the National Collegiate Athletic Association Injury Surveillance System (NCAA ISS), and the High School Reporting Injury Online (RIO™).1 These systems can be supplemented with clinical data (for example, from emergency departments, hospitalized inpatients and sports clinics), but these data are biased toward more-severe injuries and patients of higher socioeconomic status. Indeed, schools in rural areas or communities with lower socioeconomic status often have limited access to sports medicine care professionals and facilities. Several emerging programmes may improve surveillance. Regional efforts such as Clinical Outcomes Research Education for Athletic Trainers (CORE-AT) and national efforts such as the National Athletic Trainers' Association National Athletic Treatment, Injury and Outcomes Network (NATA NATION™) attempt to integrate injury tracking with treatment and outcomes data at the high school and collegiate levels. However, none of these systems specifically capture injuries to younger athletes, those participating in non-school sponsored sports, or those at schools without athletic trainers. Sports injury databases also rarely account for demographic factors including socioeconomic status, race or ethnicity, and health-care coverage. Currently, no effective mechanisms exist to consistently and inexpensively link various surveillance data sets, or to follow up individual athletes across sports, tracking systems or the age continuum. There is a considerable need for a system that tracks individual athletes through their playing careers and beyond. Each individual should be tracked for several decades to establish if, when and how a given burden of TBI evolves into CTE, and to assess all the possible negative health outcomes associated with concussion. Such a system would also provide more-accurate descriptions of concussion history and exposure to risk factors, and could capture both short-term and long-term outcomes, including measures of physical and mental health, academic and career success, quality of life and social connectivity, and evolving socioeconomic status. Such efforts are challenged by a variety of issues, including a lack of mandatory reporting of concussion at any level. Mandatory concussion reporting, funding for surveillance efforts, and provision of training to data reporters (for example, coaches and athletic trainers) would greatly improve epidemiological research. However, mandatory reporting will not provide meaningful results without validated, consensus definitions for concussions, and development of a universal data repository and a global unique identifier (GUID) system. Data sets from standardized surveillance efforts could then be linked, thereby improving data sharing for research and clinical care. Coupling of surveillance data with standardized collection, storage and curation infrastructures for biobanking of tissue and fluid samples could dramatically improve injury and outcomes research.200 These efforts might be catalyzed by funding from public–private partnerships, and made actionable by setting realistic short-term and long-term goals to create a multi-year plan. However, in the USA at least, such efforts are currently hampered by misunderstanding of Health Insurance Portability and Accountability Act (HIPAA) regulations and general concerns for athlete confidentiality. Wider use of computerized neurocognitive testing (CNT) for athletes could improve concussion surveillance, as well as diagnosis and management. However, several important challenges must be overcome before CNT becomes routine. These challenges include a lack of standardized administration protocols, the potential for technological errors arising from different computer hardware, limits in the types of cognitive functions assessed, and a lack of qualified test administrators and data interpreters.201 Despite these shortcomings, however, CNT is already used by approximately 40% of US high schools that employ athletic trainers.202 Though not affordable for all schools, CNT could enhance ground-level data collection and aid risk-exposure estimation and post-concussion recovery tracking, as well as increasing the quality of data reported to sports injury surveillance networks. CNT may be also useful in evaluating and tracking post-concussion cognitive improvement or decline, and could have utility in predicting outcomes.203, 204 Whether CNT data collected in the school setting will reach the validation and reproducibility standards achieved by CNT conducted by a clinical research team remains to be seen. Importantly, CNT needs standardization and guidelines for determining 'return to play' and 'return to learn' for athletes who show recovery in one domain but are still symptomatic in others. More research is required on the utility of CNT, both in the clinic and for concussion surveillance and management of youth athletes. In several critical areas, incomplete knowledge hampers meaningful advances in the field of paediatric concussion. At the molecular and cellular levels, research that focuses on axonal damage after concussion and repetitive subconcussive injury is urgently needed to elucidate changes in axonal trafficking and repair, and to better define the role of transient Aβ accumulation as a potential driver of downstream and/or future pathology. Concussion researchers may need to identify more-suitable animal models to study molecular pathology, including tau and its contribution to post-concussion and CTE pathologies, as the structure and organization of the brain differs dramatically in rodents and humans. Without a clearer understanding of how TBI changes the young, still-developing brain, and what pathological events happen in the weeks, months and years following injury, we are left to speculate about the underlying biological bases of such changes. Head impact data collection and risk assessment in youth sports might be improved through use of sensor technologies that record linear and rotational forces. Such commercially available devices, if validated, could determine levels of cumulative head impact forces during games and across seasons of play, and the findings could be linked to neuroimaging data and functional outcome assessments. Combined with 'hit-count' metrics, sensor data may improve knowledge of short-term and long-term neuropsychological outcomes of repetitive subconcussive impacts. Our knowledge of CTE might be improved by understanding baseline rates in the general population, in injured athletes, among uninjured athletes matched by sport and playing positions, and in 'control' athletes in low-risk sports. Improved knowledge of risk exposures could lead to prevention efforts, including practice and competition rule changes. A decades-long, prospective, longitudinal study, following youth athletes through their sporting careers and beyond, would provide more-definitive knowledge of cumulative head impacts and risks of long-term neuropsychological dysfunction and dementia. Such a study is underway in NCAA alumni, who were first studied in 2003 and were re-assessed in 2013.29, 205 Studies in other populations, especially if NIH-funded, would probably begin with a 5-year study that could be renewed in further 5-year increments. Public–private partnerships are likely to be required to secure enough funding to involve multiple study centres. The NCAA has provided partial sponsorship for the 10-year re-assessment of over 100 athletes, but further funding from the NIH, the US Department of Defense (DoD), and private philanthropic sources will be required to extend the range of assessment from neuropsychology, through MRI, to molecular imaging for amyloid, tau and/or inflammation. Ideally, the longitudinal study design should combine epidemiological and interventional trial methodologies and utilize multiple control groups, including non-contact athletes and uninjured impact sport athletes. A longitudinal study would also shed light on the role of cognitive reserve. A precedent for such studies has been established by the late-life dementia research community, using NIH funds and public–private partnerships involving pharmaceutical companies and foundations. For such studies to be successful, additional surveillance systems and data repositories must first be established. Efforts would be accelerated if athletes participating in impact sports had universal access to athletic trainers, who could act as reliable data reporters while promoting safety and providing basic care. In addition, any longitudinal studies must include postmortem analyses to better understand the influence of childhood and young-adult concussions on the development of neurodegenerative pathology and dementia in later life. 'Return-to-play' guidelines are currently hampered by a lack of rigorous epidemiological evidence, and could be greatly improved by long-term safety data from longitudinal studies.206 Longitudinal research could also include studies to determine whether those athletes who fail to follow guidelines experience any negative health effects, such as lingering symptoms or altered risk of incurring a second concussion. The infrastructure for a long-term prospective study might be created through the formation of a research consortium modelled after the Alzheimer's Disease Neuroimaging Initiative (ADNI). ADNI has set standards for data collection, dissemination agreements, testing methodologies, and biomarker collection and analysis. A version of ADNI currently underway with participation of the DoD (ADNI-DoD) is focused on blast-related TBI research in military populations.207 In May 2014, in addition to the NCAA Concussion Study, the NCAA and the DoD announced the launch of the largest prospective sports-related concussion study to date, which will monitor approximately 37,000 NCAA athletes over 3 years. One can envision how this study's infrastructure may eventually be extended to study younger athletes over an extended longitudinal range. Many gaps remain in our knowledge of the biology of TBI, which limit our ability to develop effective drugs. These gaps must be filled if we are to tackle the underlying disease pathology and move beyond treating the symptoms. However, much can be accomplished while research into fundamental TBI biology continues. Drug repurposing involves testing of existing FDA-approved drugs for new indications, and can reduce expense and shorten the path for drug approval. Current repurposing trials include methylphenidate for pain and mental fatigue,208 the dopamine receptor agonist bromocriptine for working memory,209 and the antidepressant sertraline for mood and anxiety, the most frequent neuropsychological complications that influence long-term outcomes after concussion.210 Larger randomized clinical trials should be conducted before these drugs can be introduced into clinical practice for these new indications. In addition, the recent failure of the PROTECT phase III trial of progesterone to improve outcomes after acute TBI211 may serve as a reminder of the need for more research to better understand the fundamental biology underlying TBI. Although many drug repurposing efforts are designed primarily to address concussion symptoms, the drugs may also influence injury pathology and progression. Research on established drugs can also lead to new drug discovery efforts and, potentially, new preventive or management therapeutics. New drugs are urgently needed for TBI and concussions that do not resolve. Drug discovery efforts in the areas of neuroprotection and anti-inflammation are especially relevant because of their potential cross-applicability to neurodegenerative diseases such as AD. Similarly, drugs currently in development for other neurodegenerative diseases might be repositioned for testing in patients with TBI or nonresolving concussion symptoms. As is often the case in medical research, recent advances in concussion research raise as many questions as they answer. Evidence exists for long-term neuropsychological dysfunction and later-life dementia after concussions or repetitive subconcussive head impacts, and more work is needed to better understand the implications and outcomes of youth participation in impact sports. As outlined in this Expert Consensus Document, there is a path forward, but achieving the goals outlined here will require public and private sector cooperation. While recommendations can be improved with increased knowledge, the available evidence can still inform individual decision-making when considering youth sport participation, as well as practice policies and competition rules. With an ageing population and a looming epidemic of dementia, we must learn more about potential early-life risk factors, including sports-related concussion. The choices made by parents, coaches, school boards and children will be better informed when the critical gaps in scientific knowledge of concussion are filled. Download references|与运动相关的脑震荡和重复性亚震荡暴露越来越被认为是儿科人群的潜在危险，但是对于这些事件的短期和长期后果，包括潜在的认知障碍和晚年痴呆的风险，仍然知之甚少。这份专家共识文件是由全球安全儿童、阿尔茨海默氏症药物发现基金会和安德鲁斯矫形外科和运动医学研究所召集的为期一天的会议的结果。目标是强调在脑震荡科学、痴呆症、遗传学、诊断和预后生物标志物、神经影像学、运动损伤监测和信息共享等领域的知识差距和亟需研究的领域。针对这些领域，我们提出了明确和可实现的途径，以提高对青少年体育相关脑震荡的理解、治疗和预防。2009年，美国年龄 < 19岁的个体中记录了约250,000例非致命性创伤性脑损伤(TBI)。1疾病控制和预防中心估计，5-18岁的年轻人维持着所有运动相关脑震荡的65% 。2尽管最近在诊断性脑成像方面取得了进展，并且在我们对脑震荡物理学的理解方面，长期的认知结果仍然知之甚少。由于脑震荡的身体、认知和情感后果引起了公众的广泛关注，我们对如何预防、诊断和治疗这种伤害的不完整知识危及我们儿童的总体健康，特别是他们的大脑健康。这份专家共识文件是儿科和成人创伤性脑损伤、阿兹海默病(AD)研究、遗传学、流行病学、生物伦理学和运动医学领域专家为期一天的会议的结果(专栏1) ，该会议于2013年11月由全球安全儿童、阿尔茨海默氏症药物发现基金会和安德鲁斯矫形外科和运动医学研究所召集。我们的主要目标是强调我们在儿童和青少年脑震荡知识方面的重大差距。我们强调需要进行研究的领域，如开发诊断和预测性生物标志物，阐明遗传风险因素，以及预测短期和长期结果。在我们的结论中，我们提出了提高我们对与运动相关的儿童脑震荡的长期后果的理解的途径。术语“脑震荡”经常与术语“轻度 TBI”(mTBI)交替使用，考虑到脑震荡后可能的脑损伤程度和慢性神经心理功能障碍的潜在可能性，这是一种潜在的误导性做法。然而，我们应该强调的是，大多数脑震荡不会产生后遗症。美国康复医学会将 mTBI 定义为格拉斯哥昏迷量表3评分为13-15分，意识丧失 < 30分钟，创伤后遗忘持续时间 < 24小时。脑震荡描述了损伤表型的异质混合物，取决于许多因素，包括头部撞击的大小，位置和方向。尽管缺乏宏观结构发现，脑震荡损伤涉及由线性和旋转剪切力破坏轴突和膜功能(弥漫性轴突损伤，5离子通量和谷氨酸兴奋毒性)引起的原发性神经元损伤，随后是继发性病理生理效应，包括线粒体氧化应激，脑血流中断，血脑屏障(BBB)完整性受损，突触功能障碍和神经炎症。持续的神经心理学脑震荡后症状(脑震盪症候群)包括情绪障碍(例如抑郁症) ，难以集中和记忆问题(方框2)。年轻运动员的脖子和躯干比老年人的脖子和躯干更弱，因此，造成脑损伤所需的力量更少。发育中的大脑也可能特别容易受到由头部创伤的剪切力引起的轴突损伤，这在美国青年足球中可以超过100g 的线性加速力。然而，青年运动中持续的平均力量通常会小于较高水平的运动。正确的突触发育对认知和行为健康至关重要。神经发生、竞争性突触消除(“修剪”)、髓鞘形成、轴突和树突树枝化等过程在产前发育的整个生命周期中持续进行。额叶和颞叶是最后成熟的区域，人类在20岁出头的时候经历了这些区域的修剪[16] ，因此这些仍在发育的区域的损伤可能对大脑产生病理生理效应，增加了以后生活中出现神经心理问题的可能性。轴突髓鞘形成在青春期持续到20岁出头，易受损伤的影响。职业拳击手大脑健康研究的早期结果表明，第一次接触拳击比赛的年龄越早，尾状核体积损失越大，额叶轴突损伤越严重。这项研究对拳击手和追踪研究综合格斗拳击手进行了5年的研究，他们都经历过重复性的脑震荡和脑震荡。23,24年轻的大脑也有一些有助于恢复的特征。已经显示，这个年龄组的神经可塑性增加有助于局灶性损伤后更好的结果[25]。此外，发育中的动物对重复 TBI 的葡萄糖代谢障碍的窗口比成年动物更短[26]。总的来说，发育中的大脑在 TBI 后显示出脆弱性和恢复力。这些相互交织的因素可能解释了脑震荡和重复 mTBI 对年轻人和成年人大脑影响的差异。应高度重视对脑震荡风险采取保守的方法，并加大努力调查这些发育差异。大多数人ーー无论老少ーー从脑震荡中完全恢复过来。在儿童中，可能影响康复的因素包括年龄和脑震荡史。27,28在一项研究中，大约90% 的年轻成年男运动员在21天内经历了症状恢复。然而，在一项针对11-22岁患者(包括所有脑震荡原因，而不仅仅是运动相关)的急诊科研究中，15% 的样本在受伤后90天仍然表现出脑震荡后症状，包括头痛，头晕，“精神模糊”和抑郁。一些研究表明，美国高中橄榄球运动员从脑震荡中恢复的速度比大学运动员和职业运动员要慢。尽管最近一项包括青春期前年龄组(11-12岁)的研究表明，脑震荡后恢复持续时间可能与年龄没有线性关系，但与高中以下青少年的直接比较尚未发表[30] ，因为这个样本中的青少年恢复时间比青春期前的儿童更长。这些发现加在一起，意味着男性青春期年龄组的恢复时间较长的独特风险。对年幼儿童和女性的进一步研究将大大提高我们评估和减轻整个儿科和青少年年龄段风险的能力。在新的脑震荡发生前1年内遭受一次或多次脑震荡的青少年报告出现更长时间的症状，30表明可能存在“脆弱性窗口”，并将先前受伤的青少年置于更高的长期恢复风险中。11-18岁的青少年在急诊室出现脑震荡后发生脑震盪症候群的可能性比5-10岁的儿童高出近80% ，同样，伴有头痛的儿童和青少年出现脑震盪症候群的风险增加了一倍。在 mtBI 后在急诊室接受治疗的儿童中，6岁以上的儿童在受伤后3个月报告持续症状的发生率高于6岁以下的儿童。当然，获得 < 6岁儿童脑震荡症状的准确信息的能力可能受到缺乏症状自我意识和有效沟通这些症状的必要语言技能的限制。此外，从这些报告中不可能直接比较损伤的严重程度; 事实上，各种损伤的身体异质性，加上个体从脑震荡中恢复的先天能力，使得这种比较具有高度挑战性。一些专业研究中心正在使用“智能头盔”来标准化头部撞击产生的体力和角加速度，目前正在研究这些头盔用于测量和预测可能导致脑震荡的影响。36,37从脑震荡中恢复的年轻人可能会经历重大挑战，包括社会和学术发展的改变，38,39,40在一般智力测试中得分较低，以及学校表现下降(以年级平均分衡量)。39较低的父母教育水平和儿童学业成绩都与较差的脑震荡恢复相关。人格特质也起到了一定的作用，例如，伤前焦虑是运动性脑震荡后长时间恢复的一个危险因素。42年轻的男女运动员都有脑震荡的危险，但是女孩的脑震荡发生率高于男孩，特别是在高中和大学的足球、篮球、棒球或垒球比赛中。28,43,44,45解释这些差异的因素仍然不确定，但可能包括保护装备的质量，脑震荡症状的识别和报告，以及颈部长度和颈部肌肉力量。46男女之间在恢复轨迹方面的差异也知之甚少。然而，最近的一项研究表明，女性黄体酮水平影响脑震荡后的恢复。47青春期激素变化导致偏头痛，也可能导致脑震荡后恢复的性别差异。在青春期后，女性偏头痛的发病率是男性的四倍[48,49] ，一些证据表明，偏头痛患者在脑震荡后恢复较慢[50,51]。有必要进一步研究脑震荡风险和恢复的性别差异。一般来说，成人脑震荡比儿童和青少年脑震荡更容易理解。有几点值得注意。首先，脑震荡有多种非协调的定义。其次，脑震荡诊断是一门不完善的艺术。最后，在缺乏快速和廉价的客观诊断措施的情况下，脑震荡仍然是一种临床诊断，受到变异性的影响，包括不同亚专业和个体医生、神经心理学家和运动训练员的诊断阈值不同，以及教练、家长和年轻运动员报告不足。如果没有经过验证的诊断，脑震荡将仍然是一个模糊和报告不足的实体，发病率估计的准确性将继续受到不确切标准的差别应用的影响。重复性次级脑震荡可导致大脑结构和功能的改变。52弥散张量成像(DTI)检测到的白质异常在职业足球运动员中已有报道，即使没有任何明显的脑震荡史。与游泳运动员相比，男性职业足球运动员表现出 DTI 信号改变，提示几个大脑区域的白质完整性降低，这可能表明轴突髓鞘形成的丧失，类似于 mTBI 患者的改变。53名大学冰球运动员在一个赛季中表现出类似的白质变化。54,55,56,57此外，美国大学生橄榄球运动员重复性亚震荡性头部撞击已经以剂量依赖性方式与 BBB 完整性缺陷，白质完整性潜在丧失和认知功能障碍有关。58这些研究结果可能反映了持续遭受重复性次生脑震荡撞击的青少年的某种程度的风险，尽管很少有专门针对这一主题的研究。一个跟踪头部影响的指标ーー即“命中次数”ーー已经提出，59可以作为确定累积风险敞口的一个因素。这种方法的一个挑战是准确定义“命中”的参数，但改进的生物传感器在这方面显示出一些希望。与棒球中的“投球次数”类似，这个概念最近也被提出用于拳击运动员。24目前没有证据表明青少年重复性脑震荡冲击与晚年痴呆之间的因果关系，如果未来的研究将头部冲击与随后的神经心理功能障碍相关联，这些指标可能被证明是无价的。在成年人中，包括脑震荡在内的脑外伤可能会增加个体发生神经退行性疾病的风险，包括 AD 和 CTE (CTE) ，这是一种仅与重复性头部创伤相关的疾病[65,66]。尽管 mTBI 和 PD 风险之间的关系仍然不确定，但 TBI 也可能增加发生帕金森氏症的风险[67]。在儿科人群，特别是年轻运动员中，单次或重复性脑震荡对晚年神经退行性疾病和痴呆风险的影响是未知的。CTE 在20世纪20年代后期首次被症状性描述为拳击运动员的“拳击醉”痴呆，69后来被描述为“痴呆拳击”[70] ，并在1973年首次被病理学描述[71]。自2005年在一名前职业美式足球运动员身上发现 CTE 以来,这种病症已经引起了公众的广泛关注，目前已经在前冰球、棒球、橄榄球和足球运动员、73名摔跤运动员、74名退伍军人的大脑中发现。75,76业余和职业运动员慢性创伤性脑病的患病率和发病率仍然是未知的，这增加了讨论其流行病学和运动员的人口风险的困难。虽然慢性创伤性脑病主要被认为是一种神经退行性疾病，有时是由大学或专业接触性运动的职业生涯造成的，但在高中运动员中也有慢性创伤性脑病的报道。这一发现表明，慢性创伤性脑病的发展并不需要长期的运动生涯，青年运动员代表着高危人群。新出现的证据表明，临床的慢性创伤性脑病症状可以分为认知和情绪行为两种常见表现[78,79]。主观记忆症状如顺行性遗忘症是常见的，包括焦虑或抑郁在内的情绪障碍也是常见的[79] ，并且执行功能降低，这可能导致去抑制和决策技能受损[80]。这些临床症状定义了疾病的严重程度[81]。慢性创伤性脑病的神经退行性病理生理学是复杂的，对神经系统后遗症的了解很少。在严重的情况下，大脑皮层和内侧颞叶似乎受到最深刻的影响，81,82与病理学拥有属性由磷酸化 tau79组成的神经原纤维缠结，在某些情况下，TAR DNA 结合蛋白43病理学。CTE 也与明显的萎缩有关，特别是在额叶皮层和内侧颞叶，以及在乳头体，丘脑和下丘脑。79确诊的 CTE 临床诊断仍以尸检为基础。鉴于慢性脑震荡中描述的重复病变是否引起临床表型的不确定性，以及大多数专业和大学运动员不发展慢性脑震荡的事实，了解早期暴露于脑震荡是否与其他形式的神经退行性疾病和认知功能障碍(包括慢性神经认知障碍(CNI))相关至关重要。CTE 和 CNI 之间存在重要的临床区别，其中一些使得直接比较困难。CTE 是一种新出现的临床和病理状况，涉及多个领域的神经和认知功能的进行性恶化，主要在尸检中诊断。相反，CNI 表型并不一定是进行性的，而是拥有属性功能从组平均值或基线功能下降到创伤性脑损伤之前的水平。CNI 可以通过神经心理测试进行临床诊断。CNI 与头部创伤之间的因果关系尚未得到证实，但在专业运动员中一直发现剂量依赖性风险。此外，在业余运动员中进行的几乎一半的研究发现 CNI 的风险升高。年轻人群中是否存在类似的风险关联仍有待确定。一个假设是 CNI 代表了慢性创伤性脑病的前驱症状，但并非不可避免，类似于轻微认知障碍和 AD 之间的关系。另外，CNI 可能代表静态损伤而不退化。我们目前对 CNI 和 CTE 的基本生物学基础缺乏了解，这强调了进一步研究的必要性。对这两种情况的生物学知识的增加以及运动员(特别是青年运动员) CNI 的早期检测可能会推动干预措施以阻止进一步认知障碍的发展，并且还可能有助于验证推定的生物标志物。通过 tau 成像评估 CNI 可能有助于确定进展为 CTE 的可能性。脑震荡遗传学领域，特别是在儿科人群中，仍然处于起步阶段。尽管重复的头部撞击似乎对于 CTE 的发展是必要的，但是包括遗传学在内的其他因素可能具有重要作用，因为大多数脑震荡运动员不发展 CTE.87 CTE 的遗传危险因素可能与影响脑震荡易感性和恢复的因素重叠，AD 的遗传危险因素为这些因素的身份提供了重要的线索。E型载脂蛋白质的 ε4等位基因(APOEε4)是迄今为止发现的 AD 最重要的遗传危险因素，它严重影响中枢神经系统的损伤反应，特别是从大脑中清除淀粉样蛋白 -β (Aβ)。APOE 的三个等位基因赋予不同程度的 AD 风险: APOEε2降低风险，APOEε3是最常见的等位基因，代表与其他变体进行比较的基线风险，APOEε4增加风险。90,91研究表明 APOEε4与性别之间存在相互作用，因此 APOEε4相关的 AD 风险在女性中比在男性中更为突出。92,93 APOE 基因型与 TBI 协同作用增加 AD 的风险[94] ，尽管其与 CTE 作为重复 mTBI 的结果的假设风险相关性需要更多的研究。关于 APOE 同种型对儿童 TBI 结果的影响尚未达成共识，但来自成年人的数据表明 APOEε4对脑震荡结果有负面影响。一些研究表明，拥有至少一个 APOEε4等位基因与美国职业橄榄球运动员，96名拳击运动员95和其他成年人97,98,99,100的脑震荡后认知较差和持续的神经心理障碍有关，尽管其他研究没有发现这种关联。101,102一些证据表明 APOE 基因及其启动子的多态性是大学生运动员脑震荡危险的促成因素。另一项研究没有确定 APOEε4在脑震荡风险中的作用[105] ，尽管这个等位基因可能增加中年或晚年 mTBI 后痴呆的风险。106由于样本量小，方法不同，很难从这些相互矛盾的研究中得出结论。在儿童中，对于 APOEε4与脑震荡后神经心理学结果之间的关系知之甚少，而且 APOEε4测试在儿科 TBI 研究中并不常规。2012年，Kurowski 回顾了少数现有的研究，并结合了使用格拉斯哥结果量表的三项研究的结果[107,108,109]。在合并样本(252名儿童)中，6-12个月后不良临床结果的风险在 APOEε4携带者中高于非携带者(19% 比9%)。然而，这些研究包括了广泛的异质性损伤儿童的发育范围，并没有考虑到年龄和基因型之间可能的相互作用。此外，APOE 与性别之间的相互作用尚未在脑震荡的背景下进行研究。改进的前瞻性研究有助于澄清这些联系。将遗传学纳入儿科脑震荡研究充满了复杂的挑战，包括获得父母同意和儿童的知情同意，临床研究参与者的感知耻辱，获得的遗传知识的可行性以及关于可保性(特别是长期护理保险)的潜在担忧。对了解 APOEε4 + 状态的成年人的研究表明，许多人愿意改变生活方式，包括增加运动和改善药物管理[111] ，以及增加购买健康和长期护理保险[112,113]。关于新的遗传知识和相应的疾病风险的教育是必不可少的，正如个人对获得的知识的影响的个人感觉与痴呆风险增加的实际后果之间的实质性不一致所证明的那样.114 APOE 遗传知识对儿童，其家庭和参与影响性体育的决策过程的影响尚不清楚。APOE 基因型对该年龄组脑震荡风险和恢复的影响也需要进一步阐明。如果未来的研究发现，对于任何特定水平的影响，具有 APOEε4 + 状态的儿童比其 APOEε4同龄人具有更大的脑震荡或恢复不良的风险，则应考虑在参加影响性运动之前对学龄运动员进行基因检测。要充分理解基因影响的细微差别，就需要对高中和年轻运动员进行仔细研究。未来对青少年脑震荡结果(包括认知结果和痴呆风险)的研究应尽可能包括 APOE 基因分型。新的 APOE 研究应标准化研究方法和报告措施，包括收集“共同数据元素”，以确保有效的比较研究。110,115 APOE 基因型不一定是脑震荡恢复的不可改变的危险因素: 正在开发的 AD 治疗包括改变 ApoE4蛋白和 Aβ 之间相互作用的药物，这也可能适用于儿科脑震荡。编码脑源性神经营养因子的基因中的 Val66Met 多态性与 mtBI 后更好的结果有关，但与局灶性穿透性脑损伤后更差的结果有关。参与多巴胺能信号传导的基因多态性也可能有助于解释广泛的 TBI 结果。120此外，α-synuclein 基因启动子区的 Rep1多态性可能增加头部损伤后帕金森病的风险。为了提高我们对脑震荡风险和管理的理解，应该进行大型的前瞻性基于人群的全基因组关联研究(GWAS)和全基因组测序研究，以确定其他遗传变异(可能是低频率或低外显率) ，这些变异可以改变长期恢复，认知结果差或痴呆的风险。122这样的研究将需要大规模的数据共享，并且必须解决道德、隐私以及对可保性和可雇佣性的潜在影响等问题。尽管在确定可能应用于成人创伤性脑损伤治疗的可能的脑嵴液(CSF)和血液生物标志物方面取得了进展，但成人或儿科人群都没有经过临床验证的生物标志物。与成人脑震荡相比，儿童脑震荡的临床变异性更大; 因此，生物标志物在改善儿童脑震荡诊断方面具有特殊的潜力。值得注意的是，大多数 TBI 生物标志物已经在中度至重度 TBI 的背景下进行了研究，这使我们在 mTBI 生物标志物的知识方面存在明显的差距，特别是在儿童中。生物标志物的发展对 AD 治疗的进步至关重要。基于脑脊液的生物标志物已经被用于识别高危患者，并改善流行病学研究和临床试验的设计。123新的 PET 放射性配体，如淀粉样蛋白标记剂(其中三种现在是 FDA 批准的) ，可以用于诊断和改善基于神经病理学的患者临床试验分层。一些 tau 成像剂也在人体试验中，它们在包括 CTE 在内的 tau 病中的应用正在迅速建立。与基于液体的生物标志物一样，目前还没有足够敏感或特异的神经影像生物标志物来诊断成人或儿童的脑震荡或 CTE。目前 FDA 尚未批准任何创伤性脑损伤的诊断或治疗药物，而脑震荡生物标志物的验证可以加速这类药物的开发。然而，必须努力确保临床生物标志物检测的成本效益和广泛可用性。此外，考虑到与腰椎穿刺相关的风险，对脑震荡青少年脑脊液取样用于生物标志物研究的伦理问题应该得到解决。在成人体液为基础的生物标志物研究中有希望的发现必须在儿科人群中探索。过去数十年，推定脑震荡的生物标志物在科学文献中零星出现，其中最突出的是星形胶质细胞活化的非特异性标志物 S100钙结合蛋白 B (S100B)。血清中 S100B 的存在可能提示血脑屏障完整性的丧失。在成年拳击手比赛后观察到血清和脑脊液 S100B 水平升高，并且与头部撞击的数量和严重程度呈正相关。在脑震荡的职业冰球运动员中也观察到血清 S100B 水平升高，126在脑震荡后1小时测量的水平预测症状恢复时间。然而，S100B 的水平也提高后，控制发挥，没有发生脑震荡，表明这一标志物是不伤害特异性。事实上，没有头部损伤的成年创伤患者血清 S100B 水平升高。127,128,129其他研究表明，脑震荡后最初的 S100B 水平对于恢复不能很好地预测。与所有生物标志物一样，S100B 在儿童 TBI 管理中的作用甚至更不清楚[131] ，一些人认为这种标志物在儿科人群中几乎没有诊断或预后效用。132在一项关于≤15岁 TBI 患儿的研究中，5岁以下或9岁以上儿童的血清 S100B 水平高于5-9岁儿童。因此，S100B 可能不足以区分有症状和无症状的脑震荡儿童[133] ，S100B 在诊断和预后预后方面的效用是值得怀疑的。134,135,136神经元特异性烯醇化酶(NSE)是神经元损伤的标志物，但其作为血清或脑脊液生物标志物的用途仍不确定。拳击手头部撞击后观察到血清 NSE 水平升高[133,134,135,136,137] ，但在没有发生脑震荡的比赛后，冰球运动员也观察到 NSE 水平升高。血清 NSE 水平无法预测脑震荡后的恢复时间，可能与儿童损伤严重程度无关。133在≤15岁的儿童中，血清 NSE 水平与年龄呈负相关。一旦释放到血液中，NSE 具有缓慢的消除动力学，使得难以根据 NSE 水平区分原发性和继发性神经元损伤。神经丝轻链和胶质纤维酸性蛋白(GFAP)分别是 CSF 神经元特异性和胶质特异性损伤标志物，并且在成年拳击手打斗后 CSF 均升高。125,137,140在儿科脑震荡的情况下，对任何一种标志物都知之甚少，但对儿童和年轻成年人的初步研究表明，脑震荡后72小时内的血清 GFAP 水平与损伤后1个月的症状负担相关。神经元特异性蛋白 UCH-L1(泛素羧基末端水解酶同工酶 L1)首先通过参与 PD 与神经退行性病理学相关[142] ，其在血清中的存在后来被确定为严重 TBI 的生物标志物。血清 UCH-L1水平可能对脑震荡有诊断价值[146] ，但最近的证据表明血清水平升高与脑震荡次数之间缺乏相关性。UCH-L1在儿科人群中的临床应用值得进一步研究。也许最有希望的进展成人液基 TBI 生物标志物涉及 tau 蛋白。血清或脑脊液 tau 蛋白水平被认为表明轴突损伤，因为 tau 蛋白通常存在于轴突中，稳定微管。在 AD 患者中，脑脊液中切割的 tau 蛋白水解水平可能与认知功能相关。拳击手在比赛后脑脊液和血液中的 Tau 水平升高，脑脊液 Tau 水平与头部撞击的质量和数量相关。125,150最近的证据表明，脑震荡后冰球运动员血液中的 tau 水平升高，可能有助于预测恢复时间。然而，问题依然存在，一些研究报道血清切割 tau 对预测脑震盪症候群或长期结果的价值很小或没有价值。130,151 tau 作为儿童生物标志物的潜力尚不清楚，至今没有进行研究。事实上，血清 tau 作为一种生物标志物的可靠性尚未被确定为任何适应症。这种可能性是没有单一的生物标志物将足以诊断儿童脑震荡或预测结果。此外，很少有研究调查遗传组成和推定的生物标志物之间的相互作用。随着我们对生物标志物与损伤严重程度及其相互关系的理解的增加，生物标志物小组的发展，可能包括炎症和氧化标志物，152应该被考虑。未来的研究应试图进一步确定这些关系，建立生物标志物小组的临床价值，考虑到商业成本和实际可行性。代谢组学、脂质组学和蛋白质组学的最新进展ーー特别是寻找 AD 的代谢组学和脂质组学标志物ーー可能为今后研究脑震荡和脑震荡下损伤的生物标志物提供参考。最近的一些研究提出了与 MCI 和 AD 相关的代谢物和脂质谱的改变.153,154,155,156来自动物模型的数据表明，脂质和代谢物变化伴随着急性和慢性脑震荡后期，并且可能有助于预测恢复轨迹，157,158但是这些发现尚未在人类中得到验证。将生物标志物的搜索范围从血液和脑脊液扩展到唾液和尿液159，可能会提高快速和非侵入性测量的能力，特别是从儿童身上。从儿童抽取脑脊液样本，特别是在需要快速评估的情况下，在很大程度上是不切实际的。Mondello 等人提出了一套评估 TBI 生物标志物的有用标准，这些标准应该允许更精简的开发和验证.137任何经过验证的生物标志物小组必然是更大的多模式诊断套件的组成部分，其中可能包括结构和功能成像以及神经心理学测试。在设计未来的生物标志物研究时，应考虑 FDA 批准的可能性，以加快批准临床使用。虽然脑震荡仍然是一种临床诊断，但神经影像学技术正在提高我们对成人脑结构和功能后果的认识。儿科人群的神经影像学可能受到几个因素的限制，例如，脑震荡后纵向变化的测量由于动态的、未成熟的大脑的背景而变得复杂。没有成像技术被证实为脑震荡的诊断工具，成像结果与临床可测量的认知或行为功能之间的相关性是可变的。目前正在研究容积成像、 DTI 和功能磁共振成像(fMRI)等工具，特别是动脉自旋标记。通过 DTI 测量的分数各向异性(FA)可以推断白质束的结构完整性，TBI 后白质束通常被破坏。FA 变化的临床意义仍然存在争议，因为在脑震荡研究中观察到 FA 增加和减少[162,163,164,165,166]。这些差异可能部分是由于所检查的脑区域的相当大的空间异质性[167]以及损伤后间隔的差异。FA 可能仍然具有预后价值，有证据表明变化的方向和幅度与临床结果相关; 然而，这个想法等待在儿科和成人人群中验证。FA 可能缺乏必要的敏感性来充分评估脑损伤后白质束完整性的变化，扩散率的测量可能更合适。169 DTI 领域将大大受益于规范数据集的开发，以衡量观察到的变化。年轻运动员的赛前、赛后和赛季研究可以采用连续 DTI 成像技术为特定个体建立规范的数据，但数据汇总后的效用尚不清楚。儿科标准数据的缺乏严重限制了包括 DTI 在内的神经影像技术的临床应用。儿童脑震荡后的“回归基线”神经影像学研究也是必要的，因为它们可以极大地改善恢复的预测。尽管自动化提高了重复性，但 DTI 测量仍然对硬件和软件特异性，采集参数和分析软件敏感，这限制了重复性，标准化和中心之间以及跨研究之间的比较。标准化 DTI 成像中心的努力正在进行中。170 MRI 在绘制大脑的“连接体”(结构和功能神经连接网络及其各自的焦点节点的集合)以及研究脑震荡如何影响这些网络方面特别成功。局灶性或弥漫性 TBI 可以破坏大脑的功能连接，导致多个网络的功能障碍，包括默认模式和显着网络，这与记忆，情绪和情绪有关[171]。网络功能障碍对恢复的影响可能比病变部位更强[171,172,173] ，但对大脑发育和认知功能的长期影响尚不清楚[26,174]。脑震荡后儿童网络连接功能障碍的进一步研究对于改善损伤预后和管理至关重要。用于 PET 成像的放射性示踪剂有可能推进脑震荡和 CTE 的诊断和治疗，但目前它们在儿科人群中的应用纯粹是研究性的。三种 FDA 批准的放射性标记成像剂目前可用于检测疑似 AD 患者的脑淀粉样蛋白。175在成年人中，一些脑震荡病例与急性 Aβ 病理有关。PET 扫描可以使儿科患者监测急性脑震荡后淀粉样蛋白的存在和持续性，并确定扫描阳性和阴性是否预测不同的结果.176,177在儿科人群中具有潜在用途的其他 PET 成像剂包括结合由 tau 组成的神经原纤维缠结的新示踪剂。用18F-T807,18F-T808和18F-THK5105进行的早期成像结果证明对于确认包括 AD 在内的各种临床情况下存在共病是有用的。178,179,180在最近的一项 AD 研究中，tau 示踪信号的大小与疾病的分期和认知障碍的严重程度呈正相关。第三种 tau PET 示踪剂11C-PBB3已经在健康个体和 AD 患者中进行了测试，并且可能能够检测 tau 的非 AD 构象。181此外，最近的一份报告首次描述了疑似与运动相关的慢性创伤性脑病(CTE)在活人中的重病影像学表现。鉴于脑震荡，重复性亚震荡损伤和 CTE 中慢性 tau 病理学的程度，tau 示踪剂可用作诊断和预后生物标志物(例如，区分 CNI 和 CTE)。目前正在对 CTE 成人进行这些示踪剂的研究，但它们在儿科人群中的应用将取决于未来的研究，以确定 TBI 或脑震荡后年轻患者是否存在 tau 病理学。小胶质细胞胆固醇转运蛋白的 PET 示踪剂可能有助于成像与创伤性脑损伤相关的神经炎症。182正在开发的新型 PET 配体可以成像脑小胶质细胞，对神经退行性疾病具有潜在的应用价值，也可能证明对脑震荡和慢性创伤性脑病的治疗有用。在脑震荡和 TBI 的儿科人群中探索这些 PET 配体将是有益的，但是在开始进行涉及该年龄组放射性示踪剂的研究之前必须进行风险-效益分析。任何 PET 成像剂的最终效用将取决于其作为多模式生物标志物和神经影像技术小组的一部分的诊断和预后价值。非侵入性技术如经颅磁力刺激(tMS)也发现了创伤性脑损伤和脑震荡后突触可塑性的变化，特别是在无症状的个体中。对20多岁有脑震荡史的年轻运动员进行的几项小型 TMS 研究表明，运动皮层中 γ-氨基丁酸和/或谷氨酸神经传导的不平衡与突触长时程增强作用和抑郁症的缺陷有关。184,185,187,188经颅磁刺激还显示，脑震荡相关的突触可塑性损伤可以损害运动学习的各个方面，这些缺陷在个体最后一次脑震荡几十年后仍然可以检测到。另一个检测与脑震荡相关的神经化学功能障碍的关键非侵入性工具是质子磁共振谱(MRS)。专门针对运动相关脑震荡后使用光谱学的报告表明，与神经化学改变一致的各种异常。在年轻(高中)运动员中，MRS 在赛季后与赛季前评估中检测到谷氨酸和谷氨酰胺水平增加，即使在赛季期间没有经历临床显着脑震荡的运动员中也是如此。这些发现表明，即使是次震荡性头部撞击也可能导致谷氨酸途径的激活，意味着细胞损伤或神经元死亡，尽管没有症状。在上述研究中，一部分参与者的肌酐和肌醇水平(位于星形胶质细胞中的有机渗透液192,193)也发生了显著变化。在一项使用 MRS 的罕见追踪研究中，194名持续单次运动相关脑震荡的个体在受伤后3天在大脑中表现出显着降低的 N- 乙酰天冬氨酸(NAA，神经元和轴突健康，完整性和功能的标志物195)水平。损伤后15天水平升高，损伤后30天恢复到对照值。相比之下，在第一次脑震荡后10-13天再次受到脑震荡的参与者表现出 NAA 水平的长时间下降，即使在受伤后45天也没有恢复正常。这些结果表明，在短时间内反复受伤增加了延长或不完全恢复的可能性。除了 MRS 检测到的急性和亚急性改变之外，其他关于脑震荡长期影响的研究已经揭示了在其他健康的前运动员中，内侧颞叶中肌醇(与胶质增殖相关)增加和胆碱(与膜转换相关195)水平降低在测试之前持续最后一次脑震荡超过三十年。196最近的另一项研究使用一种叫做相关光谱学(COSY)的先进的 MRS 方法，检测了一组有症状的退役国家橄榄球联盟球员，这种方法可以测量额外的代谢物。作者发现胆碱和谷氨酸-谷氨酰胺水平升高(分别表明弥漫性轴突损伤和兴奋性毒性) ，与之前的 mtBI MRS 研究一致，以及额外的大脑代谢物表明神经炎症的变化。这些新陈代谢的变化可能提供了损伤机制的洞察力，如兴奋性毒性和/或炎症，这可能是所报道的结构变化的基础。总的来说，现有的数据支持使用 MRS 作为一种研究工具，以确定改变的神经生理学和监测恢复成年运动员，即使在解决后脑震荡症状。目前，MRS 检测到的生化改变可以增强我们对潜在病理生理学的理解，但尚不能提供具体的诊断信息。需要更大的横断面，前瞻性和纵向研究来确定 MRS 在运动相关脑震荡领域内的敏感性和预后价值.190由于未成熟大脑中 MRS 的解释需要某些发育方面的考虑，因此将来在儿童中的工作将需要适当的比较样本。具有更高光谱分辨率的 MRS 技术，包括 COSY，可能提供额外的生化特异性。空间分辨率的其他进展，如3D 化学位移成像，也可以通过允许调查整个大脑的代谢改变而不是在特定的感兴趣的区域，提供更大的特异性。最后，MRS 可以在测量治疗效果方面发挥作用，例如经颅直流电刺激198和 TMS.199。体育相关伤害测量，报告，跟踪和数据共享的机制和监测基础设施不足以满足目前的需求和目标。脑震荡的研究和临床工作受到缺乏运动和运动水平的脑震荡数据的阻碍。2014年美国医学研究所的一份报告只确定了三个国家运动伤害监测系统: 国家电子伤害监测系统ーー所有伤害项目(NEISS-AIP)、全美大学体育协会伤害监测系统(NCAA ISS)和高中伤害在线报告系统(rIOTM)。1这些系统可以补充临床数据(例如，来自急诊科、住院病人和体育诊所) ，但这些数据偏向于更严重的伤害和社会经济地位更高的病人。事实上，农村地区或社会经济地位较低的社区的学校往往很难获得运动医疗专业人员和设施。一些新出现的项目可能会改善监督。区域性的努力，如运动训练员临床结果研究教育(CORE-AT)和全国性的努力，如全国运动训练员协会全国运动治疗，伤害和结果网络(NATA NATIONTM)试图将伤害跟踪与高中和大学水平的治疗和结果数据结合起来。然而，这些系统中没有一个专门针对年轻运动员、那些参加非学校赞助体育项目的运动员或那些在没有运动教练的学校的运动员。运动损伤数据库也很少考虑人口统计因素，包括社会经济地位、种族或民族以及医疗保健覆盖率。目前，还没有有效的机制来连贯和廉价地将各种监测数据集联系起来，或者跨越体育、跟踪系统或年龄连续体跟踪个别运动员。现在相当需要一个系统来追踪个人运动员的运动生涯和其他方面。应该对每个人进行数十年的跟踪，以确定 TBI 的负担是否、何时以及如何演变为 CTE，并评估与脑震荡相关的所有可能的负面健康结果。这种系统还可以更准确地描述脑震荡病史和风险因素，并可以捕捉短期和长期的结果，包括身体和心理健康、学业和职业成功、生活质量和社会联系以及不断变化的社会经济地位。这种努力受到各种问题的挑战，包括缺乏任何级别的脑震荡强制性报告。强制性脑震荡报告、为监测工作提供资金以及为数据记者(例如教练和运动员培训员)提供培训将极大地改善流行病学研究。然而，如果没有经过验证的、对脑震荡的共识定义，以及通用数据库和全球唯一标识符(GUID)系统的开发，强制性报告将无法提供有意义的结果。然后可以将标准化监测工作的数据集联系起来，从而改善研究和临床护理的数据共享。将监测数据与组织和液体样本生物库的标准化收集、储存和管理基础设施耦合起来，可以大大改善损伤和结果研究。200这些努力可以通过公私伙伴关系的资金来催化，并通过制定现实的短期和长期目标来实现，以创建一个多年计划。然而，至少在美国，这些努力目前受到对健康保险便利和责任法案(HIPAA)规定的误解和对运动员保密的普遍关注的阻碍。运动员更广泛地使用计算机神经认知测试(CNT)可以改善脑震荡的监测，以及诊断和管理。然而，在 CNT 成为常规手术之前，必须克服几个重要的挑战。这些挑战包括缺乏标准化的管理协议，不同计算机硬件引起的技术错误的可能性，评估的认知功能类型的限制，以及缺乏合格的测试管理员和数据解释员.201尽管存在这些缺陷，但是，CNT 已经被大约40% 的美国高中雇用运动教练员.202虽然不是所有学校都负担得起，但是 CNT 可以加强地面数据收集，帮助风险暴露估计和脑震荡后恢复跟踪，以及提高向运动损伤监测网络报告的数据质量。CNT 也可能有助于评估和跟踪脑震荡后认知改善或下降，并可能有助于预测结果.203,204在学校环境中收集的 CNT 数据是否将达到由临床研究小组进行的 CNT 所达到的验证和重复性标准仍有待观察。重要的是，CNT 需要标准化和指导方针，以确定“返回运动”和“返回学习”的运动员在一个领域表现出恢复，但在其他领域仍然有症状。在临床和青少年运动员脑震荡监测和管理方面，需要对 CNT 的应用进行更多的研究。在一些关键领域，不完整的知识阻碍了儿科脑震荡领域有意义的进展。在分子和细胞水平上，迫切需要重点研究脑震荡和重复性亚震荡损伤后的轴突损伤，以阐明轴突运输和修复的变化，并更好地定义瞬时 Aβ 积累作为下游和/或未来病理学的潜在驱动因素的作用。脑震荡研究人员可能需要确定更合适的动物模型来研究分子病理学，包括 tau 蛋白及其对脑震荡后和慢性创伤脑炎病理学的贡献，因为啮齿动物和人类的大脑结构和组织大不相同。如果不能更清楚地了解创伤性脑损伤如何改变年轻、仍在发育中的大脑，以及在损伤后的数周、数月和数年内会发生什么样的病理事件，我们就只能推测这种改变的潜在生物学基础。通过使用记录线性和旋转力的传感器技术，可以改进青年体育运动中头部影响数据的收集和风险评估。这种商业上可用的设备，如果经过验证，可以确定在比赛期间和整个比赛季节中头部累积冲击力的水平，并且研究结果可以与神经影像学数据和功能结果评估联系起来。结合“击中计数”指标，传感器数据可以提高对重复性次生震荡影响的短期和长期神经心理学结果的认识。我们对慢性创伤性脑病的认识可以通过了解一般人群、受伤运动员、运动和运动位置匹配的未受伤运动员以及低风险运动中的“控制”运动员的基线率来改善。提高对风险暴露的认识可导致预防努力，包括改变做法和竞争规则。一项长达数十年的前瞻性追踪研究，追踪青年运动员的运动生涯及以后的发展，将提供有关累积性头部撞击以及长期神经心理功能障碍和痴呆风险的更确切知识。这样的研究正在 NCAA 校友中进行，他们于2003年首次接受研究，并于2013年重新评估。其他人群的研究，特别是如果 NIH 资助的话，可能会从5年的研究开始，可以进一步延长5年的增量。可能需要建立公私伙伴关系，以获得足够的资金，使多个研究中心参与进来。NCAA 已经为100多名运动员的10年重新评估提供了部分赞助，但需要来自 NIH，美国国防部(DoD)和私人慈善来源的进一步资助，以扩大评估范围，从神经心理学，通过 MRI，淀粉样蛋白，tau 和/或炎症的分子成像。理想情况下，追踪研究设计应结合流行病学和介入试验方法，并利用多个对照组，包括非接触运动员和未受伤的撞击运动员。追踪研究还将阐明认知储备的作用。老年痴呆症研究团体利用国家卫生研究院的资金以及涉及制药公司和基金会的公私伙伴关系，开创了这类研究的先例。为了使这类研究取得成功，必须首先建立更多的监测系统和数据库。如果参加影响力体育运动的运动员能够普遍获得运动员训练员的帮助，这些训练员能够在促进安全和提供基本护理的同时充当可靠的数据报告员，那么将加快努力。此外，任何纵向研究都必须包括死后分析，以便更好地了解儿童和青少年脑震荡对今后生活中神经退行性病理和痴呆发展的影响。由于缺乏严格的流行病学证据，“重返赛场”的指导方针目前受到阻碍，纵向研究的长期安全数据可能会大大改善这一点。纵向研究还可以包括确定那些未能遵循指导方针的运动员是否会经历任何负面健康影响的研究，例如持续的症状或改变发生第二次脑震荡的风险。长期前瞻性研究的基础设施可以通过建立一个以阿尔茨海默氏病神经影像学倡议(ADNI)为模型的研究联盟来创建。ADNI 为数据收集、传播协议、测试方法和生物标志物收集和分析制定了标准。目前正在国防部参与的一个版本的 ADNI (ADNI-DoD)专注于军事人群中与爆炸相关的 TBI 研究。2072014年5月，除了 NCAA 脑震荡研究，NCAA 和国防部宣布启动迄今为止最大的前瞻性运动相关脑震荡研究，该研究将在3年内监测大约37,000名 NCAA 运动员。我们可以想象，这项研究的基础设施可能最终扩展到研究年轻运动员在一个延长的纵向范围。我们对创伤性脑损伤的生物学知识仍然存在许多差距，这限制了我们开发有效药物的能力。如果我们要解决潜在的疾病病理，并超越治疗症状，就必须填补这些空白。然而，当基础创伤性脑损伤生物学的研究继续进行时，许多工作可以完成。药物再利用包括测试现有 FDA 批准的新适应症药物，可以减少费用和缩短药物批准的路径。目前的再利用试验包括哌醋甲酯治疗疼痛和精神疲劳，多巴胺受体激动剂溴隐亭治疗工作记忆，舍曲林治疗情绪和焦虑，这是最常见的影响脑震荡后长期结果的神经心理并发症。此外，黄体酮的 PROTECT III 期临床试验最近未能改善急性 TBI211后的结局，这可能提醒人们需要更多的研究来更好地理解 TBI 的基础生物学。虽然许多药物重新利用的努力主要是为了解决脑震荡症状，药物也可能影响损伤病理学和进展。对现有药物的研究也可能导致新的药物发现努力，并可能导致新的预防或管理治疗。急需新的药物治疗创伤性脑损伤和无法消除的脑震荡。在神经保护和抗炎领域的药物发现努力是特别相关的，因为它们潜在的交叉适用于神经退行性疾病，如 AD。同样，目前正在开发的治疗其他神经退行性疾病的药物可能会被重新定位，用于 TBI 或无脑震荡症状患者的检测。正如医学研究中经常出现的情况一样，脑震荡研究的最新进展提出的问题和回答的问题一样多。有证据表明脑震荡或重复性次生脑震荡后长期神经心理功能障碍和晚年痴呆，需要更多的工作来更好地理解青年参与影响性运动的含义和结果。正如本专家共识文件所概述的那样，有一条前进的道路，但实现这里概述的目标将需要公共和私营部门的合作。虽然可以通过增加知识来改进建议，但现有证据仍然可以在考虑青年参与体育运动以及实践政策和竞赛规则时为个人决策提供信息。随着人口老龄化和痴呆症的流行，我们必须更多地了解潜在的早期生活风险因素，包括与运动有关的脑震荡。家长、教练、学校董事会和孩子们做出的选择将在脑震荡科学知识的关键差距得到填补时得到更好的信息。下载参考资料|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Design+of+Performant+Recommender+Systems+using+Large-scale+Linear+Programming-based+Global+Inference)|0|
|[Rank-heterogeneous Preference Models for School Choice](https://doi.org/10.1145/3580305.3599484)|Amel Awadelkarim, Arjun Seshadri, Itai Ashlagi, Irene Lo, Johan Ugander|Stanford University; Amazon|School choice mechanism designers use discrete choice models to understand and predict families' preferences. The most widely-used choice model, the multinomial logit (MNL), is linear in school and/or household attributes. While the model is simple and interpretable, it assumes the ranked preference lists arise from a choice process that is uniform throughout the ranking, from top to bottom. In this work, we introduce two strategies for rank-heterogeneous choice modeling tailored for school choice. First, we adapt a context-dependent random utility model (CDM), considering down-rank choices as occurring in the context of earlier up-rank choices. Second, we consider stratifying the choice modeling by rank, regularizing rank-adjacent models towards one another when appropriate. Using data on household preferences from the San Francisco Unified School District (SFUSD) across multiple years, we show that the contextual models considerably improve our out-of-sample evaluation metrics across all rank positions over the non-contextual models in the literature. Meanwhile, stratifying the model by rank can yield more accurate first-choice predictions while down-rank predictions are relatively unimproved. These models provide performance upgrades that school choice researchers can adopt to improve predictions and counterfactual analyses.|学校选择机制的设计者使用离散选择模型来理解和预测家庭的偏好。最广泛使用的选择模型，多项式 logit (MNL) ，在学校和/或家庭属性中是线性的。虽然这个模型是简单和可解释的，但是它假设排名的偏好列表来自于一个从上到下在整个排名过程中是统一的选择过程。本文介绍了两种适用于学校选择的秩异质选择模型的建模策略。首先，我们采用了一个上下文相关的随机效用模型(CDM) ，考虑了在早期上层选择的情况下发生的下层选择。其次，我们考虑根据等级对选择模型进行分层，在适当的时候将相邻等级的模型相互调整。使用来自旧金山联合校区多年的家庭偏好数据，我们发现相对于文献中的非上下文模型，上下文模型大大提高了我们在所有排名位置的外部评估指标。同时，按等级对模型进行分层可以得到更准确的第一选择预测，而低等级预测相对来说没有改进。这些模型提供了学校选择研究人员可以用来改进预测和反事实分析的绩效提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rank-heterogeneous+Preference+Models+for+School+Choice)|0|
|[Connecting the Dots - Density-Connectivity Distance unifies DBSCAN, k-Center and Spectral Clustering](https://doi.org/10.1145/3580305.3599283)|Anna Beer, Andrew Draganov, Ellen Hohma, Philipp Jahn, Christian M. M. Frey, Ira Assent||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Connecting+the+Dots+-+Density-Connectivity+Distance+unifies+DBSCAN,+k-Center+and+Spectral+Clustering)|0|
|[Shilling Black-box Review-based Recommender Systems through Fake Review Generation](https://doi.org/10.1145/3580305.3599502)|HungYun Chiang, YiSyuan Chen, YunZhu Song, HongHan Shuai, Jason S. Chang|National Tsing Hua University; National Yang Ming Chiao Tung University|Review-Based Recommender Systems (RBRS) have attracted increasing research interest due to their ability to alleviate well-known cold-start problems. RBRS utilizes reviews to construct the user and items representations. However, in this paper, we argue that such a reliance on reviews may instead expose systems to the risk of being shilled. To explore this possibility, in this paper, we propose the first generation-based model for shilling attacks against RBRSs. Specifically, we learn a fake review generator through reinforcement learning, which maliciously promotes items by forcing prediction shifts after adding generated reviews to the system. By introducing the auxiliary rewards to increase text fluency and diversity with the aid of pre-trained language models and aspect predictors, the generated reviews can be effective for shilling with high fidelity. Experimental results demonstrate that the proposed framework can successfully attack three different kinds of RBRSs on the Amazon corpus with three domains and Yelp corpus. Furthermore, human studies also show that the generated reviews are fluent and informative. Finally, equipped with Attack Review Generators (ARGs), RBRSs with adversarial training are much more robust to malicious reviews.|基于评论的推荐系统(RBRS)由于其缓解众所周知的冷启动问题的能力而引起了越来越多的研究兴趣。RBRS 利用评论来构建用户和项目表示。然而，在本文中，我们认为，这种对审查的依赖反而可能使系统面临被托儿的风险。为了探索这种可能性，本文提出了第一代基于先令攻击的 RBRS 模型。具体来说，我们通过强化学习学习一个虚假的评论生成器，它在向系统添加生成的评论之后，通过强制预测变化来恶意推销项目。通过引入辅助奖励，以提高文本流畅性和多样性的帮助下，预先训练的语言模型和方面预测，生成的评论可以有效的先令与高保真度。实验结果表明，该框架能够成功地利用三个域和 Yelp 语料库对亚马逊语料库中的三种不同类型的 RBRS 进行攻击。此外，人类研究也表明，生成的评论是流畅和信息。最后，配备了攻击评论生成器(ARGs) ，具有对抗性训练的 RBRS 对恶意评论更加有力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shilling+Black-box+Review-based+Recommender+Systems+through+Fake+Review+Generation)|0|
|[Below the Surface: Summarizing Event Sequences with Generalized Sequential Patterns](https://doi.org/10.1145/3580305.3599264)|Joscha Cüppers, Jilles Vreeken||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Below+the+Surface:+Summarizing+Event+Sequences+with+Generalized+Sequential+Patterns)|0|
|[Generalized Matrix Local Low Rank Representation by Random Projection and Submatrix Propagation](https://doi.org/10.1145/3580305.3599361)|Pengtao Dang, Haiqi Zhu, Tingbo Guo, Changlin Wan, Tong Zhao, Paul Salama, Yijie Wang, Sha Cao, Chi Zhang|; Indiana University, School of Medicine; Indiana University, Bloomington; Purdue University; Genentech; Amazon; Indiana University|Detecting distinct submatrices of low rank property is a highly desirable matrix representation learning technique for the ease of data interpretation, called the matrix local low rank representation (MLLRR). Based on different mathematical assumptions of the local pattern, the MLLRR problem could be categorized into two sub-problems, namely local constant variation (LCV) and local linear low rank (LLR). Existing solutions on MLLRR only focused on the LCV problem, which misses a substantial amount of true and interesting patterns. In this work, we develop a novel matrix computational framework called RPSP (Random Probing based submatrix Propagation) that provides an effective solution for both of the LCV and LLR problems. RPSP detects local low rank patterns that grow from small submatrices of low rank property, which are determined by a random projection approach. RPSP is supported by theories of random projection. Experiments on synthetic data demonstrate that RPSP outperforms all state-of-the-art methods, with the capacity to robustly and correctly identify the low rank matrices under both LCV and LLR settings. On real-world datasets, RPSP also demonstrates its effectiveness in identifying interpretable local low rank matrices.|矩阵局部低秩表示(MLLRR)是一种非常理想的矩阵表示学习技术，它可以检测出具有低秩性质的不同子矩阵。根据对局部模式的不同数学假设，MLLRR 问题可以分为局部常变(LCV)和局部线性低秩(LLR)两个子问题。MLLRR 上的现有解决方案只关注 LCV 问题，而这个问题忽略了大量真实而有趣的模式。在这项工作中，我们开发了一个新的矩阵计算框架称为 RPSP (随机探测为基础的子矩阵传播) ，提供了一个有效的解决方案，这两个 LCV 和 LLR 问题。RPSP 检测由低秩性质的小子矩阵生成的局部低秩模式，这些小子矩阵由随机投影方法确定。RPSP 得到了随机投影理论的支持。对合成数据的实验表明，RPSP 算法优于所有的最新方法，在 LCV 和 LLR 设置下都具有鲁棒性和正确识别低秩矩阵的能力。在实际数据集上，RPSP 也证明了其识别可解释的局部低秩矩阵的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalized+Matrix+Local+Low+Rank+Representation+by+Random+Projection+and+Submatrix+Propagation)|0|
|[TWIN: Personalized Clinical Trial Digital Twin Generation](https://doi.org/10.1145/3580305.3599534)|Trisha Das, Zifeng Wang, Jimeng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TWIN:+Personalized+Clinical+Trial+Digital+Twin+Generation)|0|
|[Accelerating Dynamic Network Embedding with Billions of Parameter Updates to Milliseconds](https://doi.org/10.1145/3580305.3599250)|Haoran Deng, Yang Yang, Jiahe Li, Haoyang Cai, Shiliang Pu, Weihao Jiang|Hikvision Research Institute; Zhejiang University; Carnegie Mellon University|Network embedding, a graph representation learning method illustrating network topology by mapping nodes into lower-dimension vectors, is challenging to accommodate the ever-changing dynamic graphs in practice. Existing research is mainly based on node-by-node embedding modifications, which falls into the dilemma of efficient calculation and accuracy. Observing that the embedding dimensions are usually much smaller than the number of nodes, we break this dilemma with a novel dynamic network embedding paradigm that rotates and scales the axes of embedding space instead of a node-by-node update. Specifically, we propose the Dynamic Adjacency Matrix Factorization (DAMF) algorithm, which achieves an efficient and accurate dynamic network embedding by rotating and scaling the coordinate system where the network embedding resides with no more than the number of edge modifications changes of node embeddings. Moreover, a dynamic Personalized PageRank is applied to the obtained network embeddings to enhance node embeddings and capture higher-order neighbor information dynamically. Experiments of node classification, link prediction, and graph reconstruction on different-sized dynamic graphs suggest that DAMF advances dynamic network embedding. Further, we unprecedentedly expand dynamic network embedding experiments to billion-edge graphs, where DAMF updates billion-level parameters in less than 10ms.|网络嵌入是一种通过将节点映射为低维向量来表示网络拓扑的图形表示学习方法，在实际应用中很难适应不断变化的动态图形。现有的研究主要是基于逐个节点的嵌入修改，这种方法陷入了计算效率和精度的两难境地。针对嵌入维数通常远小于节点数的问题，提出了一种新的动态网络嵌入方法，该方法不需要逐个节点更新，而是通过对嵌入空间的轴线进行旋转和缩放来解决这一问题。具体来说，我们提出了动态邻接矩阵分解(dAMF)算法，该算法通过旋转和缩放网络嵌入所在的坐标系，在不超过节点嵌入的边修改变化量的情况下，实现了一个高效、准确的动态网络嵌入。此外，将动态个性化 PageRank 应用于所获得的网络嵌入，以增强节点的嵌入，并动态捕获高阶邻居信息。对不同大小的动态图进行节点分类、链路预测和图重构的实验表明，DAMF 推进了动态网络嵌入。进一步，我们前所未有地将动态网络嵌入实验扩展到十亿边图，其中 DAMF 在不到10ms 的时间内更新十亿级参数。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+Dynamic+Network+Embedding+with+Billions+of+Parameter+Updates+to+Milliseconds)|0|
|[MetricPrompt: Prompting Model as a Relevance Metric for Few-shot Text Classification](https://doi.org/10.1145/3580305.3599430)|Hongyuan Dong, Weinan Zhang, Wanxiang Che|Harbin Institute of Technology|Prompting methods have shown impressive performance in a variety of text mining tasks and applications, especially few-shot ones. Despite the promising prospects, the performance of prompting model largely depends on the design of prompt template and verbalizer. In this work, we propose MetricPrompt, which eases verbalizer design difficulty by reformulating few-shot text classification task into text pair relevance estimation task. MetricPrompt adopts prompting model as the relevance metric, further bridging the gap between Pre-trained Language Model's (PLM) pre-training objective and text classification task, making possible PLM's smooth adaption. Taking a training sample and a query one simultaneously, MetricPrompt captures cross-sample relevance information for accurate relevance estimation. We conduct experiments on three widely used text classification datasets across four few-shot settings. Results show that MetricPrompt outperforms manual verbalizer and other automatic verbalizer design methods across all few-shot settings, achieving new state-of-the-art (SOTA) performance.|提示方法已经在各种文本挖掘任务和应用程序中显示出了令人印象深刻的性能，特别是那些很少使用的方法。尽管激励模式前景广阔，但其性能在很大程度上取决于激励模板和语言表达器的设计。在这项工作中，我们提出了 MetricPrompt，它通过将少镜头文本分类任务重构为文本对相关性估计任务，从而减轻了语言表达器的设计难度。MetricPrompt 采用提示模型作为相关度量，进一步缩小了预训练语言模型(Pre-training Language Model，PLM)的预训练目标与文本分类任务之间的差距，使得 PLM 的顺利适应成为可能。同时采用训练样本和查询样本，MetricPrompt 捕获跨样本的相关性信息以进行准确的相关性估计。我们在三个广泛使用的文本分类数据集上通过四个少镜头设置进行实验。结果表明，MetricPrompt 在所有短镜头设置中都优于手动语音表达器和其他自动语音表达器设计方法，实现了新的最新(SOTA)性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetricPrompt:+Prompting+Model+as+a+Relevance+Metric+for+Few-shot+Text+Classification)|0|
|[Delving into Global Dialogue Structures: Structure Planning Augmented Response Selection for Multi-turn Conversations](https://doi.org/10.1145/3580305.3599304)|Tingchen Fu, Xueliang Zhao, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Delving+into+Global+Dialogue+Structures:+Structure+Planning+Augmented+Response+Selection+for+Multi-turn+Conversations)|0|
|[Partial-label Learning with Mixed Closed-set and Open-set Out-of-candidate Examples](https://doi.org/10.1145/3580305.3599460)|Shuo He, Lei Feng, Guowu Yang|University of Electronic Science and Technology of China; Nanyang Technological University|Partial-label learning (PLL) relies on a key assumption that the true label of each training example must be in the candidate label set. This restrictive assumption may be violated in complex real-world scenarios, and thus the true label of some collected examples could be unexpectedly outside the assigned candidate label set. In this paper, we term the examples whose true label is outside the candidate label set OOC (out-of-candidate) examples, and pioneer a new PLL study to learn with OOC examples. We consider two types of OOC examples in reality, i.e., the closed-set/open-set OOC examples whose true label is inside/outside the known label space. To solve this new PLL problem, we first calculate the wooden cross-entropy loss from candidate and non-candidate labels respectively, and dynamically differentiate the two types of OOC examples based on specially designed criteria. Then, for closed-set OOC examples, we conduct reversed label disambiguation in the non-candidate label set; for open-set OOC examples, we leverage them for training by utilizing an effective regularization strategy that dynamically assigns random candidate labels from the candidate label set. In this way, the two types of OOC examples can be differentiated and further leveraged for model training. Extensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods.|部分标签学习(PLL)依赖于一个关键的假设，即每个训练样本的真实标签必须在候选标签集中。在复杂的现实场景中，这种限制性假设可能会被违反，因此，一些收集的示例的真实标签可能意外地位于分配的候选标签集之外。在本文中，我们将真实标签在候选标签集外的例子称为候选标签集外的例子，并且开创了一种新的 PLL 研究方法来学习候选标签集外的例子。我们在实际中考虑两种类型的 OOC 示例，即闭集/开集 OOC 示例，它们的真实标签位于已知标签空间的内部或外部。为了解决这个新的锁相环问题，我们首先分别计算候选标签和非候选标签的木质交叉熵损失，并根据特定的准则动态区分两种类型的 OOC 实例。然后，对于闭集 OOC 例子，我们在非候选标签集中进行反向标签消歧; 对于开集 OOC 例子，我们利用它们进行训练，利用一种有效的正则化策略，从候选标签集中动态分配随机候选标签。通过这种方式，两种类型的 OOC 示例可以区分并进一步用于模型培训。大量的实验表明，我们提出的方法优于最先进的锁相环方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Partial-label+Learning+with+Mixed+Closed-set+and+Open-set+Out-of-candidate+Examples)|0|
|[COMET: Learning Cardinality Constrained Mixture of Experts with Trees and Local Search](https://doi.org/10.1145/3580305.3599278)|Shibal Ibrahim, Wenyu Chen, Hussein Hazimeh, Natalia Ponomareva, Zhe Zhao, Rahul Mazumder|Massachusetts Institute of Technology; Google Research; Google DeepMind|The sparse Mixture-of-Experts (Sparse-MoE) framework efficiently scales up model capacity in various domains, such as natural language processing and vision. Sparse-MoEs select a subset of the "experts" (thus, only a portion of the overall network) for each input sample using a sparse, trainable gate. Existing sparse gates are prone to convergence and performance issues when training with first-order optimization methods. In this paper, we introduce two improvements to current MoE approaches. First, we propose a new sparse gate: COMET, which relies on a novel tree-based mechanism. COMET is differentiable, can exploit sparsity to speed up computation, and outperforms state-of-the-art gates. Second, due to the challenging combinatorial nature of sparse expert selection, first-order methods are typically prone to low-quality solutions. To deal with this challenge, we propose a novel, permutation-based local search method that can complement first-order methods in training any sparse gate, e.g., Hash routing, Top-k, DSelect-k, and COMET. We show that local search can help networks escape bad initializations or solutions. We performed large-scale experiments on various domains, including recommender systems, vision, and natural language processing. On standard vision and recommender systems benchmarks, COMET+ (COMET with local search) achieves up to 13% improvement in ROC AUC over popular gates, e.g., Hash routing and Top-k, and up to 9% over prior differentiable gates e.g., DSelect-k. When Top-k and Hash gates are combined with local search, we see up to $100\times$ reduction in the budget needed for hyperparameter tuning. Moreover, for language modeling, our approach improves over the state-of-the-art MoEBERT model for distilling BERT on 5/7 GLUE benchmarks as well as SQuAD dataset.|稀疏混合专家(Sparse-MoE)框架有效地扩展了各种领域的模型容量，例如自然语言处理和视觉。稀疏-MoEs 使用稀疏的、可训练的门为每个输入样本选择一个“专家”子集(因此，只是整个网络的一部分)。现有的稀疏门在用一阶优化方法进行训练时容易出现收敛和性能问题。在本文中，我们介绍了两个改进的目前的教育方法。首先，我们提出了一种新的稀疏门: COMET，它依赖于一种新的基于树的机制。COMET 是可微的，可以利用稀疏性来加速计算，并且性能优于最先进的门。其次，由于稀疏专家选择具有挑战性的组合性质，一阶方法通常倾向于低质量的解决方案。为了应对这一挑战，我们提出了一种新颖的基于置换的局部搜索方法，可以补充一阶方法训练任何稀疏门，例如，散列路由，Top-k，DSelect-k 和 COMET。我们展示了本地搜索可以帮助网络逃避糟糕的初始化或解决方案。我们在不同的领域进行了大规模的实验，包括推荐系统、视觉和自然语言处理。在标准愿景和推荐系统基准上，COMET + (本地搜索的 COMET)在 ROC AUC 比流行的门(如散列路由和 Top-k)提高了13% ，比以前的可微分门(如 DSelect-k)提高了9% 。当 Top-k 和 Hash 门与本地搜索相结合时，我们看到超参数调优所需的预算减少了100倍。此外，对于语言建模，我们的方法改进了最先进的 MoEBERT 模型，用于提取5/7 GLUE 基准测试和 SQuAD 数据集上的 BERT。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COMET:+Learning+Cardinality+Constrained+Mixture+of+Experts+with+Trees+and+Local+Search)|0|
|[Exploiting Relation-aware Attribute Representation Learning in Knowledge Graph Embedding for Numerical Reasoning](https://doi.org/10.1145/3580305.3599338)|Gayeong Kim, Sookyung Kim, Ko Keun Kim, Suchan Park, Heesoo Jung, Hogun Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Relation-aware+Attribute+Representation+Learning+in+Knowledge+Graph+Embedding+for+Numerical+Reasoning)|0|
|[Efficient Distributed Approximate k-Nearest Neighbor Graph Construction by Multiway Random Division Forest](https://doi.org/10.1145/3580305.3599327)|SangHong Kim, HaMyung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Distributed+Approximate+k-Nearest+Neighbor+Graph+Construction+by+Multiway+Random+Division+Forest)|0|
|[MM-DAG: Multi-task DAG Learning for Multi-modal Data - with Application for Traffic Congestion Analysis](https://doi.org/10.1145/3580305.3599436)|Tian Lan, Ziyue Li, Zhishuai Li, Lei Bai, Man Li, Fugee Tsung, Wolfgang Ketter, Rui Zhao, Chen Zhang|University of Cologne; Tsinghua University; The Hong Kong University of Science and Technology; SenseTime Research; Shanghai AI Laboratory; The Hong Kong University of Science and Technology (Guangzhou)|This paper proposes to learn Multi-task, Multi-modal Direct Acyclic Graphs (MM-DAGs), which are commonly observed in complex systems, e.g., traffic, manufacturing, and weather systems, whose variables are multi-modal with scalars, vectors, and functions. This paper takes the traffic congestion analysis as a concrete case, where a traffic intersection is usually regarded as a DAG. In a road network of multiple intersections, different intersections can only have some overlapping and distinct variables observed. For example, a signalized intersection has traffic light-related variables, whereas unsignalized ones do not. This encourages the multi-task design: with each DAG as a task, the MM-DAG tries to learn the multiple DAGs jointly so that their consensus and consistency are maximized. To this end, we innovatively propose a multi-modal regression for linear causal relationship description of different variables. Then we develop a novel Causality Difference (CD) measure and its differentiable approximator. Compared with existing SOTA measures, CD can penalize the causal structural difference among DAGs with distinct nodes and can better consider the uncertainty of causal orders. We rigidly prove our design's topological interpretation and consistency properties. We conduct thorough simulations and one case study to show the effectiveness of our MM-DAG. The code is available under https://github.com/Lantian72/MM-DAG|本文提出学习多任务、多模态直接无环图(MM-DAGs) ，这是在交通、制造、天气等复杂系统中常见的图形，其变量是多模态的，包括标量、向量和函数。本文以交通堵塞分析作为一个具体案例，其中交通十字路口通常被视为一个 DAG。在一个多交叉口的道路网络中，不同的交叉口只能观察到一些重叠的、不同的变量。例如，信号交叉口有与交通灯相关的变量，而无信号交叉口没有。这鼓励了多任务设计: 将每个 DAG 作为一个任务，MM-DAG 试图联合学习多个 DAG，以便最大化它们的一致性和一致性。为此，我们创新性地提出了一种多模态回归方法来描述不同变量之间的线性因果关系。然后我们发展了一个新的因果差分(CD)测度及其可微逼近器。与现有的 SOTA 方法相比，CD 方法能够更好地考虑因果顺序的不确定性，并且能够惩罚具有不同节点的 DAGs 之间的因果结构差异。我们严格证明了我们的设计的拓扑解释和一致性性质。我们进行了彻底的模拟和一个案例研究，以显示我们的 MM-DAG 的有效性。代码可在 https://github.com/lantian72/mm-dag 下查阅|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MM-DAG:+Multi-task+DAG+Learning+for+Multi-modal+Data+-+with+Application+for+Traffic+Congestion+Analysis)|0|
|[Who Should Be Given Incentives? Counterfactual Optimal Treatment Regimes Learning for Recommendation](https://doi.org/10.1145/3580305.3599550)|Haoxuan Li, Chunyuan Zheng, Peng Wu, Kun Kuang, Yue Liu, Peng Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Who+Should+Be+Given+Incentives?+Counterfactual+Optimal+Treatment+Regimes+Learning+for+Recommendation)|0|
|[UCEpic: Unifying Aspect Planning and Lexical Constraints for Generating Explanations in Recommendation](https://doi.org/10.1145/3580305.3599535)|Jiacheng Li, Zhankui He, Jingbo Shang, Julian J. McAuley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UCEpic:+Unifying+Aspect+Planning+and+Lexical+Constraints+for+Generating+Explanations+in+Recommendation)|0|
|[Learning-Based Ad Auction Design with Externalities: The Framework and A Matching-Based Approach](https://doi.org/10.1145/3580305.3599403)|Ningyuan Li, Yunxuan Ma, Yang Zhao, Zhijian Duan, Yurong Chen, Zhilin Zhang, Jian Xu, Bo Zheng, Xiaotie Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning-Based+Ad+Auction+Design+with+Externalities:+The+Framework+and+A+Matching-Based+Approach)|0|
|[Communication Efficient Distributed Newton Method with Fast Convergence Rates](https://doi.org/10.1145/3580305.3599280)|Chengchang Liu, Lesi Chen, Luo Luo, John C. S. Lui|Fudan University; The Chinese University of Hong Kong; Chinese University of Hong Kong|We propose a communication and computation efficient second-order method for distributed optimization. For each iteration, our method only requires $\mathcal{O}(d)$ communication complexity, where $d$ is the problem dimension. We also provide theoretical analysis to show the proposed method has the similar convergence rate as the classical second-order optimization algorithms. Concretely, our method can find~$\big(\epsilon, \sqrt{dL\epsilon}\,\big)$-second-order stationary points for nonconvex problem by $\mathcal{O}\big(\sqrt{dL}\,\epsilon^{-3/2}\big)$ iterations, where $L$ is the Lipschitz constant of Hessian. Moreover, it enjoys a local superlinear convergence under the strongly-convex assumption. Experiments on both convex and nonconvex problems show that our proposed method performs significantly better than baselines.|提出了一种分布式优化的通信和计算有效的二阶方法。对于每个迭代，我们的方法只需要 $mathcal { O }(d) $通信复杂性，其中 $d $是问题维度。理论分析表明，该方法与经典的二阶优化算法具有相似的收敛速度。具体地说，我们的方法可以通过数学上的{ O } big (sqrt { dL } ，epsilon ^ {-3/2} big)迭代找到非凸问题的 ~ $big (epsilon，sqrt { dL epsilon } ，big) $- 二阶驻点，其中 $L $是 Hessian 的 Lipschitz 常数。在强凸假设下，该算法具有局部超线性收敛性。对凸问题和非凸问题的实验表明，该方法的性能明显优于基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Communication+Efficient+Distributed+Newton+Method+with+Fast+Convergence+Rates)|0|
|[Meta Multi-agent Exercise Recommendation: A Game Application Perspective](https://doi.org/10.1145/3580305.3599429)|Fei Liu, Xuegang Hu, Shuochen Liu, Chenyang Bu, Le Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta+Multi-agent+Exercise+Recommendation:+A+Game+Application+Perspective)|0|
|[Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation](https://doi.org/10.1145/3580305.3599292)|JinDuk Park, Siqing Li, Xin Cao, WonYong Shin|Yonsei University; The University of New South Wales|The multi-criteria (MC) recommender system, which leverages MC rating information in a wide range of e-commerce areas, is ubiquitous nowadays. Surprisingly, although graph neural networks (GNNs) have been widely applied to develop various recommender systems due to GNN's high expressive capability in learning graph representations, it has been still unexplored how to design MC recommender systems with GNNs. In light of this, we make the first attempt towards designing a GNN-aided MC recommender system. Specifically, rather than straightforwardly adopting existing GNN-based recommendation methods, we devise a novel criteria preference-aware light graph convolution CPA-LGC method, which is capable of precisely capturing the criteria preference of users as well as the collaborative signal in complex high-order connectivities. To this end, we first construct an MC expansion graph that transforms user--item MC ratings into an expanded bipartite graph to potentially learn from the collaborative signal in MC ratings. Next, to strengthen the capability of criteria preference awareness, CPA-LGC incorporates newly characterized embeddings, including user-specific criteria-preference embeddings and item-specific criterion embeddings, into our graph convolution model. Through comprehensive evaluations using four real-world datasets, we demonstrate (a) the superiority over benchmark MC recommendation methods and benchmark recommendation methods using GNNs with tremendous gains, (b) the effectiveness of core components in CPA-LGC, and (c) the computational efficiency.|多准则推荐系统在电子商贸领域广泛应用，充分利用多准则评级信息。令人惊讶的是，尽管图神经网络(GNN)由于其在学习图表示方面的高度表达能力而被广泛应用于开发各种推荐系统，但是如何利用 GNN 设计 MC 推荐系统仍然是一个未知数。有鉴于此，我们首次尝试设计一个 GNN 辅助的 MC 推荐系统。具体而言，我们不直接采用现有的基于 GNN 的推荐方法，而是设计了一种新的标准偏好感知光图卷积 CPA-LGC 方法，该方法能够精确地捕获用户的标准偏好以及复杂高阶连接中的协作信号。为此，我们首先构建一个 MC 扩展图，将用户-项目 MC 评分转换为一个扩展的二分图，以便潜在地学习 MC 评分中的协作信号。接下来，为了加强标准偏好意识的能力，CPA-LGC 将新的特征嵌入，包括用户特定的标准偏好嵌入和项目特定的标准嵌入，纳入我们的图卷积模型。通过使用四个实际数据集的综合评估，我们证明了(a)使用 GNN 的基准 MC 推荐方法和基准推荐方法的优越性，(b) CPA-LGC 中核心组件的有效性，以及(c)计算效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Criteria+Tell+You+More+than+Ratings:+Criteria+Preference-Aware+Light+Graph+Convolution+for+Effective+Multi-Criteria+Recommendation)|0|
|[Locality Sensitive Hashing for Optimizing Subgraph Query Processing in Parallel Computing Systems](https://doi.org/10.1145/3580305.3599419)|Peng Peng, Shengyi Ji, Zhen Tian, Hongbo Jiang, Weiguo Zheng, Xuecang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Locality+Sensitive+Hashing+for+Optimizing+Subgraph+Query+Processing+in+Parallel+Computing+Systems)|0|
|[Deep Pipeline Embeddings for AutoML](https://doi.org/10.1145/3580305.3599303)|Sebastian PinedaArango, Josif Grabocka|University of Freiburg|Automated Machine Learning (AutoML) is a promising direction for democratizing AI by automatically deploying Machine Learning systems with minimal human expertise. The core technical challenge behind AutoML is optimizing the pipelines of Machine Learning systems (e.g. the choice of preprocessing, augmentations, models, optimizers, etc.). Existing Pipeline Optimization techniques fail to explore deep interactions between pipeline stages/components. As a remedy, this paper proposes a novel neural architecture that captures the deep interaction between the components of a Machine Learning pipeline. We propose embedding pipelines into a latent representation through a novel per-component encoder mechanism. To search for optimal pipelines, such pipeline embeddings are used within deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup. Furthermore, we meta-learn the parameters of the pipeline embedding network using existing evaluations of pipelines on diverse collections of related datasets (a.k.a. meta-datasets). Through extensive experiments on three large-scale meta-datasets, we demonstrate that pipeline embeddings yield state-of-the-art results in Pipeline Optimization.|自动机器学习(AutoML)是通过自动部署具有最少人类专业知识的机器学习系统来实现人工智能大众化的一个有前途的方向。AutoML 背后的核心技术挑战是优化机器学习系统的管道(例如，预处理、扩展、模型、优化器等的选择)。现有的流水线优化技术无法探索流水线阶段/组件之间的深层交互。作为补救措施，本文提出了一种新颖的神经网络结构，该结构能够捕捉机器学习流水线各组件之间的深层交互。我们提出了一种新的每组件编码机制，将管道嵌入到潜在表示中。为了寻找最佳管道，这种管道嵌入在贝叶斯优化设置内的深核高斯过程代理中使用。此外，我们使用现有的对不同相关数据集(也称为元数据集)上的管道的评估来元学习管道嵌入网络的参数。通过在三个大规模元数据集上的大量实验，我们证明了流水线嵌入在流水线优化中产生了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Pipeline+Embeddings+for+AutoML)|0|
|[FedAPEN: Personalized Cross-silo Federated Learning with Adaptability to Statistical Heterogeneity](https://doi.org/10.1145/3580305.3599344)|Zhen Qin, Shuiguang Deng, Mingyu Zhao, Xueqiang Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedAPEN:+Personalized+Cross-silo+Federated+Learning+with+Adaptability+to+Statistical+Heterogeneity)|0|
|[All in One: Multi-Task Prompting for Graph Neural Networks](https://doi.org/10.1145/3580305.3599256)|Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, Jihong Guan|Southeast University; The Hong Kong University of Science and Technology (Guangzhou); The Chinese University of Hong Kong; Tongji University|Recently, ''pre-training and fine-tuning'' has been adopted as a standard workflow for many graph tasks since it can take general graph knowledge to relieve the lack of graph annotations from each application. However, graph tasks with node level, edge level, and graph level are far diversified, making the pre-training pretext often incompatible with these multiple tasks. This gap may even cause a ''negative transfer'' to the specific application, leading to poor results. Inspired by the prompt learning in natural language processing (NLP), which has presented significant effectiveness in leveraging prior knowledge for various NLP tasks, we study the prompting topic for graphs with the motivation of filling the gap between pre-trained models and various graph tasks. In this paper, we propose a novel multi-task prompting method for graph models. Specifically, we first unify the format of graph prompts and language prompts with the prompt token, token structure, and inserting pattern. In this way, the prompting idea from NLP can be seamlessly introduced to the graph area. Then, to further narrow the gap between various graph tasks and state-of-the-art pre-training strategies, we further study the task space of various graph applications and reformulate downstream problems to the graph-level task. Afterward, we introduce meta-learning to efficiently learn a better initialization for the multi-task prompt of graphs so that our prompting framework can be more reliable and general for different tasks. We conduct extensive experiments, results from which demonstrate the superiority of our method.|近年来，“预训练和微调”已经成为许多图形任务的标准工作流，因为它需要一般的图形知识来解决每个应用程序缺乏图形注释的问题。然而，具有节点级、边级和图级的图形任务种类繁多，使得预训练的借口往往与这些多任务不相容。这种差距甚至可能导致特定应用程序的“负转移”，从而导致较差的结果。自然语言处理中的快速学习在利用先验知识完成各种自然语言处理任务方面表现出了显著的效果，受此启发，我们研究了图形的提示主题，以填补预先训练的模型和各种图形任务之间的空白。本文提出了一种新的图模型多任务提示方法。具体来说，我们首先将图形提示符和语言提示符的格式与提示符标记、标记结构和插入模式统一起来。通过这种方式，可以将自然语言处理中的提示思想无缝地引入到图区域中。然后，为了进一步缩小各种图形任务与最先进的预训练策略之间的差距，我们进一步研究了各种图形应用的任务空间，并将下游问题重新表述为图形级任务。在此基础上，引入元学习，有效地学习图形的多任务提示的初始化，使得提示框架对于不同的任务具有更高的可靠性和通用性。我们进行了广泛的实验，实验结果证明了我们方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=All+in+One:+Multi-Task+Prompting+for+Graph+Neural+Networks)|0|
|[GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized Adaptive Testing](https://doi.org/10.1145/3580305.3599367)|Hangyu Wang, Ting Long, Liang Yin, Weinan Zhang, Wei Xia, Qichen Hong, Dingyin Xia, Ruiming Tang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GMOCAT:+A+Graph-Enhanced+Multi-Objective+Method+for+Computerized+Adaptive+Testing)|0|
|[Theoretical Convergence Guaranteed Resource-Adaptive Federated Learning with Mixed Heterogeneity](https://doi.org/10.1145/3580305.3599521)|Yangyang Wang, Xiao Zhang, Mingyi Li, Tian Lan, Huashan Chen, Hui Xiong, Xiuzhen Cheng, Dongxiao Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Theoretical+Convergence+Guaranteed+Resource-Adaptive+Federated+Learning+with+Mixed+Heterogeneity)|0|
|[Efficient Bi-Level Optimization for Recommendation Denoising](https://doi.org/10.1145/3580305.3599324)|Zongwei Wang, Min Gao, Wentao Li, Junliang Yu, Linxin Guo, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Bi-Level+Optimization+for+Recommendation+Denoising)|0|
|[Meta Graph Learning for Long-tail Recommendation](https://doi.org/10.1145/3580305.3599428)|Chunyu Wei, Jian Liang, Di Liu, Zehui Dai, Mang Li, Fei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta+Graph+Learning+for+Long-tail+Recommendation)|0|
|[Personalized Federated Learning with Parameter Propagation](https://doi.org/10.1145/3580305.3599464)|Jun Wu, Wenxuan Bao, Elizabeth A. Ainsworth, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Federated+Learning+with+Parameter+Propagation)|0|
|[Serverless Federated AUPRC Optimization for Multi-Party Collaborative Imbalanced Data Mining](https://doi.org/10.1145/3580305.3599499)|Xidong Wu, Zhengmian Hu, Jian Pei, Heng Huang|University of Pittsburgh; Duke University|Multi-party collaborative training, such as distributed learning and federated learning, is used to address the big data challenges. However, traditional multi-party collaborative training algorithms were mainly designed for balanced data mining tasks and are intended to optimize accuracy (\emph{e.g.}, cross-entropy). The data distribution in many real-world applications is skewed and classifiers, which are trained to improve accuracy, perform poorly when applied to imbalanced data tasks since models could be significantly biased toward the primary class. Therefore, the Area Under Precision-Recall Curve (AUPRC) was introduced as an effective metric. Although single-machine AUPRC maximization methods have been designed, multi-party collaborative algorithm has never been studied. The change from the single-machine to the multi-party setting poses critical challenges.   To address the above challenge, we study the serverless multi-party collaborative AUPRC maximization problem since serverless multi-party collaborative training can cut down the communications cost by avoiding the server node bottleneck, and reformulate it as a conditional stochastic optimization problem in a serverless multi-party collaborative learning setting and propose a new ServerLess biAsed sTochastic gradiEnt (SLATE) algorithm to directly optimize the AUPRC. After that, we use the variance reduction technique and propose ServerLess biAsed sTochastic gradiEnt with Momentum-based variance reduction (SLATE-M) algorithm to improve the convergence rate, which matches the best theoretical convergence result reached by the single-machine online method. To the best of our knowledge, this is the first work to solve the multi-party collaborative AUPRC maximization problem.|多方协作培训，如分布式学习和联合学习，被用来解决大数据的挑战。然而，传统的多方协同训练算法主要是针对平衡的数据挖掘任务而设计的，其目的是优化精度(例如: 交叉熵)。许多实际应用中的数据分布是倾斜的，分类器经过训练以提高准确性，但在应用于不平衡的数据任务时表现不佳，因为模型可能明显偏向于主类。因此，引入精确回忆曲线下面积(AUPRC)作为一个有效的度量指标。虽然单机 AUPRC 最大化方法已经设计出来，但是多方协作算法还没有得到研究。从单一机器设置到多方设置的变化提出了关键的挑战。为了解决上述问题，我们研究了无服务器多方协作的 AUPRC 最大化问题，因为无服务器多方协作培训可以通过避免服务器节点瓶颈来降低通信成本，并将其重新表述为无服务器多方协作环境中的条件随机最佳化问题，提出了一种新的无服务器偏置 sTo侯机梯度(slATE)算法来直接优化 AUPRC，该算法可以用于解决无服务器多方协作的合作学习。在此基础上，利用方差减少技术，提出了基于动量方差减少(SLATE-M)的 ServerLess 偏向随机梯度算法，提高了算法的收敛速度，达到了单机在线算法的最佳理论收敛效果。据我们所知，这是第一个解决多方协作 AUPRC 最大化问题的工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Serverless+Federated+AUPRC+Optimization+for+Multi-Party+Collaborative+Imbalanced+Data+Mining)|0|
|[MSSRNet: Manipulating Sequential Style Representation for Unsupervised Text Style Transfer](https://doi.org/10.1145/3580305.3599438)|Yazheng Yang, Zhou Zhao, Qi Liu|The University of Hong Kong; Zhejiang University|Unsupervised text style transfer task aims to rewrite a text into target style while preserving its main content. Traditional methods rely on the use of a fixed-sized vector to regulate text style, which is difficult to accurately convey the style strength for each individual token. In fact, each token of a text contains different style intensity and makes different contribution to the overall style. Our proposed method addresses this issue by assigning individual style vector to each token in a text, allowing for fine-grained control and manipulation of the style strength. Additionally, an adversarial training framework integrated with teacher-student learning is introduced to enhance training stability and reduce the complexity of high-dimensional optimization. The results of our experiments demonstrate the efficacy of our method in terms of clearly improved style transfer accuracy and content preservation in both two-style transfer and multi-style transfer settings.|无监督文本样式转换任务的目标是在保留文本主要内容的同时将文本重写成目标样式。传统的方法依赖于使用固定大小的向量来调整文本样式，这很难准确地表达每个单独标记的样式强度。事实上，文本的每一个标记都包含着不同的风格强度，并对整体风格做出不同的贡献。我们提出的方法通过为文本中的每个标记分配单独的样式向量来解决这个问题，从而允许对样式强度进行细粒度控制和操作。此外，为了提高训练的稳定性，降低高维优化的复杂性，提出了一种结合师生学习的对抗性训练框架。实验结果表明，该方法在两种类型和多种类型的转移设置下，均能明显提高文体转移的准确性和内容保存率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSSRNet:+Manipulating+Sequential+Style+Representation+for+Unsupervised+Text+Style+Transfer)|0|
|[Knowledge Graph Self-Supervised Rationalization for Recommendation](https://doi.org/10.1145/3580305.3599400)|Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang|The University of Hong Kong; Tencent|In this paper, we introduce a new self-supervised rationalization method, called KGRec, for knowledge-aware recommender systems. To effectively identify informative knowledge connections, we propose an attentive knowledge rationalization mechanism that generates rational scores for knowledge triplets. With these scores, KGRec integrates generative and contrastive self-supervised tasks for recommendation through rational masking. To highlight rationales in the knowledge graph, we design a novel generative task in the form of masking-reconstructing. By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales. To further rationalize the effect of collaborative interactions on knowledge graph learning, we introduce a contrastive learning task that aligns signals from knowledge and user-item interaction views. To ensure noise-resistant contrasting, potential noisy edges in both graphs judged by the rational scores are masked. Extensive experiments on three real-world datasets demonstrate that KGRec outperforms state-of-the-art methods. We also provide the implementation codes for our approach at https://github.com/HKUDS/KGRec.|本文针对知识感知推荐系统，提出了一种新的自监督合理化方法 KGRec。为了有效地识别信息知识连接，我们提出了一种注意的知识合理化机制，为知识三元组生成合理的分数。根据这些分数，KGRec 通过合理的掩蔽将生成性和对比性自我监督任务集成到推荐系统中。为了突出知识图中的基本原理，我们设计了一个新的生成任务，即掩蔽-重构。通过用高理性分数掩盖重要的知识，KGRec 被训练重建和突出作为基本原理的有用的知识联系。为了进一步合理化协作交互对知识图学习的影响，我们引入了一个对比学习任务，该任务从知识和用户项目交互视图中调整信号。为了确保抗噪声的对比，在两个图的潜在噪声边缘判断有理分数被掩盖。在三个真实世界数据集上的大量实验表明，KGRec 的性能优于最先进的方法。我们亦会在 https://github.com/hkuds/kgrec 为我们的方法提供实施守则。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Self-Supervised+Rationalization+for+Recommendation)|0|
|[FedCP: Separating Feature Information for Personalized Federated Learning via Conditional Policy](https://doi.org/10.1145/3580305.3599345)|Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Haibing Guan|Louisiana State University; Shanghai Jiao Tong University; Queen’s University Belfast|Recently, personalized federated learning (pFL) has attracted increasing attention in privacy protection, collaborative learning, and tackling statistical heterogeneity among clients, e.g., hospitals, mobile smartphones, etc. Most existing pFL methods focus on exploiting the global information and personalized information in the client-level model parameters while neglecting that data is the source of these two kinds of information. To address this, we propose the Federated Conditional Policy (FedCP) method, which generates a conditional policy for each sample to separate the global information and personalized information in its features and then processes them by a global head and a personalized head, respectively. FedCP is more fine-grained to consider personalization in a sample-specific manner than existing pFL methods. Extensive experiments in computer vision and natural language processing domains show that FedCP outperforms eleven state-of-the-art methods by up to 6.69%. Furthermore, FedCP maintains its superiority when some clients accidentally drop out, which frequently happens in mobile settings. Our code is public at https://github.com/TsingZ0/FedCP.|近年来，个性化联邦学习(pFL)在保护个人隐私、合作学习以及处理客户之间的统计异质性等方面受到越来越多的关注，例如医院、移动智能手机等。现有的 pFL 方法大多侧重于利用客户端模型参数中的全局信息和个性化信息，而忽视了数据是这两类信息的来源。为了解决这个问题，我们提出了联邦条件策略(FedCP)方法，该方法为每个样本生成一个条件策略来分离其特征中的全局信息和个性化信息，然后分别通过一个全局头和一个个性化头来处理它们。与现有的 pFL 方法相比，FedCP 更加细粒度地以特定于样本的方式考虑个性化。在计算机视觉和自然语言处理领域的大量实验表明，FedCP 比11种最先进的方法的性能提高了6.69% 。此外，当一些客户端意外退出时，FedCP 仍然保持其优势，这种情况在移动设置中经常发生。我们的代码在 https://github.com/tsingz0/fedcp 是公开的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedCP:+Separating+Feature+Information+for+Personalized+Federated+Learning+via+Conditional+Policy)|0|
|[CFGL-LCR: A Counterfactual Graph Learning Framework for Legal Case Retrieval](https://doi.org/10.1145/3580305.3599273)|Kun Zhang, Chong Chen, Yuanzhuo Wang, Qi Tian, Long Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CFGL-LCR:+A+Counterfactual+Graph+Learning+Framework+for+Legal+Case+Retrieval)|0|
|[DM-PFL: Hitchhiking Generic Federated Learning for Efficient Shift-Robust Personalization](https://doi.org/10.1145/3580305.3599311)|Wenhao Zhang, Zimu Zhou, Yansheng Wang, Yongxin Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DM-PFL:+Hitchhiking+Generic+Federated+Learning+for+Efficient+Shift-Robust+Personalization)|0|
|[Efficient Approximation Algorithms for Spanning Centrality](https://doi.org/10.1145/3580305.3599323)|Shiqi Zhang, Renchi Yang, Jing Tang, Xiaokui Xiao, Bo Tang|The Hong Kong University of Science and Technology (Guangzhou); National University of Singapore; Southern University of Science and Technology; Hong Kong Baptist University|Given a graph $\mathcal{G}$, the spanning centrality (SC) of an edge $e$ measures the importance of $e$ for $\mathcal{G}$ to be connected. In practice, SC has seen extensive applications in computational biology, electrical networks, and combinatorial optimization. However, it is highly challenging to compute the SC of all edges (AESC) on large graphs. Existing techniques fail to deal with such graphs, as they either suffer from expensive matrix operations or require sampling numerous long random walks. To circumvent these issues, this paper proposes TGT and its enhanced version TGT+, two algorithms for AESC computation that offers rigorous theoretical approximation guarantees. In particular, TGT remedies the deficiencies of previous solutions by conducting deterministic graph traversals with carefully-crafted truncated lengths. TGT+ further advances TGT in terms of both empirical efficiency and asymptotic performance while retaining result quality, based on the combination of TGT with random walks and several additional heuristic optimizations. We experimentally evaluate TGT+ against recent competitors for AESC using a variety of real datasets. The experimental outcomes authenticate that TGT+ outperforms the state of the arts often by over one order of magnitude speedup without degrading the accuracy.|给定一个图 $mathal { G } $，边 $e $的生成中心性(SC)度量 $e $对于要连接的 $mathal { G } $的重要性。在实践中，SC 已经在计算生物学、电力网络和组合优化等领域得到了广泛的应用。然而，计算大图上所有边的 SC (AESC)是一个非常具有挑战性的问题。现有的技术无法处理这样的图，因为它们要么需要进行昂贵的矩阵运算，要么需要对大量的长随机游动进行采样。为了解决这些问题，本文提出了 TGT 及其改进版本 TGT + ，这两种 AESC 计算算法提供了严格的理论近似保证。特别是，TGT 通过使用精心设计的截断长度进行确定性图遍历，弥补了以前解决方案的缺陷。TGT + 基于 TGT 与随机游动的结合以及几个附加的启发式优化，在保持结果质量的同时，进一步提高了 TGT 的经验有效性和渐近性能。我们使用各种实际数据集对 AESC 的最近竞争对手进行了 TGT + 的实验评估。实验结果表明，在不降低准确性的情况下，TGT + 的性能通常比现有技术水平高出一个数量级。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Approximation+Algorithms+for+Spanning+Centrality)|0|
|[Improving Search Clarification with Structured Information Extracted from Search Results](https://doi.org/10.1145/3580305.3599389)|Ziliang Zhao, Zhicheng Dou, Yu Guo, Zhao Cao, Xiaohua Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Search+Clarification+with+Structured+Information+Extracted+from+Search+Results)|0|
|[Dense Representation Learning and Retrieval for Tabular Data Prediction](https://doi.org/10.1145/3580305.3599305)|Lei Zheng, Ning Li, Xianyu Chen, Quan Gan, Weinan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dense+Representation+Learning+and+Retrieval+for+Tabular+Data+Prediction)|0|
|[A Sublinear Time Algorithm for Opinion Optimization in Directed Social Networks via Edge Recommendation](https://doi.org/10.1145/3580305.3599247)|Xiaotian Zhou, Liwang Zhu, Wei Li, Zhongzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Sublinear+Time+Algorithm+for+Opinion+Optimization+in+Directed+Social+Networks+via+Edge+Recommendation)|0|
|[Path-Specific Counterfactual Fairness for Recommender Systems](https://doi.org/10.1145/3580305.3599462)|Yaochen Zhu, Jing Ma, Liang Wu, Qi Guo, Liangjie Hong, Jundong Li|LinkedIn Inc.; University of Virginia|Recommender systems (RSs) have become an indispensable part of online platforms. With the growing concerns of algorithmic fairness, RSs are not only expected to deliver high-quality personalized content, but are also demanded not to discriminate against users based on their demographic information. However, existing RSs could capture undesirable correlations between sensitive features and observed user behaviors, leading to biased recommendations. Most fair RSs tackle this problem by completely blocking the influences of sensitive features on recommendations. But since sensitive features may also affect user interests in a fair manner (e.g., race on culture-based preferences), indiscriminately eliminating all the influences of sensitive features inevitably degenerate the recommendations quality and necessary diversities. To address this challenge, we propose a path-specific fair RS (PSF-RS) for recommendations. Specifically, we summarize all fair and unfair correlations between sensitive features and observed ratings into two latent proxy mediators, where the concept of path-specific bias (PS-Bias) is defined based on path-specific counterfactual inference. Inspired by Pearl's minimal change principle, we address the PS-Bias by minimally transforming the biased factual world into a hypothetically fair world, where a fair RS model can be learned accordingly by solving a constrained optimization problem. For the technical part, we propose a feasible implementation of PSF-RS, i.e., PSF-VAE, with weakly-supervised variational inference, which robustly infers the latent mediators such that unfairness can be mitigated while necessary recommendation diversities can be maximally preserved simultaneously. Experiments conducted on semi-simulated and real-world datasets demonstrate the effectiveness of PSF-RS.|推荐系统已经成为在线平台不可或缺的一部分。随着对算法公平性的日益关注，RSS 不仅被期望提供高质量的个性化内容，而且被要求不因用户的人口统计信息而歧视用户。然而，现有的 RSS 可能捕获敏感特性和观察到的用户行为之间不希望看到的相关性，从而导致有偏见的推荐。大多数公平的 RSS 通过完全屏蔽敏感特性对推荐的影响来解决这个问题。但是，由于敏感特性也可能以公平的方式影响用户的兴趣(例如，基于文化的偏好的种族) ，不加区分地消除敏感特性的所有影响必然会降低推荐的质量和必要的多样性。为了应对这一挑战，我们提出了一个路径特定公平 RS (PSF-RS)的建议。具体而言，我们将敏感特征和观察评分之间的所有公平和不公平的相关性总结为两个潜在的代理中介，其中路径特异性偏倚(PS-Bias)的概念是基于路径特异性反事实推断定义的。受珀尔的最小改变原则的启发，我们通过最小化地将有偏见的现实世界转化为一个假设的公平世界，在这个假设的公平世界中，可以通过解决一个受限制的最佳化问题来相应地学习一个公平的遥感模型，从而解决偏差问题。在技术部分，我们提出了一种可行的 PSF-RS 实现方法，即 PSF-VAE，该方法利用弱监督变分推理强有力地推导出潜在的中介因子，从而在最大限度地保留必要的推荐多样性的同时减少不公平性。在半模拟和真实数据集上进行的实验证明了 PSF-RS 算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Path-Specific+Counterfactual+Fairness+for+Recommender+Systems)|0|
|[Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach](https://doi.org/10.1145/3580305.3599788)|Zhangming Chan, Yu Zhang, Shuguang Han, Yong Bai, XiangRong Sheng, Siyuan Lou, Jiacen Hu, Baolin Liu, Yuning Jiang, Jian Xu, Bo Zheng|University of Science and Technology Beijing; Alibaba Group; Nanjing University|Conversion rate (CVR) prediction is one of the core components in online recommender systems, and various approaches have been proposed to obtain accurate and well-calibrated CVR estimation. However, we observe that a well-trained CVR prediction model often performs sub-optimally during sales promotions. This can be largely ascribed to the problem of the data distribution shift, in which the conventional methods no longer work. To this end, we seek to develop alternative modeling techniques for CVR prediction. Observing similar purchase patterns across different promotions, we propose reusing the historical promotion data to capture the promotional conversion patterns. Herein, we propose a novel \textbf{H}istorical \textbf{D}ata \textbf{R}euse (\textbf{HDR}) approach that first retrieves historically similar promotion data and then fine-tunes the CVR prediction model with the acquired data for better adaptation to the promotion mode. HDR consists of three components: an automated data retrieval module that seeks similar data from historical promotions, a distribution shift correction module that re-weights the retrieved data for better aligning with the target promotion, and a TransBlock module that quickly fine-tunes the original model for better adaptation to the promotion mode. Experiments conducted with real-world data demonstrate the effectiveness of HDR, as it improves both ranking and calibration metrics to a large extent. HDR has also been deployed on the display advertising system in Alibaba, bringing a lift of $9\%$ RPM and $16\%$ CVR during Double 11 Sales in 2022.|转化率(CVR)预测是在线推荐系统的核心组成部分之一，为了获得准确、标定良好的 CVR 估计，人们提出了各种方法。然而，我们观察到，训练有素的 CVR 预测模型在促销期间往往表现不佳。这在很大程度上归因于数据分布偏移的问题，在这个问题中，传统的方法不再起作用。为此，我们寻求发展可替代的 CVR 预测建模技术。通过观察不同促销活动中相似的购买模式，我们建议重用历史促销数据来捕获促销转换模式。在这里，我们提出了一种新的 textbf { H }历史 textbf { D } ata textbf { R } euse (textbf { HDR })方法，首先检索历史上相似的促销数据，然后用所获得的数据对 CVR 预测模型进行微调，以更好地适应促销模式。人类发展报告由三个组成部分组成: 一个自动数据检索模块，从历史促销活动中寻找类似数据; 一个分配转移校正模块，重新加权检索的数据，以便更好地与目标促销活动保持一致; 一个 TransBlock 模块，快速微调原始模型，以便更好地适应促销模式。利用实际数据进行的实验证明了 HDR 的有效性，因为它在很大程度上改善了排序和校准指标。HDR 也已经部署在阿里巴巴的显示广告系统上，在2022年双11销售期间，带来了9% 的每分钟转速和16% 的 CVR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Capturing+Conversion+Rate+Fluctuation+during+Sales+Promotions:+A+Novel+Historical+Data+Reuse+Approach)|0|
|[SAMD: An Industrial Framework for Heterogeneous Multi-Scenario Recommendation](https://doi.org/10.1145/3580305.3599955)|Zhaoxin Huan, Ang Li, Xiaolu Zhang, Xu Min, Jieyu Yang, Yong He, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAMD:+An+Industrial+Framework+for+Heterogeneous+Multi-Scenario+Recommendation)|0|
|[Learning Discrete Document Representations in Web Search](https://doi.org/10.1145/3580305.3599854)|Rong Huang, Danfeng Zhang, Weixue Lu, Han Li, Meng Wang, Daiting Shi, Jun Fan, Zhicong Cheng, Simiu Gu, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Discrete+Document+Representations+in+Web+Search)|0|
|[AdSEE: Investigating the Impact of Image Style Editing on Advertisement Attractiveness](https://doi.org/10.1145/3580305.3599770)|Liyao Jiang, Chenglin Li, Haolan Chen, Xiaodong Gao, Xinwang Zhong, Yang Qiu, Shani Ye, Di Niu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdSEE:+Investigating+the+Impact+of+Image+Style+Editing+on+Advertisement+Attractiveness)|0|
|[Adaptive Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3580305.3599768)|Yangqin Jiang, Chao Huang, Lianghao Huang|University of Hong Kong|Recently, graph neural networks (GNNs) have been successfully applied to recommender systems as an effective collaborative filtering (CF) approach. The key idea of GNN-based recommender system is to recursively perform the message passing along the user-item interaction edge for refining the encoded embeddings, relying on sufficient and high-quality training data. Since user behavior data in practical recommendation scenarios is often noisy and exhibits skewed distribution, some recommendation approaches, e.g., SGL and SimGCL, leverage self-supervised learning to improve user representations against the above issues. Despite their effectiveness, however, they conduct self-supervised learning through creating contrastvie views, depending on the exploration of data augmentations with the problem of tedious trial-and-error selection of augmentation methods. In this paper, we propose a novel Adaptive Graph Contrastive Learning (AdaptiveGCL) framework which conducts graph contrastive learning with two adaptive contrastive view generators to better empower CF paradigm. Specifically, we use two trainable view generators, which are a graph generative model and a graph denoising model respectively, to create contrastive views. Two generators are able to create adaptive contrastive views, addressing the problem of model collapse and achieving adaptive contrastive learning. With two adaptive contrasive views, more additionally high-quality training signals will be introduced into the CF paradigm and help to alleviate the data sparsity and noise issues. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over various state-of-the-art recommendation methods. Further visual analysis intuitively explains why our AdaptiveGCL outperforms existing contrastive learning approaches based on selected data augmentation methods.|最近，图形神经网络(GNN)已成功应用于推荐系统，作为一种有效的协同过滤(CF)方法。基于 GNN 的推荐系统的关键思想是依靠充分和高质量的训练数据，递归地执行沿用户项目交互边缘传递的消息，以完善编码的嵌入。由于实际推荐场景中的用户行为数据通常是有噪音的，并且呈现出偏态分布，因此一些推荐方法，如 SGL 和 SimGCL，利用自监督学习来改善用户对上述问题的表示。然而，尽管他们的有效性，他们进行自我监督学习通过创建对比观点，依赖于探索数据增强与繁琐的试错选择增强方法的问题。本文提出了一种新的自适应图形对比学习(AdaptiveGCL)框架，该框架使用两个自适应对比视图生成器进行图形对比学习，以更好地支持 CF 范式。具体来说，我们使用两个可训练的视图生成器，分别是一个图形生成模型和一个图形去噪模型，来创建对比视图。两个生成器能够创建自适应对比视图，解决模型崩溃问题，实现自适应对比学习。通过两个自适应对立视图，在 CF 范式中引入更多高质量的训练信号，有助于缓解数据稀疏和噪声问题。在三个基准数据集上的大量实验证明了我们的模型优于各种最先进的推荐方法。进一步的可视化分析直观地解释了为什么我们的 AdaptiveGCL 优于基于所选数据增强方法的现有对比学习方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Graph+Contrastive+Learning+for+Recommendation)|0|
|[PGLBox: Multi-GPU Graph Learning Framework for Web-Scale Recommendation](https://doi.org/10.1145/3580305.3599885)|Xuewu Jiao, Weibin Li, Xinxuan Wu, Wei Hu, Miao Li, Jiang Bian, Siming Dai, Xinsheng Luo, Mingqing Hu, Zhengjie Huang, Danlei Feng, Junchao Yang, Shikun Feng, Haoyi Xiong, Dianhai Yu, Shuanglong Li, Jingzhou He, Yanjun Ma, Lin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PGLBox:+Multi-GPU+Graph+Learning+Framework+for+Web-Scale+Recommendation)|0|
|[IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size of Public Graph Datasets for Deep Learning Research](https://doi.org/10.1145/3580305.3599843)|Arpandeep Khatua, Vikram Sharma Mailthody, Bhagyashree Taleka, Tengfei Ma, Xiang Song, WenMei Hwu|UIUC; AWS AI; IBM Research; NVIDIA|Graph neural networks (GNNs) have shown high potential for a variety of real-world, challenging applications, but one of the major obstacles in GNN research is the lack of large-scale flexible datasets. Most existing public datasets for GNNs are relatively small, which limits the ability of GNNs to generalize to unseen data. The few existing large-scale graph datasets provide very limited labeled data. This makes it difficult to determine if the GNN model's low accuracy for unseen data is inherently due to insufficient training data or if the model failed to generalize. Additionally, datasets used to train GNNs need to offer flexibility to enable a thorough study of the impact of various factors while training GNN models.   In this work, we introduce the Illinois Graph Benchmark (IGB), a research dataset tool that the developers can use to train, scrutinize and systematically evaluate GNN models with high fidelity. IGB includes both homogeneous and heterogeneous graphs of enormous sizes, with more than 40% of their nodes labeled. Compared to the largest graph datasets publicly available, the IGB provides over 162X more labeled data for deep learning practitioners and developers to create and evaluate models with higher accuracy. The IGB dataset is designed to be flexible, enabling the study of various GNN architectures, embedding generation techniques, and analyzing system performance issues. IGB is open-sourced, supports DGL and PyG frameworks, and comes with releases of the raw text that we believe foster emerging language models and GNN research projects. An early public version of IGB is available at https://github.com/IllinoisGraphBenchmark/IGB-Datasets.|图形神经网络(GNN)在现实世界中具有很大的应用潜力，但是缺乏大规模的灵活数据集是 GNN 研究的主要障碍之一。大多数现有的 GNN 公共数据集相对较小，这限制了 GNN 推广到未见数据的能力。少数现有的大规模图形数据集提供非常有限的标记数据。这使得很难确定 GNN 模型对于不可见数据的低精度是否本质上是由于训练数据不足或者模型没有推广。此外，用于训练 GNN 的数据集需要提供灵活性，以便在训练 GNN 模型时能够对各种因素的影响进行彻底的研究。在这项工作中，我们介绍了伊利诺伊图基准(IGB) ，一个研究数据集工具，开发人员可以用来训练，审查和系统地评估 GNN 模型的高保真度。IGB 包括大型的同质和异质图，其中超过40% 的节点被标记。与公开发布的最大的图形数据集相比，IGB 为深度学习从业者和开发者提供了超过162倍的标记数据，以创建和评估更高精度的模型。IGB 数据集的设计是灵活的，能够研究各种 GNN 体系结构、嵌入生成技术和分析系统性能问题。IGB 是开源的，支持 DGL 和 PyG 框架，并且附带了原始文本的发布，我们相信这些原始文本可以促进新兴语言模型和 GNN 研究项目的发展。IGB 的早期公开版本可在 https://github.com/illinoisgraphbenchmark/IGB-datasets 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IGB:+Addressing+The+Gaps+In+Labeling,+Features,+Heterogeneity,+and+Size+of+Public+Graph+Datasets+for+Deep+Learning+Research)|0|
|[AdaTT: Adaptive Task-to-Task Fusion Network for Multitask Learning in Recommendations](https://doi.org/10.1145/3580305.3599769)|Danwei Li, Zhengyu Zhang, Siyang Yuan, Mingze Gao, Weilin Zhang, Chaofei Yang, Xi Liu, Jiyan Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaTT:+Adaptive+Task-to-Task+Fusion+Network+for+Multitask+Learning+in+Recommendations)|0|
|[Stationary Algorithmic Balancing For Dynamic Email Re-Ranking Problem](https://doi.org/10.1145/3580305.3599909)|Jiayi Liu, Jennifer Neville|Purdue University|Email platforms need to generate personalized rankings of emails that satisfy user preferences, which may vary over time. We approach this as a recommendation problem based on three criteria: closeness (how relevant the sender and topic are to the user), timeliness (how recent the email is), and conciseness (how brief the email is). We propose MOSR (Multi-Objective Stationary Recommender), a novel online algorithm that uses an adaptive control model to dynamically balance these criteria and adapt to preference changes. We evaluate MOSR on the Enron Email Dataset, a large collection of real emails, and compare it with other baselines. The results show that MOSR achieves better performance, especially under non-stationary preferences, where users value different criteria more or less over time. We also test MOSR's robustness on a smaller down-sampled dataset that exhibits high variance in email characteristics, and show that it maintains stable rankings across different samples. Our work offers novel insights into how to design email re-ranking systems that account for multiple objectives impacting user satisfaction.|电子邮件平台需要生成个性化的电子邮件排名，以满足用户的喜好，这可能随着时间的推移而变化。我们基于三个标准来处理这个推荐问题: 亲密性(发送者和主题与用户的相关程度)、及时性(邮件发送时间有多近)和简洁性(邮件有多简短)。我们提出了一种新的在线算法——多目标平稳推荐(MOSR) ，它使用自适应控制模型来动态平衡这些标准，并适应偏好的变化。我们评估 MOSR 的安然电子邮件数据集，一大批真实的电子邮件，并比较它与其他基线。结果表明，在非平稳偏好条件下，特别是在用户随着时间的推移或多或少评价不同标准的情况下，MOSR 可以获得更好的性能。我们还测试了 MOSR 的稳健性较小的下采样数据集，表现出高的电子邮件特征方差，并表明它保持稳定的排名在不同的样本。我们的工作提供了新颖的见解，如何设计电子邮件重新排序系统的帐户多个目标影响用户的满意度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stationary+Algorithmic+Balancing+For+Dynamic+Email+Re-Ranking+Problem)|0|
|[Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation](https://doi.org/10.1145/3580305.3599919)|Xiao Lin, Xiaokai Chen, Linfeng Song, Jingwei Liu, Biao Li, Peng Jiang|Kuaishou Technology|An accurate prediction of watch time has been of vital importance to enhance user engagement in video recommender systems. To achieve this, there are four properties that a watch time prediction framework should satisfy: first, despite its continuous value, watch time is also an ordinal variable and the relative ordering between its values reflects the differences in user preferences. Therefore the ordinal relations should be reflected in watch time predictions. Second, the conditional dependence between the video-watching behaviors should be captured in the model. For instance, one has to watch half of the video before he/she finishes watching the whole video. Third, modeling watch time with a point estimation ignores the fact that models might give results with high uncertainty and this could cause bad cases in recommender systems. Therefore the framework should be aware of prediction uncertainty. Forth, the real-life recommender systems suffer from severe bias amplifications thus an estimation without bias amplification is expected. Therefore we propose TPM for watch time prediction. Specifically, the ordinal ranks of watch time are introduced into TPM and the problem is decomposed into a series of conditional dependent classification tasks which are organized into a tree structure. The expectation of watch time can be generated by traversing the tree and the variance of watch time predictions is explicitly introduced into the objective function as a measurement for uncertainty. Moreover, we illustrate that backdoor adjustment can be seamlessly incorporated into TPM, which alleviates bias amplifications. Extensive offline evaluations have been conducted in public datasets and TPM have been deployed in a real-world video app Kuaishou with over 300 million DAUs. The results indicate that TPM outperforms state-of-the-art approaches and indeed improves video consumption significantly.|准确预测观看时间对于提高用户在视频推荐系统中的参与度至关重要。为了实现这一点，手表时间预测框架应该满足四个特性: 第一，尽管手表时间是连续的，但它也是一个有序变量，其值之间的相对排序反映了用户偏好的差异。因此，序数关系应反映在手表时间预测中。其次，在模型中要捕捉视频观看行为之间的条件依赖关系。例如，一个人必须看完一半的视频才能看完整个视频。第三，使用点估计对手表时间进行建模忽略了这样一个事实，即模型可能会给出高度不确定性的结果，这可能会导致推荐系统出现问题。因此，框架应该意识到预测的不确定性。第四，现实生活中的推荐系统遭受严重的偏差放大，因此估计没有偏差放大的预期。因此，我们提出 TPM 来预测手表时间。在 TPM 中引入了观察时间序列，并将问题分解为一系列条件相关的分类任务，这些任务被组织成一个树形结构。通过遍历该树可以产生观察时间的期望值，并且在目标函数中明确地引入观察时间预测的方差作为不确定性的度量。此外，我们说明后门调整可以无缝地纳入 TPM，从而减轻偏差放大。在公共数据集中已经进行了广泛的离线评估，TPM 已经部署在一个现实世界的视频应用快手中，有超过3亿 DAU。结果表明，TPM 优于最先进的方法，确实显著提高了视频消费。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tree+based+Progressive+Regression+Model+for+Watch-Time+Prediction+in+Short-video+Recommendation)|0|
|[HUGE: Huge Unsupervised Graph Embeddings with TPUs](https://doi.org/10.1145/3580305.3599840)|Brandon A. Mayer, Anton Tsitsulin, Hendrik Fichtenberger, Jonathan Halcrow, Bryan Perozzi|Google Research|Graphs are a representation of structured data that captures the relationships between sets of objects. With the ubiquity of available network data, there is increasing industrial and academic need to quickly analyze graphs with billions of nodes and trillions of edges. A common first step for network understanding is Graph Embedding, the process of creating a continuous representation of nodes in a graph. A continuous representation is often more amenable, especially at scale, for solving downstream machine learning tasks such as classification, link prediction, and clustering. A high-performance graph embedding architecture leveraging Tensor Processing Units (TPUs) with configurable amounts of high-bandwidth memory is presented that simplifies the graph embedding problem and can scale to graphs with billions of nodes and trillions of edges. We verify the embedding space quality on real and synthetic large-scale datasets.|图表是结构化数据的表示，它捕捉对象集之间的关系。随着可用网络数据的普及，工业界和学术界越来越需要快速分析具有数十亿个节点和数万亿条边的图形。网络理解的一个常见的第一步是图形嵌入，即在图形中创建连续的节点表示的过程。连续表示通常更适合于解决下游机器学习任务，如分类、链接预测和聚类，尤其是在规模上。提出了一种利用张量处理单元(TPU)和可配置的高带宽存储器构成的高性能图嵌入体系结构，简化了图嵌入问题，并且可以扩展到具有数十亿个节点和数万亿条边的图。在实际和合成的大规模数据集上验证了嵌入空间的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HUGE:+Huge+Unsupervised+Graph+Embeddings+with+TPUs)|0|
|[Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks](https://doi.org/10.1145/3580305.3599898)|Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng|Hong Kong University of Science and Technology; Alibaba Group|In this work, besides improving prediction accuracy, we study whether personalization could bring robustness benefits to backdoor attacks. We conduct the first study of backdoor attacks in the pFL framework, testing 4 widely used backdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and CIFAR-10, a total of 600 experiments. The study shows that pFL methods with partial model-sharing can significantly boost robustness against backdoor attacks. In contrast, pFL methods with full model-sharing do not show robustness. To analyze the reasons for varying robustness performances, we provide comprehensive ablation studies on different pFL methods. Based on our findings, we further propose a lightweight defense method, Simple-Tuning, which empirically improves defense performance against backdoor attacks. We believe that our work could provide both guidance for pFL application in terms of its robustness and offer valuable insights to design more robust FL methods in the future.|在这项工作中，除了提高预测的准确性，我们研究个性化是否可以带来健壮性的好处后门攻击。我们在 pFL 框架中进行了后门攻击的第一次研究，在基准数据集 FEMNIST 和 CIFAR-10上测试了4个广泛使用的后门攻击与6个 pFL 方法，共计600个实验。研究表明，部分模型共享的 pFL 方法可以显著提高对后门攻击的鲁棒性。相比之下，完全模型共享的 pFL 方法不具有鲁棒性。为了分析鲁棒性能变化的原因，我们对不同的 pFL 方法进行了全面的消融研究。在此基础上，我们进一步提出了一种轻量级的防御方法——简单调整(Simple-Tuning) ，该方法可以实验性地提高对后门攻击的防御性能。我们相信，我们的工作可以为 pFL 的应用提供指导，在其健壮性方面，并提供有价值的见解，以设计更健壮的 FL 方法在未来。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Personalized+Federated+Learning:+Robustness+Against+Backdoor+Attacks)|0|
|[Joint Optimization of Ranking and Calibration with Contextualized Hybrid Model](https://doi.org/10.1145/3580305.3599851)|XiangRong Sheng, Jingyue Gao, Yueyao Cheng, Siran Yang, Shuguang Han, Hongbo Deng, Yuning Jiang, Jian Xu, Bo Zheng|Alibaba Group|Despite the development of ranking optimization techniques, the pointwise model remains the dominating approach for click-through rate (CTR) prediction. It can be attributed to the calibration ability of the pointwise model since the prediction can be viewed as the click probability. In practice, a CTR prediction model is also commonly assessed with the ranking ability, for which prediction models based on ranking losses (e.g., pairwise or listwise loss) usually achieve better performances than the pointwise loss. Previous studies have experimented with a direct combination of the two losses to obtain the benefit from both losses and observed an improved performance. However, previous studies break the meaning of output logit as the click-through rate, which may lead to sub-optimal solutions. To address this issue, we propose an approach that can Jointly optimize the Ranking and Calibration abilities (JRC for short). JRC improves the ranking ability by contrasting the logit value for the sample with different labels and constrains the predicted probability to be a function of the logit subtraction. We further show that JRC consolidates the interpretation of logits, where the logits model the joint distribution. With such an interpretation, we prove that JRC approximately optimizes the contextualized hybrid discriminative-generative objective. Experiments on public and industrial datasets and online A/B testing show that our approach improves both ranking and calibration abilities. Since May 2022, JRC has been deployed on the display advertising platform of Alibaba and has obtained significant performance improvements.|尽管排序优化技术不断发展，逐点模型仍然是点进率预测的主要方法。这可以归因于点态模型的校准能力，因为预测可以被视为点击概率。在实践中，CTR 预测模型通常也是用排序能力来评估的，其中基于排序损失的预测模型(例如，成对损失或列表损失)通常比逐点损失的预测模型获得更好的性能。以前的研究已经试验了两种损失的直接组合，以获得两种损失的收益，并观察到改善的性能。然而，以前的研究打破了 logit 作为点进率的意义，这可能导致次优解。为了解决这个问题，我们提出了一种方法，可以联合优化排名和校准能力(简称 JRC)。JRC 通过对比不同标签样本的 logit 值来提高排序能力，并将预测概率约束为 logit 减法的函数。我们进一步表明，JRC 巩固了 logit 的解释，其中 logit 模型的联合分布。通过这样的解释，我们证明了 JRC 近似地优化了上下文混合判别生成目标。在公共和工业数据集上的实验和在线 A/B 测试表明，该方法提高了排序和校准能力。自2022年5月起，JRC 已被部署在阿里巴巴的展示广告平台上，并取得显著的性能改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Optimization+of+Ranking+and+Calibration+with+Contextualized+Hybrid+Model)|0|
|[Workplace Recommendation with Temporal Network Objectives](https://doi.org/10.1145/3580305.3599932)|Kiran Tomlinson, Jennifer Neville, Longqi Yang, Mengting Wan, Cao Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Workplace+Recommendation+with+Temporal+Network+Objectives)|0|
|[Experimentation Platforms Meet Reinforcement Learning: Bayesian Sequential Decision-Making for Continuous Monitoring](https://doi.org/10.1145/3580305.3599818)|Runzhe Wan, Yu Liu, James McQueen, Doug Hains, Rui Song|Amazon|With the growing needs of online A/B testing to support the innovation in industry, the opportunity cost of running an experiment becomes non-negligible. Therefore, there is an increasing demand for an efficient continuous monitoring service that allows early stopping when appropriate. Classic statistical methods focus on hypothesis testing and are mostly developed for traditional high-stake problems such as clinical trials, while experiments at online service companies typically have very different features and focuses. Motivated by the real needs, in this paper, we introduce a novel framework that we developed in Amazon to maximize customer experience and control opportunity cost. We formulate the problem as a Bayesian optimal sequential decision making problem that has a unified utility function. We discuss extensively practical design choices and considerations. We further introduce how to solve the optimal decision rule via Reinforcement Learning and scale the solution. We show the effectiveness of this novel approach compared with existing methods via a large-scale meta-analysis on experiments in Amazon.|随着支持行业创新的在线 A/B 测试需求的不断增长，运行一个实验的机会成本变得不可忽视。因此，人们越来越需要一种有效的连续监测服务，以便能够在适当的时候提早停止。经典的统计方法侧重于假设检验，主要针对传统的高风险问题，如临床试验，而在线服务公司的实验通常具有非常不同的特点和重点。本文从实际需求出发，介绍了我们在亚马逊开发的一个新的框架，以最大限度地提高客户体验和控制机会成本。将该问题表示为一个具有统一效用函数的贝叶斯最优序贯决策问题。我们广泛讨论实用的设计选择和考虑因素。我们进一步介绍了如何通过强化学习和规模求解最优决策规则。我们通过对亚马逊上的实验进行大规模的荟萃分析，证明了这种新方法与现有方法相比的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Experimentation+Platforms+Meet+Reinforcement+Learning:+Bayesian+Sequential+Decision-Making+for+Continuous+Monitoring)|0|
|[BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction](https://doi.org/10.1145/3580305.3599780)|Dong Wang, Kavé Salamatian, Yunqing Xia, Weiwei Deng, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BERT4CTR:+An+Efficient+Framework+to+Combine+Pre-trained+Language+Model+with+Non-textual+Features+for+CTR+Prediction)|0|
|[Macular: A Multi-Task Adversarial Framework for Cross-Lingual Natural Language Understanding](https://doi.org/10.1145/3580305.3599864)|Haoyu Wang, Yaqing Wang, Feijie Wu, Hongfei Xue, Jing Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Macular:+A+Multi-Task+Adversarial+Framework+for+Cross-Lingual+Natural+Language+Understanding)|0|
|[ECGGAN: A Framework for Effective and Interpretable Electrocardiogram Anomaly Detection](https://doi.org/10.1145/3580305.3599812)|Huazhang Wang, Zhaojing Luo, James W. L. Yip, Chuyang Ye, Meihui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ECGGAN:+A+Framework+for+Effective+and+Interpretable+Electrocardiogram+Anomaly+Detection)|0|
|[Fresh Content Needs More Attention: Multi-funnel Fresh Content Recommendation](https://doi.org/10.1145/3580305.3599826)|Jianling Wang, Haokai Lu, Sai Zhang, Bart N. Locanthi, Haoting Wang, Dylan Greaves, Benjamin Lipshitz, Sriraj Badam, Ed H. Chi, Cristos J. Goodrow, SuLin Wu, Lexi Baugher, Minmin Chen|Google|Recommendation system serves as a conduit connecting users to an incredibly large, diverse and ever growing collection of contents. In practice, missing information on fresh (and tail) contents needs to be filled in order for them to be exposed and discovered by their audience. We here share our success stories in building a dedicated fresh content recommendation stack on a large commercial platform. To nominate fresh contents, we built a multi-funnel nomination system that combines (i) a two-tower model with strong generalization power for coverage, and (ii) a sequence model with near real-time update on user feedback for relevance. The multi-funnel setup effectively balances between coverage and relevance. An in-depth study uncovers the relationship between user activity level and their proximity toward fresh contents, which further motivates a contextual multi-funnel setup. Nominated fresh candidates are then scored and ranked by systems considering prediction uncertainty to further bootstrap content with less exposure. We evaluate the benefits of the dedicated fresh content recommendation stack, and the multi-funnel nomination system in particular, through user corpus co-diverted live experiments. We conduct multiple rounds of live experiments on a commercial platform serving billion of users demonstrating efficacy of our proposed methods.|推荐系统作为一个管道，将用户连接到一个极其庞大、多样化和不断增长的内容集合。在实践中，需要填补关于新鲜(和尾部)内容的缺失信息，以便它们被观众暴露和发现。我们在这里分享我们在一个大型商业平台上建立一个专门的新内容推荐堆栈的成功故事。为了提名新的内容，我们建立了一个多漏斗提名系统，该系统结合了(i)一个具有很强覆盖泛化能力的双塔模型和(ii)一个具有近实时更新用户反馈相关性的序列模型。多漏斗设置有效地平衡了覆盖率和相关性。深入的研究揭示了用户活动水平与其接近新鲜内容之间的关系，进一步激发了上下文多漏斗设置。提名的新鲜候选人，然后得分和排名的系统考虑预测不确定性，以进一步引导内容，较少的曝光。我们通过用户语料库共转向的现场实验，评估了专用新鲜内容推荐堆栈，特别是多漏斗提名系统的优点。我们在一个为数十亿用户服务的商业平台上进行多轮实验，证明我们提出的方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fresh+Content+Needs+More+Attention:+Multi-funnel+Fresh+Content+Recommendation)|0|
|[Contrastive Learning of Stress-specific Word Embedding for Social Media based Stress Detection](https://doi.org/10.1145/3580305.3599795)|Xin Wang, Huijun Zhang, Lei Cao, Kaisheng Zeng, Qi Li, Ningyun Li, Ling Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+of+Stress-specific+Word+Embedding+for+Social+Media+based+Stress+Detection)|0|
|[RLTP: Reinforcement Learning to Pace for Delayed Impression Modeling in Preloaded Ads](https://doi.org/10.1145/3580305.3599900)|Penghui Wei, Yongqiang Chen, Shaoguo Liu, Liang Wang, Bo Zheng|Alibaba Group|To increase brand awareness, many advertisers conclude contracts with advertising platforms to purchase traffic and then deliver advertisements to target audiences. In a whole delivery period, advertisers usually desire a certain impression count for the ads, and they also expect that the delivery performance is as good as possible (e.g., obtaining high click-through rate). Advertising platforms employ pacing algorithms to satisfy the demands via adjusting the selection probabilities to traffic requests in real-time. However, the delivery procedure is also affected by the strategies from publishers, which cannot be controlled by advertising platforms. Preloading is a widely used strategy for many types of ads (e.g., video ads) to make sure that the response time for displaying after a traffic request is legitimate, which results in delayed impression phenomenon. Traditional pacing algorithms cannot handle the preloading nature well because they rely on immediate feedback signals, and may fail to guarantee the demands from advertisers.   In this paper, we focus on a new research problem of impression pacing for preloaded ads, and propose a Reinforcement Learning To Pace framework RLTP. It learns a pacing agent that sequentially produces selection probabilities in the whole delivery period. To jointly optimize the two objectives of impression count and delivery performance, RLTP employs tailored reward estimator to satisfy the guaranteed impression count, penalize the over-delivery and maximize the traffic value. Experiments on large-scale industrial datasets verify that RLTP outperforms baseline pacing algorithms by a large margin. We have deployed the RLTP framework online to our advertising platform, and results show that it achieves significant uplift to core metrics including delivery completion rate and click-through rate.|为了提高品牌知名度，许多广告商与广告平台签订合同，购买流量，然后向目标受众投放广告。在整个投放期间，广告商通常希望广告能给人留下一定的印象，而且他们也希望投放的效果尽可能好(例如，获得较高的点进率)。广告平台采用节奏算法，通过实时调整流量请求的选择概率来满足需求。然而，传递过程也受到出版商策略的影响，而出版商策略又不受广告平台的控制。预加载是一种广泛使用的策略，许多类型的广告(如视频广告) ，以确保响应时间显示后的流量请求是合法的，这导致了延迟印象现象。传统的节奏算法不能很好地处理预载性质，因为它们依赖于即时反馈信号，可能无法保证来自广告商的需求。在这篇文章中，我们关注一个新的研究问题——预装广告的印象节奏，并提出了一个强化学习到节奏的框架 RLTP。它学习一种起搏剂，该起搏剂在整个交付期间依次产生选择概率。为了共同优化印象计数和传递性能这两个目标，RLTP 使用定制的报酬估计器来满足保证的印象计数，惩罚超额传递和最大化流量价值。在大规模工业数据集上的实验证明，RLTP 算法的性能优于基线起搏算法。我们已经在我们的广告平台上部署了 RLTP 框架，结果显示它实现了包括交付完成率和点进率在内的核心指标的显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RLTP:+Reinforcement+Learning+to+Pace+for+Delayed+Impression+Modeling+in+Preloaded+Ads)|0|
|[Multi-channel Integrated Recommendation with Exposure Constraints](https://doi.org/10.1145/3580305.3599868)|Yue Xu, Qijie Shen, Jianwen Yin, Zengde Deng, Dimin Wang, Hao Chen, Lixiang Lai, Tao Zhuang, Junfeng Ge|Alibaba Group.; Cainiao Network.; The Hong Kong Polytechnic University.|Integrated recommendation, which aims at jointly recommending heterogeneous items from different channels in a main feed, has been widely applied to various online platforms. Though attractive, integrated recommendation requires the ranking methods to migrate from conventional user-item models to the new user-channel-item paradigm in order to better capture users' preferences on both item and channel levels. Moreover, practical feed recommendation systems usually impose exposure constraints on different channels to ensure user experience. This leads to greater difficulty in the joint ranking of heterogeneous items. In this paper, we investigate the integrated recommendation task with exposure constraints in practical recommender systems. Our contribution is forth-fold. First, we formulate this task as a binary online linear programming problem and propose a two-layer framework named Multi-channel Integrated Recommendation with Exposure Constraints (MIREC) to obtain the optimal solution. Second, we propose an efficient online allocation algorithm to determine the optimal exposure assignment of different channels from a global view of all user requests over the entire time horizon. We prove that this algorithm reaches the optimal point under a regret bound of $ \mathcal{O}(\sqrt{T}) $ with linear complexity. Third, we propose a series of collaborative models to determine the optimal layout of heterogeneous items at each user request. The joint modeling of user interests, cross-channel correlation, and page context in our models aligns more with the browsing nature of feed products than existing models. Finally, we conduct extensive experiments on both offline datasets and online A/B tests to verify the effectiveness of MIREC. The proposed framework has now been implemented on the homepage of Taobao to serve the main traffic.|综合推荐是指在一个主要的推送平台上联合推荐来自不同渠道的异构项目，已广泛应用于各种在线平台。虽然综合推荐具有吸引力，但是它需要排名方法从传统的用户项目模型迁移到新的用户渠道项目范式，以便更好地捕捉用户在项目和渠道级别上的偏好。此外，实际的饲料推荐系统通常对不同的渠道施加暴露约束，以确保用户体验。这导致了异构项目联合排序的更大困难。本文研究了实际推荐系统中具有曝光约束的集成推荐任务。我们的贡献是四倍。首先，我们将这个任务表述为一个二进制在线线性规划问题，并提出一个名为多通道暴露约束综合推荐(MIREC)的两层架构来获得最优解。其次，我们提出了一个有效的在线分配算法，从全局的角度来确定不同信道在整个时间范围内的最佳曝光分配。证明了该算法在线性复杂度为 $数学{ O }(sqrt { T }) $的遗憾界下达到最优点。第三，我们提出了一系列的协作模型，以确定在每个用户请求的异构项目的最佳布局。在我们的模型中，用户兴趣、跨通道相关性和页面上下文的联合建模比现有模型更符合饲料产品的浏览特性。最后，我们对离线数据集和在线 A/B 测试进行了广泛的实验，以验证 MIREC 的有效性。这个建议框架现已在淘宝网的主页上实施，以服务于主要流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-channel+Integrated+Recommendation+with+Exposure+Constraints)|0|
|[Interactive Generalized Additive Model and Its Applications in Electric Load Forecasting](https://doi.org/10.1145/3580305.3599848)|Linxiao Yang, Rui Ren, Xinyue Gu, Liang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interactive+Generalized+Additive+Model+and+Its+Applications+in+Electric+Load+Forecasting)|0|
|[UA-FedRec: Untargeted Attack on Federated News Recommendation](https://doi.org/10.1145/3580305.3599923)|Jingwei Yi, Fangzhao Wu, Bin Zhu, Jing Yao, Zhulin Tao, Guangzhong Sun, Xing Xie|; Microsoft Research Asia; University of Science and Technology of China|News recommendation is critical for personalized news distribution. Federated news recommendation enables collaborative model learning from many clients without sharing their raw data. It is promising for privacy-preserving news recommendation. However, the security of federated news recommendation is still unclear. In this paper, we study this problem by proposing an untargeted attack called UA-FedRec. By exploiting the prior knowledge of news recommendation and federated learning, UA-FedRec can effectively degrade the model performance with a small percentage of malicious clients. First, the effectiveness of news recommendation highly depends on user modeling and news modeling. We design a news similarity perturbation method to make representations of similar news farther and those of dissimilar news closer to interrupt news modeling, and propose a user model perturbation method to make malicious user updates in opposite directions of benign updates to interrupt user modeling. Second, updates from different clients are typically aggregated by weighted-averaging based on their sample sizes. We propose a quantity perturbation method to enlarge sample sizes of malicious clients in a reasonable range to amplify the impact of malicious updates. Extensive experiments on two real-world datasets show that UA-FedRec can effectively degrade the accuracy of existing federated news recommendation methods, even when defense is applied. Our study reveals a critical security issue in existing federated news recommendation systems and calls for research efforts to address the issue.|新闻推荐对个性化新闻发布至关重要。联合新闻推荐使得许多客户能够在不共享原始数据的情况下进行协作模型学习。它对于保护隐私的新闻推荐来说是很有前途的。然而，联邦新闻推荐的安全性仍不清楚。在本文中，我们通过提出一种称为 UA-FedRec 的非目标攻击来研究这个问题。通过利用新闻推荐和联邦学习的先验知识，UA-FedRec 能够有效地降低小比例恶意客户端的模型性能。首先，新闻推荐的有效性很大程度上取决于用户建模和新闻建模。设计了一种新闻相似性摄动方法，使相似新闻和不同新闻的表示更接近于中断新闻建模，提出了一种用户模型摄动方法，使恶意用户在良性更新的相反方向更新，以中断用户建模。其次，来自不同客户端的更新通常根据样本大小进行加权平均。我们提出了一种数量扰动方法，在合理的范围内扩大恶意客户端的样本量，以放大恶意更新的影响。在两个实际数据集上的大量实验表明，UA-FedRec 能够有效地降低现有联邦新闻推荐方法的准确性，即使在采用防御策略的情况下也是如此。我们的研究揭示了现有联邦新闻推荐系统中的一个关键安全问题，并呼吁研究人员努力解决这个问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UA-FedRec:+Untargeted+Attack+on+Federated+News+Recommendation)|0|
|[Group-based Fraud Detection Network on e-Commerce Platforms](https://doi.org/10.1145/3580305.3599836)|Jianke Yu, Hanchen Wang, Xiaoyang Wang, Zhao Li, Lu Qin, Wenjie Zhang, Jian Liao, Ying Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Group-based+Fraud+Detection+Network+on+e-Commerce+Platforms)|0|
|[Commonsense Knowledge Graph towards Super APP and Its Applications in Alipay](https://doi.org/10.1145/3580305.3599791)|Xiaoling Zang, Binbin Hu, Jun Chu, Zhiqiang Zhang, Guannan Zhang, Jun Zhou, Wenliang Zhong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Commonsense+Knowledge+Graph+towards+Super+APP+and+Its+Applications+in+Alipay)|0|
|[Revisiting Neural Retrieval on Accelerators](https://doi.org/10.1145/3580305.3599897)|Jiaqi Zhai, Zhaojie Gong, Yueming Wang, Xiao Sun, Zheng Yan, Fu Li, Xing Liu|Meta Platforms, Inc.|Retrieval finds a small number of relevant candidates from a large corpus for information retrieval and recommendation applications. A key component of retrieval is to model (user, item) similarity, which is commonly represented as the dot product of two learned embeddings. This formulation permits efficient inference, commonly known as Maximum Inner Product Search (MIPS). Despite its popularity, dot products cannot capture complex user-item interactions, which are multifaceted and likely high rank. We hence examine non-dot-product retrieval settings on accelerators, and propose \textit{mixture of logits} (MoL), which models (user, item) similarity as an adaptive composition of elementary similarity functions. This new formulation is expressive, capable of modeling high rank (user, item) interactions, and further generalizes to the long tail. When combined with a hierarchical retrieval strategy, \textit{h-indexer}, we are able to scale up MoL to 100M corpus on a single GPU with latency comparable to MIPS baselines. On public datasets, our approach leads to uplifts of up to 77.3\% in hit rate (HR). Experiments on a large recommendation surface at Meta showed strong metric gains and reduced popularity bias, validating the proposed approach's performance and improved generalization.|Retrieval 从一个大型语料库中为信息检索和推荐应用程序找到少量相关的候选人。检索的一个关键组成部分是模型(用户，项目)的相似性，这是通常表示为点积的两个学习嵌入。这个公式允许有效的推理，通常称为最大内积搜索(MIPS)。尽管广受欢迎，点产品不能捕捉复杂的用户项目交互，这是多方面的，可能排名很高。因此，我们研究了加速器上的非点积检索设置，并提出了 text { mix of logits }(MoL) ，它将(用户，项目)相似度建模为基本相似度函数的自适应组合。这个新的公式是有表现力的，能够建模高级别(用户，项目)的交互，并进一步推广到长尾。当结合分层检索策略 texttit { h-indexer }时，我们能够在单个 GPU 上扩展 MoL 到100M 语料库，延迟与 MIPS 基线相当。在公共数据集上，我们的方法导致命中率(HR)提高高达77.3% 。在 Meta 的一个大型推荐面上进行的实验表明，该方法具有很强的度量增益和较小的普及偏差，验证了该方法的性能和改进的泛化能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Neural+Retrieval+on+Accelerators)|0|
|[Constrained Social Community Recommendation](https://doi.org/10.1145/3580305.3599793)|Xingyi Zhang, Shuliang Xu, Wenqing Lin, Sibo Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constrained+Social+Community+Recommendation)|0|
|[Modeling Dual Period-Varying Preferences for Takeaway Recommendation](https://doi.org/10.1145/3580305.3599866)|Yuting Zhang, Yiqing Wu, Ran Le, Yongchun Zhu, Fuzhen Zhuang, Ruidong Han, Xiang Li, Wei Lin, Zhulin An, Yongjun Xu|Unaffiliated; Institute of Artificial Intelligence, Beihang University; Meituan; Institute of Computing Technology, Chinese Academy of Sciences|Takeaway recommender systems, which aim to accurately provide stores that offer foods meeting users' interests, have served billions of users in our daily life. Different from traditional recommendation, takeaway recommendation faces two main challenges: (1) Dual Interaction-Aware Preference Modeling. Traditional recommendation commonly focuses on users' single preferences for items while takeaway recommendation needs to comprehensively consider users' dual preferences for stores and foods. (2) Period-Varying Preference Modeling. Conventional recommendation generally models continuous changes in users' preferences from a session-level or day-level perspective. However, in practical takeaway systems, users' preferences vary significantly during the morning, noon, night, and late night periods of the day. To address these challenges, we propose a Dual Period-Varying Preference modeling (DPVP) for takeaway recommendation. Specifically, we design a dual interaction-aware module, aiming to capture users' dual preferences based on their interactions with stores and foods. Moreover, to model various preferences in different time periods of the day, we propose a time-based decomposition module as well as a time-aware gating mechanism. Extensive offline and online experiments demonstrate that our model outperforms state-of-the-art methods on real-world datasets and it is capable of modeling the dual period-varying preferences. Moreover, our model has been deployed online on Meituan Takeaway platform, leading to an average improvement in GMV (Gross Merchandise Value) of 0.70%.|外卖推荐系统，旨在准确地提供商店，提供符合用户兴趣的食品，已服务于数十亿用户在我们的日常生活。与传统的推荐不同，外卖推荐面临着两个主要挑战: (1)双交互感知偏好建模。传统的推荐方式通常侧重于用户对商品的单一偏好，而外卖推荐方式则需要全面考虑用户对商店和食品的双重偏好。(变周期偏好模型。传统的推荐通常从会话级或日级的角度模拟用户偏好的持续变化。然而，在实际的外卖系统中，用户的偏好在白天的早上、中午、晚上和深夜各不相同。为了应对这些挑战，我们提出了一个外卖推荐的双周期变化偏好模型(DPVP)。具体来说，我们设计了一个双交互感知模块，旨在根据用户与商店和食物的交互来捕捉他们的双重偏好。此外，为了模拟一天中不同时段的不同偏好，我们提出了一个基于时间的分解模块以及一个时间感知的门控机制。大量的离线和在线实验表明，我们的模型优于现实世界数据集的最先进的方法，它能够建模的双周期变化的偏好。此外，我们的模型已经在美团外卖平台上进行了在线部署，导致平均商品总值(GMV)提高了0.70% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Dual+Period-Varying+Preferences+for+Takeaway+Recommendation)|0|
|[JiuZhang 2.0: A Unified Chinese Pre-trained Language Model for Multi-task Mathematical Problem Solving](https://doi.org/10.1145/3580305.3599850)|Xin Zhao, Kun Zhou, Beichen Zhang, Zheng Gong, Zhipeng Chen, Yuanhang Zhou, JiRong Wen, Jing Sha, Shijin Wang, Cong Liu, Guoping Hu|School of Information, Renmin University of China; iFLYTEK AI Research (Central China; Gaoling School of Artificial Intelligence, Renmin University of China; iFLYTEK Research; iFLYTEK Research, State Key Laboratory of Cognitive Intelligence|Although pre-trained language models~(PLMs) have recently advanced the research progress in mathematical reasoning, they are not specially designed as a capable multi-task solver, suffering from high cost for multi-task deployment (\eg a model copy for a task) and inferior performance on complex mathematical problems in practical applications. To address these issues, in this paper, we propose \textbf{JiuZhang~2.0}, a unified Chinese PLM specially for multi-task mathematical problem solving. Our idea is to maintain a moderate-sized model and employ the \emph{cross-task knowledge sharing} to improve the model capacity in a multi-task setting. Specially, we construct a Mixture-of-Experts~(MoE) architecture for modeling mathematical text, so as to capture the common mathematical knowledge across tasks. For optimizing the MoE architecture, we design \emph{multi-task continual pre-training} and \emph{multi-task fine-tuning} strategies for multi-task adaptation. These training strategies can effectively decompose the knowledge from the task data and establish the cross-task sharing via expert networks. In order to further improve the general capacity of solving different complex tasks, we leverage large language models~(LLMs) as complementary models to iteratively refine the generated solution by our PLM, via in-context learning. Extensive experiments have demonstrated the effectiveness of our model.|尽管预先训练的语言模型 ~ (PLM)最近已经推动了数学推理的研究进展，但是它们并没有被特别设计成一个有能力的多任务解决者，因为多任务部署的高成本(例如一个任务的模型拷贝)和在实际应用中复杂数学问题的低表现。为了解决这些问题，本文提出了一个专门用于多任务数学问题求解的统一中文 PLM textbf {旧掌 ~ 2.0}。我们的想法是维持一个中等规模的模型，并采用跨任务知识共享的方法来提高模型在多任务环境下的能力。特别地，我们构建了一个专家混合模型，用于数学文本建模，以便跨任务获取常见的数学知识。为了优化教学体系结构，我们设计了多任务连续预训练和多任务微调策略来实现多任务自适应。这些训练策略可以有效地分解任务数据中的知识，并通过专家网络建立跨任务共享。为了进一步提高解决不同复杂任务的能力，我们利用大语言模型 ~ (LLM)作为补充模型，通过上下文学习的方法，迭代地完善 PLM 生成的解决方案。大量的实验证明了我们模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=JiuZhang+2.0:+A+Unified+Chinese+Pre-trained+Language+Model+for+Multi-task+Mathematical+Problem+Solving)|0|
|[ReLoop2: Building Self-Adaptive Recommendation Models via Responsive Error Compensation Loop](https://doi.org/10.1145/3580305.3599785)|Jieming Zhu, Guohao Cai, Junjie Huang, Zhenhua Dong, Ruiming Tang, Weinan Zhang|Shanghai Jiao Tong University; Huawei Noah’s Ark Lab|Industrial recommender systems face the challenge of operating in non-stationary environments, where data distribution shifts arise from evolving user behaviors over time. To tackle this challenge, a common approach is to periodically re-train or incrementally update deployed deep models with newly observed data, resulting in a continual training process. However, the conventional learning paradigm of neural networks relies on iterative gradient-based updates with a small learning rate, making it slow for large recommendation models to adapt. In this paper, we introduce ReLoop2, a self-correcting learning loop that facilitates fast model adaptation in online recommender systems through responsive error compensation. Inspired by the slow-fast complementary learning system observed in human brains, we propose an error memory module that directly stores error samples from incoming data streams. These stored samples are subsequently leveraged to compensate for model prediction errors during testing, particularly under distribution shifts. The error memory module is designed with fast access capabilities and undergoes continual refreshing with newly observed data samples during the model serving phase to support fast model adaptation. We evaluate the effectiveness of ReLoop2 on three open benchmark datasets as well as a real-world production dataset. The results demonstrate the potential of ReLoop2 in enhancing the responsiveness and adaptiveness of recommender systems operating in non-stationary environments.|工业推荐系统面临着在非平稳环境下运行的挑战，数据分布随着时间的推移而发生变化。为了应对这一挑战，一种常见的方法是定期用新观测数据重新训练或增量更新已部署的深度模型，从而形成持续的训练过程。然而，传统的神经网络学习范式依赖于迭代的基于梯度的更新，学习速度很小，使得大型推荐模型的适应速度变慢。本文介绍了 ReLoop2，一种通过响应误差补偿实现在线推荐系统中模型快速自适应的自校正学习循环。受到在人脑中观察到的慢-快互补学习系统的启发，我们提出了一个错误记忆模块，它直接存储来自输入数据流的错误样本。这些存储的样本随后被用来补偿测试期间的模型预测错误，特别是在分布变化的情况下。错误存储模块设计具有快速访问能力，并在模型服务阶段不断刷新新观察到的数据样本，以支持快速模型适应。我们评估了 ReLoop2在三个开放基准数据集和一个真实生产数据集上的有效性。结果表明，ReLoop2在提高非平稳环境中运行的推荐系统的响应能力和适应能力方面具有潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReLoop2:+Building+Self-Adaptive+Recommendation+Models+via+Responsive+Error+Compensation+Loop)|0|
|[Trustworthy Recommender Systems: Foundations and Frontiers](https://doi.org/10.1145/3580305.3599575)|Wenqi Fan, Xiangyu Zhao, Lin Wang, Xiao Chen, Jingtong Gao, Qidong Liu, Shijie Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trustworthy+Recommender+Systems:+Foundations+and+Frontiers)|0|
|[Mining Electronic Health Records for Real-World Evidence](https://doi.org/10.1145/3580305.3599566)|Chengxi Zang, Weishen Pan, Fei Wang|Department of Clinical Pharmacy and Toxicology, Leiden University Medical Center, Leiden, the Netherlands.|Real-world evidence can close the inferential gap between marketing authorization studies and clinical practice. However, the current standard for real-world data extraction from electronic health records (EHRs) for treatment evaluation is manual review (MR), which is time-consuming and laborious. Clinical Data Collector (CDC) is a novel natural language processing and text mining software tool for both structured and unstructured EHR data and only shows relevant EHR sections improving efficiency. We investigated CDC as a real-world data (RWD) collection method, through application of CDC queries for patient inclusion and information extraction on a cohort of patients with metastatic renal cell carcinoma (RCC) receiving systemic drug treatment. Baseline patient characteristics, disease characteristics, and treatment outcomes were extracted and these were compared with MR for validation. One hundred patients receiving 175 treatments were included using CDC, which corresponded to 99% with MR. Calculated median overall survival was 21.7 months (95% confidence interval (CI) 18.7-24.8) vs. 21.7 months (95% CI 18.6-24.8) and progression-free survival 8.9 months (95% CI 5.4-12.4) vs. 7.6 months (95% CI 5.7-9.4) for CDC vs. MR, respectively. Highest F1-score was found for cancer-related variables (88.1-100), followed by comorbidities (71.5-90.4) and adverse drug events (53.3-74.5), with most diverse scores on international metastatic RCC database criteria (51.4-100). Mean data collection time was 12 minutes (CDC) vs. 86 minutes (MR). In conclusion, CDC is a promising tool for retrieving RWD from EHRs because the correct patient population can be identified as well as relevant outcome data, such as overall survival and progression-free survival.|真实世界的证据可以缩小上市许可研究和临床实践之间的推断差距。然而，目前从电子健康记录(EHRs)中提取真实数据用于治疗评估的标准是人工审查(MR) ，这是一项费时费力的工作。临床数据采集器(CDC)是一种新型的自然语言处理和文本挖掘软件工具，用于结构化和非结构化 EHR 数据，只显示相关的 EHR 部分提高效率。我们研究了 CDC 作为一种现实世界数据(RWD)收集方法，通过应用 CDC 查询对患者进行纳入，并对接受全身药物治疗的转移性信息抽取(rCC)患者队列进行肾细胞癌分析。提取基线患者特征、疾病特征和治疗结果，并与 MR 进行比较验证。接受175次治疗的100名患者使用 CDC，其中99% 为 MR。计算的中位总生存期分别为21.7个月(95% 置信区间(CI)18.7-24.8)和21.7个月(95% CI 18.6-24.8)和无进展生存期分别为 CDC 和 MR 的8.9个月(95% CI 5.4-12.4)和7.6个月(95% CI 5.7-9.4)。发现癌症相关变量(88.1-100)的 F1评分最高，其次是合并症(71.5-90.4)和不良药物事件(53.3-74.5) ，国际转移性 RCC 数据库标准(51.4-100)。平均数据收集时间为12分钟(CDC)比86分钟(MR)。总之，CDC 是从 EHR 中检索 RWD 的有希望的工具，因为可以确定正确的患者人群以及相关的结果数据，如总生存期和无进展生存期。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Electronic+Health+Records+for+Real-World+Evidence)|0|
|[EvalRS 2023: Well-Rounded Recommender Systems for Real-World Deployments](https://doi.org/10.1145/3580305.3599222)|Federico Bianchi, Patrick John Chia, Jacopo Tagliabue, Ciro Greco, Gabriel de Souza P. Moreira, Davide Eynard, Fahd Husain, Claudio Pomo||EvalRS aims to bring together practitioners from industry and academia to foster a debate on rounded evaluation of recommender systems, with a focus on real-world impact across a multitude of deployment scenarios. Recommender systems are often evaluated only through accuracy metrics, which fall short of fully characterizing their generalization capabilities and miss important aspects, such as fairness, bias, usefulness, informativeness. This workshop builds on the success of last year's workshop at CIKM, but with a broader scope and an interactive format.|EvalRS 旨在汇集来自行业和学术界的从业人员，促进关于全面评估推荐系统的辩论，重点是在多种部署情景下的现实世界影响。推荐系统往往只能通过精度指标进行评估，这些指标不能充分表征推荐系统的泛化能力，而且忽略了公平性、偏差性、有用性、信息性等重要方面。这个研讨会建立在去年 CIKM 研讨会的成功基础之上，但是范围更广，而且采用了交互式的形式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EvalRS+2023:+Well-Rounded+Recommender+Systems+for+Real-World+Deployments)|0|
|[A Multi-stage Framework for Online Bonus Allocation Based on Constrained User Intent Detection](https://doi.org/10.1145/3580305.3599764)|Chao Wang, Xiaowei Shi, Shuai Xu, Zhe Wang, Zhiqiang Fan, Yan Feng, An You, Yu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-stage+Framework+for+Online+Bonus+Allocation+Based+on+Constrained+User+Intent+Detection)|0|
|[LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias](https://doi.org/10.1145/3580305.3599402)|Mario Almagro, Emilio J. Almazán, Diego Ortego, David Jiménez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEA:+Improving+Sentence+Similarity+Robustness+to+Typos+Using+Lexical+Attention+Bias)|0|
|[IPOC: An Adaptive Interval Prediction Model based on Online Chasing and Conformal Inference for Large-Scale Systems](https://doi.org/10.1145/3580305.3599396)|Jiadong Chen, Yang Luo, Xiuqi Huang, Fuxin Jiang, Yangguang Shi, Tieying Zhang, Xiaofeng Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IPOC:+An+Adaptive+Interval+Prediction+Model+based+on+Online+Chasing+and+Conformal+Inference+for+Large-Scale+Systems)|0|
|[SketchPolymer: Estimate Per-item Tail Quantile Using One Sketch](https://doi.org/10.1145/3580305.3599505)|Jiarui Guo, Yisen Hong, Yuhan Wu, Yunfei Liu, Tong Yang, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SketchPolymer:+Estimate+Per-item+Tail+Quantile+Using+One+Sketch)|0|
|[Unbiased Locally Private Estimator for Polynomials of Laplacian Variables](https://doi.org/10.1145/3580305.3599537)|Quentin Hillebrand, Vorapong Suppakitpaisarn, Tetsuo Shibuya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unbiased+Locally+Private+Estimator+for+Polynomials+of+Laplacian+Variables)|0|
|[Semantic Dissimilarity Guided Locality Preserving Projections for Partial Label Dimensionality Reduction](https://doi.org/10.1145/3580305.3599496)|Yuheng Jia, Jiahao Jiang, Yongheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+Dissimilarity+Guided+Locality+Preserving+Projections+for+Partial+Label+Dimensionality+Reduction)|0|
|[B2-Sampling: Fusing Balanced and Biased Sampling for Graph Contrastive Learning](https://doi.org/10.1145/3580305.3599262)|Mengyue Liu, Yun Lin, Jun Liu, Bohao Liu, Qinghua Zheng, Jin Song Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=B2-Sampling:+Fusing+Balanced+and+Biased+Sampling+for+Graph+Contrastive+Learning)|0|
|[DotHash: Estimating Set Similarity Metrics for Link Prediction and Document Deduplication](https://doi.org/10.1145/3580305.3599314)|Igor Nunes, Mike Heddes, Pere Vergés, Danny Abraham, Alexander V. Veidenbaum, Alex Nicolau, Tony Givargis|University of California, Irvine|Metrics for set similarity are a core aspect of several data mining tasks. To remove duplicate results in a Web search, for example, a common approach looks at the Jaccard index between all pairs of pages. In social network analysis, a much-celebrated metric is the Adamic-Adar index, widely used to compare node neighborhood sets in the important problem of predicting links. However, with the increasing amount of data to be processed, calculating the exact similarity between all pairs can be intractable. The challenge of working at this scale has motivated research into efficient estimators for set similarity metrics. The two most popular estimators, MinHash and SimHash, are indeed used in applications such as document deduplication and recommender systems where large volumes of data need to be processed. Given the importance of these tasks, the demand for advancing estimators is evident. We propose DotHash, an unbiased estimator for the intersection size of two sets. DotHash can be used to estimate the Jaccard index and, to the best of our knowledge, is the first method that can also estimate the Adamic-Adar index and a family of related metrics. We formally define this family of metrics, provide theoretical bounds on the probability of estimate errors, and analyze its empirical performance. Our experimental results indicate that DotHash is more accurate than the other estimators in link prediction and detecting duplicate documents with the same complexity and similar comparison time.|集合相似性度量是数据挖掘任务的一个核心方面。例如，为了删除 Web 搜索中的重复结果，通常的方法是查看所有页对之间的 Jaccard 索引。在社会网络分析中，一个著名的度量是阿达姆-阿达尔指数，广泛用于比较节点邻域集在预测链路的重要问题。然而，随着需要处理的数据量的增加，计算所有对之间的精确相似度是很困难的。在这种规模下工作的挑战促使人们研究集合相似度量的有效估计器。MinHash 和 SimHash 这两个最流行的估计器确实用于需要处理大量数据的应用程序，如文档删除重复数据和推荐系统。鉴于这些任务的重要性，提前估算的需求是显而易见的。我们提出了 DotHash，一个两个集合的交集大小的无偏估计。DotHash 可以用来估计 Jaccard 指数，据我们所知，DotHash 是第一种也可以估计 Adam-Adar 指数和一系列相关指标的方法。我们正式地定义了这个度量族，给出了估计误差概率的理论界限，并分析了它的经验性能。实验结果表明，在相同复杂度和相似比较时间的链路预测和重复文档检测方面，DotHash 比其他估计器具有更高的精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DotHash:+Estimating+Set+Similarity+Metrics+for+Link+Prediction+and+Document+Deduplication)|0|
|[Domain-Guided Spatio-Temporal Self-Attention for Egocentric 3D Pose Estimation](https://doi.org/10.1145/3580305.3599312)|Jinman Park, Kimathi Kaai, Saad Hossain, Norikatsu Sumi, Sirisha Rambhatla, Paul W. Fieguth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain-Guided+Spatio-Temporal+Self-Attention+for+Egocentric+3D+Pose+Estimation)|0|
|[Quantitatively Measuring and Contrastively Exploring Heterogeneity for Domain Generalization](https://doi.org/10.1145/3580305.3599481)|Yunze Tong, Junkun Yuan, Min Zhang, Didi Zhu, Keli Zhang, Fei Wu, Kun Kuang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantitatively+Measuring+and+Contrastively+Exploring+Heterogeneity+for+Domain+Generalization)|0|
|[Grace: Graph Self-Distillation and Completion to Mitigate Degree-Related Biases](https://doi.org/10.1145/3580305.3599368)|Hui Xu, Liyao Xiang, Femke Huang, Yuting Weng, Ruijie Xu, Xinbing Wang, Chenghu Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Grace:+Graph+Self-Distillation+and+Completion+to+Mitigate+Degree-Related+Biases)|0|
|[DisasterNet: Causal Bayesian Networks with Normalizing Flows for Cascading Hazards Estimation from Satellite Imagery](https://doi.org/10.1145/3580305.3599807)|Xuechun Li, Paula M. Bürgi, Wei Ma, Hae Young Noh, David Jay Wald, Susu Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DisasterNet:+Causal+Bayesian+Networks+with+Normalizing+Flows+for+Cascading+Hazards+Estimation+from+Satellite+Imagery)|0|
|[Explicit Feature Interaction-aware Uplift Network for Online Marketing](https://doi.org/10.1145/3580305.3599820)|Dugang Liu, Xing Tang, Han Gao, Fuyuan Lyu, Xiuqiang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explicit+Feature+Interaction-aware+Uplift+Network+for+Online+Marketing)|0|
|[Online Quality Prediction in Windshield Manufacturing using Data-Efficient Machine Learning](https://doi.org/10.1145/3580305.3599880)|Hasan Tercan, Tobias Meisen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Quality+Prediction+in+Windshield+Manufacturing+using+Data-Efficient+Machine+Learning)|0|
|[C-AOI: Contour-based Instance Segmentation for High-Quality Areas-of-Interest in Online Food Delivery Platform](https://doi.org/10.1145/3580305.3599786)|Yida Zhu, Liying Chen, Daping Xiong, Shuiping Chen, Fangxiao Du, Jinghua Hao, Renqing He, Zhizhao Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=C-AOI:+Contour-based+Instance+Segmentation+for+High-Quality+Areas-of-Interest+in+Online+Food+Delivery+Platform)|0|
|[Addressing Bias and Fairness in Machine Learning: A Practical Guide and Hands-on Tutorial](https://doi.org/10.1145/3580305.3599180)|Rayid Ghani, Kit T. Rodolfa, Pedro Saleiro, Sérgio M. Jesus||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Bias+and+Fairness+in+Machine+Learning:+A+Practical+Guide+and+Hands-on+Tutorial)|0|
|[Causal Inference and Machine Learning in Practice: Use Cases for Product, Brand, Policy and Beyond](https://doi.org/10.1145/3580305.3599221)|JeongYoon Lee, Yifeng Wu, Keith Battocchi, Fabio Vera, Zhenyu Zhao, Totte Harinen, Jing Pan, Huigang Chen, Zeyu Zheng, Chu Wang, Yingfei Wang, Xinwei Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Inference+and+Machine+Learning+in+Practice:+Use+Cases+for+Product,+Brand,+Policy+and+Beyond)|0|
|[Sketch-Based Anomaly Detection in Streaming Graphs](https://doi.org/10.1145/3580305.3599504)|Siddharth Bhatia, Mohit Wadhwa, Kenji Kawaguchi, Neil Shah, Philip S. Yu, Bryan Hooi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sketch-Based+Anomaly+Detection+in+Streaming+Graphs)|0|
|[On Hierarchical Disentanglement of Interactive Behaviors for Multimodal Spatiotemporal Data with Incompleteness](https://doi.org/10.1145/3580305.3599448)|Jiayi Chen, Aidong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Hierarchical+Disentanglement+of+Interactive+Behaviors+for+Multimodal+Spatiotemporal+Data+with+Incompleteness)|0|
|[Multiplex Heterogeneous Graph Neural Network with Behavior Pattern Modeling](https://doi.org/10.1145/3580305.3599441)|Chaofan Fu, Guanjie Zheng, Chao Huang, Yanwei Yu, Junyu Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiplex+Heterogeneous+Graph+Neural+Network+with+Behavior+Pattern+Modeling)|0|
|[Pyramid Graph Neural Network: A Graph Sampling and Filtering Approach for Multi-scale Disentangled Representations](https://doi.org/10.1145/3580305.3599478)|Haoyu Geng, Chao Chen, Yixuan He, Gang Zeng, Zhaobing Han, Hua Chai, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pyramid+Graph+Neural+Network:+A+Graph+Sampling+and+Filtering+Approach+for+Multi-scale+Disentangled+Representations)|0|
|[Detecting Interference in Online Controlled Experiments with Increasing Allocation](https://doi.org/10.1145/3580305.3599308)|Kevin Han, Shuangning Li, Jialiang Mao, Han Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Interference+in+Online+Controlled+Experiments+with+Increasing+Allocation)|0|
|[CLUR: Uncertainty Estimation for Few-Shot Text Classification with Contrastive Learning](https://doi.org/10.1145/3580305.3599276)|Jianfeng He, Xuchao Zhang, Shuo Lei, Abdulaziz Alhamadani, Fanglan Chen, Bei Xiao, ChangTien Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLUR:+Uncertainty+Estimation+for+Few-Shot+Text+Classification+with+Contrastive+Learning)|0|
|[Planning to Fairly Allocate: Probabilistic Fairness in the Restless Bandit Setting](https://doi.org/10.1145/3580305.3599467)|Christine Herlihy, Aviva Prins, Aravind Srinivasan, John P. Dickerson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Planning+to+Fairly+Allocate:+Probabilistic+Fairness+in+the+Restless+Bandit+Setting)|0|
|[Similarity Preserving Adversarial Graph Contrastive Learning](https://doi.org/10.1145/3580305.3599503)|Yeonjun In, Kanghoon Yoon, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Similarity+Preserving+Adversarial+Graph+Contrastive+Learning)|0|
|[Fast and Accurate Dual-Way Streaming PARAFAC2 for Irregular Tensors - Algorithm and Application](https://doi.org/10.1145/3580305.3599342)|JunGi Jang, Jeongyoung Lee, Yongchan Park, U Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+and+Accurate+Dual-Way+Streaming+PARAFAC2+for+Irregular+Tensors+-+Algorithm+and+Application)|0|
|[Predicting Information Pathways Across Online Communities](https://doi.org/10.1145/3580305.3599470)|Yiqiao Jin, YeonChang Lee, Kartik Sharma, Meng Ye, Karan Sikka, Ajay Divakaran, Srijan Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Information+Pathways+Across+Online+Communities)|0|
|[Task Relation-aware Continual User Representation Learning](https://doi.org/10.1145/3580305.3599516)|Sein Kim, Namkyeong Lee, Donghyun Kim, MinChul Yang, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task+Relation-aware+Continual+User+Representation+Learning)|0|
|[GraphSHA: Synthesizing Harder Samples for Class-Imbalanced Node Classification](https://doi.org/10.1145/3580305.3599374)|WenZhi Li, ChangDong Wang, Hui Xiong, JianHuang Lai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphSHA:+Synthesizing+Harder+Samples+for+Class-Imbalanced+Node+Classification)|0|
|[Physics-Guided Discovery of Highly Nonlinear Parametric Partial Differential Equations](https://doi.org/10.1145/3580305.3599466)|Yingtao Luo, Qiang Liu, Yuntian Chen, Wenbo Hu, Tian Tian, Jun Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Physics-Guided+Discovery+of+Highly+Nonlinear+Parametric+Partial+Differential+Equations)|0|
|[Online Fairness Auditing through Iterative Refinement](https://doi.org/10.1145/3580305.3599454)|Pranav Maneriker, Codi Burley, Srinivasan Parthasarathy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Fairness+Auditing+through+Iterative+Refinement)|0|
|[Online Level-wise Hierarchical Clustering](https://doi.org/10.1145/3580305.3599455)|Nicholas Monath, Manzil Zaheer, Andrew McCallum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Level-wise+Hierarchical+Clustering)|0|
|[Cracking White-box DNN Watermarks via Invariant Neuron Transforms](https://doi.org/10.1145/3580305.3599291)|Xudong Pan, Mi Zhang, Yifan Yan, Yining Wang, Min Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cracking+White-box+DNN+Watermarks+via+Invariant+Neuron+Transforms)|0|
|[Graph Neural Bandits](https://doi.org/10.1145/3580305.3599371)|Yunzhe Qi, Yikun Ban, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Bandits)|0|
|[Source-Free Domain Adaptation with Temporal Imputation for Time Series Data](https://doi.org/10.1145/3580305.3599507)|Mohamed Ragab, Emadeldeen Eldele, Min Wu, ChuanSheng Foo, Xiaoli Li, Zhenghua Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Source-Free+Domain+Adaptation+with+Temporal+Imputation+for+Time+Series+Data)|0|
|[Causal Effect Estimation on Hierarchical Spatial Graph Data](https://doi.org/10.1145/3580305.3599269)|Koh Takeuchi, Ryo Nishida, Hisashi Kashima, Masaki Onishi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Effect+Estimation+on+Hierarchical+Spatial+Graph+Data)|0|
|[Networked Time Series Imputation via Position-aware Graph Enhanced Variational Autoencoders](https://doi.org/10.1145/3580305.3599444)|Dingsu Wang, Yuchen Yan, Ruizhong Qiu, Yada Zhu, Kaiyu Guan, Andrew Margenot, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Networked+Time+Series+Imputation+via+Position-aware+Graph+Enhanced+Variational+Autoencoders)|0|
|[Incremental Causal Graph Learning for Online Root Cause Analysis](https://doi.org/10.1145/3580305.3599392)|Dongjie Wang, Zhengzhang Chen, Yanjie Fu, Yanchi Liu, Haifeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incremental+Causal+Graph+Learning+for+Online+Root+Cause+Analysis)|0|
|[Treatment Effect Estimation with Adjustment Feature Selection](https://doi.org/10.1145/3580305.3599531)|Haotian Wang, Kun Kuang, Haoang Chi, Longqi Yang, Mingyang Geng, Wanrong Huang, Wenjing Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Treatment+Effect+Estimation+with+Adjustment+Feature+Selection)|0|
|[Adversarial Constrained Bidding via Minimax Regret Optimization with Causality-Aware Reinforcement Learning](https://doi.org/10.1145/3580305.3599254)|Haozhe Wang, Chao Du, Panyan Fang, Li He, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Constrained+Bidding+via+Minimax+Regret+Optimization+with+Causality-Aware+Reinforcement+Learning)|0|
|[Efficient Sparse Linear Bandits under High Dimensional Data](https://doi.org/10.1145/3580305.3599329)|Xue Wang, Mike Mingcheng Wei, Tao Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Sparse+Linear+Bandits+under+High+Dimensional+Data)|0|
|[MicroscopeSketch: Accurate Sliding Estimation Using Adaptive Zooming](https://doi.org/10.1145/3580305.3599432)|Yuhan Wu, Shiqi Jiang, Siyuan Dong, Zheng Zhong, Jiale Chen, Yutong Hu, Tong Yang, Steve Uhlig, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MicroscopeSketch:+Accurate+Sliding+Estimation+Using+Adaptive+Zooming)|0|
|[Learning Behavior-oriented Knowledge Tracing](https://doi.org/10.1145/3580305.3599407)|Bihan Xu, Zhenya Huang, Jiayu Liu, Shuanghong Shen, Qi Liu, Enhong Chen, Jinze Wu, Shijin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Behavior-oriented+Knowledge+Tracing)|0|
|[MimoSketch: A Framework to Mine Item Frequency on Multiple Nodes with Sketches](https://doi.org/10.1145/3580305.3599433)|Yuchen Xu, Wenfei Wu, Bohan Zhao, Tong Yang, Yikai Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MimoSketch:+A+Framework+to+Mine+Item+Frequency+on+Multiple+Nodes+with+Sketches)|0|
|[Kernel Ridge Regression-Based Graph Dataset Distillation](https://doi.org/10.1145/3580305.3599398)|Zhe Xu, Yuzhong Chen, Menghai Pan, Huiyuan Chen, Mahashweta Das, Hao Yang, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Kernel+Ridge+Regression-Based+Graph+Dataset+Distillation)|0|
|[BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision, Language, and Graphs](https://doi.org/10.1145/3580305.3599263)|Zhen Yang, Tinglin Huang, Ming Ding, Yuxiao Dong, Rex Ying, Yukuo Cen, Yangliao Geng, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BatchSampler:+Sampling+Mini-Batches+for+Contrastive+Learning+in+Vision,+Language,+and+Graphs)|0|
|[Web-based Long-term Spine Treatment Outcome Forecasting](https://doi.org/10.1145/3580305.3599545)|Hangting Ye, Zhining Liu, Wei Cao, Amir M. Amiri, Jiang Bian, Yi Chang, Jon D. Lurie, Jim Weinstein, TieYan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Web-based+Long-term+Spine+Treatment+Outcome+Forecasting)|0|
|[Optimal Dynamic Subset Sampling: Theory and Applications](https://doi.org/10.1145/3580305.3599458)|Lu Yi, Hanzhi Wang, Zhewei Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Dynamic+Subset+Sampling:+Theory+and+Applications)|0|
|[Sharpness-Aware Minimization Revisited: Weighted Sharpness as a Regularization Term](https://doi.org/10.1145/3580305.3599501)|Yun Yue, Jiadi Jiang, Zhiling Ye, Ning Gao, Yongchao Liu, Ke Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sharpness-Aware+Minimization+Revisited:+Weighted+Sharpness+as+a+Regularization+Term)|0|
|[Doubly Robust AUC Optimization against Noisy and Adversarial Samples](https://doi.org/10.1145/3580305.3599316)|Chenkang Zhang, Wanli Shi, Lei Luo, Bin Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Doubly+Robust+AUC+Optimization+against+Noisy+and+Adversarial+Samples)|0|
|[Finding Favourite Tuples on Data Streams with Provably Few Comparisons](https://doi.org/10.1145/3580305.3599352)|Guangyi Zhang, Nikolaj Tatti, Aristides Gionis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Finding+Favourite+Tuples+on+Data+Streams+with+Provably+Few+Comparisons)|0|
|[Domain-Specific Risk Minimization for Domain Generalization](https://doi.org/10.1145/3580305.3599313)|YiFan Zhang, Jindong Wang, Jian Liang, Zhang Zhang, Baosheng Yu, Liang Wang, Dacheng Tao, Xing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain-Specific+Risk+Minimization+for+Domain+Generalization)|0|
|[Towards Fair Disentangled Online Learning for Changing Environments](https://doi.org/10.1145/3580305.3599523)|Chen Zhao, Feng Mi, Xintao Wu, Kai Jiang, Latifur Khan, Christan Grant, Feng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Disentangled+Online+Learning+for+Changing+Environments)|0|
|[SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding](https://doi.org/10.1145/3580305.3599907)|Vasilisa Bashlovkina, Riley Matthews, Zhaobin Kuang, Simon Baumgartner, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SMILE:+Evaluation+and+Domain+Adaptation+for+Social+Media+Language+Understanding)|0|
|[Augmenting Rule-based DNS Censorship Detection at Scale with Machine Learning](https://doi.org/10.1145/3580305.3599775)|Jacob Alexander Markson Brown, Xi Jiang, Van Tran, Arjun Nitin Bhagoji, Nguyen Phong Hoang, Nick Feamster, Prateek Mittal, Vinod Yegneswaran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Augmenting+Rule-based+DNS+Censorship+Detection+at+Scale+with+Machine+Learning)|0|
|[Taming the Domain Shift in Multi-source Learning for Energy Disaggregation](https://doi.org/10.1145/3580305.3599910)|Xiaomin Chang, Wei Li, Yunchuan Shi, Albert Y. Zomaya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Taming+the+Domain+Shift+in+Multi-source+Learning+for+Energy+Disaggregation)|0|
|[Variance Reduction Using In-Experiment Data: Efficient and Targeted Online Measurement for Sparse and Delayed Outcomes](https://doi.org/10.1145/3580305.3599928)|Alex Deng, Michelle Du, Anna Matlin, Qing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Variance+Reduction+Using+In-Experiment+Data:+Efficient+and+Targeted+Online+Measurement+for+Sparse+and+Delayed+Outcomes)|0|
|[Modelling Delayed Redemption with Importance Sampling and Pre-Redemption Engagement](https://doi.org/10.1145/3580305.3599867)|Samik Datta, Anshuman Mourya, Anirban Majumder, Vineet Chaoji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modelling+Delayed+Redemption+with+Importance+Sampling+and+Pre-Redemption+Engagement)|0|
|[From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams](https://doi.org/10.1145/3580305.3599827)|Iddo Drori, Sarah J. Zhang, Reece Shuttleworth, Sarah Zhang, Keith Tyser, Zad Chin, Pedro Lantigua, Saisamrit Surbehera, Gregory Hunter, Derek Austin, Leonard Tang, Yann Hicke, Sage Simhon, Sathwik Karnik, Darnell Granberry, Madeleine Udell||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Human+Days+to+Machine+Seconds:+Automatically+Answering+and+Generating+Machine+Learning+Final+Exams)|0|
|[Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance](https://doi.org/10.1145/3580305.3599856)|Yuchen Fang, Zhenggang Tang, Kan Ren, Weiqing Liu, Li Zhao, Jiang Bian, Dongsheng Li, Weinan Zhang, Yong Yu, TieYan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Multi-Agent+Intention-Aware+Communication+for+Optimal+Multi-Order+Execution+in+Finance)|0|
|[iETA: A Robust and Scalable Incremental Learning Framework for Time-of-Arrival Estimation](https://doi.org/10.1145/3580305.3599842)|Jindong Han, Hao Liu, Shui Liu, Xi Chen, Naiqiang Tan, Hua Chai, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iETA:+A+Robust+and+Scalable+Incremental+Learning+Framework+for+Time-of-Arrival+Estimation)|0|
|[Identifying Complicated Contagion Scenarios from Cascade Data](https://doi.org/10.1145/3580305.3599841)|Galen Harrison, Amro Alabsi Aljundi, Jiangzhuo Chen, S. S. Ravi, Anil Kumar S. Vullikanti, Madhav V. Marathe, Abhijin Adiga||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Complicated+Contagion+Scenarios+from+Cascade+Data)|0|
|[Large-scale Urban Cellular Traffic Generation via Knowledge-Enhanced GANs with Multi-Periodic Patterns](https://doi.org/10.1145/3580305.3599853)|Shuodi Hui, Huandong Wang, Tong Li, Xinghao Yang, Xing Wang, Junlan Feng, Lin Zhu, Chao Deng, Pan Hui, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large-scale+Urban+Cellular+Traffic+Generation+via+Knowledge-Enhanced+GANs+with+Multi-Periodic+Patterns)|0|
|[SentiGOLD: A Large Bangla Gold Standard Multi-Domain Sentiment Analysis Dataset and Its Evaluation](https://doi.org/10.1145/3580305.3599904)|Md. Ekramul Islam, Labib Chowdhury, Faisal Ahamed Khan, Shazzad Hossain, Md. Sourave Hossain, Mohammad Mamun Or Rashid, Nabeel Mohammed, Mohammad Ruhul Amin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SentiGOLD:+A+Large+Bangla+Gold+Standard+Multi-Domain+Sentiment+Analysis+Dataset+and+Its+Evaluation)|0|
|[Off-Policy Learning-to-Bid with AuctionGym](https://doi.org/10.1145/3580305.3599877)|Olivier Jeunen, Sean Murphy, Ben Allison||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Learning-to-Bid+with+AuctionGym)|0|
|[FairCod: A Fairness-aware Concurrent Dispatch System for Large-scale Instant Delivery Services](https://doi.org/10.1145/3580305.3599824)|Lin Jiang, Shuai Wang, Baoshen Guo, Hai Wang, Desheng Zhang, Guang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairCod:+A+Fairness-aware+Concurrent+Dispatch+System+for+Large-scale+Instant+Delivery+Services)|0|
|[CBLab: Supporting the Training of Large-scale Traffic Control Policies with Scalable Traffic Simulation](https://doi.org/10.1145/3580305.3599789)|Chumeng Liang, Zherui Huang, Yicheng Liu, Zhanyu Liu, Guanjie Zheng, Hanyuan Shi, Kan Wu, Yuhao Du, Fuliang Li, Zhenhui Jessie Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CBLab:+Supporting+the+Training+of+Large-scale+Traffic+Control+Policies+with+Scalable+Traffic+Simulation)|0|
|[Practical Synthetic Human Trajectories Generation Based on Variational Point Processes](https://doi.org/10.1145/3580305.3599888)|Qingyue Long, Huandong Wang, Tong Li, Lisi Huang, Kun Wang, Qiong Wu, Guangyu Li, Yanping Liang, Li Yu, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Synthetic+Human+Trajectories+Generation+Based+on+Variational+Point+Processes)|0|
|[Deep Landscape Forecasting in Multi-Slot Real-Time Bidding](https://doi.org/10.1145/3580305.3599799)|Weitong Ou, Bo Chen, Yingxuan Yang, Xinyi Dai, Weiwen Liu, Weinan Zhang, Ruiming Tang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Landscape+Forecasting+in+Multi-Slot+Real-Time+Bidding)|0|
|[NFT-Based Data Marketplace with Digital Watermarking](https://doi.org/10.1145/3580305.3599876)|Saeed Ranjbar Alvar, Mohammad Akbari, David (Ming Xuan) Yue, Yong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NFT-Based+Data+Marketplace+with+Digital+Watermarking)|0|
|[Rover: An Online Spark SQL Tuning Service via Generalized Transfer Learning](https://doi.org/10.1145/3580305.3599953)|Yu Shen, Xinyuyang Ren, Yupeng Lu, Huaijun Jiang, Huanyong Xu, Di Peng, Yang Li, Wentao Zhang, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rover:+An+Online+Spark+SQL+Tuning+Service+via+Generalized+Transfer+Learning)|0|
|[Root Cause Analysis for Microservice Systems via Hierarchical Reinforcement Learning from Human Feedback](https://doi.org/10.1145/3580305.3599934)|Lu Wang, Chaoyun Zhang, Ruomeng Ding, Yong Xu, Qihang Chen, Wentao Zou, Qingjun Chen, Meng Zhang, Xuedong Gao, Hao Fan, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Root+Cause+Analysis+for+Microservice+Systems+via+Hierarchical+Reinforcement+Learning+from+Human+Feedback)|0|
|[Knowledge Based Prohibited Item Detection on Heterogeneous Risk Graphs](https://doi.org/10.1145/3580305.3599852)|Tingyan Xiang, Ao Li, Yugang Ji, Dong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Based+Prohibited+Item+Detection+on+Heterogeneous+Risk+Graphs)|0|
|[A Data-Driven Decision Support Framework for Player Churn Analysis in Online Games](https://doi.org/10.1145/3580305.3599759)|Yu Xiong, Runze Wu, Shiwei Zhao, Jianrong Tao, Xudong Shen, Tangjie Lyu, Changjie Fan, Peng Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Data-Driven+Decision+Support+Framework+for+Player+Churn+Analysis+in+Online+Games)|0|
|[Multi Datasource LTV User Representation (MDLUR)](https://doi.org/10.1145/3580305.3599871)|Junwoo Yun, Wonryeol Kwak, Joohyun Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi+Datasource+LTV+User+Representation+(MDLUR))|0|
|[Understanding the Semantics of GPS-based Trajectories for Road Closure Detection](https://doi.org/10.1145/3580305.3599926)|Jiasheng Zhang, Kaiqiang An, Guoping Liu, Xiang Wen, Runbo Hu, Jie Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Semantics+of+GPS-based+Trajectories+for+Road+Closure+Detection)|0|
|[TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter](https://doi.org/10.1145/3580305.3599921)|Xinyang Zhang, Yury Malkov, Omar Florez, Serim Park, Brian McWilliams, Jiawei Han, Ahmed ElKishky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TwHIN-BERT:+A+Socially-Enriched+Pre-trained+Language+Model+for+Multilingual+Tweet+Representations+at+Twitter)|0|
|[Online Few-Shot Time Series Classification for Aftershock Detection](https://doi.org/10.1145/3580305.3599879)|Sheng Zhong, Vinicius M. A. Souza, Glenn Eli Baker, Abdullah Mueen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Few-Shot+Time+Series+Classification+for+Aftershock+Detection)|0|
|[A Feature-Based Coalition Game Framework with Privileged Knowledge Transfer for User-tag Profile Modeling](https://doi.org/10.1145/3580305.3599761)|Xianghui Zhu, Peng Du, Shuo Shao, Chenxu Zhu, Weinan Zhang, Yang Wang, Yang Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Feature-Based+Coalition+Game+Framework+with+Privileged+Knowledge+Transfer+for+User-tag+Profile+Modeling)|0|
|[Fairness in Graph Machine Learning: Recent Advances and Future Prospectives](https://doi.org/10.1145/3580305.3599555)|Yushun Dong, Oyku Deniz Kose, Yanning Shen, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+in+Graph+Machine+Learning:+Recent+Advances+and+Future+Prospectives)|0|
|[Socially Responsible Machine Learning: A Causal Perspective](https://doi.org/10.1145/3580305.3599571)|Raha Moraffah, AmirHossein Karimi, Adrienne Raglin, Huan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Socially+Responsible+Machine+Learning:+A+Causal+Perspective)|0|
|[Training Large-scale Foundation Models on Emerging AI Chips](https://doi.org/10.1145/3580305.3599573)|Aashiq Muhamed, Christian Bock, Rahul Solanki, Youngsuk Park, Yida Wang, Jun Huan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Training+Large-scale+Foundation+Models+on+Emerging+AI+Chips)|0|
|[How to DP-fy ML: A Practical Tutorial to Machine Learning with Differential Privacy](https://doi.org/10.1145/3580305.3599561)|Natalia Ponomareva, Sergei Vassilvitskii, Zheng Xu, Brendan McMahan, Alexey Kurakin, Chiyaun Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+to+DP-fy+ML:+A+Practical+Tutorial+to+Machine+Learning+with+Differential+Privacy)|0|
|[Trustworthy Machine Learning: Robustness, Generalization, and Interpretability](https://doi.org/10.1145/3580305.3599574)|Jindong Wang, Haoliang Li, Haohan Wang, Sinno Jialin Pan, Xing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trustworthy+Machine+Learning:+Robustness,+Generalization,+and+Interpretability)|0|
|[Large-Scale Graph Neural Networks: The Past and New Frontiers](https://doi.org/10.1145/3580305.3599565)|Rui Xue, Haoyu Han, Tong Zhao, Neil Shah, Jiliang Tang, Xiaorui Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large-Scale+Graph+Neural+Networks:+The+Past+and+New+Frontiers)|0|
|[Knowledge-augmented Graph Machine Learning for Drug Discovery: From Precision to Interpretability](https://doi.org/10.1145/3580305.3599563)|Zhiqiang Zhong, Davide Mottin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-augmented+Graph+Machine+Learning+for+Drug+Discovery:+From+Precision+to+Interpretability)|0|
|[Foundations and Applications in Large-scale AI Models: Pre-training, Fine-tuning, and Prompt-based Learning](https://doi.org/10.1145/3580305.3599209)|Derek Cheng, Dhaval Patel, Linsey Pang, Sameep Mehta, Kexin Xie, Ed H. Chi, Wei Liu, Nitesh V. Chawla, James Bailey||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Foundations+and+Applications+in+Large-scale+AI+Models:+Pre-training,+Fine-tuning,+and+Prompt-based+Learning)|0|
|[Minimizing Hitting Time between Disparate Groups with Shortcut Edges](https://doi.org/10.1145/3580305.3599434)|Florian Adriaens, Honglian Wang, Aristides Gionis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Minimizing+Hitting+Time+between+Disparate+Groups+with+Shortcut+Edges)|0|
|[Fair Allocation Over Time, with Applications to Content Moderation](https://doi.org/10.1145/3580305.3599340)|Amine Allouah, Christian Kroer, Xuan Zhang, Vashist Avadhanula, Nona Bohanon, Anil Dania, Caner Gocmen, Sergey Pupyrev, Parikshit Shah, Nicolás Stier Moses, Ken Rodríguez Taarup||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Allocation+Over+Time,+with+Applications+to+Content+Moderation)|0|
|[Maximizing Neutrality in News Ordering](https://doi.org/10.1145/3580305.3599425)|Rishi Advani, Paolo Papotti, Abolfazl Asudeh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Maximizing+Neutrality+in+News+Ordering)|0|
|[Knowledge Graph Reasoning over Entities and Numerical Values](https://doi.org/10.1145/3580305.3599399)|Jiaxin Bai, Chen Luo, Zheng Li, Qingyu Yin, Bing Yin, Yangqiu Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Reasoning+over+Entities+and+Numerical+Values)|0|
|[Communication Efficient and Differentially Private Logistic Regression under the Distributed Setting](https://doi.org/10.1145/3580305.3599279)|Ergute Bao, Dawei Gao, Xiaokui Xiao, Yaliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Communication+Efficient+and+Differentially+Private+Logistic+Regression+under+the+Distributed+Setting)|0|
|[Preemptive Detection of Fake Accounts on Social Networks via Multi-Class Preferential Attachment Classifiers](https://doi.org/10.1145/3580305.3599471)|Adam Breuer, Nazanin Khosravani Tehrani, Michael Tingley, Bradford Cottel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preemptive+Detection+of+Fake+Accounts+on+Social+Networks+via+Multi-Class+Preferential+Attachment+Classifiers)|0|
|[On Improving the Cohesiveness of Graphs by Merging Nodes: Formulation, Analysis, and Algorithms](https://doi.org/10.1145/3580305.3599449)|Fanchen Bu, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Improving+the+Cohesiveness+of+Graphs+by+Merging+Nodes:+Formulation,+Analysis,+and+Algorithms)|0|
|[When to Pre-Train Graph Neural Networks? From Data Generation Perspective!](https://doi.org/10.1145/3580305.3599548)|Yuxuan Cao, Jiarong Xu, Carl Yang, Jiaan Wang, Yunchao Zhang, Chunping Wang, Lei Chen, Yang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+to+Pre-Train+Graph+Neural+Networks?+From+Data+Generation+Perspective!)|0|
|[MBrain: A Multi-channel Self-Supervised Learning Framework for Brain Signals](https://doi.org/10.1145/3580305.3599426)|Donghong Cai, Junru Chen, Yang Yang, Teng Liu, Yafeng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MBrain:+A+Multi-channel+Self-Supervised+Learning+Framework+for+Brain+Signals)|0|
|[Efficient Coreset Selection with Cluster-based Methods](https://doi.org/10.1145/3580305.3599326)|Chengliang Chai, Jiayi Wang, Nan Tang, Ye Yuan, Jiabin Liu, Yuhao Deng, Guoren Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Coreset+Selection+with+Cluster-based+Methods)|0|
|[SURE: Robust, Explainable, and Fair Classification without Sensitive Attributes](https://doi.org/10.1145/3580305.3599514)|Deepayan Chakrabarti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SURE:+Robust,+Explainable,+and+Fair+Classification+without+Sensitive+Attributes)|0|
|[Data-Efficient and Interpretable Tabular Anomaly Detection](https://doi.org/10.1145/3580305.3599294)|ChunHao Chang, Jinsung Yoon, Sercan Ö. Arik, Madeleine Udell, Tomas Pfister||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data-Efficient+and+Interpretable+Tabular+Anomaly+Detection)|0|
|[Open-Set Semi-Supervised Text Classification with Latent Outlier Softening](https://doi.org/10.1145/3580305.3599456)|Junfan Chen, Richong Zhang, Junchi Chen, Chunming Hu, Yongyi Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Open-Set+Semi-Supervised+Text+Classification+with+Latent+Outlier+Softening)|0|
|[Improving Expressivity of GNNs with Subgraph-specific Factor Embedded Normalization](https://doi.org/10.1145/3580305.3599388)|Kaixuan Chen, Shunyu Liu, Tongtian Zhu, Ji Qiao, Yun Su, Yingjie Tian, Tongya Zheng, Haofei Zhang, Zunlei Feng, Jingwen Ye, Mingli Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Expressivity+of+GNNs+with+Subgraph-specific+Factor+Embedded+Normalization)|0|
|[Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler](https://doi.org/10.1145/3580305.3599445)|Zhijun Chen, Hailong Sun, Wanhao Zhang, Chunyi Xu, Qianren Mao, Pengpeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural-Hidden-CRF:+A+Robust+Weakly-Supervised+Sequence+Labeler)|0|
|[Classification of Edge-dependent Labels of Nodes in Hypergraphs](https://doi.org/10.1145/3580305.3599274)|Minyoung Choe, Sunwoo Kim, Jaemin Yoo, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Classification+of+Edge-dependent+Labels+of+Nodes+in+Hypergraphs)|0|
|[Representation Learning on Hyper-Relational and Numeric Knowledge Graphs with Transformers](https://doi.org/10.1145/3580305.3599490)|Chanyoung Chung, Jaejun Lee, Joyce Jiyoung Whang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+Learning+on+Hyper-Relational+and+Numeric+Knowledge+Graphs+with+Transformers)|0|
|[Reducing Exposure to Harmful Content via Graph Rewiring](https://doi.org/10.1145/3580305.3599489)|Corinna Coupette, Stefan Neumann, Aristides Gionis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reducing+Exposure+to+Harmful+Content+via+Graph+Rewiring)|0|
|[MGNN: Graph Neural Networks Inspired by Distance Geometry Problem](https://doi.org/10.1145/3580305.3599431)|Guanyu Cui, Zhewei Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MGNN:+Graph+Neural+Networks+Inspired+by+Distance+Geometry+Problem)|0|
|[Deep Encoders with Auxiliary Parameters for Extreme Classification](https://doi.org/10.1145/3580305.3599301)|Kunal Dahiya, Sachin Yadav, Sushant Sondhi, Deepak Saini, Sonu Mehta, Jian Jiao, Sumeet Agarwal, Purushottam Kar, Manik Varma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Encoders+with+Auxiliary+Parameters+for+Extreme+Classification)|0|
|[A Unified Framework of Graph Information Bottleneck for Robustness and Membership Privacy](https://doi.org/10.1145/3580305.3599248)|Enyan Dai, Limeng Cui, Zhengyang Wang, Xianfeng Tang, Yinghan Wang, Monica Xiao Cheng, Bing Yin, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Unified+Framework+of+Graph+Information+Bottleneck+for+Robustness+and+Membership+Privacy)|0|
|[Investigating Trojan Attacks on Pre-trained Language Model-powered Database Middleware](https://doi.org/10.1145/3580305.3599395)|Peiran Dong, Song Guo, Junxiao Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Trojan+Attacks+on+Pre-trained+Language+Model-powered+Database+Middleware)|0|
|[Localised Adaptive Spatial-Temporal Graph Neural Network](https://doi.org/10.1145/3580305.3599418)|Wenying Duan, Xiaoxi He, Zimu Zhou, Lothar Thiele, Hong Rao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Localised+Adaptive+Spatial-Temporal+Graph+Neural+Network)|0|
|[TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting](https://doi.org/10.1145/3580305.3599533)|Vijay Ekambaram, Arindam Jati, Nam Nguyen, Phanwadee Sinthong, Jayant Kalagnanam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TSMixer:+Lightweight+MLP-Mixer+Model+for+Multivariate+Time+Series+Forecasting)|0|
|[Dependence and Model Selection in LLP: The Problem of Variants](https://doi.org/10.1145/3580305.3599307)|Gabriel Franco, Mark Crovella, Giovanni Comarela||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dependence+and+Model+Selection+in+LLP:+The+Problem+of+Variants)|0|
|[Pre-training Antibody Language Models for Antigen-Specific Computational Antibody Design](https://doi.org/10.1145/3580305.3599468)|Kaiyuan Gao, Lijun Wu, Jinhua Zhu, Tianbo Peng, Yingce Xia, Liang He, Shufang Xie, Tao Qin, Haiguang Liu, Kun He, TieYan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-training+Antibody+Language+Models+for+Antigen-Specific+Computational+Antibody+Design)|0|
|[GAL-VNE: Solving the VNE Problem with Global Reinforcement Learning and Local One-Shot Neural Prediction](https://doi.org/10.1145/3580305.3599358)|Haoyu Geng, Runzhong Wang, Fei Wu, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAL-VNE:+Solving+the+VNE+Problem+with+Global+Reinforcement+Learning+and+Local+One-Shot+Neural+Prediction)|0|
|[Sparse Binary Transformers for Multivariate Time Series Modeling](https://doi.org/10.1145/3580305.3599508)|Matt Gorbett, Hossein Shirazi, Indrakshi Ray||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sparse+Binary+Transformers+for+Multivariate+Time+Series+Modeling)|0|
|[3D-Polishing for Triangular Mesh Compression of Point Cloud Data](https://doi.org/10.1145/3580305.3599239)|Jiaqi Gu, Guosheng Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3D-Polishing+for+Triangular+Mesh+Compression+of+Point+Cloud+Data)|0|
|[ESSA: Explanation Iterative Supervision via Saliency-guided Data Augmentation](https://doi.org/10.1145/3580305.3599336)|Siyi Gu, Yifei Zhang, Yuyang Gao, Xiaofeng Yang, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ESSA:+Explanation+Iterative+Supervision+via+Saliency-guided+Data+Augmentation)|0|
|[CounterNet: End-to-End Training of Prediction Aware Counterfactual Explanations](https://doi.org/10.1145/3580305.3599290)|Hangzhi Guo, Thanh Hong Nguyen, Amulya Yadav||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CounterNet:+End-to-End+Training+of+Prediction+Aware+Counterfactual+Explanations)|0|
|[Clenshaw Graph Neural Networks](https://doi.org/10.1145/3580305.3599275)|Yuhe Guo, Zhewei Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clenshaw+Graph+Neural+Networks)|0|
|[CampER: An Effective Framework for Privacy-Aware Deep Entity Resolution](https://doi.org/10.1145/3580305.3599266)|Yuxiang Guo, Lu Chen, Zhengjie Zhou, Baihua Zheng, Ziquan Fang, Zhikun Zhang, Yuren Mao, Yunjun Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CampER:+An+Effective+Framework+for+Privacy-Aware+Deep+Entity+Resolution)|0|
|[A Data-centric Framework to Endow Graph Neural Networks with Out-Of-Distribution Detection Ability](https://doi.org/10.1145/3580305.3599244)|Yuxin Guo, Cheng Yang, Yuluo Chen, Jixi Liu, Chuan Shi, Junping Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Data-centric+Framework+to+Endow+Graph+Neural+Networks+with+Out-Of-Distribution+Detection+Ability)|0|
|[Frigate: Frugal Spatio-temporal Forecasting on Road Networks](https://doi.org/10.1145/3580305.3599357)|Mridul Gupta, Hariprasad Kodamana, Sayan Ranu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Frigate:+Frugal+Spatio-temporal+Forecasting+on+Road+Networks)|0|
|[Mitigating Action Hysteresis in Traffic Signal Control with Traffic Predictive Reinforcement Learning](https://doi.org/10.1145/3580305.3599528)|Xiao Han, Xiangyu Zhao, Liang Zhang, Wanyu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Action+Hysteresis+in+Traffic+Signal+Control+with+Traffic+Predictive+Reinforcement+Learning)|0|
|[GAT-MF: Graph Attention Mean Field for Very Large Scale Multi-Agent Reinforcement Learning](https://doi.org/10.1145/3580305.3599359)|Qianyue Hao, Wenzhen Huang, Tao Feng, Jian Yuan, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAT-MF:+Graph+Attention+Mean+Field+for+Very+Large+Scale+Multi-Agent+Reinforcement+Learning)|0|
|[Prescriptive PCA: Dimensionality Reduction for Two-stage Stochastic Optimization](https://doi.org/10.1145/3580305.3599474)|Long He, HoYin Mak||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prescriptive+PCA:+Dimensionality+Reduction+for+Two-stage+Stochastic+Optimization)|0|
|[Graph Neural Processes for Spatio-Temporal Extrapolation](https://doi.org/10.1145/3580305.3599372)|Junfeng Hu, Yuxuan Liang, Zhencheng Fan, Hongyang Chen, Yu Zheng, Roger Zimmermann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Processes+for+Spatio-Temporal+Extrapolation)|0|
|[ST-iFGSM: Enhancing Robustness of Human Mobility Signature Identification Model via Spatial-Temporal Iterative FGSM](https://doi.org/10.1145/3580305.3599513)|Mingzhi Hu, Xin Zhang, Yanhua Li, Xun Zhou, Jun Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ST-iFGSM:+Enhancing+Robustness+of+Human+Mobility+Signature+Identification+Model+via+Spatial-Temporal+Iterative+FGSM)|0|
|[Leveraging Relational Graph Neural Network for Transductive Model Ensemble](https://doi.org/10.1145/3580305.3599414)|Zhengyu Hu, Jieyu Zhang, Haonan Wang, Siwei Liu, Shangsong Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Relational+Graph+Neural+Network+for+Transductive+Model+Ensemble)|0|
|[One for All: Unified Workload Prediction for Dynamic Multi-tenant Edge Cloud Platforms](https://doi.org/10.1145/3580305.3599453)|Shaoyuan Huang, Zheng Wang, Heng Zhang, Xiaofei Wang, Cheng Zhang, Wenyu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One+for+All:+Unified+Workload+Prediction+for+Dynamic+Multi-tenant+Edge+Cloud+Platforms)|0|
|[Generalizing Graph ODE for Learning Complex System Dynamics across Environments](https://doi.org/10.1145/3580305.3599362)|Zijie Huang, Yizhou Sun, Wei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalizing+Graph+ODE+for+Learning+Complex+System+Dynamics+across+Environments)|0|
|[The Information Pathways Hypothesis: Transformers are Dynamic Self-Ensembles](https://doi.org/10.1145/3580305.3599520)|Md. Shamim Hussain, Mohammed J. Zaki, Dharmashankar Subramanian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Information+Pathways+Hypothesis:+Transformers+are+Dynamic+Self-Ensembles)|0|
|[Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution](https://doi.org/10.1145/3580305.3599365)|Tsuyoshi Idé, Naoki Abe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Perturbation+Analysis+for+Probabilistic+Black-Box+Anomaly+Attribution)|0|
|[Parameter-free Spikelet: Discovering Different Length and Warped Time Series Motifs using an Adaptive Time Series Representation](https://doi.org/10.1145/3580305.3599310)|Makoto Imamura, Takaaki Nakamura||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Parameter-free+Spikelet:+Discovering+Different+Length+and+Warped+Time+Series+Motifs+using+an+Adaptive+Time+Series+Representation)|0|
|[Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting](https://doi.org/10.1145/3580305.3599378)|Arindam Jati, Vijay Ekambaram, Shaonli Pal, Brian Quanz, Wesley M. Gifford, Pavithra Harsha, Stuart Siegel, Sumanta Mukherjee, Chandra Narayanaswami||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Proxy+Modeling+for+Improved+HPO+in+Time+Series+Forecasting)|0|
|[Precursor-of-Anomaly Detection for Irregular Time Series](https://doi.org/10.1145/3580305.3599469)|Sheo Yon Jhin, Jaehoon Lee, Noseong Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Precursor-of-Anomaly+Detection+for+Irregular+Time+Series)|0|
|[Community-based Dynamic Graph Learning for Popularity Prediction](https://doi.org/10.1145/3580305.3599281)|Shuo Ji, Xiaodong Lu, Mingzhe Liu, Leilei Sun, Chuanren Liu, Bowen Du, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Community-based+Dynamic+Graph+Learning+for+Popularity+Prediction)|0|
|[GetPt: Graph-enhanced General Table Pre-training with Alternate Attention Network](https://doi.org/10.1145/3580305.3599366)|Ran Jia, Haoming Guo, Xiaoyuan Jin, Chao Yan, Lun Du, Xiaojun Ma, Tamara Stankovic, Marko Lozajic, Goran Zoranovic, Igor Ilic, Shi Han, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GetPt:+Graph-enhanced+General+Table+Pre-training+with+Alternate+Attention+Network)|0|
|[Enhancing Node-Level Adversarial Defenses by Lipschitz Regularization of Graph Neural Networks](https://doi.org/10.1145/3580305.3599335)|Yaning Jia, Dongmian Zou, Hongfei Wang, Hai Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Node-Level+Adversarial+Defenses+by+Lipschitz+Regularization+of+Graph+Neural+Networks)|0|
|[Complementary Classifier Induced Partial Label Learning](https://doi.org/10.1145/3580305.3599282)|Yuheng Jia, Chongjie Si, MinLing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Complementary+Classifier+Induced+Partial+Label+Learning)|0|
|[Anomaly Detection with Score Distribution Discrimination](https://doi.org/10.1145/3580305.3599258)|Minqi Jiang, Songqiao Han, Hailiang Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anomaly+Detection+with+Score+Distribution+Discrimination)|0|
|[CF-GODE: Continuous-Time Causal Inference for Multi-Agent Dynamical Systems](https://doi.org/10.1145/3580305.3599272)|Song Jiang, Zijie Huang, Xiao Luo, Yizhou Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CF-GODE:+Continuous-Time+Causal+Inference+for+Multi-Agent+Dynamical+Systems)|0|
|[FedSkill: Privacy Preserved Interpretable Skill Learning via Imitation](https://doi.org/10.1145/3580305.3599349)|Yushan Jiang, Wenchao Yu, Dongjin Song, Lu Wang, Wei Cheng, Haifeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedSkill:+Privacy+Preserved+Interpretable+Skill+Learning+via+Imitation)|0|
|[Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks](https://doi.org/10.1145/3580305.3599376)|Bowen Jin, Yu Zhang, Qi Zhu, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterformer:+Transformer-based+Deep+Node+Representation+Learning+on+Heterogeneous+Text-Rich+Networks)|0|
|[Transferable Graph Structure Learning for Graph-based Traffic Forecasting Across Cities](https://doi.org/10.1145/3580305.3599529)|Yilun Jin, Kai Chen, Qiang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transferable+Graph+Structure+Learning+for+Graph-based+Traffic+Forecasting+Across+Cities)|0|
|[When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting](https://doi.org/10.1145/3580305.3599547)|Harshavardhan Kamarthi, Lingkai Kong, Alexander Rodríguez, Chao Zhang, B. Aditya Prakash||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Rigidity+Hurts:+Soft+Consistency+Regularization+for+Probabilistic+Hierarchical+Time+Series+Forecasting)|0|
|[R-Mixup: Riemannian Mixup for Biological Networks](https://doi.org/10.1145/3580305.3599483)|Xuan Kan, Zimu Li, Hejie Cui, Yue Yu, Ran Xu, Shaojun Yu, Zilong Zhang, Ying Guo, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=R-Mixup:+Riemannian+Mixup+for+Biological+Networks)|0|
|[Task-Equivariant Graph Few-shot Learning](https://doi.org/10.1145/3580305.3599515)|Sungwon Kim, Junseok Lee, Namkyeong Lee, Wonjoong Kim, Seungyoon Choi, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Equivariant+Graph+Few-shot+Learning)|0|
|[Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning](https://doi.org/10.1145/3580305.3599297)|Deniz Koyuncu, Alex Gittens, Bülent Yener, Moti Yung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deception+by+Omission:+Using+Adversarial+Missingness+to+Poison+Causal+Structure+Learning)|0|
|[Optimizing Traffic Control with Model-Based Learning: A Pessimistic Approach to Data-Efficient Policy Inference](https://doi.org/10.1145/3580305.3599459)|Mayuresh Kunjir, Sanjay Chawla, Siddarth Chandrasekar, Devika Jay, Balaraman Ravindran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Traffic+Control+with+Model-Based+Learning:+A+Pessimistic+Approach+to+Data-Efficient+Policy+Inference)|0|
|[Shift-Robust Molecular Relational Learning with Causal Substructure](https://doi.org/10.1145/3580305.3599437)|Namkyeong Lee, Kanghoon Yoon, Gyoung S. Na, Sein Kim, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shift-Robust+Molecular+Relational+Learning+with+Causal+Substructure)|0|
|[Boosting Multitask Learning on Graphs through Higher-Order Task Affinities](https://doi.org/10.1145/3580305.3599265)|Dongyue Li, Haotian Ju, Aneesh Sharma, Hongyang R. Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Multitask+Learning+on+Graphs+through+Higher-Order+Task+Affinities)|0|
|[Interpretable Sparsification of Brain Graphs: Better Practices and Effective Designs for Graph Neural Networks](https://doi.org/10.1145/3580305.3599394)|Gaotang Li, Marlena Duda, Xiang Zhang, Danai Koutra, Yujun Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Sparsification+of+Brain+Graphs:+Better+Practices+and+Effective+Designs+for+Graph+Neural+Networks)|0|
|[What's Behind the Mask: Understanding Masked Graph Modeling for Graph Autoencoders](https://doi.org/10.1145/3580305.3599546)|Jintang Li, Ruofan Wu, Wangbin Sun, Liang Chen, Sheng Tian, Liang Zhu, Changhua Meng, Zibin Zheng, Weiqiang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What's+Behind+the+Mask:+Understanding+Masked+Graph+Modeling+for+Graph+Autoencoders)|0|
|[OPORP: One Permutation + One Random Projection](https://doi.org/10.1145/3580305.3599457)|Ping Li, Xiaoyun Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OPORP:+One+Permutation+++One+Random+Projection)|0|
|[Multi-Temporal Relationship Inference in Urban Areas](https://doi.org/10.1145/3580305.3599440)|Shuangli Li, Jingbo Zhou, Ji Liu, Tong Xu, Enhong Chen, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Temporal+Relationship+Inference+in+Urban+Areas)|0|
|[HomoGCL: Rethinking Homophily in Graph Contrastive Learning](https://doi.org/10.1145/3580305.3599380)|WenZhi Li, ChangDong Wang, Hui Xiong, JianHuang Lai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HomoGCL:+Rethinking+Homophily+in+Graph+Contrastive+Learning)|0|
|[Urban Region Representation Learning with OpenStreetMap Building Footprints](https://doi.org/10.1145/3580305.3599538)|Yi Li, Weiming Huang, Gao Cong, Hao Wang, Zheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Urban+Region+Representation+Learning+with+OpenStreetMap+Building+Footprints)|0|
|[Machine Unlearning in Gradient Boosting Decision Trees](https://doi.org/10.1145/3580305.3599420)|Huawei Lin, Jun Woo Chung, Yingjie Lao, Weijie Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Machine+Unlearning+in+Gradient+Boosting+Decision+Trees)|0|
|[Fire: An Optimization Approach for Fast Interpretable Rule Extraction](https://doi.org/10.1145/3580305.3599353)|Brian Liu, Rahul Mazumder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fire:+An+Optimization+Approach+for+Fast+Interpretable+Rule+Extraction)|0|
|[Robust Spatiotemporal Traffic Forecasting with Reinforced Dynamic Adversarial Training](https://doi.org/10.1145/3580305.3599492)|Fan Liu, Weijia Zhang, Hao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Spatiotemporal+Traffic+Forecasting+with+Reinforced+Dynamic+Adversarial+Training)|0|
|[Discovering Dynamic Causal Space for DAG Structure Learning](https://doi.org/10.1145/3580305.3599309)|Fangfu Liu, Wenchang Ma, An Zhang, Xiang Wang, Yueqi Duan, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Dynamic+Causal+Space+for+DAG+Structure+Learning)|0|
|[Semi-Supervised Graph Imbalanced Regression](https://doi.org/10.1145/3580305.3599497)|Gang Liu, Tong Zhao, Eric Inae, Tengfei Luo, Meng Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-Supervised+Graph+Imbalanced+Regression)|0|
|[Enhancing Graph Representations Learning with Decorrelated Propagation](https://doi.org/10.1145/3580305.3599334)|Hua Liu, Haoyu Han, Wei Jin, Xiaorui Liu, Hui Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Graph+Representations+Learning+with+Decorrelated+Propagation)|0|
|[Guiding Mathematical Reasoning via Mastering Commonsense Formula Knowledge](https://doi.org/10.1145/3580305.3599375)|Jiayu Liu, Zhenya Huang, Zhiyuan Ma, Qi Liu, Enhong Chen, Tianhuang Su, Haifeng Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Guiding+Mathematical+Reasoning+via+Mastering+Commonsense+Formula+Knowledge)|0|
|[Using Motif Transitions for Temporal Graph Generation](https://doi.org/10.1145/3580305.3599540)|Penghang Liu, Ahmet Erdem Sariyüce||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+Motif+Transitions+for+Temporal+Graph+Generation)|0|
|[Fairness-Aware Continuous Predictions of Multiple Analytics Targets in Dynamic Networks](https://doi.org/10.1145/3580305.3599341)|Ruifeng Liu, Qu Liu, Tingjian Ge||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness-Aware+Continuous+Predictions+of+Multiple+Analytics+Targets+in+Dynamic+Networks)|0|
|[Decoupled Rationalization with Asymmetric Learning Rates: A Flexible Lipschitz Restraint](https://doi.org/10.1145/3580305.3599299)|Wei Liu, Jun Wang, Haozhao Wang, Ruixuan Li, Yang Qiu, Yuankai Zhang, Jie Han, Yixiong Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Rationalization+with+Asymmetric+Learning+Rates:+A+Flexible+Lipschitz+Restraint)|0|
|[FLOOD: A Flexible Invariant Learning Framework for Out-of-Distribution Generalization on Graphs](https://doi.org/10.1145/3580305.3599355)|Yang Liu, Xiang Ao, Fuli Feng, Yunshan Ma, Kuan Li, TatSeng Chua, Qing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLOOD:+A+Flexible+Invariant+Learning+Framework+for+Out-of-Distribution+Generalization+on+Graphs)|0|
|[QTIAH-GNN: Quantity and Topology Imbalance-aware Heterogeneous Graph Neural Network for Bankruptcy Prediction](https://doi.org/10.1145/3580305.3599479)|Yucheng Liu, Zipeng Gao, Xiangyang Liu, Pengfei Luo, Yang Yang, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QTIAH-GNN:+Quantity+and+Topology+Imbalance-aware+Heterogeneous+Graph+Neural+Network+for+Bankruptcy+Prediction)|0|
|[Multi-Grained Multimodal Interaction Network for Entity Linking](https://doi.org/10.1145/3580305.3599439)|Pengfei Luo, Tong Xu, Shiwei Wu, Chen Zhu, Linli Xu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Grained+Multimodal+Interaction+Network+for+Entity+Linking)|0|
|[Learning Strong Graph Neural Networks with Weak Information](https://doi.org/10.1145/3580305.3599410)|Yixin Liu, Kaize Ding, Jianling Wang, Vincent C. S. Lee, Huan Liu, Shirui Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Strong+Graph+Neural+Networks+with+Weak+Information)|0|
|[Augmenting Recurrent Graph Neural Networks with a Cache](https://doi.org/10.1145/3580305.3599260)|Guixiang Ma, Vy A. Vo, Theodore L. Willke, Nesreen K. Ahmed||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Augmenting+Recurrent+Graph+Neural+Networks+with+a+Cache)|0|
|[Learning for Counterfactual Fairness from Observational Data](https://doi.org/10.1145/3580305.3599408)|Jing Ma, Ruocheng Guo, Aidong Zhang, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+for+Counterfactual+Fairness+from+Observational+Data)|0|
|[Towards Graph-level Anomaly Detection via Deep Evolutionary Mapping](https://doi.org/10.1145/3580305.3599524)|Xiaoxiao Ma, Jia Wu, Jian Yang, Quan Z. Sheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Graph-level+Anomaly+Detection+via+Deep+Evolutionary+Mapping)|0|
|[Context-aware Event Forecasting via Graph Disentanglement](https://doi.org/10.1145/3580305.3599285)|Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-aware+Event+Forecasting+via+Graph+Disentanglement)|0|
|[End-to-End Inventory Prediction and Contract Allocation for Guaranteed Delivery Advertising](https://doi.org/10.1145/3580305.3599332)|Wuyang Mao, Chuanren Liu, Yundu Huang, Zhonglin Zu, M. Harshvardhan, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Inventory+Prediction+and+Contract+Allocation+for+Guaranteed+Delivery+Advertising)|0|
|[Densest Diverse Subgraphs: How to Plan a Successful Cocktail Party with Diversity](https://doi.org/10.1145/3580305.3599306)|Atsushi Miyauchi, Tianyi Chen, Konstantinos Sotiropoulos, Charalampos E. Tsourakakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Densest+Diverse+Subgraphs:+How+to+Plan+a+Successful+Cocktail+Party+with+Diversity)|0|
|[Causal Inference via Style Transfer for Out-of-distribution Generalisation](https://doi.org/10.1145/3580305.3599270)|Toan Nguyen, Kien Do, Duc Thanh Nguyen, Bao Duong, Thin Nguyen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Inference+via+Style+Transfer+for+Out-of-distribution+Generalisation)|0|
|[A Higher-Order Temporal H-Index for Evolving Networks](https://doi.org/10.1145/3580305.3599242)|Lutz Oettershagen, Nils M. Kriege, Petra Mutzel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Higher-Order+Temporal+H-Index+for+Evolving+Networks)|0|
|[Deep Weakly-supervised Anomaly Detection](https://doi.org/10.1145/3580305.3599302)|Guansong Pang, Chunhua Shen, Huidong Jin, Anton van den Hengel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Weakly-supervised+Anomaly+Detection)|0|
|[FedDefender: Client-Side Attack-Tolerant Federated Learning](https://doi.org/10.1145/3580305.3599346)|Sungwon Park, Sungwon Han, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, Meeyoung Cha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedDefender:+Client-Side+Attack-Tolerant+Federated+Learning)|0|
|[Few-shot Low-resource Knowledge Graph Completion with Multi-view Task Representation Generation](https://doi.org/10.1145/3580305.3599350)|Shichao Pei, Ziyi Kou, Qiannan Zhang, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+Low-resource+Knowledge+Graph+Completion+with+Multi-view+Task+Representation+Generation)|0|
|[Efficient Centrality Maximization with Rademacher Averages](https://doi.org/10.1145/3580305.3599325)|Leonardo Pellegrina||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Centrality+Maximization+with+Rademacher+Averages)|0|
|[Learning from Positive and Unlabeled Multi-Instance Bags in Anomaly Detection](https://doi.org/10.1145/3580305.3599409)|Lorenzo Perini, Vincent Vercruyssen, Jesse Davis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+from+Positive+and+Unlabeled+Multi-Instance+Bags+in+Anomaly+Detection)|0|
|[Generalizable Low-Resource Activity Recognition with Diverse and Discriminative Representation Learning](https://doi.org/10.1145/3580305.3599360)|Xin Qin, Jindong Wang, Shuo Ma, Wang Lu, Yongchun Zhu, Xing Xie, Yiqiang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalizable+Low-Resource+Activity+Recognition+with+Diverse+and+Discriminative+Representation+Learning)|0|
|[3D-IDS: Doubly Disentangled Dynamic Intrusion Detection](https://doi.org/10.1145/3580305.3599238)|Chenyang Qiu, Yingsheng Geng, Junrui Lu, Kaida Chen, Shitong Zhu, Ya Su, Guoshun Nan, Can Zhang, Junsong Fu, Qimei Cui, Xiaofeng Tao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3D-IDS:+Doubly+Disentangled+Dynamic+Intrusion+Detection)|0|
|[Reconstructing Graph Diffusion History from a Single Snapshot](https://doi.org/10.1145/3580305.3599488)|Ruizhong Qiu, Dingsu Wang, Lei Ying, H. Vincent Poor, Yifang Zhang, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reconstructing+Graph+Diffusion+History+from+a+Single+Snapshot)|0|
|[FedPseudo: Privacy-Preserving Pseudo Value-Based Deep Learning Models for Federated Survival Analysis](https://doi.org/10.1145/3580305.3599348)|Md. Mahmudur Rahman, Sanjay Purushotham||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedPseudo:+Privacy-Preserving+Pseudo+Value-Based+Deep+Learning+Models+for+Federated+Survival+Analysis)|0|
|[Robustness Certification for Structured Prediction with General Inputs via Safe Region Modeling in the Semimetric Output Space](https://doi.org/10.1145/3580305.3599493)|Huaqing Shao, Lanjun Wang, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robustness+Certification+for+Structured+Prediction+with+General+Inputs+via+Safe+Region+Modeling+in+the+Semimetric+Output+Space)|0|
|[CARL-G: Clustering-Accelerated Representation Learning on Graphs](https://doi.org/10.1145/3580305.3599268)|William Shiao, Uday Singh Saini, Yozen Liu, Tong Zhao, Neil Shah, Evangelos E. Papalexakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CARL-G:+Clustering-Accelerated+Representation+Learning+on+Graphs)|0|
|[One-shot Joint Extraction, Registration and Segmentation of Neuroimaging Data](https://doi.org/10.1145/3580305.3599452)|Yao Su, Zhentian Qian, Lei Ma, Lifang He, Xiangnan Kong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-shot+Joint+Extraction,+Registration+and+Segmentation+of+Neuroimaging+Data)|0|
|[Learning Autoregressive Model in LSM-Tree based Store](https://doi.org/10.1145/3580305.3599405)|Yunxiang Su, Wenxuan Ma, Shaoxu Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Autoregressive+Model+in+LSM-Tree+based+Store)|0|
|[Enhance Diffusion to Improve Robust Generalization](https://doi.org/10.1145/3580305.3599333)|Jianhui Sun, Sanchit Sinha, Aidong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhance+Diffusion+to+Improve+Robust+Generalization)|0|
|[ShapleyFL: Robust Federated Learning Based on Shapley Value](https://doi.org/10.1145/3580305.3599500)|Qiheng Sun, Xiang Li, Jiayao Zhang, Li Xiong, Weiran Liu, Jinfei Liu, Zhan Qin, Kui Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ShapleyFL:+Robust+Federated+Learning+Based+on+Shapley+Value)|0|
|[Mastering Stock Markets with Efficient Mixture of Diversified Trading Experts](https://doi.org/10.1145/3580305.3599424)|Shuo Sun, Xinrun Wang, Wanqi Xue, Xiaoxuan Lou, Bo An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mastering+Stock+Markets+with+Efficient+Mixture+of+Diversified+Trading+Experts)|0|
|[Joint Pre-training and Local Re-training: Transferable Representation Learning on Multi-source Knowledge Graphs](https://doi.org/10.1145/3580305.3599397)|Zequn Sun, Jiacheng Huang, Jinghao Lin, Xiaozhou Xu, Qijin Chen, Wei Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Pre-training+and+Local+Re-training:+Transferable+Representation+Learning+on+Multi-source+Knowledge+Graphs)|0|
|[PERT-GNN: Latency Prediction for Microservice-based Cloud-Native Applications via Graph Neural Networks](https://doi.org/10.1145/3580305.3599465)|Da Sun Handason Tam, Yang Liu, Huanle Xu, Siyue Xie, Wing Cheong Lau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PERT-GNN:+Latency+Prediction+for+Microservice-based+Cloud-Native+Applications+via+Graph+Neural+Networks)|0|
|[ExplainableFold: Understanding AlphaFold Prediction with Explainable AI](https://doi.org/10.1145/3580305.3599337)|Juntao Tan, Yongfeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ExplainableFold:+Understanding+AlphaFold+Prediction+with+Explainable+AI)|0|
|[Feature-based Learning for Diverse and Privacy-Preserving Counterfactual Explanations](https://doi.org/10.1145/3580305.3599343)|Vy Vo, Trung Le, Van Nguyen, He Zhao, Edwin V. Bonilla, Gholamreza Haffari, Dinh Q. Phung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Feature-based+Learning+for+Diverse+and+Privacy-Preserving+Counterfactual+Explanations)|0|
|[Adversaries with Limited Information in the Friedkin-Johnsen Model](https://doi.org/10.1145/3580305.3599255)|Sijing Tu, Stefan Neumann, Aristides Gionis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversaries+with+Limited+Information+in+the+Friedkin-Johnsen+Model)|0|
|[Pattern Expansion and Consolidation on Evolving Graphs for Continual Traffic Prediction](https://doi.org/10.1145/3580305.3599463)|Binwu Wang, Yudong Zhang, Xu Wang, Pengkun Wang, Zhengyang Zhou, Lei Bai, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pattern+Expansion+and+Consolidation+on+Evolving+Graphs+for+Continual+Traffic+Prediction)|0|
|[Financial Default Prediction via Motif-preserving Graph Neural Network with Curriculum Learning](https://doi.org/10.1145/3580305.3599351)|Daixin Wang, Zhiqiang Zhang, Yeyu Zhao, Kai Huang, Yulin Kang, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Financial+Default+Prediction+via+Motif-preserving+Graph+Neural+Network+with+Curriculum+Learning)|0|
|[Accelerating Antimicrobial Peptide Discovery with Latent Structure](https://doi.org/10.1145/3580305.3599249)|Danqing Wang, Zeyu Wen, Fei Ye, Lei Li, Hao Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+Antimicrobial+Peptide+Discovery+with+Latent+Structure)|0|
|[Efficient and Effective Edge-wise Graph Representation Learning](https://doi.org/10.1145/3580305.3599321)|Hewen Wang, Renchi Yang, Keke Huang, Xiaokui Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Effective+Edge-wise+Graph+Representation+Learning)|0|
|[PROSE: Graph Structure Learning via Progressive Strategy](https://doi.org/10.1145/3580305.3599476)|Huizhao Wang, Yao Fu, Tao Yu, Linghui Hu, Weihao Jiang, Shiliang Pu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PROSE:+Graph+Structure+Learning+via+Progressive+Strategy)|0|
|[Empower Post-hoc Graph Explanations with Information Bottleneck: A Pre-training and Fine-tuning Perspective](https://doi.org/10.1145/3580305.3599330)|Jihong Wang, Minnan Luo, Jundong Li, Yun Lin, Yushun Dong, Jin Song Dong, Qinghua Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empower+Post-hoc+Graph+Explanations+with+Information+Bottleneck:+A+Pre-training+and+Fine-tuning+Perspective)|0|
|[WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis](https://doi.org/10.1145/3580305.3599549)|Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WHEN:+A+Wavelet-DTW+Hybrid+Attention+Network+for+Heterogeneous+Time+Series+Analysis)|0|
|[Federated Few-shot Learning](https://doi.org/10.1145/3580305.3599347)|Song Wang, Xingbo Fu, Kaize Ding, Chen Chen, Huiyuan Chen, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Few-shot+Learning)|0|
|[Contrastive Meta-Learning for Few-shot Node Classification](https://doi.org/10.1145/3580305.3599288)|Song Wang, Zhen Tan, Huan Liu, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Meta-Learning+for+Few-shot+Node+Classification)|0|
|[An Observed Value Consistent Diffusion Model for Imputing Missing Values in Multivariate Time Series](https://doi.org/10.1145/3580305.3599257)|Xu Wang, Hongbo Zhang, Pengkun Wang, Yudong Zhang, Binwu Wang, Zhengyang Zhou, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Observed+Value+Consistent+Diffusion+Model+for+Imputing+Missing+Values+in+Multivariate+Time+Series)|0|
|[Automated 3D Pre-Training for Molecular Property Prediction](https://doi.org/10.1145/3580305.3599252)|Xu Wang, Huan Zhao, WeiWei Tu, Quanming Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+3D+Pre-Training+for+Molecular+Property+Prediction)|0|
|[Rapid Image Labeling via Neuro-Symbolic Learning](https://doi.org/10.1145/3580305.3599485)|Yifeng Wang, Zhi Tu, Yiwen Xiang, Shiyuan Zhou, Xiyuan Chen, Bingxuan Li, Tianyi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rapid+Image+Labeling+via+Neuro-Symbolic+Learning)|0|
|[Learning to Schedule in Diffusion Probabilistic Models](https://doi.org/10.1145/3580305.3599412)|Yunke Wang, Xiyu Wang, AnhDung Dinh, Bo Du, Charles Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Schedule+in+Diffusion+Probabilistic+Models)|0|
|[A Message Passing Neural Network Space for Better Capturing Data-dependent Receptive Fields](https://doi.org/10.1145/3580305.3599243)|Zhili Wang, Shimin Di, Lei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Message+Passing+Neural+Network+Space+for+Better+Capturing+Data-dependent+Receptive+Fields)|0|
|[To Aggregate or Not? Learning with Separate Noisy Labels](https://doi.org/10.1145/3580305.3599522)|Jiaheng Wei, Zhaowei Zhu, Tianyi Luo, Ehsan Amid, Abhishek Kumar, Yang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=To+Aggregate+or+Not?+Learning+with+Separate+Noisy+Labels)|0|
|[Granger Causal Chain Discovery for Sepsis-Associated Derangements via Continuous-Time Hawkes Processes](https://doi.org/10.1145/3580305.3599369)|Song Wei, Yao Xie, Christopher S. Josef, Rishikesan Kamaleswaran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Granger+Causal+Chain+Discovery+for+Sepsis-Associated+Derangements+via+Continuous-Time+Hawkes+Processes)|0|
|[Deep Bayesian Active Learning for Accelerating Stochastic Simulation](https://doi.org/10.1145/3580305.3599300)|Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, YiAn Ma, Rose Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Bayesian+Active+Learning+for+Accelerating+Stochastic+Simulation)|0|
|[Self-Adaptive Perturbation Radii for Adversarial Training](https://doi.org/10.1145/3580305.3599495)|Huimin Wu, Wanli Shi, Chenkang Zhang, Bin Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Adaptive+Perturbation+Radii+for+Adversarial+Training)|0|
|[DECOR: Degree-Corrected Social Graph Refinement for Fake News Detection](https://doi.org/10.1145/3580305.3599298)|Jiaying Wu, Bryan Hooi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DECOR:+Degree-Corrected+Social+Graph+Refinement+for+Fake+News+Detection)|0|
|[Certified Edge Unlearning for Graph Neural Networks](https://doi.org/10.1145/3580305.3599271)|Kun Wu, Jie Shen, Yue Ning, Ting Wang, Wendy Hui Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Certified+Edge+Unlearning+for+Graph+Neural+Networks)|0|
|[Recognizing Unseen Objects via Multimodal Intensive Knowledge Graph Propagation](https://doi.org/10.1145/3580305.3599486)|Likang Wu, Zhi Li, Hongke Zhao, Zhefeng Wang, Qi Liu, Baoxing Huai, Nicholas Jing Yuan, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recognizing+Unseen+Objects+via+Multimodal+Intensive+Knowledge+Graph+Propagation)|0|
|[Towards Reliable Rare Category Analysis on Graphs via Individual Calibration](https://doi.org/10.1145/3580305.3599525)|Longfeng Wu, Bowen Lei, Dongkuan Xu, Dawei Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Reliable+Rare+Category+Analysis+on+Graphs+via+Individual+Calibration)|0|
|[TransformerLight: A Novel Sequence Modeling Based Traffic Signaling Mechanism via Gated Transformer](https://doi.org/10.1145/3580305.3599530)|Qiang Wu, Mingyuan Li, Jun Shen, Linyuan Lü, Bo Du, Ke Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TransformerLight:+A+Novel+Sequence+Modeling+Based+Traffic+Signaling+Mechanism+via+Gated+Transformer)|0|
|[MedLink: De-Identified Patient Health Record Linkage](https://doi.org/10.1145/3580305.3599427)|Zhenbang Wu, Cao Xiao, Jimeng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MedLink:+De-Identified+Patient+Health+Record+Linkage)|0|
|[A Sequence-to-Sequence Approach with Mixed Pointers to Topic Segmentation and Segment Labeling](https://doi.org/10.1145/3580305.3599245)|Jinxiong Xia, Houfeng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Sequence-to-Sequence+Approach+with+Mixed+Pointers+to+Topic+Segmentation+and+Segment+Labeling)|0|
|[Graph Contrastive Learning with Generative Adversarial Network](https://doi.org/10.1145/3580305.3599370)|Cheng Wu, Chaokun Wang, Jingcao Xu, Ziyang Liu, Kai Zheng, Xiaowei Wang, Yang Song, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+with+Generative+Adversarial+Network)|0|
|[A Causality Inspired Framework for Model Interpretation](https://doi.org/10.1145/3580305.3599240)|Chenwang Wu, Xiting Wang, Defu Lian, Xing Xie, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Causality+Inspired+Framework+for+Model+Interpretation)|0|
|[Imputation-based Time-Series Anomaly Detection with Conditional Weight-Incremental Diffusion Models](https://doi.org/10.1145/3580305.3599391)|Chunjing Xiao, Zehua Gou, Wenxin Tai, Kunpeng Zhang, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Imputation-based+Time-Series+Anomaly+Detection+with+Conditional+Weight-Incremental+Diffusion+Models)|0|
|[Spatial Heterophily Aware Graph Neural Networks](https://doi.org/10.1145/3580305.3599510)|Congxi Xiao, Jingbo Zhou, Jizhou Huang, Tong Xu, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatial+Heterophily+Aware+Graph+Neural+Networks)|0|
|[A Dual-Agent Scheduler for Distributed Deep Learning Jobs on Public Cloud via Reinforcement Learning](https://doi.org/10.1145/3580305.3599241)|Mingzhe Xing, Hangyu Mao, Shenglin Yin, Lichen Pan, Zhengchao Zhang, Zhen Xiao, Jieyi Long||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dual-Agent+Scheduler+for+Distributed+Deep+Learning+Jobs+on+Public+Cloud+via+Reinforcement+Learning)|0|
|[How does the Memorization of Neural Networks Impact Adversarial Robust Models?](https://doi.org/10.1145/3580305.3599381)|Han Xu, Xiaorui Liu, Wentao Wang, Zitao Liu, Anil K. Jain, Jiliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+does+the+Memorization+of+Neural+Networks+Impact+Adversarial+Robust+Models?)|0|
|[Internal Logical Induction for Pixel-Symbolic Reinforcement Learning](https://doi.org/10.1145/3580305.3599393)|Jiacheng Xu, Chao Chen, Fuxiang Zhang, Lei Yuan, Zongzhang Zhang, Yang Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Internal+Logical+Induction+for+Pixel-Symbolic+Reinforcement+Learning)|0|
|[Node Classification Beyond Homophily: Towards a General Solution](https://doi.org/10.1145/3580305.3599446)|Zhe Xu, Yuzhong Chen, Qinghai Zhou, Yuhang Wu, Menghai Pan, Hao Yang, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Node+Classification+Beyond+Homophily:+Towards+a+General+Solution)|0|
|[CriticalFL: A Critical Learning Periods Augmented Client Selection Framework for Efficient Federated Learning](https://doi.org/10.1145/3580305.3599293)|Gang Yan, Hao Wang, Xu Yuan, Jian Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CriticalFL:+A+Critical+Learning+Periods+Augmented+Client+Selection+Framework+for+Efficient+Federated+Learning)|0|
|[Fragility Index: A New Approach for Binary Classification](https://doi.org/10.1145/3580305.3599356)|Chen Yang, Ziqiang Zhang, Bo Cao, Zheng Cui, Bin Hu, Tong Li, Daniel Zhuoyu Long, Jin Qi, Feng Wang, Ruohan Zhan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragility+Index:+A+New+Approach+for+Binary+Classification)|0|
|[IDToolkit: A Toolkit for Benchmarking and Developing Inverse Design Algorithms in Nanophotonics](https://doi.org/10.1145/3580305.3599385)|JiaQi Yang, Yucheng Xu, JiaLei Shen, KeBin Fan, DeChuan Zhan, Yang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IDToolkit:+A+Toolkit+for+Benchmarking+and+Developing+Inverse+Design+Algorithms+in+Nanophotonics)|0|
|[MAPLE: Semi-Supervised Learning with Multi-Alignment and Pseudo-Learning](https://doi.org/10.1145/3580305.3599423)|Juncheng Yang, Chao Li, Zuchao Li, Wei Yu, Bo Du, Shijun Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAPLE:+Semi-Supervised+Learning+with+Multi-Alignment+and+Pseudo-Learning)|0|
|[EXTRACT and REFINE: Finding a Support Subgraph Set for Graph Representation](https://doi.org/10.1145/3580305.3599339)|Kuo Yang, Zhengyang Zhou, Wei Sun, Pengkun Wang, Xu Wang, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EXTRACT+and+REFINE:+Finding+a+Support+Subgraph+Set+for+Graph+Representation)|0|
|[κHGCN: Tree-likeness Modeling via Continuous and Discrete Curvature Learning](https://doi.org/10.1145/3580305.3599532)|Menglin Yang, Min Zhou, Lujia Pan, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=κHGCN:+Tree-likeness+Modeling+via+Continuous+and+Discrete+Curvature+Learning)|0|
|[Specify Robust Causal Representation from Mixed Observations](https://doi.org/10.1145/3580305.3599512)|Mengyue Yang, Xinyu Cai, Furui Liu, Weinan Zhang, Jun Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Specify+Robust+Causal+Representation+from+Mixed+Observations)|0|
|[Counterfactual Learning on Heterogeneous Graphs with Greedy Perturbation](https://doi.org/10.1145/3580305.3599289)|Qiang Yang, Changsheng Ma, Qiannan Zhang, Xin Gao, Chuxu Zhang, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Learning+on+Heterogeneous+Graphs+with+Greedy+Perturbation)|0|
|[LightPath: Lightweight and Scalable Path Representation Learning](https://doi.org/10.1145/3580305.3599415)|Sean Bin Yang, Jilin Hu, Chenjuan Guo, Bin Yang, Christian S. Jensen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LightPath:+Lightweight+and+Scalable+Path+Representation+Learning)|0|
|[Test Accuracy vs. Generalization Gap: Model Selection in NLP without Accessing Training or Testing Data](https://doi.org/10.1145/3580305.3599518)|Yaoqing Yang, Ryan Theisen, Liam Hodgkinson, Joseph E. Gonzalez, Kannan Ramchandran, Charles H. Martin, Michael W. Mahoney||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Test+Accuracy+vs.+Generalization+Gap:+Model+Selection+in+NLP+without+Accessing+Training+or+Testing+Data)|0|
|[DCdetector: Dual Attention Contrastive Representation Learning for Time Series Anomaly Detection](https://doi.org/10.1145/3580305.3599295)|Yiyuan Yang, Chaoli Zhang, Tian Zhou, Qingsong Wen, Liang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DCdetector:+Dual+Attention+Contrastive+Representation+Learning+for+Time+Series+Anomaly+Detection)|0|
|[Improving the Expressiveness of K-hop Message-Passing GNNs by Injecting Contextualized Substructure Information](https://doi.org/10.1145/3580305.3599390)|Tianjun Yao, Yingxu Wang, Kun Zhang, Shangsong Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+the+Expressiveness+of+K-hop+Message-Passing+GNNs+by+Injecting+Contextualized+Substructure+Information)|0|
|[PAT: Geometry-Aware Hard-Label Black-Box Adversarial Attacks on Text](https://doi.org/10.1145/3580305.3599461)|Muchao Ye, Jinghui Chen, Chenglin Miao, Han Liu, Ting Wang, Fenglong Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PAT:+Geometry-Aware+Hard-Label+Black-Box+Adversarial+Attacks+on+Text)|0|
|[Less is More: SlimG for Accurate, Robust, and Interpretable Graph Mining](https://doi.org/10.1145/3580305.3599413)|Jaemin Yoo, MengChieh Lee, Shubhranshu Shekhar, Christos Faloutsos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Less+is+More:+SlimG+for+Accurate,+Robust,+and+Interpretable+Graph+Mining)|0|
|[FLAMES2Graph: An Interpretable Federated Multivariate Time Series Classification Framework](https://doi.org/10.1145/3580305.3599354)|Raneen Younis, Zahra Ahmadi, Abdul Hakmeh, Marco Fisichella||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLAMES2Graph:+An+Interpretable+Federated+Multivariate+Time+Series+Classification+Framework)|0|
|[Towards Variance Reduction for Reinforcement Learning of Industrial Decision-making Tasks: A Bi-Critic based Demand-Constraint Decoupling Approach](https://doi.org/10.1145/3580305.3599527)|Jianyong Yuan, Jiayi Zhang, Zinuo Cai, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Variance+Reduction+for+Reinforcement+Learning+of+Industrial+Decision-making+Tasks:+A+Bi-Critic+based+Demand-Constraint+Decoupling+Approach)|0|
|[Spatio-temporal Diffusion Point Processes](https://doi.org/10.1145/3580305.3599511)|Yuan Yuan, Jingtao Ding, Chenyang Shao, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-temporal+Diffusion+Point+Processes)|0|
|[Hyperbolic Graph Topic Modeling Network with Continuously Updated Topic Tree](https://doi.org/10.1145/3580305.3599384)|Delvin Ce Zhang, Rex Ying, Hady W. Lauw||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperbolic+Graph+Topic+Modeling+Network+with+Continuously+Updated+Topic+Tree)|0|
|[Quantifying Node Importance over Network Structural Stability](https://doi.org/10.1145/3580305.3599480)|Fan Zhang, Qingyuan Linghu, Jiadong Xie, Kai Wang, Xuemin Lin, Wenjie Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+Node+Importance+over+Network+Structural+Stability)|0|
|[HiMacMic: Hierarchical Multi-Agent Deep Reinforcement Learning with Dynamic Asynchronous Macro Strategy](https://doi.org/10.1145/3580305.3599379)|Hancheng Zhang, Guozheng Li, Chi Harold Liu, Guoren Wang, Jian Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiMacMic:+Hierarchical+Multi-Agent+Deep+Reinforcement+Learning+with+Dynamic+Asynchronous+Macro+Strategy)|0|
|[A Study of Situational Reasoning for Traffic Understanding](https://doi.org/10.1145/3580305.3599246)|Jiarui Zhang, Filip Ilievski, Kaixin Ma, Aravinda Kollaa, Jonathan Francis, Alessandro Oltramari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Study+of+Situational+Reasoning+for+Traffic+Understanding)|0|
|[MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation](https://doi.org/10.1145/3580305.3599435)|Jiaxing Zhang, Dongsheng Luo, Hua Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MixupExplainer:+Generalizing+Explanations+for+Graph+Neural+Networks+with+Data+Augmentation)|0|
|[Warpformer: A Multi-scale Modeling Approach for Irregular Clinical Time Series](https://doi.org/10.1145/3580305.3599543)|Jiawen Zhang, Shun Zheng, Wei Cao, Jiang Bian, Jia Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Warpformer:+A+Multi-scale+Modeling+Approach+for+Irregular+Clinical+Time+Series)|0|
|[Navigating Alignment for Non-identical Client Class Sets: A Label Name-Anchored Federated Learning Framework](https://doi.org/10.1145/3580305.3599443)|Jiayun Zhang, Xiyuan Zhang, Xinyang Zhang, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Navigating+Alignment+for+Non-identical+Client+Class+Sets:+A+Label+Name-Anchored+Federated+Learning+Framework)|0|
|[DyTed: Disentangled Representation Learning for Discrete-time Dynamic Graph](https://doi.org/10.1145/3580305.3599319)|Kaike Zhang, Qi Cao, Gaolin Fang, Bingbing Xu, Hongjian Zou, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DyTed:+Disentangled+Representation+Learning+for+Discrete-time+Dynamic+Graph)|0|
|[Rumor Detection with Diverse Counterfactual Evidence](https://doi.org/10.1145/3580305.3599494)|Kaiwei Zhang, Junchi Yu, Haichao Shi, Jian Liang, XiaoYu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rumor+Detection+with+Diverse+Counterfactual+Evidence)|0|
|[Local Boosting for Weakly-Supervised Learning](https://doi.org/10.1145/3580305.3599417)|Rongzhi Zhang, Yue Yu, Jiaming Shen, Xiquan Cui, Chao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Local+Boosting+for+Weakly-Supervised+Learning)|0|
|[Capacity Constrained Influence Maximization in Social Networks](https://doi.org/10.1145/3580305.3599267)|Shiqi Zhang, Yiqian Huang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, Bo Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Capacity+Constrained+Influence+Maximization+in+Social+Networks)|0|
|[AdaProp: Learning Adaptive Propagation for Graph Neural Network based Knowledge Graph Reasoning](https://doi.org/10.1145/3580305.3599404)|Yongqi Zhang, Zhanke Zhou, Quanming Yao, Xiaowen Chu, Bo Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaProp:+Learning+Adaptive+Propagation+for+Graph+Neural+Network+based+Knowledge+Graph+Reasoning)|0|
|[Weakly Supervised Multi-Label Classification of Full-Text Scientific Papers](https://doi.org/10.1145/3580305.3599544)|Yu Zhang, Bowen Jin, Xiusi Chen, Yanzhen Shen, Yunyi Zhang, Yu Meng, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weakly+Supervised+Multi-Label+Classification+of+Full-Text+Scientific+Papers)|0|
|[DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend Forecasting](https://doi.org/10.1145/3580305.3599315)|Lifan Zhao, Shuming Kong, Yanyan Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DoubleAdapt:+A+Meta-learning+Approach+to+Incremental+Learning+for+Stock+Trend+Forecasting)|0|
|[Spatial Clustering Regression of Count Value Data via Bayesian Mixture of Finite Mixtures](https://doi.org/10.1145/3580305.3599509)|Peng Zhao, HouCheng Yang, Dipak K. Dey, Guanyu Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatial+Clustering+Regression+of+Count+Value+Data+via+Bayesian+Mixture+of+Finite+Mixtures)|0|
|[Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations](https://doi.org/10.1145/3580305.3599506)|Tianxiang Zhao, Wenchao Yu, Suhang Wang, Lu Wang, Xiang Zhang, Yuncong Chen, Yanchi Liu, Wei Cheng, Haifeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Skill+Disentanglement+for+Imitation+Learning+from+Suboptimal+Demonstrations)|0|
|[GraphGLOW: Universal and Generalizable Structure Learning for Graph Neural Networks](https://doi.org/10.1145/3580305.3599373)|Wentao Zhao, Qitian Wu, Chenxiao Yang, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphGLOW:+Universal+and+Generalizable+Structure+Learning+for+Graph+Neural+Networks)|0|
|[Generative Causal Interpretation Model for Spatio-Temporal Representation Learning](https://doi.org/10.1145/3580305.3599363)|Yu Zhao, Pan Deng, Junting Liu, Xiaofeng Jia, Jianwei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Causal+Interpretation+Model+for+Spatio-Temporal+Representation+Learning)|0|
|[Maintaining the Status Quo: Capturing Invariant Relations for OOD Spatiotemporal Learning](https://doi.org/10.1145/3580305.3599421)|Zhengyang Zhou, Qihe Huang, Kuo Yang, Kun Wang, Xu Wang, Yudong Zhang, Yuxuan Liang, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Maintaining+the+Status+Quo:+Capturing+Invariant+Relations+for+OOD+Spatiotemporal+Learning)|0|
|[Dual-view Molecular Pre-training](https://doi.org/10.1145/3580305.3599317)|Jinhua Zhu, Yingce Xia, Lijun Wu, Shufang Xie, Wengang Zhou, Tao Qin, Houqiang Li, TieYan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-view+Molecular+Pre-training)|0|
|[On Structural Expressive Power of Graph Transformers](https://doi.org/10.1145/3580305.3599451)|Wenhao Zhu, Tianyu Wen, Guojie Song, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Structural+Expressive+Power+of+Graph+Transformers)|0|
|[WinGNN: Dynamic Graph Neural Networks with Random Gradient Aggregation Window](https://doi.org/10.1145/3580305.3599551)|Yifan Zhu, Fangpeng Cong, Dan Zhang, Wenwen Gong, Qika Lin, Wenzheng Feng, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WinGNN:+Dynamic+Graph+Neural+Networks+with+Random+Gradient+Aggregation+Window)|0|
|[DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling](https://doi.org/10.1145/3580305.3599318)|Yuchen Zhuang, Yue Yu, Lingkai Kong, Xiang Chen, Chao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DyGen:+Learning+from+Noisy+Labels+via+Dynamics-Enhanced+Generative+Modeling)|0|
|[Learning to Solve Grouped 2D Bin Packing Problems in the Manufacturing Industry](https://doi.org/10.1145/3580305.3599860)|Wenxuan Ao, Guozhen Zhang, Yong Li, Depeng Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Solve+Grouped+2D+Bin+Packing+Problems+in+the+Manufacturing+Industry)|0|
|[Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive Text Summarization (TL;DR) of Scientific Contents](https://doi.org/10.1145/3580305.3599830)|Yash Kumar Atri, Vikram Goyal, Tanmoy Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fusing+Multimodal+Signals+on+Hyper-complex+Space+for+Extreme+Abstractive+Text+Summarization+(TL;DR)+of+Scientific+Contents)|0|
|[Web-Scale Academic Name Disambiguation: The WhoIsWho Benchmark, Leaderboard, and Toolkit](https://doi.org/10.1145/3580305.3599930)|Bo Chen, Jing Zhang, Fanjin Zhang, Tianyi Han, Yuqing Cheng, Xiaoyan Li, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Web-Scale+Academic+Name+Disambiguation:+The+WhoIsWho+Benchmark,+Leaderboard,+and+Toolkit)|0|
|[FS-REAL: Towards Real-World Cross-Device Federated Learning](https://doi.org/10.1145/3580305.3599829)|Daoyuan Chen, Dawei Gao, Yuexiang Xie, Xuchen Pan, Zitao Li, Yaliang Li, Bolin Ding, Jingren Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FS-REAL:+Towards+Real-World+Cross-Device+Federated+Learning)|0|
|[A Data-driven Region Generation Framework for Spatiotemporal Transportation Service Management](https://doi.org/10.1145/3580305.3599760)|Liyue Chen, Jiangyi Fang, Zhe Yu, Yongxin Tong, Shaosheng Cao, Leye Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Data-driven+Region+Generation+Framework+for+Spatiotemporal+Transportation+Service+Management)|0|
|[Binary Classifier Evaluation on Unlabeled Segments using Inverse Distance Weighting with Distance Learning](https://doi.org/10.1145/3580305.3599781)|Xu Chen, Katerina Marazopoulou, Wesley Lee, Christine Agarwal, Jason Sukumaran, Aude Hofleitner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Binary+Classifier+Evaluation+on+Unlabeled+Segments+using+Inverse+Distance+Weighting+with+Distance+Learning)|0|
|[Evolve Path Tracer: Early Detection of Malicious Addresses in Cryptocurrency](https://doi.org/10.1145/3580305.3599817)|Ling Cheng, Feida Zhu, Yong Wang, Ruicheng Liang, Huiwen Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evolve+Path+Tracer:+Early+Detection+of+Malicious+Addresses+in+Cryptocurrency)|0|
|[Conditional Neural ODE Processes for Individual Disease Progression Forecasting: A Case Study on COVID-19](https://doi.org/10.1145/3580305.3599792)|Ting Dang, Jing Han, Tong Xia, Erika Bondareva, Chloë SiegeleBrown, Jagmohan Chauhan, Andreas Grammenos, Dimitris Spathis, Pietro Cicuta, Cecilia Mascolo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conditional+Neural+ODE+Processes+for+Individual+Disease+Progression+Forecasting:+A+Case+Study+on+COVID-19)|0|
|[Time-to-Event Modeling with Hypernetwork based Hawkes Process](https://doi.org/10.1145/3580305.3599912)|Manisha Dubey, P. K. Srijith, Maunendra Sankar Desarkar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-to-Event+Modeling+with+Hypernetwork+based+Hawkes+Process)|0|
|[Discovering Novel Biological Traits From Images Using Phylogeny-Guided Neural Networks](https://doi.org/10.1145/3580305.3599808)|Mohannad Elhamod, Mridul Khurana, Harish Babu Manogaran, Josef C. Uyeda, Meghan A. Balk, Wasila M. Dahdul, Yasin Bakis, Henry L. Bart Jr., Paula M. Mabee, Hilmar Lapp, James P. Balhoff, Caleb Charpentier, David Carlyn, WeiLun Chao, Charles V. Stewart, Daniel I. Rubenstein, Tanya Y. BergerWolf, Anuj Karpatne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Novel+Biological+Traits+From+Images+Using+Phylogeny-Guided+Neural+Networks)|0|
|[Demystifying Fraudulent Transactions and Illicit Nodes in the Bitcoin Network for Financial Forensics](https://doi.org/10.1145/3580305.3599803)|Youssef Elmougy, Ling Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demystifying+Fraudulent+Transactions+and+Illicit+Nodes+in+the+Bitcoin+Network+for+Financial+Forensics)|0|
|[RecruitPro: A Pretrained Language Model with Skill-Aware Prompt Learning for Intelligent Recruitment](https://doi.org/10.1145/3580305.3599894)|Chuyu Fang, Chuan Qin, Qi Zhang, Kaichun Yao, Jingshuai Zhang, Hengshu Zhu, Fuzhen Zhuang, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecruitPro:+A+Pretrained+Language+Model+with+Skill-Aware+Prompt+Learning+for+Intelligent+Recruitment)|0|
|[A Lightweight, Efficient and Explainable-by-Design Convolutional Neural Network for Internet Traffic Classification](https://doi.org/10.1145/3580305.3599762)|Kevin Fauvel, Fuxing Chen, Dario Rossi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Lightweight,+Efficient+and+Explainable-by-Design+Convolutional+Neural+Network+for+Internet+Traffic+Classification)|0|
|[ILRoute: A Graph-based Imitation Learning Method to Unveil Riders' Routing Strategies in Food Delivery Service](https://doi.org/10.1145/3580305.3599844)|Tao Feng, Huan Yan, Huandong Wang, Wenzhen Huang, Yuyang Han, Hongsen Liao, Jinghua Hao, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ILRoute:+A+Graph-based+Imitation+Learning+Method+to+Unveil+Riders'+Routing+Strategies+in+Food+Delivery+Service)|0|
|[Influence Maximization with Fairness at Scale](https://doi.org/10.1145/3580305.3599847)|Yuting Feng, Ankitkumar Patel, Bogdan Cautis, Hossein Vahabi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Influence+Maximization+with+Fairness+at+Scale)|0|
|[Yggdrasil Decision Forests: A Fast and Extensible Decision Forests Library](https://doi.org/10.1145/3580305.3599933)|Mathieu GuillameBert, Sebastian Bruch, Richard Stotz, Jan Pfeifer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Yggdrasil+Decision+Forests:+A+Fast+and+Extensible+Decision+Forests+Library)|0|
|[Towards Equitable Assignment: Data-Driven Delivery Zone Partition at Last-mile Logistics](https://doi.org/10.1145/3580305.3599915)|Baoshen Guo, Shuai Wang, Haotian Wang, Yunhuai Liu, Fanshuo Kong, Desheng Zhang, Tian He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Equitable+Assignment:+Data-Driven+Delivery+Zone+Partition+at+Last-mile+Logistics)|0|
|[An Interpretable, Flexible, and Interactive Probabilistic Framework for Melody Generation](https://doi.org/10.1145/3580305.3599772)|Stephen Hahn, Rico Zhu, Simon Mak, Cynthia Rudin, Yue Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Interpretable,+Flexible,+and+Interactive+Probabilistic+Framework+for+Melody+Generation)|0|
|[Efficient Continuous Space Policy Optimization for High-frequency Trading](https://doi.org/10.1145/3580305.3599813)|Li Han, Nan Ding, Guoxuan Wang, Dawei Cheng, Yuqi Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Continuous+Space+Policy+Optimization+for+High-frequency+Trading)|0|
|[Expert Knowledge-Aware Image Difference Graph Representation Learning for Difference-Aware Medical Visual Question Answering](https://doi.org/10.1145/3580305.3599819)|Xinyue Hu, Lin Gu, Qiyuan An, Mengliang Zhang, Liangchen Liu, Kazuma Kobayashi, Tatsuya Harada, Ronald M. Summers, Yingying Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expert+Knowledge-Aware+Image+Difference+Graph+Representation+Learning+for+Difference-Aware+Medical+Visual+Question+Answering)|0|
|[Graph Learning in Physical-informed Mesh-reduced Space for Real-world Dynamic Systems](https://doi.org/10.1145/3580305.3599835)|Yeping Hu, Bo Lei, Victor M. Castillo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Learning+in+Physical-informed+Mesh-reduced+Space+for+Real-world+Dynamic+Systems)|0|
|[Multimodal Indoor Localisation in Parkinson's Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting](https://doi.org/10.1145/3580305.3599872)|Ferdian Jovan, Catherine Morgan, Ryan McConville, Emma L. Tonkin, Ian Craddock, Alan L. Whone||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Indoor+Localisation+in+Parkinson's+Disease+for+Detecting+Medication+Use:+Observational+Pilot+Study+in+a+Free-Living+Setting)|0|
|[Ball Trajectory Inference from Multi-Agent Sports Contexts Using Set Transformer and Hierarchical Bi-LSTM](https://doi.org/10.1145/3580305.3599779)|Hyunsung Kim, HanJun Choi, Chang Jo Kim, Jinsung Yoon, SangKi Ko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ball+Trajectory+Inference+from+Multi-Agent+Sports+Contexts+Using+Set+Transformer+and+Hierarchical+Bi-LSTM)|0|
|[Neural Insights for Digital Marketing Content Design](https://doi.org/10.1145/3580305.3599875)|Fanjie Kong, Yuan Li, Houssam Nassif, Tanner Fiez, Ricardo Henao, Shreya Chakrabarti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Insights+for+Digital+Marketing+Content+Design)|0|
|[Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment](https://doi.org/10.1145/3580305.3599896)|Atharva Kulkarni, Sarah Masud, Vikram Goyal, Tanmoy Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Hate+Speech+Benchmarks:+From+Data+Curation+to+System+Deployment)|0|
|[Towards Suicide Prevention from Bipolar Disorder with Temporal Symptom-Aware Multitask Learning](https://doi.org/10.1145/3580305.3599917)|Daeun Lee, Sejung Son, Hyolim Jeon, Seungbae Kim, Jinyoung Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Suicide+Prevention+from+Bipolar+Disorder+with+Temporal+Symptom-Aware+Multitask+Learning)|0|
|[Learning Slow and Fast System Dynamics via Automatic Separation of Time Scales](https://doi.org/10.1145/3580305.3599858)|Ruikun Li, Huandong Wang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Slow+and+Fast+System+Dynamics+via+Automatic+Separation+of+Time+Scales)|0|
|[Diga: Guided Diffusion Model for Graph Recovery in Anti-Money Laundering](https://doi.org/10.1145/3580305.3599806)|Xujia Li, Yuan Li, Xueying Mo, Hebing Xiao, Yanyan Shen, Lei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diga:+Guided+Diffusion+Model+for+Graph+Recovery+in+Anti-Money+Laundering)|0|
|[HardSATGEN: Understanding the Difficulty of Hard SAT Formula Generation and A Strong Structure-Hardness-Aware Baseline](https://doi.org/10.1145/3580305.3599837)|Yang Li, Xinyan Chen, Wenxuan Guo, Xijun Li, Wanqian Luo, Junhua Huang, HuiLing Zhen, Mingxuan Yuan, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HardSATGEN:+Understanding+the+Difficulty+of+Hard+SAT+Formula+Generation+and+A+Strong+Structure-Hardness-Aware+Baseline)|0|
|[Learning Joint Relational Co-evolution in Spatial-Temporal Knowledge Graph for SMEs Supply Chain Prediction](https://doi.org/10.1145/3580305.3599855)|Youru Li, Zhenfeng Zhu, Xiaobo Guo, Linxun Chen, Zhouyin Wang, Yinmeng Wang, Bing Han, Yao Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Joint+Relational+Co-evolution+in+Spatial-Temporal+Knowledge+Graph+for+SMEs+Supply+Chain+Prediction)|0|
|[Analysis of COVID-19 Offensive Tweets and Their Targets](https://doi.org/10.1145/3580305.3599773)|Song Liao, Ebuka Okpala, Long Cheng, Mingqi Li, Nishant Vishwamitra, Hongxin Hu, Feng Luo, Matthew Costello||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analysis+of+COVID-19+Offensive+Tweets+and+Their+Targets)|0|
|[Balancing Approach for Causal Inference at Scale](https://doi.org/10.1145/3580305.3599778)|Sicheng Lin, Meng Xu, Xi Zhang, ShihKang Chao, YingKai Huang, Xiaolin Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Approach+for+Causal+Inference+at+Scale)|0|
|[Uncertainty-Aware Probabilistic Travel Time Prediction for On-Demand Ride-Hailing at DiDi](https://doi.org/10.1145/3580305.3599925)|Hao Liu, Wenzhao Jiang, Shui Liu, Xi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty-Aware+Probabilistic+Travel+Time+Prediction+for+On-Demand+Ride-Hailing+at+DiDi)|0|
|[WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences](https://doi.org/10.1145/3580305.3599931)|Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WebGLM:+Towards+An+Efficient+Web-Enhanced+Question+Answering+System+with+Human+Preferences)|0|
|[Impact-Oriented Contextual Scholar Profiling using Self-Citation Graphs](https://doi.org/10.1145/3580305.3599845)|Yuankai Luo, Lei Shi, Mufan Xu, Yuwen Ji, Fengli Xiao, Chunming Hu, Zhiguang Shan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Impact-Oriented+Contextual+Scholar+Profiling+using+Self-Citation+Graphs)|0|
|[A Look into Causal Effects under Entangled Treatment in Graphs: Investigating the Impact of Contact on MRSA Infection](https://doi.org/10.1145/3580305.3599763)|Jing Ma, Chen Chen, Anil Vullikanti, Ritwick Mishra, Gregory Madden, Daniel Borrajo, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Look+into+Causal+Effects+under+Entangled+Treatment+in+Graphs:+Investigating+the+Impact+of+Contact+on+MRSA+Infection)|0|
|[SAInf: Stay Area Inference of Vehicles using Surveillance Camera Records](https://doi.org/10.1145/3580305.3599952)|Zhipeng Ma, Chuishi Meng, Huimin Ren, Sijie Ruan, Jie Bao, Xiaoting Wang, Tianrui Li, Yu Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAInf:+Stay+Area+Inference+of+Vehicles+using+Surveillance+Camera+Records)|0|
|[Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network](https://doi.org/10.1145/3580305.3599804)|Jinzhu Mao, Liu Cao, Chen Gao, Huandong Wang, Hangyu Fan, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Vulnerable+Nodes+in+Urban+Infrastructure+Interdependent+Network)|0|
|[DRL4Route: A Deep Reinforcement Learning Framework for Pick-up and Delivery Route Prediction](https://doi.org/10.1145/3580305.3599811)|Xiaowei Mao, Haomin Wen, Hengrui Zhang, Huaiyu Wan, Lixia Wu, Jianbin Zheng, Haoyuan Hu, Youfang Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DRL4Route:+A+Deep+Reinforcement+Learning+Framework+for+Pick-up+and+Delivery+Route+Prediction)|0|
|[Deep Offline Reinforcement Learning for Real-world Treatment Optimization Applications](https://doi.org/10.1145/3580305.3599800)|Mila Nambiar, Supriyo Ghosh, Priscilla Ong, Yu En Chan, Yong Mong Bee, Pavitra Krishnaswamy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Offline+Reinforcement+Learning+for+Real-world+Treatment+Optimization+Applications)|0|
|[Rewiring Police Officer Training Networks to Reduce Forecasted Use of Force](https://doi.org/10.1145/3580305.3599899)|Ritika Pandey, Jeremy G. Carter, James Hill, George O. Mohler||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rewiring+Police+Officer+Training+Networks+to+Reduce+Forecasted+Use+of+Force)|0|
|[Extreme Multi-Label Classification for Ad Targeting using Factorization Machines](https://doi.org/10.1145/3580305.3599822)|Martin Pavlovski, Srinath Ravindran, Djordje Gligorijevic, Shubham Agrawal, Ivan Stojkovic, Nelson SeguraNunez, Jelena Gligorijevic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extreme+Multi-Label+Classification+for+Ad+Targeting+using+Factorization+Machines)|0|
|[un-xPass: Measuring Soccer Player's Creativity](https://doi.org/10.1145/3580305.3599924)|Pieter Robberechts, Maaike Van Roy, Jesse Davis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=un-xPass:+Measuring+Soccer+Player's+Creativity)|0|
|[QTNet: Theory-based Queue Length Prediction for Urban Traffic](https://doi.org/10.1145/3580305.3599890)|Ryu Shirakami, Toshiya Kitahara, Koh Takeuchi, Hisashi Kashima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QTNet:+Theory-based+Queue+Length+Prediction+for+Urban+Traffic)|0|
|[Deep Transfer Learning for City-scale Cellular Traffic Generation through Urban Knowledge Graph](https://doi.org/10.1145/3580305.3599801)|Shiyuan Zhang, Tong Li, Shuodi Hui, Guangyu Li, Yanping Liang, Li Yu, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Transfer+Learning+for+City-scale+Cellular+Traffic+Generation+through+Urban+Knowledge+Graph)|0|
|[Hierarchical Reinforcement Learning for Dynamic Autonomous Vehicle Navigation at Intelligent Intersections](https://doi.org/10.1145/3580305.3599839)|Qian Sun, Le Zhang, Huan Yu, Weijia Zhang, Yu Mei, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Reinforcement+Learning+for+Dynamic+Autonomous+Vehicle+Navigation+at+Intelligent+Intersections)|0|
|[TrustGeo: Uncertainty-Aware Dynamic Graph Learning for Trustworthy IP Geolocation](https://doi.org/10.1145/3580305.3599920)|Wenxin Tai, Bin Chen, Fan Zhou, Ting Zhong, Goce Trajcevski, Yong Wang, Kai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrustGeo:+Uncertainty-Aware+Dynamic+Graph+Learning+for+Trustworthy+IP+Geolocation)|0|
|[Automatic Music Playlist Generation via Simulation-based Reinforcement Learning](https://doi.org/10.1145/3580305.3599777)|Federico Tomasi, Joseph Cauteruccio, Surya Kanoria, Kamil Ciosek, Matteo Rinaldi, Zhenwen Dai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Music+Playlist+Generation+via+Simulation-based+Reinforcement+Learning)|0|
|[Stabilising Job Survival Analysis for Disability Employment Services in Unseen Environments](https://doi.org/10.1145/3580305.3599908)|Ha Xuan Tran, Thuc Duy Le, Jiuyong Li, Lin Liu, Xiaomei Li, Jixue Liu, Tony Waters||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stabilising+Job+Survival+Analysis+for+Disability+Employment+Services+in+Unseen+Environments)|0|
|[Fair Multilingual Vandalism Detection System for Wikipedia](https://doi.org/10.1145/3580305.3599823)|Mykola Trokhymovych, Muniza Aslam, AiJou Chou, Ricardo BaezaYates, Diego SáezTrumper||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Multilingual+Vandalism+Detection+System+for+Wikipedia)|0|
|[Auto-Validate by-History: Auto-Program Data Quality Constraints to Validate Recurring Data Pipelines](https://doi.org/10.1145/3580305.3599776)|Dezhan Tu, Yeye He, Weiwei Cui, Song Ge, Haidong Zhang, Shi Han, Dongmei Zhang, Surajit Chaudhuri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Auto-Validate+by-History:+Auto-Program+Data+Quality+Constraints+to+Validate+Recurring+Data+Pipelines)|0|
|[The Missing Indicator Method: From Low to High Dimensions](https://doi.org/10.1145/3580305.3599911)|Mike Van Ness, Tomas M. Bosschieter, Roberto HalpinGregorio, Madeleine Udell||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Missing+Indicator+Method:+From+Low+to+High+Dimensions)|0|
|[Interdependent Causal Networks for Root Cause Localization](https://doi.org/10.1145/3580305.3599849)|Dongjie Wang, Zhengzhang Chen, Jingchao Ni, Liang Tong, Zheng Wang, Yanjie Fu, Haifeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interdependent+Causal+Networks+for+Root+Cause+Localization)|0|
|[Learning to Discover Various Simpson's Paradoxes](https://doi.org/10.1145/3580305.3599859)|Jingwei Wang, Jianshan He, Weidi Xu, Ruopeng Li, Wei Chu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Discover+Various+Simpson's+Paradoxes)|0|
|[Removing Camouflage and Revealing Collusion: Leveraging Gang-crime Pattern in Fraudster Detection](https://doi.org/10.1145/3580305.3599895)|Lewen Wang, Haozhe Zhao, Cunguang Feng, Weiqing Liu, Congrui Huang, Marco Santoni, Manuel Cristofaro, Paola Jafrancesco, Jiang Bian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Removing+Camouflage+and+Revealing+Collusion:+Leveraging+Gang-crime+Pattern+in+Fraudster+Detection)|0|
|[ShuttleSet: A Human-Annotated Stroke-Level Singles Dataset for Badminton Tactical Analysis](https://doi.org/10.1145/3580305.3599906)|WeiYao Wang, YungChang Huang, TsiUi Ik, WenChih Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ShuttleSet:+A+Human-Annotated+Stroke-Level+Singles+Dataset+for+Badminton+Tactical+Analysis)|0|
|[VRDU: A Benchmark for Visually-rich Document Understanding](https://doi.org/10.1145/3580305.3599929)|Zilong Wang, Yichao Zhou, Wei Wei, ChenYu Lee, Sandeep Tata||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VRDU:+A+Benchmark+for+Visually-rich+Document+Understanding)|0|
|[DNet: Distributional Network for Distributional Individualized Treatment Effects](https://doi.org/10.1145/3580305.3599809)|Guojun Wu, Ge Song, Xiaoxiang Lv, Shikai Luo, Chengchun Shi, Hongtu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DNet:+Distributional+Network+for+Distributional+Individualized+Treatment+Effects)|0|
|[A Predict-Then-Optimize Couriers Allocation Framework for Emergency Last-mile Logistics](https://doi.org/10.1145/3580305.3599766)|Kaiwen Xia, Li Lin, Shuai Wang, Haotian Wang, Desheng Zhang, Tian He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Predict-Then-Optimize+Couriers+Allocation+Framework+for+Emergency+Last-mile+Logistics)|0|
|[Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help Multiple Graph Applications](https://doi.org/10.1145/3580305.3599833)|Han Xie, Da Zheng, Jun Ma, Houyu Zhang, Vassilis N. Ioannidis, Xiang Song, Qing Ping, Sheng Wang, Carl Yang, Yi Xu, Belinda Zeng, Trishul Chilimbi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-Aware+Language+Model+Pre-Training+on+a+Large+Graph+Corpus+Can+Help+Multiple+Graph+Applications)|0|
|[NEON: Living Needs Prediction System in Meituan](https://doi.org/10.1145/3580305.3599874)|Xiaochong Lan, Chen Gao, Shiqi Wen, Xiuqi Chen, Yingge Che, Han Zhang, Huazhou Wei, Hengliang Luo, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NEON:+Living+Needs+Prediction+System+in+Meituan)|0|
|[AlerTiger: Deep Learning for AI Model Health Monitoring at LinkedIn](https://doi.org/10.1145/3580305.3599802)|Zhentao Xu, Ruoying Wang, Girish Balaji, Manas Bundele, XiaoFei Liu, Leo Liu, Tie Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AlerTiger:+Deep+Learning+for+AI+Model+Health+Monitoring+at+LinkedIn)|0|
|[Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation](https://doi.org/10.1145/3580305.3599774)|Bing Xue, Ahmed Sameh Said, Ziqi Xu, Hanyang Liu, Neel Shah, Hanqing Yang, Philip R. O. Payne, Chenyang Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assisting+Clinical+Decisions+for+Scarcely+Available+Treatment+via+Disentangled+Latent+Representation)|0|
|[Contextual Self-attentive Temporal Point Process for Physical Decommissioning Prediction of Cloud Assets](https://doi.org/10.1145/3580305.3599794)|Fangkai Yang, Jue Zhang, Lu Wang, Bo Qiao, Di Weng, Xiaoting Qin, Gregory Weber, Durgesh Nandini Das, Srinivasan Rakhunathan, Ranganathan Srikanth, Qingwei Lin, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contextual+Self-attentive+Temporal+Point+Process+for+Physical+Decommissioning+Prediction+of+Cloud+Assets)|0|
|[From Labels to Decisions: A Mapping-Aware Annotator Model](https://doi.org/10.1145/3580305.3599828)|Evan Yao, Jagdish Ramakrishnan, Xu Chen, VietAn Nguyen, Udi Weinsberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Labels+to+Decisions:+A+Mapping-Aware+Annotator+Model)|0|
|[M3PT: A Multi-Modal Model for POI Tagging](https://doi.org/10.1145/3580305.3599862)|Jingsong Yang, Guanzhou Han, Deqing Yang, Jingping Liu, Yanghua Xiao, Xiang Xu, Baohua Wu, Shenghua Ni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M3PT:+A+Multi-Modal+Model+for+POI+Tagging)|0|
|[Self-supervised Classification of Clinical Multivariate Time Series using Time Series Dynamics](https://doi.org/10.1145/3580305.3599954)|Yakir Yehuda, Daniel Freedman, Kira Radinsky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+Classification+of+Clinical+Multivariate+Time+Series+using+Time+Series+Dynamics)|0|
|[DGI: An Easy and Efficient Framework for GNN Model Evaluation](https://doi.org/10.1145/3580305.3599805)|Peiqi Yin, Xiao Yan, Jinjing Zhou, Qiang Fu, Zhenkun Cai, James Cheng, Bo Tang, Minjie Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DGI:+An+Easy+and+Efficient+Framework+for+GNN+Model+Evaluation)|0|
|[Learning Multivariate Hawkes Process via Graph Recurrent Neural Network](https://doi.org/10.1145/3580305.3599857)|Kanghoon Yoon, Youngjun Im, Jingyu Choi, Taehwan Jeong, Jinkyoo Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Multivariate+Hawkes+Process+via+Graph+Recurrent+Neural+Network)|0|
|[Generating Synergistic Formulaic Alpha Collections via Reinforcement Learning](https://doi.org/10.1145/3580305.3599831)|Shuo Yu, Hongyan Xue, Xiang Ao, Feiyang Pan, Jia He, Dandan Tu, Qing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Synergistic+Formulaic+Alpha+Collections+via+Reinforcement+Learning)|0|
|[LibAUC: A Deep Learning Library for X-Risk Optimization](https://doi.org/10.1145/3580305.3599861)|Zhuoning Yuan, Dixian Zhu, ZiHao Qiu, Gang Li, Xuanhui Wang, Tianbao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LibAUC:+A+Deep+Learning+Library+for+X-Risk+Optimization)|0|
|[Towards a Generic Framework for Mechanism-guided Deep Learning for Manufacturing Applications](https://doi.org/10.1145/3580305.3599913)|Hanbo Zhang, Jiangxin Li, Shen Liang, Peng Wang, Themis Palpanas, Chen Wang, Wei Wang, Haoxuan Zhou, Jianwei Song, Wen Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Generic+Framework+for+Mechanism-guided+Deep+Learning+for+Manufacturing+Applications)|0|
|[GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue Generation](https://doi.org/10.1145/3580305.3599832)|Jing Zhang, Xiaokang Zhang, Daniel ZhangLi, Jifan Yu, Zijun Yao, Zeyao Ma, Yiqi Xu, Haohua Wang, Xiaohan Zhang, Nianyi Lin, Sunrui Lu, Juanzi Li, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GLM-Dialog:+Noise-tolerant+Pre-training+for+Knowledge-grounded+Dialogue+Generation)|0|
|[Robust Multimodal Failure Detection for Microservice Systems](https://doi.org/10.1145/3580305.3599902)|Chenyu Zhao, Minghua Ma, Zhenyu Zhong, Shenglin Zhang, Zhiyuan Tan, Xiao Xiong, LuLu Yu, Jiayi Feng, Yongqian Sun, Yuzhi Zhang, Dan Pei, Qingwei Lin, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Multimodal+Failure+Detection+for+Microservice+Systems)|0|
|[CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X](https://doi.org/10.1145/3580305.3599790)|Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Lei Shen, Zihan Wang, Andi Wang, Yang Li, Teng Su, Zhilin Yang, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CodeGeeX:+A+Pre-Trained+Model+for+Code+Generation+with+Multilingual+Benchmarking+on+HumanEval-X)|0|
|[MIDLG: Mutual Information based Dual Level GNN for Transaction Fraud Complaint Verification](https://doi.org/10.1145/3580305.3599865)|Wen Zheng, Bingbing Xu, Emiao Lu, Yang Li, Qi Cao, Xuan Zong, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MIDLG:+Mutual+Information+based+Dual+Level+GNN+for+Transaction+Fraud+Complaint+Verification)|0|
|[Road Planning for Slums via Deep Reinforcement Learning](https://doi.org/10.1145/3580305.3599901)|Yu Zheng, Hongyuan Su, Jingtao Ding, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Road+Planning+for+Slums+via+Deep+Reinforcement+Learning)|0|
|[AI Explainability 360 Toolkit for Time-Series and Industrial Use Cases](https://doi.org/10.1145/3580305.3599182)|Giridhar Ganapavarapu, Sumanta Mukherjee, Natalia Martinez Gil, Kanthi K. Sarpatwar, Amaresh Rajasekharan, Amit Dhurandhar, Vijay Arya, Roman Vaculín||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+Explainability+360+Toolkit+for+Time-Series+and+Industrial+Use+Cases)|0|
|[Hands-on Tutorial: "Explanations in AI: Methods, Stakeholders and Pitfalls"](https://doi.org/10.1145/3580305.3599181)|Mia C. Mayer, Muhammad Bilal Zafar, Luca Franceschi, Huzefa Rangwala||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hands-on+Tutorial:+"Explanations+in+AI:+Methods,+Stakeholders+and+Pitfalls")|0|
|[Graph Neural Networks in TensorFlow](https://doi.org/10.1145/3580305.3599177)|Bryan Perozzi, Sami AbuElHaija, Anton Tsitsulin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks+in+TensorFlow)|0|
|[PyHealth: A Deep Learning Toolkit for Healthcare Applications](https://doi.org/10.1145/3580305.3599178)|Chaoqi Yang, Zhenbang Wu, Patrick Jiang, Zhen Lin, Junyi Gao, Benjamin P. Danek, Jimeng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PyHealth:+A+Deep+Learning+Toolkit+for+Healthcare+Applications)|0|
|[GraphStorm an Easy-to-use and Scalable Graph Neural Network Framework: From Beginners to Heroes](https://doi.org/10.1145/3580305.3599179)|Jian Zhang, Da Zheng, Xiang Song, Theodore Vasiloudis, Israt Nisa, Jim Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphStorm+an+Easy-to-use+and+Scalable+Graph+Neural+Network+Framework:+From+Beginners+to+Heroes)|0|
|[Towards Next-Generation Intelligent Assistants Leveraging LLM Techniques](https://doi.org/10.1145/3580305.3599572)|Xin Luna Dong, Seungwhan Moon, Yifan Ethan Xu, Kshitiz Malik, Zhou Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Next-Generation+Intelligent+Assistants+Leveraging+LLM+Techniques)|0|
|[XAI for Predictive Maintenance](https://doi.org/10.1145/3580305.3599578)|João Gama, Slawomir Nowaczyk, Sepideh Pashami, Rita P. Ribeiro, Grzegorz J. Nalepa, Bruno Veloso||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XAI+for+Predictive+Maintenance)|0|
|[Distributed Optimization for Big Data Analytics: Beyond Minimization](https://doi.org/10.1145/3580305.3599554)|Hongchang Gao, Xinwen Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Optimization+for+Big+Data+Analytics:+Beyond+Minimization)|0|
|[Privacy in Advertising: Analytics and Modeling](https://doi.org/10.1145/3580305.3599570)|Badih Ghazi, Ravi Kumar, Pasin Manurangsi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy+in+Advertising:+Analytics+and+Modeling)|0|
|[Causal Discovery from Temporal Data](https://doi.org/10.1145/3580305.3599552)|Chang Gong, Di Yao, Chuzhe Zhang, Wenbin Li, Jingping Bi, Lun Du, Jin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Discovery+from+Temporal+Data)|0|
|[Generative AI meets Responsible AI: Practical Challenges and Opportunities](https://doi.org/10.1145/3580305.3599557)|Krishnaram Kenthapadi, Himabindu Lakkaraju, Nazneen Rajani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+meets+Responsible+AI:+Practical+Challenges+and+Opportunities)|0|
|[Getting an h-Index of 100 in 20 Years or Less!](https://doi.org/10.1145/3580305.3599558)|Eamonn Keogh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Getting+an+h-Index+of+100+in+20+Years+or+Less!)|0|
|[Uncertainty Quantification in Deep Learning](https://doi.org/10.1145/3580305.3599577)|Lingkai Kong, Harshavardhan Kamarthi, Peng Chen, B. Aditya Prakash, Chao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty+Quantification+in+Deep+Learning)|0|
|[Mining of Real-world Hypergraphs: Patterns, Tools, and Generators](https://doi.org/10.1145/3580305.3599567)|Geon Lee, Jaemin Yoo, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+of+Real-world+Hypergraphs:+Patterns,+Tools,+and+Generators)|0|
|[Knowledge Graph Reasoning and Its Applications](https://doi.org/10.1145/3580305.3599564)|Lihui Liu, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Reasoning+and+Its+Applications)|0|
|[Fast Text Generation with Text-Editing Models](https://doi.org/10.1145/3580305.3599579)|Eric Malmi, Yue Dong, Jonathan Mallinson, Aleksandr Chuklin, Jakub Adámek, Daniil Mirylenka, Felix Stahlberg, Sebastian Krause, Shankar Kumar, Aliaksei Severyn||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Text+Generation+with+Text-Editing+Models)|0|
|[Pretrained Language Representations for Text Understanding: A Weakly-Supervised Perspective](https://doi.org/10.1145/3580305.3599569)|Yu Meng, Jiaxin Huang, Yu Zhang, Yunyi Zhang, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pretrained+Language+Representations+for+Text+Understanding:+A+Weakly-Supervised+Perspective)|0|
|[Precision Health in the Age of Large Language Models](https://doi.org/10.1145/3580305.3599568)|Hoifung Poon, Tristan Naumann, Sheng Zhang, Javier González Hernández||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Precision+Health+in+the+Age+of+Large+Language+Models)|0|
|[Trustworthy Transfer Learning: Transferability and Trustworthiness](https://doi.org/10.1145/3580305.3599576)|Jun Wu, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trustworthy+Transfer+Learning:+Transferability+and+Trustworthiness)|0|
|[Graph Neural Networks: Foundation, Frontiers and Applications](https://doi.org/10.1145/3580305.3599560)|Lingfei Wu, Peng Cui, Jian Pei, Liang Zhao, Xiaojie Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks:+Foundation,+Frontiers+and+Applications)|0|
|[Graph and Geometry Generative Modeling for Drug Discovery](https://doi.org/10.1145/3580305.3599559)|Minkai Xu, Meng Liu, Wengong Jin, Shuiwang Ji, Jure Leskovec, Stefano Ermon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+and+Geometry+Generative+Modeling+for+Drug+Discovery)|0|
|[Data-centric AI: Techniques and Future Perspectives](https://doi.org/10.1145/3580305.3599553)|Daochen Zha, KweiHerng Lai, Fan Yang, Na Zou, Huiji Gao, Xia Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data-centric+AI:+Techniques+and+Future+Perspectives)|0|
|[Hyperbolic Graph Neural Networks: A Tutorial on Methods and Applications](https://doi.org/10.1145/3580305.3599562)|Min Zhou, Menglin Yang, Bo Xiong, Hui Xiong, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperbolic+Graph+Neural+Networks:+A+Tutorial+on+Methods+and+Applications)|0|
|[Fragile Earth: AI for Climate Sustainability - From Wildfire Disaster Management to Public Health and Beyond](https://doi.org/10.1145/3580305.3599217)|Naoki Abe, Kathleen Buckingham, Yuzhou Chen, Bistra Dilkina, Emre Eftelioglu, Auroop R. Ganguly, Yulia R. Gel, James Hodson, Ramakrishnan Kannan, Huikyo Lee, Jiafu Mao, Rose Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragile+Earth:+AI+for+Climate+Sustainability+-+From+Wildfire+Disaster+Management+to+Public+Health+and+Beyond)|0|
|[AdKDD 2023](https://doi.org/10.1145/3580305.3599582)|Abraham Bagherjeiran, Nemanja Djuric, KuangChih Lee, Linsey Pang, Vladan Radosavljevic, Suju Rajan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdKDD+2023)|0|
|[Robust NLP for Finance (RobustFin)](https://doi.org/10.1145/3580305.3599211)|Sameena Shah, Xiaodan Zhu, Gerard de Melo, Armineh Nourbakhsh, Xiaomo Liu, Zhiqiang Ma, Charese Smiley, Zhiyu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+NLP+for+Finance+(RobustFin))|0|
|[From Innovation to Scale (I2S) - Discuss and Learn How to Successfully Build, Commercialize, and Scale AI Innovations in Challenging Market Conditions](https://doi.org/10.1145/3580305.3599580)|Ankur M. Teredesai, Michael Zeller, Shenghua Bao, Wee Hyong Tok, Linsey Pang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Innovation+to+Scale+(I2S)+-+Discuss+and+Learn+How+to+Successfully+Build,+Commercialize,+and+Scale+AI+Innovations+in+Challenging+Market+Conditions)|0|
|[Deep Learning on Graphs: Methods and Applications (DLG-KDD2023)](https://doi.org/10.1145/3580305.3599207)|Lingfei Wu, Jian Pei, Jiliang Tang, Yinglong Xia, Xiaojie Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning+on+Graphs:+Methods+and+Applications+(DLG-KDD2023))|0|
|[Scenario-Adaptive Feature Interaction for Click-Through Rate Prediction](https://doi.org/10.1145/3580305.3599936)|Erxue Min, Da Luo, Kangyi Lin, Chunzhen Huang, Yang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scenario-Adaptive+Feature+Interaction+for+Click-Through+Rate+Prediction)|-1|
|[Sequential Learning Algorithms for Contextual Model-Free Influence Maximization](https://doi.org/10.1145/3580305.3599498)|Alexandra Iacob, Bogdan Cautis, Silviu Maniu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential+Learning+Algorithms+for+Contextual+Model-Free+Influence+Maximization)|-1|
|[LightToken: A Task and Model-agnostic Lightweight Token Embedding Framework for Pre-trained Language Models](https://doi.org/10.1145/3580305.3599416)|Haoyu Wang, Ruirui Li, Haoming Jiang, Zhengyang Wang, Xianfeng Tang, Bin Bi, Monica Xiao Cheng, Bing Yin, Yaqing Wang, Tuo Zhao, Jing Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LightToken:+A+Task+and+Model-agnostic+Lightweight+Token+Embedding+Framework+for+Pre-trained+Language+Models)|-1|
|[Automatic Temporal Relation in Multi-Task Learning](https://doi.org/10.1145/3580305.3599261)|Menghui Zhou, Po Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Temporal+Relation+in+Multi-Task+Learning)|-1|
|[Empowering General-purpose User Representation with Full-life Cycle Behavior Modeling](https://doi.org/10.1145/3580305.3599331)|Bei Yang, Jie Gu, Ke Liu, Xiaoxiao Xu, Renjun Xu, Qinghui Sun, Hong Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+General-purpose+User+Representation+with+Full-life+Cycle+Behavior+Modeling)|-1|
|[Towards Understanding and Enhancing Robustness of Deep Learning Models against Malicious Unlearning Attacks](https://doi.org/10.1145/3580305.3599526)|Wei Qian, Chenxu Zhao, Wei Le, Meiyi Ma, Mengdi Huai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Understanding+and+Enhancing+Robustness+of+Deep+Learning+Models+against+Malicious+Unlearning+Attacks)|-1|
|[Virtual Node Tuning for Few-shot Node Classification](https://doi.org/10.1145/3580305.3599541)|Zhen Tan, Ruocheng Guo, Kaize Ding, Huan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Virtual+Node+Tuning+for+Few-shot+Node+Classification)|-1|
|[Select and Trade: Towards Unified Pair Trading with Hierarchical Reinforcement Learning](https://doi.org/10.1145/3580305.3599951)|Weiguang Han, Boyi Zhang, Qianqian Xie, Min Peng, Yanzhao Lai, Jimin Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Select+and+Trade:+Towards+Unified+Pair+Trading+with+Hierarchical+Reinforcement+Learning)|-1|
