# KDD2024 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[On the Convergence of Zeroth-Order Federated Tuning for Large Language Models](https://doi.org/10.1145/3637528.3671865)|Zhenqing Ling, Daoyuan Chen, Liuyi Yao, Yaliang Li, Ying Shen|Alibaba Group, Bellevue, Washington, USA; Sun Yat-sen University & Pazhou Lab, Shenzhen, Guangdong, China; Alibaba Group, Hangzhou, Zhejiang, China; Sun Yat-sen University, Shenzhen, Guangdong, China|The confluence of Federated Learning (FL) and Large Language Models (LLMs) isushering in a new era in privacy-preserving natural language processing.However, the intensive memory requirements for fine-tuning LLMs posesignificant challenges, especially when deploying on clients with limitedcomputational resources. To circumvent this, we explore the novel integrationof Memory-efficient Zeroth-Order Optimization within a federated setting, asynergy we term as FedMeZO. Our study is the first to examine the theoreticalunderpinnings of FedMeZO in the context of LLMs, tackling key questionsregarding the influence of large parameter spaces on optimization behavior, theestablishment of convergence properties, and the identification of criticalparameters for convergence to inform personalized federated strategies. Ourextensive empirical evidence supports the theory, showing that FedMeZO not onlyconverges faster than traditional first-order methods such as FedAvg but alsosignificantly reduces GPU memory usage during training to levels comparable tothose during inference. Moreover, the proposed personalized FL strategy that isbuilt upon the theoretical insights to customize the client-wise learning ratecan effectively accelerate loss reduction. We hope our work can help to bridgetheoretical and practical aspects of federated fine-tuning for LLMs, therebystimulating further advancements and research in this area.|联邦学习(FL)和大语言模型(LLM)的融合开创了保护隐私的自然语言处理的新纪元。然而，微调 LLM 所需的大量内存带来了巨大的挑战，特别是在部署到计算资源有限的客户机上时。为了规避这个问题，我们探索了一种新的集成内存高效的零阶优化在一个联邦设置，我们称之为 FedMeZO 的不协调。我们的研究首次在 LLM 的背景下检验了 FedMeZO 的理论基础，解决了大参数空间对优化行为的影响，建立收敛性质，以及识别收敛的关键参数以通知个性化的联邦策略等关键问题。我们广泛的经验证明支持这一理论，表明 FedmeZO 不仅比传统的一阶方法(如 FedAvg)收敛得更快，而且在训练过程中显著降低了 GPU 内存的使用，与推理过程中的使用水平相当。此外，提出的个性化 FL 策略是建立在理论的洞察力，定制客户明智的学习率，可以有效地加速减少损失。我们希望我们的工作能够有助于联合微调 LLM 的理论和实践方面的桥梁，从而促进该领域的进一步发展和研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Convergence+of+Zeroth-Order+Federated+Tuning+for+Large+Language+Models)|2|
|[LLM4DyG: Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs?](https://doi.org/10.1145/3637528.3671709)|Zeyang Zhang, Xin Wang, Ziwei Zhang, Haoyang Li, Yijian Qin, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM4DyG:+Can+Large+Language+Models+Solve+Spatial-Temporal+Problems+on+Dynamic+Graphs?)|2|
|[FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning](https://doi.org/10.1145/3637528.3671573)|Weirui Kuang, Bingchen Qian, Zitao Li, Daoyuan Chen, Dawei Gao, Xuchen Pan, Yuexiang Xie, Yaliang Li, Bolin Ding, Jingren Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FederatedScope-LLM:+A+Comprehensive+Package+for+Fine-tuning+Large+Language+Models+in+Federated+Learning)|2|
|[Ads Recommendation in a Collapsed and Entangled World](https://doi.org/10.1145/3637528.3671607)|Junwei Pan, Wei Xue, Ximei Wang, Haibin Yu, Xun Liu, Shijie Quan, Xueming Qiu, Dapeng Liu, Lei Xiao, Jie Jiang|Tencent Inc., Shenzhen, China|We present Tencent's ads recommendation system and examine the challenges and practices of learning appropriate recommendation representations. Our study begins by showcasing our approaches to preserving prior knowledge when encoding features of diverse types into embedding representations. We specifically address sequence features, numeric features, and pre-trained embedding features. Subsequently, we delve into two crucial challenges related to feature representation: the dimensional collapse of embeddings and the interest entanglement across different tasks or scenarios. We propose several practical approaches to address these challenges that result in robust and disentangled recommendation representations. We then explore several training techniques to facilitate model optimization, reduce bias, and enhance exploration. Additionally, we introduce three analysis tools that enable us to study feature correlation, dimensional collapse, and interest entanglement. This work builds upon the continuous efforts of Tencent's ads recommendation team over the past decade. It summarizes general design principles and presents a series of readily applicable solutions and analysis tools. The reported performance is based on our online advertising platform, which handles hundreds of billions of requests daily and serves millions of ads to billions of users.|我们将介绍腾讯的广告推荐系统，并探讨学习适当的推荐表达的挑战和实践。我们的研究首先展示了我们在将不同类型的特征编码到嵌入表示中时保留先验知识的方法。我们专门讨论序列特征、数字特征和预先训练的嵌入特征。随后，我们深入研究了与特征表示相关的两个关键挑战: 嵌入的维度崩溃和不同任务或场景之间的兴趣纠缠。我们提出了几个实用的方法来解决这些挑战，导致健壮的和分离的建议表示。然后，我们探讨了几种训练技术，以促进模型优化，减少偏差，并加强探索。此外，我们还介绍了三种分析工具，使我们能够研究特征相关性、维度折叠和利益纠缠。这项工作建立在腾讯广告推荐团队过去十年不断努力的基础上。它总结了一般的设计原则，并提出了一系列容易适用的解决方案和分析工具。报告的性能是基于我们的在线广告平台，该平台每天处理数千亿个请求，为数十亿用户提供数百万个广告。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ads+Recommendation+in+a+Collapsed+and+Entangled+World)|1|
|[EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration](https://doi.org/10.1145/3637528.3671775)|Ye Wang, Jiahao Xun, Minjie Hong, Jieming Zhu, Tao Jin, Wang Lin, Haoyuan Li, Linjun Li, Yan Xia, Zhou Zhao, Zhenhua Dong|Zhejiang University, Hangzhou, China; Huawei Noah's Ark Lab, Shenzhen, China; Zhejiang University, Hangzhou, Zhejiang, China|Generative retrieval has recently emerged as a promising approach to sequential recommendation, framing candidate item retrieval as an autoregressive sequence generation problem. However, existing generative methods typically focus solely on either behavioral or semantic aspects of item information, neglecting their complementary nature and thus resulting in limited effectiveness. To address this limitation, we introduce EAGER, a novel generative recommendation framework that seamlessly integrates both behavioral and semantic information. Specifically, we identify three key challenges in combining these two types of information: a unified generative architecture capable of handling two feature types, ensuring sufficient and independent learning for each type, and fostering subtle interactions that enhance collaborative information utilization. To achieve these goals, we propose (1) a two-stream generation architecture leveraging a shared encoder and two separate decoders to decode behavior tokens and semantic tokens with a confidence-based ranking strategy; (2) a global contrastive task with summary tokens to achieve discriminative decoding for each type of information; and (3) a semantic-guided transfer task designed to implicitly promote cross-interactions through reconstruction and estimation objectives. We validate the effectiveness of EAGER on four public benchmarks, demonstrating its superior performance compared to existing methods. Our source code will be publicly available on PapersWithCode.com.|生成性检索是近年来出现的一种有前途的序列推荐方法，它将候选项检索框架为一个自回归序列生成问题。然而，现有的生成方法通常只关注项目信息的行为方面或语义方面，忽视了它们的互补性，因此效果有限。为了解决这个问题，我们引入了一个新的生成推荐框架 EAGER，它能够无缝地整合行为推荐和语义信息推荐。具体来说，我们确定了将这两种类型的信息结合起来的三个关键挑战: 一个能够处理两种特征类型的统一生成体系结构，确保对每种类型进行充分和独立的学习，以及培养能够提高协作信息利用率的微妙交互。为了实现这些目标，我们提出(1)利用共享编码器和两个单独的解码器的两流生成架构，以基于置信度的排序策略解码行为标记和语义标记; (2)具有摘要标记的全局对比任务，以实现每种类型的信息的区分性解码; 和(3)语义指导的转移任务，旨在通过重建和评估目标隐式促进交叉互动。我们在四个公共基准上验证了 EAGER 算法的有效性，证明了与现有方法相比，EAGER 算法具有更好的性能。我们的源代码将在 paperswithcode.com 上公开。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EAGER:+Two-Stream+Generative+Recommender+with+Behavior-Semantic+Collaboration)|1|
|[Debiased Recommendation with Noisy Feedback](https://doi.org/10.1145/3637528.3671915)|Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, XiaoHua Zhou|University of Science and Technology of China, Hefei, China; University of California, San Diego, Beijing, China; National University of Singapore, Singapore, Singapore; Peking University, Beijing, China; Zhejiang University, Hangzhou, China|Ratings of a user to most items in recommender systems are usually missing not at random (MNAR), largely because users are free to choose which items to rate. To achieve unbiased learning of the prediction model under MNAR data, three typical solutions have been proposed, including error-imputation-based (EIB), inverse-propensity-scoring (IPS), and doubly robust (DR) methods. However, these methods ignore an alternative form of bias caused by the inconsistency between the observed ratings and the users' true preferences, also known as noisy feedback or outcome measurement errors (OME), e.g., due to public opinion or low-quality data collection process. In this work, we study intersectional threats to the unbiased learning of the prediction model from data MNAR and OME in the collected data. First, we design OME-EIB, OME-IPS, and OME-DR estimators, which largely extend the existing estimators to combat OME in real-world recommendation scenarios. Next, we theoretically prove the unbiasedness and generalization bound of the proposed estimators. We further propose an alternate denoising training approach to achieve unbiased learning of the prediction model under MNAR data with OME. Extensive experiments are conducted on three real-world datasets and one semi-synthetic dataset to show the effectiveness of our proposed approaches. The code is available at https://github.com/haoxuanli-pku/KDD24-OME-DR.|在推荐系统中，用户对大多数项目的评分通常不是随机丢失的(MNAR) ，主要是因为用户可以自由选择对哪些项目进行评分。为了实现 MNAR 数据下预测模型的无偏学习，提出了三种典型的解决方案，包括基于错误插补(EIB)、逆倾向评分(IPS)和双鲁棒(DR)方法。然而，这些方法忽略了由观察到的评分和用户的真实偏好之间的不一致引起的另一种形式的偏差，也称为噪声反馈或结果测量错误(OME) ，例如由于公众意见或低质量的数据收集过程。在这项工作中，我们研究交叉威胁的预测模型无偏学习的数据 MNAR 和 OME 收集的数据。首先，我们设计了 OME-EIB、 OME-IPS 和 OME-DR 估计器，它们在很大程度上扩展了现有的估计器，以便在实际推荐场景中对抗 OME。接着，我们从理论上证明了所提出的估计量的无偏性和广义界。我们进一步提出了一种交替去噪训练方法，用 OME 实现 MNAR 数据下预测模型的无偏学习。在三个实际数据集和一个半合成数据集上进行了广泛的实验，以证明我们提出的方法的有效性。密码可在 https://github.com/haoxuanli-pku/kdd24-ome-dr 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiased+Recommendation+with+Noisy+Feedback)|1|
|[Harm Mitigation in Recommender Systems under User Preference Dynamics](https://doi.org/10.1145/3637528.3671925)|Jerry Chee, Shankar Kalyanaraman, Sindhu Kiranmai Ernala, Udi Weinsberg, Sarah Dean, Stratis Ioannidis|Northeastern University, Boston, MA, USA; Cornell University, Ithaca, NY, USA; Meta, Menlo Park, CA, USA|We consider a recommender system that takes into account the interplaybetween recommendations, the evolution of user interests, and harmful content.We model the impact of recommendations on user behavior, particularly thetendency to consume harmful content. We seek recommendation policies thatestablish a tradeoff between maximizing click-through rate (CTR) and mitigatingharm. We establish conditions under which the user profile dynamics have astationary point, and propose algorithms for finding an optimal recommendationpolicy at stationarity. We experiment on a semi-synthetic movie recommendationsetting initialized with real data and observe that our policies outperformbaselines at simultaneously maximizing CTR and mitigating harm.|我们考虑建议之间的相互作用，用户兴趣的演变和有害内容的推荐系统。我们模拟建议对用户行为的影响，特别是消费有害内容的趋势。我们寻求建议政策，在最大化点进率和减少伤害之间建立平衡。我们建立了用户轮廓动态具有平稳点的条件，并提出了在平稳点寻找最优推荐策略的算法。我们在一个半合成的电影推荐设置上进行了实验，初始化为真实数据，并观察到我们的策略在同时最大化点击率和减少危害方面优于基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harm+Mitigation+in+Recommender+Systems+under+User+Preference+Dynamics)|1|
|[Face4Rag: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese](https://doi.org/10.1145/3637528.3671656)|Yunqi Xu, Tianchi Cai, Jiyan Jiang, Xierui Song|Tsinghua University, Beijing, China; Ant Group, Shanghai, China; Ant Group, Hangzhou, China|The prevailing issue of factual inconsistency errors in conventional Retrieval Augmented Generation (RAG) motivates the study of Factual Consistency Evaluation (FCE). Despite the various FCE methods proposed earlier, these methods are evaluated on datasets generated by specific Large Language Models (LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE methods perform on other LLMs with different error distributions or even unseen error types, as these methods may fail to detect the error types generated by other LLMs. To fill this gap, in this paper, we propose the first comprehensive FCE benchmark Face4RAG for RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality inconsistency error and a real-world dataset constructed from six commonly used LLMs, enabling evaluation of FCE methods on specific error types or real-world error distributions. On the proposed benchmark, we discover the failure of existing FCE methods to detect the logical fallacy, which refers to a mismatch of logic structures between the answer and the retrieved reference. To fix this issue, we further propose a new method called L-Face4RAG with two novel designs of logic-preserving answer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG substantially outperforms previous methods for factual inconsistency detection on a wide range of tasks, notably beyond the RAG task from which it is originally motivated. Both the benchmark and our proposed method are publicly available. https://huggingface.co/datasets/yq27/Face4RAG|传统检索增强生成(RAG)中事实不一致性错误的普遍问题激发了事实一致性评价(FCE)的研究。尽管之前提出了各种 FCE 方法，但是这些方法是在特定的大语言模型(LLM)生成的数据集上进行评估的。由于没有一个全面的基准测试，这些 FCE 方法在其他具有不同错误分布甚至不可见错误类型的 LLM 上的表现仍然是未知的，因为这些方法可能无法检测其他 LLM 产生的错误类型。为了填补这个空白，在本文中，我们提出了独立于底层 LLM 的 RAG 的第一个全面的 FCE 基准 Face4RAG。我们的基准包括一个基于事实不一致性错误类型精心设计的合成数据集，以及一个由六个常用 LLM 构建的现实世界数据集，从而能够对特定错误类型或现实世界错误分布的 FCE 方法进行评估。在所提出的基准上，我们发现现有的 FCE 方法在检测逻辑谬误方面的失败，这是指答案和检索到的引用之间的逻辑结构不匹配。为了解决这一问题，我们进一步提出了一种新的方法，称为 L-Face4RAG 与两个新颖的设计保持逻辑的答案分解和事实逻辑 FCE。大量的实验表明，L-Face4RAG 在广泛的任务范围内大大优于以前的事实不一致性检测方法，特别是在 RAG 任务之外。基准测试和我们提出的方法都是公开的。Https://huggingface.co/datasets/yq27/face4rag|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Face4Rag:+Factual+Consistency+Evaluation+for+Retrieval+Augmented+Generation+in+Chinese)|1|
|[A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)](https://doi.org/10.1145/3637528.3671474)|Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, René Vidal, Maheswaran Sathiamoorthy, Atoosa Kasirzadeh, Silvia Milano|Bespoke Labs, Santa Clara, CA, USA; University of California, La Jolla, CA, USA; Polytechnic University of Bari, Bari, Italy; University of Toronto, Toronto, ON, Canada; Amazon, Palo Alto, CA, USA; University of Exeter and LMU Munich, Munich, Germany; University of Edinburgh, Edinburgh, UK|Traditional recommender systems typically use user-item rating histories as their main data source. However, deep generative models now have the capability to model and sample from complex data distributions, including user-item interactions, text, images, and videos, enabling novel recommendation tasks. This comprehensive, multidisciplinary survey connects key advancements in RS using Generative Models (Gen-RecSys), covering: interaction-driven generative models; the use of large language models (LLM) and textual data for natural language recommendation; and the integration of multimodal models for generating and processing images/videos in RS. Our work highlights necessary paradigms for evaluating the impact and harm of Gen-RecSys and identifies open challenges. This survey accompanies a "tutorial" presented at ACM KDD'24, with supporting materials provided at: https://encr.pw/vDhLq.|传统的推荐系统通常使用用户项评分历史作为其主要数据源。然而，深层生成模型现在能够对复杂的数据分布进行建模和采样，包括用户项交互、文本、图像和视频，从而实现新的推荐任务。这个全面的，多学科的调查连接了 RS 使用生成模型(Gen-RecSys)的关键进步，包括: 交互驱动的生成模型; 使用大语言模型(LLM)和文本数据进行自然语言推荐; 以及集成多模态模型用于生成和处理 RS 中的图像/视频。我们的工作突出了评估 Gen-RecSys 的影响和危害的必要范式，并确定了公开的挑战。本调查附有在 ACM kDD’24会议上提出的“教程”，辅助材料提供在以下 https://encr.pw/vdhlq。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Review+of+Modern+Recommender+Systems+Using+Generative+Models+(Gen-RecSys))|1|
|[A Population-to-individual Tuning Framework for Adapting Pretrained LM to On-device User Intent Prediction](https://doi.org/10.1145/3637528.3671984)|Jiahui Gong, Jingtao Ding, Fanjin Meng, Guilong Chen, Hong Chen, Shen Zhao, Haisheng Lu, Yong Li|Department of Electronic Engineering, BNRist, Tsinghua University, Beijing, China; Honor Device Co., Ltd., Shenzhen, China|Mobile devices, especially smartphones, can support rich functions and have developed into indispensable tools in daily life. With the rise of generative AI services, smartphones can potentially transform into personalized assistants, anticipating user needs and scheduling services accordingly. Predicting user intents on smartphones, and reflecting anticipated activities based on past interactions and context, remains a pivotal step towards this vision. Existing research predominantly focuses on specific domains, neglecting the challenge of modeling diverse event sequences across dynamic contexts. Leveraging pre-trained language models (PLMs) offers a promising avenue, yet adapting PLMs to on-device user intent prediction presents significant challenges. To address these challenges, we propose PITuning, a Population-to-Individual Tuning framework. PITuning enhances common pattern extraction through dynamic event-to-intent transition modeling and addresses long-tailed preferences via adaptive unlearning strategies. Experimental results on real-world datasets demonstrate PITuning's superior intent prediction performance, highlighting its ability to capture long-tailed preferences and its practicality for on-device prediction scenarios.|移动设备，尤其是智能手机，可以支持丰富的功能，并已发展成为日常生活中不可或缺的工具。随着产生式人工智能服务的兴起，智能手机有可能转变为个性化的助手，预测用户需求并相应地安排服务。在智能手机上预测用户意图，并根据过去的交互和上下文反映预期活动，仍然是实现这一愿景的关键一步。现有的研究主要集中在特定领域，忽视了在动态背景下建模不同事件序列的挑战。利用预先训练的语言模型(PLM)提供了一个有前途的途径，然而使 PLM 适应设备上的用户意图预测提出了重大挑战。为了应对这些挑战，我们提出 PITuning，一个人口到个人的调整框架。PITuning 通过动态事件-意图转换模型增强了公共模式提取，并通过自适应忘却策略解决了长尾偏好。在真实世界数据集上的实验结果表明，PITuning 具有优越的意图预测性能，突出了其捕获长尾偏好的能力以及在设备上预测场景的实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Population-to-individual+Tuning+Framework+for+Adapting+Pretrained+LM+to+On-device+User+Intent+Prediction)|1|
|[Efficient Exploration of the Rashomon Set of Rule-Set Models](https://doi.org/10.1145/3637528.3671818)|Martino Ciaperoni, Han Xiao, Aristides Gionis|Aalto University, Espoo, Uusimaa, Finland; The Upright Project, Helsinki, Uusimaa, Finland; KTH Royal Institute of Technology, Stockholm, Sweden|Today, as increasingly complex predictive models are developed, simple rule sets remain a crucial tool to obtain interpretable predictions and drive high-stakes decision making. However, a single rule set provides a partial representation of a learning task. An emerging paradigm in interpretable machine learning aims at exploring the Rashomon set of all models exhibiting near-optimal performance. Existing work on Rashomon-set exploration focuses on exhaustive search of the Rashomon set for particular classes of models, which can be a computationally challenging task. On the other hand, exhaustive enumeration leads to redundancy that often is not necessary, and a representative sample or an estimate of the size of the Rashomon set is sufficient for many applications. In this work, we propose, for the first time, efficient methods to explore the Rashomon set of rule set models with or without exhaustive search. Extensive experiments demonstrate the effectiveness of the proposed methods in a variety of scenarios.|今天，随着越来越复杂的预测模型的发展，简单的规则集仍然是获得可解释的预测和推动高风险决策的关键工具。但是，单个规则集提供了学习任务的部分表示。可解释机器学习的一个新兴范式旨在探索所有表现出接近最佳性能的罗生门模型集。现有的罗生门集探索工作侧重于对罗生门集进行详尽的搜索，寻找特定类别的模型，这可能是一项具有计算挑战性的任务。另一方面，穷举导致冗余，往往是不必要的，一个代表性的样本或罗生门集大小的估计是足够的许多应用程序。在这项工作中，我们首次提出了有效的方法来探索罗生门集的规则集模型有或没有穷举搜索。大量的实验证明了该方法在各种场景下的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Exploration+of+the+Rashomon+Set+of+Rule-Set+Models)|1|
|[Learning the Covariance of Treatment Effects Across Many Weak Experiments](https://doi.org/10.1145/3637528.3672034)|Aurélien Bibaut, Winston Chou, Simon Ejdemyr, Nathan Kallus||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+the+Covariance+of+Treatment+Effects+Across+Many+Weak+Experiments)|1|
|[Compact Decomposition of Irregular Tensors for Data Compression: From Sparse to Dense to High-Order Tensors](https://doi.org/10.1145/3637528.3671846)|Taehyung Kwon, Jihoon Ko, Jinhong Jung, JunGi Jang, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compact+Decomposition+of+Irregular+Tensors+for+Data+Compression:+From+Sparse+to+Dense+to+High-Order+Tensors)|1|
|[TDNetGen: Empowering Complex Network Resilience Prediction with Generative Augmentation of Topology and Dynamics](https://doi.org/10.1145/3637528.3671934)|Chang Liu, Jingtao Ding, Yiwen Song, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TDNetGen:+Empowering+Complex+Network+Resilience+Prediction+with+Generative+Augmentation+of+Topology+and+Dynamics)|1|
|[Scalable Temporal Motif Densest Subnetwork Discovery](https://doi.org/10.1145/3637528.3671889)|Ilie Sarpe, Fabio Vandin, Aristides Gionis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Temporal+Motif+Densest+Subnetwork+Discovery)|1|
|[UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction](https://doi.org/10.1145/3637528.3671662)|Yuan Yuan, Jingtao Ding, Jie Feng, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniST:+A+Prompt-Empowered+Universal+Model+for+Urban+Spatio-Temporal+Prediction)|1|
|[UrbanGPT: Spatio-Temporal Large Language Models](https://doi.org/10.1145/3637528.3671578)|Zhonghang Li, Lianghao Xia, Jiabin Tang, Yong Xu, Lei Shi, Long Xia, Dawei Yin, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UrbanGPT:+Spatio-Temporal+Large+Language+Models)|1|
|[Choosing a Proxy Metric from Past Experiments](https://doi.org/10.1145/3637528.3671543)|Nilesh Tripuraneni, Lee Richardson, Alexander D'Amour, Jacopo Soriano, Steve Yadlowsky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Choosing+a+Proxy+Metric+from+Past+Experiments)|1|
|[A Review of Graph Neural Networks in Epidemic Modeling](https://doi.org/10.1145/3637528.3671455)|Zewen Liu, Guancheng Wan, B. Aditya Prakash, Max S. Y. Lau, Wei Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Review+of+Graph+Neural+Networks+in+Epidemic+Modeling)|1|
|[Cross-Domain LifeLong Sequential Modeling for Online Click-Through Rate Prediction](https://doi.org/10.1145/3637528.3671601)|Ruijie Hou, Zhaoyang Yang, Ming Yu, Hongyu Lu, Zhuobin Zheng, Yu Chen, Qinsong Zeng, Ming Chen|Wechat, Tencent, Beijing, China; Wechat, Tencent, Guangzhou, China|Lifelong sequential modeling (LSM) has significantly advanced recommendation systems on social media platforms. Diverging from single-domain LSM, cross-domain LSM involves modeling lifelong behavior sequences from a source domain to a different target domain. In this paper, we propose the Lifelong Cross Network (LCN), a novel approach for cross-domain LSM. LCN features a Cross Representation Production (CRP) module that utilizes contrastive loss to improve the learning of item embeddings, effectively bridging items across domains. This is important for enhancing the retrieval of relevant items in cross-domain lifelong sequences. Furthermore, we propose the Lifelong Attention Pyramid (LAP) module, which contains three cascading attention levels. By adding an intermediate level and integrating the results from all three levels, the LAP module can capture a broad spectrum of user interests and ensure gradient propagation throughout the sequence. The proposed LAP can also achieve remarkable consistency across attention levels, making it possible to further narrow the candidate item pool of the top level. This allows for the use of advanced attention techniques to effectively mitigate the impact of the noise in cross-domain sequences and improve the non-linearity of the representation, all while maintaining computational efficiency. Extensive experiments conducted on both a public dataset and an industrial dataset from the WeChat Channels platform reveal that the LCN outperforms current methods in terms of prediction accuracy and online performance metrics.|终身顺序建模(LSM)在社交媒体平台上拥有非常先进的推荐系统。与单域 LSM 不同，跨域 LSM 涉及从源域到不同目标域的终身行为序列建模。本文提出了一种新的跨域 LSM 方法——终身交叉网络(LCN)。LCN 提供了一个交叉表示生成(CRP)模块，该模块利用对比度损失来改进项目嵌入的学习，有效地跨域连接项目。这对于提高跨域终身序列中相关项目的检索是非常重要的。此外，我们提出了终身注意金字塔(LAP)模块，它包含三个级联注意水平。通过增加一个中间层，并整合来自所有三个层次的结果，LAP 模块可以捕获广泛的用户兴趣，并确保梯度传播整个序列。提出的 LAP 还可以在不同的注意水平上实现显著的一致性，从而有可能进一步缩小最高水平的候选项库。这允许使用先进的注意力技术，以有效地减轻跨域序列中噪声的影响，并改善非线性表示，同时保持计算效率。在公共数据集和来自微信频道平台的工业数据集上进行的大量实验表明，LCN 在预测准确性和在线性能指标方面优于目前的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Domain+LifeLong+Sequential+Modeling+for+Online+Click-Through+Rate+Prediction)|0|
|[Mitigating Pooling Bias in E-commerce Search via False Negative Estimation](https://doi.org/10.1145/3637528.3671630)|Xiaochen Wang, Xiao Xiao, Ruhan Zhang, Xuan Zhang, Taesik Na, Tejaswi Tenneti, Haixun Wang, Fenglong Ma|The Pennsylvania State University, University Park, PA, USA; Instacart, San Francisco, CA, USA|Efficient and accurate product relevance assessment is critical for user experiences and business success. Training a proficient relevance assessment model requires high-quality query-product pairs, often obtained through negative sampling strategies. Unfortunately, current methods introduce pooling bias by mistakenly sampling false negatives, diminishing performance and business impact. To address this, we present Bias-mitigating Hard Negative Sampling (BHNS), a novel negative sampling strategy tailored to identify and adjust for false negatives, building upon our original False Negative Estimation algorithm. Our experiments in the Instacart search setting confirm BHNS as effective for practical e-commerce use. Furthermore, comparative analyses on public dataset showcase its domain-agnostic potential for diverse applications.|高效、准确的产品相关性评估对于用户体验和商业成功至关重要。训练一个熟练的相关性评估模型需要高质量的查询产品对，通常通过负抽样策略获得。不幸的是，目前的方法通过错误地采样错误的否定，减少性能和业务影响引入汇集偏见。为了解决这个问题，我们提出了消除偏差的硬负采样(BHNS) ，一种新的负采样策略，专门用于识别和调整假阴性，建立在我们原来的假阴性估计算法的基础上。我们在 Instacart 搜索设置中的实验证实了 BHNS 对于实际电子商务的使用是有效的。此外，对公共数据集的比较分析表明，其领域不可知的潜力适用于不同的应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Pooling+Bias+in+E-commerce+Search+via+False+Negative+Estimation)|0|
|[Automatic Multi-Task Learning Framework with Neural Architecture Search in Recommendations](https://doi.org/10.1145/3637528.3671715)|Shen Jiang, Guanghui Zhu, Yue Wang, Chunfeng Yuan, Yihua Huang|State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China|Multi-task learning (MTL), which aims to make full use of knowledge contained in multiple tasks to enhance overall performance and efficiency, has been broadly applied in recommendations. The main challenge for MTL models is negative transfer. Existing MTL models, mainly built on the Mixture-of-Experts (MoE) structure, seek enhancements in performance through feature selection and specific expert sharing mode design. However, one expert sharing mode may not be universally applicable due to the complex correlations and diverse demands among various tasks. Additionally, homogeneous expert architectures in such models further limit their performance. To address these issues, in this paper, we propose an innovative automatic MTL framework, AutoMTL, leveraging neural architecture search (NAS) to design optimal expert architectures and sharing modes. The Dual-level Expert Sharing mode and Architecture Navigator (DESAN) search space of AutoMTL can not only efficiently explore expert sharing modes and feature selection schemes but also focus on the architectures of expert subnetworks. Along with this, we introduce an efficient Progressively Discretizing Differentiable Architecture Search (PD-DARTS) algorithm for search space exploration. Extensive experiments demonstrate that AutoMTL can consistently outperform state-of-the-art, human-crafted MTL models. Moreover, the insights obtained from the discovered architectures provide valuable guidance for building new multi-task recommendation models.|多任务学习(Multi-Task Learning，MTL)旨在充分利用多任务中包含的知识，提高整体绩效和效率，已被广泛应用于建议学习中。MTL 模型的主要挑战是负迁移。现有的 MTL 模型主要建立在专家混合(MoE)结构的基础上，通过特征选择和专家共享模式设计来提高性能。然而，由于各种任务之间复杂的相关性和不同的需求，一种专家共享模式并不能普遍适用。此外，这些模型中的同类专家体系结构进一步限制了它们的性能。为了解决这些问题，本文提出了一种创新的自动 MTL 框架 AutoMTL，利用神经结构搜索(NAS)来设计最优的专家结构和共享模式。AutoMTL 的双层专家共享模式和体系结构导航器(DESAN)搜索空间不仅可以有效地探索专家共享模式和特征选择方案，而且可以集中研究专家子网的体系结构。在此基础上，提出了一种高效的逐次离散可微体系结构搜索(PD-DARTS)算法。大量的实验表明，AutoMTL 可以持续优于最先进的，人工制作的 MTL 模型。此外，从所发现的体系结构中获得的见解为构建新的多任务推荐模型提供了有价值的指导。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Multi-Task+Learning+Framework+with+Neural+Architecture+Search+in+Recommendations)|0|
|[CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation](https://doi.org/10.1145/3637528.3671901)|Junda Wu, ChengChun Chang, Tong Yu, Zhankui He, Jianing Wang, Yupeng Hou, Julian J. McAuley|Adobe Research, San Jose, CA, USA; University of California San Diego, La Jolla, CA, USA; Columbia University, New York, NY, USA|The long-tail recommendation is a challenging task for traditionalrecommender systems, due to data sparsity and data imbalance issues. The recentdevelopment of large language models (LLMs) has shown their abilities incomplex reasoning, which can help to deduce users' preferences based on veryfew previous interactions. However, since most LLM-based systems rely on items'semantic meaning as the sole evidence for reasoning, the collaborativeinformation of user-item interactions is neglected, which can cause the LLM'sreasoning to be misaligned with task-specific collaborative information of thedataset. To further align LLMs' reasoning to task-specific user-iteminteraction knowledge, we introduce collaborative retrieval-augmented LLMs,CoRAL, which directly incorporate collaborative evidence into the prompts.Based on the retrieved user-item interactions, the LLM can analyze shared anddistinct preferences among users, and summarize the patterns indicating whichtypes of users would be attracted by certain items. The retrieved collaborativeevidence prompts the LLM to align its reasoning with the user-item interactionpatterns in the dataset. However, since the capacity of the input prompt islimited, finding the minimally-sufficient collaborative information forrecommendation tasks can be challenging. We propose to find the optimalinteraction set through a sequential decision-making process and develop aretrieval policy learned through a reinforcement learning (RL) framework,CoRAL. Our experimental results show that CoRAL can significantly improve LLMs'reasoning abilities on specific recommendation tasks. Our analysis also revealsthat CoRAL can more efficiently explore collaborative information throughreinforcement learning.|由于数据稀疏和数据不平衡的问题，长尾推荐对于传统的推荐系统来说是一项具有挑战性的任务。大型语言模型(LLM)的最新发展已经显示出它们在复杂推理方面的能力，这种能力可以帮助推断用户基于极少数以前的交互的偏好。然而，由于大多数基于 LLM 的系统依赖于项目的语义作为推理的唯一证据，用户-项目交互的协作信息被忽视，这可能导致 LLM 的推理与数据集的特定任务的协作信息不一致。为了进一步将 LLM 的推理与特定于任务的用户项目交互知识结合起来，我们引入了协作检索增强 LLM，CoRAL，它直接将协作证据合并到提示中。基于检索到的用户-项目交互，LLM 可以分析用户之间的共享和不同偏好，并总结模式，指出哪些类型的用户会被某些项目吸引。检索到的协作证据提示 LLM 使其推理与数据集中的用户项交互模式保持一致。然而，由于输入提示的能力是有限的，找到最低限度-足够的协作信息的推荐任务可能是具有挑战性的。我们建议通过一个连续的决策过程来寻找最佳的交互集合，并通过一个强化学习(RL)框架 CoRAL 来发展检索策略。实验结果表明，CoRAL 可以显著提高 LLM 对特定推荐任务的推理能力。我们的分析还显示，通过强化学习，CoRAL 可以更有效地探索协作信息。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoRAL:+Collaborative+Retrieval-Augmented+Large+Language+Models+Improve+Long-tail+Recommendation)|0|
|[Text Matching Indexers in Taobao Search](https://doi.org/10.1145/3637528.3671654)|Sen Li, Fuyu Lv, Ruqing Zhang, Dan Ou, Zhixuan Zhang, Maarten de Rijke|University of Amsterdam, Amsterdam, Netherlands; Alibaba Group, Hangzhou, China; CAS Key Lab of Network Data Science and Technology, ICT, CAS, Beijing, China|Product search is an important service on Taobao, the largest e-commerce platform in China. Through this service, users can easily find products relevant to their specific needs. Coping with billion-size query loads, Taobao product search has traditionally relied on classical term-based retrieval models due to their powerful and interpretable indexes. In essence, efficient retrieval hinges on the proper storage of the inverted index. Recent successes involve reducing the size (pruning) of the inverted index but the construction and deployment of lossless static index pruning in practical product search still pose non-trivial challenges. In this work, we introduce a novel SM art INDexing (SMIND) solution in Taobao product search. SMIND is designed to reduce information loss during the static pruning process by incorporating user search preferences. Specifically, we first construct "user-query-item'' hypergraphs for four different search preferences, namely purchase, click, exposure, and relevance. Then, we develop an efficient TermRank algorithm applied to these hypergraphs, to preserve relevant items based on specific user preferences during the pruning of the inverted indexer. Our approach offers fresh insights into the field of product search, emphasizing that term dependencies in user search preferences go beyond mere text relevance. Moreover, to address the vocabulary mismatch problem inherent in term-based models, we also incorporate an multi-granularity semantic retrieval model to facilitate semantic matching. Empirical results from both offline evaluation and online A/B tests showcase the superiority of SMIND over state-of-the-art methods, especially in commerce metrics with significant improvements of 1.34% in Pay Order Count and 1.50% in Gross Merchandise Value. Besides, SMIND effectively mitigates the Matthew effect of user queries and has been in service for hundreds of millions of daily users since November 2022.|产品搜索是中国最大的电子商务平台淘宝上的一项重要服务。通过这项服务，用户可以很容易地找到与他们的具体需求相关的产品。为了应对数十亿大小的查询负载，淘宝产品搜索传统上依赖于传统的基于词汇的检索模型，因为它们的索引功能强大且易于解释。实质上，有效的检索取决于适当存储倒排索引。最近的成功包括减少了反向索引的大小(修剪) ，但是在实际的产品搜索中构建和部署无损静态索引修剪仍然带来了不小的挑战。在本文中，我们介绍了一个新颖的 SM 艺术索引(SMIND)解决方案在淘宝产品搜索。SMIND 的目的是通过合并用户搜索偏好，减少静态修剪过程中的信息损失。具体来说，我们首先为四种不同的搜索偏好(即购买、点击、曝光和相关性)构建“用户查询项目”超图。然后，我们开发了一个有效的 TermRank 算法应用于这些超图，以保留相关的项目基于特定的用户喜好在反向索引器的修剪过程中。我们的方法为产品搜索领域提供了新的视角，强调用户搜索偏好中的术语依赖性不仅仅是文本相关性。此外，为了解决基于词汇的模型所固有的词汇不匹配问题，我们还引入了一个多粒度的语义检索模型来促进语义匹配。线下评估和在线 A/B 测试的实证结果表明，SMIND 相对于最先进的方法具有优势，尤其是在商业指标方面，支付订单计数和商品总价值分别显著提高了1.34% 和1.50% 。此外，SMIND 有效地减轻了用户查询的“马太效应”，自2022年11月以来已为数亿日常用户提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text+Matching+Indexers+in+Taobao+Search)|0|
|[Unified Low-rank Compression Framework for Click-through Rate Prediction](https://doi.org/10.1145/3637528.3671520)|Hao Yu, Minghao Fu, Jiandong Ding, Yusheng Zhou, Jianxin Wu|Nanjing University, Nanjing, Jiangsu, China; Researcher, Shanghai, China|Deep Click-Through Rate (CTR) prediction models play an important role in modern industrial recommendation scenarios. However, high memory overhead and computational costs limit their deployment in resource-constrained environments. Low-rank approximation is an effective method for computer vision and natural language processing models, but its application in compressing CTR prediction models has been less explored. Due to the limited memory and computing resources, compression of CTR prediction models often confronts three fundamental challenges, i.e., (1). How to reduce the model sizes to adapt to edge devices? (2). How to speed up CTR prediction model inference? (3). How to retain the capabilities of original models after compression? Previous low-rank compression research mostly uses tensor decomposition, which can achieve a high parameter compression ratio, but brings in AUC degradation and additional computing overhead. To address these challenges, we propose a unified low-rank decomposition framework for compressing CTR prediction models. We find that even with the most classic matrix decomposition SVD method, our framework can achieve better performance than the original model. To further improve the effectiveness of our framework, we locally compress the output features instead of compressing the model weights. Our unified low-rank compression framework can be applied to embedding tables and MLP layers in various CTR prediction models. Extensive experiments on two academic datasets and one real industrial benchmark demonstrate that, with 3--5× model size reduction, our compressed models can achieve both faster inference and higher AUC than the uncompressed original models. Our code is at https://github.com/yuhao318/Atomic_Feature_Mimicking.|深点进率(ctrl)预测模型在现代工业推荐方案中扮演着重要角色。但是，较高的内存开销和计算成本限制了它们在资源受限环境中的部署。低秩近似是计算机视觉和自然语言处理模型的一种有效方法，但其在压缩 CTR 预测模型方面的应用研究较少。由于有限的内存和计算资源，CTR 预测模型的压缩往往面临三个基本挑战，即(1)。如何减小模型尺寸以适应边缘设备？(2).如何加快 CTR 预测模型的推导？(3).如何保留原始模型压缩后的能力？先前的低秩压缩研究大多使用张量分解，这可以实现高参数的压缩比，但是带来了 AUC 降解和额外的计算开销。为了应对这些挑战，我们提出了一个统一的低秩分解框架来压缩 CTR 预测模型。我们发现，即使使用最经典的矩阵分解奇异值分解方法，我们的框架也能取得比原始模型更好的性能。为了进一步提高框架的有效性，我们对输出特征进行了局部压缩，而不是对模型权重进行压缩。我们统一的低秩压缩框架可以应用于各种 CTR 预测模型中的表和 MLP 层的嵌入。在两个学术数据集和一个实际工业基准上的大量实验表明，与未压缩的原始模型相比，通过3-5 × 模型尺寸的缩减，我们的压缩模型可以实现更快的推理和更高的 AUC。我们的代码是 https://github.com/yuhao318/atomic_feature_mimicking。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Low-rank+Compression+Framework+for+Click-through+Rate+Prediction)|0|
|[Optimizing Smartphone App Usage Prediction: A Click-Through Rate Ranking Approach](https://doi.org/10.1145/3637528.3671567)|Yuqi Zhang, Meiying Kang, Xiucheng Li, Yu Qiu, Zhijun Li|Independent, Chengdu, China; Harbin Institute of Technology, Harbin, China; Harbin Institute of Technology, Shenzhen, China; Soochow University, Suzhou, China|Over the past decade, smartphones have become indispensable personal mobile devices, experiencing a remarkable surge in software apps. These apps empower users to seamlessly connect with various internet services, such as social communication and online shopping. Accurately predicting smartphone app usage can effectively improve user experience and optimize resource utilization. However, existing models often treat app usage prediction as a classification problem, which suffers from issues of app usage imbalance and out-of-distribution (OOD) during deployment. To address these challenges, this paper proposes a novel click-through rate (CTR) ranking-based method for predicting app usage. By transforming the classification problem into a CTR problem, we can eliminate the negative impact of the app usage imbalance issue. To address the OOD issue during deployment, we generate the app click sequence and three types of discriminative features, which enable generalization on unseen apps. The app click sequence and the three types of features serve as inputs for training a CTR estimation model in the cloud, and the trained model is then deployed on the user's smartphone to predict the CTR for each installed app. The decision-making process involves ranking these CTR values and selecting the app with the highest CTR as the final prediction. Our method has been extensively tested with large-scale app usage data. The results demonstrate that our approach is able to outperform state-of-the-art methods, with improvements over 4.93% in top-3 accuracy and 6.64% in top-5 accuracy. It achieves approximately twice the accuracy in predicting apps with low usage frequencies in comparison to baseline methods. Our method has been successfully deployed on the app recommendation system of a leading smartphone manufacturer.|在过去十年里，智能手机已经成为不可或缺的个人移动设备，软件应用程序出现了惊人的增长。这些应用程序使用户能够无缝连接各种互联网服务，如社会交流和网上购物。准确预测智能手机应用程序的使用情况可以有效地改善用户体验和优化资源利用。然而，现有的模型往往将应用程序使用预测视为一个分类问题，在部署过程中存在应用程序使用不平衡和分布不均衡(OOD)的问题。为了应对这些挑战，本文提出了一种新的基于点进率排名(ctrr)的方法来预测应用程序的使用情况。通过将分类问题转化为 CTR 问题，我们可以消除应用程序使用不平衡问题的负面影响。为了解决部署过程中的 OOD 问题，我们生成了应用程序的点击序列和三种类型的区分特性，这些特性可以对看不见的应用程序进行泛化。应用程序点击序列和三种类型的功能作为输入，用于在云中训练一个点击率估计模型，然后将训练好的模型部署到用户的智能手机上，以预测每个安装的应用程序的点击率。决策过程包括对这些点击率值进行排序，并选择点击率最高的应用程序作为最终预测。我们的方法已经通过大规模的应用程序使用数据进行了广泛的测试。结果表明，我们的方法能够优于国家的最先进的方法，提高了4.93% 以上的前3名的准确性和6.64% 以上的前5名的准确性。与基线方法相比，它在预测使用频率较低的应用程序方面达到了大约两倍的准确性。我们的方法已成功应用于一家领先的智能手机制造商的应用程序推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Smartphone+App+Usage+Prediction:+A+Click-Through+Rate+Ranking+Approach)|0|
|[Relevance Meets Diversity: A User-Centric Framework for Knowledge Exploration Through Recommendations](https://doi.org/10.1145/3637528.3671949)|Erica Coppolillo, Giuseppe Manco, Aristides Gionis|Department of Computer Science, University of Calabria & ICAR-CNR, Rende, Italy; ICAR-CNR, Rende, Italy; Division of Theoretical Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden|Providing recommendations that are both relevant and diverse is a key consideration of modern recommender systems. Optimizing both of these measures presents a fundamental trade-off, as higher diversity typically comes at the cost of relevance, resulting in lower user engagement. Existing recommendation algorithms try to resolve this trade-off by combining the two measures, relevance and diversity, into one aim and then seeking recommendations that optimize the combined objective, for a given number of items. Traditional approaches, however, do not consider the user interaction with the suggested items. In this paper, we put the user at the central stage, and build on the interplay between relevance, diversity, and user behavior. In contrast to applications where the goal is solely to maximize engagement, we focus on scenarios aiming at maximizing the total amount of knowledge encountered by the user. We use diversity as a surrogate for the amount of knowledge obtained by the user while interacting with the system, and we seek to maximize diversity. We propose a probabilistic user-behavior model in which users keep interacting with the recommender system as long as they receive relevant suggestions, but they may stop if the relevance of the recommended items drops. Thus, for a recommender system to achieve a high-diversity measure, it will need to produce recommendations that are both relevant and diverse. Finally, we propose a novel recommendation strategy that combines relevance and diversity by a copula function. We conduct an extensive evaluation of the proposed methodology over multiple datasets, and we show that our strategy outperforms several state-of-the-art competitors. Our implementation is publicly available at https://github.com/EricaCoppolillo/EXPLORE.|提供相关和多样化的建议是现代推荐系统的一个关键考虑因素。优化这两个措施提出了一个基本的权衡，因为更高的多样性通常以相关性为代价，导致用户参与度降低。现有的推荐算法试图通过将相关性和多样性这两个衡量标准结合为一个目标来解决这种权衡，然后寻求建议，优化合并目标，以满足给定数量的项目。但是，传统方法不考虑用户与建议项的交互。在本文中，我们把用户放在中心阶段，并建立在相关性，多样性和用户行为之间的相互作用。与目标仅仅是最大化参与的应用程序不同，我们关注的场景旨在最大化用户遇到的知识总量。我们使用多样性作为用户在与系统交互时获得的知识量的替代指标，并寻求最大化多样性。我们提出了一个概率用户行为模型，在这个模型中，用户只要收到相关的建议，就会与推荐系统保持互动，但是如果推荐项目的相关性下降，他们可能会停止。因此，推荐系统要实现高度多样化的措施，就需要提出相关且多样化的建议。最后，我们提出了一个新的推荐策略，通过一个 Copula 函数结合相关性和多样性。我们在多个数据集上对提出的方法进行了广泛的评估，我们表明我们的策略优于几个最先进的竞争对手。我们的实施 https://github.com/ericacoppolillo/explore 公开发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevance+Meets+Diversity:+A+User-Centric+Framework+for+Knowledge+Exploration+Through+Recommendations)|0|
|[Understanding the Ranking Loss for Recommendation with Sparse User Feedback](https://doi.org/10.1145/3637528.3671565)|Zhutian Lin, Junwei Pan, Shangyu Zhang, Ximei Wang, Xi Xiao, Shudong Huang, Lei Xiao, Jie Jiang|Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Tencent Inc., Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, Guangdong, China|Click-through rate (CTR) prediction is a crucial area of research in online advertising. While binary cross entropy (BCE) has been widely used as the optimization objective for treating CTR prediction as a binary classification problem, recent advancements have shown that combining BCE loss with an auxiliary ranking loss can significantly improve performance. However, the full effectiveness of this combination loss is not yet fully understood. In this paper, we uncover a new challenge associated with the BCE loss in scenarios where positive feedback is sparse: the issue of gradient vanishing for negative samples. We introduce a novel perspective on the effectiveness of the auxiliary ranking loss in CTR prediction: it generates larger gradients on negative samples, thereby mitigating the optimization difficulties when using the BCE loss only and resulting in improved classification ability. To validate our perspective, we conduct theoretical analysis and extensive empirical evaluations on public datasets. Additionally, we successfully integrate the ranking loss into Tencent's online advertising system, achieving notable lifts of 0.70% and 1.26% in Gross Merchandise Value (GMV) for two main scenarios. The code is openly accessible at: https://github.com/SkylerLinn/Understanding-the-Ranking-Loss.|点进率预测是在线广告研究的一个关键领域。二进制交叉熵(BCE)已被广泛用作将 CTR 预测作为二进制分类问题处理的优化目标，但最近的研究表明，将 BCE 损失与辅助排序损失相结合可以显著提高性能。然而，这种组合损失的全部有效性尚未完全了解。在本文中，我们揭示了一个新的挑战与 BCE 损失相关的情况下，正反馈是稀疏的: 问题的梯度消失的负样本。我们介绍了一种新的视角辅助排序损失在 CTR 预测中的有效性: 它在负样本上产生较大的梯度，从而减少了优化时仅使用 BCE 损失的困难，并导致分类能力的提高。为了验证我们的观点，我们对公共数据集进行了理论分析和广泛的实证评估。此外，我们成功地将排名损失纳入腾讯的在线广告系统，在两个主要情况下，商品总值(GMV)分别显著提高了0.70% 和1.26% 。该守则可在以下 https://github.com/skylerlinn/understanding-The-ranking-loss 公开查阅:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Ranking+Loss+for+Recommendation+with+Sparse+User+Feedback)|0|
|[Multi-Task Neural Linear Bandit for Exploration in Recommender Systems](https://doi.org/10.1145/3637528.3671649)|Yi Su, Haokai Lu, Yuening Li, Liang Liu, Shuchao Bi, Ed H. Chi, Minmin Chen|Google, Mountain View, CA, USA; Google Deepmind, Mountain View, CA, USA|Exposure bias and its induced feedback loop effect are well-known problems in recommender systems. Exploration is believed to be the key to break such feedback loops. While classical contextual bandit algorithms such as Upper-Confidence-Bound and Thompson Sampling have been successful in addressing the exploration-exploitation trade-off in the single-task settings with one clear reward signal, modern recommender systems often leverage multiple rich sources of feedback such as clicks, likes, dislikes, shares, satisfaction survey responses, and employ multi-task learning in practice. It is unclear how one can incorporate exploration in the multi-task setup with different objectives. In this paper, we study an efficient bandit algorithm tailored to multi-task recommender systems, named Multi-task Neural Linear Bandit (mtNLB). In particular, we investigate efficient feature embeddings in the multi-task setups that could be used as contextual features in the Neural Linear Bandit, a contextual bandit algorithm that nicely combines the representation power from DNN and simplicity in uncertainty calculation from linear models. We further study cost-effective approximations of the uncertainty estimate and principled ways to incorporate uncertainty into the multi-task scoring of items. To showcase the efficacy of our proposed method, we conduct live experiments on a large-scale commercial recommendation platform that serves billions of users. We evaluate the quality of the uncertainty estimate and demonstrate its ability to improve exploration across the different dimensions of the reward signals in comparison to baseline approaches.|在推荐系统中，曝光偏差及其诱导反馈回路效应是一个众所周知的问题。勘探被认为是打破这种反馈循环的关键。尽管传统的情境强盗算法如 Upper-Confidence-Bound 和 Thompson Sampling 已经成功地解决了单任务环境中的探索-开发权衡问题，但是现代推荐系统往往利用多种丰富的反馈来源，如点击，喜欢，不喜欢，分享，满意度调查反馈，并在实践中采用多任务学习。目前还不清楚如何将探索结合到具有不同目标的多任务设置中。本文研究了一种适用于多任务推荐系统的高效盗贼算法——多任务神经网络线性盗贼(mtNLB)。特别地，我们研究了在多任务设置中有效的特征嵌入，这些特征可以作为神经网络线性匪徒算法中的上下文特征，这种上下文匪徒算法很好地结合了 DNN 的表示能力和线性模型的不确定性计算的简单性。我们进一步研究了不确定性估计的成本效益近似，以及将不确定性纳入多任务项目评分的原则方法。为了展示我们提出的方法的有效性，我们在一个服务于数十亿用户的大规模商业推荐平台上进行了现场实验。我们评估不确定性估计的质量，并证明其能力，以改善探索的不同维度的奖励信号相比，基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Neural+Linear+Bandit+for+Exploration+in+Recommender+Systems)|0|
|[Enhancing Pre-Ranking Performance: Tackling Intermediary Challenges in Multi-Stage Cascading Recommendation Systems](https://doi.org/10.1145/3637528.3671580)|Jianping Wei, Yujie Zhou, Zhengwei Wu, Ziqi Liu|Ant Group, HangZhou, China|Large-scale search engines and recommendation systems utilize a three-stage cascading architecture-recall, pre-ranking, and ranking-to deliver relevant results within stringent latency limits. The pre-ranking stage is crucial for filtering a large number of recalled items into a manageable set for the ranking stage, greatly affecting the system's performance. Pre-ranking faces two intermediary challenges: Sample Selection Bias (SSB) arises when training is based on ranking stage feedback but the evaluation is on a broader recall dataset. Also, compared to the ranking stage, simpler pre-rank models may perform worse and less consistently. Traditional methods to tackle SSB issues include using all recall results and treating unexposed portions as negatives for training, which can be costly and noisy. To boost performance and consistency, some pre-ranking feature interaction enhancers don't fully fix consistency issues, while methods like knowledge distillation in ranking models ignore exposure bias. Our proposed framework targets these issues with three integral modules: Sample Selection, Domain Adaptation, and Unbiased Distillation. Sample Selection filters recall results to mitigate SSB and compute costs. Domain Adaptation enhances model robustness by assigning pseudo-labels to unexposed samples. Unbiased Distillation uses exposure-independent scores from Domain Adaptation to implement unbiased distillation for the pre-ranking model. The framework focuses on optimizing pre-ranking while maintaining training efficiency. We introduce new metrics for pre-ranking evaluation, while experiments confirm the effectiveness of our framework. Our framework is also deployed in real industrial systems.|大型搜索引擎和推荐系统利用三阶段级联架构——召回、预先排序和排序——在严格的延迟限制内交付相关结果。预排序阶段对于将大量被召回的项目过滤到一个可管理的集合中以进行排序至关重要，这极大地影响了系统的性能。预排序面临两个中间挑战: 样本选择偏差(SSB)出现时，训练是基于排序阶段的反馈，但评估是在一个更广泛的召回数据集。此外，与排名阶段相比，更简单的预排名模型可能表现得更差，更不一致。解决 SSB 问题的传统方法包括使用所有的召回结果，并将未暴露的部分作为培训的负面因素，这可能是昂贵和嘈杂的。为了提高性能和一致性，一些预排序特征交互增强器不能完全解决一致性问题，而排序模型中的知识提取等方法忽略了暴露偏差。我们提出的框架通过三个整体模块来解决这些问题: 样本选择、领域适应和无偏提取。示例选择过滤器召回结果以减少 SSB 和计算成本。领域自适应通过为未暴露的样本分配伪标签来增强模型的鲁棒性。无偏蒸馏使用领域适应的暴露无关分数实现预排序模型的无偏蒸馏。该框架的重点是优化预排序，同时保持培训效率。在实验的基础上，我们引入了新的指标来进行预排序评价，并验证了该框架的有效性。我们的框架也部署在真实的工业系统中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Pre-Ranking+Performance:+Tackling+Intermediary+Challenges+in+Multi-Stage+Cascading+Recommendation+Systems)|0|
|[Explicit and Implicit Modeling via Dual-Path Transformer for Behavior Set-informed Sequential Recommendation](https://doi.org/10.1145/3637528.3671755)|Ming Chen, Weike Pan, Zhong Ming|; Shenzhen University & Shenzhen Technology University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China|Sequential recommendation (SR) and multi-behavior sequential recommendation (MBSR) both come from real-world scenarios. Compared with SR, MBSR takes into account the dependencies of different behaviors. We find that most existing works on MBSR are studied in the context of e-commerce scenarios. In terms of the data format of the behavior types, we observe that the conventional label-formatted data carries limited information and is inadequate for scenarios like social media. With this observation, we introducebehavior set and extend MBSR to behavior set-informed sequential recommendation (BSSR). In BSSR, behavior dependencies become more complex and personalized, and user interest arousal may lack explicit contextual associations. To delve into the dynamics inhered within a behavior set and adaptively tailor recommendation lists upon its variability, we propose a novel solution called Explicit and Implicit modeling via Dual-Path Transformer (EIDP) for BSSR. Our EIDP adopts a dual-path architecture, distinguishing between explicit modeling path (EMP) and implicit modeling path (IMP) based on whether to directly incorporate the behavior representations. EMP features the personalized behavior set-wise transition pattern extractor (PBS-TPE) as its core component. It couples behavioral representations with both the items and positions to explore intra-behavior dynamics within a behavior set at a fine granularity. IMP utilizes light multi-head self-attention blocks (L-MSAB) as encoders under specific behavior types. The obtained multi-view representations are then aggregated by cross-behavior attention fusion (CBAF), using the behavior set of the next time step as a guidance to extract collaborative semantics at the behavioral level. Extensive experiments on two real-world datasets demonstrate the effectiveness of our EIDP. We release the implementation code at: https://github.com/OshiNoCSMA/EIDP.|序贯推荐(SR)和多行为序贯推荐(MBSR)都来自于现实场景。与 SR 相比，MBSR 考虑了不同行为的依赖性。我们发现现有的大多数 MBSR 的研究工作都是在电子商务环境下进行的。就行为类型的数据格式而言，我们观察到传统的标签格式的数据携带有限的信息，对于像社交媒体这样的场景来说是不够的。在此基础上，我们引入了行为集合，并将 MBSR 扩展到行为集合知情序列推荐(BSSR)。在 BSSR，行为依赖变得更加复杂和个性化，用户兴趣唤起可能缺乏明确的上下文关联。为了深入研究行为集内部的动态性，并根据其可变性自适应调整推荐列表，我们提出了一种新的解决方案，即通过双路径转换器(EIDP)对 BSSR 进行显式和隐式建模。我们的 EIDP 采用双路径结构，根据是否直接合并行为表示，区分显式建模路径(EMP)和隐式建模路径(IMP)。EMP 以个性化行为集合过渡模式提取器(PBS-TPE)为核心组件。它将行为表示与项目和位置耦合起来，以便在一个细粒度的行为集内探索行为内动态。IMP 利用轻型多头自我注意块(L-MSAB)作为特定行为类型下的编码器。然后通过交叉行为注意融合(CBAF)对所获得的多视图表示进行聚合，利用下一个时间步骤的行为集作为指导，从行为层面提取协作语义。在两个实际数据集上的大量实验证明了我们的 EIDP 算法的有效性。我们在以下 https://github.com/oshinocsma/eidp 发布实现代码:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explicit+and+Implicit+Modeling+via+Dual-Path+Transformer+for+Behavior+Set-informed+Sequential+Recommendation)|0|
|[Disentangled Multi-interest Representation Learning for Sequential Recommendation](https://doi.org/10.1145/3637528.3671800)|Yingpeng Du, Ziyan Wang, Zhu Sun, Yining Ma, Hongzhi Liu, Jie Zhang|Nanyang Technological University, Singapore, Singapore; Singapore University of Technology and Design, Singapore, Singapore; Peking University, Beijing, China|Recently, much effort has been devoted to modeling users' multi-interests (aka multi-faceted preferences) based on their behaviors, aiming to accurately capture users' complex preferences. Existing methods attempt to model each interest of users through a distinct representation, but these multi-interest representations easily collapse into similar ones due to a lack of effective guidance. In this paper, we propose a generic multi-interest method for sequential recommendation, achieving disentangled representation learning of diverse interests technically and theoretically. To alleviate the collapse issue of multi-interests, we propose to conduct item partition guided by their likelihood of being co-purchased in a global view. It can encourage items in each group to focus on a discriminated interest, thus achieving effective disentangled learning of multi-interests. Specifically, we first prove the theoretical connection between item partition and spectral clustering, demonstrating its effectiveness in alleviating item-level and facet-level collapse issues that hinder existing disentangled methods. To efficiently optimize this problem, we then propose a Markov Random Field (MRF)-based method that samples small-scale sub-graphs from two separate MRFs, thus it can be approximated with a cross-entropy loss and optimized through contrastive learning. Finally, we perform multi-task learning to seamlessly align item partition learning with multi-interest modeling for more accurate recommendation. Experiments on three real-world datasets show that our method significantly outperforms state-of-the-art methods and can flexibly integrate with existing multi-interest models as a plugin to enhance their performances.|近年来，人们致力于根据用户的行为建立用户的多重兴趣(即多方面偏好)模型，以准确捕捉用户的复杂偏好。现有的方法试图通过一个不同的表示来对用户的每个兴趣进行建模，但是由于缺乏有效的指导，这些多兴趣表示很容易崩溃成为相似的表示。本文提出了一种通用的多兴趣序列推荐方法，从理论和技术上实现了不同兴趣的分离表示学习。为了缓解多重利益的崩溃问题，我们提出在全局视角下，以多重利益共同购买的可能性为指导进行项目分割。它可以鼓励项目在每个组集中在一个歧视性的兴趣，从而实现有效的多兴趣分离学习。具体来说，我们首先证明了项目划分和 SVD 之间的理论联系，证明了它在缓解阻碍现有分离方法的项目级和面级崩溃问题方面的有效性。为了有效地优化这个问题，我们提出了一个基于马尔可夫网络(MRF)的方法，从两个不同的 MRF 中抽取小规模子图，因此它可以用交叉熵损失近似，并通过对比学习进行优化。最后，我们进行多任务学习，使项目划分学习与多兴趣模型无缝对齐，以获得更准确的推荐。在三个实际数据集上的实验表明，该方法的性能明显优于最新的方法，并且可以灵活地与现有的多兴趣模型集成，作为一个插件来提高它们的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Multi-interest+Representation+Learning+for+Sequential+Recommendation)|0|
|[Continual Collaborative Distillation for Recommender System](https://doi.org/10.1145/3637528.3671924)|Gyuseok Lee, SeongKu Kang, Wonbin Kweon, Hwanjo Yu|Pohang University of Science and Technology, Pohang, Gyeongsangbuk-do, Republic of Korea; University of Illinois Urbana-Champaign, Champaign, Illinois, USA|Knowledge distillation (KD) has emerged as a promising technique foraddressing the computational challenges associated with deploying large-scalerecommender systems. KD transfers the knowledge of a massive teacher system toa compact student model, to reduce the huge computational burdens for inferencewhile retaining high accuracy. The existing KD studies primarily focus onone-time distillation in static environments, leaving a substantial gap intheir applicability to real-world scenarios dealing with continuously incomingusers, items, and their interactions. In this work, we delve into a systematicapproach to operating the teacher-student KD in a non-stationary data stream.Our goal is to enable efficient deployment through a compact student, whichpreserves the high performance of the massive teacher, while effectivelyadapting to continuously incoming data. We propose Continual CollaborativeDistillation (CCD) framework, where both the teacher and the studentcontinually and collaboratively evolve along the data stream. CCD facilitatesthe student in effectively adapting to new data, while also enabling theteacher to fully leverage accumulated knowledge. We validate the effectivenessof CCD through extensive quantitative, ablative, and exploratory experiments ontwo real-world datasets. We expect this research direction to contribute tonarrowing the gap between existing KD studies and practical applications,thereby enhancing the applicability of KD in real-world systems.|知识精馏(KD)已经成为解决部署大规模推荐系统所面临的计算挑战的一种有前途的技术。KD 将大规模教师系统的知识转移到一个紧凑的学生模型，以减少推理的巨大计算负担，同时保持高精度。现有的 KD 研究主要集中在静态环境中的一次性提取，在处理不断进入的用户、项目及其交互的实际场景的适用性方面留下了很大的空白。在这项工作中，我们深入探讨了一个系统的方法来运行师生知识发展在一个非平稳的数据流。我们的目标是通过一个紧凑的学生实现有效的部署，这样可以保持大规模教师的高性能，同时有效地适应不断传入的数据。我们提出了持续协作蒸馏(CCD)框架，在这个框架中，教师和学生沿着数据流不断地、协作地发展。CCD 帮助学生有效地适应新的数据，同时也使教师能够充分利用积累的知识。我们通过在两个实际数据集上进行广泛的定量、消融和探索性实验，验证了 CCD 的有效性。我们期望这一研究方向能够缩小现有 KD 研究与实际应用之间的差距，从而提高 KD 在现实世界系统中的适用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Collaborative+Distillation+for+Recommender+System)|0|
|[Mitigating Negative Transfer in Cross-Domain Recommendation via Knowledge Transferability Enhancement](https://doi.org/10.1145/3637528.3671799)|Zijian Song, Wenhan Zhang, Lifang Deng, Jiandong Zhang, Zhihua Wu, Kaigui Bian, Bin Cui|; Lazada Group, Beijing, China|Cross-Domain Recommendation (CDR) is a promising technique to alleviate data sparsity by transferring knowledge across domains. However, the negative transfer issue in the presence of numerous domains has received limited attention. Most existing methods transfer all information from source domains to the target domain without distinction. This introduces harmful noise and irrelevant features, resulting in suboptimal performance. Although some methods decompose user features into domain-specific and domain-shared components, they fail to consider other causes of negative transfer. Worse still, we argue that simple feature decomposition is insufficient for multi-domain scenarios. To bridge this gap, we propose TrineCDR, the TRIple-level kNowledge transferability Enhanced model for multi-target CDR. Unlike previous methods, TrineCDR captures single domain and targeted cross-domain embeddings to serve multi-domain recommendation. For the latter, we identify three fundamental causes of negative transfer, ranging from micro to macro perspectives, and correspondingly enhance knowledge transferability at three different levels: the feature level, the interaction level, and the domain level. Through these efforts, TrineCDR effectively filters out noise and irrelevant information from source domains, leading to more comprehensive and accurate representations in the target domain. We extensively evaluate the proposed model on real-world datasets, sampled from Amazon and Douban, under both dual-target and multi-target scenarios. The experimental results demonstrate the superiority of TrineCDR over state-of-the-art cross-domain recommendation methods.|跨域推荐(CDR)是一种通过跨域传输知识来缓解数据稀疏性的有前途的技术。然而，在众多领域存在的负迁移问题受到的关注有限。大多数现有的方法不加区别地将所有信息从源域传输到目标域。这会引入有害的噪音和不相关的特征，导致性能不理想。尽管有些方法将用户特性分解为特定于领域和共享领域的组件，但它们没有考虑到负迁移的其他原因。更糟糕的是，我们认为简单的特征分解对于多领域场景是不够的。为了弥补这一差距，我们提出了 TrineCDR，一种针对多目标 CDR 的 TRIple-level 知识可转移性增强模型。与以前的方法不同，TrineCDR 捕获单个域和目标跨域嵌入，以服务于多域推荐。对于后者，我们从微观到宏观的角度找出了负迁移的三个基本原因，并相应地在三个不同的层面上提高了知识的可迁移性: 特征层面、交互层面和领域层面。通过这些努力，TrineCDR 有效地过滤掉源域中的噪声和不相关信息，从而在目标域中实现更全面、更准确的表示。在双目标和多目标情景下，我们对亚马逊和豆瓣采样的真实世界数据集上提出的模型进行了广泛的评估。实验结果表明 TrineCDR 方法优于目前最先进的跨域推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Negative+Transfer+in+Cross-Domain+Recommendation+via+Knowledge+Transferability+Enhancement)|0|
|[Controllable Multi-Behavior Recommendation for In-Game Skins with Large Sequential Model](https://doi.org/10.1145/3637528.3671572)|Yanjie Gou, Yuanzhou Yao, Zhao Zhang, Yiqing Wu, Yi Hu, Fuzhen Zhuang, Jiangming Liu, Yongjun Xu|; Common Data Platform, Tencent, Shenzhen, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Institute of Artificial Intelligence, Beihang University & Zhongguancun Laboratory, Beijing, China; School of Information Science and Engineering, Yunnan University, Kunming, China|Online games often house virtual shops where players can acquire character skins. Our task is centered on tailoring skin recommendations across diverse scenarios by analyzing historical interactions such as clicks, usage, and purchases. Traditional multi-behavior recommendation models employed for this task are limited. They either only predict skins based on a single type of behavior or merely recommend skins for target behavior type/task. These models lack the ability to control predictions of skins that are associated with different scenarios and behaviors. To overcome these limitations, we utilize the pretraining capabilities of Large Sequential Models (LSMs) coupled with a novel stimulus prompt mechanism and build a controllable multi-behavior recommendation (CMBR) model. In our approach, the pretraining ability is used to encapsulate users' multi-behavioral sequences into the representation of users' general interests. Subsequently, our designed stimulus prompt mechanism stimulates the model to extract scenario-related interests, thus generating potential skin purchases (or clicks and other interactions) for users. To the best of our knowledge, this is the first work to provide controlled multi-behavior recommendations, and also the first to apply the pretraining capabilities of LSMs in game domain. Through offline experiments and online A/B tests, we validate our method significantly outperforms baseline models, exhibiting about a tenfold improvement on various metrics during the offline test.|在线游戏通常会有虚拟商店，玩家可以在那里获得角色皮肤。我们的任务是通过分析点击、使用和购买等历史交互，跨不同场景裁剪皮肤推荐。传统的用于此任务的多行为推荐模型是有限的。它们要么只根据单一类型的行为预测皮肤，要么只为目标行为类型/任务推荐皮肤。这些模型缺乏控制与不同场景和行为相关联的皮肤预测的能力。为了克服这些局限性，我们利用大序列模型(LSM)的预训练能力，结合一种新颖的刺激提示机制，建立了一个可控的多行为推荐(CMBR)模型。该方法利用预训练能力将用户的多行为序列封装成用户兴趣的表示。随后，我们设计的刺激提示机制刺激模型以提取场景相关的兴趣，从而为用户产生潜在的皮肤购买(或点击和其他交互)。据我们所知，这是第一个提供可控的多行为建议的工作，也是第一个应用在游戏领域的 LSM 的预训练能力。通过离线实验和在线 A/B 测试，我们验证了我们的方法明显优于基线模型，在离线测试期间在各种指标上表现出大约10倍的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Controllable+Multi-Behavior+Recommendation+for+In-Game+Skins+with+Large+Sequential+Model)|0|
|[Multi-objective Learning to Rank by Model Distillation](https://doi.org/10.1145/3637528.3671597)|Jie Tang, Huiji Gao, Liwei He, Sanjeev Katariya|Airbnb, San Francisco, CA, USA|In online marketplaces, search ranking's objective is not only to purchase or conversion (primary objective), but to also the purchase outcomes(secondary objectives), e.g. order cancellation(or return), review rating, customer service inquiries, platform long term growth. Multi-objective learning to rank has been widely studied to balance primary and secondary objectives. But traditional approaches in industry face some challenges including expensive parameter tuning leads to sub-optimal solution, suffering from imbalanced data sparsity issue, and being not compatible with ad-hoc objective. In this paper, we propose a distillation-based ranking solution for multi-objective ranking, which optimizes the end-to-end ranking system at Airbnb across multiple ranking models on different objectives along with various considerations to optimize training and serving efficiency to meet industry standards. We found it performs much better than traditional approaches, it doesn't only significantly increases primary objective by a large margin but also meet secondary objectives constraints and improve model stability. We also demonstrated the proposed system could be further simplified by model self-distillation. Besides this, we did additional simulations to show that this approach could also help us efficiently inject ad-hoc non-differentiable business objective into the ranking system while enabling us to balance our optimization objectives.|在在线市场中，搜索排名的目标不仅仅是购买或转换(主要目标) ，还包括购买结果(次要目标) ，例如取消订单(或返回) ，评论等级，客户服务查询，平台长期增长。多目标排序学习已被广泛研究，以平衡小学和中学的目标。但是，传统的方法在工业上面临着一些挑战，包括参数调整费用昂贵、数据稀疏性不平衡、与特定目标不兼容等问题。针对多目标排序问题，提出了一种基于精馏的排序方法，该方法在不同目标的多个排序模型上对 Airbnb 的端到端排序系统进行优化，同时考虑各种因素，优化培训和服务效率，以满足行业标准。我们发现它比传统的方法有更好的性能，它不仅大幅度增加了主要目标，而且满足次要目标的约束，提高了模型的稳定性。我们还证明了模型自蒸馏可以进一步简化所提出的体系。除此之外，我们做了额外的模拟，以表明这种方法也可以帮助我们有效地注入临时不可微的业务目标到排名系统，同时使我们能够平衡我们的优化目标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-objective+Learning+to+Rank+by+Model+Distillation)|0|
|[Unified Dual-Intent Translation for Joint Modeling of Search and Recommendation](https://doi.org/10.1145/3637528.3671519)|Yuting Zhang, Yiqing Wu, Ruidong Han, Ying Sun, Yongchun Zhu, Xiang Li, Wei Lin, Fuzhen Zhuang, Zhulin An, Yongjun Xu|; Meituan, Beijing, China; Institute of Artificial Intelligence, Beihang University & Zhongguancun Laboratory, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Recommendation systems, which assist users in discovering their preferred items among numerous options, have served billions of users across various online platforms. Intuitively, users' interactions with items are highly driven by their unchanging inherent intents (e.g., always preferring high-quality items) and changing demand intents (e.g., wanting a T-shirt in summer but a down jacket in winter). However, both types of intents are implicitly expressed in recommendation scenario, posing challenges in leveraging them for accurate intent-aware recommendations. Fortunately, in search scenario, often found alongside recommendation on the same online platform, users express their demand intents explicitly through their query words. Intuitively, in both scenarios, a user shares the same inherent intent and his/her interactions may be influenced by the same demand intent. It is therefore feasible to utilize the interaction data from both scenarios to reinforce the dual intents for joint intent-aware modeling. But the joint modeling should deal with two problems: (1) accurately modeling users' implicit demand intents in recommendation; (2) modeling the relation between the dual intents and the interactive items. To address these problems, we propose a novel model named Unified Dual-Intents Translation for joint modeling of Search and Recommendation (UDITSR). To accurately simulate users' demand intents in recommendation, we utilize real queries from search data as supervision information to guide its generation. To explicitly model the relation among the triplet , we propose a dual-intent translation propagation mechanism to learn the triplet in the same semantic space via embedding translations. Extensive experiments demonstrate that UDITSR outperforms SOTA baselines both in search and recommendation tasks. Moreover, our model has been deployed online on Meituan Waimai platform, leading to an average improvement in GMV (Gross Merchandise Value) of 1.46% and CTR(Click-Through Rate) of 0.77% over one month.|推荐系统帮助用户在众多选项中发现他们喜欢的项目，已经在各种在线平台上为数十亿用户服务。直觉上，用户与物品的互动高度受到他们不变的内在意图(例如，总是喜欢高质量的物品)和不断变化的需求意图(例如，夏天想要一件 T 恤，冬天想要一件羽绒服)的驱动。然而，这两种类型的意图都隐式地在推荐场景中表达，在利用它们获得准确的意图感知建议方面提出了挑战。幸运的是，在搜索场景中，用户通过他们的查询词明确地表达他们的需求意图，这种情况经常在同一个在线平台的推荐旁边发现。直观地说，在这两种情况下，用户共享相同的内在意图，他/她的交互可能受到相同的需求意图的影响。因此，利用来自两个场景的交互数据来加强联合意图感知建模的双重意图是可行的。但是联合建模需要解决两个问题: (1)准确地建立推荐中用户隐含需求意图的模型; (2)建立双重意图与交互项目之间的关系模型。针对这些问题，本文提出了一种新的联合建模模型——统一双意图翻译模型(UDITSR)。为了准确地模拟推荐中用户的需求意图，我们利用搜索数据中的实际查询作为监督信息来指导推荐的生成。为了明确地模拟三联体之间的关系，我们提出了一种双意图翻译传播机制，通过嵌入翻译来学习同一语义空间中的三联体。大量的实验表明，UDITSR 在搜索和推荐任务中都优于 SOTA 基线。此外，我们的模型已经在 Waimai 的美团平台上使用，导致一个月内平均商品总值(GMV)提高了1.46% ，点击率(点进率)提高了0.77% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Dual-Intent+Translation+for+Joint+Modeling+of+Search+and+Recommendation)|0|
|[Shopping Trajectory Representation Learning with Pre-training for E-commerce Customer Understanding and Recommendation](https://doi.org/10.1145/3637528.3671747)|Yankai Chen, QuocTuan Truong, Xin Shen, Jin Li, Irwin King|Amazon, Seattle, WA, USA; The Chinese University of Hong Kong, Hong Kong, China|Understanding customer behavior is crucial for improving service quality in large-scale E-commerce. This paper proposes C-STAR, a new framework that learns compact representations from customer shopping journeys, with good versatility to fuel multiple downstream customer-centric tasks. We define the notion of shopping trajectory that encompasses customer interactions at the level of product categories, capturing the overall flow of their browsing and purchase activities. C-STAR excels at modeling both inter-trajectory distribution similarity-the structural similarities between different trajectories, and intra-trajectory semantic correlation-the semantic relationships within individual ones. This coarse-to-fine approach ensures informative trajectory embeddings for representing customers. To enhance embedding quality, we introduce a pre-training strategy that captures two intrinsic properties within the pre-training data. Extensive evaluation on large-scale industrial and public datasets demonstrates the effectiveness of C-STAR across three diverse customer-centric tasks. These tasks empower customer profiling and recommendation services for enhancing personalized shopping experiences on our E-commerce platform.|了解顾客行为是提高大规模电子商务服务质量的关键。本文提出了一个新的框架 C-STAR，它从顾客购物旅程中学习紧凑的表示，具有良好的通用性，可以为多个下游顾客中心任务提供支持。我们定义了购物轨迹的概念，它包含了产品类别层面的客户交互，捕捉了他们浏览和购买活动的总体流程。C-STAR 在建立轨迹间分布相似性(不同轨迹之间的结构相似性)和轨迹内语义相关性(各个轨迹之间的语义关系)两方面都表现出色。这种从粗到细的方法确保为代表客户嵌入信息轨迹。为了提高嵌入质量，我们引入了一种预训练策略，捕获预训练数据的两个内在属性。对大规模工业和公共数据集的广泛评估证明了 C-STAR 在三种不同的以客户为中心的任务中的有效性。这些任务授权客户档案和推荐服务，以提高我们的电子商务平台上的个性化购物体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shopping+Trajectory+Representation+Learning+with+Pre-training+for+E-commerce+Customer+Understanding+and+Recommendation)|0|
|[DIET: Customized Slimming for Incompatible Networks in Sequential Recommendation](https://doi.org/10.1145/3637528.3671669)|Kairui Fu, Shengyu Zhang, Zheqi Lv, Jingyuan Chen, Jiwei Li|Zhejiang University, Hangzhou, China; Zhejiang University & Shanghai Institute for Advanced Study of Zhejiang University, Hangzhou, China|Due to the continuously improving capabilities of mobile edges, recommendersystems start to deploy models on edges to alleviate network congestion causedby frequent mobile requests. Several studies have leveraged the proximity ofedge-side to real-time data, fine-tuning them to create edge-specific models.Despite their significant progress, these methods require substantial on-edgecomputational resources and frequent network transfers to keep the model up todate. The former may disrupt other processes on the edge to acquirecomputational resources, while the latter consumes network bandwidth, leadingto a decrease in user satisfaction. In response to these challenges, we proposea customizeD slImming framework for incompatiblE neTworks(DIET). DIET deploysthe same generic backbone (potentially incompatible for a specific edge) to alldevices. To minimize frequent bandwidth usage and storage consumption inpersonalization, DIET tailors specific subnets for each edge based on its pastinteractions, learning to generate slimming subnets(diets) within incompatiblenetworks for efficient transfer. It also takes the inter-layer relationshipsinto account, empirically reducing inference time while obtaining more suitablediets. We further explore the repeated modules within networks and propose amore storage-efficient framework, DIETING, which utilizes a single layer ofparameters to represent the entire network, achieving comparably excellentperformance. The experiments across four state-of-the-art datasets and twowidely used models demonstrate the superior accuracy in recommendation andefficiency in transmission and storage of our framework.|由于移动边缘功能的不断改进，推荐系统开始在边缘部署模型，以缓解频繁的移动请求造成的拥塞控制。一些研究已经利用边缘接近实时数据，微调它们以创建边缘特定的模型。尽管这些方法取得了显著的进展，但它们需要大量的边缘计算资源和频繁的网络传输来保持模型的最新性。前者可能破坏边缘的其他进程以获取计算资源，而后者消耗网络带宽，导致用户满意度下降。为了应对这些挑战，我们提出了针对不兼容网络(DIET)的定制减肥框架。DIET 为所有设备部署相同的通用主干网(对于特定的边缘可能不兼容)。为了尽量减少频繁的带宽使用和个性化存储消耗，DIET 根据其过去的相互作用为每个边裁剪特定的子网，学习在不兼容的网络中生成减肥子网(饮食)以便有效地传输。它还考虑到层间关系，通过实验减少推断时间，同时获得更合适的饮食。我们进一步探讨了网络中的重复模块，并提出了一种存储效率更高的框架—— DIETING，它利用一个单一的参数层来表示整个网络，取得了较好的性能。通过四个最先进的数据集和两个广泛使用的模型进行的实验表明，我们的框架在传输和存储方面具有优越的推荐准确性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIET:+Customized+Slimming+for+Incompatible+Networks+in+Sequential+Recommendation)|0|
|[Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System](https://doi.org/10.1145/3637528.3671931)|Sein Kim, Hongseok Kang, Seungyoon Choi, Donghyun Kim, MinChul Yang, Chanyoung Park|NAVER Corporation, Seongnam, Republic of Korea; KAIST, Daejeon, Republic of Korea|Collaborative filtering recommender systems (CF-RecSys) have shown successiveresults in enhancing the user experience on social media and e-commerceplatforms. However, as CF-RecSys struggles under cold scenarios with sparseuser-item interactions, recent strategies have focused on leveraging modalityinformation of user/items (e.g., text or images) based on pre-trained modalityencoders and Large Language Models (LLMs). Despite their effectiveness undercold scenarios, we observe that they underperform simple traditionalcollaborative filtering models under warm scenarios due to the lack ofcollaborative knowledge. In this work, we propose an efficient All-roundLLM-based Recommender system, called A-LLMRec, that excels not only in the coldscenario but also in the warm scenario. Our main idea is to enable an LLM todirectly leverage the collaborative knowledge contained in a pre-trainedstate-of-the-art CF-RecSys so that the emergent ability of the LLM as well asthe high-quality user/item embeddings that are already trained by thestate-of-the-art CF-RecSys can be jointly exploited. This approach yields twoadvantages: (1) model-agnostic, allowing for integration with various existingCF-RecSys, and (2) efficiency, eliminating the extensive fine-tuning typicallyrequired for LLM-based recommenders. Our extensive experiments on variousreal-world datasets demonstrate the superiority of A-LLMRec in variousscenarios, including cold/warm, few-shot, cold user, and cross-domainscenarios. Beyond the recommendation task, we also show the potential ofA-LLMRec in generating natural language outputs based on the understanding ofthe collaborative knowledge by performing a favorite genre prediction task. Ourcode is available at https://github.com/ghdtjr/A-LLMRec .|协同过滤推荐系统(CF-recsys)在增强社交媒体和电子商务平台的用户体验方面取得了成功。然而，由于 CF-RecSys 在冷场景下与稀疏用户-项目交互的斗争，最近的策略集中在基于预先训练的 modalityencoders 和 Large Language Model (LLM)利用用户/项目(例如文本或图像)的模态信息。尽管它们在低温情景下有效，但是我们观察到，由于缺乏协作知识，它们在温暖情景下表现不如传统的简单协作过滤模型。在这项工作中，我们提出了一个高效的基于全局 LLM 的推荐系统，称为 A-LLmrec，它不仅在冷场景中表现出色，而且在暖场景中也表现出色。我们的主要想法是使 LLM 能够直接利用包含在预先培训的最先进的 CF-RecSys 中的协作知识，以便 LLM 的应急能力以及已经由最先进的 CF-RecSys 培训的高质量用户/项目嵌入能够被共同利用。这种方法有两个优点: (1)模型无关，允许与各种现有的 CF-RecSys 集成; (2)效率，消除了基于 LLM 的推荐程序通常需要的广泛的微调。我们在各种真实世界数据集上的广泛实验证明了 A-LLMRec 在各种场景下的优越性，包括冷/温、少拍摄、冷用户和跨域场景。除了推荐任务，我们还展示了 A-LLMRec 的潜力，通过执行一个喜欢的体裁预测任务，基于对协作知识的理解来生成自然语言输出。我们的代码可以在 https://github.com/ghdtjr/a-llmrec 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+meet+Collaborative+Filtering:+An+Efficient+All-round+LLM-based+Recommender+System)|0|
|[Probabilistic Attention for Sequential Recommendation](https://doi.org/10.1145/3637528.3671733)|Yuli Liu, Christian Walder, Lexing Xie, Yiqun Liu|; Australian National University & Data61 CSIRO, Canberra, Australia; Google Research, Brain Team, Montreal, Canada|Sequential Recommendation (SR) navigates users' dynamic preferences through modeling their historical interactions. The incorporation of the popular Transformer framework, which captures long relationships through pairwise dot products, has notably benefited SR. However, prevailing research in this domain faces three significant challenges: (i) Existing studies directly adopt the primary component of Transformer (i.e., the self-attention mechanism), without a clear explanation or tailored definition for its specific role in SR; (ii) The predominant focus on pairwise computations overlooks the global context or relative prevalence of item pairs within the overall sequence; (iii) Transformer primarily pursues relevance-dominated relationships, neglecting another essential objective in recommendation, i.e., diversity. In response, this work introduces a fresh perspective to elucidate the attention mechanism in SR. Here, attention is defined as dependency interactions among items, quantitatively determined under a global probabilistic model by observing the probabilities of corresponding item subsets. This viewpoint offers a precise and context-specific definition of attention, leading to the design of a distinctive attention mechanism tailored for SR. Specifically, we transmute the well-formulated global, repulsive interactions in Determinantal Point Processes (DPPs) to effectively model dependency interactions. Guided by the repulsive interactions, a theoretically and practically feasible DPP kernel is designed, enabling our attention mechanism to directly consider category/topic distribution for enhancing diversity. Consequently, the Probabilistic Attention mechanism (PAtt) for sequential recommendation is developed. Experimental results demonstrate the excellent scalability and adaptability of our attention mechanism, which significantly improves recommendation performance in terms of both relevance and diversity.|顺序推荐(SR)通过建模用户的历史交互来导航用户的动态偏好。通过成对点产品捕获长关系的流行的 Transformer 框架的结合，使 SR 受益匪浅。然而，这个领域的主流研究面临三个重大挑战: (i)现有的研究直接采用 Transformer 的主要组成部分(即自我注意机制) ，没有明确的解释或量身定制的定义其在 SR 中的具体作用; (ii)成对计算的主要重点忽视了整体序列中项目对的全局上下文或相对流行程度; (iii) Transformer 主要追求相关性主导的关系，忽视了推荐中的另一个基本目标，即多样性。作为回应，本文引入了一个新的视角来阐明注意机制。这里，注意被定义为项目之间的依赖交互作用，在全局概率模型下通过观察相应项目子集的概率来定量确定。这一观点提供了一个精确的和具体的上下文关注的定义，导致了一个独特的注意机制的设计专门为 SR。具体来说，我们转换了确定性点过程(DPP)中的良好制定的全局排斥交互作用，以有效地建模依赖交互作用。在排斥交互作用的指导下，设计了一个理论上和实际上可行的 DPP 核，使我们的注意机制能够直接考虑类别/主题分布，从而增强多样性。为此，提出了序贯推荐的概率注意机制。实验结果表明，该注意机制具有良好的可扩展性和适应性，在相关性和多样性方面显著提高了推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Probabilistic+Attention+for+Sequential+Recommendation)|0|
|[Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations](https://doi.org/10.1145/3637528.3671743)|Jing Long, Guanhua Ye, Tong Chen, Yang Wang, Meng Wang, Hongzhi Yin|Hefei University of Technology, Hefei, China; Beijing University of Posts and Telecommunications, BeiJing, China; The University of Queensland, Brisbane, Australia|The rapid expansion of Location-Based Social Networks (LBSNs) has highlightedthe importance of effective next Point-of-Interest (POI) recommendations, whichleverage historical check-in data to predict users' next POIs to visit.Traditional centralized deep neural networks (DNNs) offer impressive POIrecommendation performance but face challenges due to privacy concerns andlimited timeliness. In response, on-device POI recommendations have beenintroduced, utilizing federated learning (FL) and decentralized approaches toensure privacy and recommendation timeliness. However, these methods oftensuffer from computational strain on devices and struggle to adapt to new usersand regions. This paper introduces a novel collaborative learning framework,Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POIRecommendations (DCPR), leveraging the diffusion model known for its successacross various domains. DCPR operates with a cloud-edge-device architecture tooffer region-specific and highly personalized POI recommendations whilereducing on-device computational burdens. DCPR minimizes on-devicecomputational demands through a unique blend of global and local learningprocesses. Our evaluation with two real-world datasets demonstrates DCPR'ssuperior performance in recommendation accuracy, efficiency, and adaptabilityto new users and regions, marking a significant step forward in on-device POIrecommendation technology.|基于位置的社交网络(LBSNs)的快速扩张突出了有效的下一个兴趣点(POI)建议的重要性，这些建议利用历史签入数据来预测用户下一个访问的 POI。传统的集中式深层神经网络(DNN)提供了令人印象深刻的 POI 推荐性能，但由于隐私问题和有限的时间面临挑战。作为回应，在设备上的 POI 推荐已经被引入，利用联邦学习(FL)和分散的方法来确保隐私和推荐的及时性。然而，这些方法经常受到设备计算压力的影响，难以适应新的用户和地区。本文介绍了一个新的合作学习框架，基于扩散的云端设备合作学习，用于下一个 POI 建议(DCPR) ，利用扩散模型在各个领域的成功。DCPR 采用云端设备架构，可以提供区域特定的高度个性化的 POI 建议，同时减少设备上的计算负担。DCPR 通过独特的全球和本地学习过程的混合，最大限度地减少了设备上的计算需求。我们用两个真实世界的数据集进行的评估表明，DCPR 在推荐准确性、效率以及对新用户和地区的适应性方面具有优越的性能，这标志着在设备 POI 推荐技术方面向前迈进了一大步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion-Based+Cloud-Edge-Device+Collaborative+Learning+for+Next+POI+Recommendations)|0|
|[Certified Robustness on Visual Graph Matching via Searching Optimal Smoothing Range](https://doi.org/10.1145/3637528.3671852)|Huaqing Shao, Lanjun Wang, Yongwei Wang, Qibing Ren, Junchi Yan|Department of CSE, Shanghai Jiao Tong University, Shanghai, China; SNMC, Tianjin University, Tianjin, China; Department of CSE and MoE Key Lab of AI, Shanghai Jiao Tong University, Shanghai, China; School of AI and Department of CSE, Shanghai Jiao Tong University, Shanghai, China; SIAS and College of Computer Science, Zhejiang University, Hangzhou, China|Deep visual graph matching (GM) is a challenging combinatorial task that involves finding a permutation matrix that indicates the correspondence between keypoints from a pair of images. Like many learning systems, empirical studies have shown that visual GM is susceptible to adversarial attacks, with reliability issues in downstream applications. To the best of our knowledge, certifying robustness for deep visual GM remains an open challenge with two main difficulties: how to handle the paired inputs together with the heavily non-linear permutation output space (especially at large scale), and how to balance the trade-off between certified robustness and matching performance. Inspired by the randomized smoothing (RS) technique, we propose the Certified Robustness based on the Optimal Smoothing Range Search (CR-OSRS) technique to fulfill the robustness guarantee for deep visual GM. First, unlike conventional RS methods that use isotropic Gaussian distributions for smoothing, we build the smoothed model with paired joint Gaussian distributions, which capture the structural information among keypoints, and mitigate the performance degradation caused by smoothing. For the vast space of the permutation output, we devise a similarity-based partitioning method that can lower the computational complexity and certification difficulty. We then derive a stringent robustness guarantee that links the certified space of inputs to their corresponding fixed outputs. Second, we design a global optimization method to search for optimal joint Gaussian distributions and facilitate a larger certified space and better performance. Third, we apply data augmentation and a similarity-based regularizer in training to enhance smoothed model performance. Lastly, for the high-dimensional and multivariable nature of the certified space, we propose two methods (sampling and marginal radii) to evaluate it. Experimental results on public benchmarks show that our method achieves state-of-the-art certified robustness.|深度视觉图形匹配(GM)是一项具有挑战性的组合任务，包括从一对图像中找到一个指示关键点之间对应关系的置换矩阵。与许多学习系统一样，经验研究表明，视觉 GM 易受敌对攻击，在下游应用中存在可靠性问题。据我们所知，深度视觉 GM 的鲁棒性认证仍然是一个公开的挑战，有两个主要的困难: 如何处理配对输入和严重的非线性排列输出空间(特别是在大规模) ，以及如何平衡之间的权衡认证鲁棒性和匹配性能。受随机平滑(RS)技术的启发，我们提出了基于最优平滑范围搜索(CR-OSRS)技术的认证鲁棒性，以实现深层视觉 GM 的鲁棒性保证。首先，不同于传统的 RS 方法使用各向同性高斯分布进行平滑，我们建立了平滑模型与配对联合高斯分布，捕捉关键点之间的结构信息，并减轻平滑造成的性能下降。针对排列输出的巨大空间，提出了一种基于相似度的划分方法，降低了计算复杂度和认证难度。然后，我们推导出一个严格的鲁棒性保证，将经过验证的输入空间与它们相应的固定输出联系起来。其次，我们设计了一个全局优化方法来寻找最佳的联合高斯分布，使得更大的认证空间和更好的性能。第三，在训练中应用数据增强和基于相似性的正则化方法来提高平滑模型的性能。最后，针对证明空间的高维性和多变量性，提出了两种评价方法(抽样法和边缘半径法)。对公共基准测试的实验结果表明，该方法具有较好的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Certified+Robustness+on+Visual+Graph+Matching+via+Searching+Optimal+Smoothing+Range)|0|
|[Pre-Training with Transferable Attention for Addressing Market Shifts in Cross-Market Sequential Recommendation](https://doi.org/10.1145/3637528.3671698)|Chen Wang, Ziwei Fan, Liangwei Yang, Mingdai Yang, Xiaolong Liu, Zhiwei Liu, Philip S. Yu|Tsinghua University, Beijing, China; Amazon, Santa Clara, CA, USA; The University of Chicago, Chicago, IL, USA; University of Illinois Chicago, Chicago, IL, USA; Salesforce AI Research, Palo Alto, CA, USA|Cross-market recommendation (CMR) involves selling the same set of items across multiple nations or regions within a transfer learning framework. However, CMR's distinctive characteristics, including limited data sharing due to privacy policies, absence of user overlap, and a shared item set between markets present challenges for traditional recommendation methods. Moreover, CMR experiences market shifts, leading to differences in item popularity and user preferences among different markets. This study focuses on cross-market sequential recommendation (CMSR) and proposes the Cross-market Attention Transferring with Sequential Recommendation (CAT-SR) framework to address these challenges and market shifts. CAT-SR incorporates a pre-training strategy emphasizing item-item correlation, selective self-attention transferring for effective transfer learning, and query and key adapters for market-specific user preferences. Experimental results on real-world cross-market datasets demonstrate the superiority of CAT-SR, and ablation studies validate the benefits of its components across different geographical continents. CAT-SR offers a robust and adaptable solution for cross-market sequential recommendation. The code is available at https://github.com/ChenMetanoia/CATSR-KDD/.|跨市场推荐(CMR)涉及在一个迁移学习框架内在多个国家或地区销售同一套产品。然而，CMR 的显著特点，包括由于隐私政策导致的有限数据共享、用户重叠的缺失以及市场之间的共享项目集，对传统的推荐方法提出了挑战。此外，CMR 经历了市场变化，导致不同市场之间的产品流行度和用户偏好的差异。本研究以跨市场序贯推荐(CMSR)为研究对象，提出了基于序贯推荐的跨市场注意力转移(CAT-SR)框架，以解决这些挑战和市场转移问题。CAT-SR 包括一个强调项目-项目相关性的预训练策略，选择性自我注意转移以有效转移学习，以及针对特定市场用户偏好的查询和关键适配器。在现实世界跨市场数据集上的实验结果证明了 CAT-SR 的优越性，并且消融研究验证了其组件在不同地理大陆上的优势。CAT-SR 为跨市场连续推荐提供了一个健壮的、适应性强的解决方案。密码可在 https://github.com/chenmetanoia/catsr-kdd/查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-Training+with+Transferable+Attention+for+Addressing+Market+Shifts+in+Cross-Market+Sequential+Recommendation)|0|
|[Dataset Regeneration for Sequential Recommendation](https://doi.org/10.1145/3637528.3671841)|Mingjia Yin, Hao Wang, Wei Guo, Yong Liu, Suojuan Zhang, Sirui Zhao, Defu Lian, Enhong Chen|; Huawei Singapore Research Center, Singapore, Singapore|The sequential recommender (SR) system is a crucial component of modern recommender systems, as it aims to capture the evolving preferences of users. Significant efforts have been made to enhance the capabilities of SR systems. These methods typically follow the model-centric paradigm, which involves developing effective models based on fixed datasets. However, this approach often overlooks potential quality issues and flaws inherent in the data. Driven by the potential of data-centric AI, we propose a novel data-centric paradigm for developing an ideal training dataset using a model-agnostic dataset regeneration framework called DR4SR. This framework enables the regeneration of a dataset with exceptional cross-architecture generalizability. Additionally, we introduce the DR4SR+ framework, which incorporates a model-aware dataset personalizer to tailor the regenerated dataset specifically for a target model. To demonstrate the effectiveness of the data-centric paradigm, we integrate our framework with various model-centric methods and observe significant performance improvements across four widely adopted datasets. Furthermore, we conduct in-depth analyses to explore the potential of the data-centric paradigm and provide valuable insights. The code can be found at https://github.com/USTC-StarTeam/DR4SR.|顺序推荐(SR)系统是现代推荐系统的重要组成部分，因为它旨在捕获用户不断变化的偏好。为提高 SR 系统的性能已经做出了重大努力。这些方法通常遵循以模型为中心的范式，其中包括基于固定数据集开发有效的模型。然而，这种方法常常忽略数据中潜在的质量问题和固有缺陷。在以数据为中心的人工智能的潜力驱动下，我们提出了一种新的以数据为中心的范式，用于开发一个理想的训练数据集，使用一个模型无关的数据集再生框架 DR4SR。这个框架使得数据集的再生具有异常的跨架构通用性。此外，我们还介绍了 DR4SR + 框架，该框架结合了一个模型感知的数据集个性化工具，可以专门为目标模型定制重新生成的数据集。为了证明以数据为中心的范式的有效性，我们将我们的框架与各种以模型为中心的方法集成在一起，并观察四个广泛采用的数据集的显著性能改进。此外，我们进行深入的分析，以探索潜在的数据为中心的范式，并提供有价值的见解。密码可以在 https://github.com/ustc-starteam/dr4sr 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dataset+Regeneration+for+Sequential+Recommendation)|0|
|[GPFedRec: Graph-Guided Personalization for Federated Recommendation](https://doi.org/10.1145/3637528.3671702)|Chunxu Zhang, Guodong Long, Tianyi Zhou, Zijian Zhang, Peng Yan, Bo Yang|; Computer Science and UMIACS, University of Maryland, Maryland, USA|The federated recommendation system is an emerging AI service architecture that provides recommendation services in a privacy-preserving manner. Using user-relation graphs to enhance federated recommendations is a promising topic. However, it is still an open challenge to construct the user-relation graph while preserving data locality-based privacy protection in federated settings. Inspired by a simple motivation, similar users share a similar vision (embeddings) to the same item set, this paper proposes a novel Graph-guided Personalization for Federated Recommendation (GPFedRec). The proposed method constructs a user-relation graph from user-specific personalized item embeddings at the server without accessing the users' interaction records. The personalized item embedding is locally fine-tuned on each device, and then a user-relation graph will be constructed by measuring the similarity among client-specific item embeddings. Without accessing users' historical interactions, we embody the data locality-based privacy protection of vanilla federated learning. Furthermore, a graph-guided aggregation mechanism is designed to leverage the user-relation graph and federated optimization framework simultaneously. Extensive experiments on five benchmark datasets demonstrate GPFedRec's superior performance. The in-depth study validates that GPFedRec can generally improve existing federated recommendation methods as a plugin while keeping user privacy safe. Code is available https://github.com/Zhangcx19/GPFedRec|联邦推荐系统是一种新兴的人工智能服务架构，它以保护隐私的方式提供推荐服务。使用用户关系图来增强联邦推荐是一个很有前途的课题。然而，在联邦环境中保护基于数据位置的隐私保护的同时构建用户关系图仍然是一个公开的挑战。受简单动机的启发，相似用户对同一条目集有着相似的愿景(嵌入) ，本文提出了一种新的基于图的联邦推荐个性化(GPFedRec)方法。该方法在不访问用户交互记录的情况下，通过在服务器上嵌入用户特定的个性化项目来构造用户关系图。在每个设备上对个性化项目嵌入进行局部微调，然后通过测量客户特定项目嵌入之间的相似度来构造用户关系图。在不访问用户历史交互的情况下，体现了基于数据位置的普通联邦学习的隐私保护。此外，设计了一种图引导的聚合机制，同时利用用户关系图和联邦优化框架。在五个基准数据集上的大量实验证明了 GPFedRec 的优越性能。深入的研究证实，GPFedRec 可以作为一个插件改进现有的联邦推荐方法，同时保护用户隐私安全。密码 https://github.com/zhangcx19/gpfedrec|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GPFedRec:+Graph-Guided+Personalization+for+Federated+Recommendation)|0|
|[GradCraft: Elevating Multi-task Recommendations through Holistic Gradient Crafting](https://doi.org/10.1145/3637528.3671585)|Yimeng Bai, Yang Zhang, Fuli Feng, Jing Lu, Xiaoxue Zang, Chenyi Lei, Yang Song|University of Science and Technology of China, Hefei, China; Kuaishou Technology, Beijing, China; University of Science and Technology of China & USTC Beijing Research Institute, Hefei, China|Recommender systems require the simultaneous optimization of multiple objectives to accurately model user interests, necessitating the application of multi-task learning methods. However, existing multi-task learning methods in recommendations overlook the specific characteristics of recommendation scenarios, falling short in achieving proper gradient balance. To address this challenge, we set the target of multi-task learning as attaining the appropriate magnitude balance and the global direction balance, and propose an innovative methodology named GradCraft in response. GradCraft dynamically adjusts gradient magnitudes to align with the maximum gradient norm, mitigating interference from gradient magnitudes for subsequent manipulation. It then employs projections to eliminate gradient conflicts in directions while considering all conflicting tasks simultaneously, theoretically guaranteeing the global resolution of direction conflicts. GradCraft ensures the concurrent achievement of appropriate magnitude balance and global direction balance, aligning with the inherent characteristics of recommendation scenarios. Both offline and online experiments attest to the efficacy of GradCraft in enhancing multi-task performance in recommendations. The source code for GradCraft can be accessed at https://github.com/baiyimeng/GradCraft.|推荐系统需要同时对多个目标进行优化，以准确地建立用户兴趣模型，这就需要应用多任务学习方法。然而，现有的多任务推荐学习方法忽视了推荐场景的特殊性，未能实现适当的梯度平衡。为了应对这一挑战，我们将多任务学习的目标设定为实现适当的量级平衡和全局方向平衡，并提出了一种名为“毕业设计”的创新方法。梯度工艺动态调整梯度大小，以符合最大梯度范数，减少干扰梯度大小，以便随后的操作。然后利用预测消除方向梯度冲突，同时考虑所有冲突任务，从理论上保证了方向冲突的全局解决。Gracraft 确保同时实现适当的规模平衡和全球方向平衡，与建议方案的固有特点保持一致。线下和线上的实验都证明了 GradCraft 在提高推荐中的多任务表现方面的有效性。你可透过 https://github.com/baiyimeng/GradCraft 查阅葛拉夫特的源代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GradCraft:+Elevating+Multi-task+Recommendations+through+Holistic+Gradient+Crafting)|0|
|[NudgeRank: Digital Algorithmic Nudging for Personalized Health](https://doi.org/10.1145/3637528.3671562)|Jodi Chiam, Aloysius Lim, Ankur Teredesai|CueZen, Inc., Singapore, Singapore; CueZen, Inc. & University of Washington, Seattle, WA, USA|In this paper we describe NudgeRankTM, an innovative digital algorithmic nudging system designed to foster positive health behaviors on a population-wide scale. Utilizing a novel combination of Graph Neural Networks augmented with an extensible Knowledge Graph, this Recommender System is operational in production, delivering personalized and context-aware nudges to over 1.1 million care recipients daily. This enterprise deployment marks one of the largest AI-driven health behavior change initiatives, accommodating diverse health conditions and wearable devices. Rigorous evaluation reveals statistically significant improvements in health outcomes, including a 6.17% increase in daily steps and 7.61% more exercise minutes. Moreover, user engagement and program enrollment surged, with a 13.1% open rate compared to baseline systems' 4%. Demonstrating scalability and reliability, NudgeRankTM operates efficiently on commodity compute resources while maintaining automation and observability standards essential for production systems.|在本文中，我们描述了 NudgeRankTM，一个创新的数字算法推动系统，旨在培养积极的健康行为在全人口范围内。利用图形神经网络与可扩展的知识图表相结合的新颖组合，这个推荐系统在生产中运作，每天向超过110万名护理接受者提供个性化和上下文感知的推动。这个企业部署标志着一个最大的人工智能驱动的健康行为改变倡议，适应不同的健康条件和可穿戴设备。严格的评估显示，健康结果在统计学上有显著的改善，包括每日步数增加6.17% ，运动时间增加7.61% 。此外，用户参与度和程序注册率也大幅上升，开放率为13.1% ，而基准系统的开放率为4% 。NudgeRankTM 展示了可伸缩性和可靠性，它可以有效地运行商品计算资源，同时维护生产系统必不可少的自动化和可观测性标准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NudgeRank:+Digital+Algorithmic+Nudging+for+Personalized+Health)|0|
|[Achieving a Better Tradeoff in Multi-stage Recommender Systems through Personalization](https://doi.org/10.1145/3637528.3671593)|Ariel Evnine, Stratis Ioannidis, Dimitris Kalimeris, Shankar Kalyanaraman, Weiwei Li, Israel Nir, Wei Sun, Udi Weinsberg|Northeastern University, Boston, MA, USA; Meta, Menlo Park, CA, USA|Recommender systems in social media websites provide value to their communities by recommending engaging content and meaningful connections. Scaling high-quality recommendations to billions of users in real-time requires sophisticated ranking models operating on a vast number of potential items to recommend, becoming prohibitively expensive computationally. A common technique "funnels'' these items through progressively complex models ("multi-stage''), each ranking fewer items but at higher computational cost for greater accuracy. This architecture introduces a trade-off between the cost of ranking items and providing users with the best recommendations. A key observation we make in this paper is that, all else equal, ranking more items indeed improves the overall objective but has diminishing returns. Following this observation, we provide a rigorous formulation through the framework of DR-submodularity, and argue that for a certain class of objectives (reward functions), it is possible to improve the trade-off between performance and computational cost in multi-stage ranking systems with strong theoretical guarantees. We show that this class of reward functions that provide this guarantee is large and robust to various noise models. Finally, we describe extensive experimentation of our method on three real-world recommender systems in Facebook, achieving 8.8% reduction in overall compute resources with no significant impact on recommendation quality, compared to a 0.8% quality loss in a non-personalized budget allocation.|社交媒体网站的推荐系统通过推荐参与内容和有意义的联系，为社区提供价值。实时将高质量推荐扩展到数十亿用户需要对大量潜在项目进行复杂的排名模型，计算成本高得令人望而却步。一种常见的技术是通过逐步复杂的模型(“多阶段”)“漏斗”这些项目，每个项目的排名较少，但计算成本较高，以获得更高的准确性。这种体系结构在对项目排序的成本和为用户提供最佳建议之间进行了权衡。我们在本文中的一个关键观察结果是，在其他条件相同的情况下，对更多项目进行排序确实会提高整体目标，但具有报酬递减。在此基础上，我们通过 DR- 子模块化的框架提供了一个严格的公式，并认为对于一定类型的目标(奖励函数) ，在具有强理论保证的多阶段排序系统中，可以改善性能和计算成本之间的权衡。我们证明了这类提供这种保证的奖励函数对各种噪声模型是大的和鲁棒的。最后，我们描述了我们的方法在 Facebook 的三个现实世界推荐系统上的广泛实验，实现了总体计算资源减少8.8% ，对推荐质量没有显着影响，而非个性化预算分配中的质量损失为0.8% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Achieving+a+Better+Tradeoff+in+Multi-stage+Recommender+Systems+through+Personalization)|0|
|[Residual Multi-Task Learner for Applied Ranking](https://doi.org/10.1145/3637528.3671523)|Cong Fu, Kun Wang, Jiahua Wu, Yizhou Chen, Guangda Huzhang, Yabo Ni, Anxiang Zeng, Zhiming Zhou|Nanyang Technological University, Singapore, Singapore; Shopee Pte. Ltd., Shanghai, China; Shopee Pte. Ltd., Singapore, Singapore; ECONCS, Shanghai University of Finance and Economics, Shanghai, China; SCSE, Nanyang Technological University, Singapore, Singapore|Modern e-commerce platforms rely heavily on modeling diverse user feedback to provide personalized services. Consequently, multi-task learning has become an integral part of their ranking systems. However, existing multi-task learning methods encounter two main challenges: some lack explicit modeling of task relationships, resulting in inferior performance, while others have limited applicability due to being computationally intensive, having scalability issues, or relying on strong assumptions. To address these limitations and better fit our real-world scenario, pre-rank in Shopee Search, we introduce in this paper ResFlow, a lightweight multi-task learning framework that enables efficient cross-task information sharing via residual connections between corresponding layers of task networks. Extensive experiments on datasets from various scenarios and modalities demonstrate its superior performance and adaptability over state-of-the-art methods. The online A/B tests in Shopee Search showcase its practical value in large-scale industrial applications, evidenced by a 1.29% increase in OPU (order-per-user) without additional system latency. ResFlow is now fully deployed in the pre-rank module of Shopee Search. To facilitate efficient online deployment, we propose a novel offline metric Weighted Recall@K, which aligns well with our online metric OPU, addressing the longstanding online-offline metric misalignment issue. Besides, we propose to fuse scores from the multiple tasks additively when ranking items, which outperforms traditional multiplicative fusion.|现代电子商务平台在很大程度上依赖于建模不同的用户反馈来提供个性化服务。因此，多任务学习已成为其排名系统的一个组成部分。然而，现有的多任务学习方法遇到了两个主要的挑战: 一些方法缺乏对任务关系的明确建模，导致性能较差，而另一些方法由于计算密集、存在可伸缩性问题或依赖于强大的假设而适用性有限。为了解决这些局限性，并更好地适应我们的现实世界场景，在 Shopee 搜索中的预排序，本文介绍了 ResFlow，一个轻量级的多任务学习框架，使得有效的跨任务信息共享通过相应的任务网络层之间的剩余连接。对来自不同场景和模式的数据集进行的大量实验表明，它比最先进的方法具有更好的性能和适应性。Shopee Search 的在线 A/B 测试展示了其在大规模工业应用中的实用价值，在不增加系统延迟的情况下，OPU (每用户订单)增长了1.29% 。ResFlow 现在完全部署在 Shopee Search 的 pre-rank 模块中。为了促进有效的在线部署，我们提出了一种新的离线度量加权召回@K，它与我们的在线度量 OPU 很好地一致，解决了长期存在的在线-离线度量失调问题。此外，本文还提出了在项目排序时对多个任务的得分进行累加融合，这种融合方法的性能优于传统的乘法融合方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Residual+Multi-Task+Learner+for+Applied+Ranking)|0|
|[Multi-task Conditional Attention Network for Conversion Prediction in Logistics Advertising](https://doi.org/10.1145/3637528.3671549)|Baoshen Guo, Xining Song, Shuai Wang, Wei Gong, Tian He, Xue Liu|University of Science and Technology of China, Hefei, China; Southeast University, Nanjing, China; McGill University, Montréal, Canada; Southeast University & JD Logistics, Nanjing, China; JD Logistics, Beijing, China|Logistics advertising is an emerging task in online-to-offline logistics systems, where logistics companies expand parcel shipping services to new users through advertisements on shopping websites. Compared to existing online e-commerce advertising, logistics advertising has two significant new characteristics: (i) the complex factors in logistics advertising considering both users' offline logistics preference and online purchasing profiles; and (ii) data sparsity and mutual relations among multiple steps due to longer advertising conversion processes. To address these challenges, we design MCAC, a Multi-task Conditional Attention network-based logistics advertising Conversion prediction framework, which consists of (i) an offline shipping preference extraction model to extract the user's offline logistics preference from historical shipping records, and (ii) a multi-task conditional attention-based conversion rate prediction module to model mutual relations among multiple steps in logistics advertising conversion processes. We evaluate and deploy MCAC on one of the largest e-commerce platforms in China for logistics advertising. Extensive offline experiments show that our method outperforms state-of-the-art baselines in various metrics. Moreover, the conversion rate prediction results of large-scale online A/B testing show that MCAC achieves a 15.22% improvement compared to existing industrial practices, which demonstrates the effectiveness of the proposed framework.|物流广告是线上到线下物流系统中的一项新兴任务，物流公司通过在购物网站上投放广告，向新用户提供包裹运输服务。与现有的在线电子商务广告相比，物流广告具有两个重要的新特点: (1)考虑用户线下物流偏好和线上购买概况的物流广告复杂因素; (2)由于广告转换过程较长，数据稀疏和多步骤之间的相互关系。针对这些挑战，我们设计了基于多任务条件注意网络的物流广告转化预测框架 MCAC，该框架包括: (1)离线运输偏好提取模型，从历史运输记录中提取用户的离线物流偏好; (2)基于多任务条件注意的转化率预测模型，模拟物流广告转化过程中多个步骤之间的相互关系。我们评估和部署 MCAC 在中国最大的电子商务平台之一的物流广告。大量的离线实验表明，我们的方法在各种指标上都优于最先进的基线。此外，大规模在线 A/B 测试的转换率预测结果表明，与现有工业实践相比，MCAC 的转换率提高了15.22% ，证明了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-task+Conditional+Attention+Network+for+Conversion+Prediction+in+Logistics+Advertising)|0|
|[Learning to Rank for Maps at Airbnb](https://doi.org/10.1145/3637528.3671648)|Malay Haldar, Hongwei Zhang, Kedar Bellare, Sherry Chen, Soumyadip Banerjee, Xiaotang Wang, Mustafa Abdool, Huiji Gao, Pavan Tapadia, Liwei He, Sanjeev Katariya|Airbnb, Inc., San Francisco, WA, USA; Airbnb, Inc., San Francisco, CA, USA|As a two-sided marketplace, Airbnb brings together hosts who own listings for rent with prospective guests from around the globe. Results from a guest's search for listings are displayed primarily through two interfaces: (1) as a list of rectangular cards that contain on them the listing image, price, rating, and other details, referred to as list-results (2) as oval pins on a map showing the listing price, called map-results. Both these interfaces, since their inception, have used the same ranking algorithm that orders listings by their booking probabilities and selects the top listings for display. But some of the basic assumptions underlying ranking, built for a world where search results are presented as lists, simply break down for maps. This paper describes how we rebuilt ranking for maps by revising the mathematical foundations of how users interact with search results. Our iterative and experiment-driven approach led us through a path full of twists and turns, ending in a unified theory for the two interfaces. Our journey shows how assumptions taken for granted when designing machine learning algorithms may not apply equally across all user interfaces, and how they can be adapted. The net impact was one of the largest improvements in user experience for Airbnb which we discuss as a series of experimental validations.|作为一个双向的市场，Airbnb 将拥有房源的房东和来自世界各地的潜在客人聚集在一起。客人对列表的搜索结果主要通过两个界面显示: (1)作为一个矩形卡片列表，其中包含列表图像、价格、评级和其他细节，称为列表结果(2)作为椭圆形针在地图上显示列表价格，称为地图结果。这两个界面从一开始就使用相同的排名算法，根据预订概率对列表进行排序，并选择最上面的列表进行显示。但是，一些基本的排名假设，建立在一个世界里，搜索结果显示为列表，只是分解为地图。本文描述了我们如何通过修改用户与搜索结果交互的数学基础来重建地图的排名。我们的迭代和实验驱动的方法带领我们走过了一条充满曲折的道路，最终形成了两个接口的统一理论。我们的旅程表明，当设计机器学习算法时，假设是理所当然的，可能不会平等地适用于所有用户界面，以及它们是如何适应的。净影响是 Airbnb 用户体验的最大改进之一，我们将其作为一系列实验验证进行讨论。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Rank+for+Maps+at+Airbnb)|0|
|[Deep Bag-of-Words Model: An Efficient and Interpretable Relevance Architecture for Chinese E-Commerce](https://doi.org/10.1145/3637528.3671559)|Zhe Lin, Jiwei Tan, Dan Ou, Xi Chen, Shaowei Yao, Bo Zheng|Alibaba Group, HangZhou, China|Text relevance or text matching of query and product is an essential technique for the e-commerce search system to ensure that the displayed products can match the intent of the query. Many studies focus on improving the performance of the relevance model in search system. Recently, pre-trained language models like BERT have achieved promising performance on the text relevance task. While these models perform well on the offline test dataset, there are still obstacles to deploy the pre-trained language model to the online system as their high latency. The two-tower model is extensively employed in industrial scenarios, owing to its ability to harmonize performance with computational efficiency. Regrettably, such models present an opaque ''black box'' nature, which prevents developers from making special optimizations. In this paper, we raise deep Bag-o f-Words (DeepBoW) model, an efficient and interpretable relevance architecture for Chinese e-commerce. Our approach proposes to encode the query and the product into the sparse BoW representation, which is a set of word-weight pairs. The weight means the important or the relevant score between the corresponding word and the raw text. The relevance score is measured by the accumulation of the matched word between the sparse BoW representation of the query and the product. Compared to popular dense distributed representation that usually suffers from the drawback of black-box, the most advantage of the proposed representation model is highly explainable and interventionable, which is a superior advantage to the deployment and operation of online search engines. Moreover, the online efficiency of the proposed model is even better than the most efficient inner product form of dense representation. The proposed model is experimented on three different datasets for learning the sparse BoW representations, including the human-annotation set, the search-log set and the click-through set. Then the models are evaluated by experienced human annotators. Both the auto metrics and the online evaluations show our DeepBoW model achieves competitive performance while the online inference is much more efficient than the other models. Our DeepBoW model has already deployed to the biggest Chinese e-commerce search engine Taobao and served the entire search traffic for over 6 months.|查询与产品的文本相关性或文本匹配是电子商务搜索系统中保证所显示的产品与查询意图相匹配的关键技术。许多研究集中在提高搜索系统中相关性模型的性能。近年来，像 BERT 这样的预训练语言模型在文本相关性任务中取得了良好的效果。尽管这些模型在离线测试数据集上表现良好，但仍然存在将预先训练的语言模型部署到在线系统的障碍，因为它们具有较高的延迟。由于双塔模型能够协调性能和计算效率，因此在工业场景中得到了广泛的应用。遗憾的是，这样的模型呈现出一种不透明的“黑盒”特性，这阻止了开发人员进行特殊的优化。本文提出了一种面向中国电子商务的高效、易解释的关联结构——深层 Bag-o-Words 模型。我们的方法建议将查询和产品编码成稀疏的 BW 表示，这是一组字权重对。加权表示相应单词和原始文本之间的重要或相关得分。相关性得分是通过查询的稀疏弓形表示和产品之间匹配词的累积来衡量的。该模型的最大优点是可解释性强、可干预性强，优于在线搜索引擎的部署和运行。此外，该模型的在线效率甚至优于最有效的密集表示内积形式。该模型在三个不同的数据集上进行了实验，包括人工注释集、搜索日志集和点击通过集。然后由经验丰富的人工注释者对模型进行评估。自动度量和在线评估都表明，我们的 DeepBW 模型达到了竞争性能，而在线推理是更有效的比其他模型。我们的 DeepBow 模式已经部署到中国最大的电子商务搜索引擎淘宝，并服务于整个搜索流量超过6个月。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Bag-of-Words+Model:+An+Efficient+and+Interpretable+Relevance+Architecture+for+Chinese+E-Commerce)|0|
|[GRAM: Generative Retrieval Augmented Matching of Data Schemas in the Context of Data Security](https://doi.org/10.1145/3637528.3671602)|Xuanqing Liu, Runhui Wang, Yang Song, Luyang Kong|Amazon Web Services, Seattle, WA, USA|Schema matching constitutes a pivotal phase in the data ingestion process forcontemporary database systems. Its objective is to discern pairwisesimilarities between two sets of attributes, each associated with a distinctdata table. This challenge emerges at the initial stages of data analytics,such as when incorporating a third-party table into existing databases toinform business insights. Given its significance in the realm of databasesystems, schema matching has been under investigation since the 2000s. Thisstudy revisits this foundational problem within the context of large languagemodels. Adhering to increasingly stringent data security policies, our focuslies on the zero-shot and few-shot scenarios: the model should analyze only aminimal amount of customer data to execute the matching task, contrasting withthe conventional approach of scrutinizing the entire data table. We emphasizethat the zero-shot or few-shot assumption is imperative to safeguard theidentity and privacy of customer data, even at the potential cost of accuracy.The capability to accurately match attributes under such stringent requirementsdistinguishes our work from previous literature in this domain.|模式匹配是现代数据库系统数据摄取过程中的一个关键阶段。它的目标是识别两组属性之间的成对相似性，每组属性都与一个不同的数据表相关联。这一挑战出现在数据分析的初始阶段，例如将第三方表合并到现有数据库中以提供业务见解。鉴于模式匹配在数据库领域的重要性，自2000年以来，模式匹配一直在研究之中。本研究在大型语言模型的背景下重新审视这个基本问题。坚持越来越严格的数据安全策略，我们的重点是零射击和少射击场景: 模型应该只分析最小数量的客户数据来执行匹配任务，与审查整个数据表的传统方法形成对比。我们强调，零拍摄或少拍摄假设是必要的，以保护客户数据的身份和隐私，即使在潜在的准确性成本。在如此严格的要求下精确匹配属性的能力使我们的工作区别于这个领域以前的文献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GRAM:+Generative+Retrieval+Augmented+Matching+of+Data+Schemas+in+the+Context+of+Data+Security)|0|
|[Non-autoregressive Generative Models for Reranking Recommendation](https://doi.org/10.1145/3637528.3671645)|Yuxin Ren, Qiya Yang, Yichun Wu, Wei Xu, Yalong Wang, Zhiqiang Zhang|Peking University, Beijing, China; Kuaishou Technology, Beijing, China; Tsinghua University, Beijing, China|Contemporary recommendation systems are designed to meet users' needs by delivering tailored lists of items that align with their specific demands or interests. In a multi-stage recommendation system, reranking plays a crucial role by modeling the intra-list correlations among items. The key challenge of reranking lies in the exploration of optimal sequences within the combinatorial space of permutations. Recent research proposes a generator-evaluator learning paradigm, where the generator generates multiple feasible sequences and the evaluator picks out the best sequence based on the estimated listwise score. The generator is of vital importance, and generative models are well-suited for the generator function. Current generative models employ an autoregressive strategy for sequence generation. However, deploying autoregressive models in real-time industrial systems is challenging. Firstly, the generator can only generate the target items one by one and hence suffers from slow inference. Secondly, the discrepancy between training and inference brings an error accumulation. Lastly, the left-to-right generation overlooks information from succeeding items, leading to suboptimal performance. To address these issues, we propose a Non-AutoRegressive generative model for reranking Recommendation (NAR4Rec) designed to enhance efficiency and effectiveness. To tackle challenges such as sparse training samples and dynamic candidates, we introduce a matching model. Considering the diverse nature of user feedback, we employ a sequence-level unlikelihood training objective to differentiate feasible sequences from unfeasible ones. Additionally, to overcome the lack of dependency modeling in non-autoregressive models regarding target items, we introduce contrastive decoding to capture correlations among these items. Extensive offline experiments validate the superior performance of NAR4Rec over state-of-the-art reranking methods. Online A/B tests reveal that NAR4Rec significantly enhances the user experience. Furthermore, NAR4Rec has been fully deployed in a popular video app Kuaishou with over 300 million daily active users.|当代的推荐系统通过提供符合用户特定需求或兴趣的量身定制的项目列表来满足用户的需求。在多阶段推荐系统中，重新排序通过建立项目之间的列表内相关性起着至关重要的作用。重新排序的关键挑战在于在排列的组合空间中探索最优序列。最近的研究提出了生成器-评估器学习范式，其中生成器生成多个可行序列，评估器根据估计的列表分数挑选出最佳序列。生成器是至关重要的，生成模型非常适合于生成器函数。当前的生成模型采用自回归策略进行序列生成。然而，在实时工业系统中部署自回归模型是具有挑战性的。首先，生成器只能生成一个个目标项，因此存在推理速度慢的问题。其次，训练与推理的差异带来了错误的积累。最后，从左到右的生成会忽略来自后续项的信息，从而导致性能不理想。为了解决这些问题，我们提出了一个非自动回归的重新排名建议(NAR4rec)生成模型，旨在提高效率和效力。为了解决稀疏训练样本和动态候选人等问题，我们引入了一个匹配模型。考虑到用户反馈的多样性，我们采用序列级不似然训练目标来区分可行序列和不可行序列。此外，为了克服非自回归模型中缺乏对目标项的依赖建模，我们引入对比解码来捕获这些项之间的相关性。大量的离线实验验证了 NAR4Rec 优于最先进的重新排序方法的性能。在线 A/B 测试显示 NAR4Rec 显著提高了用户体验。此外，NAR4Rec 已经完全部署在一个流行的视频应用快手中，每天有超过3亿的活跃用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-autoregressive+Generative+Models+for+Reranking+Recommendation)|0|
|[Chaining Text-to-Image and Large Language Model: A Novel Approach for Generating Personalized e-commerce Banners](https://doi.org/10.1145/3637528.3671636)|Shanu Vashishtha, Abhinav Prakash, Lalitesh Morishetti, Kaushiki Nag, Yokila Arora, Sushant Kumar, Kannan Achan|Walmart Global Tech, Sunnyvale, CA, USA|Text-to-image models such as stable diffusion have opened a plethora ofopportunities for generating art. Recent literature has surveyed the use oftext-to-image models for enhancing the work of many creative artists. Manye-commerce platforms employ a manual process to generate the banners, which istime-consuming and has limitations of scalability. In this work, we demonstratethe use of text-to-image models for generating personalized web banners withdynamic content for online shoppers based on their interactions. The novelty inthis approach lies in converting users' interaction data to meaningful promptswithout human intervention. To this end, we utilize a large language model(LLM) to systematically extract a tuple of attributes from itemmeta-information. The attributes are then passed to a text-to-image model viaprompt engineering to generate images for the banner. Our results show that theproposed approach can create high-quality personalized banners for users.|文本到图像的模型，例如稳定的扩散，已经为艺术的生成提供了大量的机会。最近的文献调查了文本到图像模型的使用，以提高许多创造性的艺术家的工作。许多电子商务平台使用手工过程来生成横幅，这非常耗时并且具有可伸缩性的限制。在这项工作中，我们演示了使用文本到图像的模型来生成个性化的网络横幅与动态内容的在线购物者基于他们的交互。这种方法的新颖之处在于无需人工干预就能将用户的交互数据转换为有意义的提示。为此，我们利用大型语言模型(LLM)系统地从 itemmeta 信息中提取属性元组。然后通过提示工程将属性传递给文本到图像模型，以生成横幅的图像。结果表明，该方法可以为用户创建高质量的个性化横幅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Chaining+Text-to-Image+and+Large+Language+Model:+A+Novel+Approach+for+Generating+Personalized+e-commerce+Banners)|0|
|[LiMAML: Personalization of Deep Recommender Models via Meta Learning](https://doi.org/10.1145/3637528.3671599)|Ruofan Wang, Prakruthi Prabhakar, Gaurav Srivastava, Tianqi Wang, Zeinab S. Jalali, Varun Bharill, Yunbo Ouyang, Aastha Nigam, Divya Venugopalan, Aman Gupta, Fedor Borisyuk, S. Sathiya Keerthi, Ajith Muralidharan|Aliveo AI Corp, Sunnyvale, CA, USA; LinkedIn Corporation, Sunnyvale, CA, USA|In the realm of recommender systems, the ubiquitous adoption of deep neural networks has emerged as a dominant paradigm for modeling diverse business objectives. As user bases continue to expand, the necessity of personalization and frequent model updates have assumed paramount significance to ensure the delivery of relevant and refreshed experiences to a diverse array of members. In this work, we introduce an innovative meta-learning solution tailored to the personalization of models for individual members and other entities, coupled with the frequent updates based on the latest user interaction signals. Specifically, we leverage the Model-Agnostic Meta Learning (MAML) algorithm to adapt per-task sub-networks using recent user interaction data. Given the near infeasibility of productionizing original MAML-based models in online recommendation systems, we propose an efficient strategy to operationalize meta-learned sub-networks in production, which involves transforming them into fixed-sized vectors, termed meta embeddings, thereby enabling the seamless deployment of models with hundreds of billions of parameters for online serving. Through extensive experimentation on production data drawn from various applications at LinkedIn, we demonstrate that the proposed solution consistently outperforms the best performing baseline models of those applications, including strong baselines such as using wide-and-deep ID based personalization approach. Our approach has enabled the deployment of a range of highly personalized AI models across diverse LinkedIn applications, leading to substantial improvements in business metrics as well as refreshed experience for our members.|在推荐系统领域，深层神经网络的普遍采用已经成为建模不同业务目标的主要范例。随着用户基础的不断扩大，个性化和频繁更新模型的必要性对于确保向各类成员提供相关的最新经验具有至关重要的意义。在这项工作中，我们介绍了一个创新的元学习解决方案，专为个人成员和其他实体的模型个性化，加上基于最新用户交互信号的频繁更新。具体来说，我们利用模型不可知元学习(MAML)算法来使用最近的用户交互数据来适应每个任务的子网络。鉴于在在线推荐系统中生产原始的基于 MAML 的模型几乎是不可行的，我们提出了一个有效的策略来操作生产中的元学习子网络，包括将它们转换成固定大小的向量，称为元嵌入，从而能够无缝部署具有数千亿参数的在线服务模型。通过对来自 LinkedIn 各种应用程序的生产数据进行广泛的实验，我们证明了所提出的解决方案始终优于这些应用程序的最佳性能基线模型，包括强大的基线，例如使用基于广泛和深度 ID 的个性化方法。我们的方法使得一系列高度个性化的人工智能模型能够在不同的 LinkedIn 应用程序中部署，从而大大改善了业务指标，并为我们的会员带来了全新的体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LiMAML:+Personalization+of+Deep+Recommender+Models+via+Meta+Learning)|0|
|[Enhancing Asymmetric Web Search through Question-Answer Generation and Ranking](https://doi.org/10.1145/3637528.3671517)|Dezhi Ye, Jie Liu, Jiabin Fan, Bowen Tian, Tianhua Zhou, Xiang Chen, Jin Ma|Tencent PCG, Beijing, China|This paper addresses the challenge of the semantic gap between user queries and web content, commonly referred to as asymmetric text matching, within the domain of web search. By leveraging BERT for reading comprehension, current algorithms enable significant advancements in query understanding, but still encounter limitations in effectively resolving the asymmetrical ranking problem due to model comprehension and summarization constraints. To tackle this issue, we propose the QAGR (Question-Answer Generation and Ranking) method, comprising an offline module called QAGeneration and an online module called QARanking. The QAGeneration module utilizes large language models (LLMs) to generate high-quality question-answering pairs for each web page. This process involves two steps: generating question-answer pairs and performing verification to eliminate irrelevant questions, resulting in high-quality questions associated with their respective documents. The QARanking module combines and ranks the generated questions and web page content. To ensure efficient online inference, we design the QARanking model as a homogeneous dual-tower model, incorporating query intent to drive score fusion while balancing keyword matching and asymmetric matching. Additionally, we conduct a preliminary screening of questions for each document, selecting only the top-N relevant questions for further relevance calculation. Empirical results demonstrate the substantial performance improvement of our proposed method in web search. We achieve over 8.7% relative offline relevance improvement and over 8.5% online engagement gain compared to the state-of-the-art web search system. Furthermore, we deploy QAGR to online web search engines and share our deployment experience, including production considerations and ablation experiments. This research contributes to advancing the field of asymmetric web search and provides valuable insights for enhancing search engine performance.|本文讨论了在网络搜索领域中，用户查询和网页内容之间的语义差异(通常称为非对称文本匹配)所带来的挑战。通过利用 BERT 的阅读理解，当前的算法在查询理解方面取得了显著的进步，但由于模型理解和摘要约束，在有效解决非对称排序问题方面仍然存在局限性。为了解决这个问题，我们提出了 QAGR (问答生成和排序)方法，包括一个称为 QAGeneration 的离线模块和一个称为 QARanking 的在线模块。QAGeneration 模块利用大语言模型(LLM)为每个网页生成高质量的问答对。这个过程包括两个步骤: 生成问题-答案对和进行验证，以消除不相关的问题，从而产生与各自文件相关的高质量问题。QARanking 模块将生成的问题和网页内容进行组合和排序。为了保证在线推理的有效性，我们将 QARanking 模型设计成一个均匀的双塔模型，在平衡关键字匹配和非对称匹配的同时，结合查询意图驱动得分融合。此外，我们对每个文档的问题进行初步筛选，只选择排名前 N 位的相关问题进行进一步的相关性计算。实验结果表明，本文提出的方法在网络搜索中性能得到了显著提高。与最先进的网络搜索系统相比，我们实现了超过8.7% 的相对离线相关性改善和超过8.5% 的在线参与收益。此外，我们部署 QAGR 到在线网络搜索引擎和分享我们的部署经验，包括生产考虑和烧蚀实验。本文的研究有助于推进非对称网络搜索领域的发展，为提高搜索引擎性能提供了有价值的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Asymmetric+Web+Search+through+Question-Answer+Generation+and+Ranking)|0|
|[Unsupervised Ranking Ensemble Model for Recommendation](https://doi.org/10.1145/3637528.3671598)|Wenhui Yu, Bingqi Liu, Bin Xia, Xiaoxiao Xu, Ying Chen, Yongchang Li, Lantao Hu|Kuaishou Technology, Beijing, China|When visiting an online platform, a user generates various actions, such as clicks, long views, likes, comments, etc. To capture user preferences in these aspects, we learn these objectives and return multiple rankings of candidate items for each user. We need to aggregate them into one to truncate the candidate set, and ranking ensemble model is proposed for this task. However, there is a critical issue: though we input abundant information, what model learns depends on the supervision. Unfortunately, the existing supervision is poorly designed, leading to serious information loss issue. To address this issue, we designed an unsupervised loss to compel the ranking ensemble model to learn all information of input rankings, including sequential and numerical information. (1) For sequential information, we design a distance measure between two rankings, and train the ensemble ranking to have similar order with all input rankings by minimizing the distance. (2) For numerical information, we design a decoder to reconstruct values of original rankings from the hidden layer of the model, to guarantee that the model captures as much input information as possible. Our unsupervised loss is compatible with all ranking ensemble models. We optimize several widely-used structures to propose unsupervised ranking ensemble models. We devise comprehensive experiments on two real-world datasets to demonstrate the effectiveness of the proposed models. We also apply our model in a short video platform with billions of users, and achieve significant improvement.|当访问在线平台时，用户生成各种各样的动作，如点击、长视图、喜欢、评论等。为了捕获这些方面的用户偏好，我们学习这些目标，并返回每个用户的候选项的多个排名。为了截断候选集，我们需要将它们聚合成一个集合，并提出了排序集成模型。然而，有一个关键的问题: 虽然我们输入了大量的信息，但是模型学到了什么取决于监督。然而，现有的监管体系设计不当，导致了严重的信息流失问题。为了解决这个问题，我们设计了一个无监督的损失，以迫使排名集成模型学习所有的输入排名信息，包括顺序和数字信息。(1)对于序列信息，我们设计了两个排名之间的距离度量，并通过最小化距离训练集合排名与所有输入排名具有相似的顺序。(2)对于数值信息，我们设计了一个解码器，从模型的隐层重建原始排名值，以保证模型捕获尽可能多的输入信息。我们的无监督损失与所有等级集合模型兼容。我们优化了几个广泛使用的结构，提出了无监督排序集成模型。我们设计了两个实际数据集的综合实验来验证所提出模型的有效性。在一个拥有数十亿用户的短视频平台上应用了该模型，并取得了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Ranking+Ensemble+Model+for+Recommendation)|0|
|[Adapting Job Recommendations to User Preference Drift with Behavioral-Semantic Fusion Learning](https://doi.org/10.1145/3637528.3671759)|Xiao Han, Chen Zhu, Xiao Hu, Chuan Qin, Xiangyu Zhao, Hengshu Zhu|Career Science Lab, BOSS Zhipin, University of Science and Technology of China, Beijing, China; City University of Hong Kong, Hong Kong, China; Career Science Lab, BOSS Zhipin, Beijing, China|Job recommender systems are crucial for aligning job opportunities with job-seekers in online job-seeking. However, users tend to adjust their job preferences to secure employment opportunities continually, which limits the performance of job recommendations. The inherent frequency of preference drift poses a challenge to promptly and precisely capture user preferences. To address this issue, we propose a novel session-based framework, BISTRO, to timely model user preference through fusion learning of semantic and behavioral information. Specifically, BISTRO is composed of three stages: 1) coarse-grained semantic clustering, 2) fine-grained job preference extraction, and 3) personalized top-k job recommendation. Initially, BISTRO segments the user interaction sequence into sessions and leverages session-based semantic clustering to achieve broad identification of person-job matching. Subsequently, we design a hypergraph wavelet learning method to capture the nuanced job preference drift. To mitigate the effect of noise in interactions caused by frequent preference drift, we innovatively propose an adaptive wavelet filtering technique to remove noisy interaction. Finally, a recurrent neural network is utilized to analyze session-based interaction for inferring personalized preferences. Extensive experiments on three real-world offline recruitment datasets demonstrate the significant performances of our framework. Significantly, BISTRO also excels in online experiments, affirming its effectiveness in live recruitment settings. This dual success underscores the robustness and adaptability of BISTRO. The source code is available at https://github.com/Applied-Machine-Learning-Lab/BISTRO.|在网上求职中，职位推荐系统对于将求职机会与求职者联系起来至关重要。然而，用户倾向于不断调整自己的工作偏好以获得就业机会，这就限制了工作推荐的效果。偏好漂移的固有频率对及时、准确地捕捉用户偏好提出了挑战。为了解决这个问题，我们提出了一个新的基于会话的框架 BISTRO，通过语义和行为信息的融合学习来及时建模用户偏好。具体来说，BISTRO 由三个阶段组成: 1)粗粒度语义聚类，2)细粒度工作偏好提取，3)个性化的 top-k 工作推荐。最初，BISTRO 将用户交互序列分割成会话，并利用基于会话的语义聚类实现人-工匹配的广泛识别。随后，我们设计了一种超图小波学习方法来捕捉细微的工作偏好漂移。为了消除频繁偏好漂移引起的相互作用中的噪声影响，本文创新性地提出了一种自适应小波滤波技术来去除噪声相互作用。最后，一个递归神经网络被用来分析基于会话的交互来推断个性化的偏好。在三个真实世界的离线招聘数据集上的大量实验证明了我们的框架的显著性能。值得注意的是，BISTRO 还擅长在线实验，确认其在现场招聘设置的有效性。这种双重成功突出了 BISTRO 的稳健性和适应性。源代码可在 https://github.com/applied-machine-learning-lab/bistro 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adapting+Job+Recommendations+to+User+Preference+Drift+with+Behavioral-Semantic+Fusion+Learning)|0|
|[Learning to Bid the Interest Rate in Online Unsecured Personal Loans](https://doi.org/10.1145/3637528.3671584)|Dong Jun Jee, Seung Jung Jin, JiHoon Yoo, Byunggyu Ahn|PFC Technologies, Seoul, Republic of Korea|The unsecured personal loan (UPL) market is a multi-billion dollar market where numerous financial institutions compete. Due to the development of online banking, loan applicants start to compare numerous loan products. They aim for high loan limits and low interest rates. Since loan applicants have a desired loan amount, institutions instead focus on adjusting interest rates. Despite the importance of determining optimal interest strategies, institutions have traditionally relied on heuristic methods by human experts to set interest rates. This is done by adding a target return on assets (ROA) to the applicant's expected default probability predicted by a credit scoring system (CSS) such as the FICO score. We conceptualize the UPL market dynamics as a repeated auction scenario, where loan applicants (akin to sellers) seek the lowest interest rates, while financial institutions (akin to bidders) aim to maximize profits through higher interest rates. To the best of our knowledge, this is the first time anyone has approached the UPL market through the viewpoint of a repeated auction. While there are several research done in learning to bid in repeated auctions, those works cannot be directly applied to the UPL market due to the lack of any feedback about other bidders' strategies and the need to satisfy the bidder's target loan volume and profit variance. We present an algorithm named AutoInterest, which is a modification of the dual gradient descent algorithm. In addition, we provide a framework to evaluate interest rate bidding strategies on a benchmark dataset and the credit bureau dataset of actual loan applicants in South Korea. We evaluate AutoInterest on this framework and show higher cumulative profit compared to other common online algorithms and the current fixed strategy used by real institutions.|无担保个人贷款(UPL)市场是一个数十亿美元的市场，众多金融机构在其中展开竞争。由于网上银行的发展，贷款申请者开始比较众多的贷款产品。他们的目标是高贷款限额和低利率。由于贷款申请人有一个理想的贷款数额，机构反而把重点放在调整利率。尽管确定最优利率策略很重要，但机构历来依赖人类专家的启发式方法来设定利率。这是通过将目标资产收益率(ROA)添加到由信用评分系统(CSS)(例如 FICO 评分)预测的申请者的预期违约概率来完成的。我们将 UPL 市场动态概念化为一个重复的拍卖场景，其中贷款申请者(类似于卖方)寻求最低的利率，而金融机构(类似于投标者)旨在通过更高的利率实现利润最大化。据我们所知，这是第一次有人通过重复拍卖的观点进入 UPL 市场。虽然在重复拍卖中学习投标已经有了一些研究，但是由于缺乏对其他投标者策略的反馈，以及需要满足投标者的目标贷款量和利润差异，这些工作不能直接应用于 UPL 市场。我们提出了一个名为“自动兴趣”的算法，它是对双梯度下降法算法的修改。此外，我们还提供了一个基于基准数据集和韩国实际贷款申请者信用局数据集评估利率投标策略的框架。我们在这个框架下评估了自动收益，并显示了比其他常见的在线算法和当前实际机构使用的固定策略更高的累积利润。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Bid+the+Interest+Rate+in+Online+Unsecured+Personal+Loans)|0|
|[A Hierarchical and Disentangling Interest Learning Framework for Unbiased and True News Recommendation](https://doi.org/10.1145/3637528.3671944)|Shoujin Wang, Wentao Wang, Xiuzhen Zhang, Yan Wang, Huan Liu, Fang Chen|Arizona State University, Tempe, USA; RMIT University, Melbourne, Australia; Macquarie University, Sydney, Australia; University of Technology Sydney, Sydney, Australia|In the era of information explosion, news recommender systems are crucial for users to effectively and efficiently discover their interested news. However, most of the existing news recommender systems face two major issues, hampering recommendation quality. Firstly, they often oversimplify users' reading interests, neglecting their hierarchical nature, spanning from high-level event (e.g., US Election) related interests to low-level news article-specifc interests. Secondly, existing work often assumes a simplistic context, disregarding the prevalence of fake news and political bias under the real-world context. This oversight leads to recommendations of biased or fake news, posing risks to individuals and society. To this end, this paper addresses these gaps by introducing a novel framework, the Hierarchical and Disentangling Interest learning framework (HDInt). HDInt incorporates a hierarchical interest learning module and a disentangling interest learning module. The former captures users' high- and low-level interests, enhancing next-news recommendation accuracy. The latter effectively separates polarity and veracity information from news contents and model them more specifcally, promoting fairness- and truth-aware reading interest learning for unbiased and true news recommendations. Extensive experiments on two real-world datasets demonstrate HDInt's superiority over state-of-the-art news recommender systems in delivering accurate, unbiased, and true news recommendations.|在信息爆炸时代，新闻推荐系统对于用户有效发现感兴趣的新闻至关重要。然而，大多数现有的新闻推荐系统面临两个主要问题，阻碍了推荐质量。首先，他们往往过分简化用户的阅读兴趣，忽视了他们的等级性质，从高水平的事件(如美国大选)相关兴趣低水平的新闻文章的具体兴趣。其次，现有作品往往假设一个简单化的语境，忽视了现实语境下假新闻和政治偏见的盛行。这种疏忽导致了有偏见或假新闻的建议，给个人和社会带来风险。为此，本文提出了一种新的兴趣学习框架——分层分离式兴趣学习框架(HDInt)。HDInt 集成了分层兴趣学习模块和分离兴趣学习模块。前者捕捉用户的高层次和低层次兴趣，提高下一新闻推荐的准确性。后者有效地将极性和准确性信息从新闻内容中分离出来，并对其进行更具体的建模，促进公平和真实意识的阅读兴趣学习，以获得无偏见和真实的新闻推荐。在两个真实世界数据集上的大量实验表明，HDInt 在提供准确、公正和真实的新闻推荐方面优于最先进的新闻推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hierarchical+and+Disentangling+Interest+Learning+Framework+for+Unbiased+and+True+News+Recommendation)|0|
|[Warming Up Cold-Start CTR Prediction by Learning Item-Specific Feature Interactions](https://doi.org/10.1145/3637528.3671784)|Yaqing Wang, Hongming Piao, Daxiang Dong, Quanming Yao, Jingbo Zhou|Department of Computer Science, City University of Hong Kong, Hong Kong, Hong Kong; Baidu Research, Baidu Inc., Beijing, China; Baidu AI Cloud, Baidu Inc., Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China|In recommendation systems, new items are continuously introduced, initially lacking interaction records but gradually accumulating them over time. Accurately predicting the click-through rate (CTR) for these items is crucial for enhancing both revenue and user experience. While existing methods focus on enhancing item ID embeddings for new items within general CTR models, they tend to adopt a global feature interaction approach, often overshadowing new items with sparse data by those with abundant interactions. Addressing this, our work introduces EmerG, a novel approach that warms up cold-start CTR prediction by learning item-specific feature interaction patterns. EmerG utilizes hypernetworks to generate an item-specific feature graph based on item characteristics, which is then processed by a Graph Neural Network (GNN). This GNN is specially tailored to provably capture feature interactions at any order through a customized message passing mechanism. We further design a meta learning strategy that optimizes parameters of hypernetworks and GNN across various item CTR prediction tasks, while only adjusting a minimal set of item-specific parameters within each task. This strategy effectively reduces the risk of overfitting when dealing with limited data. Extensive experiments on benchmark datasets validate that EmerG consistently performs the best given no, a few and sufficient instances of new items.|在推荐系统中，不断引入新的项目，最初缺乏交互记录，但随着时间的推移逐渐积累。准确地预测这些项目的点进率对于提高收入和用户体验至关重要。虽然现有的方法侧重于在一般的 CTR 模型中增强新项目的项目 ID 嵌入，但它们倾向于采用全局特征交互方法，往往使那些具有丰富交互的数据稀疏的新项目黯然失色。为了解决这个问题，我们的工作介绍了 EmerG，这是一种通过学习项目特定的特征交互模式来预测冷启动 CTR 的新方法。EmerG 利用超网络生成基于项目特征的项目特征图，然后通过图神经网络(GNN)对其进行处理。这个 GNN 是专门定制的，可以通过定制的消息传递机制以任何顺序捕获特性交互。我们进一步设计了一个元学习策略，在不同的项目 CTR 预测任务中优化超级网络和 GNN 的参数，同时在每个任务中只调整最小的项目特定参数集。这种策略有效地降低了处理有限数据时过度拟合的风险。在基准数据集上的大量实验验证了 EmerG 始终如一地表现出最好的特性——没有、少数和充分的新项目实例。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Warming+Up+Cold-Start+CTR+Prediction+by+Learning+Item-Specific+Feature+Interactions)|0|
|[Improving Multi-modal Recommender Systems by Denoising and Aligning Multi-modal Content and User Feedback](https://doi.org/10.1145/3637528.3671703)|Guipeng Xv, Xinyu Li, Ruobing Xie, Chen Lin, Chong Liu, Feng Xia, Zhanhui Kang, Leyu Lin|School of Informatics, Xiamen University, Xiamen, Fujian, China; Tencent, Beijing, China|Multi-modal recommender systems (MRSs) are pivotal in diverse online web platforms and have garnered considerable attention in recent years. However, previous studies overlook the challenges of (1)noisy multi-modal content, (2) noisy user feedback, and (3) aligning multi-modal content and user feedback. To tackle these challenges, we propose Denoising and Aligning Multi-modal Recommender System (DA-MRS). To mitigate noise in multi-modal content, DA-MRS first constructs item-item graphs determined by consistent content similarity across modalities. To denoise user feedback, DA-MRS associates the probability of observed feedback with multi-modal content and devises a denoised BPR loss. Furthermore, DA-MRS implements Alignment guided by User preference to enhance task-specific item representation and Alignment guided by graded Item relations to provide finer-grained alignment. Extensive experiments verify that DA-MRS is a plug-and-play framework and achieves significant and consistent improvements across various datasets, backbone models, and noisy scenarios.|多模态推荐系统(MRS)是各种在线网络平台中的关键技术，近年来得到了广泛的关注。然而，以往的研究忽略了以下挑战: (1)噪声多模态内容，(2)噪声用户反馈，和(3)调整多模态内容和用户反馈。为了应对这些挑战，我们提出了去噪和对齐多模态推荐系统(DA-MRS)。为了减轻多模态内容中的噪声，DA-MRS 首先构建由不同模态间一致的内容相似性确定的项目-项目图。为了去除用户反馈的噪声，DA-MRS 将观测反馈的概率与多模态内容联系起来，设计了一种去除 BPR 损失的方法。此外，DA-MRS 还实现了用户偏好引导的对齐，增强了任务特定项目的表示和分级项目关系引导的对齐，提供了更细粒度的对齐。大量的实验验证了 DA-MRS 是一个即插即用的框架，并在各种数据集、骨干模型和噪声场景中实现了显著和一致的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Multi-modal+Recommender+Systems+by+Denoising+and+Aligning+Multi-modal+Content+and+User+Feedback)|0|
|[DDCDR: A Disentangle-based Distillation Framework for Cross-Domain Recommendation](https://doi.org/10.1145/3637528.3671605)|Zhicheng An, Zhexu Gu, Li Yu, Ke Tu, Zhengwei Wu, Binbin Hu, Zhiqiang Zhang, Lihong Gu, Jinjie Gu|Ant Group, Hangzhou, Zhejiang, China|Modern recommendation platforms frequently encompass multiple domains to cater to the varied preferences of users. Recently, cross-domain learning has gained traction as a significant paradigm within the context of recommendation systems, enabling the leveraging of rich information from a well-endowed source domain to enhance a target domain, often limited by inadequate data resources. A primary concern in cross-domain recommendation is the mitigation of negative transfer-ensuring the selective transference of pertinent knowledge from the source (domain-shared knowledge) while maintaining the integrity of domain-unique insights within the target domain (domain-specific knowledge). In this paper, we propose a novel Disentangle-based Distillation Framework for Cross-Domain Recommendation (DDCDR), designed to operate at the representational level and rooted in the established teacher-student knowledge distillation paradigm. Our methodology begins with the development of a cross-domain teacher model, trained adversarially alongside a domain discriminator. This is followed by the creation of a target domain-specific student model. By employing the trained domain discriminator, we successfully segregate domain-shared from domain-specific representations. The teacher model guides the learning of domain-shared features, while domain-specific features are enhanced via contrastive learning methods. Experiments conducted on both public datasets and an industrial dataset demonstrate DDCDR achieves a new state-of-the-art performance. The implementation within Ant Group's platform further confirms its online efficacy, manifesting relative improvements of 0.33% and 0.45% in Unique Visitor Click-Through Rate (UVCTR) across two distinct recommendation scenarios, compared to baseline performances.|现代推荐平台经常包含多个域，以满足用户的不同偏好。最近，跨领域学习作为推荐系统范围内的一个重要范式已经获得了广泛的关注，使得能够利用来自资源丰富的源领域的丰富信息来增强目标领域，而这往往受到数据资源不足的限制。跨领域推荐的主要关注点是减轻负面转移-确保从源(领域共享知识)选择性转移相关知识，同时保持目标领域(领域特定知识)内领域独特见解的完整性。本文提出了一种新的基于分离角度的跨域推荐精馏框架(DDCDR) ，该框架基于已建立的师生知识精馏范式，设计在表示层次上进行操作。我们的方法开始于开发一个跨领域的教师模型，与领域鉴别器一起进行对抗性的培训。然后创建特定于目标领域的学生模型。通过使用训练有素的领域鉴别器，我们成功地将领域共享与领域特定的表示隔离开来。教师模型指导领域共享特征的学习，而领域特定特征通过对比学习方法得到增强。在公共数据集和工业数据集上进行的实验表明，DDCDR 实现了一种新的最先进的性能。蚂蚁集团平台的实施进一步证实了其在线功效，与基线表现相比，在两个不同的推荐场景中，Unique Visitor 点进率(UVCTR)的相对改善率分别为0.33% 和0.45% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DDCDR:+A+Disentangle-based+Distillation+Framework+for+Cross-Domain+Recommendation)|0|
|[Rankability-enhanced Revenue Uplift Modeling Framework for Online Marketing](https://doi.org/10.1145/3637528.3671516)|Bowei He, Yunpeng Weng, Xing Tang, Ziqiang Cui, Zexu Sun, Liang Chen, Xiuqiang He, Chen Ma|City University of Hong Kong, Hong Kong, Hong Kong; Renmin University of China, Beijing, China; FiT, Tencent, Shenzhen, China|Uplift modeling has been widely employed in online marketing by predicting the response difference between the treatment and control groups, so as to identify the sensitive individuals toward interventions like coupons or discounts. Compared with traditional conversion uplift modeling,revenue uplift modeling exhibits higher potential due to its direct connection with the corporate income. However, previous works can hardly handle the continuous long-tail response distribution in revenue uplift modeling. Moreover, they have neglected to optimize the uplift ranking among different individuals, which is actually the core of uplift modeling. To address such issues, in this paper, we first utilize the zero-inflated lognormal (ZILN) loss to regress the responses and customize the corresponding modeling network, which can be adapted to different existing uplift models. Then, we study the ranking-related uplift modeling error from the theoretical perspective and propose two tighter error bounds as the additional loss terms to the conventional response regression loss. Finally, we directly model the uplift ranking error for the entire population with a listwise uplift ranking loss. The experiment results on offline public and industrial datasets validate the effectiveness of our method for revenue uplift modeling. Furthermore, we conduct large-scale experiments on a prominent online fintech marketing platform, Tencent FiT, which further demonstrates the superiority of our method in real-world applications.|提升模型通过预测治疗组与对照组之间的反应差异，以识别对优惠券或折扣等干预措施敏感的个体，在网络营销中得到了广泛的应用。与传统的转换提升模型相比，收入提升模型由于与企业收入直接相关，因此具有更大的潜力。然而，以往的工作难以处理连续的长尾响应分布的收入提升模型。而且，他们忽略了优化不同个体之间的提升排序，这实际上是提升模型的核心。为了解决这些问题，本文首先利用零膨胀对数正态(ZILN)损失对响应进行回归，并定制相应的模型网络，以适应不同的现有抬升模型。然后，从理论角度研究了与排名相关的提升模型误差，提出了两个更严格的误差界作为常规响应回归损失的附加损失项。最后，我们直接模型的提升排名误差的整个人口与列表提升排名损失。在离线公共数据集和工业数据集上的实验结果验证了该方法对收入提升模型的有效性。此外，我们在一个著名的网上金融科技营销平台腾讯 FiT 上进行了大规模的实验，这进一步证明了我们的方法在实际应用中的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rankability-enhanced+Revenue+Uplift+Modeling+Framework+for+Online+Marketing)|0|
|[Personalized Product Assortment with Real-time 3D Perception and Bayesian Payoff Estimation](https://doi.org/10.1145/3637528.3671518)|Porter Jenkins, Michael Selander, J. Stockton Jenkins, Andrew Merrill, Kyle Armstrong|Delicious AI, Lehi, UT, USA; Department of Computer Science, Brigham Young University, Provo, UT, USA|Product assortment selection is a critical challenge facing physical retailers. Effectively aligning inventory with the preferences of shoppers can increase sales and decrease out-of-stocks. However, in real-world settings the problem is challenging due to the combinatorial explosion of product assortment possibilities. Consumer preferences are typically heterogeneous across space and time, making inventory-preference alignment challenging. Additionally, existing strategies rely on syndicated data, which tends to be aggregated, low resolution, and suffer from high latency. To solve these challenges, we introduce a real-time recommendation system, which we call EdgeRec3D. Our system utilizes recent advances in 3D computer vision for perception and automatic, fine grained sales estimation. These perceptual components run on the edge of the network and facilitate real-time reward signals. Additionally, we develop a Bayesian payoff model to account for noisy estimates from 3D LIDAR data. We rely on spatial clustering to allow the system to adapt to heterogeneous consumer preferences, and a graph-based candidate generation algorithm to address the combinatorial search problem. We test our system in real-world stores across two, 6-8 week A/B tests with beverage products and demonstrate a 35% and 27% increase in sales respectively. Finally, we monitor the deployed system for a period of 28 weeks with an observational study and show a 9.4% increase in sales.|产品分类选择是实体零售商面临的一个关键挑战。有效地调整库存与购物者的偏好可以增加销售和减少缺货。然而，在现实世界中，这个问题是具有挑战性的，因为产品分类的可能性是组合爆炸的。消费者的偏好在空间和时间上具有典型的异质性，这使得库存偏好的调整具有挑战性。此外，现有的策略依赖于聚合数据，这些数据往往是聚合的、低分辨率的，并且存在高延迟。为了解决这些问题，我们引入了一个实时推荐系统，我们称之为 EdgeRec3D。我们的系统利用三维计算机视觉的最新进展来进行感知和自动、细粒度的销售估算。这些感知成分运行在网络的边缘，便于实时奖励信号。此外，我们开发了贝叶斯支付模型，以考虑噪声估计从三维激光雷达数据。我们依靠空间聚类来使系统能够适应不同的消费者偏好，以及一个基于图的候选人生成算法来解决组合搜索问题。我们测试我们的系统在现实世界的商店两个，6-8周的 A/B 测试与饮料产品，并证明了35% 和27% 的销售分别增长。最后，我们对已部署的系统进行了为期28周的观察性研究监控，结果显示销售额增长了9.4% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Product+Assortment+with+Real-time+3D+Perception+and+Bayesian+Payoff+Estimation)|0|
|[Where Have You Been? A Study of Privacy Risk for Point-of-Interest Recommendation](https://doi.org/10.1145/3637528.3671758)|Kunlin Cai, Jinghuai Zhang, Zhiqing Hong, William Shand, Guang Wang, Desheng Zhang, Jianfeng Chi, Yuan Tian|Meta, New York, NY, USA; Rutgers University, New Brunswick, NJ, USA; Florida State University, Tallahassee, FL, USA; University of California, Los Angeles, Los Angeles, CA, USA|As location-based services (LBS) have grown in popularity, more human mobility data has been collected. The collected data can be used to build machine learning (ML) models for LBS to enhance their performance and improve overall experience for users. However, the convenience comes with the risk of privacy leakage since this type of data might contain sensitive information related to user identities, such as home/work locations. Prior work focuses on protecting mobility data privacy during transmission or prior to release, lacking the privacy risk evaluation of mobility data-based ML models. To better understand and quantify the privacy leakage in mobility data-based ML models, we design a privacy attack suite containing data extraction and membership inference attacks tailored for point-of-interest (POI) recommendation models, one of the most widely used mobility data-based ML models. These attacks in our attack suite assume different adversary knowledge and aim to extract different types of sensitive information from mobility data, providing a holistic privacy risk assessment for POI recommendation models. Our experimental evaluation using two real-world mobility datasets demonstrates that current POI recommendation models are vulnerable to our attacks. We also present unique findings to understand what types of mobility data are more susceptible to privacy attacks. Finally, we evaluate defenses against these attacks and highlight future directions and challenges.|随着基于位置的服务(LBS)越来越流行，越来越多的移动性数据被收集。所收集的数据可以用来为 LBS 建立机器学习(ML)模型，以提高它们的性能和改善用户的整体体验。然而，这种便利伴随着隐私泄露的风险，因为这类数据可能包含与用户身份有关的敏感信息，例如家庭/工作地点。此前的工作重点是保护移动数据在传输过程中或发布之前的隐私，缺乏基于移动数据的机器学习模型的隐私风险评估。为了更好地理解和量化基于移动性数据的机器学习模型中的隐私泄漏，我们设计了一个隐私攻击套件，其中包含针对感兴趣点(POI)推荐模型的数据提取和成员推断攻击，这是最广泛使用的基于移动性数据的机器学习模型之一。我们的攻击套件中的这些攻击假设不同的敌人知识，目的是从移动数据中提取不同类型的敏感信息，为 POI 推荐模型提供一个全面的隐私风险评估。我们的实验评估使用两个真实世界的移动性数据集表明，目前的 POI 推荐模型是脆弱的，我们的攻击。我们还提出了独特的发现，以了解哪些类型的移动数据更容易受到隐私攻击。最后，我们将评估针对这些攻击的防御措施，并强调未来的方向和挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Where+Have+You+Been?+A+Study+of+Privacy+Risk+for+Point-of-Interest+Recommendation)|0|
|[Neural Retrievers are Biased Towards LLM-Generated Content](https://doi.org/10.1145/3637528.3671882)|Sunhao Dai, Yuqi Zhou, Liang Pang, Weihao Liu, Xiaolin Hu, Yong Liu, Xiao Zhang, Gang Wang, Jun Xu|; Noah's Ark Lab, Huawei, Shenzhen, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China|Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search, by generating vast amounts of human-like texts on the Internet. As a result, IR systems in the LLM era are facing a new challenge: the indexed documents are now not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that neural retrieval models tend to rank LLM-generated documents higher. We refer to this category of biases in neural retrievers towards the LLM-generated content as the source bias. Moreover, we discover that this bias is not confined to the first-stage neural retrievers, but extends to the second-stage neural re-rankers. Then, in-depth analyses from the perspective of text compression indicate that LLM-generated texts exhibit more focused semantics with less noise, making it easier for neural retrieval models to semantic match. To mitigate the source bias, we also propose a plug-and-play debiased constraint for the optimization objective, and experimental results show its effectiveness. Finally, we discuss the potential severe concerns stemming from the observed source bias and hope our findings can serve as a critical wake-up call to the IR community and beyond. To facilitate future explorations of IR in the LLM era, the constructed two new benchmarks are available at https://github.com/KID-22/Source-Bias.|最近，大语言模型(LLMs)的出现彻底改变了信息检索(IR)应用的范式，特别是在网络搜索中，通过在互联网上生成大量类似人类的文本。因此，LLM 时代的信息检索系统面临着新的挑战: 索引文档不仅由人工编写，而且由 LLM 自动生成。这些 LLM 生成的文档如何影响 IR 系统是一个紧迫的、尚未探索的问题。在这项工作中，我们进行了定量评估的情况下，国际关系模型的人写和 LLM 生成的文本都涉及。令人惊讶的是，我们的研究结果表明，神经检索模型往往排名 LLM 生成的文档更高。我们将神经检索器对 LLM 生成的内容的这类偏差称为源偏差。此外，我们发现这种偏差并不局限于第一阶段的神经检索，而是延伸到第二阶段的神经重新排序。然后，从文本压缩的角度进行深入分析，结果表明 LLM 生成的文本具有更集中的语义和更少的噪声，使得神经检索模型更容易进行语义匹配。为了减小源偏差，我们还提出了一个即插即用的去偏约束优化目标，实验结果表明其有效性。最后，我们讨论了由观察到的来源偏差引起的潜在的严重关切，并希望我们的发现可以作为对 IR 社区和其他方面的一个关键的警告。为了促进 LLM 时代对信息检索的未来探索，构建了两个新的基准 https://github.com/kid-22/source-bias。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Retrievers+are+Biased+Towards+LLM-Generated+Content)|0|
|[DisCo: Towards Harmonious Disentanglement and Collaboration between Tabular and Semantic Space for Recommendation](https://doi.org/10.1145/3637528.3672008)|Kounianhua Du, Jizheng Chen, Jianghao Lin, Yunjia Xi, Hangyu Wang, Xinyi Dai, Bo Chen, Ruiming Tang, Weinan Zhang|Shanghai Jiao Tong University, Shanghai, China; Huawei Noah's Ark Lab, Shanghai, China; Huawei Noah's Ark Lab, Shenzhen, China|Recommender systems play important roles in various applications such ase-commerce, social media, etc. Conventional recommendation methods usuallymodel the collaborative signals within the tabular representation space.Despite the personalization modeling and the efficiency, the latent semanticdependencies are omitted. Methods that introduce semantics into recommendationthen emerge, injecting knowledge from the semantic representation space wherethe general language understanding are compressed. However, existingsemantic-enhanced recommendation methods focus on aligning the two spaces,during which the representations of the two spaces tend to get close while theunique patterns are discarded and not well explored. In this paper, we proposeDisCo to Disentangle the unique patterns from the two representation spaces andCollaborate the two spaces for recommendation enhancement, where both thespecificity and the consistency of the two spaces are captured. Concretely, wepropose 1) a dual-side attentive network to capture the intra-domain patternsand the inter-domain patterns, 2) a sufficiency constraint to preserve thetask-relevant information of each representation space and filter out thenoise, and 3) a disentanglement constraint to avoid the model from discardingthe unique information. These modules strike a balance between disentanglementand collaboration of the two representation spaces to produce informativepattern vectors, which could serve as extra features and be appended toarbitrary recommendation backbones for enhancement. Experiment results validatethe superiority of our method against different models and the compatibility ofDisCo over different backbones. Various ablation studies and efficiencyanalysis are also conducted to justify each model component.|推荐系统在电子商务、社交媒体等各种应用中发挥着重要作用。传统的推荐方法通常是在表格表示空间中对协作信号进行建模。尽管个性化建模和效率，潜在的语义依赖性被忽略。然后出现将语义引入推荐的方法，从语义表示空间注入知识，在这个空间中一般语言理解被压缩。然而，现有的语义增强推荐方法侧重于对齐这两个空间，在此期间，两个空间的表示趋于接近，而唯一的模式被丢弃，没有得到很好的探索。在本文中，我们提出了 DisCo 从两个表示空间中分离出唯一的模式，并协作两个空间进行推荐增强，同时捕获两个空间的特殊性和一致性。具体来说，我们提出了两种方案: 1)双侧注意网络捕获域内模式和域间模式; 2)充分约束保留每个表示空间的任务相关信息并过滤掉噪声; 3)解缠约束避免模型丢弃唯一信息。这些模块在两个表示空间的分离和协作之间取得了平衡，从而产生了信息模式向量，这些向量可以作为额外的特征，并附加到任意的推荐主干上进行增强。实验结果验证了该方法对不同模型的优越性以及 DisCo 在不同骨架上的兼容性。各种消融研究和效率分析也进行了验证每个模型组件。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DisCo:+Towards+Harmonious+Disentanglement+and+Collaboration+between+Tabular+and+Semantic+Space+for+Recommendation)|0|
|[Label Shift Correction via Bidirectional Marginal Distribution Matching](https://doi.org/10.1145/3637528.3671867)|Ruidong Fan, Xiao Ouyang, Hong Tao, Chenping Hou|National University of Defense Technology, Changsha, Hunan, China|Due to the timeliness and uncertainty of data acquisition, label shift, which assumes that the source (training) and target (test) label distributions differ, occurs with the changing environment and reduces the generalization ability of traditional models. To correct the label shift, existing methods estimate the true label distribution by prediction of target data from a source classifier, which results in high variance, especially with large label shift. In this paper, we tackle this problem by proposing a novel approach termed as Label Shift Correction via Bidirectional Marginal Distribution Matching (BMDM). Our approach matchs the label and feature marginal distributions simultaneously to ensure the stability of estimated class proportions. We prove theoretically that there is a unique optimal solution, i.e., true target label distribution, for our approach under mild conditions, and an efficient optimization strategy is also proposed. On this basis, in multi-shot scenario where label distribution changes continuously, we extend BMDM by designing a new distribution matching mechanism and constructing a regularization term that constrains the direction of label distribution change. Extensive experimental results validate the effectiveness of our approach over existing state-of-the-arts methods.|由于数据采集的及时性和不确定性，假设源(训练)和目标(测试)标签分布不同的标签偏移随着环境的变化而发生，降低了传统模型的泛化能力。为了校正标签偏移，现有的方法通过预测源分类器的目标数据来估计真实的标签分布，这导致了很大的方差，尤其是标签偏移。在本文中，我们提出了一种新的方法来解决这个问题，这种方法被称为双向边缘分布匹配的标签偏移校正(bMDM)。我们的方法同时匹配标签和特征的边际分布，以确保估计的类比例的稳定性。从理论上证明了该方法在温和条件下存在唯一的最优解，即真实目标标签分布，并提出了一种有效的优化策略。在此基础上，在标签分布不断变化的多镜头场景下，通过设计一种新的分布匹配机制，构造一个约束标签分布变化方向的正则项，对 BMDM 进行了扩展。大量的实验结果验证了我们的方法比现有的最先进的方法更有效。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Label+Shift+Correction+via+Bidirectional+Marginal+Distribution+Matching)|0|
|[On (Normalised) Discounted Cumulative Gain as an Off-Policy Evaluation Metric for Top-n Recommendation](https://doi.org/10.1145/3637528.3671687)|Olivier Jeunen, Ivan Potapov, Aleksei Ustimenko|ShareChat, London, United Kingdom; ShareChat, Edinburgh, United Kingdom|Approaches to recommendation are typically evaluated in one of two ways: (1)via a (simulated) online experiment, often seen as the gold standard, or (2)via some offline evaluation procedure, where the goal is to approximate theoutcome of an online experiment. Several offline evaluation metrics have beenadopted in the literature, inspired by ranking metrics prevalent in the fieldof Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is onesuch metric that has seen widespread adoption in empirical studies, and higher(n)DCG values have been used to present new methods as the state-of-the-art intop-n recommendation for many years. Our work takes a critical look at this approach, and investigates when we canexpect such metrics to approximate the gold standard outcome of an onlineexperiment. We formally present the assumptions that are necessary to considerDCG an unbiased estimator of online reward and provide a derivation for thismetric from first principles, highlighting where we deviate from itstraditional uses in IR. Importantly, we show that normalising the metricrenders it inconsistent, in that even when DCG is unbiased, ranking competingmethods by their normalised DCG can invert their relative order. Through acorrelation analysis between off- and on-line experiments conducted on alarge-scale recommendation platform, we show that our unbiased DCG estimatesstrongly correlate with online reward, even when some of the metric's inherentassumptions are violated. This statement no longer holds for its normalisedvariant, suggesting that nDCG's practical utility may be limited.|推荐方法通常以两种方式之一进行评估: (1)通过(模拟)在线实验，通常被视为黄金标准，或者(2)通过一些离线评估程序，其目标是近似在线实验的结果。文献中已经采用了一些线下评估指标，这些指标的灵感来自于信息检索领域中流行的排名指标。(标准化)贴现累积增益(nDCG)是在实证研究中得到广泛采用的一种度量标准，较高的(n) DCG 值已被用于表示新方法作为最先进的推荐方法多年。我们的工作对这种方法进行了批判性的研究，并且调查了我们什么时候可以期望这些指标接近在线实验的黄金标准结果。我们正式提出的假设是必要的，认为 DCG 是一个公正的估计在线奖励，并提供了从第一原则这一度量的推导，突出了我们偏离其传统用途在 IR。重要的是，我们表明，规范化的度量呈现它不一致，即使当 DCG 是无偏见的，排名竞争方法的规范化 DCG 可以颠倒他们的相对顺序。通过在大规模推荐平台上进行的离线和在线实验之间的相关性分析，我们表明我们的无偏 DCG 估计与在线奖励强烈相关，即使一些度量的固有假设被违背。这种说法不再适用于它的正常化变体，表明 nDCG 的实际用途可能是有限的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+(Normalised)+Discounted+Cumulative+Gain+as+an+Off-Policy+Evaluation+Metric+for+Top-n+Recommendation)|0|
|[FairMatch: Promoting Partial Label Learning by Unlabeled Samples](https://doi.org/10.1145/3637528.3671685)|Jiahao Jiang, Yuheng Jia, Hui Liu, Junhui Hou|Department of Computer Science, City University of Hong Kong, HongKong, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; College of Software Engineering, Southeast University, Nanjing, China; School of Computing & Information Sciences, Saint Francis University, HongKong, China|This paper studies the semi-supervised partial label learning (SSPLL) problem, which aims to improve the partial label learning (PLL) by leveraging unlabeled samples. Both the existing SSPLL methods and the semi-supervised learning methods exploit the information in unlabeled samples by selecting high-confidence unlabeled samples as the pseudo labels based on the maximum value of the model output. However, the scarcity of labeled samples and the ambiguity from partial labels skew this strategy towards an unfair selection of high-confidence samples on each class, most notably during the initial phases of training, resulting in slower training and performance degradation. In this paper, we propose a novel method FairMatch, which adopts a learning state aware self-adaptive threshold for selecting the same number of high-confidence samples on each class, and uses augmentation consistency to incorporate the unlabeled samples to promote PLL. In addition, we adopt the candidate label disambiguation to utilize the partial labeled samples and mix up the partial labeled samples and the selected high-confidence unlabeled samples to prevent the model from overfitting on partial label samples. FairMatch can achieve maximum accuracy improvements of 9.53%, 4.9%, and 16.45% on CIFAR-10, CIFAR-100, and CIFAR-100H, respectively. The codes can be found at https://github.com/jhjiangSEU/FairMatch.|本文研究了半监督部分标记学习(SSPLL)问题，旨在利用未标记样本改进部分标记学习(PLL)。现有的 SSPLL 方法和半监督学习方法都是根据模型输出的最大值，选择高置信度的未标记样本作为伪标签，从而利用未标记样本的信息。然而，标记样本的稀缺性和部分标记的模糊性使该策略倾向于在每个类别上不公平地选择高置信度样本，最显着的是在训练的初始阶段，导致训练较慢和性能下降。本文提出了一种新的 FairMatch 方法，该方法采用一种学习状态感知的自适应阈值来选择每类中相同数量的高置信度样本，并使用增强一致性来合并未标记的样本来提升锁相环。此外，我们采用候选标签消歧的方法，利用部分标签样本，混合部分标签样本和选择的高置信度未标签样本，以防止模型对部分标签样本的过度拟合。FairMatch 可以分别在 CIFAR-10，CIFAR-100和 CIFAR-100H 上实现9.53% ，4.9% 和16.45% 的最大准确性改进。密码可以在 https://github.com/jhjiangseu/fairmatch 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairMatch:+Promoting+Partial+Label+Learning+by+Unlabeled+Samples)|0|
|[Privileged Knowledge State Distillation for Reinforcement Learning-based Educational Path Recommendation](https://doi.org/10.1145/3637528.3671872)|Qingyao Li, Wei Xia, Li'ang Yin, Jiarui Jin, Yong Yu|Shanghai Jiao Tong University, Shanghai, China; Huawei Noah's Ark Lab, Shenzhen, China|Educational recommendation seeks to suggest knowledge concepts that match a learner's ability, thus facilitating a personalized learning experience. In recent years, reinforcement learning (RL) methods have achieved considerable results by taking the encoding of the learner's exercise log as the state and employing an RL-based agent to make suitable recommendations. However, these approaches suffer from handling the diverse and dynamic learner's knowledge states. In this paper, we introduce the privileged feature distillation technique and propose the P rivileged K nowledge S tate D istillation (PKSD ) framework, allowing the RL agent to leverage the "actual'' knowledge state as privileged information in the state encoding to help tailor recommendations to meet individual needs. Concretely, our PKSD takes the privileged knowledge states together with the representations of the exercise log for the state representations during training. And through distillation, we transfer the ability to adapt to learners to aknowledge state adapter. During inference, theknowledge state adapter would serve as the estimated privileged knowledge states instead of the real one since it is not accessible. Considering that there are strong connections among the knowledge concepts in education, we further propose to collaborate the graph structure learning for concepts into our PKSD framework. This new approach is termed GEPKSD (Graph-Enhanced PKSD). As our method is model-agnostic, we evaluate PKSD and GEPKSD by integrating them with five different RL bases on four public simulators, respectively. Our results verify that PKSD can consistently improve the recommendation performance with various RL methods, and our GEPKSD could further enhance the effectiveness of PKSD in all the simulations.|教育推荐旨在建议符合学习者能力的知识概念，从而促进个性化的学习体验。近年来，以学习者运动日志的编码为状态，并使用基于强化学习的代理来提出合适的建议，这些方法已经取得了相当大的成果。然而，这些方法在处理多样化和动态学习者的知识状态时存在缺陷。本文介绍了特权特征提取技术，提出了 P 特权 K 知识 S 状态 D 提取(PKSD)框架，允许 RL 代理利用“实际”知识状态作为状态编码中的特权信息，帮助定制推荐以满足个体需求。具体地说，我们的 PKSD 将特权知识状态与训练日志的表示一起提取，用于训练过程中的状态表示。并通过升华，将学习者的适应能力转化为知识状态适应能力。在推理过程中，知识状态适配器将作为估计的特权知识状态，而不是实际知识状态，因为它是不可访问的。考虑到教育中知识概念之间的紧密联系，我们进一步提出将概念的图形结构学习协同到 PKSD 框架中。这种新的方法被称为 GEPKSD (图形增强 PKSD)。由于我们的方法是模型无关的，所以我们分别在四个公共模拟器上将 PKSD 和 GEPKSD 与五个不同的 RL 基地集成在一起进行评估。实验结果表明，PKSD 能够持续改善各种 RL 方法的推荐性能，而 GEPKSD 能够进一步提高 PKSD 在所有仿真中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privileged+Knowledge+State+Distillation+for+Reinforcement+Learning-based+Educational+Path+Recommendation)|0|
|[Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach](https://doi.org/10.1145/3637528.3671848)|Yicong Li, Yu Yang, Jiannong Cao, Shuaiqi Liu, Haoran Tang, Guandong Xu|The Hong Kong Polytechnic University, Hong Kong, Hong Kong; The Education University of Hong Kong & University of Technology Sydney, Hong Kong, Hong Kong|Recent studies successfully learned static graph embeddings that arestructurally fair by preventing the effectiveness disparity of high- andlow-degree vertex groups in downstream graph mining tasks. However, achievingstructure fairness in dynamic graph embedding remains an open problem.Neglecting degree changes in dynamic graphs will significantly impair embeddingeffectiveness without notably improving structure fairness. This is because theembedding performance of high-degree and low-to-high-degree vertices willsignificantly drop close to the generally poorer embedding performance of mostslightly changed vertices in the long-tail part of the power-law distribution.We first identify biased structural evolutions in a dynamic graph based on theevolving trend of vertex degree and then propose FairDGE, the firststructurally Fair Dynamic Graph Embedding algorithm. FairDGE learns biasedstructural evolutions by jointly embedding the connection changes amongvertices and the long-short-term evolutionary trend of vertex degrees.Furthermore, a novel dual debiasing approach is devised to encode fairembeddings contrastively, customizing debiasing strategies for different biasedstructural evolutions. This innovative debiasing strategy breaks theeffectiveness bottleneck of embeddings without notable fairness loss. Extensiveexperiments demonstrate that FairDGE achieves simultaneous improvement in theeffectiveness and fairness of embeddings.|最近的研究成功地学习了静态图嵌入，通过防止有效性差异的高度和低度顶点组在下游图挖掘任务。然而，在动态图嵌入中实现结构公平性仍然是一个悬而未决的问题。忽略动态图的度变化会显著降低嵌入效率，而不能显著提高结构的公平性。这是因为在幂律分布的长尾部分，高度顶点和低到高度顶点的嵌入性能会明显下降，接近于最微小变化顶点的嵌入性能普遍较差。我们首先根据顶点度的演化趋势在动态图中识别有偏的结构演化，然后提出 FairDGE，第一个结构公平的动态图嵌入算法。FairDGE 通过联合嵌入顶点之间的联系变化和顶点度的长期短期演化趋势来学习有偏的结构演化。此外，设计了一种新的双重消偏方法来对比编码公平层合，定制消偏策略以适应不同的有偏结构演化。这种创新的去偏策略打破了嵌入的有效性瓶颈，没有明显的公平性损失。大量实验表明，FairDGE 算法同时提高了嵌入的有效性和公平性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Structure+Fairness+in+Dynamic+Graph+Embedding:+A+Trend-aware+Dual+Debiasing+Approach)|0|
|[Bridging Items and Language: A Transition Paradigm for Large Language Model-Based Recommendation](https://doi.org/10.1145/3637528.3671884)|Xinyu Lin, Wenjie Wang, Yongqi Li, Fuli Feng, SeeKiong Ng, TatSeng Chua|National University of Singapore, Singapore, Singapore; The Hong Kong Polytechnic University, Hong Kong SAR, China; University of Science and Technology of China, Hefei, China|Harnessing Large Language Models (LLMs) for recommendation is rapidly emerging, which relies on two fundamental steps to bridge the recommendation item space and the language space: 1) item indexing utilizes identifiers to represent items in the language space, and 2) generation grounding associates LLMs' generated token sequences to in-corpus items. However, previous methods exhibit inherent limitations in the two steps. Existing ID-based identifiers (e.g., numeric IDs) and description-based identifiers (e.g., titles) either lose semantics or lack adequate distinctiveness. Moreover, prior generation grounding methods might generate invalid identifiers, thus misaligning with in-corpus items. To address these issues, we propose a novel Transition paradigm for LLM-based Recommender (named TransRec) to bridge items and language. Specifically, TransRec presents multi-facet identifiers, which simultaneously incorporate ID, title, and attribute for item indexing to pursue both distinctiveness and semantics. Additionally, we introduce a specialized data structure for TransRec to ensure generating valid identifiers only and utilize substring indexing to encourage LLMs to generate from any position of identifiers. Lastly, TransRec presents an aggregated grounding module to leverage generated multi-facet identifiers to rank in-corpus items efficiently. We instantiate TransRec on two backbone models, BART-large and LLaMA-7B. Extensive results on three real-world datasets under diverse settings validate the superiority of TransRec.|利用大型语言模型(LLM)进行推荐正在迅速兴起，这依赖于两个基本步骤来连接推荐项空间和语言空间: 1)项索引利用标识符来表示语言空间中的项目，2)生成基础将 LLM 生成的令牌序列与语料库中的项目相关联。然而，以前的方法在这两个步骤中表现出固有的局限性。现有的基于 ID 的标识符(例如，数字 ID)和基于描述的标识符(例如，标题)要么失去语义，要么缺乏足够的区别性。此外，上一代接地方法可能会产生无效的标识符，从而与语料库中的项目不一致。为了解决这些问题，我们提出了一种新的基于 LLM 的传输范式(称为 TransRec) ，以连接项目和语言。具体来说，TransRec 提供了多方面标识符，这些标识符同时合并 ID、 title 和属性用于项目索引，以实现独特性和语义。此外，我们还为 TransRec 引入了专门的数据结构，以确保只生成有效的标识符，并利用子字符串索引鼓励 LLM 从标识符的任何位置生成标识符。最后，TransRec 提出了一个聚合的接地模块，利用生成的多方面标识符对语料库中的项目进行有效排序。我们在两个骨干模型上实例化 TransRec，BART-large 和 LLaMA-7B。在三个不同设置的真实世界数据集上的广泛结果验证了 TransRec 的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Items+and+Language:+A+Transition+Paradigm+for+Large+Language+Model-Based+Recommendation)|0|
|[BadSampler:  Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning](https://doi.org/10.1145/3637528.3671879)|Yi Liu, Cong Wang, Xingliang Yuan|City University of Hong Kong, Hong Kong, China; The University of Melbourne, Melbourne, Australia|Federated Learning (FL) is susceptible to poisoning attacks, wherein compromised clients manipulate the global model by modifying local datasets or sending manipulated model updates. Experienced defenders can readily detect and mitigate the poisoning effects of malicious behaviors using Byzantine-robust aggregation rules. However, the exploration of poisoning attacks in scenarios where such behaviors are absent remains largely unexplored for Byzantine-robust FL. This paper addresses the challenging problem of poisoning Byzantine-robust FL by introducing catastrophic forgetting. To fill this gap, we first formally define generalization error and establish its connection to catastrophic forgetting, paving the way for the development of a clean-label data poisoning attack named BadSampler. This attack leverages only clean-label data (i.e., without poisoned data) to poison Byzantine-robust FL and requires the adversary to selectively sample training data with high loss to feed model training and maximize the model's generalization error. We formulate the attack as an optimization problem and present two elegant adversarial sampling strategies, Top-k sampling, and meta-sampling, to approximately solve it. Additionally, our formal error upper bound and time complexity analysis demonstrate that our design can preserve attack utility with high efficiency. Extensive evaluations on two real-world datasets illustrate the effectiveness and performance of our proposed attacks.|联邦学习(FL)容易受到中毒攻击，其中受损的客户端通过修改本地数据集或发送受控模型更新来操纵全局模型。经验丰富的防御者可以很容易地使用拜占庭稳健的聚合规则检测和减轻恶意行为的毒害效应。然而，在没有这种行为的情况下，对中毒攻击的探索对于拜占庭-鲁棒 FL 来说仍然很大程度上是未知的。本文通过引入灾难遗忘，解决了对拜占庭-鲁棒 FL 中毒的挑战性问题。为了填补这一空白，我们首先正式定义了泛化误差，并建立了它与灾难性遗忘之间的联系，为名为 BadSampler 的清洁标签数据中毒攻击的开发铺平了道路。这种攻击只利用干净的标签数据(即，没有中毒的数据)来毒害拜占庭-鲁棒的 FL，并要求对手有选择地采样高损失的训练数据来提供模型训练，并最大限度地提高模型的泛化误差。我们把这种攻击作为一种最佳化问题，并提出了两种优雅的对抗性抽样策略: Top-k 抽样和 meta 抽样，来近似地解决这个问题。此外，我们的形式误差上限和时间复杂度分析表明，我们的设计可以保持攻击效用的高效率。对两个真实世界数据集的广泛评估说明了我们提出的攻击的有效性和性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BadSampler:++Harnessing+the+Power+of+Catastrophic+Forgetting+to+Poison+Byzantine-robust+Federated+Learning)|0|
|[Dataset Condensation for Time Series Classification via Dual Domain Matching](https://doi.org/10.1145/3637528.3671675)|Zhanyu Liu, Ke Hao, Guanjie Zheng, Yanwei Yu|Ocean University of China, Qingdao, China; Shanghai Jiao Tong University, Shanghai, China|Time series data has been demonstrated to be crucial in various researchfields. The management of large quantities of time series data presentschallenges in terms of deep learning tasks, particularly for training a deepneural network. Recently, a technique named Dataset Condensation hasemerged as a solution to this problem. This technique generates a smallersynthetic dataset that has comparable performance to the full real dataset indownstream tasks such as classification. However, previous methods areprimarily designed for image and graph datasets, and directly adapting them tothe time series dataset leads to suboptimal performance due to their inabilityto effectively leverage the rich information inherent in time series data,particularly in the frequency domain. In this paper, we propose a novelframework named Dataset Condensation forTime SeriesClassification via Dual Domain Matching (CondTSC)which focuses on the time series classification dataset condensation task.Different from previous methods, our proposed framework aims to generate acondensed dataset that matches the surrogate objectives in both the time andfrequency domains. Specifically, CondTSC incorporates multi-view dataaugmentation, dual domain training, and dual surrogate objectives to enhancethe dataset condensation process in the time and frequency domains. Throughextensive experiments, we demonstrate the effectiveness of our proposedframework, which outperforms other baselines and learns a condensed syntheticdataset that exhibits desirable characteristics such as conforming to thedistribution of the original data.|时间序列数据已被证明在各个研究领域都是至关重要的。大量时间序列数据的管理在深度学习任务方面面临挑战，特别是在训练深度神经网络方面。最近，一种名为“数据集压缩”的技术被用来解决这个问题。该技术生成一个较小的合成数据集，其性能与完整的实际数据集的下游任务(如分类)具有可比性。然而，以前的方法主要是为图像和图形数据集设计的，直接将它们适应于时间序列数据集会导致次优性能，因为它们无法有效地利用时间序列数据中固有的丰富信息，特别是在频率域。本文提出了一种基于双域匹配的时间序列分类数据集压缩框架(CondTSC) ，该框架主要针对时间序列分类数据集压缩任务。与以往的方法不同，我们提出的框架旨在生成在时间和频率领域匹配替代目标的浓缩数据集。具体来说，CondTSC 结合了多视图数据增强、双域训练和双代理目标来增强数据集在时间和频率域的缩聚过程。通过大量的实验，我们证明了我们提出的框架的有效性，它的性能优于其他基线，并学习了一个浓缩的合成数据集，这个数据集展示了令人满意的特征，例如符合原始数据的分布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dataset+Condensation+for+Time+Series+Classification+via+Dual+Domain+Matching)|0|
|[Self-Supervised Denoising through Independent Cascade Graph Augmentation for Robust Social Recommendation](https://doi.org/10.1145/3637528.3671958)|Youchen Sun, Zhu Sun, Yingpeng Du, Jie Zhang, Yew Soon Ong|; Nanyang Technological University, Singapore, Singapore; ASTAR Centre for Frontier AI Research & Nanyang Technological University, Singapore, Singapore|Social Recommendation (SR) typically exploits neighborhood influence in the social network to enhance user preference modeling. However, users' intricate social behaviors may introduce noisy social connections for user modeling and harm the models' robustness. Existing solutions to alleviate social noise either filter out the noisy connections or generate new potential social connections. Due to the absence of labels, the former approaches may retain uncertain connections for user preference modeling while the latter methods may introduce additional social noise. Through data analysis, we discover that (1) social noise likely comes from the connected users with low preference similarity; and (2) Opinion Leaders (OLs) play a pivotal role in influence dissemination, surpassing high-similarity neighbors, regardless of their preference similarity with trusting peers. Guided by these observations, we propose a novel Self-Supervised Denoising approach through Independent Cascade Graph Augmentation, for more robust SR. Specifically, we employ the independent cascade diffusion model to generate an augmented graph view, which traverses the social graph and activates the edges in sequence to simulate the cascading influence spread. To steer the augmentation towards a denoised social graph, we (1) introduce a hierarchical contrastive loss to prioritize the activation of OLs first, followed by high-similarity neighbors, while weakening the low-similarity neighbors; and (2) integrate an information bottleneck based contrastive loss, aiming to minimize mutual information between original and augmented graphs yet preserve sufficient information for improved SR. Experiments conducted on two public datasets demonstrate that our model outperforms the state-of-the-art while also exhibiting higher robustness to different extents of social noise.|社交推荐(SR)通常利用社交网络中的邻域影响来增强用户偏好建模。然而，用户错综复杂的社会行为可能为用户建模引入噪声社会关系，损害模型的鲁棒性。现有的减轻社会噪音的解决方案要么过滤掉噪音连接，要么产生新的潜在社会连接。由于标签的缺失，前一种方法在用户偏好建模时可能会保留不确定的联系，而后一种方法可能会引入额外的社会噪声。通过数据分析，我们发现: (1)社交噪声可能来自偏好相似度较低的关联用户; (2)意见领袖(OLs)在影响力传播中发挥着关键作用，超过了高相似度的邻居，而不管他们与信任同伴的偏好相似度如何。在这些观测结果的指导下，我们提出了一种新的自我监督去噪方法，通过独立级联图增强，更健壮的 SR。具体来说，我们采用独立的级联扩散模型来生成一个扩展图视图，该视图横穿社会图并依次激活边界，以模拟级联影响的传播。为了将扩展引向去噪的社会图，我们(1)引入分层对比损失来优先激活 OLs，然后是高相似性邻居，同时弱化低相似性邻居; (2)整合基于对比损失的信息瓶颈，旨在最小化原始图和扩展图之间的相互信息，同时保留足够的信息以改善 SR。在两个公共数据集上进行的实验表明，我们的模型优于最先进的水平，同时也表现出对不同程度的社会噪声更高的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Denoising+through+Independent+Cascade+Graph+Augmentation+for+Robust+Social+Recommendation)|0|
|[Revisiting Local PageRank Estimation on Undirected Graphs: Simple and Optimal](https://doi.org/10.1145/3637528.3671820)|Hanzhi Wang|Renmin University of China, Beijing, China|We propose a simple and optimal algorithm, BackMC, for local PageRank estimation in undirected graphs: given an arbitrary target node t in an undirected graph G comprising n nodes and m edges, BackMC accurately estimates the PageRank score of node t while assuring a small relative error and a high success probability. The worst-case computational complexity of BackMC is upper bounded by O(1/dmin ⋅ min(dt, m1/2)), where dmin denotes the minimum degree of G, and dt denotes the degree of t, respectively. Compared to the previously best upper bound of O(log n ⋅ min(dt, m1/2)) (VLDB '23), which is derived from a significantly more complex algorithm and analysis, our BackMC improves the computational complexity for this problem by a factor of Θ(log n/dmin) with a much simpler algorithm. Furthermore, we establish a matching lower bound of Ω(1/dmin ⋅ min(dt, m1/2)) for any algorithm that attempts to solve the problem of local PageRank estimation, demonstrating the theoretical optimality of our BackMC. We conduct extensive experiments on various large-scale real-world and synthetic graphs, where BackMC consistently shows superior performance.|针对无向图的局部 PageRank 估计问题，提出了一种简单而优化的 BackMC 算法: 在包含 n 个节点和 m 条边的无向图 G 中，给定一个任意目标节点 t，BackMC 在保证较小的相对误差和较高的成功概率的情况下，精确地估计节点 t 的 PageRank 得分。最坏情况下 BackMC 的计算复杂度上界为 O (1/dmin ≥ min (dt，m1/2)) ，其中 dmin 表示 G 的最小度，dt 表示 t 的最小度。相比之前的最佳上界 O (log n  (dt，m1/2))(VLDB’23) ，它是由一个更加复杂的算法和分析得到的，我们的 BackMC 用一个更加简单的算法提高了 Θ (log n/dmin)的一个因子，从而提高了这个问题的计算复杂度。进一步，我们建立了任何试图解决局部 PageRank 估计问题的算法的匹配下界 Ω (1/dmin min (dt，m1/2)) ，证明了我们的 BackMC 算法的理论最优性。我们在各种大规模的真实世界和合成图上进行广泛的实验，其中 BackMC 始终显示出优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Local+PageRank+Estimation+on+Undirected+Graphs:+Simple+and+Optimal)|0|
|[Performative Debias with Fair-exposure Optimization Driven by Strategic Agents in Recommender Systems](https://doi.org/10.1145/3637528.3671786)|Zhichen Xiang, Hongke Zhao, Chuang Zhao, Ming He, Jianping Fan|; AI Lab at Lenovo Research, Beijing, China; The Hong Kong University of Science and Technology, Hong Kong, China|Data bias, e.g., popularity impairs the dynamics of two-sided markets within recommender systems. This overshadows the less visible but potentially intriguing long-tail items that could capture user interest. Despite the abundance of research surrounding this issue, it still poses challenges and remains a hot topic in academic circles. Along this line, in this paper, we developed a re-ranking approach in dynamic settings with fair-exposure optimization driven by strategic agents. Designed for the producer side, the execution of agents assumes content creators can modify item features based on strategic incentives to maximize their exposure. This iterative process entails an end-to-end optimization, employing differentiable ranking operators that simultaneously target accuracy and fairness. Joint objectives ensure the performance of recommendations while enhancing the visibility of tail items. We also leveraged the performativity nature of predictions to illustrate how strategic learning influences content creators to shift towards fairness efficiently, thereby incentivizing features of tail items. Through comprehensive experiments on both public and industrial datasets, we have substantiated the effectiveness and dominance of the proposed method especially on unveiling the potential of tail items.|数据偏差，例如，受欢迎程度会损害推荐系统中双边市场的动态性。这掩盖了不太可见但可能引起用户兴趣的长尾项目。尽管围绕这一问题进行了大量的研究，但它仍然是学术界面临的挑战和热点问题。沿着这条路线，本文开发了一种在动态环境下的重新排序方法，其中公平曝光优化是由战略代理驱动的。代理的执行是为生产者设计的，它假定内容创造者可以基于战略激励来修改项目特征，以最大限度地提高他们的曝光率。这个迭代过程需要一个端到端的优化，使用可微排名运算符，同时目标的准确性和公平性。联合目标确保建议的执行，同时提高尾部项目的可见性。我们还利用预测的执行性质来说明战略学习如何影响内容创建者有效地转向公平，从而激励尾部项目的特性。通过对公共数据集和工业数据集的综合实验，验证了该方法的有效性和优越性，特别是在揭示尾部项目的潜力方面。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Performative+Debias+with+Fair-exposure+Optimization+Driven+by+Strategic+Agents+in+Recommender+Systems)|0|
|[Preventing Strategic Behaviors in Collaborative Inference for Vertical Federated Learning](https://doi.org/10.1145/3637528.3671663)|Yidan Xing, Zhenzhe Zheng, Fan Wu|Shanghai Jiao Tong University, Shanghai, China|Vertical federated learning (VFL) is an emerging collaborative machine learning paradigm to facilitate the utilization of private features distributed across multiple parties. During the inference process of VFL, the involved parties need to upload their local embeddings to be aggregated for the final prediction. Despite its remarkable performances, the inference process of the current VFL system is vulnerable to the strategic behavior of involved parties, as they could easily change the uploaded local embeddings to exert direct influences on the prediction result. In a representative case study of federated recommendation, we find the allocation of display opportunities to be severely disrupted due to the parties' preferences in display content. In order to elicit the true local embeddings for VFL system, we propose a distribution-based penalty mechanism to detect and penalize the strategic behaviors in collaborative inference. As the key motivation of our design, we theoretically prove the power of constraining the distribution of uploaded embeddings in preventing the dishonest parties from achieving higher utility. Our mechanism leverages statistical two-sample tests to distinguish whether the distribution of uploaded embeddings is reasonable, and penalize the dishonest party through deactivating her uploaded embeddings. The resulted mechanism could be shown to admit truth-telling to converge to a Bayesian Nash equilibrium asymptotically under mild conditions. The experimental results further demonstrate the effectiveness of the proposed mechanism to reduce the dishonest utility increase of strategic behaviors and promote the truthful uploading of local embeddings in inferences.|垂直联邦学习(VFL)是一种新兴的协作机器学习范式，它有助于利用分布在多个方面的私有特性。在 VFL 的推理过程中，各参与方需要上传自己的局部嵌入信息进行聚合，才能得到最终的预测结果。当前 VFL 系统的推理过程虽然具有显著的性能，但容易受到相关各方策略行为的影响，因为它们很容易改变上传的局部嵌入，从而直接影响预测结果。在联邦推荐的一个典型案例中，我们发现由于各方对显示内容的偏好，显示机会的分配会受到严重干扰。为了在 VFL 系统中实现真正的局部嵌入，我们提出了一种基于分布的惩罚机制来检测和惩罚协同推理中的策略行为。作为我们设计的关键动机，我们从理论上证明了约束上传嵌入分布的力量，防止不诚实的当事人获得更高的效用。我们的机制利用统计双样本检验来判断上传嵌入的分布是否合理，并通过停用不诚实方的上传嵌入来惩罚不诚实方。结果显示，在温和的条件下，该机制能够承认说实话，并渐近地收敛到贝叶斯纳什均衡点。实验结果进一步证明了该机制在减少策略行为的不诚实效用增加和促进推理中局部嵌入的真实上传方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preventing+Strategic+Behaviors+in+Collaborative+Inference+for+Vertical+Federated+Learning)|0|
|[Extreme Meta-Classification for Large-Scale Zero-Shot Retrieval](https://doi.org/10.1145/3637528.3672046)|Sachin Yadav, Deepak Saini, Anirudh Buvanesh, Bhawna Paliwal, Kunal Dahiya, Siddarth Asokan, Yashoteja Prabhu, Jian Jiao, Manik Varma|Indian Institute of Technology, Delhi, India; Microsoft, Redmond, WA, USA; Microsoft Research, Bangalore, India|We develop accurate and efficient solutions for large-scale retrieval tasks where novel (zero-shot) items can arrive continuously at a rapid pace. Conventional Siamese-style approaches embed both queries and items through a small encoder and retrieve the items lying closest to the query. While this approach allows efficient addition and retrieval of novel items, the small encoder lacks sufficient capacity for the necessary world knowledge in complex retrieval tasks. The extreme classification approaches have addressed this by learning a separate classifier for each item observed in the training set which significantly increases the representation capacity of the model. Such classifiers outperform Siamese approaches on observed items, but cannot be trained for novel items due to data and latency constraints. To bridge these gaps, this paper develops: (1) A new algorithmic framework, EMMETT, which efficiently synthesizes classifiers on-the-fly for novel items, by relying on the readily available classifiers for observed items; (2) A new algorithm, IRENE, which is a simple and effective instance of EMMETT that is specifically suited for large-scale deployments, and (3) A new theoretical framework for analyzing the generalization performance in large-scale zero-shot retrieval which guides our algorithm and training related design decisions. Comprehensive experiments are conducted on a wide range of retrieval tasks which demonstrate that IRENE improves the zero-shot retrieval accuracy by up to 15% points in Recall@10 when added on top of leading encoders. Additionally, on an online A/B test in a large-scale ad retrieval task in a major search engine, IRENE improved the ad click-through rate by 4.2%. Lastly, we validate our design choices through extensive ablative experiments. The source code for IRENE is available at https://aka.ms/irene.|我们开发准确和有效的解决方案，大规模的检索任务，新的(零射击)项目可以连续到达快速的步伐。传统的暹罗式方法通过一个小编码器嵌入查询和项，并检索与查询最接近的项。虽然这种方法可以有效地增加和检索新的项目，小编码器缺乏足够的能力，必要的世界知识在复杂的检索任务。极端分类方法通过为训练集中观察到的每个项目学习一个单独的分类器来解决这个问题，这大大提高了模型的表示能力。这种分类器在观察项目上的表现优于暹罗方法，但是由于数据和延迟限制，不能对新项目进行训练。为了弥补这些差距，本文开发了: (1)一种新的算法框架—— EMMETT，该算法依靠现有的分类器对观察到的项目进行高效的动态综合分类; (2)一种新的算法—— IRENE，它是 EMMETT 的一个简单而有效的实例，特别适合于大规模部署; (3)一种新的理论框架，用于分析大规模零拍检索中的泛化性能，指导我们的算法和训练相关的设计决策。实验结果表明，在前置编码器的基础上加入 IRENE 后，Recall@10的零镜头检索精度提高了15% 。此外，在一个主要搜索引擎的大规模广告检索任务的在线 A/B 测试中，iRENE 将广告点进率提高了4.2% 。最后，我们通过广泛的烧蚀实验验证了我们的设计选择。IRENe 的源代码可在 https://aka.ms/IRENE 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extreme+Meta-Classification+for+Large-Scale+Zero-Shot+Retrieval)|0|
|[Conversational Dueling Bandits in Generalized Linear Models](https://doi.org/10.1145/3637528.3671892)|Shuhua Yang, Hui Yuan, Xiaoying Zhang, Mengdi Wang, Hong Zhang, Huazheng Wang|ByteDance, Beijing, China; University of Science and Technology of China, Hefei, China; Oregon State University, Corvallis, OR, USA; Princeton University, Princeton, NJ, USA|Conversational recommendation systems elicit user preferences by interacting with users to obtain their feedback on recommended commodities. Such systems utilize a multi-armed bandit framework to learn user preferences in an online manner and have received great success in recent years. However, existing conversational bandit methods have several limitations. First, they only enable users to provide explicit binary feedback on the recommended items or categories, leading to ambiguity in interpretation. In practice, users are usually faced with more than one choice. Relative feedback, known for its informativeness, has gained increasing popularity in recommendation system design. Moreover, current contextual bandit methods mainly work under linear reward assumptions, ignoring practical non-linear reward structures in generalized linear models. Therefore, in this paper, we introduce relative feedback-based conversations into conversational recommendation systems through the integration of dueling bandits in generalized linear models (GLM) and propose a novel conversational dueling bandit algorithm called ConDuel. Theoretical analyses of regret upper bounds and empirical validations on synthetic and real-world data underscore ConDuel's efficacy. We also demonstrate the potential to extend our algorithm to multinomial logit bandits with theoretical and experimental guarantees, which further proves the applicability of the proposed framework.|对话式推荐系统通过与用户进行交互以获得他们对推荐商品的反馈，从而引起用户的偏好。这类系统利用多臂老虎机框架，以在线方式学习用户偏好，近年来取得了巨大成功。然而，现有的会话强盗方法有一些局限性。首先，它们只允许用户对推荐的项目或类别提供明确的二进制反馈，从而导致解释上的歧义。实际上，用户通常面临不止一种选择。相对反馈以信息量大而闻名，在推荐系统设计中越来越受欢迎。此外，目前的情境强盗方法主要在线性报酬假设下工作，忽略了广义线性模型中实际的非线性报酬结构。因此，本文通过广义线性模型(GLM)中对决斗强盗的集成，将基于相对反馈的会话引入到会话推荐系统中，提出了一种新的会话决斗强盗算法 ConDuel。对遗憾上限的理论分析以及对合成数据和现实数据的经验验证强调了 ConDuel 的有效性。在理论和实验的基础上，证明了该算法在多项式 Logit 强盗问题上的可行性，进一步证明了该算法的适用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Dueling+Bandits+in+Generalized+Linear+Models)|0|
|[User Welfare Optimization in Recommender Systems with Competing Content Creators](https://doi.org/10.1145/3637528.3672021)|Fan Yao, Yiming Liao, Mingzhe Wu, Chuanhao Li, Yan Zhu, James Yang, Jingzhou Liu, Qifan Wang, Haifeng Xu, Hongning Wang|Google, Mountain View, USA; Yale University, New Haven, USA; Meta Platforms, Inc., Menlo Park, USA; University of Southern California, Los Angeles, USA; University of Virginia, Charlottesville, USA; University of Chicago, Chicago, USA; Meta Platforms, Inc., New York, USA|Driven by the new economic opportunities created by the creator economy, an increasing number of content creators rely on and compete for revenue generated from online content recommendation platforms. This burgeoning competition reshapes the dynamics of content distribution and profoundly impacts long-term user welfare on the platform. However, the absence of a comprehensive picture of global user preference distribution often traps the competition, especially the creators, in states that yield sub-optimal user welfare. To encourage creators to best serve a broad user population with relevant content, it becomes the platform's responsibility to leverage its information advantage regarding user preference distribution to accurately signal creators. In this study, we perform system-side user welfare optimization under a competitive game setting among content creators. We propose an algorithmic solution for the platform, which dynamically computes a sequence of weights for each user based on their satisfaction of the recommended content. These weights are then utilized to design mechanisms that adjust the recommendation policy or the post-recommendation rewards, thereby influencing creators' content production strategies. To validate the effectiveness of our proposed method, we report our findings from a series of experiments, including: 1. a proof-of-concept negative example illustrating how creators' strategies converge towards sub-optimal states without platform intervention; 2. offline experiments employing our proposed intervention mechanisms on diverse datasets; and 3. results from a three-week online experiment conducted on Instagram Reels short-video recommendation platform.|在创作者经济带来的新经济机遇的驱动下，越来越多的内容创作者依赖并竞争在线内容推荐平台产生的收入。这种蓬勃发展的竞争重塑了内容分发的动态，并深刻影响了平台上的长期用户福利。然而，缺乏全球用户偏好分布的全面图像，往往会使竞争，尤其是创造者陷入产生次优用户福利的状态。为了鼓励创作者用相关内容最好地服务于广泛的用户群体，平台有责任利用其在用户偏好分布方面的信息优势来准确地向创作者发出信号。在这项研究中，我们在内容创作者之间的竞争博弈环境下进行系统端用户福利优化。我们提出了一个平台的算法解决方案，该方案根据每个用户对推荐内容的满意度动态计算每个用户的权重序列。然后利用这些权重来设计调整推荐策略或推荐后奖励的机制，从而影响创作者的内容生产策略。为了验证我们提出的方法的有效性，我们报告了一系列的实验结果，包括: 1。一个概念证明的否定例子，说明创造者的策略如何在没有平台干预的情况下收敛到次优状态;。在不同的数据集上使用我们提出的干预机制的离线实验;。在 Instagram Reels 短视频推荐平台上进行了为期三周的在线实验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Welfare+Optimization+in+Recommender+Systems+with+Competing+Content+Creators)|0|
|[Embedding Two-View Knowledge Graphs with Class Inheritance and Structural Similarity](https://doi.org/10.1145/3637528.3671941)|Kyuhwan Yeom, Hyeongjun Yang, Gayeon Park, Myeongheon Jeon, Yunjeong Ko, Byungkook Oh, KyongHo Lee|Computer Science and Engineering, Konkuk University, Seoul, Republic of Korea; Artificial Intelligence, Yonsei University, Seoul, Republic of Korea; Computer Science, Yonsei University, Seoul, Republic of Korea|Numerous large-scale knowledge graphs (KGs) fundamentally represent two-view KGs: an ontology-view KG with abstract classes in ontology and an instance-view KG with specific collections of entities instantiated from ontology classes. Two-view KG embedding aims to jointly learn continuous vector representations of entities and relations in the aforementioned two-view KGs. In essence, an ontology schema exhibits a tree-like structure guided by class hierarchies, which leads classes to form inheritance hierarchies. However, existing two-view KG embedding models neglect those hierarchies, which provides the necessity to reflect class inheritance. On the other hand, KG is constructed based on a pre-defined ontology schema that includes heterogeneous relations between classes. Furthermore, these relations are defined within the scope of those among classes since instances inherit all the properties of their corresponding classes, which reveals structural similarity between two multi-relational networks. Despite the consideration to bridge the gap among two-view KG representations, existing methods ignore the existence of structural similarity between two-view KGs. To address these issues, we propose a novel two-view KG embedding model, CISS, considering Class Inheritance and Structural Similarity between two-view KGs. To deal with class inheritance, we utilize class sets, each of which is composed of sibling classes, to learn fine-grained class representations. In addition, we configure virtual instance-view KG from clustered instances and compare subgraph representations of two-view KGs to enhance structural similarity between them. Experimental results show our superior performance compared to existing models.|许多大规模的知识图(KG)从根本上表示两个视图 KG: 一个本体视图 KG 具有本体中的抽象类，一个实例视图 KG 具有从本体类实例化的实体的特定集合。双视图幼儿园嵌入的目的是联合学习上述两视图幼儿园中实体和关系的连续向量表示。从本质上讲，本体模式表现出一种由类层次结构引导的树状结构，这种结构引导类形成继承层次结构。然而，现有的双视图 KG 嵌入模型忽略了这些层次结构，这就需要反映类继承。另一方面，KG 是基于一个预定义的本体模式构建的，该模式包含类之间的异构关系。此外，这些关系是在类之间的范围内定义的，因为实例继承了相应类的所有属性，这揭示了两个多关系网络之间的结构相似性。尽管现行方法已考虑填补双视角幼稚园表现形式之间的差距，但却忽略了双视角幼稚园之间是否存在结构相似性。为了解决这些问题，我们提出了一个新的双视图幼儿园嵌入模型 CISS，该模型考虑了类继承和双视图幼儿园之间的结构相似性。为了处理类继承，我们利用类集(每个类集都由兄弟类组成)来学习细粒度的类表示。此外，我们从集群实例配置虚拟实例视图幼稚园，并比较两个视图幼稚园的子图表示，以增强它们之间的结构相似性。实验结果表明，我们的性能优于现有的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+Two-View+Knowledge+Graphs+with+Class+Inheritance+and+Structural+Similarity)|0|
|[Item-Difficulty-Aware Learning Path Recommendation: From a Real Walking Perspective](https://doi.org/10.1145/3637528.3671947)|Haotian Zhang, Shuanghong Shen, Bihan Xu, Zhenya Huang, Jinze Wu, Jing Sha, Shijin Wang|; iFLYTEK AI Research, Hefei, China; State Key Laboratory of Cognitive Intelligence & iFLYTEK AI Research, Hefei, China|Learning path recommendation aims to provide learners with a reasonable order of items to achieve their learning goals. Intuitively, the learning process on the learning path can be metaphorically likened to walking. Despite extensive efforts in this area, most previous methods mainly focus on the relationship among items but overlook the difficulty of items, which may raise two issues from a real walking perspective: (1) The path may be rough: When learners tread the path without considering item difficulty, it's akin to walking a dark, uneven road, making learning harder and dampening interest. (2) The path may be inefficient: Allowing learners only a few attempts on very challenging items before switching, or persisting with a difficult item despite numerous attempts without mastery, can result in inefficiencies in the learning journey. To conquer the above limitations, we propose a novel method named Difficulty-constrained Learning Path Recommendation (DLPR), which is aware of item difficulty. Specifically, we first explicitly categorize items into learning items and practice items, then construct a hierarchical graph to model and leverage item difficulty adequately. Then we design a Difficulty-driven Hierarchical Reinforcement Learning (DHRL) framework to facilitate learning paths with efficiency and smoothness. Finally, extensive experiments on three different simulators demonstrate our framework achieves state-of-the-art performance.|学习路径推荐的目的是为学习者提供一个合理的项目顺序，以实现他们的学习目标。直观地说，学习过程中的学习路径可以比喻为行走。尽管在这个领域做了大量的努力，以前的大多数方法主要关注项目之间的关系，但是忽略了项目的难度，这可能会从一个真正的行走的角度提出两个问题: (1)路径可能是粗糙的: 当学习者在不考虑项目难度的情况下行走在路径上，这就像走在一条黑暗的、不平坦的路上，使学习更加困难和抑制兴趣。(2)路径可能是低效的: 允许学习者在转换之前只尝试几次非常具有挑战性的项目，或者尽管尝试了很多次但没有掌握，仍然坚持一个困难的项目，可能会导致学习过程中的低效。为了克服上述限制，本文提出了一种新的学习路径推荐方法——难度约束学习路径推荐(DLPR) ，该方法能够识别项目的难度。具体来说，我们首先明确地将项目分类为学习项目和实践项目，然后构建一个层次图来充分地建模和利用项目难度。然后，我们设计了一个难度驱动的层次强化学习(dHRL)框架，以促进学习路径的有效性和顺畅性。最后，在三个不同的模拟器上进行了广泛的实验，证明了我们的框架实现了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item-Difficulty-Aware+Learning+Path+Recommendation:+From+a+Real+Walking+Perspective)|0|
|[Optimized Cost Per Click in Online Advertising: A Theoretical Analysis](https://doi.org/10.1145/3637528.3671767)|Kaichen Zhang, Zixuan Yuan, Hui Xiong||In recent years, Optimized Cost Per Click (OCPC) and Optimized Cost Per Mille(OCPM) have emerged as the most widely adopted pricing models in the onlineadvertising industry. However, the existing literature has yet to identify thespecific conditions under which these models outperform traditional pricingmodels like Cost Per Click (CPC) and Cost Per Action (CPA). To fill the gap,this paper builds an economic model that compares OCPC with CPC and CPAtheoretically, which incorporates out-site scenarios and outside options as twokey factors. Our analysis reveals that OCPC can effectively replace CPA bytackling the problem of advertisers strategically manipulating conversionreporting in out-site scenarios where conversions occur outside the advertisingplatform. Furthermore, OCPC exhibits the potential to surpass CPC in platformpayoffs by providing higher advertiser payoffs and consequently attracting moreadvertisers. However, if advertisers have less competitive outside options andconsistently stay in the focal platform, the platform may achieve higherpayoffs using CPC. Our findings deliver valuable insights for onlineadvertising platforms in selecting optimal pricing models, and providerecommendations for further enhancing their payoffs. To the best of ourknowledge, this is the first study to analyze OCPC from an economicperspective. Moreover, our analysis can be applied to the OCPM model as well.|近年来，优化每点击成本(OCPC)和优化每公里成本(OCPM)已经成为在线广告行业最广泛采用的定价模型。然而，现有文献尚未确定这些模型优于传统定价模型如每次点击成本(CPC)和每次行动成本(CPA)的具体条件。为了填补这一空白，本文从理论上建立了一个比较 OCPC 与 CPC 和 CPA 的经济模型，该模型将场外情景和场外选择作为两个关键因素。我们的分析表明，OCPC 可以有效地替代 CPA，解决广告商在转化发生在广告平台之外的外部场景中策略性地操纵转化报告的问题。此外，OCPC 通过提供更高的广告客户收益，从而吸引更多的广告客户，在平台收益方面显示出超过 CPC 的潜力。然而，如果广告商没有那么多竞争性的外部选择，并且一直呆在焦点平台上，那么该平台可能会利用 CPC 获得更高的回报。我们的研究结果为在线广告平台选择最佳定价模型提供了有价值的见解，并为进一步提高其收益提供了建议。据我们所知，这是第一个从经济学角度分析 OCPC 的研究。此外，我们的分析也适用于 OCPM 模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimized+Cost+Per+Click+in+Online+Advertising:+A+Theoretical+Analysis)|0|
|[Counteracting Duration Bias in Video Recommendation via Counterfactual Watch Time](https://doi.org/10.1145/3637528.3671817)|Haiyuan Zhao, Guohao Cai, Jieming Zhu, Zhenhua Dong, Jun Xu, JiRong Wen|Noah's Ark Lab, Huawei, Shenzhen, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China|In video recommendation, an ongoing effort is to satisfy users' personalizedinformation needs by leveraging their logged watch time. However, watch timeprediction suffers from duration bias, hindering its ability to reflect users'interests accurately. Existing label-correction approaches attempt to uncoveruser interests through grouping and normalizing observed watch time accordingto video duration. Although effective to some extent, we found that theseapproaches regard completely played records (i.e., a user watches the entirevideo) as equally high interest, which deviates from what we observed on realdatasets: users have varied explicit feedback proportion when completelyplaying videos. In this paper, we introduce the counterfactual watch time(CWT),the potential watch time a user would spend on the video if its duration issufficiently long. Analysis shows that the duration bias is caused by thetruncation of CWT due to the video duration limitation, which usually occurs onthose completely played records. Besides, a Counterfactual Watch Model (CWM) isproposed, revealing that CWT equals the time users get the maximum benefit fromvideo recommender systems. Moreover, a cost-based transform function is definedto transform the CWT into the estimation of user interest, and the model can belearned by optimizing a counterfactual likelihood function defined overobserved user watch times. Extensive experiments on three real videorecommendation datasets and online A/B testing demonstrated that CWMeffectively enhanced video recommendation accuracy and counteracted theduration bias.|在视频推荐中，一个持续的努力是通过利用用户的观看时间来满足用户的个性化信息需求。然而，手表时间预测存在持续时间偏差，影响了其准确反映用户兴趣的能力。现有的标签校正方法试图通过根据视频持续时间对观看时间进行分组和标准化来揭示用户的兴趣。虽然在某种程度上有效，但是我们发现这些方法把完全播放的记录(例如，用户观看整个视频)视为同样高的兴趣，这偏离了我们在真实数据集上观察到的: 当完全播放视频时，用户有不同的显式反馈比例。本文介绍了反事实观看时间(CWT) ，即当视频持续时间过长时，用户可能花在视频上的观看时间。分析表明，持续时间偏差是由于视频持续时间受到限制而导致的连续小波变换(CWT)截断所引起的，这种情况通常发生在完全播放的记录上。此外，提出了一种反事实观察模型(CWM) ，揭示了 CWT 等于用户从视频推荐系统中获得最大收益的时间。此外，定义了一个基于代价的转换函数，将连续小波变换转换为用户兴趣的估计，该模型可以通过优化一个反事实似然函数来定义过度观察的用户观察时间。在三个真实视频推荐数据集上的大量实验和在线 A/B 测试表明，CWM 有效地提高了视频推荐的准确性，抵消了持续时间偏差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counteracting+Duration+Bias+in+Video+Recommendation+via+Counterfactual+Watch+Time)|0|
|[MMBee: Live Streaming Gift-Sending Recommendations via Multi-Modal Fusion and Behaviour Expansion](https://doi.org/10.1145/3637528.3671511)|Jiaxin Deng, Shiyao Wang, Yuchen Wang, Jiansong Qi, Liqin Zhao, Guorui Zhou, Gaofeng Meng|; Institute of Automation, Beijing, China; KuaiShou Inc., Beijing, China|Live streaming services are becoming increasingly popular due to real-time interactions and entertainment. Viewers can chat and send comments or virtual gifts to express their preferences for the streamers. Accurately modeling the gifting interaction not only enhances users' experience but also increases streamers' revenue. Previous studies on live streaming gifting prediction treat this task as a conventional recommendation problem, and model users' preferences using categorical data and observed historical behaviors. However, it is challenging to precisely describe the real-time content changes in live streaming using limited categorical information. Moreover, due to the sparsity of gifting behaviors, capturing the preferences and intentions of users is quite difficult. In this work, we propose MMBee based on real-time Multi-Modal Fusion and Behaviour Expansion to address these issues. Specifically, we first present a Multi-modal Fusion Module with Learnable Query (MFQ) to perceive the dynamic content of streaming segments and process complex multi-modal interactions, including images, text comments and speech. To alleviate the sparsity issue of gifting behaviors, we present a novel Graph-guided Interest Expansion (GIE) approach that learns both user and streamer representations on large-scale gifting graphs with multi-modal attributes. It consists of two main parts: graph node representations pre-training and metapath-based behavior expansion, all of which help model jump out of the specific historical gifting behaviors for exploration and largely enrich the behavior representations. Comprehensive experiment results show that MMBee achieves significant performance improvements on both public datasets and Kuaishou real-world streaming datasets and the effectiveness has been further validated through online A/B experiments. MMBee has been deployed and is serving hundreds of millions of users at Kuaishou.|由于实时交互和娱乐，流媒体直播服务变得越来越流行。观众可以聊天和发送评论或虚拟礼物来表达他们对主播的喜好。精确建模礼物互动不仅提高了用户的体验，而且增加了主播的收入。以往的流媒体直播礼物预测研究将这一任务视为一个传统的推荐问题，并利用分类数据和观察到的历史行为对用户的偏好进行建模。然而，使用有限的分类信息来精确描述直播流中的实时内容变化是一个挑战。此外，由于送礼行为的稀少性，要捕捉用户的喜好和意图是相当困难的。在这项工作中，我们提出了基于实时多模态融合和行为扩展的 MMBee 来解决这些问题。具体来说，我们首先提出了一种基于可学习查询(Learnable Query，MFQ)的多模态融合模块来感知流媒体片段的动态内容，并处理复杂的多模态交互，包括图像、文本注释和语音。为了缓解送礼行为的稀疏性问题，我们提出了一种新的图引导兴趣扩展(GIE)方法，该方法同时学习用户和流媒体在具有多模态属性的大规模送礼图上的表示。它包括两个主要部分: 图节点表示预训练和基于元路径的行为扩展，所有这些都有助于模型跳出具体的历史馈赠行为去探索，并大大丰富了行为表示。综合实验结果表明，mMBee 在公共数据集和 Kuaishou 真实世界流数据集上都取得了显著的性能改善，并通过在线 A/B 实验进一步验证了其有效性。MMBee 已经部署完毕，目前正在 Kuaishou 为数亿用户服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMBee:+Live+Streaming+Gift-Sending+Recommendations+via+Multi-Modal+Fusion+and+Behaviour+Expansion)|0|
|[Contextual Distillation Model for Diversified Recommendation](https://doi.org/10.1145/3637528.3671514)|Fan Li, Xu Si, Shisong Tang, Dingmin Wang, Kunyan Han, Bing Han, Guorui Zhou, Yang Song, Hechang Chen|University of Science and Technology of China, Hefei, China; Kuaishou Inc., Beijing, China; Jilin University, Changchun, China; Tsinghua University, Beijing, China; Kuaishou Inc. & Tsinghua University, Beijing, China; University of Oxford, Oxford, United Kingdom|The diversity of recommendation is equally crucial as accuracy in improvinguser experience. Existing studies, e.g., Determinantal Point Process (DPP) andMaximal Marginal Relevance (MMR), employ a greedy paradigm to iterativelyselect items that optimize both accuracy and diversity. However, prior methodstypically exhibit quadratic complexity, limiting their applications to there-ranking stage and are not applicable to other recommendation stages with alarger pool of candidate items, such as the pre-ranking and ranking stages. Inthis paper, we propose Contextual Distillation Model (CDM), an efficientrecommendation model that addresses diversification, suitable for thedeployment in all stages of industrial recommendation pipelines. Specifically,CDM utilizes the candidate items in the same user request as context to enhancethe diversification of the results. We propose a contrastive context encoderthat employs attention mechanisms to model both positive and negative contexts.For the training of CDM, we compare each target item with its context embeddingand utilize the knowledge distillation framework to learn the win probabilityof each target item under the MMR algorithm, where the teacher is derived fromMMR outputs. During inference, ranking is performed through a linearcombination of the recommendation and student model scores, ensuring bothdiversity and efficiency. We perform offline evaluations on two industrialdatasets and conduct online A/B test of CDM on the short-video platformKuaiShou. The considerable enhancements observed in both recommendation qualityand diversity, as shown by metrics, provide strong superiority for theeffectiveness of CDM.|推荐的多样性与提高用户体验的准确性同样重要。现有的研究，例如行列式点过程(DPP)和最大边际相关性(MMR) ，采用贪婪的范式迭代选择项目，优化准确性和多样性。然而，先验方法通常表现出二次复杂性，将其应用限制在三阶段排名阶段，不适用于其他候选项目较多的推荐阶段，如预先排名阶段和排名阶段。本文提出了一种适用于行业推荐流程各个阶段的高效多样化推荐模型——上下文精馏模型(CDM)。具体来说，CDM 利用同一用户请求中的候选项作为上下文，以增强结果的多样化。我们提出了一个对比语境编码器，它使用注意机制来模拟积极和消极的语境。对于 CDM 的培训，我们将每个目标项目与其上下文嵌入进行比较，并利用知识提取框架在 MMR 算法下学习每个目标项目的获胜概率，其中教师是从 MMR 输出中获得的。在推理过程中，排名是通过推荐和学生模型得分的线性组合来完成的，从而保证了多样性和效率。我们对两个工业数据集进行离线评估，并在快手短视频平台上对 CDM 进行在线 A/B 测试。指标表明，在推荐质量和多样性方面观察到的显著增强为 CDM 的有效性提供了强大的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contextual+Distillation+Model+for+Diversified+Recommendation)|0|
|[MGMatch: Fast Matchmaking with Nonlinear Objective and Constraints via Multimodal Deep Graph Learning](https://doi.org/10.1145/3637528.3671553)|Yu Sun, Kai Wang, Zhipeng Hu, Runze Wu, Yaoxin Wu, Wen Song, Xudong Shen, Tangjie Lv, Changjie Fan|Eindhoven University of Technology, Eindhoven, Netherlands; Fuxi AI Lab, NetEase Inc., Hangzhou, Zhejiang, China; Shandong University, Qingdao, Shandong, China|As a core problem of online games, matchmaking is to assign players into multiple teams to maximize their gaming experience. With the rapid development of game industry, it is increasingly difficulty to explicitly model players' experiences as linear functions. Instead, it is often modeled in a data-driven way by training a neural network. Meanwhile, complex rules must be satisfied to ensure the robustness of matchmaking, which are often described using logical operators. Therefore, matchmaking in practical scenarios is a challenging combinatorial optimization problem with nonlinear objective, linear constraints and logical constraints, which receives much less attention in previous research. In this paper, we propose a novel deep learning method for high-quality matchmaking in real-time. We first cast the problem as standard mixed-integer programming (MIP) by linearizing ReLU networks and logical constraints. Then, based on supervised learning, we design and train a multi-modal graph learning architecture to predict optimal solutions end-to-end from instance data, and solve a surrogate problem to efficiently obtain feasible solutions. Evaluation results on real industry datasets show that our method can deliver near-optimal solutions within 100ms.|作为网络游戏的一个核心问题，匹配是将玩家分配到多个团队中，以最大限度地提高他们的游戏体验。随着游戏产业的快速发展，将玩家的体验明确地建模为线性函数变得越来越困难。相反，它通常是通过训练神经网络以数据驱动的方式建模的。同时，为了保证匹配的鲁棒性，必须满足复杂的规则，这些规则通常用逻辑运算符来描述。因此，实际场景中的匹配问题是一个具有非线性目标、线性约束和逻辑约束的组合优化问题，在以往的研究中受到的关注较少。本文提出了一种新的高质量实时匹配的深度学习方法。首先通过线性化 ReLU 网络和逻辑约束将问题转化为标准的混合整数规划(MIP)问题。然后，在监督式学习的基础上，我们设计并训练了一个多模态图学习架构来从实例数据中预测端到端的最优解，并解决一个代理问题来有效地获得可行的解。对实际工业数据集的评估结果表明，该方法可以在100ms 内提供接近最优的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MGMatch:+Fast+Matchmaking+with+Nonlinear+Objective+and+Constraints+via+Multimodal+Deep+Graph+Learning)|0|
|[R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models](https://doi.org/10.1145/3637528.3671564)|Shangqing Tu, Yuanchun Wang, Jifan Yu, Yuyang Xie, Yaran Shi, Xiaozhi Wang, Jing Zhang, Lei Hou, Juanzi Li|DCST, Tsinghua University, Beijing, China; BNRist, DCST, Tsinghua University, Beijing, China; SIOE, Beihang University, Beijing, China; SoI, Renmin University of China, Beijing, China|Large language models have achieved remarkable success on general NLP tasks,but they may fall short for domain-specific problems. Recently, variousRetrieval-Augmented Large Language Models (RALLMs) are proposed to address thisshortcoming. However, existing evaluation tools only provide a few baselinesand evaluate them on various domains without mining the depth of domainknowledge. In this paper, we address the challenges of evaluating RALLMs byintroducing the R-Eval toolkit, a Python toolkit designed to streamline theevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,which supports popular built-in RAG workflows and allows for the incorporationof customized testing data on the specific domain, is designed to beuser-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMsacross three task levels and two representative domains, revealing significantvariations in the effectiveness of RALLMs across different tasks and domains.Our analysis emphasizes the importance of considering both task and domainrequirements when choosing a RAG workflow and LLM combination. We are committedto continuously maintaining our platform at https://github.com/THU-KEG/R-Evalto facilitate both the industry and the researchers.|大型语言模型已经在一般的 NLP 任务上取得了显著的成功，但是它们可能在特定领域的问题上有所不足。最近，各种检索增强大型语言模型(RALLMs)被提出来解决这个问题。然而，现有的评估工具只提供了一些基线，并在不同的领域进行评估，而没有挖掘领域知识的深度。在本文中，我们通过引入 R-Eval 工具包来解决评估 RAG 工作流的挑战，这是一个 Python 工具包，旨在与 LLM 一起简化不同 RAG 工作流的评估。我们的工具包，支持流行的内置 RAG 工作流程，并允许在特定领域集成定制的测试数据，被设计成用户友好的、模块化的和可扩展的。我们在三个任务级别和两个代表性领域对21个 RALLM 进行了评估，揭示了 RALLM 在不同任务和领域的有效性的显著差异。我们的分析强调了在选择 RAG 工作流和 LLM 组合时同时考虑任务和领域需求的重要性。我们致力于不断维护我们的平台， https://github.com/thu-keg/r-evalto 为业界和研究人员提供便利。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=R-Eval:+A+Unified+Toolkit+for+Evaluating+Domain+Knowledge+of+Retrieval+Augmented+Large+Language+Models)|0|
|[ADSNet: Cross-Domain LTV Prediction with an Adaptive Siamese Network in Advertising](https://doi.org/10.1145/3637528.3671612)|Ruize Wang, Hui Xu, Ying Cheng, Qi He, Xing Zhou, Rui Feng, Wei Xu, Lei Huang, Jie Jiang|Tencent Inc., Shanghai, China; Tencent Inc., Shenzhen, China; School of Computer Science, Fudan University, Shanghai, China|Advertising platforms have evolved in estimating Lifetime Value (LTV) to better align with advertisers' true performance metric which considers cumulative sum of purchases a customer contributes over a period. Accurate LTV estimation is crucial for the precision of the advertising system and the effectiveness of advertisements. However, the sparsity of real-world LTV data presents a significant challenge to LTV predictive model(i.e., pLTV), severely limiting the their capabilities. Therefore, we propose to utilize external data, in addition to the internal data of advertising platform, to expand the size of purchase samples and enhance the LTV prediction model of the advertising platform. To tackle the issue of data distribution shift between internal and external platforms, we introduce an Adaptive Difference Siamese Network (ADSNet), which employs cross-domain transfer learning to prevent negative transfer. Specifically, ADSNet is designed to learn information that is beneficial to the target domain. We introduce a gain evaluation strategy to calculate information gain, aiding the model in learning helpful information for the target domain and providing the ability to reject noisy samples, thus avoiding negative transfer. Additionally, we also design a Domain Adaptation Module as a bridge to connect different domains, reduce the distribution distance between them, and enhance the consistency of representation space distribution. We conduct extensive offline experiments and online A/B tests on a real advertising platform. Our proposed ADSNet method outperforms other methods, improving GINI by 2%. The ablation study highlights the importance of the gain evaluation strategy in negative gain sample rejection and improving model performance. Additionally, ADSNet significantly improves long-tail prediction. The online A/B tests confirm ADSNet's efficacy, increasing online LTV by 3.47% and GMV by 3.89%.|广告平台已经发展到估算终身价值(LTV) ，以便更好地与广告商的真实业绩指标保持一致，后者考虑的是消费者在一段时间内贡献的累计购买总额。准确的 LTV 估计对于广告系统的准确性和广告的有效性至关重要。然而，实际 LTV 数据的稀疏性对 LTV 预测模型(即 pLTV)提出了严峻的挑战，严重限制了它们的能力。因此，我们建议利用外部数据，除了广告平台的内部数据外，扩大购买样本的规模，提高广告平台的 LTV 预测模型。为了解决内部平台和外部平台之间数据分布转移的问题，我们引入了自适应差分暹罗网(ADSNet) ，该网络采用跨域传输学习来防止负向传输。具体来说，ADSNet 是为了学习对目标域有益的信息而设计的。我们引入一个增益评估策略来计算信息增益，帮助模型学习目标域的有用信息，并提供拒绝噪声样本的能力，从而避免负迁移。此外，我们还设计了一个领域适应模块作为连接不同领域的桥梁，减少它们之间的分布距离，提高表示空间分布的一致性。我们在一个真实的广告平台上进行广泛的离线实验和在线 A/B 测试。我们提出的 ADSNet 方法优于其他方法，GINI 提高了2% 。烧蚀研究突出了增益评价策略在抑制负增益样本和改善模型性能中的重要性。此外，ADSNet 显著改善了长尾预测。在线 A/B 测试证实了 ADSNet 的有效性，在线 LTV 增加了3.47% ，GMV 增加了3.89% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ADSNet:+Cross-Domain+LTV+Prediction+with+an+Adaptive+Siamese+Network+in+Advertising)|0|
|[Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks](https://doi.org/10.1145/3637528.3671569)|Yijie Zhang, Yuanchen Bei, Hao Chen, Qijie Shen, Zheng Yuan, Huan Gong, Senzhang Wang, Feiran Huang, Xiao Huang|National University of Defense Technology, Changsha, China; Central South University, Hunan, Changsha, China; Jinan University, Guangzhou, China; Zhejiang University, Zhejiang, Hangzhou, China; Alibaba Group, Zhejiang, Hangzhou, China; The Hong Kong Polytechnic University, Hong Kong, China|Representing information of multiple behaviors in the single graph collaborative filtering (CF) vector has been a long-standing challenge. This is because different behaviors naturally form separate behavior graphs and learn separate CF embeddings. Existing models merge the separate embeddings by appointing the CF embeddings for some behaviors as the primary embedding and utilizing other auxiliaries to enhance the primary embedding. However, this approach often results in the joint embedding performing well on the main tasks but poorly on the auxiliary ones. To address the problem arising from the separate behavior graphs, we propose the concept of Partial Order Recommendation Graphs (POG). POG defines the partial order relation of multiple behaviors and models behavior combinations as weighted edges to merge separate behavior graphs into a joint POG. Theoretical proof verifies that POG can be generalized to any given set of multiple behaviors. Based on POG, we propose the tailored Partial Order Graph Convolutional Networks (POGCN) that convolute neighbors' information while considering the behavior relations between users and items. POGCN also introduces a partial-order BPR sampling strategy for efficient and effective multiple-behavior CF training. POGCN has been successfully deployed on the homepage of Alibaba for two months, providing recommendation services for over one billion users. Extensive offline experiments conducted on three public benchmark datasets demonstrate that POGCN outperforms state-of-the-art multi-behavior baselines across all types of behaviors. Furthermore, online A/B tests confirm the superiority of POGCN in billion-scale recommender systems.|在单一图形协同过滤(CF)向量中表示多种行为的信息一直是一个长期的挑战。这是因为不同的行为自然地形成独立的行为图，并学习独立的 CF 嵌入。现有的模型通过指定一些行为的 CF 嵌入作为主嵌入，并利用其他辅助来增强主嵌入，从而将分离的嵌入进行合并。然而，这种方法往往导致联合嵌入在主要任务上表现良好，但在辅助任务上表现不佳。为了解决分离的行为图所带来的问题，我们提出了偏序推荐图(POG)的概念。POG 将多个行为和模型行为组合的偏序关系定义为加权边，以便将单独的行为图合并到一个联合 POG 中。理论证明了 POG 可以推广到任意给定的一组多行为。在 POG 的基础上，提出了一种考虑用户与项目之间行为关系的卷积邻居信息的剪裁偏序图卷积网络(POGCN)。POGCN 还引入了一种偏序 BPR 抽样策略，用于有效的多行为 CF 训练。POgcn 已成功登入阿里巴巴网页两个月，为超过十亿用户提供推荐服务。在三个公共基准数据集上进行的大量离线实验表明，POGCN 在所有类型的行为上都优于最先进的多行为基准。此外，在线 A/B 测试证实了 POGCN 在亿万规模推荐系统中的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavior+Collaborative+Filtering+with+Partial+Order+Graph+Convolutional+Networks)|0|
|[Inductive Modeling for Realtime Cold Start Recommendations](https://doi.org/10.1145/3637528.3671588)|Chandler Zuo, Jonathan Castaldo, Hanqing Zhu, Haoyu Zhang, Ji Liu, Yangpeng Ou, Xiao Kong|Meta, Menlo Park, CA, USA|In recommendation systems, the timely delivery of new content to their relevant audiences is critical for generating a growing and high quality collection of content for all users. The nature of this problem requires retrieval models to be able to make inferences in real time and with high relevance. There are two specific challenges for cold start contents. First, the information loss problem in a standard Two Tower model, due to the limited feature interactions between the user and item towers, is exacerbated for cold start items due to training data sparsity. Second, the huge volume of user-generated content in industry applications today poses a big bottleneck in the end-to-end latency of recommending new content. To overcome the two challenges, we propose a novel architecture, the Item History Model (IHM). IHM directly injects user-interaction information into the item tower to overcome information loss. In addition, IHM incorporates an inductive structure using attention-based pooling to eliminate the need for recurring training, a key bottleneck for the real-timeness. On both public and industry datasets, we demonstrate that IHM can not only outperform baselines in recommending cold start contents, but also achieves SoTA real-timeness in industry applications.|在推荐系统中，及时向相关受众提供新内容对于为所有用户收集越来越多的高质量内容至关重要。这个问题的性质要求检索模型能够实时地进行推理，并且具有高度的相关性。对于冷启动内容有两个具体的挑战。首先，标准双塔模型中的信息丢失问题，由于用户和项目塔之间的特征交互有限，由于训练数据稀疏而加剧了冷启动项目的信息丢失问题。其次，当今行业应用程序中的大量用户生成内容对推荐新内容的端到端延迟造成了巨大的瓶颈。为了克服这两个挑战，我们提出了一个新的体系结构，项目历史模型(IHM)。IHM 直接将用户交互信息注入到项目塔中以克服信息丢失。此外，IHM 采用了一种归纳结构，使用基于注意力的汇集来消除重复训练的需要，这是实时性的一个关键瓶颈。在公共数据集和工业数据集上，我们证明 IHM 不仅在推荐冷启动内容方面优于基线，而且在工业应用中实现了 SoTA 的实时性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inductive+Modeling+for+Realtime+Cold+Start+Recommendations)|0|
|[Bias and Unfairness in Information Retrieval Systems: New Challenges in the LLM Era](https://doi.org/10.1145/3637528.3671458)|Sunhao Dai, Chen Xu, Shicheng Xu, Liang Pang, Zhenhua Dong, Jun Xu|; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Huawei Noah's Ark Lab, Shenzhen, China|With the rapid advancements of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a significant paradigm shift. This evolution, while heralding new opportunities, introduces emerging challenges, particularly in terms of biases and unfairness, which may threaten the information ecosystem. In this paper, we present a comprehensive survey of existing works on emerging and pressing bias and unfairness issues in IR systems when the integration of LLMs. We first unify bias and unfairness issues as distribution mismatch problems, providing a groundwork for categorizing various mitigation strategies through distribution alignment. Subsequently, we systematically delve into the specific bias and unfairness issues arising from three critical stages of LLMs integration into IR systems: data collection, model development, and result evaluation. In doing so, we meticulously review and analyze recent literature, focusing on the definitions, characteristics, and corresponding mitigation strategies associated with these issues. Finally, we identify and highlight some open problems and challenges for future work, aiming to inspire researchers and stakeholders in the IR field and beyond to better understand and mitigate bias and unfairness issues of IR in this LLM era. We also consistently maintain a GitHub repository for the relevant papers and resources in this rising direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey.|随着大型语言模型(LLM)的快速发展，搜索引擎和推荐系统等信息检索(IR)系统经历了一个重大的范式转变。这种演变虽然预示着新的机遇，但也带来了新的挑战，特别是偏见和不公平方面的挑战，可能威胁到信息生态系统。在本文中，我们提出了一个综合调查的现有工作中出现的和紧迫的偏见和不公平问题的国际关系系统时，一体化的 LLM。我们首先将偏见和不公平问题统一为分布不匹配问题，为通过分布对齐来分类各种缓解策略提供了基础。随后，我们系统地研究了 LLM 集成到 IR 系统的三个关键阶段所引起的具体的偏见和不公平问题: 数据收集、模型开发和结果评估。在这样做的时候，我们仔细审查和分析最近的文献，重点是定义，特点和相应的缓解策略与这些问题有关。最后，我们确定并强调了一些开放的问题和未来工作的挑战，旨在激励研究人员和利益相关者在国际关系领域和以外更好地理解和减轻在这个 LLM 时代的国际关系的偏见和不公平问题。我们也一直保持着一个 GitHub 资源库，用来存放这个不断增长的 https://GitHub.com/kid-22/llm-ir-bias-fairness-survey 的相关文章和资源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+and+Unfairness+in+Information+Retrieval+Systems:+New+Challenges+in+the+LLM+Era)|0|
|[Approximating Memorization Using Loss Surface Geometry for Dataset Pruning and Summarization](https://doi.org/10.1145/3637528.3671985)|Andrea Agiollo, Young In Kim, Rajiv Khanna|University of Bologna, Bologna, Italy; Purdue University, West Lafayette, IN, USA|The sustainable training of modern neural network models represents an open challenge. Several existing methods approach this issue by identifying a subset of relevant data samples from the full training data to be used in model optimization with the goal of matching the performance of the full data training with that of the subset data training. Our work explores using memorization scores to find representative and atypical samples. We demonstrate that memorization-aware dataset summarization improves the subset construction performance. However, computing memorization scores is notably resource-intensive. To this end, we propose a novel method that leverages the discrepancy between sharpness-aware minimization and stochastic gradient descent to capture data points atypicality. We evaluate our metric over several efficient approximation functions for memorization scores - namely proxies -, empirically showing superior correlation and effectiveness. We explore the causes behind our approximation quality, highlighting how typical data points trigger a flatter loss landscape compared to atypical ones. Extensive experiments confirm the effectiveness of our proxy for dataset pruning and summarization tasks, surpassing state-of-the-art approaches both on canonical setups - where atypical data points benefit performance - and few-shot learning scenarios-where atypical data points can be detrimental.|现代神经网络模型的可持续训练是一个开放的挑战。一些现有的方法通过从完整的训练数据中确定一个相关数据样本子集来解决这个问题，这些数据样本将用于模型优化，目标是使完整数据训练的性能与子集数据训练的性能相匹配。我们的工作探索使用记忆分数来寻找代表性和非典型样本。我们证明了记忆感知的数据集摘要能够提高幂集构造的性能。然而，计算记忆分数是显著的资源密集型。为此，我们提出了一种新的方法，利用锐度感知最小化和随机梯度下降之间的差异来捕捉数据点的非典型性。我们评估我们的度量在几个有效的近似函数的记忆分数-即代理-，经验表明优越的相关性和有效性。我们探索了近似质量背后的原因，强调了典型数据点与非典型数据点相比如何触发更平坦的损失景观。大量的实验证实了我们的代理对于数据集裁剪和总结任务的有效性，超越了在规范设置(非典型数据点有利于性能)和少数学习场景(非典型数据点可能是有害的)上的最新方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Approximating+Memorization+Using+Loss+Surface+Geometry+for+Dataset+Pruning+and+Summarization)|0|
|[Evading Community Detection via Counterfactual Neighborhood Search](https://doi.org/10.1145/3637528.3671896)|Andrea Bernini, Fabrizio Silvestri, Gabriele Tolomei|Sapienza University of Rome, Rome, Italy|Community detection techniques are useful for social media platforms todiscover tightly connected groups of users who share common interests. However,this functionality often comes at the expense of potentially exposingindividuals to privacy breaches by inadvertently revealing their tastes orpreferences. Therefore, some users may wish to preserve their anonymity and optout of community detection for various reasons, such as affiliation withpolitical or religious organizations, without leaving the platform. In thisstudy, we address the challenge of community membership hiding, which involvesstrategically altering the structural properties of a network graph to preventone or more nodes from being identified by a given community detectionalgorithm. We tackle this problem by formulating it as a constrainedcounterfactual graph objective, and we solve it via deep reinforcementlearning. Extensive experiments demonstrate that our method outperformsexisting baselines, striking the best balance between accuracy and cost.|社区检测技术对于社交媒体平台发现有共同兴趣的紧密联系的用户群非常有用。然而，这种功能往往是以牺牲个人隐私被侵犯的潜在风险为代价的，因为它无意中暴露了个人的品味或偏好。因此，一些用户可能希望保持匿名，并出于各种原因，例如与政治或宗教组织的联系，而不离开平台，拒绝进行社区检测。在这项研究中，我们解决了社区成员隐藏的挑战，这涉及到策略性地改变网络图的结构特性，以防止一个或多个节点被给定的社区检测算法识别。我们把这个问题表述为一个有约束的反事实图目标，并通过深度强化学习来解决它。大量的实验表明，我们的方法性能优于现有的基线，在准确性和成本之间达到了最佳的平衡。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evading+Community+Detection+via+Counterfactual+Neighborhood+Search)|0|
|[FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering](https://doi.org/10.1145/3637528.3672065)|Tianchi Cai, Zhiwen Tan, Xierui Song, Tao Sun, Jiyan Jiang, Yunqi Xu, Yinger Zhang, Jinjie Gu|Tsinghua University, Beijing, China; Ant Group, Hangzhou, China|Retrieval Augmented Generation (RAG) has become prevalent in question-answering (QA) tasks due to its ability of utilizing search engine to enhance the quality of long-form question-answering (LFQA). Despite the emergence of various open source methods and web-enhanced commercial systems such as Bing Chat, two critical problems remain unsolved, i.e., the lack of factuality and clear logic in the generated long-form answers. In this paper, we remedy these issues via a systematic study on answer generation in web-enhanced LFQA. Specifically, we first propose a novel outline-enhanced generator to achieve clear logic in the generation of multifaceted answers and construct two datasets accordingly. Then we propose a factuality optimization method based on a carefully designed doubly fine-grained RLHF framework, which contains automatic evaluation and reward modeling in different levels of granularity. Our generic framework comprises conventional fine-grained RLHF methods as special cases. Extensive experiments verify the superiority of our proposed Factuality-optimized RAG (FoRAG) method on both English and Chinese benchmarks. In particular, when applying our method to Llama2-7B-chat, the derived model FoRAG-L-7B outperforms WebGPT-175B in terms of three commonly used metrics (i.e., coherence, helpfulness, and factuality), while the number of parameters is much smaller (only 1/24 of that of WebGPT-175B). Our datasets and models are made publicly available for better reproducibility.https://huggingface.co/forag łabelfootnote_dataset_url|检索增强生成技术(RAG)由于能够利用搜索引擎提高长形式问答(LFQA)的质量，在问答(QA)任务中得到了广泛的应用。尽管出现了各种开源方法和网络增强的商业系统，如必应聊天，两个关键问题仍然没有得到解决，即缺乏事实性和清晰的逻辑生成的长形式的答案。本文通过对网络增强型 LFQA 中问题生成的系统研究，解决了这些问题。具体来说，我们首先提出了一种新的轮廓增强生成器，以实现清晰的逻辑生成多方面的答案，并相应地构造两个数据集。然后提出了一种基于精心设计的双细粒度 RLHF 框架的事实优化方法，该框架包含了不同粒度级别的自动评价和奖励建模。我们的通用框架包括传统的细粒度 RLHF 方法作为特殊情况。大量的实验验证了我们提出的基于事实优化的 RAG (FoRAG)方法在中英文基准测试中的优越性。特别是，当将我们的方法应用于 Llama2-7B-chat 时，衍生模型 FoRAG-L-7B 在三个常用指标(即一致性，有益性和真实性)方面优于 WebGPT-175B，而参数的数量要小得多(只有 WebGPT-175B 的1/24)。我们的数据集和模型公开发布，以便更好地重现。 https://huggingface.co/forag abelfoonote _ datset _ url|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FoRAG:+Factuality-optimized+Retrieval+Augmented+Generation+for+Web-enhanced+Long-form+Question+Answering)|0|
|[A Hierarchical Context Augmentation Method to Improve Retrieval-Augmented LLMs on Scientific Papers](https://doi.org/10.1145/3637528.3671847)|TianYi Che, XianLing Mao, Tian Lan, Heyan Huang|Beijing Institute of Technology, Beijing, China|Scientific papers of a large scale on the Internet encompass a wealth of data and knowledge, attracting the attention of numerous researchers. To fully utilize these knowledge, Retrieval-Augmented Large Language Models (LLMs) usually leverage large-scale scientific corpus to train and then retrieve relevant passages from external memory to improve generation, which have demonstrated outstanding performance. However, existing methods can only capture one-dimension fragmented textual information without incorporating hierarchical structural knowledge, eg. the deduction relationship of abstract and main body, which makes it difficult to grasp the central thought of papers. To tackle this problem, we propose a hierarchical context augmentation method, which helps Retrieval-Augmented LLMs to autoregressively learn the structure knowledge of scientific papers. Specifically, we utilize the document tree to represent the hierarchical relationship of a paper and enhance the structure information of scientific context from three aspects: scale, format and global information. First, we think each top-bottom path of document tree is a logical independent context, which can be used to largely increase the scale of extracted structural corpus. Second, we propose a novel label-based format to represent the structure of context in textual sequences, unified between training and inference. Third, we introduce the global information of retrieved passages to further enhance the structure of context. Extensive experiments on three scientific tasks show that the proposed method significantly improves the performance of Retrieval-Augmented LLMs on all tasks. Besides, our method achieves start-of-art performance in Question Answer task and outperforms ChatGPT. Moreover, it also brings considerate gains with irrelevant retrieval passages, illustrating its effectiveness on practical application scenarios.|互联网上的大量科学论文包含了丰富的数据和知识，吸引了众多研究者的关注。为了充分利用这些知识，检索增强型大语言模型通常利用大规模的科学语料库来训练和检索外部记忆中的相关段落，以提高生成能力。然而，现有的方法只能捕捉一维零碎的文本信息，没有结合层次结构知识，如抽象与主体的演绎关系，难以把握论文的中心思想。针对这一问题，提出了一种层次上下文增强方法，该方法可以帮助检索增强 LLM 自回归地学习科技论文的结构知识。具体来说，我们利用文档树来表示论文的层次关系，并从规模、格式和全局信息三个方面增强科学语境的结构信息。首先，我们认为文档树的每一条顶底路径都是一个逻辑独立的上下文，可以用来大幅度增加提取结构化语料的规模。其次，我们提出了一种新的基于标签的格式来表示文本序列中的上下文结构，统一于训练和推理。第三，引入检索段落的全局信息，进一步增强语境结构。在三个科学任务上的大量实验表明，该方法可以显著提高检索增强 LLM 在所有任务上的性能。此外，该方法在问答任务中取得了较好的启动性能，优于 ChatGPT。此外，它也带来了相当的收益与不相关的检索段落，说明其在实际应用场景的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hierarchical+Context+Augmentation+Method+to+Improve+Retrieval-Augmented+LLMs+on+Scientific+Papers)|0|
|[Maximum-Entropy Regularized Decision Transformer with Reward Relabelling for Dynamic Recommendation](https://doi.org/10.1145/3637528.3671750)|Xiaocong Chen, Siyu Wang, Lina Yao|Data 61, CSIRO, Eveleigh, Australia; Data 61, CSIRO & The University of New South Wales, Eveleigh, Australia; The University of New South Wales, Sydney, Australia|Reinforcement learning-based recommender systems have recently gainedpopularity. However, due to the typical limitations of simulation environments(e.g., data inefficiency), most of the work cannot be broadly applied in alldomains. To counter these challenges, recent advancements have leveragedoffline reinforcement learning methods, notable for their data-driven approachutilizing offline datasets. A prominent example of this is the DecisionTransformer. Despite its popularity, the Decision Transformer approach hasinherent drawbacks, particularly evident in recommendation methods based on it.This paper identifies two key shortcomings in existing DecisionTransformer-based methods: a lack of stitching capability and limitedeffectiveness in online adoption. In response, we introduce a novel methodologynamed Max-Entropy enhanced Decision Transformer with Reward Relabeling forOffline RLRS (EDT4Rec). Our approach begins with a max entropy perspective,leading to the development of a max entropy enhanced exploration strategy. Thisstrategy is designed to facilitate more effective exploration in onlineenvironments. Additionally, to augment the model's capability to stitchsub-optimal trajectories, we incorporate a unique reward relabeling technique.To validate the effectiveness and superiority of EDT4Rec, we have conductedcomprehensive experiments across six real-world offline datasets and in anonline simulator.|基于强化学习的推荐系统最近变得流行起来。然而，由于模拟环境的典型局限性(例如，数据效率低下) ，大多数工作不能广泛应用于所有领域。为了应对这些挑战，最近的进步已经利用了离线强化学习方法，值得注意的是它们利用离线数据集的数据驱动方法。这方面的一个突出例子是决策转换器。尽管决策转换器方法很流行，但是它有固有的缺点，在基于它的推荐方法中尤其明显。本文指出了现有基于决策变压器的方法存在的两个关键缺陷: 缺乏拼接能力和在线采用的有效性有限。作为回应，我们介绍了一种新的方法，最大熵增强决策变压器与奖励重新标记离线 RLRS (EDT4Rec)。我们的方法从最大熵的角度出发，导致了最大熵增强勘探策略的发展。该策略旨在促进在线环境中更有效的探索。此外，为了增强模型缝合次优轨迹的能力，我们纳入了独特的奖励重新标记技术。为了验证 EDT4Rec 的有效性和优越性，我们在六个真实世界的离线数据集和在线模拟器中进行了全面的实验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Maximum-Entropy+Regularized+Decision+Transformer+with+Reward+Relabelling+for+Dynamic+Recommendation)|0|
|[Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction](https://doi.org/10.1145/3637528.3672041)|Zhangtao Cheng, Jienan Zhang, Xovee Xu, Goce Trajcevski, Ting Zhong, Fan Zhou|; Iowa State University, Ames, Iowa, USA; University of Electronic Science and Technology of China, Chengdu, Sichuan, China|Accurately predicting the popularity of multimodal user-generated content (UGC) is fundamental for many real-world applications such as online advertising and recommendation. Existing approaches generally focus on limited contextual information within individual UGCs, yet overlook the potential benefit of exploiting meaningful knowledge in relevant UGCs. In this work, we propose RAGTrans, an aspect-aware retrieval-augmented multi-modal hypergraph transformer that retrieves pertinent knowledge from a multi-modal memory bank and enhances UGC representations via neighborhood knowledge aggregation on multi-model hypergraphs. In particular, we initially retrieve relevant multimedia instances from a large corpus of UGCs via the aspect information and construct a knowledge-enhanced hypergraph based on retrieved relevant instances. This allows capturing meaningful contextual information across the data. We then design a novel bootstrapping hypergraph transformer on multimodal hypergraphs to strengthen UGC representations across modalities via customizing a propagation algorithm to effectively diffuse information across nodes and edges. Additionally, we propose a user-aware attention-based fusion module to comprise the enriched UGC representations for popularity prediction. Extensive experiments on real-world social media datasets demonstrate that RAGTrans outperforms state-of-the-art popularity prediction models across settings.|准确预测多模式用户生成内容的流行程度对于许多现实世界的应用程序(如在线广告和推荐)至关重要。现有的方法一般集中于个别教资会内有限的上下文资料，但却忽略了利用相关教资会内有意义的知识的潜在好处。在这项工作中，我们提出了 RAGTrans，一个方面感知检索增强型多模态超图转换器，它可以从多模态记忆库中检索相关知识，并通过多模态超图上的邻域知识聚合来增强 UGC 表示。特别地，我们首先通过方面信息从一个大型的用户教学资源库中检索相关的多媒体实例，然后在检索到的相关实例的基础上构造一个知识增强的超图。这允许跨数据捕获有意义的上下文信息。然后在多模态超图上设计了一种新的自举超图转换器，通过定制传播算法有效地在节点和边上传播信息，从而增强跨模态的 UGC 表示。此外，我们还提出了一个基于用户感知的注意力融合模块来构成用户用户生成表示，用于流行度预测。在真实世界的社交媒体数据集上进行的大量实验表明，RAGTrans 在不同设置下的流行程度预测模型优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Augmented+Hypergraph+for+Multimodal+Social+Media+Popularity+Prediction)|0|
|[ROTAN: A Rotation-based Temporal Attention Network for Time-Specific Next POI Recommendation](https://doi.org/10.1145/3637528.3671809)|Shanshan Feng, Feiyu Meng, Lisi Chen, Shuo Shang, Yew Soon Ong|; University of Electronic Science and Technology of China, Chengdu, China; Centre for Frontier AI Research, ASTAR & Nanyang Technological University, Singapore, Singapore; University of Electronic Science and Technology of China, Chengdu, Sichuan, China|The next Point-of-interest recommendation has attracted extensive research interest recently, which predicts users' subsequent movements. The main challenge is how to effectively capture users' personalized sequential transitions in check-in trajectory, and various methods have been developed. However, most existing studies ignore the temporal information when conducting the next POI recommendation. To fill this gap, we investigate a time-specific next POI recommendation task, which additionally incorporates the target time information. We propose a brand new Time2Rotation technique to capture the temporal information. Different from conventional methods, we represent timeslots as rotation vectors and then perform the rotation operations. Based on the Time2Rotation technique, we propose a novel rotation-based temporal attention network, namely ROTAN, for the time-specific next POI recommendation task. The ROTAN begins by building a collaborative POI transition graph, capturing the asymmetric temporal influence in sequential transitions. After that, it incorporates temporal information into the modeling of individual check-in trajectories, extracting separate representations for user preference and POI influence to reflect their distinct temporal patterns. Lastly, the target time is integrated to generate recommendations. Extensive experiments are conducted on three real-world datasets, which demonstrates the advantages of the proposed Time2Rotation technique and ROTAN recommendation model.|最近，下一个兴趣点推荐引起了广泛的研究兴趣，它可以预测用户随后的活动。如何有效地捕获用户在签入轨迹中的个性化顺序转换是其面临的主要挑战，各种方法已经被开发出来。然而，大多数现有的研究忽略了时间信息进行下一个 POI 建议。为了填补这个空白，我们研究了一个特定于时间的下一个 POI 推荐任务，它还包含了目标时间信息。我们提出了一种全新的 Time2旋转技术来捕获时间信息。与传统的方法不同，我们将时隙表示为旋转向量，然后进行旋转运算。基于 Time2旋转技术，我们提出了一个新的基于旋转的时间注意网络，即 ROTAN，用于特定时间的下一个 POI 推荐任务。ROTAN 从建立一个合作的 POI 转换图开始，捕捉连续转换中不对称的时间影响。然后，将时间信息融入到单个签入轨迹的建模中，提取用户偏好和 POI 影响的独立表示，以反映它们不同的时间模式。最后，整合目标时间来生成建议。在三个真实世界的数据集上进行了大量的实验，这些实验证明了提出的 Time2旋转技术和 ROTAN 推荐模型的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ROTAN:+A+Rotation-based+Temporal+Attention+Network+for+Time-Specific+Next+POI+Recommendation)|0|
|[AutoXPCR: Automated Multi-Objective Model Selection for Time Series Forecasting](https://doi.org/10.1145/3637528.3672057)|Raphael Fischer, Amal Saadallah||Automated machine learning (AutoML) streamlines the creation of ML models, but few specialized methods have approached the challenging domain of time series forecasting. Deep neural networks (DNNs) often deliver state-of-the-art predictive performance for forecasting data, however these models are also criticized for being computationally intensive black boxes. As a result, when searching for the "best" model, it is crucial to also acknowledge other aspects, such as interpretability and resource consumption. In this paper, we propose AutoXPCR - a novel method that produces DNNs for forecasting under consideration of multiple objectives in an automated and explainable fashion. Our approach leverages meta-learning to estimate any model's performance along PCR criteria, which encompass (P)redictive error, (C)omplexity, and (R)esource demand. Explainability is addressed on multiple levels, as AutoXPCR pro-vides by-product explanations of recommendations and allows to interactively control the desired PCR criteria importance and trade-offs. We demonstrate the practical feasibility AutoXPCR across 108 forecasting data sets from various domains. Notably, our method outperforms competing AutoML approaches - on average, it only requires 20% of computation costs for recommending highly efficient models with 85% of the empirical best quality.|自动机器学习(AutoML)简化了机器学习模型的创建，但很少有专门的方法能够接近时间序列预测这一具有挑战性的领域。深度神经网络(DNN)往往提供最先进的预测性能的预测数据，但这些模型也被批评为计算密集型黑盒。因此，在寻找“最佳”模型时，关键是还要承认其他方面，如可解释性和资源消耗。在本文中，我们提出 AutoXPCR-一种新的方法，产生 DNN 的预测考虑多个目标，在一个自动化和可解释的方式。我们的方法利用元学习来估计任何模型沿 PCR 标准的性能，其中包括(P)预测误差，(C)复杂性和(R)资源需求。可解释性是在多个层面上解决的，因为 AutoXPCR 提供建议的副产品解释，并允许交互式地控制所需的 PCR 标准的重要性和权衡。我们论证了 AutoXPCR 在108个不同领域的预测数据集中的实际可行性。值得注意的是，我们的方法优于竞争对手 AutoML 方法-平均而言，它只需要20% 的计算成本推荐高效率的模型与85% 的经验最佳质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoXPCR:+Automated+Multi-Objective+Model+Selection+for+Time+Series+Forecasting)|0|
|[Topology-Driven Multi-View Clustering via Tensorial Refined Sigmoid Rank Minimization](https://doi.org/10.1145/3637528.3672070)|Zhibin Gu, Zhendong Li, Songhe Feng||Benefiting from the effective exploitation of the high-order correlations across multiple views, tensor-based multi-view clustering (TMVC) has garnered considerable attention in recent years. Nevertheless, prior TMVC techniques commonly involve assembling multiple view-specific spatial similarity graphs into a three-dimensional tensor, overlooking the intrinsic topological structure essential for precise clustering of data within a manifold. Additionally, mainstream techniques are constrained by equally shrinking all singular values to recover a low-rank tensor, limiting their capacity to distinguish significant variations among different singular values. In this investigation, we present an innovative TMVC framework termed toPology-driven multi-view clustering viA refined teNsorial sigmoiD rAnk minimization (PANDA ). Specifically, PANDA extracts view-specific topological structures from Euclidean graphs and intricately integrates them into a low-rank three-dimensional tensor, facilitating the concurrent utilization of intra-view topological connectivity and inter-view high-order correlations. Moreover, we develop a refined sigmoid function as the tighter surrogate to tensor rank, enabling the exploration of significant information of heterogeneous singular values. Meanwhile, the topological structures are merged into a unified structure with varying weights, associated with a connectivity constraint, empowering the significant divergence among views and the explicit cluster structure of the target graph are simultaneously leveraged. Extensive experiments demonstrate the superiority of PANDA, outperforming SOTA methods.|基于张量的多视图聚类算法(TMVC)得益于多视图高阶相关性的有效利用，近年来引起了人们的广泛关注。然而，先前的 TMVC 技术通常涉及将多个视图特定的空间相似性图组装成一个三维张量，忽略了流形中数据精确聚类所必需的内在拓扑结构。此外，主流技术受到同样缩小所有奇异值以恢复低秩张量的限制，从而限制了它们区分不同奇异值之间显著变化的能力。在这项研究中，我们提出了一个创新的 TMVC 框架，称为拓扑驱动的多视图聚类通过一个精化的 teNsorial sigmoiD rRank 最小化(PANDA)。具体而言，PANDA 从欧几里德图中提取视图特定的拓扑结构，并将其复杂地集成到一个低秩三维张量中，促进视图内拓扑连通性和视图间高阶相关性的并发利用。此外，我们发展了一个精确的 S形函数，作为张量级更紧密的替代品，使探索异质奇异值的重要信息成为可能。同时，将拓扑结构合并为一个具有不同权重的统一结构，并结合连通性约束，赋予视图之间的显著差异，同时利用目标图的显式聚类结构。大量的实验证明了 PANDA 方法的优越性，优于 SOTA 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topology-Driven+Multi-View+Clustering+via+Tensorial+Refined+Sigmoid+Rank+Minimization)|0|
|[Ranking with Slot Constraints](https://doi.org/10.1145/3637528.3672000)|Wentao Guo, Andrew Wang, Bradon Thymes, Thorsten Joachims||We introduce the problem of ranking with slot constraints, which can be used to model a wide range of application problems -- from college admission with limited slots for different majors, to composing a stratified cohort of eligible participants in a medical trial. We show that the conventional Probability Ranking Principle (PRP) can be highly sub-optimal for slot-constrained ranking problems, and we devise a new ranking algorithm, called MatchRank. The goal of MatchRank is to produce rankings that maximize the number of filled slots if candidates are evaluated by a human decision maker in the order of the ranking. In this way, MatchRank generalizes the PRP, and it subsumes the PRP as a special case when there are no slot constraints. Our theoretical analysis shows that MatchRank has a strong approximation guarantee without any independence assumptions between slots or candidates. Furthermore, we show how MatchRank can be implemented efficiently. Beyond the theoretical guarantees, empirical evaluations show that MatchRank can provide substantial improvements over a range of synthetic and real-world tasks.|我们介绍了有时间限制的排名问题，这个问题可以用来模拟范围广泛的申请问题——从不同专业有时间限制的大学录取，到在医学试验中合格参与者的分层队列组成。我们证明了传统的概率排序原则(PRP)对于时隙约束排序问题可能是高度次优的，并且我们设计了一种新的排序算法，称为 MatchRank。MatchRank 的目标是，如果候选人是由人类决策者按照排名顺序进行评估的，那么它将产生最大化已填补空缺数量的排名。通过这种方式，MatchRank 对 PRP 进行泛化，当没有时隙约束时，它将 PRP 包含为特殊情况。我们的理论分析表明，MatchRank 有一个强大的近似保证，没有任何独立的假设之间的插槽或候选人。此外，我们还展示了如何有效地实现 MatchRank。除了理论上的保证，经验性的评估表明，MatchRank 可以在一系列合成和现实世界的任务上提供实质性的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking+with+Slot+Constraints)|0|
|[Consistency and Discrepancy-Based Contrastive Tripartite Graph Learning for Recommendations](https://doi.org/10.1145/3637528.3672056)|Linxin Guo, Yaochen Zhu, Min Gao, Yinghui Tao, Junliang Yu, Chen Chen|Institute of Guizhou Aerospace Measuring and Testing Technology, Guiyang, China; the University of Queensland, Queensland, Australia; University of Virginia, Charlottesville, VA, USA; Chongqing University, Chongqing, China|Tripartite graph-based recommender systems markedly diverge from traditional models by recommending unique combinations such as user groups and item bundles. Despite their effectiveness, these systems exacerbate the long-standing cold-start problem in traditional recommender systems, because any number of user groups or item bundles can be formed among users or items. To address this issue, we introduce a Consistency and Discrepancy-based graph contrastive learning method for tripartite graph-based Recommendation (CDR). This approach leverages two novel meta-path-based metrics-consistency and discrepancy-to capture nuanced, implicit associations between the recommended objects and the recommendees. These metrics, indicative of high-order similarities, can be efficiently calculated with infinite graph convolutional networks (GCN) layers under a multi-objective optimization framework, using the limit theory of GCN. Additionally, we introduce a novel Contrastive Divergence (CD) loss, which can seamlessly integrate the consistency and discrepancy metrics into the contrastive objective as the positive and contrastive supervision signals to learn node representations, enhancing the pairwise ranking of recommended objects and proving particularly valuable in severe cold-start scenarios. Extensive experiments demonstrate the effectiveness of the proposed CDR. The code is released at https://github.com/foodfaust/CDR.|基于三方图表的推荐系统通过推荐独特的组合，如用户组和项目包，明显地区别于传统模型。尽管这些系统很有效，但它们加剧了传统推荐系统中长期存在的“冷启动”问题，因为在用户或项目之间可以形成任意数量的用户组或项目包。为了解决这个问题，我们提出了一种基于一致性和差异性的图形对比学习方法。这种方法利用两种新颖的基于元路径的度量——一致性和差异性——来捕获被推荐对象和被推荐对象之间微妙的、隐含的关联。在多目标优化框架下，利用无穷图卷积网络(GCN)的极限理论，可以有效地计算这些指标，它们表示高阶相似性。此外，我们引入了一种新的对比发散(CD)损失，它可以无缝地将一致性和差异度量集成到对比目标中，作为正向和对比监督信号来学习节点表示，提高推荐对象的成对排序，并证明在严重的冷启动情况下特别有价值。大量的实验证明了所提出的 CDR 算法的有效性。密码在 https://github.com/foodfaust/cdr 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Consistency+and+Discrepancy-Based+Contrastive+Tripartite+Graph+Learning+for+Recommendations)|0|
|[Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors](https://doi.org/10.1145/3637528.3671793)|Croix Gyurek, Niloy Talukder, Mohammad Al Hasan|University of Waterloo, Waterloo, Ontario, Canada; Indiana University at Indianapolis, Indianapolis, IN, USA|For natural language understanding and generation, embedding concepts using an order-based representation is an essential task. Unlike traditional point vector based representation, an order-based representation imposes geometric constraints on the representation vectors for explicitly capturing various semantic relationships that may exist between a pair of concepts. In existing literature, several approaches on order-based embedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include vectors in Euclidean space, complex, Hyperbolic, order, and Box Embedding. Box embedding creates region-based rich representation of concepts, but along the process it sacrifices simplicity, requiring a custom-made optimization scheme for learning the representation. Hyperbolic embedding improves embedding quality by exploiting the ever-expanding property of Hyperbolic space, but it also suffers from the same fate as box embedding as gradient descent like optimization is not simple in the Hyperbolic space. In this work, we propose Binder, a novel approach for order-based representation. Binder uses binary vectors for embedding, so the embedding vectors are compact with an order of magnitude smaller footprint than other methods. Binder uses a simple and efficient optimization scheme for learning representation vectors with a linear time complexity. Our comprehensive experimental results show that Binder is very accurate, yielding competitive results on the representation task. But Binder stands out from its competitors on the transitive closure link prediction task as it can learn concept embeddings just from the direct edges, whereas all existing order-based approaches rely on the indirect edges. In particular, Binder achieves a whopping 70% higher F1-score than the second best method (98.6% vs 29%) in our largest dataset, WordNet Nouns (743,241 edges), when using only direct edges during training.|对于自然语言的理解和生成，使用基于顺序的表示来嵌入概念是一个基本的任务。与传统的基于点向量的表示不同，基于顺序的表示对表示向量施加几何约束，以显式地捕获可能存在于一对概念之间的各种语义关系。在现有的文献中，已经提出了几种基于顺序的嵌入方法，主要集中在捕获层次关系，例如欧氏空间中的向量，复数，双曲，顺序和盒嵌入。框嵌入创建了基于区域的概念丰富表示，但是在这个过程中它牺牲了简单性，需要一个定制的优化方案来学习表示。双曲嵌入通过利用双曲空间不断扩展的特性来提高嵌入质量，但是它也遭受着与盒子嵌入相同的命运，因为像优化这样的梯度下降法在双曲空间中并不简单。在这项工作中，我们提出了一种新的基于顺序的表示方法 Binder。Binder 使用二进制向量进行嵌入，因此嵌入向量比其他方法更紧凑，数量级更小。Binder 使用一种简单有效的优化方法来学习具有线性时间复杂度的表示向量。我们的综合实验结果表明，粘合剂是非常准确的，产生了竞争结果的表示任务。但是 Binder 在传递闭包链接预测任务中脱颖而出，因为它只能从直接边缘学习概念嵌入，而现有的基于顺序的方法都依赖于间接边缘。特别是，在我们最大的数据集 WordNet 名词(743,241条边)中，当仅在训练期间使用直接边时，Binder 比第二最佳方法(98.6% 比29%)高出70% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Binder:+Hierarchical+Concept+Representation+through+Order+Embedding+of+Binary+Vectors)|0|
|[An Efficient Local Search Algorithm for Large GD Advertising Inventory Allocation with Multilinear Constraints](https://doi.org/10.1145/3637528.3671811)|Xiang He, Wuyang Mao, Zhenghang Xu, Yuanzhe Gu, Yundu Huang, Zhonglin Zu, Liang Wang, Mengyu Zhao, Mengchuan Zou|; Alibaba Group, Beijing, China; Alibaba Group, Hangzhou, China|The Guaranteed Delivery (GD) advertising is a crucial component of the online advertising industry, and the allocation of inventory in GD advertising is an important procedure that influences directly the ability of the publisher to fulfill the requirements and increase its revenues. Nowadays, as the requirements of advertisers become more and more diverse and fine-grained, the focus ratio requirement, which states that the portion of allocated impressions of a designated contract on focus media among all possible media should be greater than another contract, often appears in business scenarios. However, taking these requirements into account brings hardness for the GD advertising inventory allocation as the focus ratio requirements involve non-convex multilinear constraints. Existing methods which rely on the convex properties are not suitable for processing this problem, while mathematical programming or constraint-based heuristic solvers are unable to produce high-quality solutions within the time limit. Therefore, we propose a local search framework to address this challenge. It incorporates four new operators designed for handling multilinear constraints and a two-mode algorithmic architecture. Experimental results demonstrate that our algorithm is able to compute high-quality allocations with better business metrics compared to the state-of-the-art mathematical programming or constraint based heuristic solvers. Moreover, our algorithm is able to handle the general multilinear constraints and we hope it could be used to solve other problems in GD advertising with similar requirements.|保送广告是网络广告业的重要组成部分，而保送广告的库存分配是直接影响发行商满足需求和增加收入的重要环节。如今，随着广告商的要求变得越来越多样化和细化，焦点比率要求往往出现在商业场景中。然而，考虑到这些要求，GD 广告库存分配的困难，因为焦点比率的要求涉及非凸多线性约束。现有的依赖于凸性质的方法不适合处理这个问题，而数学规划或基于约束的启发式求解器不能在时间限制内产生高质量的解。因此，我们提出了一个本地搜索框架来应对这一挑战。它包括四个新的运算符设计处理多线性约束和一个双模算法体系结构。实验结果表明，与最先进的数学规划或基于约束的启发式求解器相比，该算法能够以更好的业务指标计算高质量的分配。此外，我们的算法能够处理一般的多线性约束，我们希望它可以用来解决其他问题广东广告类似的要求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Local+Search+Algorithm+for+Large+GD+Advertising+Inventory+Allocation+with+Multilinear+Constraints)|0|
|[Double Correction Framework for Denoising Recommendation](https://doi.org/10.1145/3637528.3671692)|Zhuangzhuang He, Yifan Wang, Yonghui Yang, Peijie Sun, Le Wu, Haoyue Bai, Jinqi Gong, Richang Hong, Min Zhang|; Hefei University of Technology, Hefei, China; University of Macau, Macau, China; Tsinghua University, Beijing, China|As its availability and generality in online services, implicit feedback ismore commonly used in recommender systems. However, implicit feedback usuallypresents noisy samples in real-world recommendation scenarios (such asmisclicks or non-preferential behaviors), which will affect precise userpreference learning. To overcome the noisy samples problem, a popular solutionis based on dropping noisy samples in the model training phase, which followsthe observation that noisy samples have higher training losses than cleansamples. Despite the effectiveness, we argue that this solution still haslimits. (1) High training losses can result from model optimization instabilityor hard samples, not just noisy samples. (2) Completely dropping of noisysamples will aggravate the data sparsity, which lacks full data exploitation.To tackle the above limitations, we propose a Double Correction Framework forDenoising Recommendation (DCF), which contains two correction components fromviews of more precise sample dropping and avoiding more sparse data. In thesample dropping correction component, we use the loss value of the samples overtime to determine whether it is noise or not, increasing dropping stability.Instead of averaging directly, we use the damping function to reduce the biaseffect of outliers. Furthermore, due to the higher variance exhibited by hardsamples, we derive a lower bound for the loss through concentration inequalityto identify and reuse hard samples. In progressive label correction, weiteratively re-label highly deterministic noisy samples and retrain them tofurther improve performance. Finally, extensive experimental results on threedatasets and four backbones demonstrate the effectiveness and generalization ofour proposed framework.|由于在线服务的可用性和普遍性，隐式反馈在推荐系统中得到了广泛的应用。然而，在现实推荐场景中，隐式反馈通常会产生噪声样本(如错误点击或非优先行为) ，从而影响精确的用户偏好学习。为了克服噪声样本问题，提出了一种在模型训练阶段丢弃噪声样本的方法，该方法通过观察噪声样本比清洗样本具有更高的训练损失。尽管有效，我们认为这个解决方案仍然有局限性。(1)模型优化的不稳定性或硬样本会导致高训练损失，而不仅仅是噪声样本。(2)完全丢弃噪声样本会加剧数据稀疏性，而数据稀疏性缺乏充分的数据利用。针对上述限制，我们建议采用双修正框架去噪建议(DCF) ，其中包含两个修正组成部分，从更精确的丢弃样本和避免更稀疏的数据的角度出发。在样本掉落校正分量中，我们利用样本的损失值来判断样本是否为噪声，增加了掉落的稳定性。我们使用阻尼函数来减少异常值的偏差效应，而不是直接求平均值。此外，由于硬样本具有较高的方差，我们通过浓度不等式得到了一个损失的下界来识别和重用硬样本。在渐进式标记校正中，反复重新标记高确定性噪声样本，并对它们进行再训练以进一步提高性能。最后，在三个数据集和四个骨干上的大量实验结果证明了该框架的有效性和通用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Double+Correction+Framework+for+Denoising+Recommendation)|0|
|[Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models](https://doi.org/10.1145/3637528.3671932)|Zhibo Hu, Chen Wang, Yanfeng Shu, HyeYoung Paik, Liming Zhu|The University of New South Wales & CSIRO Data61, Sydney, NSW, Australia; University of New South Wales, Sydney, NSW, Australia; CSIRO Data61 & University of New South Wales, Sydney, NSW, Australia; CSIRO Data61 & The University of New South Wales, Sydney, NSW, Australia; CSIRO Data61, Hobart, Tasmania, Australia|The robustness of large language models (LLMs) becomes increasingly importantas their use rapidly grows in a wide range of domains. Retrieval-AugmentedGeneration (RAG) is considered as a means to improve the trustworthiness oftext generation from LLMs. However, how the outputs from RAG-based LLMs areaffected by slightly different inputs is not well studied. In this work, wefind that the insertion of even a short prefix to the prompt leads to thegeneration of outputs far away from factually correct answers. Wesystematically evaluate the effect of such prefixes on RAG by introducing anovel optimization technique called Gradient Guided Prompt Perturbation (GGPP).GGPP achieves a high success rate in steering outputs of RAG-based LLMs totargeted wrong answers. It can also cope with instructions in the promptsrequesting to ignore irrelevant context. We also exploit LLMs' neuronactivation difference between prompts with and without GGPP perturbations togive a method that improves the robustness of RAG-based LLMs through a highlyeffective detector trained on neuron activation triggered by GGPP generatedprompts. Our evaluation on open-sourced LLMs demonstrates the effectiveness ofour methods.|随着大型语言模型在广泛领域的应用迅速增长，其健壮性变得越来越重要。检索-增强生成(RAG)被认为是提高 LLM 文本生成可信度的一种手段。然而，基于 RAG 的 LLM 的输出如何受到稍微不同的输入的影响还没有得到很好的研究。在这项工作中，我们发现，即使在提示符中插入一个短的前缀，也会导致输出远离事实上正确的答案。通过引入梯度引导提示扰动(GGPP)这一新的优化技术，系统地评价了这些前缀对 RAG 的影响。GGPP 在引导基于 RAG 的 LLM 的输出定位错误答案方面取得了很高的成功率。它还可以处理提示中要求忽略不相关上下文的指令。我们还利用具有和不具有 GGPP 扰动的提示之间的 LLM 的神经元激活差异，通过对由 GGPP 产生的提示触发的神经元激活进行训练的高效检测器来提高基于 RAG 的 LLM 的鲁棒性。我们对开源 LLM 的评估证明了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Perturbation+in+Retrieval-Augmented+Generation+based+Large+Language+Models)|0|
|[Dynamic Neural Dowker Network: Approximating Persistent Homology in Dynamic Directed Graphs](https://doi.org/10.1145/3637528.3671980)|Hao Li, Hao Jiang, Jiajun Fan, Dongsheng Ye, Liang Du|Electronic Information School, Wuhan University, Wuhan, Hubei, China|Persistent homology, a fundamental technique within Topological Data Analysis (TDA), captures structural and shape characteristics of graphs, yet encounters computational difficulties when applied to dynamic directed graphs. This paper introduces the Dynamic Neural Dowker Network (DNDN), a novel framework specifically designed to approximate the results of dynamic Dowker filtration, aiming to capture the high-order topological features of dynamic directed graphs. Our approach creatively uses line graph transformations to produce both source and sink line graphs, highlighting the shared neighbor structures that Dowker complexes focus on. The DNDN incorporates a Source-Sink Line Graph Neural Network (SSLGNN) layer to effectively capture the neighborhood relationships among dynamic edges. Additionally, we introduce an innovative duality edge fusion mechanism, ensuring that the results for both the sink and source line graphs adhere to the duality principle intrinsic to Dowker complexes. Our approach is validated through comprehensive experiments on real-world datasets, demonstrating DNDN's capability not only to effectively approximate dynamic Dowker filtration results but also to perform exceptionally in dynamic graph classification tasks.|持久同调是拓扑数据分析(TDA)中的一项基本技术，它捕获图的结构和形状特征，但在应用于动态有向图时遇到了计算困难。本文介绍了动态神经道克网络(DNDN) ，这是一种专门设计来逼近动态道克滤波结果的新框架，旨在捕获动态有向图的高阶拓扑特征。我们的方法创造性地使用线图转换来生成源和汇线图，突出道克复合体关注的共享邻居结构。DNDN 结合源-汇线图神经网络(SSLGNN)层，有效地捕获动态边之间的邻域关系。此外，我们还引入了一种创新的对偶边融合机制，确保汇和源线图的结果都坚持道克复合体固有的对偶原则。通过对实际数据集的全面实验验证了该方法的有效性，证明了 DNDN 不仅能有效逼近动态 Dowker 滤波结果，而且能在动态图形分类任务中表现优异。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Neural+Dowker+Network:+Approximating+Persistent+Homology+in+Dynamic+Directed+Graphs)|0|
|[RecExplainer: Aligning Large Language Models for Explaining Recommendation Models](https://doi.org/10.1145/3637528.3671802)|Yuxuan Lei, Jianxun Lian, Jing Yao, Xu Huang, Defu Lian, Xing Xie|University of Science and Technology of China, Hefei, China; Microsoft Research Asia, Beijing, China|Recommender systems are widely used in online services, with embedding-based models being particularly popular due to their expressiveness in representing complex signals. However, these models often function as a black box, making them less transparent and reliable for both users and developers. Recently, large language models (LLMs) have demonstrated remarkable intelligence in understanding, reasoning, and instruction following. This paper presents the initial exploration of using LLMs as surrogate models to explaining black-box recommender models. The primary concept involves training LLMs to comprehend and emulate the behavior of target recommender models. By leveraging LLMs' own extensive world knowledge and multi-step reasoning abilities, these aligned LLMs can serve as advanced surrogates, capable of reasoning about observations. Moreover, employing natural language as an interface allows for the creation of customizable explanations that can be adapted to individual user preferences. To facilitate an effective alignment, we introduce three methods: behavior alignment, intention alignment, and hybrid alignment. Behavior alignment operates in the language space, representing user preferences and item information as text to mimic the target model's behavior; intention alignment works in the latent space of the recommendation model, using user and item representations to understand the model's behavior; hybrid alignment combines both language and latent spaces. Comprehensive experiments conducted on three public datasets show that our approach yields promising results in understanding and mimicking target models, producing high-quality, high-fidelity, and distinct explanations. Our code is available at https://github.com/microsoft/RecAI.|推荐系统在在线服务中得到了广泛的应用，基于嵌入的推荐系统模型因其表达复杂信号的能力而受到人们的青睐。然而，这些模型通常起到黑匣子的作用，使它们对用户和开发人员来说都不那么透明和可靠。近年来，大型语言模型(LLM)在理解、推理和指令跟随方面显示出非凡的智力。本文介绍了利用 LLM 作为代理模型来解释黑盒推荐模型的初步探索。主要概念包括训练 LLM 理解和仿真目标推荐模型的行为。通过利用 LLM 自身丰富的世界知识和多步推理能力，这些对齐的 LLM 可以作为高级代理，能够对观测进行推理。此外，使用自然语言作为界面允许创建可定制的解释，可以适应个人用户的喜好。为了实现有效的校准，我们介绍了三种方法: 行为校准、意图校准和混合校准。行为对齐操作在语言空间中，将用户偏好和项目信息表示为文本，以模仿目标模型的行为; 意图对齐工作在推荐模型的潜在空间中，使用用户和项目表示来理解模型的行为; 混合对齐结合了语言和潜在空间。在三个公共数据集上进行的综合实验表明，我们的方法在理解和模仿目标模型方面产生了有希望的结果，产生了高质量、高保真度和独特的解释。我们的代码可以在 https://github.com/microsoft/recai 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecExplainer:+Aligning+Large+Language+Models+for+Explaining+Recommendation+Models)|0|
|[Customizing Graph Neural Network for CAD Assembly Recommendation](https://doi.org/10.1145/3637528.3671788)|Fengqi Liang, Huan Zhao, Yuhan Quan, Wei Fang, Chuan Shi|4Paradigm Inc., Beijing, China; Beijing University of Post and Telecommunication, Beijing, China|CAD assembly modeling, which refers to using CAD software to design new products from a catalog of existing machine components, is important in the industrial field. The graph neural network (GNN) based recommender system for CAD assembly modeling can help designers make decisions and speed up the design process by recommending the next required component based on the existing components in CAD software. These components can be represented as a graph naturally. However, present recommender systems for CAD assembly modeling adopt fixed GNN architectures, which may be sub-optimal for different manufacturers with different data distribution. Therefore, to customize a well-suited recommender system for different manufacturers, we propose a novel neural architecture search (NAS) framework, dubbed CusGNN, which can design data-specific GNN automatically. Specifically, we design a search space from three dimensions (i.e., aggregation, fusion, and readout functions), which contains a wide variety of GNN architectures. Then, we develop an effective differentiable search algorithm to search high-performing GNN from the search space. Experimental results show that the customized GNNs achieve 1.5-5.1% higher top-10 accuracy compared to previous manual designed methods, demonstrating the superiority of the proposed approach. Code and data are available at https://github.com/BUPT-GAMMA/CusGNN.|CAD 装配建模是指利用 CAD 软件从现有机械零部件目录中设计新产品，在工业领域具有重要意义。基于图形神经网络(GNN)的 CAD 装配建模推荐系统可以帮助设计人员根据 CAD 软件中现有的组件推荐下一个需要的组件，从而帮助设计人员做出决策并加快设计过程。这些组件可以自然地表示为一个图形。然而，现有的 CAD 装配建模推荐系统采用固定的 GNN 体系结构，对于具有不同数据分布的不同制造商可能是次优的。因此，为了为不同的制造商定制一个非常适合的推荐系统，我们提出了一个新的神经结构搜索(NAS)框架，称为 CusGNN，它可以自动设计数据特定的 GNN。具体来说，我们从三个维度(即聚合、融合和读出函数)设计一个搜索空间，其中包含多种 GNN 体系结构。然后，我们开发了一个有效的可微搜索算法来搜索高性能的 GNN 从搜索空间。实验结果表明，与以往的手工设计方法相比，自定义 GNN 的前10位精度提高了1.5 -5.1% ，证明了该方法的优越性。代码和数据可在 https://github.com/bupt-gamma/cusgnn 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Customizing+Graph+Neural+Network+for+CAD+Assembly+Recommendation)|0|
|[When Box Meets Graph Neural Network in Tag-aware Recommendation](https://doi.org/10.1145/3637528.3671973)|Fake Lin, Ziwei Zhao, Xi Zhu, Da Zhang, Shitian Shen, Xueying Li, Tong Xu, Suojuan Zhang, Enhong Chen|Army Engineering University of PLA, Nanjing, China; Alibaba Group, Hangzhou, China; University of Science and Technology of China, Hefei, China; Alibaba Group, Hangzhou, NC, USA|Last year has witnessed the re-flourishment of tag-aware recommender systems supported by the LLM-enriched tags. Unfortunately, though large efforts have been made, current solutions may fail to describe the diversity and uncertainty inherent in user preferences with only tag-driven profiles. Recently, with the development of geometry-based techniques, e.g., box embeddings, the diversity of user preferences now could be fully modeled as the range within a box in high dimension space. However, defect still exists as these approaches are incapable of capturing high-order neighbor signals, i.e., semantic-rich multi-hop relations within the user-tag-item tripartite graph, which severely limits the effectiveness of user modeling. To deal with this challenge, in this paper, we propose a novel framework, called BoxGNN, to perform message aggregation via combinations of logical operations, thereby incorporating high-order signals. Specifically, we first embed users, items, and tags as hyper-boxes rather than simple points in the representation space, and define two logical operations, i.e., union and intersection, to facilitate the subsequent process. Next, we perform the message aggregation mechanism via the combination of logical operations, to obtain the corresponding high-order box representations. Finally, we adopt a volume-based learning objective with Gumbel smoothing techniques to refine the representation of boxes. Extensive experiments on two publicly available datasets and one LLM-enhanced e-commerce dataset have validated the superiority of BoxGNN compared with various state-of-the-art baselines. The code is released online: https://github.com/critical88/BoxGNN.|去年见证了标签感知推荐系统的重新繁荣，这些系统由 LLM 丰富的标签支持。不幸的是，尽管已经做出了巨大的努力，目前的解决方案可能无法描述用户偏好中固有的多样性和不确定性，只能使用标签驱动的配置文件。近年来，随着几何技术的发展，如盒子嵌入，用户偏好的多样性现在可以完全模拟为高维空间中盒子内的范围。然而，由于这些方法不能捕获高阶相邻信号，即用户标签项三部分图中语义丰富的多跳关系，这严重限制了用户建模的有效性。为了应对这一挑战，在本文中，我们提出了一种新的框架，称为 BoxGNN，通过逻辑操作的组合来执行消息聚合，从而合并高阶信号。具体来说，我们首先将用户、项目和标记作为超盒而不是表示空间中的简单点嵌入，并定义两个逻辑操作，即联合和交集，以方便后续处理。接下来，我们通过逻辑操作的组合执行消息聚合机制，以获得相应的高阶框表示。最后，我们采用基于体积的学习目标和 Gumbel 平滑技术来改善盒子的表示。在两个公开可用的数据集和一个 LLM 增强的电子商务数据集上的大量实验验证了 BoxGNN 相对于各种最新基线的优越性。代码在网上发布:  https://github.com/critical88/boxgnn。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Box+Meets+Graph+Neural+Network+in+Tag-aware+Recommendation)|0|
|[Fast Query of Biharmonic Distance in Networks](https://doi.org/10.1145/3637528.3671856)|Changan Liu, Ahad N. Zehmakan, Zhongzhi Zhang|Fudan University, Shanghai, China; Australian National University, Canberra, Australia|Thebiharmonic distance (BD) is a fundamental metric that measures the distance of two nodes in a graph. It has found applications in network coherence, machine learning, and computational graphics, among others. In spite of BD's importance, efficient algorithms for the exact computation or approximation of this metric on large graphs remain notably absent. In this work, we provide several algorithms to estimate BD, building on a novel formulation of this metric. These algorithms enjoy locality property (that is, they only read a small portion of the input graph) and at the same time possess provable performance guarantees. In particular, our main algorithms approximate the BD between any node pair with an arbitrarily small additive error ε in time O(1/ε2 poly(log n/ε)). Furthermore, we perform an extensive empirical study on several benchmark networks, validating the performance and accuracy of our algorithms.|双调和距离(BD)是度量图中两个节点之间距离的基本度量。它在网络一致性、机器学习和计算图形学等领域都有应用。尽管 BD 的重要性，有效的算法精确计算或逼近这一度量在大图仍然明显缺乏。在这项工作中，我们提供了几种算法来估计 BD，建立在一个新的公式的这个度量。这些算法具有局部性(也就是说，它们只读取输入图的一小部分) ，同时具有可证明的性能保证。特别地，我们的主要算法在时间 O (1/ε2多边形(log n/ε))上具有任意小的加性误差 ε 的任意节点对之间逼近 BD。此外，我们对几个基准网络进行了广泛的实证研究，验证了我们的算法的性能和准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Query+of+Biharmonic+Distance+in+Networks)|0|
|[Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization](https://doi.org/10.1145/3637528.3672040)|Fei Liu, Xi Lin, Zhenkun Wang, Qingfu Zhang, Tong Xialiang, Mingxuan Yuan|City University of Hong Kong, Hong Kong, China; Huawei Technologies Ltd., Shenzhen, China; Huawei Technologies Ltd., Hong Kong, China; Southern University of Science and Technology, Shenzhen, China|Vehicle routing problems (VRP) are very important in many real-world applications and has been studied for several decades. Recently, neural combinatorial optimization (NCO) has attracted growing research effort. NCO is to train a neural network model to solve an optimization problem in question. However, existing NCO methods often build a different model for each routing problem, which significantly hinders their application in some areas where there are many different VRP variants to solve. In this work, we make a first attempt to tackle the crucial challenge of cross-problem generalization in NCO. We formulate VRPs as different combinations of a set of shared underlying attributes and solve them simultaneously via a single model through attribute composition. In this way, our proposed model can successfully solve VRPs with unseen attribute combinations in a zero-shot generalization manner. In our experiments, the neural model is trained on five VRP variants and its performance is tested on eleven VRP variants. The experimental results show that the model demonstrates superior performance on these eleven VRP variants, reducing the average gap to around 5% from over 20% and achieving a notable performance boost on both benchmark datasets and real-world logistics scenarios.|车辆路径问题(VRP)是车辆路径问题的一个重要研究方向。最近，神经组合优化(NCO)已经吸引了越来越多的研究人员。神经网络模型来解决最佳化问题问题。然而，现有的 NCO 方法往往为每个路由问题建立不同的模型，这严重阻碍了它们在有许多不同的 VRP 变量需要解决的一些领域的应用。在这项工作中，我们首次尝试解决 NCO 中跨问题泛化的关键挑战。我们将 VRP 描述为一组共享的底层属性的不同组合，并通过属性组合的方法通过单一模型同时求解。通过这种方法，我们提出的模型可以成功地解决具有不可见属性组合的 VRP 问题。在我们的实验中，神经模型被训练在五个 VRP 变体上，它的性能被测试在十一个 VRP 变体上。实验结果显示，该模型在这十一种 VRP 变种上表现卓越，将平均差距从超过20% 缩小至约5% ，并在基准数据集和现实世界物流场景上均取得显著的性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Learning+for+Routing+Problem+with+Cross-Problem+Zero-Shot+Generalization)|0|
|[Low Rank Multi-Dictionary Selection at Scale](https://doi.org/10.1145/3637528.3671723)|Boya Ma, Maxwell McNeil, Abram Magner, Petko Bogdanov|Department of Computer Science, University at Albany, State University of New York, Albany, NY, USA|The sparse dictionary coding framework represents signals as a linear combination of a few predefined dictionary atoms. It has been employed for images, time series, graph signals and recently for 2-way (or 2D) spatio-temporal data employing jointly temporal and spatial dictionaries. Large and over-complete dictionaries enable high-quality models, but also pose scalability challenges which are exacerbated in multi-dictionary settings. Hence, an important problem that we address in this paper is: How to scale multi-dictionary coding for large dictionaries and datasets? We propose a multi-dictionary atom selection technique for low-rank sparse coding named LRMDS. To enable scalability to large dictionaries and datasets, it progressively selects groups of row-column atom pairs based on their alignment with the data and performs convex relaxation coding via the corresponding sub-dictionaries. We demonstrate both theoretically and experimentally that when the data has a low-rank encoding with a sparse subset of the atoms, LRMDS is able to select them with strong guarantees under mild assumptions. Furthermore, we demonstrate the scalability and quality of LRMDS in both synthetic and real-world datasets and for a range of coding dictionaries. It achieves 3 times to 10 times speed-up compared to baselines, while obtaining up to two orders of magnitude improvement in representation quality on some of the real world datasets given a fixed target number of atoms.|稀疏字典编码框架将信号表示为几个预定义字典原子的线性组合。它已经应用于图像，时间序列，图形信号和最近的2路(或2D)时空数据使用联合时间和空间字典。大型和过于完整的字典使高质量的模型成为可能，但也带来了可伸缩性方面的挑战，这些挑战在多字典设置中会加剧。因此，本文要解决的一个重要问题是: 如何对大型字典和数据集进行多字典编码？提出了一种低秩稀疏编码的多字典原子选择技术 LRMDS。为了使大型字典和数据集具有可伸缩性，它逐步根据行-列原子对与数据的对齐情况选择它们的组，并通过相应的子字典执行凸松弛编码。我们在理论和实验上都证明了，当数据具有一个低秩编码和一个稀疏的原子子集时，LRMDS 能够在温和的假设条件下选择它们，并且具有很强的保证性。此外，我们证明了 LRMDS 在合成和真实世界数据集和一系列编码字典中的可伸缩性和质量。与基线相比，它的速度提高了3到10倍，同时在给定固定目标原子数量的情况下，一些真实世界数据集的表示质量提高了两个数量级。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low+Rank+Multi-Dictionary+Selection+at+Scale)|0|
|[ImputeFormer: Low Rankness-Induced Transformers for Generalizable Spatiotemporal Imputation](https://doi.org/10.1145/3637528.3671751)|Tong Nie, Guoyang Qin, Wei Ma, Yuewen Mei, Jian Sun|Tongji University, Shanghai, China; The Hong Kong Polytechnic University, Hong Kong SAR, China|Missing data is a pervasive issue in both scientific and engineering tasks, especially for the modeling of spatiotemporal data. Existing imputation solutions mainly include low-rank models and deep learning models. The former assumes general structural priors but has limited model capacity. The latter possesses salient expressivity, but lacks prior knowledge of the underlying spatiotemporal structures. Leveraging the strengths of both two paradigms, we demonstrate a low rankness-induced Transformer to achieve a balance between strong inductive bias and high expressivity. The exploitation of the inherent structures of spatiotemporal data enables our model to learn balanced signal-noise representations, making it generalizable for a variety of imputation tasks. We demonstrate its superiority in terms of accuracy, efficiency, and versatility in heterogeneous datasets, including traffic flow, solar energy, smart meters, and air quality. Promising empirical results provide strong conviction that incorporating time series primitives, such as low-rankness, can substantially facilitate the development of a generalizable model to approach a wide range of spatiotemporal imputation problems.|缺失数据是科学和工程任务中普遍存在的问题，特别是对于时空数据的建模。现有的归责解决方案主要包括低阶模型和深度学习模型。前者假设一般结构先验，但模型容量有限。后者具有显著的表现力，但缺乏对潜在时空结构的先验知识。利用这两种模式的优势，我们展示了一个低等级感应变压器，以实现强感应偏置和高表达性之间的平衡。利用时空数据的固有结构，使我们的模型能够学习平衡的信号-噪声表示，使它可以推广到各种插补任务。我们证明了它在准确性、效率和异构数据集的通用性方面的优势，包括交通流量、太阳能、智能仪表和空气质量。有希望的经验结果提供了强有力的信念，结合时间序列原语，如低秩，可以大大促进发展一个可推广的模型来处理广泛的时空插补问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ImputeFormer:+Low+Rankness-Induced+Transformers+for+Generalizable+Spatiotemporal+Imputation)|0|
|[Improving the Consistency in Cross-Lingual Cross-Modal Retrieval with 1-to-K Contrastive Learning](https://doi.org/10.1145/3637528.3671787)|Zhijie Nie, Richong Zhang, Zhangchi Feng, Hailang Huang, Xudong Liu|CCSE, Beihang University, Beijing, China|Cross-lingual Cross-modal Retrieval (CCR) is an essential task in web search, which aims to break the barriers between modality and language simultaneously and achieves image-text retrieval in the multi-lingual scenario with a single model. In recent years, excellent progress has been made based on cross-lingual cross-modal pre-training; particularly, the methods based on contrastive learning on large-scale data have significantly improved retrieval tasks. However, these methods directly follow the existing pre-training methods in the cross-lingual or cross-modal domain, leading to two problems of inconsistency in CCR: The methods with cross-lingual style suffer from the intra-modal error propagation, resulting in inconsistent recall performance across languages in the whole dataset. The methods with cross-modal style suffer from the inter-modal optimization direction bias, resulting in inconsistent rank across languages within each instance, which cannot be reflected by Recall@K. To solve these problems, we propose a simple but effective 1-to-K contrastive learning method, which treats each language equally and eliminates error propagation and optimization bias. In addition, we propose a new evaluation metric, Mean Rank Variance (MRV), to reflect the rank inconsistency across languages within each instance. Extensive experiments on four CCR datasets show that our method improves both recall rates and MRV with smaller-scale pre-trained data, achieving the new state-of-art.|跨语言交叉模式检索(CCR)是网络搜索中的一项重要任务，其目的是同时打破语言和情态之间的界限，以单一的模型实现多语种情景下的图像-文本检索。近年来，基于跨语言跨模式预训练的检索方法取得了显著的进展，尤其是基于大规模数据的对比学习方法显著改善了检索任务。然而，这些方法直接遵循现有的跨语言或跨模式领域的预训练方法，导致 CCR 中的两个不一致问题: 跨语言风格的方法受到模式内错误传播的影响，导致整个数据集中跨语言的召回性能不一致。具有跨模态风格的方法存在多模态优化方向偏差，导致每个实例中语言间的排名不一致，Recall@K 不能反映这一点。为了解决这些问题，我们提出了一种简单而有效的1-To-K 对比学习方法，该方法对每种语言一视同仁，消除了错误传播和优化偏差。此外，我们提出了一个新的评估指标，平均秩方差(MRV) ，以反映秩不一致的语言在每个实例。在四个 CCR 数据集上的大量实验表明，我们的方法利用较小规模的预训练数据提高了召回率和 MRV，实现了新的技术水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+the+Consistency+in+Cross-Lingual+Cross-Modal+Retrieval+with+1-to-K+Contrastive+Learning)|0|
|[CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](https://doi.org/10.1145/3637528.3671837)|LiangBo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang|; The Hong Kong Polytechnic University, Hong Kong, China; Jinan University, Guangzhou, China|Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.|近年来，大语言模型(LLM)授权的推荐系统(RecSys)在个性化用户体验方面取得了重大进展，引起了人们的广泛关注。尽管取得了令人印象深刻的进展，关于 LLM 授权的 RecSys 的安全漏洞的研究问题仍然在很大程度上没有得到充分的研究。考虑到安全和隐私问题，更实际的做法是集中攻击黑匣子 RecSys，攻击者只能观察系统的输入和输出。然而，传统的使用强化学习代理的攻击方法并不能有效地攻击具有 LLM 授权的 RecSys，因为它在处理复杂的文本输入、规划和推理方面的能力有限。另一方面，LLM 提供了前所未有的机会作为攻击代理攻击 RecSys，因为它们在模拟类人决策过程方面具有令人印象深刻的能力。因此，本文提出了一种新的攻击框架——欺骗代理(CheatAgent) ，利用 LLM 的类人功能，开发了一种基于 LLM 的代理来攻击 LLM 授权的 RecSys。具体来说，我们的方法首先确定插入位置，以便在最小的输入修改下获得最大的影响。在此之后，LLM 代理被设计为产生对抗性扰动插入到目标位置。为了进一步提高生成扰动的质量，我们利用快速调整技术，通过迭代地从受害者 RecSys 反馈来改进攻击策略。通过对三个实际数据集的大量实验证明了我们提出的攻击方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CheatAgent:+Attacking+LLM-Empowered+Recommender+Systems+via+LLM+Agent)|0|
|[Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I](https://doi.org/10.1145/3637528.3671883)|Harrie Oosterhuis, Rolf Jagerman, Zhen Qin, Xuanhui Wang, Michael Bendersky|Google Research, New York City, USA; Google Research, Mountain View, USA; Google Research, Amsterdam, Netherlands; Google Research & Radboud University, Amsterdam, Netherlands|The traditional evaluation of information retrieval (IR) systems is generally very costly as it requires manual relevance annotation from human experts. Recent advancements in generative artificial intelligence -specifically large language models (LLMs)- can generate relevance annotations at an enormous scale with relatively small computational costs. Potentially, this could alleviate the costs traditionally associated with IR evaluation and make it applicable to numerous low-resource applications. However, generated relevance annotations are not immune to (systematic) errors, and as a result, directly using them for evaluation produces unreliable results. In this work, we propose two methods based on prediction-powered inference and conformal risk control that utilize computer-generated relevance annotations to place reliable confidence intervals (CIs) around IR evaluation metrics. Our proposed methods require a small number of reliable annotations from which the methods can statistically analyze the errors in the generated annotations. Using this information, we can place CIs around evaluation metrics with strong theoretical guarantees. Unlike existing approaches, our conformal risk control method is specifically designed for ranking metrics and can vary its CIs per query and document. Our experimental results show that our CIs accurately capture both the variance and bias in evaluation based on LLM annotations, better than the typical empirical bootstrapping estimates. We hope our contributions bring reliable evaluation to the many IR applications where this was traditionally infeasible.|传统的信息检索系统评估通常是非常昂贵的，因为它需要人类专家的手工相关注释。生成性人工智能的最新进展——特别是大语言模型(LLM)——能够以相对较小的计算成本产生大规模的相关注释。这可能会减轻传统上与 IR 评估相关的成本，并使其适用于许多低资源的应用程序。然而，生成的相关性注释不能免疫(系统)错误，因此，直接使用它们进行评估会产生不可靠的结果。在这项工作中，我们提出了两种基于预测推理和保形风险控制的方法，利用计算机生成的相关性注释，将可靠的置信区间(CI)放置在 IR 评估指标周围。我们提出的方法需要少量可靠的注释，这些方法可以从中统计分析生成的注释中的错误。利用这些信息，我们可以将 CI 放在具有强大理论保证的评估指标周围。与现有的方法不同，我们的适形风险控制方法是专门为排序指标而设计的，并且可以根据查询和文档改变其 CI。我们的实验结果表明，我们的 CI 能够准确地捕获基于 LLM 注释的评估中的方差和偏差，比典型的经验自举估计更好。我们希望我们的贡献能够为许多传统上不可行的 IR 应用带来可靠的评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reliable+Confidence+Intervals+for+Information+Retrieval+Evaluation+Using+Generative+A.I)|0|
|[How Powerful is Graph Filtering for Recommendation](https://doi.org/10.1145/3637528.3671789)|Shaowen Peng, Xin Liu, Kazunari Sugiyama, Tsunenori Mine|Kyushu University Fukuoka, Japan; NARA Institute of Science and Technology, Nara, Japan; National Institute of Advanced Industrial Science and Technology Tokyo, Japan; Osaka Seikei University Osaka, Japan|It has been shown that the effectiveness of graph convolutional network (GCN) for recommendation is attributed to the spectral graph filtering. Most GCN-based methods consist of a graph filter or followed by a low-rank mapping optimized based on supervised training. However, we show two limitations suppressing the power of graph filtering: (1) Lack of generality. Due to the varied noise distribution, graph filters fail to denoise sparse data where noise is scattered across all frequencies, while supervised training results in worse performance on dense data where noise is concentrated in middle frequencies that can be removed by graph filters without training. (2) Lack of expressive power. We theoretically show that linear GCN (LGCN) that is effective on collaborative filtering (CF) cannot generate arbitrary embeddings, implying the possibility that optimal data representation might be unreachable. To tackle the first limitation, we show close relation between noise distribution and the sharpness of spectrum where a sharper spectral distribution is more desirable causing data noise to be separable from important features without training. Based on this observation, we propose a generalized graph normalization (G2N) with hyperparameters adjusting the sharpness of spectral distribution in order to redistribute data noise to assure that it can be removed by graph filtering without training. As for the second limitation, we propose an individualized graph filter (IGF) adapting to the different confidence levels of the user preference that interactions can reflect, which is proved to be able to generate arbitrary embeddings. By simplifying LGCN, we further propose a simplified graph filtering for CF (SGFCF) which only requires the top-K singular values for recommendation. Finally, experimental results on four datasets with different density settings demonstrate the effectiveness and efficiency of our proposed methods.|研究表明，图卷积网络(GCN)的推荐有效性归功于谱图滤波。大多数基于 GCN 的方法包括一个图滤波器或后跟一个基于监督训练优化的低秩映射。然而，我们发现了抑制图滤波能力的两个限制: (1)缺乏通用性。由于噪声分布的多样性，图形滤波器在噪声散布于所有频率的稀疏数据中无法去噪，而监督训练在噪声集中于中间频率的稠密数据中效果较差，图形滤波器不需要训练就可以去除噪声。(2)缺乏表达能力。我们从理论上证明了对协同过滤有效的线性 GCN (LGCN)不能产生任意的嵌入，这意味着最佳数据表示可能无法实现。为了解决第一个局限性，我们展示了噪声分布和频谱清晰度之间的密切关系，其中更清晰的频谱分布更可取，使得数据噪声可以不经训练地从重要特征中分离出来。在此基础上，我们提出了一种带有超参数的广义图归一化算法(G2N) ，该算法通过调整光谱分布的清晰度来重新分布数据噪声，以保证不需要训练就可以通过图滤波去除噪声。针对第二个限制，我们提出了一种个性化图形滤波器(IGF) ，它能够适应交互所反映的用户偏好的不同置信水平，并且能够产生任意的嵌入。通过简化 LGCN，我们进一步提出了一种简化的 CF (SGFCF)图形滤波器，它只需要最高 K 的奇异值作为推荐值。最后，在四个不同密度设置的数据集上的实验结果表明了本文方法的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Powerful+is+Graph+Filtering+for+Recommendation)|0|
|[STEMO: Early Spatio-temporal Forecasting with Multi-Objective Reinforcement Learning](https://doi.org/10.1145/3637528.3671922)|Wei Shao, Yufan Kang, Ziyan Peng, Xiao Xiao, Lei Wang, Yuhui Yang, Flora D. Salim|Data61, CSIRO, Clayton, Victoria, Australia; University of New South Wales, Sydney, Australia; RMIT University, Melbourne, Victoria, Australia; Xidian University, Xi'an, China; Zhejiang University, Hangzhou, China|Accuracy and timeliness are indeed often conflicting goals in predictiontasks. Premature predictions may yield a higher rate of false alarms, whereasdelaying predictions to gather more information can render them too late to beuseful. In applications such as wildfires, crimes, and traffic jams, timelyforecasting are vital for safeguarding human life and property. Consequently,finding a balance between accuracy and timeliness is crucial. In this paper, wepropose an early spatio-temporal forecasting model based on Multi-Objectivereinforcement learning that can either implement an optimal policy given apreference or infer the preference based on a small number of samples. Themodel addresses two primary challenges: 1) enhancing the accuracy of earlyforecasting and 2) providing the optimal policy for determining the mostsuitable prediction time for each area. Our method demonstrates superiorperformance on three large-scale real-world datasets, surpassing existingmethods in early spatio-temporal forecasting tasks.|在预测任务中，准确性和及时性往往是矛盾的目标。过早的预测可能会产生更高的错误警报率，而为了收集更多信息而推迟预测可能会使预测太晚而无法发挥作用。在野火、犯罪和交通堵塞等应用中，及时预报对保护人类生命和财产至关重要。因此，在准确性和及时性之间找到一个平衡点是至关重要的。本文提出了一种基于多目标强化学习的早期时空预测模型，该模型既可以实现给定偏好的最优策略，也可以基于少量样本进行偏好推断。该模型解决了两个主要的挑战: 1)提高早期预测的准确性和2)为确定每个地区最合适的预测时间提供最优策略。该方法在三个大规模真实世界数据集上表现出优越的性能，在早期时空预测任务中优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STEMO:+Early+Spatio-temporal+Forecasting+with+Multi-Objective+Reinforcement+Learning)|0|
|[Marrying Dialogue Systems with Data Visualization: Interactive Data Visualization Generation from Natural Language Conversations](https://doi.org/10.1145/3637528.3671935)|Yuanfeng Song, Xuefang Zhao, Raymond ChiWing Wong|AI Group, WeBank Co., Ltd., Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, China|Data visualization (DV) has become the prevailing tool in the market due to its effectiveness into illustrating insights in vast amounts of data. To lower the barrier of using DVs, automatic DV tasks, such as natural language question (NLQ) to visualization translation (formally called text-to-vis), have been investigated in the research community. However, text-to-vis assumes the NLQ to be well-organized and expressed in a single sentence. However, in real-world settings, complex DV is needed through consecutive exchanges between the DV system and the users. In this paper, we propose a new task named CoVis, short for Conversational text-to-Visualization, aiming at constructing DVs through a series of interactions between users and the system. Since it is the task which has not been studied in the literature, we first build a benchmark dataset named Dial-NVBench, including dialogue sessions with a sequence of queries from a user and responses from the system. The ultimate goal of each dialogue session is to create a suitable DV. However, this process can contain diverse dialogue queries, such as seeking information about the dataset, manipulating parts of the data, and visualizing the data. Then, we propose a multi-modal neural network named MMCoVisNet to answer these DV-related queries. In particular, MMCoVisNet first fully understands the dialogue context and determines the corresponding responses. Then, it uses adaptive decoders to provide the appropriate replies: (i) a straightforward text decoder is used to produce general responses, (ii) an SQL-form decoder is applied to synthesize data querying responses, and (iii) a DV-form decoder tries to construct the appropriate DVs. We comparatively evaluate MMCoVisNet with other baselines over our proposed benchmark dataset. Experimental results validate that MMCoVisNet performs better than existing baselines and achieves a state-of-the-art performance.|数据可视化(DV)已成为市场上流行的工具，因为它能有效地用大量数据来说明见解。为了降低数字视频的使用障碍，自动数字视频任务，如自然语言问题(NLQ)到可视化翻译(正式称为文本到视觉) ，已经在研究界进行了研究。然而，文本-视觉假设 NLQ 是组织良好的，并表达在一个单一的句子。然而，在现实世界中，复杂的 DV 需要通过 DV 系统与用户之间的连续交换。本文提出了一个新的任务 CoVis，即会话文本到可视化(Conversational text-to-Visualization) ，旨在通过用户与系统之间的一系列交互来构建 DVs。本文首先构建了一个基准数据集 Dial-NVBench，包括用户的对话会话和系统的响应。每个对话会议的最终目标是创建一个合适的 DV。但是，这个过程可以包含不同的对话查询，例如查找有关数据集的信息、操作部分数据和可视化数据。然后，提出了一种多模态神经网络 MMCoVisNet 来回答这些与 DV 相关的查询。具体来说，MMCoVisNet 首先完全理解对话语境并确定相应的响应。然后，它使用自适应解码器提供适当的答复: (i)一个简单的文本解码器用于产生一般的响应，(ii)一个 SQL 形式的解码器用于合成数据查询响应，和(iii)一个 DV 形式的解码器试图构造适当的 DVs。我们比较评估 MMCoVisNet 与其他基线在我们提出的基准数据集。实验结果验证了 MMCoVisNet 的性能优于现有的基准线，达到了最先进的性能水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Marrying+Dialogue+Systems+with+Data+Visualization:+Interactive+Data+Visualization+Generation+from+Natural+Language+Conversations)|0|
|[Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning](https://doi.org/10.1145/3637528.3671661)|Jiakai Tang, Sunhao Dai, Zexu Sun, Xu Chen, Jun Xu, Wenhui Yu, Lantao Hu, Peng Jiang, Han Li|Kuaishou Technology, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China|In recent years, graph contrastive learning (GCL) has received increasing attention in recommender systems due to its effectiveness in reducing bias caused by data sparsity. However, most existing GCL models rely on heuristic approaches and usually assume entity independence when constructing contrastive views. We argue that these methods struggle to strike a balance between semantic invariance and view hardness across the dynamic training process, both of which are critical factors in graph contrastive learning. To address the above issues, we propose a novel GCL-based recommendation framework RGCL, which effectively maintains the semantic invariance of contrastive pairs and dynamically adapts as the model capability evolves through the training process. Specifically, RGCL first introduces decision boundary-aware adversarial perturbations to constrain the exploration space of contrastive augmented views, avoiding the decrease of task-specific information. Furthermore, to incorporate global user-user and item-item collaboration relationships for guiding on the generation of hard contrastive views, we propose an adversarial-contrastive learning objective to construct a relation-aware view-generator. Besides, considering that unsupervised GCL could potentially narrower margins between data points and the decision boundary, resulting in decreased model robustness, we introduce the adversarial examples based on maximum perturbations to achieve margin maximization. We also provide theoretical analyses on the effectiveness of our designs. Through extensive experiments on five public datasets, we demonstrate the superiority of RGCL compared against twelve baseline models.|近年来，图形对比学习(GCL)由于能够有效地减少数据稀疏带来的偏差，在推荐系统中得到了越来越多的关注。然而，大多数现有的 GCL 模型依赖于启发式方法，并且在构造对比视图时通常假设实体独立。我们认为这些方法在动态训练过程中很难在语义不变性和视图硬度之间取得平衡，这两者都是图形对比学习的关键因素。为了解决上述问题，我们提出了一种新的基于 GCL 的推荐框架 RGCL，该框架有效地保持了对比对的语义不变性，并随着模型能力在训练过程中的发展而动态适应。具体来说，RGCL 首先引入了决策边界感知的对抗扰动来约束对比增广视图的探索空间，避免了任务特定信息的减少。此外，为了整合全局用户-用户和项目-项目协作关系来指导硬对比视图的生成，我们提出了一个对抗对比学习目标来构造一个关系感知视图生成器。此外，考虑到无监督的 GCL 可能会缩小数据点与决策边界之间的利润率，从而降低模型的稳健性，我们引入了基于最大扰动的对抗性例子，以实现利润率最大化。我们还对我们的设计的有效性提供了理论分析。通过对5个公共数据集的大量实验，我们证明了 RgCL 相对于十二个基线模型的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Robust+Recommendation+via+Decision+Boundary-aware+Graph+Contrastive+Learning)|0|
|[Reinforced Compressive Neural Architecture Search for Versatile Adversarial Robustness](https://doi.org/10.1145/3637528.3672009)|Dingrong Wang, Hitesh Sapkota, Zhiqiang Tao, Qi Yu|Amazon Inc., Sunnyvale, CA, USA; Rochester Institute of Technology, Rochester, NY, USA|Prior research on neural architecture search (NAS) for adversarial robustness has revealed that a lightweight and adversarially robust sub-network could exist in a non-robust large teacher network. Such a sub-network is generally discovered based on heuristic rules to perform neural architecture search. However, heuristic rules are inadequate to handle diverse adversarial attacks and different "teacher" network capacity. To address this key challenge, we propose Reinforced Compressive Neural Architecture Search (RC-NAS), aiming to achieve Versatile Adversarial Robustness. Specifically, we define novel task settings that compose datasets, adversarial attacks, and teacher network configuration. Given diverse tasks, we develop an innovative dual-level training paradigm that consists of a meta-training and a fine-tuning phase to effectively expose the RL agent to diverse attack scenarios (in meta-training), and make it adapt quickly to locate an optimal sub-network (in fine-tuning) for previously unseen scenarios. Experiments show that our framework could achieve adaptive compression towards different initial teacher networks, datasets, and adversarial attacks, resulting in more lightweight and adversarially robust architectures. We also provide a theoretical analysis to explain why the reinforcement learning (RL)-guided adversarial architectural search helps adversarial robustness over standard adversarial training methods.|针对对抗性鲁棒性的神经网络结构搜索(NAS)研究表明，在非鲁棒的大型教师网络中存在一个轻量级的对抗性鲁棒子网络。这样的子网络通常是基于启发式规则发现的，用于执行神经结构搜索。然而，启发式规则不足以处理不同的对手攻击和不同的“教师”网络容量。为了解决这一关键问题，我们提出了增强压缩神经结构搜索(RC-NAS) ，旨在实现通用的对抗鲁棒性。具体来说，我们定义了组成数据集、对抗性攻击和教师网络配置的新任务设置。考虑到不同的任务，我们开发了一个创新的双级训练范例，其中包括元训练和微调阶段，以有效地将 RL 代理暴露于不同的攻击场景(在元训练中) ，并使其快速适应定位最佳子网络(在微调中)以前看不见的场景。实验表明，我们的框架能够针对不同的初始教师网络、数据集和对抗性攻击实现自适应压缩，从而产生更轻量级和对抗性更强的体系结构。我们还提供了一个理论分析来解释为什么强化学习指导的对抗架构搜索比标准的对抗训练方法有助于对抗的稳健性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforced+Compressive+Neural+Architecture+Search+for+Versatile+Adversarial+Robustness)|0|
|[Routing Evidence for Unseen Actions in Video Moment Retrieval](https://doi.org/10.1145/3637528.3671693)|Guolong Wang, Xun Wu, Zheng Qin, Liangliang Shi|; Tsinghua University, Beijing, China|Video moment retrieval (VMR) is a cutting-edge vision-language task locating a segment in a video according to the query. Though the methods have achieved significant performance, they assume that training and testing samples share the same action types, hindering real-world application. In this paper, we specifically consider a new problem: video moment retrieval by queries with unseen actions. We propose a plug-and-play structure, Routing Evidence (RE), with multiple evidence-learning heads and dynamically route one to locate a sentence with an unseen action. Each evidence-learning head estimates the uncertainty while regressing timestamps. We formulate the evidence distribution by a Normal-Inverse Gamma function and design a router to select the most appropriate distribution for a sample. Empirically, we study the efficacy of RE on three updated databases where training and testing samples contain different action types. We find that RE outperforms other state-of-the-art methods with a more robust predictor. Code and data will be available at https://github.com/dieuroi/Routing-Evidence.|视频矩检索(VMR)是一种根据查询对视频片段进行定位的前沿视觉语言任务。尽管这些方法已经取得了显著的性能，但是它们假设训练和测试样本共享相同的动作类型，从而阻碍了真实世界的应用。在本文中，我们特别考虑了一个新的问题: 视频时刻检索的查询与看不见的行动。我们提出了一种即插即用的结构，路由证据(RE) ，具有多个证据学习头，并动态路由其中一个来定位一个看不见动作的句子。每个证据学习负责人在回归时间戳时估计不确定性。我们利用一个正反伽玛函数来表达证据分布，并设计一个路由器来选择最适合样本的分布。通过实证研究，我们在三个更新的训练和测试样本包含不同行为类型的数据库上研究了 RE 的效能。我们发现 RE 比其他最先进的方法具有更强大的预测器。代码和数据将在 https://github.com/dieuroi/routing-evidence 公布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Routing+Evidence+for+Unseen+Actions+in+Video+Moment+Retrieval)|0|
|[Unveiling Vulnerabilities of Contrastive Recommender Systems to Poisoning Attacks](https://doi.org/10.1145/3637528.3671795)|Zongwei Wang, Junliang Yu, Min Gao, Hongzhi Yin, Bin Cui, Shazia W. Sadiq|Peking University, Beijing, China; The University of Queensland, Brisbane, Australia; Chongqing University, Chongqing, China|Contrastive learning (CL) has recently gained prominence in the domain of recommender systems due to its great ability to enhance recommendation accuracy and improve model robustness. Despite its advantages, this paper identifies a vulnerability of CL-based recommender systems that they are more susceptible to poisoning attacks aiming to promote individual items. Our analysis indicates that this vulnerability is attributed to the uniform spread of representations caused by the InfoNCE loss. Furthermore, theoretical and empirical evidence shows that optimizing this loss favors smooth spectral values of representations. This finding suggests that attackers could facilitate this optimization process of CL by encouraging a more uniform distribution of spectral values, thereby enhancing the degree of representation dispersion. With these insights, we attempt to reveal a potential poisoning attack against CL-based recommender systems, which encompasses a dual-objective framework: one that induces a smoother spectral value distribution to amplify the InfoNCE loss's inherent dispersion effect, named dispersion promotion; and the other that directly elevates the visibility of target items, named rank promotion. We validate the threats of our attack model through extensive experimentation on four datasets. By shedding light on these vulnerabilities, our goal is to advance the development of more robust CL-based recommender systems. The code is available at https://github.com/CoderWZW/ARLib.|对比学习由于具有提高推荐精度和增强模型鲁棒性的能力，近年来在推荐系统领域得到了广泛的应用。本文认为基于 CL 的推荐系统虽然具有一定的优势，但是它们更容易受到旨在推广个别项目的中毒攻击。我们的分析表明，这一漏洞是由于表示的统一传播造成的信息 NCE 的损失。此外，理论和经验证明表明，优化这种损失有利于表示的平滑光谱值。这一发现表明，攻击者可以通过鼓励谱值的更均匀分布来促进 CL 的优化过程，从而提高表示离散度。有了这些见解，我们试图揭示一种针对基于 CL 的推荐系统的潜在中毒攻击，其中包含一个双重目标框架: 一个是诱导更平滑的光谱值分布，以放大 InfoNCE 损失的固有分散效应，称为分散促进; 另一个是直接提高目标项目的可见性，称为等级促进。我们通过在四个数据集上的大量实验验证了我们的攻击模型的威胁性。通过阐明这些漏洞，我们的目标是推动开发更健壮的基于 CL 的推荐系统。密码可在 https://github.com/coderwzw/arlib 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Vulnerabilities+of+Contrastive+Recommender+Systems+to+Poisoning+Attacks)|0|
|[FedSAC: Dynamic Submodel Allocation for Collaborative Fairness in Federated Learning](https://doi.org/10.1145/3637528.3671748)|Zihui Wang, Zheng Wang, Lingjuan Lyu, Zhaopeng Peng, Zhicheng Yang, Chenglu Wen, Rongshan Yu, Cheng Wang, Xiaoliang Fan|; Sony AI, Zurich, Swaziland|Collaborative fairness stands as an essential element in federated learningto encourage client participation by equitably distributing rewards based onindividual contributions. Existing methods primarily focus on adjustinggradient allocations among clients to achieve collaborative fairness. However,they frequently overlook crucial factors such as maintaining consistency acrosslocal models and catering to the diverse requirements of high-contributingclients. This oversight inevitably decreases both fairness and model accuracyin practice. To address these issues, we propose FedSAC, a novel Federatedlearning framework with dynamic Submodel Allocation for Collaborative fairness,backed by a theoretical convergence guarantee. First, we present the concept of"bounded collaborative fairness (BCF)", which ensures fairness by tailoringrewards to individual clients based on their contributions. Second, toimplement the BCF, we design a submodel allocation module with a theoreticalguarantee of fairness. This module incentivizes high-contributing clients withhigh-performance submodels containing a diverse range of crucial neurons,thereby preserving consistency across local models. Third, we further develop adynamic aggregation module to adaptively aggregate submodels, ensuring theequitable treatment of low-frequency neurons and consequently enhancing overallmodel accuracy. Extensive experiments conducted on three public benchmarksdemonstrate that FedSAC outperforms all baseline methods in both fairness andmodel accuracy. We see this work as a significant step towards incentivizingbroader client participation in federated learning. The source code isavailable at https://github.com/wangzihuixmu/FedSAC.|协作公平是联合学习的一个重要组成部分，通过公平分配基于个人贡献的奖励来鼓励客户参与。现有的方法主要集中在调整客户间的梯度分配以实现协作公平。然而，他们经常忽略一些关键因素，例如保持当地模式的一致性以及满足高贡献客户的不同需求。这种疏忽不可避免地降低了实践中的公平性和模型的准确性。为了解决这些问题，我们提出了 FedSAC，这是一个新的联邦学习框架，具有动态子模型分配的协作公平性，在理论趋同保证的支持下。首先，我们提出了“有限协作公平(BCF)”的概念，它通过根据客户的贡献量身定制奖励来确保公平性。其次，为了实现 BCF，我们设计了一个具有公平性理论保证的子模型分配模块。该模块通过包含多种关键神经元的高性能子模型激励高贡献客户，从而保持局部模型之间的一致性。第三，我们进一步发展动态聚集模块，以自适应聚集子模型，确保公平的治疗低频神经元，从而提高整体模型的准确性。在三个公共基准上进行的大量实验表明，FedSAC 在公平性和模型准确性方面优于所有基准方法。我们认为这项工作是激励更广泛的客户参与联合学习的重要一步。源代码可以在 https://github.com/wangzihuixmu/fedsac 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedSAC:+Dynamic+Submodel+Allocation+for+Collaborative+Fairness+in+Federated+Learning)|0|
|[Unifying Graph Convolution and Contrastive Learning in Collaborative Filtering](https://doi.org/10.1145/3637528.3671840)|Yihong Wu, Le Zhang, Fengran Mo, Tianyu Zhu, Weizhi Ma, JianYun Nie|Université de Montréal, Montréal, Canada; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; MIIT Key Laboratory of Data Intelligence and Management, Beihang University, Beijing, China; Mila - Quebec AI Institute, Montréal, Canada|Graph-based models and contrastive learning have emerged as prominent methods in Collaborative Filtering (CF). While many existing models in CF incorporate these methods in their design, there seems to be a limited depth of analysis regarding the foundational principles behind them. This paper bridges graph convolution, a pivotal element of graph-based models, with contrastive learning through a theoretical framework. By examining the learning dynamics and equilibrium of the contrastive loss, we offer a fresh lens to understand contrastive learning via graph theory, emphasizing its capability to capture high-order connectivity. Building on this analysis, we further show that the graph convolutional layers often used in graph-based models are not essential for high-order connectivity modeling and might contribute to the risk of oversmoothing. Stemming from our findings, we introduce Simple Contrastive Collaborative Filtering (SCCF), a simple and effective algorithm based on a naive embedding model and a modified contrastive loss. The efficacy of the algorithm is demonstrated through extensive experiments across four public datasets. The experiment code is available at https://github.com/wu1hong/SCCF.|基于图表的模型和对比学习已经成为协同过滤研究的主要方法。虽然 CF 中的许多现有模型在其设计中包含了这些方法，但似乎对其背后的基本原则的分析深度有限。本文通过一个理论框架，将图卷积这一基于图的模型的关键要素与对比学习结合起来。通过研究对比损失的学习动力学和均衡性，我们提供了一个新的视角，通过图论来理解对比学习，强调其捕捉高阶连通性的能力。在此分析的基础上，我们进一步表明，在基于图的模型中经常使用的图卷积层并不是高阶连通性建模所必需的，而且可能会导致过度平滑的风险。根据我们的发现，我们介绍了简单对比协同过滤(SCCF) ，这是一个简单而有效的算法，基于一个幼稚的嵌入模型和一个修正的对比度损失。通过对四个公共数据集的大量实验，验证了算法的有效性。实验代码可在 https://github.com/wu1hong/sccf 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+Graph+Convolution+and+Contrastive+Learning+in+Collaborative+Filtering)|0|
|[Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification](https://doi.org/10.1145/3637528.3671706)|Beini Xie, Heng Chang, Ziwei Zhang, Zeyang Zhang, Simin Wu, Xin Wang, Yuan Meng, Wenwu Zhu|DCST, Tsinghua University, Beijing, China; Lanzhou University, Lanzhou, China; DCST, BNRist, Tsinghua University, Beijing, China|Graph Neural Architecture Search (GNAS) has achieved superior performance on various graph-structured tasks. However, existing GNAS studies overlook the applications of GNAS in resource-constrained scenarios. This paper proposes to design a joint graph data and architecture mechanism, which identifies important sub-architectures via the valuable graph data. To search for optimal lightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural Architecture Search with Graph SparsIfication and Network Pruning (GASSIP) method. In particular, GASSIP comprises an operation-pruned architecture search module to enable efficient lightweight GNN search. Meanwhile, we design a novel curriculum graph data sparsification module with an architecture-aware edge-removing difficulty measurement to help select optimal sub-architectures. With the aid of two differentiable masks, we iteratively optimize these two modules to efficiently search for the optimal lightweight architecture. Extensive experiments on five benchmarks demonstrate the effectiveness of GASSIP. Particularly, our method achieves on-par or even higher node classification performance with half or fewer model parameters of searched GNNs and a sparser graph.|图形神经结构搜索(GNAS)已经在各种图形结构的任务中取得了优异的性能。然而，现有的 GNAS 研究忽视了 GNAS 在资源受限情况下的应用。本文提出了一种联合图数据和体系结构机制，通过有价值的图数据来识别重要的子体系结构。为了寻找最优的轻量级图神经网络(GNN) ，提出了一种基于图稀疏化和网络剪枝的轻量级图神经网络体系结构搜索(GASSIP)方法。特别是，GASSIP 包含一个操作修剪的体系结构搜索模块，以支持高效的轻量级 GNN 搜索。同时，我们设计了一个新颖的课程图数据稀疏化模块，该模块具有体系结构感知的边缘去除困难度度量，以帮助选择最佳的子体系结构。借助于两个可微掩模，我们对这两个模块进行迭代优化，以有效地寻找最优的轻量级体系结构。在五个基准上的大量实验证明了 GASSIP 的有效性。特别地，我们的方法只需要搜索到的 GNN 的一半或更少的模型参数和一个更稀疏的图，就可以获得同等甚至更高的节点分类性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Lightweight+Graph+Neural+Network+Search+with+Curriculum+Graph+Sparsification)|0|
|[Revisiting Reciprocal Recommender Systems: Metrics, Formulation, and Method](https://doi.org/10.1145/3637528.3671734)|Chen Yang, Sunhao Dai, Yupeng Hou, Wayne Xin Zhao, Jun Xu, Yang Song, Hengshu Zhu|; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; University of California, San Diego, La Jolla, USA; Nanbeige Lab, BOSS Zhipin, Beijing, China; Career Science Lab, BOSS Zhipin, Beijing, China|Reciprocal recommender systems (RRS), conducting bilateral recommendations between two involved parties, have gained increasing attention for enhancing matching efficiency. However, the majority of existing methods in the literature still reuse conventional ranking metrics to separately assess the performance on each side of the recommendation process. These methods overlook the fact that the ranking outcomes of both sides collectively influence the effectiveness of the RRS, neglecting the necessity of a more holistic evaluation and a capable systemic solution. In this paper, we systemically revisit the task of reciprocal recommendation, by introducing the new metrics, formulation, and method. Firstly, we propose five new evaluation metrics that comprehensively and accurately assess the performance of RRS from three distinct perspectives: overall coverage, bilateral stability, and balanced ranking. These metrics provide a more holistic understanding of the system's effectiveness and enable a comprehensive evaluation. Furthermore, we formulate the RRS from a causal perspective, formulating recommendations as bilateral interventions, which can better model the decoupled effects of potential influencing factors. By utilizing the potential outcome framework, we further develop a model-agnostic causal reciprocal recommendation method that considers the causal effects of recommendations. Additionally, we introduce a reranking strategy to maximize matching outcomes, as measured by the proposed metrics. Extensive experiments on two real-world datasets from recruitment and dating scenarios demonstrate the effectiveness of our proposed metrics and approach. The code and dataset are available at: https://github.com/RUCAIBox/CRRS.|互惠推荐系统(RRS)在两个相关方之间进行双边推荐，在提高匹配效率方面受到越来越多的关注。然而，文献中的大多数现有方法仍然重用传统的排名指标来分别评估推荐过程的各个方面的性能。这些方法忽略了这样一个事实，即双方的排名结果共同影响区域资源规划的有效性，忽视了更加全面的评估和有能力的系统解决方案的必要性。在本文中，我们系统地重新审视互惠推荐的任务，通过介绍新的指标，公式和方法。首先，我们提出了五个新的评价指标，全面和准确地评估 RRS 的绩效从三个不同的角度: 整体覆盖，双边稳定性和平衡排名。这些指标提供了对系统有效性的更全面的理解，并能够进行全面的评估。此外，我们从因果关系的角度制定 RRS，提出建议作为双边干预措施，可以更好地模拟潜在影响因素的解耦效应。通过利用潜在的结果框架，我们进一步开发了一个模型无关的因果互惠推荐方法，考虑了推荐的因果效应。此外，我们引入了一个重新排序策略，以最大限度地匹配结果，由提议的度量衡量。来自招聘和约会场景的两个真实世界数据集的大量实验证明了我们提出的指标和方法的有效性。代码和数据集可在以下 https://github.com/rucaibox/crrs 获得:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Reciprocal+Recommender+Systems:+Metrics,+Formulation,+and+Method)|0|
|[Graph Bottlenecked Social Recommendation](https://doi.org/10.1145/3637528.3671807)|Yonghui Yang, Le Wu, Zihan Wang, Zhuangzhuang He, Richang Hong, Meng Wang|Hefei University of Technology, Hefei, China|With the emergence of social networks, social recommendation has become an essential technique for personalized services. Recently, graph-based social recommendations have shown promising results by capturing the high-order social influence. Most empirical studies of graph-based social recommendations directly take the observed social networks into formulation, and produce user preferences based on social homogeneity. Despite the effectiveness, we argue that social networks in the real-world are inevitably noisy~(existing redundant social relations), which may obstruct precise user preference characterization. Nevertheless, identifying and removing redundant social relations is challenging due to a lack of labels. In this paper, we focus on learning the denoised social structure to facilitate recommendation tasks from an information bottleneck perspective. Specifically, we propose a novel Graph Bottlenecked Social Recommendation (GBSR) framework to tackle the social noise issue. GBSR is a model-agnostic social denoising framework, that aims to maximize the mutual information between the denoised social graph and recommendation labels, meanwhile minimizing it between the denoised social graph and the original one. This enables GBSR to learn the minimal yet sufficient social structure, effectively reducing redundant social relations and enhancing social recommendations. Technically, GBSR consists of two elaborate components, preference-guided social graph refinement, and HSIC-based bottleneck learning. Extensive experimental results demonstrate the superiority of the proposed GBSR, including high performances and good generality combined with various backbones. Our code is available at: https://github.com/yimutianyang/KDD24-GBSR.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Bottlenecked+Social+Recommendation)|0|
|[Efficient and Effective Anchored Densest Subgraph Search: A Convex-programming based Approach](https://doi.org/10.1145/3637528.3671727)|Xiaowei Ye, RongHua Li, Lei Liang, Zhizhen Liu, Longlong Lin, Guoren Wang|; Southwest University, Chongqing, China; Beijing Institute of Technology, Beijing, China; Ant Group, Hangzhou, China|The quest to identify local dense communities closely connected to predetermined seed nodes is vital across numerous applications. Given the seed nodes R, the R-subgraph density of a subgraph S is defined as traditional graph density of S with penalties on the nodes in S / R. The state-of-the-art (SOTA) anchored densest subgraph model, which is based on R-subgraph density, is designed to address the community search problem. However, it often struggles to efficiently uncover truly dense communities. To eliminate this issue, we propose a novel NR-subgraph density metric, a nuanced measure that identifies communities intimately linked to seed nodes and also exhibiting overall high graph density. We redefine the anchored densest subgraph search problem through the lens of NR-subgraph density and cast it as a Linear Programming (LP) problem. This allows us to transition into a dual problem, tapping into the efficiency and effectiveness of convex programming-based iterative algorithm. To solve this redefined problem, we propose two algorithms: FDP, an iterative method that swiftly attains near-optimal solutions, and FDPE, an exact approach that ensures full convergence. We perform extensive experiments on 12 real-world networks. The results show that our proposed algorithms not only outperform the SOTA methods by 3.6~14.1 times in terms of running time, but also produce subgraphs with superior internal quality.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Effective+Anchored+Densest+Subgraph+Search:+A+Convex-programming+based+Approach)|0|
|[Approximate Matrix Multiplication over Sliding Windows](https://doi.org/10.1145/3637528.3671819)|Ziqi Yao, Lianzhi Li, Mingsong Chen, Xian Wei, Cheng Chen|East China Normal University, Shanghai, China|Large-scale streaming matrix multiplication is very common in various applications, sparking significant interest in develop efficient algorithms for approximate matrix multiplication (AMM) over streams. In addition, many practical scenarios require to process time-sensitive data and aim to compute matrix multiplication for most recent columns of the data matrices rather than the entire matrices, which motivated us to study efficient AMM algorithms over sliding windows. In this paper, we present two novel deterministic algorithms for this problem and provide corresponding error guarantees. We further reduce the space and time costs of our methods for sparse matrices by performing an approximate singular value decomposition which can utilize the sparsity of matrices. Extensive experimental results on both synthetic and real-world datasets validate our theoretical analysis and highlight the efficiency of our methods.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Approximate+Matrix+Multiplication+over+Sliding+Windows)|0|
|[Unsupervised Generative Feature Transformation via Graph Contrastive Pre-training and Multi-objective Fine-tuning](https://doi.org/10.1145/3637528.3672015)|Wangyang Ying, Dongjie Wang, Xuanming Hu, Yuanchun Zhou, Charu C. Aggarwal, Yanjie Fu|Computer Network Information Center, Chinese Academy of Sciences, Beijing, China; International Business Machines T. J. Watson Research Center, Yorktown Heights, USA; Arizona State University, Tempe, AZ, USA; The University of Kansas, Lawrence, KS, USA|Feature transformation is to derive a new feature set from original features to augment the AI power of data. In many science domains such as material performance screening, while feature transformation can model material formula interactions and compositions and discover performance drivers, supervised labels are collected from expensive and lengthy experiments. This issue motivates an Unsupervised Feature Transformation Learning (UFTL) problem. Prior literature, such as manual transformation, supervised feedback guided search, and PCA, either relies on domain knowledge or expensive supervised feedback, or suffers from large search space, or overlooks non-linear feature-feature interactions. UFTL imposes a major challenge on existing methods: how to design a new unsupervised paradigm that captures complex feature interactions and avoids large search space? To fill this gap, we connect graph, contrastive, and generative learning to develop a measurement-pretrain-finetune paradigm for UFTL. For unsupervised feature set utility measurement, we propose a feature value consistency preservation perspective and develop a mean discounted cumulative gain like unsupervised metric to evaluate feature set utility. For unsupervised feature set representation pretraining, we regard a feature set as a feature-feature interaction graph, and develop an unsupervised graph contrastive learning encoder to embed feature sets into vectors. For generative transformation finetuning, we regard a feature set as a feature cross sequence and feature transformation as sequential generation. We develop a deep generative feature transformation model that coordinates the pretrained feature set encoder and the gradient information extracted from a feature set utility evaluator to optimize a transformed feature generator. Finally, we conduct extensive experiments to demonstrate the effectiveness, efficiency, traceability, and explicitness of our framework.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Generative+Feature+Transformation+via+Graph+Contrastive+Pre-training+and+Multi-objective+Fine-tuning)|0|
|[Personalized Federated Continual Learning via Multi-Granularity Prompt](https://doi.org/10.1145/3637528.3671948)|Hao Yu, Xin Yang, Xin Gao, Yan Kang, Hao Wang, Junbo Zhang, Tianrui Li|; School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, China; JD Intelligent Cities Research & JD iCity, JD Technology, Beijing, China; Webank, Shenzhen, China; College of Computer Science, Sichuan University, Chengdu, China|Personalized Federated Continual Learning (PFCL) is a new practical scenario that poses greater challenges in sharing and personalizing knowledge. PFCL not only relies on knowledge fusion for server aggregation at the global spatial-temporal perspective but also needs model improvement for each client according to the local requirements. Existing methods, whether in Personalized Federated Learning (PFL) or Federated Continual Learning (FCL), have overlooked the multi-granularity representation of knowledge, which can be utilized to overcome Spatial-Temporal Catastrophic Forgetting (STCF) and adopt generalized knowledge to itself by coarse-to-fine human cognitive mechanisms. Moreover, it allows more effectively to personalized shared knowledge, thus serving its own purpose. To this end, we propose a novel concept called multi-granularity prompt, i.e., coarse-grained global prompt acquired through the common model learning process, and fine-grained local prompt used to personalize the generalized representation. The former focuses on efficiently transferring shared global knowledge without spatial forgetting, and the latter emphasizes specific learning of personalized local knowledge to overcome temporal forgetting. In addition, we design a selective prompt fusion mechanism for aggregating knowledge of global prompts distilled from different clients. By the exclusive fusion of coarse-grained knowledge, we achieve the transmission and refinement of common knowledge among clients, further enhancing the performance of personalization. Extensive experiments demonstrate the effectiveness of the proposed method in addressing STCF as well as improving personalized performance.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Federated+Continual+Learning+via+Multi-Granularity+Prompt)|0|
|[DipDNN: Preserving Inverse Consistency and Approximation Efficiency for Invertible Learning](https://doi.org/10.1145/3637528.3672036)|Jingyi Yuan, Yang Weng, Erik Blasch|Air Force Research Lab, Arlington, VA, USA; Arizona State University, Tempe, AZ, USA|Consistent bi-directional inferences are the key for many machine learning applications. Without consistency, inverse learning-based inferences can cause fuzzy images, erroneous control signals, and cascading failure in SCADA systems. Since standard deep neural networks (DNNs) are not inherently invertible to offer consistency, some past methods reconstruct DNN architecture analytically for one-to-one correspondence but compromise key features such as universal approximation. Other work maintains the capability of universal approximation in DNNs via iterative numerical approximation. However, these methods limit their applications significantly due to Lipschitz conditions and issues of numerical convergence. The dilemma of the analytical and numerical methods is the incompatibility between nonlinear layer compositions and bijective function construction for inverse modeling. Based on the observation, we propose decomposed-invertible-pathway DNNs (DipDNN). It relaxes the redundant reconstruction of nested DNN in the former methods and eases the Lipschitz constraint. As a result, we strictly guarantee the consistency of global inverse modeling without harming DNN's capability for universal approximation. As numerical stability and generalizability are keys for controlling critical infrastructures, we integrate contractive property with a parallel structure for inductive biases, leading to stable performance. Numerical results show that DipDNN performs significantly better than past methods, thanks to its enforcement of inverse consistency, numerical stability, and physical regularization.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DipDNN:+Preserving+Inverse+Consistency+and+Approximation+Efficiency+for+Invertible+Learning)|0|
|[Conditional Logical Message Passing Transformer for Complex Query Answering](https://doi.org/10.1145/3637528.3671869)|Chongzhi Zhang, Zhiping Peng, Junhao Zheng, Qianli Ma|South China University of Technology, Guangzhou, China; Guangdong University of Petrochemical Technology & Jiangmen Polytechnic, Maoming, China|Complex Query Answering (CQA) over Knowledge Graphs (KGs) is a challenging task. Given that KGs are usually incomplete, neural models are proposed to solve CQA by performing multi-hop logical reasoning. However, most of them cannot perform well on both one-hop and multi-hop queries simultaneously. Recent work proposes a logical message passing mechanism based on the pre-trained neural link predictors. While effective on both one-hop and multi-hop queries, it ignores the difference between the constant and variable nodes in a query graph. In addition, during the node embedding update stage, this mechanism cannot dynamically measure the importance of different messages, and whether it can capture the implicit logical dependencies related to a node and received messages remains unclear. In this paper, we propose Conditional Logical Message Passing Transformer (CLMPT), which considers the difference between constants and variables in the case of using pre-trained neural link predictors and performs message passing conditionally on the node type. We empirically verified that this approach can reduce computational costs without affecting performance. Furthermore, CLMPT uses the transformer to aggregate received messages and update the corresponding node embedding. Through the self-attention mechanism, CLMPT can assign adaptive weights to elements in an input set consisting of received messages and the corresponding node and explicitly model logical dependencies between various elements. Experimental results show that CLMPT is a new state-of-the-art neural CQA model. https://github.com/qianlima-lab/CLMPT.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conditional+Logical+Message+Passing+Transformer+for+Complex+Query+Answering)|0|
|[Natural Language Explainable Recommendation with Robustness Enhancement](https://doi.org/10.1145/3637528.3671781)|Jingsen Zhang, Jiakai Tang, Xu Chen, Wenhui Yu, Lantao Hu, Peng Jiang, Han Li|Kuaishou Technology, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China|Natural language explainable recommendation has become a promising direction to facilitate more efficient and informed user decisions. Previous models mostly focus on how to enhance the explanation accuracy. However, the robustness problem has been largely ignored, which requires the explanations generated for similar user-item pairs should not be too much different. Different from traditional classification problems, improving the robustness of natural languages has two unique characteristics: (1) Different token importances, that is, different tokens play various roles in representing the complete sentence, and the robustness requirements for predicting them should also be different. (2) Continuous token semantics, that is, the similarity of the output should be judged based on semantics, and the sequences without any token-level overlap may also be highly similar. Based on these characteristics, we formulate and solve a novel problem in the recommendation domain, that is, robust natural language explainable recommendation. To the best of our knowledge, it is the first time in this field. Specifically, we base our modeling on adversarial robust optimization and design four types of heuristic methods to modify the adversarial outputs with weighted token probabilities and synonym replacements. Furthermore, to consider the mutual influence between the above characteristics, we regard language generation as a decision-making problem and design a dual-policy reinforcement learning framework to improve the robustness of the generated languages. We conduct extensive experiments to demonstrate the effectiveness of our framework.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Natural+Language+Explainable+Recommendation+with+Robustness+Enhancement)|0|
|[Enabling Collaborative Test-Time Adaptation in Dynamic Environment via Federated Learning](https://doi.org/10.1145/3637528.3671908)|Jiayuan Zhang, Xuefeng Liu, Yukang Zhang, Guogang Zhu, Jianwei Niu, Shaojie Tang|; Shenzhen International Graduate School, Tsinghua University, Beijing, China; Jindal School of Management, The University of Texas at Dallas, Richardson, TX, USA|Deep learning models often suffer performance degradation when test data diverges from training data. Test-Time Adaptation (TTA) aims to adapt a trained model to the test data distribution using unlabeled test data streams. In many real-world applications, it is quite common for the trained model to be deployed across multiple devices simultaneously. Although each device can execute TTA independently, it fails to leverage information from the test data of other devices. To address this problem, we introduce Federated Learning (FL) to TTA to facilitate on-the-fly collaboration among devices during test time. The workflow involves clients (i.e., the devices) executing TTA locally, uploading their updated models to a central server for aggregation, and downloading the aggregated model for inference. However, implementing FL in TTA presents many challenges, especially in establishing inter-client collaboration in dynamic environment, where the test data distribution on different clients changes over time in different manners. To tackle these challenges, we propose a server-side Temporal-Spatial Aggregation (TSA) method. TSA utilizes a temporal-spatial attention module to capture intra-client temporal correlations and inter-client spatial correlations. To further improve robustness against temporal-spatial heterogeneity, we propose a heterogeneity-aware augmentation method and optimize the module using a self-supervised approach. More importantly, TSA can be implemented as a plug-in to TTA methods in distributed environments. Experiments on multiple datasets demonstrate that TSA outperforms existing methods and exhibits robustness across various levels of heterogeneity. The code is available at https://github.com/ZhangJiayuan-BUAA/FedTSA.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enabling+Collaborative+Test-Time+Adaptation+in+Dynamic+Environment+via+Federated+Learning)|0|
|[Topology-aware Embedding Memory for Continual Learning on Expanding Networks](https://doi.org/10.1145/3637528.3671732)|Xikun Zhang, Dongjin Song, Yixin Chen, Dacheng Tao|The University of Sydney, Sydney, NSW, Australia; Washington University, Saint Louis, St. Louis, MO, USA; University of Connecticut, Storrs, CT, USA|Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data. Directly applying them to continually expanding networks, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures. To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework,i.e., Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed framework not only reduces the memory space complexity from O (ndL) to O (n)1: memory budget, d: average node degree, L: the radius of the GNN receptive field, but also fully utilizes the topological information for memory replay. Specifically, PDGNNs decouple trainable parameters from the computation ego-subnetwork viaTopology-aware Embeddings (TEs), which compress ego-subnetworks into compact vectors (i.e., TEs) to reduce the memory consumption. Based on this framework, we discover a unique pseudo-training effect in continual learning on expanding networks and this effect motivates us to develop a novel coverage maximization sampling strategy that can enhance the performance with a tight memory budget. Thorough empirical studies demonstrate that, by tackling the memory explosion problem and incorporating topological information into memory replay, PDGNNs with TEM significantly outperform state-of-the-art techniques, especially in the challenging class-incremental setting.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topology-aware+Embedding+Memory+for+Continual+Learning+on+Expanding+Networks)|0|
|[Urban-Focused Multi-Task Offline Reinforcement Learning with Contrastive Data Sharing](https://doi.org/10.1145/3637528.3671823)|Xinbo Zhao, Yingxue Zhang, Xin Zhang, Yu Yang, Yiqun Xie, Yanhua Li, Jun Luo|Binghamton University, Binghamton, NY, USA; Logistics and Supply Chain MultiTech R&D Centre, Hong Kong, Hong Kong; University of Maryland, College Park, College Park, MD, USA; Lehigh University, Bethlehem, PA, USA; Worcester Polytechnic Institute, Worcester, MA, USA; San Diego State University, San Diego, CA, USA|Enhancing diverse human decision-making processes in an urban environment is a critical issue across various applications, including ride-sharing vehicle dispatching, public transportation management, and autonomous driving. Offline reinforcement learning (RL) is a promising approach to learn and optimize human urban strategies (or policies) from pre-collected human-generated spatial-temporal urban data. However, standard offline RL faces two significant challenges: (1) data scarcity and data heterogeneity, and (2) distributional shift. In this paper, we introduce MODA - a Multi-Task Offline Reinforcement Learning with Contrastive Data Sharing approach. MODA addresses the challenges of data scarcity and heterogeneity in a multi-task urban setting through Contrastive Data Sharing among tasks. This technique involves extracting latent representations of human behaviors by contrasting positive and negative data pairs. It then shares data presenting similar representations with the target task, facilitating data augmentation for each task. Moreover, MODA develops a novel model-based multi-task offline RL algorithm. This algorithm constructs a robust Markov Decision Process (MDP) by integrating a dynamics model with a Generative Adversarial Network (GAN). Once the robust MDP is established, any online RL or planning algorithm can be applied. Extensive experiments conducted in a real-world multi-task urban setting validate the effectiveness of MODA. The results demonstrate that MODA exhibits significant improvements compared to state-of-the-art baselines, showcasing its capability in advancing urban decision-making processes. We also made our code available to the research community.|在城市环境中增强多样化的人类决策过程是一个跨越多种应用的关键问题，包括拼车调度、公共交通管理和自主驾驶。离线强化学习是从预先收集的人类生成的时空城市数据中学习和优化人类城市策略(或政策)的一种很有前途的方法。然而，标准的离线 RL 面临两个重大挑战: (1)数据稀缺性和数据异构性，以及(2)分布式转移。这篇文章介绍了 MODA-一个基于对比数据共享的多任务脱机强化学习。MODA 通过任务之间的对比数据共享，解决了多任务城市环境中数据稀缺性和异质性的挑战。这种技术包括通过对比正负数据对来提取人类行为的潜在表征。然后，它与目标任务共享呈现类似表示的数据，这有助于为每个任务增强数据。此外，MODA 开发了一种新的基于模型的多任务离线 RL 算法。该算法通过将动力学模型与生成对抗网络(gAN)相结合来构建一个鲁棒的马可夫决策过程(mDP)。一旦稳健的 MDP 建立，任何在线 RL 或规划算法都可以应用。在现实世界多任务城市环境中进行的大量实验验证了 MODA 的有效性。结果表明，与最先进的基线相比，MODA 显示出显著的改进，显示了其推进城市决策进程的能力。我们还向研究团体提供了我们的代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Urban-Focused+Multi-Task+Offline+Reinforcement+Learning+with+Contrastive+Data+Sharing)|0|
|[Synthesizing Multimodal Electronic Health Records via Predictive Diffusion Models](https://doi.org/10.1145/3637528.3671836)|Yuan Zhong, Xiaochen Wang, Jiaqi Wang, Xiaokun Zhang, Yaqing Wang, Mengdi Huai, Cao Xiao, Fenglong Ma|The Pennsylvania State University, University Park, PA, USA; Iowa State University, Ames, IA, USA; Dalian University of Technology, Dalian, Liaoning, China; The Penn State University, University Park, PA, USA; Purdue University, West Lafayette, IN, USA; GE Healthcare, Seattle, WA, USA|Synthesizing electronic health records (EHR) data has become a preferredstrategy to address data scarcity, improve data quality, and model fairness inhealthcare. However, existing approaches for EHR data generation predominantlyrely on state-of-the-art generative techniques like generative adversarialnetworks, variational autoencoders, and language models. These methodstypically replicate input visits, resulting in inadequate modeling of temporaldependencies between visits and overlooking the generation of time information,a crucial element in EHR data. Moreover, their ability to learn visitrepresentations is limited due to simple linear mapping functions, thuscompromising generation quality. To address these limitations, we propose anovel EHR data generation model called EHRPD. It is a diffusion-based modeldesigned to predict the next visit based on the current one while alsoincorporating time interval estimation. To enhance generation quality anddiversity, we introduce a novel time-aware visit embedding module and apioneering predictive denoising diffusion probabilistic model (PDDPM).Additionally, we devise a predictive U-Net (PU-Net) to optimize P-DDPM.Weconduct experiments on two public datasets and evaluate EHRPD from fidelity,privacy, and utility perspectives. The experimental results demonstrate theefficacy and utility of the proposed EHRPD in addressing the aforementionedlimitations and advancing EHR data generation.|合成电子健康记录(EHR)数据已经成为解决数据稀缺性、提高数据质量和医疗保健公平性的首选策略。然而，现有的 EHR 数据生成方法主要依赖于最先进的生成技术，如生成对抗网络、变分自动编码器和语言模型。这些方法通常重复输入访问，导致访问之间的时间依赖性建模不足，并忽略了时间信息的生成，这是电子健康记录数据中的一个关键要素。此外，由于简单的线性映射函数，他们学习访问表示的能力受到限制，从而影响了生成质量。为了解决这些局限性，我们提出了一种新的 EHR 数据生成模型 EHRPD。这是一个基于扩散的模型，旨在预测下一次访问的基础上，当前的一个，同时也结合了时间间隔估计。为了提高产生的质量和多样性，我们引入了一种新的时间感知访问嵌入模块和先锋预测去噪扩散概率模型(PDDPM)。此外，我们设计了一个预测 U 网(PU-Net)来优化 P-DDPM。我们在两个公共数据集上进行实验，并从保真度、隐私和效用的角度评估 EHRPD。实验结果证明了提出的 EHRPD 在解决上述局限性和推进 EHR 数据生成方面的有效性和实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Synthesizing+Multimodal+Electronic+Health+Records+via+Predictive+Diffusion+Models)|0|
|[Generative AI in E-Commerce: What Can We Expect?](https://doi.org/10.1145/3637528.3672503)|Haixun Wang|Instacart, San Francisco, CA, USA|The impact of generative AI on e-commerce is profound. It has significantly improved the understanding of user intent and serves as a comprehensive product knowledge graph. However, the most substantial disruptions are yet to come, partic- ularly through the rise of autonomous agents. In this talk, I will outline a tentative path toward a future where e-commerce not only offers an unparalleled customer experience but also thrives in a world dominated by generative AI and autonomous agents.|生成性人工智能对电子商务的影响是深远的。它显著提高了对用户意图的理解，并作为一个全面的产品知识图。然而，最重大的破坏还没有到来，特别是通过自主代理的兴起。在这次演讲中，我将概述一条通向未来的试探性道路，在这个未来，电子商务不仅能提供无与伦比的客户体验，而且还能在一个由生成性人工智能和自主代理主导的世界中蓬勃发展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+in+E-Commerce:+What+Can+We+Expect?)|0|
|[LiRank: Industrial Large Scale Ranking Models at LinkedIn](https://doi.org/10.1145/3637528.3671561)|Fedor Borisyuk, Mingzhou Zhou, Qingquan Song, Siyu Zhu, Birjodh Tiwana, Ganesh Parameswaran, Siddharth Dangi, Lars Hertel, Qiang Charles Xiao, Xiaochen Hou, Yunbo Ouyang, Aman Gupta, Sheallika Singh, Dan Liu, Hailing Cheng, Lei Le, Jonathan Hung, Sathiya Keerthi, Ruoyan Wang, Fengyu Zhang, Mohit Kothari, Chen Zhu, Daqi Sun, Yun Dai, Xun Luan, Sirou Zhu, Zhiwei Wang, Neil Daftary, Qianqi Shen, Chengming Jiang, Haichao Wei, Maneesh Varshney, Amol Ghoting, Souvik Ghosh|LinkedIn, Mountain View, CA, USA|We present LiRank, a large-scale ranking framework at LinkedIn that brings to production state-of-the-art modeling architectures and optimization methods. We unveil several modeling improvements, including Residual DCN, which adds attention and residual connections to the famous DCNv2 architecture. We share insights into combining and tuning SOTA architectures to create a unified model, including Dense Gating, Transformers and Residual DCN. We also propose novel techniques for calibration and describe how we productionalized deep learning based explore/exploit methods. To enable effective, production-grade serving of large ranking models, we detail how to train and compress models using quantization and vocabulary compression. We provide details about the deployment setup for large-scale use cases of Feed ranking, Jobs Recommendations, and Ads click-through rate (CTR) prediction. We summarize our learnings from various A/B tests by elucidating the most effective technical approaches. These ideas have contributed to relative metrics improvements across the board at LinkedIn: +0.5% member sessions in the Feed, +1.76% qualified job applications for Jobs search and recommendations, and +4.3% for Ads CTR. We hope this work can provide practical insights and solutions for practitioners interested in leveraging large-scale deep ranking systems.|我们介绍 LiRank，一个 LinkedIn 的大规模排名框架，它带来了最先进的建模架构和优化方法。我们揭示了几个建模改进，包括残余 DCN，它为著名的 DCNv2架构增加了注意力和残余连接。我们分享了结合和调整 SOTA 架构以创建统一模型的见解，包括致密门控、变压器和剩余 DCN。我们还提出了新的校准技术，并描述了如何生产基于深度学习的探索/开发方法。为了实现大型排名模型的高效、生产级服务，我们详细介绍了如何使用量化和词汇压缩对模型进行训练和压缩。我们提供了关于 Feed 排名、工作推荐和广告点进率(ctrl)预测等大规模用例部署设置的详细信息。我们通过阐明最有效的技术方法来总结我们从各种 A/B 测试中学到的东西。这些想法促进了 LinkedIn 的相关指标的全面改善: Feed 会员增加0.5% ，工作搜索和推荐的合格工作申请增加1.76% ，广告点击率增加4.3% 。我们希望这项工作可以提供实用的见解和解决方案的从业人员有兴趣利用大规模的深入排名系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LiRank:+Industrial+Large+Scale+Ranking+Models+at+LinkedIn)|0|
|[Enhancing Multi-field B2B Cloud Solution Matching via Contrastive Pre-training](https://doi.org/10.1145/3637528.3671513)|Haonan Chen, Zhicheng Dou, Xuetong Hao, Yunhao Tao, Shiren Song, Zhenli Sheng|Renmin University of China, Beijing, China; Huawei Cloud Computing, Hangzhou, China|Cloud solutions have gained significant popularity in the technology industry as they offer a combination of services and tools to tackle specific problems. However, despite their widespread use, the task of identifying appropriate company customers for a specific target solution to the sales team of a solution provider remains a complex business problem that existing matching systems have yet to adequately address. In this work, we study the B2B solution matching problem and identify two main challenges of this scenario: (1) the modeling of complex multi-field features and (2) the limited, incomplete, and sparse transaction data. To tackle these challenges, we propose a framework CAMA, which is built with a hierarchical multi-field matching structure as its backbone and supplemented by three data augmentation strategies and a contrastive pre-training objective to compensate for the imperfections in the available data. Through extensive experiments on a real-world dataset, we demonstrate that CAMA outperforms several strong baseline matching models significantly. Furthermore, we have deployed our matching framework on a system of Huawei Cloud. Our observations indicate an improvement of about 30% compared to the previous online model in terms of Conversion Rate (CVR), which demonstrates its great business value.|云解决方案已经在技术行业中大受欢迎，因为它们提供了解决特定问题的服务和工具的组合。然而，尽管它们被广泛使用，但是为解决方案供应商的销售团队确定合适的公司客户以提供特定目标解决方案的任务仍然是一个复杂的业务问题，现有的匹配系统尚未充分解决这个问题。在这项工作中，我们研究了 B2B 解决方案匹配问题，并确定了这个场景的两个主要挑战: (1)复杂的多领域特征的建模和(2)有限的，不完整的，稀疏的事务数据。为了应对这些挑战，我们提出了一个框架 CAMA，它以层次化的多领域匹配结构为骨干，并辅以三个数据增强策略和一个对比的预训练目标来弥补现有数据中的不完善。通过对一个真实世界数据集的大量实验，我们证明了 CAMA 显著优于几个强基线匹配模型。此外，我们已经在华为云系统上部署了我们的匹配框架。我们的观察表明，在转化率(CVR)方面，与以前的在线模型相比，大约有30% 的改进，这表明了其巨大的商业价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Multi-field+B2B+Cloud+Solution+Matching+via+Contrastive+Pre-training)|0|
|[GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language Models for Adaptable Conversational Task Assistants](https://doi.org/10.1145/3637528.3671622)|Sophie Fischer, Carlos Gemmell, Niklas Tecklenburg, Iain Mackie, Federico Rossetto, Jeffrey Dalton|University of Glasgow, Glasgow, United Kingdom; University of Edinburgh, Edinburgh, United Kingdom|We tackle the challenge of building real-world multimodal assistants for complex real-world tasks. We describe the practicalities and challenges of developing and deploying GRILLBot, a leading (first and second prize winning in 2022 and 2023) system deployed in the Alexa Prize TaskBot Challenge. Building on our Open Assistant Toolkit (OAT) framework, we propose a hybrid architecture that leverages Large Language Models (LLMs) and specialised models tuned for specific subtasks requiring very low latency. OAT allows us to define when, how and which LLMs should be used in a structured and deployable manner. For knowledge-grounded question answering and live task adaptations, we show that LLM reasoning abilities over task context and world knowledge outweigh latency concerns. For dialogue state management, we implement a code generation approach and show that specialised smaller models have 84% effectiveness with 100x lower latency. Overall, we provide insights and discuss tradeoffs for deploying both traditional models and LLMs to users in complex real-world multimodal environments in the Alexa TaskBot challenge. These experiences will continue to evolve as LLMs become more capable and efficient -- fundamentally reshaping OAT and future assistant architectures.|我们应对为复杂的现实世界任务构建现实世界多式联运助手的挑战。我们描述了开发和部署 GRILLBot 的实用性和挑战性，这是一个在 Alexa Prize TaskBot 挑战赛中部署的领先(2022年和2023年获得一等奖和二等奖)系统。在我们的 Open Assistant Toolkit (OAT)框架的基础上，我们提出了一种混合体系结构，它利用大语言模型(LLM)和针对需要非常低延迟的特定子任务调优的专门模型。OAT 允许我们定义何时、如何以及以结构化和可部署的方式使用哪些 LLM。对于基于知识的问题回答和实时任务适应，我们表明 LLM 在任务上下文和世界知识上的推理能力大于对延迟的关注。对于对话状态管理，我们实现了一个代码生成方法，并显示专门的小型模型具有84% 的有效性，延迟减少了100倍。总的来说，我们在 Alexa TaskBot 挑战中为复杂的现实世界多通道环境中的用户部署传统模型和 LLM 提供了见解并讨论了折衷方案。随着 LLM 变得更加有能力和高效，这些经验将继续发展——从根本上重塑 OAT 和未来的助理架构。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GRILLBot+In+Practice:+Lessons+and+Tradeoffs+Deploying+Large+Language+Models+for+Adaptable+Conversational+Task+Assistants)|0|
|[Enhancing E-commerce Spelling Correction with Fine-Tuned Transformer Models](https://doi.org/10.1145/3637528.3671625)|Arnab Dutta, Gleb Polushin, Xiaoshuang Zhang, Daniel Stein|eBay Inc., Shanghai, China; eBay GmbH, Aachen, Germany; eBay GmbH, Dreilinden, Germany|In the realm of e-commerce, the process of search stands as the primary point of interaction for users, wielding a profound influence on the platform's revenue generation. Notably, spelling correction assumes a pivotal role in shaping the user's search experience by rectifying erroneous query inputs, thus facilitating more accurate retrieval outcomes. Within the scope of this research paper, our aim is to enhance the existing state-of-the-art discriminative model performance with generative modelling strategies while concurrently addressing the engineering concerns associated with real-time online latency, inherent to models of this category. We endeavor to refine LSTM-based classification models for spelling correction through a generative fine-tuning approach hinged upon pre-trained language models. Our comprehensive offline assessments have yielded compelling results, showcasing that transformer-based architectures, such as BART (developed by Facebook) and T5 (a product of Google), have achieved a 4% enhancement in F1 score compared to baseline models for the English language sites. Furthermore, to mitigate the challenges posed by latency, we have incorporated model pruning techniques like no-teacher distillation. We have undertaken the deployment of our model (English only) as an A/B test candidate for real-time e-commerce traffic, encompassing customers from the US and the UK. The model attest to a 100% successful request service rate within real-time scenarios, with median, 90th percentile, and 99th percentile (p90/p99) latencies comfortably falling below production service level agreements. Notably, these achievements are further reinforced by positive customer engagement, transactional and search page metrics, including a significant reduction in instances of search results page with low or almost zero recall. Moreover, we have also extended our efforts into fine-tuning a multilingual model, which, notably, exhibits substantial accuracy enhancements, amounting to a minimum of 16%, across four distinct European languages and English.|在电子商务领域，搜索过程是用户交互的主要点，对平台的收入产生深远的影响。值得注意的是，拼写纠正通过纠正错误的查询输入，在塑造用户的搜索体验方面扮演着关键的角色，从而促进更准确的检索结果。在这篇研究论文的范围内，我们的目标是通过生成建模策略来提高现有的最先进的判别模型性能，同时解决与这类模型固有的实时在线延迟相关的工程问题。我们致力于完善基于 LSTM 的拼写校正分类模型，通过一种基于预训练语言模型的生成式微调方法。我们全面的离线评估已经产生了引人注目的结果，表明基于转换器的架构，如 BART (由 Facebook 开发)和 T5(谷歌的产品) ，与英语网站的基线模型相比，F1得分提高了4% 。此外，为了缓解延迟带来的挑战，我们已经采用了模型修剪技术，如非教师精馏。我们已经开始部署我们的模型(只有英语)作为一个 A/B 测试的实时电子商务流量的候选人，包括来自美国和英国的客户。该模型证明了在实时场景中100% 的成功请求服务率，中位数，第90百分位数和第99百分位数(p90/p99)延迟轻松地低于生产服务水平协议。值得注意的是，这些成就进一步得到了积极的客户参与度、交易和搜索页面指标的加强，包括搜索结果页面实例的显著减少，这些实例的召回率很低或几乎为零。此外，我们还将努力扩展到对多语言模型进行微调，特别是在四种不同的欧洲语言和英语之间，该模型显示出大幅度的准确性增强，最低达到16% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+E-commerce+Spelling+Correction+with+Fine-Tuned+Transformer+Models)|0|
|[Personalised Drug Identifier for Cancer Treatment with Transformers using Auxiliary Information](https://doi.org/10.1145/3637528.3671652)|Aishwarya Jayagopal, Hansheng Xue, Ziyang He, Robert J. Walsh, Krishna Kumar Hariprasannan, David Shao Peng Tan, Tuan Zea Tan, Jason J. Pitt, Anand D. Jeyasekharan, Vaibhav Rajan|National University of Singapore, Singapore, Singapore; Cancer Science Institute of Singapore, Singapore, Singapore; National University Cancer Institute, Singapore, Singapore|Cancer remains a global challenge due to its growing clinical and economic burden. Its uniquely personal manifestation, which makes treatment difficult, has fuelled the quest for personalized treatment strategies. Thus, genomic profiling is increasingly becoming part of clinical diagnostic panels. Effective use of such panels requires accurate drug response prediction (DRP) models, which are challenging to build due to limited labelled patient data. Previous methods to address this problem have used various forms of transfer learning. However, they do not explicitly model the variable length sequential structure of the list of mutations in such diagnostic panels. Further, they do not utilize auxiliary information (like patient survival) for model training. We address these limitations through a novel transformer-based method, which surpasses the performance of state-of-the-art DRP models on benchmark data. Code for our method is available at https://github.com/CDAL-SOC/PREDICT-AI. We also present the design of a treatment recommendation system (TRS), which is currently deployed at the National University Hospital, Singapore and is being evaluated in a clinical trial. We discuss why the recommended drugs and their predicted scores alone, obtained from DRP models, are insufficient for treatment planning. Treatment planning for complex cancer cases, in the face of limited clinical validation, requires assessment of many other factors, including several indirect sources of evidence on drug efficacy. We discuss key lessons learnt on model validation and use of indirect supporting evidence to build clinicians' trust and aid their decision making.|癌症由于其日益增长的临床和经济负担，仍然是一个全球性的挑战。它独特的个人表现使得治疗变得困难，也促进了对个性化治疗策略的探索。因此，基因组图谱正日益成为临床诊断小组的一部分。有效使用这些小组需要准确的药物反应预测(DRP)模型，这是具有挑战性的建立由于有限的标记患者数据。以往解决这一问题的方法都采用了各种形式的迁移学习。然而，他们没有明确地模拟这些诊断小组中突变列表的可变长度顺序结构。此外，他们不利用辅助信息(如患者生存)的模型训练。我们通过一种新的基于变压器的方法来解决这些局限性，该方法在基准数据上的性能超过了最先进的 DRP 模型。我们方法的代码可在 https://github.com/cdal-soc/predict-ai 下载。我们还介绍了一个治疗推荐系统(TRS)的设计，该系统目前部署在新加坡国立大学医院，正在进行临床试验评估。我们讨论为什么推荐的药物和他们的预测评分单独从 DRP 模型获得，不足以进行治疗计划。复杂癌症病例的治疗计划，面对有限的临床验证，需要评估许多其他因素，包括药物疗效的几个间接证据来源。我们讨论在模型验证和使用间接支持证据建立临床医生的信任和帮助他们的决策的关键经验教训。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalised+Drug+Identifier+for+Cancer+Treatment+with+Transformers+using+Auxiliary+Information)|0|
|[ERASE: Benchmarking Feature Selection Methods for Deep Recommender Systems](https://doi.org/10.1145/3637528.3671571)|Pengyue Jia, Yejing Wang, Zhaocheng Du, Xiangyu Zhao, Yichao Wang, Bo Chen, Wanyu Wang, Huifeng Guo, Ruiming Tang|City University of Hong Kong, Hong Kong, China; Huawei Noah's Ark Lab, Shenzhen, China|Deep Recommender Systems (DRS) are increasingly dependent on a large number of feature fields for more precise recommendations. Effective feature selection methods are consequently becoming critical for further enhancing the accuracy and optimizing storage efficiencies to align with the deployment demands. This research area, particularly in the context of DRS, is nascent and faces three core challenges. Firstly, variant experimental setups across research papers often yield unfair comparisons, obscuring practical insights. Secondly, the existing literature's lack of detailed analysis on selection attributes, based on large-scale datasets and a thorough comparison among selection techniques and DRS backbones, restricts the generalizability of findings and impedes deployment on DRS. Lastly, research often focuses on comparing the peak performance achievable by feature selection methods. This approach is typically computationally infeasible for identifying the optimal hyperparameters and overlooks evaluating the robustness and stability of these methods. To bridge these gaps, this paper presents ERASE, a comprehensive bEnchmaRk for feAture SElection for DRS. ERASE comprises a thorough evaluation of eleven feature selection methods, covering both traditional and deep learning approaches, across four public datasets, private industrial datasets, and a real-world commercial platform, achieving significant enhancement. Our code is available online for ease of reproduction.|深度推荐系统(DRS)越来越依赖于大量的特征字段以获得更精确的推荐。因此，有效的特征选择方法对于进一步提高准确性和优化存储效率以满足部署需求变得至关重要。这一研究领域，特别是在 DRS 的背景下，还处于起步阶段，面临着三个核心挑战。首先，不同研究论文的不同实验设置往往产生不公平的比较，模糊了实践的洞察力。其次，现有文献缺乏对选择属性的详细分析，基于大规模的数据集，对选择技术和 DRS 骨干进行了深入的比较，限制了研究结果的普遍性，阻碍了 DRS 的部署。这种方法通常是计算不可行的，以确定最佳的超参数和忽略评估这些方法的稳健性和稳定性。为了弥补这些差距，本文提出了 ERASE，一个全面的 bEnchmaRk 特征选择为 DRS ERASE 包括十一个特征选择方法的彻底评估，涵盖传统和深度学习方法，四个公共数据集，私人工业数据集和一个真实世界的商业平台，实现了显着的增强。我们的代码可以在线复制。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ERASE:+Benchmarking+Feature+Selection+Methods+for+Deep+Recommender+Systems)|0|
|[Beyond Binary Preference: Leveraging Bayesian Approaches for Joint Optimization of Ranking and Calibration](https://doi.org/10.1145/3637528.3671577)|Chang Liu, Qiwei Wang, Wenqing Lin, Yue Ding, Hongtao Lu|Shanghai Jiao Tong University, Shanghai, China; Tencent, Shenzhen, China|Predicting click-through rate (CTR) is a critical task in recommendation systems, where the models are optimized with pointwise loss to infer the probability of items being clicked. In industrial practice, applications also require ranking items based on these probabilities. Existing solutions primarily combine the ranking-based loss, i.e., pairwise and listwise loss, with CTR prediction. However, they can hardly calibrate or generalize well in CTR scenarios where the clicks reflect the binary preference. This is because the binary click feedback leads to a large number of ties, which renders high data sparsity. In this paper, we propose an effective data augmentation strategy, named Beyond Binary Preference (BBP) training framework, to address this problem. Our key idea is to break the ties by leveraging Bayesian approaches, where the beta distribution models click behavior as probability distributions in the training data that naturally break ties. Therefore, we can obtain an auxiliary training label that generates more comparable pairs and improves the ranking performance. Besides, BBP formulates ranking and calibration as a multi-task framework to optimize both objectives simultaneously. Through extensive offline experiments and online tests on various datasets, we demonstrate that BBP significantly outperforms state-of-the-art methods in both ranking and calibration capabilities, showcasing its effectiveness in addressing the limitations of existing methods. Our code is available at https://github.com/AlvinIsonomia/BBP.|在推荐系统中，预测点进率(ctrl)是一项关键的任务，模型通过逐点丢失的方式进行优化，以推断项目被点击的概率。在工业实践中，应用程序还需要根据这些概率对项目进行排序。现有的解决方案主要结合了基于排名的损失，即成对损失和列表损失，以及 CTR 预测。然而，在点击反映二进制偏好的 CTR 场景中，它们很难校准或推广。这是因为二进制单击反馈会导致大量关联，从而导致高数据稀疏性。针对这一问题，本文提出了一种有效的数据增强策略——超越二进制偏好(Beyond Binary Preferences，BBP)训练框架。我们的主要想法是通过利用贝叶斯方法来打破这种联系，在贝叶斯方法中，Β分布模型将行为作为训练数据中的概率分布来点击，从而自然地打破联系。因此，我们可以得到一个辅助训练标签，生成更多的可比对，提高排序性能。此外，BBP 作为一个多任务框架制定排序和校准，以优化两个目标同时进行。通过大量的离线实验和对各种数据集的在线测试，我们证明了 BBP 在排序和校准能力方面显著优于最先进的方法，展示了它在解决现有方法的局限性方面的有效性。我们的代码可以在 https://github.com/alvinisonomia/bbp 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Binary+Preference:+Leveraging+Bayesian+Approaches+for+Joint+Optimization+of+Ranking+and+Calibration)|0|
|[Optimizing Novelty of Top-k Recommendations using Large Language Models and Reinforcement Learning](https://doi.org/10.1145/3637528.3671618)|Amit Sharma, Hua Li, Xue Li, Jian Jiao|Microsoft Research, Bengaluru, India; Microsoft Bing Ads, Redmond, USA; Microsoft Bing Ads, Mountain View, USA|Given an input query, a recommendation model is trained using user feedback data (e.g., click data) to output a ranked list of items. In real-world systems, besides accuracy, an important consideration for a new model is novelty of its top-k recommendations w.r.t. an existing deployed model. However, novelty of top-k items is a difficult goal to optimize a model for, since it involves a non-differentiable sorting operation on the model's predictions. Moreover, novel items, by definition, do not have any user feedback data. Given the semantic capabilities of large language models, we address these problems using a reinforcement learning (RL) formulation where large language models provide feedback for the novel items. However, given millions of candidate items, the sample complexity of a standard RL algorithm can be prohibitively high. To reduce sample complexity, we reduce the top-k list reward to a set of item-wise rewards and reformulate the state space to consist of tuples such that the action space is reduced to a binary decision; and show that this reformulation results in a significantly lower complexity when the number of items is large. We evaluate the proposed algorithm on improving novelty for a query-ad recommendation task on a large-scale search engine. Compared to supervised finetuning on recent pairs, the proposed RL-based algorithm leads to significant novelty gains with minimal loss in recall. We obtain similar results on the ORCAS query-webpage matching dataset and a product recommendation dataset based on Amazon reviews.|给定一个输入查询，使用用户反馈数据(例如，单击数据)来训练推荐模型，以输出一个排序的项目列表。在现实世界的系统中，除了准确性之外，新模型的一个重要考虑因素是它的 top-k 推荐 W.r.t. (现有的部署模型)的新颖性。然而，前 k 项的新颖性是一个很难优化模型的目标，因为它涉及到对模型预测的不可微排序操作。此外，根据定义，新项目没有任何用户反馈数据。考虑到大型语言模型的语义能力，我们使用强化学习(RL)公式来解决这些问题，其中大型语言模型为新项目提供反馈。然而，给定数百万个候选项，标准 RL 算法的样本复杂度可能高得令人望而却步。为了降低样本复杂度，我们将 top-k 列表奖励减少为一组项目奖励，并将状态空间重新表述为由元组组成的状态空间，从而将操作空间减少为二进制决策; 结果表明，当项目数量较大时，这种重新表述显著降低了复杂度。针对大规模搜索引擎中的查询广告推荐任务，评估了该算法的新颖性。与最近对的监督微调相比，本文提出的基于 RL 的算法在召回损失最小的情况下获得了显著的新颖性增益。在 ORCAS 查询-网页匹配数据集和基于 Amazon 评论的产品推荐数据集上，我们得到了类似的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Novelty+of+Top-k+Recommendations+using+Large+Language+Models+and+Reinforcement+Learning)|0|
|[Measuring an LLM's Proficiency at using APIs: A Query Generation Strategy](https://doi.org/10.1145/3637528.3671592)|Ying Sheng, Sudeep Gandhe, Bhargav Kanagal, Nick Edmonds, Zachary Fisher, Sandeep Tata, Aarush Selvan|Google, Mountain View, CA, USA; Google Research, Mountain View, CA, USA|Connecting Large Language Models (LLMs) with the ability to leverage APIs (Web Search, Charting, Calculators, Calendar, Flight Search, Hotel Search, Data Lookup, etc. ) is likely to allow us to solve a variety of new hard problems. Several research efforts have made this observation and suggested recipes for LLMs to emit API calls, and proposed mechanisms by which they can generate additional text conditioned on the output for the API call. However, in practice, the focus has been on relatively simple slot-filling tasks that make an API call rather unlocking novel capabilities by combining different tools, reasoning over the response from a tool, making multiple invocations, or complex planning. In this paper, we pose the following question: what does it mean to say that an LLM is proficient at using a set of APIs? We answer this question in the context of structured APIs by defining seven capabilities for API-use. We provide an approach for generating synthetic tasks that exercise each of these capabilities given only the description of an API. We argue that this provides practitioners with a principled way to construct a dataset to evaluate an LLM's ability to use a given set of APIs. Through human evaluations, we show that our approach produces high-quality tasks for each of the seven capabilities. We also describe how we used this approach to on-board new API and create principled evaluation sets for multiple LLM-based products.|将大型语言模型(LLM)与能够利用 API (网络搜索、制图、计算器、日历、航班搜索、酒店搜索、数据查询等)联系起来，可能会让我们解决各种新的难题。一些研究工作已经做出了这样的观察，并提出了 LLM 发出 API 调用的方法，以及提出了一些机制，通过这些机制，LLM 可以根据 API 调用的输出生成额外的文本。然而，在实践中，重点一直放在相对简单的插槽填充任务上，这些任务通过组合不同的工具、对工具的响应进行推理、进行多次调用或复杂的计划，使 API 调用相当于解锁新功能。在本文中，我们提出以下问题: 说 LLM 精通使用一组 API 意味着什么？我们在结构化 API 的上下文中通过定义七种 API 使用功能来回答这个问题。我们提供了一种生成综合任务的方法，这些任务只需要对 API 进行描述，就可以实现这些功能中的每一个。我们认为，这为从业者提供了一种原则性的方法来构建数据集，以评估 LLM 使用给定 API 集的能力。通过人工评估，我们表明我们的方法为七种能力中的每一种都产生了高质量的任务。我们还描述了如何使用这种方法来开发新的 API，以及如何为多个基于 LLM 的产品创建原则性评估集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+an+LLM's+Proficiency+at+using+APIs:+A+Query+Generation+Strategy)|0|
|[PEMBOT: Pareto-Ensembled Multi-task Boosted Trees](https://doi.org/10.1145/3637528.3671619)|Gokul Swamy, Anoop Saladi, Arunita Das, Shobhit Niranjan|Amazon, Bengaluru, KA, India; Amazon, Seattle, WA, USA|Multi-task problems frequently arise in machine learning when there are multiple target variables, which share a common synergy while being sufficiently different that optimizing on any of the task does not necessarily imply an optimum for the others. In this work, we develop PEMBOT, a novel Pareto-based multi-task classification framework using a gradient boosted tree architecture. The proposed methodology involves a) generating multiple instances of Pareto optimal trees, b) diverse subset selection using a determinantal point process (DPP) model, and c) ensembling of diverse Pareto optimal trees to yield the final output. We tested our framework on a problem from an e-commerce domain wherein the task is to predict at order placement time the different adverse scenarios in the order shipment journey such as the package getting lost or damaged during shipment. This model enables us to take preemptive measures to prevent these scenarios from happening resulting in significant operational cost savings. Further, to show the generality of our approach, we demonstrate the performance of our algorithm on a publicly available wine quality prediction dataset and compare against state-of-the-art baselines.|多任务问题经常出现在机器学习时，有多个目标变量，共享一个共同的协同作用，同时是充分不同的，优化任何一个任务并不一定意味着最优的其他。在这项工作中，我们开发 PEMBOT，一个新颖的基于 Pareto 的多任务分类框架使用梯度增强树结构。提出的方法包括 a)生成多个帕累托最优树的实例，b)使用行列式点过程(DPP)模型进行多样化的子集选择，以及 c)将不同的帕累托最优树集合起来以产生最终的输出。我们测试了我们的框架从一个电子商务领域的问题，其中的任务是预测在订单放置时间不同的不利情况下的订单装运旅程，如包裹丢失或损坏在装运期间。该模型使我们能够采取先发制人的措施，防止这些情况发生，从而大大节省运营成本。此外，为了展示我们方法的通用性，我们在一个公开的葡萄酒质量预测数据集上演示了我们算法的性能，并与最先进的基线进行了比较。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PEMBOT:+Pareto-Ensembled+Multi-task+Boosted+Trees)|0|
|[Enhancing Personalized Headline Generation via Offline Goal-conditioned Reinforcement Learning with Large Language Models](https://doi.org/10.1145/3637528.3671638)|Xiaoyu Tan, Leijun Cheng, Xihe Qiu, Shaojie Shi, Yuan Cheng, Wei Chu, Yinghui Xu, Yuan Qi|; INF Technology (Shanghai) Co., Ltd., Shanghai, China; AI3 Institute, Fudan University, Shanghai, China|Recently, significant advancements have been made in Large Language Models (LLMs) through the implementation of various alignment techniques. These techniques enable LLMs to generate highly tailored content in response to diverse user instructions. Consequently, LLMs have the potential to serve as robust, customizable recommendation systems in the field of content recommendation. However, using LLMs with user individual information and online exploration remains a challenge, which are important perspectives in developing personalized news headline generation algorithms. In this paper, we propose a novel framework to generate personalized news headlines using LLMs with extensive online exploration. The proposed approach involves initially training an offline goal-conditioned policy using supervised learning. Subsequently, online exploration is employed to collect new data for the next training iteration. Results from simulations, experiments, and real-word scenario demonstrate that our framework achieves outstanding performance on established benchmarks and can effectively generate personalized headlines under different reward settings. By treating the LLM as a goal-conditioned agent, the model can perform online exploration by modifying the goals without frequently retraining the model. To the best of our knowledge, this work represents the first investigation into the capability of LLMs to generate customized news headlines with goal-conditioned reinforcement learning via supervised learning within LLMs.|最近，通过实现各种对齐技术，大型语言模型(LLM)取得了重大进展。这些技术使 LLM 能够根据不同的用户指令生成高度定制的内容。因此，LLM 有可能成为内容推荐领域中健壮的、可定制的推荐系统。然而，利用具有用户个人信息和在线探索的 LLM 仍然是一个挑战，这是开发个性化新闻标题生成算法的重要视角。在本文中，我们提出了一个新的框架来生成个性化的新闻标题使用 LLM 广泛的在线探索。拟议中的方法包括最初使用监督式学习训练一种离线的以目标为条件的政策。随后，采用在线探索的方法为下一次训练迭代收集新的数据。模拟、实验和真实场景的结果表明，我们的框架在已建立的基准上取得了出色的性能，并且能够在不同的奖励设置下有效地生成个性化的标题。通过将 LLM 视为目标条件智能体，该模型可以通过修改目标进行在线探索，而无需频繁地对模型进行再训练。据我们所知，这项工作代表了首次调查的能力，生成定制的新闻标题与目标条件的强化学习通过监督式学习内部 LLM。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Personalized+Headline+Generation+via+Offline+Goal-conditioned+Reinforcement+Learning+with+Large+Language+Models)|0|
|[Future Impact Decomposition in Request-level Recommendations](https://doi.org/10.1145/3637528.3671506)|Xiaobei Wang, Shuchang Liu, Xueliang Wang, Qingpeng Cai, Lantao Hu, Han Li, Peng Jiang, Kun Gai, Guangming Xie|Peking University, Beijing, China; Kuaishou Technology, Beijing, China; Unaffiliated, Beijing, China|In recommender systems, reinforcement learning solutions have shown promisingresults in optimizing the interaction sequence between users and the systemover the long-term performance. For practical reasons, the policy's actions aretypically designed as recommending a list of items to handle users' frequentand continuous browsing requests more efficiently. In this list-wiserecommendation scenario, the user state is updated upon every request in thecorresponding MDP formulation. However, this request-level formulation isessentially inconsistent with the user's item-level behavior. In this study, wedemonstrate that an item-level optimization approach can better utilize itemcharacteristics and optimize the policy's performance even under therequest-level MDP. We support this claim by comparing the performance ofstandard request-level methods with the proposed item-level actor-criticframework in both simulation and online experiments. Furthermore, we show thata reward-based future decomposition strategy can better express the item-wisefuture impact and improve the recommendation accuracy in the long term. Toachieve a more thorough understanding of the decomposition strategy, we proposea model-based re-weighting framework with adversarial learning that furtherboost the performance and investigate its correlation with the reward-basedstrategy.|在推荐系统中，强化学习解决方案在优化用户与系统之间的交互顺序方面取得了令人满意的效果。出于实际原因，该策略的行动通常被设计为推荐一个项目列表，以更有效地处理用户频繁和连续的浏览请求。在这个列表-智能推荐场景中，用户状态会根据相应 MDP 公式中的每个请求进行更新。但是，这个请求级别的公式与用户的项目级别行为本质上是不一致的。研究表明，即使在请求级 MDP 下，项目级优化方法也能更好地利用项目特征，优化策略性能。我们通过比较标准请求级方法和提出的项目级参与者批评框架在模拟和在线实验中的性能来支持这一说法。进一步，我们发现基于奖励的未来分解策略能够更好地表达项目对未来的影响，从长远来看能够提高推荐的准确性。为了更深入地理解分解策略，我们提出了基于模型的对抗性学习重新加权框架，进一步提高绩效，并研究其与奖励策略的相关性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Future+Impact+Decomposition+in+Request-level+Recommendations)|0|
|[A Self-boosted Framework for Calibrated Ranking](https://doi.org/10.1145/3637528.3671570)|Shunyu Zhang, Hu Liu, Wentian Bao, Enyun Yu, Yang Song|Northeasten University, Beijing, China; Columbia University, Beijing, China; Kuaishou Technology, Beijing, China|Scale-calibrated ranking systems are ubiquitous in real-world applications nowadays, which pursue accurate ranking quality and calibrated probabilistic predictions simultaneously. For instance, in the advertising ranking system, the predicted click-through rate (CTR) is utilized for ranking and required to be calibrated for the downstream cost-per-click ads bidding. Recently, multi-objective based methods have been wildly adopted as a standard approach for Calibrated Ranking, which incorporates the combination of two loss functions: a pointwise loss that focuses on calibrated absolute values and a ranking loss that emphasizes relative orderings. However, when applied to industrial online applications, existing multi-objective CR approaches still suffer from two crucial limitations First, previous methods need to aggregate the full candidate list within a single mini-batch to compute the ranking loss. Such aggregation strategy violates extensive data shuffling which has long been proven beneficial for preventing overfitting, and thus degrades the training effectiveness. Second, existing multi-objective methods apply the two inherently conflicting loss functions on a single probabilistic prediction, which results in a sub-optimal trade-off between calibration and ranking. To tackle the two limitations, we propose a Self-Boosted framework for Calibrated Ranking (SBCR). In SBCR, the predicted ranking scores by the online deployed model are dumped into context features. With these additional context features, each single item can perceive the overall distribution of scores in the whole ranking list, so that the ranking loss can be constructed without the need for sample aggregation. As the deployed model is a few versions older than the training model, the dumped predictions reveal what was failed to learn and keep boosting the model to correct previously mis-predicted items. Moreover, a calibration module is introduced to decouple the point loss and ranking loss. The two losses are applied before and after the calibration module separately, which elegantly addresses the sub-optimal trade-off problem. We conduct comprehensive experiments on industrial scale datasets and online A/B tests, demonstrating that SBCR can achieve advanced performance on both calibration and ranking. Our method has been deployed on the video search system of Kuaishou, and results in significant performance improvements on CTR and the total amount of time users spend on Kuaishou.|标度校准的排序系统在现实世界的应用中是普遍存在的，它追求准确的排序质量和校准的概率预测同时进行。例如，在广告排名系统中，预测点进率(ctrl)被用于排名，并且需要根据下游按点击次数计费的广告投标进行校准。最近，基于多目标的方法已被广泛采用作为标准方法校准排名，其中包括两个损失函数的组合: 点态损失的重点是校准绝对值和排名损失的重点是相对排序。然而，现有的多目标 CR 方法在应用于工业在线应用时，仍然存在两个关键的局限性。首先，以前的方法需要在一个小批量内聚合完整的候选名单来计算排名损失。这种聚合策略违反了长期以来被证明有利于防止过拟合的广泛的数据重组策略，从而降低了训练效率。其次，现有的多目标方法将两个内在冲突的损失函数应用于单一的概率预测，导致校准和排序之间的次优平衡。为了解决这两个限制，我们提出了一个自我增强的校准排名(SBCR)框架。在 SBCR，通过在线部署模型预测的排名分数被转化为上下文特征。通过这些附加的上下文特征，每个单独的项目可以感知整个排名列表中分数的总体分布，从而不需要样本聚合就可以构造出排名损失。由于部署的模型比训练模型旧了几个版本，倾销预测揭示了未能学习的内容，并不断提升模型以纠正先前错误预测的项目。同时，引入了一个标定模块，实现了点损和等级损的解耦。这两种损耗分别应用于校准模块之前和之后，从而巧妙地解决了次优折衷问题。我们对工业规模的数据集和在线 A/B 测试进行了全面的实验，结果表明 SBCR 在校准和排序方面都具有较高的性能。我们的方法已经应用于 Kuaishou 的视频搜索系统，在点击率和用户在 Kuaishou 花费的总时间方面取得了显著的性能改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Self-boosted+Framework+for+Calibrated+Ranking)|0|
|[Bringing Multimodality to Amazon Visual Search System](https://doi.org/10.1145/3637528.3671640)|Xinliang Zhu, ShengWei Huang, Han Ding, Jinyu Yang, Kelvin Chen, Tao Zhou, Tal Neiman, Ouye Xie, Son Tran, Benjamin Z. Yao, Douglas Gray, Anuj Bindal, Arnab Dhua|Amazon.com, Seattle, WA, USA; Amazon.com, New York, New York, USA; Amazon.com, Santa Clara, CA, USA; Amazon.com, Palo Alto, CA, USA|Image to image matching has been well studied in the computer vision community. Previous studies mainly focus on training a deep metric learning model matching visual patterns between the query image and gallery images. In this study, we show that pure image-to- image matching suffers from false positives caused by matching to local visual patterns. To alleviate this issue, we propose to leverage recent advances in vision-language pretraining research. Specifically, we introduce additional image-text alignment losses into deep metric learning, which serve as constraints to the image-to-image matching loss. With additional alignments between the text (e.g., product title) and image pairs, the model can learn concepts from both modalities explicitly, which avoids matching low-level visual features. We progressively develop two variants, a 3-tower and a 4-tower model, where the latter takes one more short text query input. Through extensive experiments, we show that this change leads to a substantial improvement to the image to image matching problem. We further leveraged this model for multimodal search, which takes both image and reformulation text queries to improve search quality. Both offline and online experiments show strong improvements on the main metrics. Specifically, we see 4.95% relative improvement on image matching click through rate with the 3-tower model and 1.13% further improvement from the 4-tower model.|图像到图像的匹配已经在计算机视觉领域得到了很好的研究。以往的研究主要集中在训练一个匹配查询图像和画廊图像视觉模式的深度度量学习模型。在本研究中，我们发现纯粹的图像对图像的匹配会受到局部视觉模式匹配所引起的假阳性的影响。为了缓解这一问题，我们建议利用视觉语言预训研究的最新进展。具体地说，我们在深度度量学习中引入了额外的图像-文本对齐损失，作为图像-图像匹配损失的约束条件。通过在文本(例如，产品标题)和图像对之间进行额外的对齐，模型可以显式地从两种模式中学习概念，从而避免匹配低层次的视觉特征。我们逐步开发了两个变体，一个3塔模型和一个4塔模型，后者需要更多的短文本查询输入。通过大量的实验，我们发现这种改变使得图像到图像的匹配问题得到了实质性的改善。我们进一步利用该模型进行多模态搜索，该模型同时采用图像查询和重构文本查询来提高搜索质量。离线和在线实验都显示了主要指标的强大改进。具体来说，我们发现三塔模型的图像匹配点击率相对提高了4.95% ，而四塔模型的图像匹配点击率进一步提高了1.13% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bringing+Multimodality+to+Amazon+Visual+Search+System)|0|
|[A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models](https://doi.org/10.1145/3637528.3671470)|Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, TatSeng Chua, Qing Li|The Hong Kong Polytechnic University, Hong Kong, China; Baidu Inc., Beijing, CN; National university of Singapore, Singapore, SG|As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the quality of the generated content of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: Furthermore, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at: https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/|作为人工智能中最先进的技术之一，检索增强生成(RAG)技术可以提供可靠的、最新的外部知识，为大量的任务提供巨大的方便。特别是在人工智能生成内容(AIGC)的时代，强大的检索能力提供额外的知识使 RAG 能够协助现有的生成人工智能产生高质量的输出。近年来，大语言模型(LLM)在语言理解和语言生成方面显示出了革命性的能力，但仍然面临着诸如幻觉和过时的内部知识等固有的局限性。考虑到 RAG 在提供最新和有用的辅助信息方面的强大能力，检索增强大型语言模型(RA-LLM)已经出现，以利用外部和权威的知识库，而不是仅仅依赖于模型的内部知识，以增强 LLM 生成内容的质量。在这项调查中，我们全面回顾了 RA-LLM 的现有研究，包括三个主要的技术视角: 此外，为了提供更深入的见解，我们讨论了当前的局限性和未来研究的几个有希望的方向。有关这项调查的最新资料，可浏览以下 https://advanced-recommender-systems.github.io/rag-meets-llms/ :|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Survey+on+RAG+Meeting+LLMs:+Towards+Retrieval-Augmented+Large+Language+Models)|0|
|[Multimodal Pretraining, Adaptation, and Generation for Recommendation: A Survey](https://doi.org/10.1145/3637528.3671473)|Qijiong Liu, Jieming Zhu, Yanting Yang, Quanyu Dai, Zhaocheng Du, XiaoMing Wu, Zhou Zhao, Rui Zhang, Zhenhua Dong|Huawei Noah Ark Lab, Shenzhen, China; Huawei Noah's Ark Lab, Shenzhen, China; The HK PolyU, Hong Kong, China; Huazhong University of Science and Technology & ruizhang.info, Shenzhen, China; Zhejiang University, Hangzhou, China|Personalized recommendation serves as a ubiquitous channel for users to discover information tailored to their interests. However, traditional recommendation models primarily rely on unique IDs and categorical features for user-item matching, potentially overlooking the nuanced essence of raw item contents across multiple modalities such as text, image, audio, and video. This underutilization of multimodal data poses a limitation to recommender systems, especially in multimedia services like news, music, and short-video platforms. The recent advancements in large multimodal models offer new opportunities and challenges in developing content-aware recommender systems. This survey seeks to provide a comprehensive exploration of the latest advancements and future trajectories in multimodal pretraining, adaptation, and generation techniques, as well as their applications in enhancing recommender systems. Furthermore, we discuss current open challenges and opportunities for future research in this dynamic domain. We believe that this survey, alongside the curated resources, will provide valuable insights to inspire further advancements in this evolving landscape.|个性化推荐是用户发现适合自己兴趣的信息的一个无处不在的渠道。然而，传统的推荐模型主要依赖于用户项匹配的唯一 ID 和分类特性，这可能忽略了原始项目内容在多种模式(如文本、图像、音频和视频)中的细微差别。这种多模式数据的利用率不足对推荐系统造成了限制，特别是在新闻、音乐和短视频平台等多媒体服务中。大型多模式模型的最新进展为开发内容感知的推荐系统提供了新的机遇和挑战。本调查旨在全面探讨多模式预培训、适应和生成技术的最新进展和未来发展轨迹，以及它们在加强推荐系统方面的应用。此外，我们讨论了目前在这一动态领域的开放性挑战和未来研究的机遇。我们相信，这项调查，以及策划的资源，将提供宝贵的见解，以激励在这个不断变化的景观进一步发展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Pretraining,+Adaptation,+and+Generation+for+Recommendation:+A+Survey)|0|
|[AI for Education (AI4EDU): Advancing Personalized Education with LLM and Adaptive Learning](https://doi.org/10.1145/3637528.3671498)|Qingsong Wen, Jing Liang, Carles Sierra, Rose Luckin, Richard Jiarui Tong, Zitao Liu, Peng Cui, Jiliang Tang|Jinan University, Guangzhou, China; Squirrel Ai Learning, Shanghai, China; Tsinghua University, Beijing, China; IIIA of the Spanish National Research Council, Barcelona, Spain; Squirrel Ai Learning, Bellevue, USA; Michigan State University, East Lansing, USA; University College London, London, United Kingdom|Recent advanced AI technologies, especially large language models (LLMs) like GPTs, have significantly advanced the field of data mining and led to the development of various LLM-based applications. AI for education (AI4EDU) is a vibrant multi-disciplinary field of data mining, machine learning, and education, with increasing importance and extraordinary potential. In this field, LLM and adaptive learning-based models can be utilized as interfaces in human-in-the-loop education systems, where the model serves as a mediator among the teacher, students, and machine capabilities, including its own. This perspective has several benefits, including the ability to personalize interactions, allow unprecedented flexibility and adaptivity for human-AI collaboration and improve the user experience. However, several challenges still exist, including the need for more robust and efficient algorithms, designing effective user interfaces, and ensuring ethical considerations are addressed. This workshop aims to bring together researchers and practitioners from academia and industry to explore cutting-edge AI technologies for personalized education, especially the potential of LLMs and adaptive learning technologies.|近年来，先进的人工智能技术，特别是大型语言模型(LLM) ，如 GPTs，极大地推动了数据挖掘领域的发展，并导致了各种基于 LLM 的应用程序的开发。人工智能教育(AI4EDU)是一个充满活力的多学科领域的数据挖掘，机器学习和教育，越来越重要和非凡的潜力。在这个领域，LLM 和基于自适应学习的模型可以用作人在环路教育系统的接口，在这个系统中，模型充当教师、学生和机器能力(包括它自己的能力)之间的中介。这种视角有几个好处，包括个性化交互的能力，允许前所未有的灵活性和人工智能协作的适应性，并改善用户体验。然而，仍然存在一些挑战，包括需要更加健壮和高效的算法，设计有效的用户界面，并确保道德考虑得到解决。这个工作坊旨在汇聚来自学术界和业界的研究人员和从业员，探讨尖端人工智能技术在个人化教育方面的应用，特别是 LLM 和在线机机器学习技术的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+for+Education+(AI4EDU):+Advancing+Personalized+Education+with+LLM+and+Adaptive+Learning)|0|
|[Understanding Inter-Session Intentions via Complex Logical Reasoning](https://doi.org/10.1145/3637528.3671808)|Jiaxin Bai, Chen Luo, Zheng Li, Qingyu Yin, Yangqiu Song|Amazon.com Inc, Palo Alto, USA; Department of CSE, HKUST, Hong Kong, China|Understanding user intentions is essential for improving product recommendations, navigation suggestions, and query reformulations. However, user intentions can be intricate, involving multiple sessions and attribute requirements connected by logical operators such as And, Or, and Not. For instance, a user may search for Nike or Adidas running shoes across various sessions, with a preference for purple. In another example, a user may have purchased a mattress in a previous session and is now looking for a matching bed frame without intending to buy another mattress. Existing research on session understanding has not adequately addressed making product or attribute recommendations for such complex intentions. In this paper, we present the task of logical session complex query answering (LS-CQA), where sessions are treated as hyperedges of items, and we frame the problem of complex intention understanding as an LS-CQA task on an aggregated hypergraph of sessions, items, and attributes. This is a unique complex query answering task with sessions as ordered hyperedges. We also introduce a new model, the Logical Session Graph Transformer (LSGT), which captures interactions among items across different sessions and their logical connections using a transformer structure. We analyze the expressiveness of LSGT and prove the permutation invariance of the inputs for the logical operators. By evaluating LSGT on three datasets, we demonstrate that it achieves state-of-the-art results.|理解用户的意图对于改进产品推荐、导航建议和查询重新编排至关重要。但是，用户的意图可能很复杂，涉及多个会话和属性需求，这些需求由逻辑运算符连接，例如 And、 Or 和 Not。例如，用户可能在不同的会话中搜索耐克或阿迪达斯的跑鞋，偏爱紫色。在另一个例子中，用户可能已经在前一个阶段购买了一个床垫，现在正在寻找一个匹配的床架，而无意购买另一个床垫。关于会话理解的现有研究尚未充分解决为这种复杂意图提供产品或属性建议的问题。本文提出了逻辑会话复杂查询回答(LS-CQA)任务，其中会话被视为项目的超边缘，并将复杂意图理解问题框架为会话、项目和属性聚合超图上的 LS-CQA 任务。这是一个独特的复杂查询应答任务，会话是有序的超边缘。我们还介绍了一个新模型，逻辑会话图形转换器(Logical Session Graph former，LSGT) ，它使用转换器结构捕获跨不同会话的项之间的交互及其逻辑连接。分析了 LSGT 的表达性，证明了逻辑算子输入的置换不变性。通过对三个数据集上的 LSGT 进行评估，我们证明它达到了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+Inter-Session+Intentions+via+Complex+Logical+Reasoning)|0|
|[Online Preference Weight Estimation Algorithm with Vanishing Regret for Car-Hailing in Road Network](https://doi.org/10.1145/3637528.3671664)|Yucen Gao, Zhehao Zhu, Mingqian Ma, Fei Gao, Hui Gao, Yangguang Shi, Xiaofeng Gao|Northwestern University, Evanston, IL, USA; Didi Global Inc., Beijing, China; Shanghai Jiao Tong University, Shanghai, China; Shandong University, Qingdao, China|Car-hailing services play an important role in the modern transportation system, and the utilities of the service providers highly depend on the efficiency of route planning algorithms. A widely adopted route planning framework is to assign weights to roads and compute the routes with the shortest path algorithms. Existing techniques of weight-assigning often focus on the traveling time and length of the roads, but cannot incorporate with the preferences of the passengers (users). In this paper, a set of preference weight estimation models is employed to capture the users' preferences over paths in car-hailing with their historical choices. Since the user preferences may vary dynamically over time, it is a challenging task to make real-time decisions over the models. The main technical contribution of this paper is to propose an online learning-based preference weight chasing (PWC) algorithm to solve this problem. The worst-case performance of PWC is analyzed with the metric regret, and it is proved that PWC has a vanishing regret, which means that the time-averaged loss concerning the fixed in-hindsight best model tends to zero. Experiments based on real-world datasets are conducted to verify the effectiveness and efficiency of our algorithm. The code is available at https://github.com/GaoYucen/PWC.|叫车服务在现代交通系统中占有举足轻重的地位，路径规划算法的有效性直接决定了叫车服务提供商的效用。一种广泛采用的路径规划框架是给道路赋权，并用最短路径算法计算路径。现有的权重分配技术往往侧重于道路的行驶时间和长度，但不能与乘客(用户)的偏好相结合。本文利用一组偏好权重估计模型，通过用户的历史选择来捕捉用户对叫车路径的偏好。由于用户偏好可能随时间动态变化，因此在模型上实时做出决策是一项具有挑战性的任务。本文的主要技术贡献是提出了一种基于在线学习的偏好权重追踪(PWC)算法来解决这一问题。利用度量遗憾对 PWC 的最坏情况性能进行了分析，证明了 PWC 具有消失遗憾，这意味着与固定的事后最佳模型相关的时间平均损失趋于零。基于实际数据集进行了实验，验证了算法的有效性和高效性。密码可在 https://github.com/gaoyucen/pwc 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Preference+Weight+Estimation+Algorithm+with+Vanishing+Regret+for+Car-Hailing+in+Road+Network)|0|
|[Robust Auto-Bidding Strategies for Online Advertising](https://doi.org/10.1145/3637528.3671729)|Qilong Lin, Zhenzhe Zheng, Fan Wu|Shanghai Jiao Tong University, Shanghai, China|In online advertising, existing auto-bidding strategies for bid shading mainly adopt the approach of first predicting the winning price distribution and then calculating the optimal bid. However, the winning price information available to the Demand Side Platforms (DSPs) is extremely limited, and the associated uncertainties make it challenging for DSPs to accurately estimate winning price distribution. To address this challenge, we conducted a comprehensive analysis of the process by which DSPs obtain winning price information, and abstracted two types of uncertainties from it: known uncertainty and unknown uncertainty. Based on these uncertainties, we proposed two levels of robust bidding strategies: Robust Bidding for Censorship (RBC) and Robust Bidding for Distribution Shift (RBDS), which offer guarantees for the surplus in the worst-case scenarios under uncertain conditions. Experimental results on public datasets demonstrate that our robust bidding strategies consistently enable DSPs to achieve superior surpluses, both on test sets and under worst-case conditions.|在网络广告中，现有的自动报价策略主要采用先预测中标价格分布，然后计算最优报价的方法。然而，需求侧平台(DSP)可获得的中标价格信息是极其有限的，并且相关的不确定性使得 DSP 准确估计中标价格分布具有挑战性。为了应对这一挑战，我们对 DSP 获取中标价格信息的过程进行了全面的分析，并从中提取出两类不确定性: 已知不确定性和未知不确定性。基于这些不确定性，我们提出了两个层次的鲁棒竞价策略: 鲁棒审查竞价(RBC)和鲁棒分配偏移竞价(RBDS) ，为不确定条件下最坏情况下的盈余提供保证。对公共数据集的实验结果表明，我们的稳健的投标策略始终使得 DSP 能够在测试集和最坏情况下实现优越的盈余。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Auto-Bidding+Strategies+for+Online+Advertising)|0|
|[QSketch: An Efficient Sketch for Weighted Cardinality Estimation in Streams](https://doi.org/10.1145/3637528.3671695)|Yiyan Qi, Rundong Li, Pinghui Wang, Yufang Sun, Rui Xing|International Digital Economy Academy (IDEA), Shenzhen, China; MOE KLINNS Lab, Xi'an Jiaotong University, Xi'an, China; MOE KLINNS Lab, Shaanxi Normal University, Xi'an, China|Estimating cardinality, i.e., the number of distinct elements, of a data stream is a fundamental problem in areas like databases, computer networks, and information retrieval. This study delves into a broader scenario where each element carries a positive weight. Unlike traditional cardinality estimation, limited research exists on weighted cardinality, with current methods requiring substantial memory and computational resources, challenging for devices with limited capabilities and real-time applications like anomaly detection. To address these issues, we propose QSketch, a memory-efficient sketch method for estimating weighted cardinality in streams. QSketch uses a quantization technique to condense continuous variables into a compact set of integer variables, with each variable requiring only 8 bits, making it 8 times smaller than previous methods. Furthermore, we leverage dynamic properties during QSketch generation to significantly enhance estimation accuracy and achieve a lower time complexity of O(1) for updating estimations upon encountering a new element. Experimental results on synthetic and real-world datasets show that QSketch is approximately 30% more accurate and two orders of magnitude faster than the state-of-the-art, using only 1/8 of the memory.|在数据库、计算机网络和信息检索等领域，估计数据流的基数(即不同元素的数量)是一个基本问题。这项研究深入到一个更广泛的情况下，其中每一个因素具有积极的权重。与传统的基数估计不同，对加权基数的研究有限，目前的方法需要大量的内存和计算资源，对于功能有限的设备和实时应用(如异常检测)具有挑战性。为了解决这些问题，我们提出了 QSketch，一种内存高效的草图方法，用于估计流中的加权基数。QSketch 使用量化技术将连续变量压缩为一组紧凑的整数变量，每个变量只需要8位，使其比以前的方法小8倍。此外，我们利用 QSketch 生成过程中的动态特性来显著提高估计精度，并且在遇到新元素时更新估计时降低了 O (1)的时间复杂度。在合成和真实数据集上的实验结果显示，QSketch 只使用了1/8的内存，比最先进的数量级提高了大约30% 的准确率和2% 的速度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QSketch:+An+Efficient+Sketch+for+Weighted+Cardinality+Estimation+in+Streams)|0|
|[Make Your Home Safe: Time-aware Unsupervised User Behavior Anomaly Detection in Smart Homes via Loss-guided Mask](https://doi.org/10.1145/3637528.3671708)|Jingyu Xiao, Zhiyao Xu, Qingsong Zou, Qing Li, Dan Zhao, Dong Fang, Ruoyu Li, Wenxin Tang, Kang Li, Xudong Zuo, Penghui Hu, Yong Jiang, Zixuan Weng, Michael R. Lyu|Tsinghua Shenzhen International Graduate School & Peng Cheng Laboratory, Shenzhen, China; Beijing Jiaotong University, Beijing, China; Tencent, Shenzhen, China; Tsinghua University, Beijing, China; Peng Cheng Laborotary, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory & Tsinghua Shenzhen International Graduate School, Shenzhen, China; Tsinghua Shenzhen International Graduate School, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China; Xi'an University of Electronic Science and Technology, Xi'an, China|Smart homes, powered by the Internet of Things, offer great convenience but also pose security concerns due to abnormal behaviors, such as improper operations of users and potential attacks from malicious attackers. Several behavior modeling methods have been proposed to identify abnormal behaviors and mitigate potential risks. However, their performance often falls short because they do not effectively learn less frequent behaviors, consider temporal context, or account for the impact of noise in human behaviors. In this paper, we propose SmartGuard, an autoencoder-based unsupervised user behavior anomaly detection framework. First, we design a Loss-guided Dynamic Mask Strategy (LDMS) to encourage the model to learn less frequent behaviors, which are often overlooked during learning. Second, we propose a Three-level Time-aware Position Embedding (TTPE) to incorporate temporal information into positional embedding to detect temporal context anomaly. Third, we propose a Noise-aware Weighted Reconstruction Loss (NWRL) that assigns different weights for routine behaviors and noise behaviors to mitigate the interference of noise behaviors during inference. Comprehensive experiments demonstrate that SmartGuard consistently outperforms state-of-the-art baselines and also offers highly interpretable results.|物联网驱动的智能家居不仅提供了极大的便利，而且由于用户的不正常操作和恶意攻击者的潜在攻击等不正常行为，也引起了安全方面的担忧。为了识别异常行为和降低潜在风险，人们提出了几种行为建模方法。然而，他们的表现往往不足，因为他们没有有效地学习较少的频繁行为，考虑时间背景，或说明噪音的影响，人类行为。在本文中，我们提出了 SmartGuard，一个基于自动编码器的无监督用户行为异常检测框架。首先，我们设计了一个损失引导的动态掩模策略(LDMS)来鼓励模型学习较少频繁的行为，这些行为在学习过程中经常被忽略。其次，提出了一种三级时间感知位置嵌入算法(TTPE) ，将时间信息融合到位置嵌入算法中，检测时间上下文异常。第三，提出了一种噪声感知加权重构损失(NWRL)算法，该算法对日常行为和噪声行为赋予不同的权重，以减轻推理过程中噪声行为的干扰。综合实验表明，SmartGuard 始终优于最先进的基线，并提供高度可解释的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Make+Your+Home+Safe:+Time-aware+Unsupervised+User+Behavior+Anomaly+Detection+in+Smart+Homes+via+Loss-guided+Mask)|0|
|[Top-Down Bayesian Posterior Sampling for Sum-Product Networks](https://doi.org/10.1145/3637528.3671876)|Soma Yokoi, Issei Sato|The University of Tokyo, Tokyo, Japan|Sum-product networks (SPNs) are probabilistic models characterized by exactand fast evaluation of fundamental probabilistic operations. Its superiorcomputational tractability has led to applications in many fields, such asmachine learning with time constraints or accuracy requirements and real-timesystems. The structural constraints of SPNs supporting fast inference, however,lead to increased learning-time complexity and can be an obstacle to buildinghighly expressive SPNs. This study aimed to develop a Bayesian learningapproach that can be efficiently implemented on large-scale SPNs. We derived anew full conditional probability of Gibbs sampling by marginalizing multiplerandom variables to expeditiously obtain the posterior distribution. Thecomplexity analysis revealed that our sampling algorithm works efficiently evenfor the largest possible SPN. Furthermore, we proposed a hyperparameter tuningmethod that balances the diversity of the prior distribution and optimizationefficiency in large-scale SPNs. Our method has improved learning-timecomplexity and demonstrated computational speed tens to more than one hundredtimes faster and superior predictive performance in numerical experiments onmore than 20 datasets.|和积网络(Sum-product network，SPN)是基本概率运算的精确和快速评估的概率模型拥有属性。其优越的计算易处理性在许多领域得到了应用，例如具有时间约束或精度要求的机器学习和实时系统。然而，支持快速推理的 SPN 的结构约束导致了学习时间复杂性的增加，并可能成为构建高表达性 SPN 的障碍。本研究旨在发展一个可以在大型 SPN 上有效执行的贝叶斯学习方法。我们通过边缘化多重随机变量得到了一个全新的吉布斯抽样条件概率，以便快速获得后验概率。复杂性分析表明，我们的抽样算法工作效率甚至最大的可能 SPN。在此基础上，提出了一种平衡先验分布多样性和优化效率的超参数调谐方法。在20多个数据集的数值实验中，该方法提高了学习时间的复杂度，并显示出数十倍至一百倍以上的计算速度和优越的预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Top-Down+Bayesian+Posterior+Sampling+for+Sum-Product+Networks)|0|
|[CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification](https://doi.org/10.1145/3637528.3671515)|Lele Cao, Vilhelm von Ehrenheim, Mark GranrothWilding, Richard Anselmo Stahl, Andrew McCornack, Armin Catovic, Dhiana Deva Cavalcanti Rocha|Motherbrain, EQT Group, Stockholm, Sweden; Motherbrain, EQT Group & Silo AI, Stockholm, Sweden; Motherbrain, EQT Group & QA.tech, Stockholm, Sweden|In the investment industry, it is often essential to carry out fine-grainedcompany similarity quantification for a range of purposes, including marketmapping, competitor analysis, and mergers and acquisitions. We propose andpublish a knowledge graph, named CompanyKG, to represent and learn diversecompany features and relations. Specifically, 1.17 million companies arerepresented as nodes enriched with company description embeddings; and 15different inter-company relations result in 51.06 million weighted edges. Toenable a comprehensive assessment of methods for company similarityquantification, we have devised and compiled three evaluation tasks withannotated test sets: similarity prediction, competitor retrieval and similarityranking. We present extensive benchmarking results for 11 reproduciblepredictive methods categorized into three groups: node-only, edge-only, andnode+edge. To the best of our knowledge, CompanyKG is the first large-scaleheterogeneous graph dataset originating from a real-world investment platform,tailored for quantifying inter-company similarity.|在投资行业，为了一系列目的(包括市场地图、竞争对手分析和併购)进行细粒度的公司相似性量化往往是必不可少的。我们提出并发布了一个知识图，命名为 CompanyKG，用于表示和学习公司的各种特征和关系。具体来说，117万家公司被表示为丰富了公司描述嵌入的节点; 15种不同的公司间关系产生了5106万个加权边。为了对企业相似性量化方法进行综合评价，我们设计并编制了三个评价任务: 相似性预测、竞争对手检索和相似性排名。我们提出了广泛的基准测试结果的11个可重复的预测方法分为三组: 节点只有，边缘，和节点 + 边缘。据我们所知，CompanyKG 是第一个来自现实世界投资平台的大规模异构图形数据集，专门用于量化公司间的相似性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CompanyKG:+A+Large-Scale+Heterogeneous+Graph+for+Company+Similarity+Quantification)|0|
|[CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning](https://doi.org/10.1145/3637528.3671538)|Ulrik FriisJensen, Frederik L. Johansen, Andy S. Anker, Erik B. Dam, Kirsten M. Ø. Jensen, Raghavendra Selvan|; Department of Chemistry, University of Copenhagen, Copenhagen, Denmark; Department of Computer Science, University of Copenhagen, Copenhagen, Denmark|Advances in graph machine learning (ML) have been driven by applications in chemistry, as graphs have remained the most expressive representations of molecules. This has led to progress within both fields, as challenging chemical data has helped improve existing methods and to develop new ones. While early graph ML methods focused primarily on small organic molecules, more recently, the scope of graph ML has expanded to include inorganic materials. Modelling the periodicity and symmetry of inorganic crystalline materials poses unique challenges, which existing graph ML methods are unable to immediately address. Moving to inorganic nanomaterials further increases complexity as the scale of number of nodes within each graph can be broad (10 to 100k). In addition, the bulk of existing graph ML focuses on characterising molecules and materials by predicting target properties with graphs as input. The most exciting applications of graph ML will be in their generative capabilities, in order to explore the vast chemical space from a data-driven perspective. Currently, generative modelling of graphs is not at par with other domains such as images or text, as generating chemically valid molecules and materials of varying properties is not straightforward. In this work, we invite the graph ML community to address these open challenges by presenting two new chemically-informed large-scale inorganic (CHILI) nanomaterials datasets. These datasets contain nanomaterials of different scales and properties represented as graphs of varying sizes. The first dataset is a medium-scale dataset (with overall >6M nodes, >49M edges) of mono-metallic oxide nanomaterials generated from 12 selected crystal types (CHILI-3K). This dataset has a narrower chemical scope focused on an interesting part of chemical space with a lot of active research. The second is a large-scale dataset (with overall >183M nodes, >1.2B edges) of nanomaterials generated from experimentally determined crystal structures (CHILI-100K). The crystal structures used in CHILI-100K are obtained from a curated subset of the Crystallography Open Database (COD) and has a broader chemical scope covering database entries for 68 metals and 11 non-metals. We define 11 property prediction tasks covering node-, edge-, and graph- level tasks that span classification and regression. In addition we also define structure prediction tasks, which are of special interest for nanomaterial research. We benchmark the performance of a wide array of baseline methods starting with simple baselines to multiple off-the-shelf graph neural networks. Based on these benchmarking results, we highlight areas which need future work to achieve useful performance for applications in (nano) materials chemistry. To the best of our knowledge, CHILI-3K and CHILI-100K are the first open-source nanomaterial datasets of this scale - both on the individual graph level and of the dataset as a whole - and the only nanomaterials datasets with high structural and elemental diversity.|图形机器学习(ML)的发展受到化学应用的推动，因为图形仍然是分子最有表现力的表现形式。这导致了这两个领域的进展，因为具有挑战性的化学数据有助于改进现有方法和开发新的方法。虽然早期的图形 ML 方法主要集中在小有机分子，最近，图形 ML 的范围已经扩大到包括无机材料。模拟无机晶体材料的周期性和对称性提出了独特的挑战，现有的图 ML 方法无法立即解决。转向无机纳米材料进一步增加了复杂性，因为每个图中节点的数量范围可以很宽(10到100k)。此外，现有的大部分图 ML 侧重于通过以图形作为输入来预测目标特性来表征分子和材料。图形机器学习最令人兴奋的应用将在于它们的生成能力，以便从数据驱动的角度探索广阔的化学空间。目前，图形的生成建模与图像或文本等其他领域不同，因为生成具有不同性质的化学有效分子和材料并不简单。在这项工作中，我们邀请图形机器学习社区解决这些开放的挑战，提出两个新的化学信息大规模无机(CHILI)纳米材料数据集。这些数据集包含不同尺度和性质的纳米材料，表示为不同尺寸的图形。第一个数据集是由12种选定的晶体类型(CHILI-3K)产生的单金属氧化物纳米材料的中等规模数据集(总体 > 6M 节点，> 49M 边)。这个数据集有一个较窄的化学范围集中在一个有趣的部分的化学空间与许多活跃的研究。第二个是由实验确定的晶体结构(CHILI-100K)产生的纳米材料的大规模数据集(总体 > 183M 节点，> 1.2 B 边)。CHILI-100K 中使用的晶体结构是从晶体学开放数据库(COD)的一个精选子集中获得的，并且具有更广泛的化学范围，包括68种金属和11种非金属的数据库条目。我们定义了11个属性预测任务，涵盖了分类和回归的节点、边和图级任务。此外，我们还定义了纳米材料研究特别感兴趣的结构预测任务。从简单的基线到多个现成的图形神经网络，我们测试了大量基线方法的性能。在这些基准测试结果的基础上，我们强调了在(纳米)材料化学中实现有用性能需要进一步工作的领域。据我们所知，CHILI-3K 和 CHILI-100K 是第一个这种规模的开源纳米材料数据集-无论是在单个图形水平还是整个数据集-也是唯一具有高结构和元素多样性的纳米材料数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CHILI:+Chemically-Informed+Large-scale+Inorganic+Nanomaterials+Dataset+for+Advancing+Graph+Machine+Learning)|0|
|[Offline Reinforcement Learning for Optimizing Production Bidding Policies](https://doi.org/10.1145/3637528.3671555)|Dmytro Korenkevych, Frank Cheng, Artsiom Balakir, Alex Nikulkov, Lingnan Gao, Zhihao Cen, Zuobing Xu, Zheqing Zhu|AI at Meta, Bellevue, USA; Meta Platform Inc., Menlo Park, USA; AI at Meta, Menlo Park, USA; AI at Meta, Sunnyvale, USA|The online advertising market, with its thousands of auctions run per second, presents a daunting challenge for advertisers who wish to optimize their spend under a budget constraint. Thus, advertising platforms typically provide automated agents to their customers, which act on their behalf to bid for impression opportunities in real time at scale. Because these proxy agents are owned by the platform but use advertiser funds to operate, there is a strong practical need to balance reliability and explainability of the agent with optimizing power. We propose a generalizable approach to optimizing bidding policies in production environments by learning from real data using offline reinforcement learning. This approach can be used to optimize any differentiable base policy (practically, a heuristic policy based on principles which the advertiser can easily understand), and only requires data generated by the base policy itself. We use a hybrid agent architecture that combines arbitrary base policies with deep neural networks, where only the optimized base policy parameters are eventually deployed, and the neural network part is discarded after training. We demonstrate that such an architecture achieves statistically significant performance gains in both simulated and at-scale production bidding environments. Our approach does not incur additional infrastructure, safety, or explainability costs, as it directly optimizes parameters of existing production routines without replacing them with black box-style models like neural networks.|在线广告市场每秒钟有数千场拍卖，对于那些希望在预算线下优化支出的广告客户来说，这是一个艰巨的挑战。因此，广告平台通常向客户提供自动化代理，代表客户实时大规模地争取印象机会。由于这些代理商属于平台所有，但利用广告客户的资金进行运作，因此在代理商的可靠性和可解释性与优化权力之间存在着很强的现实需求。我们提出了一个通用的方法来优化投标政策在生产环境中通过学习使用离线强化学习的真实数据。这种方法可以用来优化任何可微的基本策略(实际上是一种基于广告商容易理解的原则的启发式策略) ，并且只需要基本策略本身生成的数据。我们采用混合智能体结构，将任意基本策略与深度神经网络相结合，最终只部署优化后的基本策略参数，训练后丢弃神经网络部分。我们证明了这样的体系结构在模拟和大规模生产投标环境中都能获得统计上显著的性能提高。我们的方法不会产生额外的基础设施、安全或可解释性成本，因为它直接优化了现有生产例程的参数，而没有用神经网络等黑箱模型来替代它们。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Reinforcement+Learning+for+Optimizing+Production+Bidding+Policies)|0|
|[Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising](https://doi.org/10.1145/3637528.3671540)|Yumin Su, Min Xiang, Yifei Chen, Yanbiao Li, Tian Qin, Hongyi Zhang, Yasong Li, Xiaobing Liu|ByteDance Inc., San Jose, CA, USA; ByteDance Inc., Beijing, China; ByteDance Inc., Singapore|Privacy policies have disrupted the multi-billion dollar online advertising market by making real-time and precise user data untraceable, which poses significant challenges to the optimization of Return-On-Investment (ROI) constrained products in the online advertising industry. Privacy protection strategies, including event aggregation and reporting delays, hinder access to detailed and instantaneous feedback data, thus incapacitating traditional identity-revealing attribution techniques. In this paper, we introduces a novel Spending Programmed Bidding (SPB) framework to navigate these challenges. SPB is a two-stage framework that separates long horizon delivery spend planning (the macro stage) and short horizon bidding execution (the micro stage). The macro stage models the target ROI to achieve maximum utility and derives the expected spend, whereas the micro stage optimizes the bid price given the expected spend. We further extend our framework to the cross-channel scenario where the agent bids in both privacy-constrained and identity-revealing attribution channels. We find that when privacy-constrained channels are present, SPB is superior to state-of-the-art bidding methods in both offline datasets and online experiments on a large ad platform.|隐私政策扰乱了数十亿美元的在线广告市场，使实时和精确的用户数据无法追踪，这对在线广告业中投资回报率(ROI)受限产品的优化提出了重大挑战。隐私保护策略，包括事件聚合和报告延迟，阻碍访问详细的和即时的反馈数据，从而使传统的身份披露归因技术丧失能力。在本文中，我们介绍了一个新的支出计划投标(SPB)框架来应对这些挑战。SPB 是一个分为两个阶段的框架，分别为长期交付支出计划(宏观阶段)和短期投标执行(微观阶段)。宏观阶段建立目标投资回报率模型以实现效用最大化并导出预期支出，而微观阶段在给定预期支出的情况下优化投标价格。我们进一步将我们的框架扩展到跨通道场景，其中代理在隐私约束和身份披露的属性通道中竞标。我们发现，当隐私受限的渠道存在时，SPB 在离线数据集和大型广告平台上的在线实验中都优于最先进的投标方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spending+Programmed+Bidding:+Privacy-friendly+Bid+Optimization+with+ROI+Constraint+in+Online+Advertising)|0|
|[Know in AdVance:  Linear-Complexity Forecasting of Ad Campaign Performance with Evolving User Interest](https://doi.org/10.1145/3637528.3671528)|Xiaoyu Wang, Yonghui Guo, Hui Sheng, Peili Lv, Chi Zhou, Wei Huang, Shiqin Ta, Dongbo Huang, Xiujin Yang, Lan Xu, Hao Zhou, Yusheng Ji|Tencent Advertising, Shanghai, China; ; University of Science and Technology of China & National Institute of Informatics, Hefei, China|Real-time Bidding (RTB) advertisers wish to know in advance theexpected cost and yield of ad campaigns to avoid trial-and-error expenses.However, Campaign Performance Forecasting (CPF), a sequence modeling taskinvolving tens of thousands of ad auctions, poses challenges of evolving userinterest, auction representation, and long context, making coarse-grained andstatic-modeling methods sub-optimal. We propose AdVance, a time-awareframework that integrates local auction-level and global campaign-levelmodeling. User preference and fatigue are disentangled using a time-positionedsequence of clicked items and a concise vector of all displayed items.Cross-attention, conditioned on the fatigue vector, captures the dynamics ofuser interest toward each candidate ad. Bidders compete with each other,presenting a complete graph similar to the self-attention mechanism. Hence, weemploy a Transformer Encoder to compress each auction into embedding by solvingauxiliary tasks. These sequential embeddings are then summarized by aconditional state space model (SSM) to comprehend long-range dependencies whilemaintaining global linear complexity. Considering the irregular time intervalsbetween auctions, we make SSM's parameters dependent on the current auctionembedding and the time interval. We further condition SSM's global predictionson the accumulation of local results. Extensive evaluations and ablationstudies demonstrate its superiority over state-of-the-art methods. AdVance hasbeen deployed on the Tencent Advertising platform, and A/B tests show aremarkable 4.5% uplift in Average Revenue per User (ARPU).|实时竞价(RTB)广告商希望提前知道广告活动的预期成本和收益，以避免试错成本。然而，运动性能预测(CPF)是一个涉及数以万计的广告拍卖的序列建模任务，面临着用户兴趣、拍卖表示和长上下文的不断变化的挑战，使得粗粒度和静态建模方法不再是最优的。我们提出了一个时间感知框架，集成了本地拍卖级别和全球活动级别的建模。使用点击项目的时间定位序列和所有显示项目的简洁向量，用户偏好和疲劳被分离开来。交叉注意力，以疲劳向量为条件，捕捉用户对每个候选广告的兴趣动态。竞标者相互竞争，呈现出一个类似于自我注意机制的完整图表。因此，我们使用变压器编码器通过解决辅助任务将每个拍卖压缩成嵌入。然后用条件状态空间模型(SSM)对这些顺序嵌入进行总结，以便在保持全局线性复杂度的同时理解长程依赖关系。考虑到拍卖之间的时间间隔不规则，我们使得 SSM 的参数依赖于当前的拍卖嵌入和时间间隔。我们进一步将 SSM 的全局预测建立在局部结果累积的基础上。广泛的评估和消融研究表明其优于最先进的方法。在腾讯广告平台上已经部署了 Advanced，a/b 测试显示平均每用户收入(ARPU)显著提高了4.5% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Know+in+AdVance:++Linear-Complexity+Forecasting+of+Ad+Campaign+Performance+with+Evolving+User+Interest)|0|
|[Trinity: Syncretizing Multi-/Long-Tail/Long-Term Interests All in One](https://doi.org/10.1145/3637528.3671651)|Jing Yan, Liu Jiang, Jianfei Cui, Zhichen Zhao, Xingyan Bin, Feng Zhang, Zuotao Liu|ByteDance Inc., Shanghai, China; ByteDance Inc., Beijing, China|Interest modeling in recommender system has been a constant topic for improving user experience, and typical interest modeling tasks (e.g. multi-interest, long-tail interest and long-term interest) have been investigated in many existing works. However, most of them only consider one interest in isolation, while neglecting their interrelationships. In this paper, we argue that these tasks suffer from a common "interest amnesia" problem, and a solution exists to mitigate it simultaneously. We propose a novel and unified framework in the retrieval stage, "Trinity", to solve interest amnesia problem and improve multiple interest modeling tasks. We construct a real-time clustering system that enables us to project items into enumerable clusters, and calculate statistical interest histograms over these clusters. Based on these histograms, Trinity recognizes underdelivered themes and remains stable when facing emerging hot topics. Its derived retrievers have been deployed on the recommender system of Douyin, significantly improving user experience and retention. We believe that such practical experience can be well generalized to other scenarios.|兴趣建模一直是提高用户体验的推荐系统，现有的许多研究工作都对典型的兴趣建模任务(如多重兴趣、长尾兴趣和长期兴趣)进行了研究。然而，他们中的大多数只考虑了孤立的一个利益，而忽视了他们之间的相互关系。在本文中，我们认为，这些任务遭受一个共同的“利益健忘症”问题，并存在一个解决方案，以减轻它同时。为了解决兴趣健忘问题和改进多兴趣建模任务，我们提出了一个新的统一的检索框架“三位一体”。我们构造了一个实时聚类系统，使我们能够将项目投射到可枚举的聚类中，并计算这些聚类上的统计兴趣直方图。基于这些直方图，三一认识到交付不足的主题，并保持稳定时，面对新兴的热门话题。它派生出来的检索器已经部署在 Douyin 的推荐系统上，大大提高了用户体验和保留率。我们相信，这种实践经验可以很好地推广到其他情况。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trinity:+Syncretizing+Multi-/Long-Tail/Long-Term+Interests+All+in+One)|0|
|[Temporal Uplift Modeling for Online Marketing](https://doi.org/10.1145/3637528.3671560)|Xin Zhang, Kai Wang, Zengmao Wang, Bo Du, Shiwei Zhao, Runze Wu, Xudong Shen, Tangjie Lv, Changjie Fan|NetEase Fuxi AI Lab, Hangzhou, China; Wuhan University, Wuhan, China; Netease Fuxi AI Lab, Hangzhou, China|In recent years, uplift modeling, also known as individual treatment effect (ITE) estimation, has seen wide applications in online marketing, such as delivering one-time issuance of coupons or discounts to motivate users' purchases. However, complex yet more realistic scenarios involving multiple interventions over time on users are still rarely explored. The challenges include handling the bias from time-varying confounders, determining optimal treatment timing, and selecting among numerous treatments. In this paper, to tackle the aforementioned challenges, we present a temporal point process-based uplift model (TPPUM) that utilizes users' temporal event sequences to estimate treatment effects via counterfactual analysis and temporal point processes. In this model, marketing actions are considered as treatments, user purchases as outcome events, and how treatments alter the future conditional intensity function of generating outcome events as the uplift. Empirical evaluations demonstrate that our method outperforms existing baselines on both real-world and synthetic datasets. In the online experiment conducted in a discounted bundle recommendation scenario involving an average of 3 to 4 interventions per day and hundreds of treatment candidates, we demonstrate how our model outperforms current state-of-the-art methods in selecting the appropriate treatment and timing of treatment, resulting in a 3.6% increase in application-level revenue.|近年来，提升模型，也被称为个体治疗效果(ITE)评估，已经在网络营销中得到了广泛的应用，例如提供一次性发行优惠券或折扣，以激励用户的购买。然而，涉及随着时间的推移对用户进行多种干预的复杂但更现实的场景仍然很少被探索。这些挑战包括处理来自时变混杂因素的偏倚，确定最佳治疗时机，以及在众多治疗方案中进行选择。为了解决上述问题，本文提出了一种基于时间点过程的提升模型(TPPUM) ，该模型利用用户的时间事件序列，通过反事实分析和时间点过程来估计治疗效果。在这个模型中，营销行为被认为是治疗，用户购买作为结果事件，以及治疗如何改变未来的条件强度函数，产生结果事件作为提升。经验评估表明，我们的方法优于现有的基线上的真实世界和合成数据集。在折扣捆绑推荐情景下进行的在线实验中，涉及平均每天3至4次干预和数百个治疗候选人，我们证明了我们的模型在选择适当的治疗和治疗时机方面如何优于当前最先进的方法，导致应用级收入增加3.6% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Uplift+Modeling+for+Online+Marketing)|0|
|[STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled Experiments](https://doi.org/10.1145/3637528.3672352)|Hao Zhou, Kun Sun, Shaoming Li, Yangfeng Fan, Guibin Jiang, Jiaqi Zheng, Tao Li|State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Meituan, Beijing, China; State Key Laboratory for Novel Software Technology, Nanjing University & Meituan, Nanjing, China|Online controlled experiments play a crucial role in enabling data-driven decisions across a wide range of companies. Variance reduction is an effective technique to improve the sensitivity of experiments, achieving higher statistical power while using fewer samples and shorter experimental periods. However, typical variance reduction methods (e.g., regression-adjusted estimators) are built upon the intuitional assumption of Gaussian distributions and cannot properly characterize the real business metrics with heavy-tailed distributions. Furthermore, outliers diminish the correlation between pre-experiment covariates and outcome metrics, greatly limiting the effectiveness of variance reduction. In this paper, we develop a novel framework that integrates the Student's t-distribution with machine learning tools to fit heavy-tailed metrics and construct a robust average treatment effect estimator in online controlled experiments, which we call STATE. By adopting a variational EM method to optimize the loglikehood function, we can infer a robust solution that greatly eliminates the negative impact of outliers and achieves significant variance reduction. Moreover, we extend the STATE method from count metrics to ratio metrics by utilizing linear transformation that preserves unbiased estimation, whose variance reduction is more complex but less investigated in existing works. Finally, both simulations on synthetic data and long-term empirical results on Meituan experiment platform demonstrate the effectiveness of our method. Compared with the state-of-the-art estimators (CUPAC/MLRATE), STATE achieves over 50% variance reduction, indicating it can reach the same statistical power with only half of the observations, or half the experimental duration.|在线控制实验在许多公司实现数据驱动的决策方面发挥着至关重要的作用。方差约简是一种提高实验灵敏度的有效方法，可以在使用较少样本和较短实验周期的情况下获得较高的统计效率。然而，典型的方差减少方法(例如，回归调整估计)是建立在高斯分布的直观假设之上的，不能正确地描述实际业务指标的重尾分布。此外，异常值降低了实验前协变量与结果指标之间的相关性，极大地限制了方差减少的有效性。本文提出了一种新的学生 t 分布与机器学习工具相结合的框架，用于在线对照实验，构造了一个稳健的平均治疗效果估计器，我们称之为状态估计器。通过采用变分 EM 方法对对数似然函数进行优化，可以推导出一个鲁棒解，大大消除了异常值的负面影响，实现了显著的方差减少。此外，我们将 STATE 方法从计数指标扩展到比率指标，使用了保留无偏估计的线性映射，其方差减少更为复杂，但在现有工作中研究较少。最后，对合成数据的模拟和在美团实验平台上的长期实验结果都证明了该方法的有效性。与最先进的估计器(CUPAC/MLRATE)相比，STATE 实现了超过50% 的方差减少，表明它可以达到相同的统计功率只有一半的观察，或一半的实验持续时间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STATE:+A+Robust+ATE+Estimator+of+Heavy-Tailed+Metrics+for+Variance+Reduction+in+Online+Controlled+Experiments)|0|
|[Practical Machine Learning for Streaming Data](https://doi.org/10.1145/3637528.3671442)|Heitor Murilo Gomes, Albert Bifet|; AI Institute, University of Waikato & LTCI, Télécom Paris, IP Paris, Waikato, New Zealand|Machine Learning for Data Streams has been an important area of research since the late 1990s, and its use in industry has grown significantly over the last few years. However, there is still a gap between the cutting-edge research and the tools that are readily available, which makes it challenging for practitioners, including experienced data scientists, to implement and evaluate these methods in this complex domain. Our tutorial aims to bridge this gap with a dual focus. We will discuss important research topics, such as partially delayed labeled streams, while providing practical demonstrations of their implementation and assessment using CapyMOA, an open-source library that provides efficient algorithm implementations through a high-level Python API. Source code is available in https://github.com/adaptive-machine-learning/CapyMOA while the accompanying tutorials and installation guide are available in https://capymoa.org/.|自20世纪90年代末以来，数据流机器学习一直是一个重要的研究领域，在过去几年中，它在工业中的应用显著增长。然而，在尖端研究和现有工具之间仍然存在差距，这使得从业人员，包括有经验的数据科学家，在这个复杂的领域实施和评估这些方法具有挑战性。我们的教程旨在通过双重关注来弥补这一差距。我们将讨论一些重要的研究主题，比如部分延迟的标记流，同时使用 CapyMOA 提供实际的实现和评估演示，CapyMOA 是一个开源库，通过高级 Python API 提供高效的算法实现。源代码可以在 https://github.com/adaptive-machine-learning/capymoa 中找到，相应的教程和安装指南也可以在 https://capymoa.org/中找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Machine+Learning+for+Streaming+Data)|0|
|[Empower an End-to-end Scalable and Interpretable Data Science Ecosystem using Statistics, AI and Domain Science](https://doi.org/10.1145/3637528.3672194)|Xihong Lin|Harvard University, Boston, MA, USA|The data science ecosystem encompasses data fairness, statistical, ML and AI methods and tools, interpretable data analysis and results, and trustworthy decision-making. Rapid advancements in AI have revolutionized data utilization and enabled machines to learn from data more effectively. Statistics, as the science of learning from data while accounting for uncertainty, plays a pivotal role in addressing complex real-world problems and facilitating trustworthy decision-making. In this talk, I will discuss the challenges and opportunities involved in building an end-to-end scalable and interpretable data science ecosystem using the analysis of whole genome sequencing studies and biobanks that integrates statistics, ML/AI, and genomic and health science as an example. Biobanks collect whole genome data, electronic health records and epidemiological data. I will illustrate key points using the analysis of multi-ancestry whole genome sequencing studies and biobanks by discussing a few scalable and interpretable statistical and ML/AI methods, tools and data science resources. Specifically, first, data fairness and diversity is a critical pillar of a trustworthy data science ecosystem. About 85+% of genome wide association study samples in the last 15 years are European, resulting in disparity in genetic research. I will discuss the community effort on improving diversity in genetic studies in the last 10 years. I will present trans-ancestry polygenic risk scores (PRS) using millions of common genetic variants across the genome by leveraging large GWAS sample sizes of European and smaller sample sizes of under-represented populations for predicting disease risk using transfer learning and genetic association summary statistics. The performance of deep learning methods for PRS will also be discussed. Second, scalability in cloud platforms is critical for large scale affordable analysis for multi-ancestry biobanks and whole genome studies. I will discuss improving scalability in cloud-computing using interpretable sparsity via FastSparseGRM. To build an interpretable and powerful end-to-end ecosystem of rare variant analysis of large scale whole genome sequencing studies and biobanks, I will first introduce FAVOR, a multi-faceted variant functional annotation database and portal of all possible 9 billions of variants across the whole genome. I will discuss FAVOR-GPT, a LLM interface of the FAVOR functional annotation database to improve user experience for navigating FAVOR and performing variant functional annotation query and variant functional summary statistics calculations. I will also discuss FAVORannotator which can be used to functionally annotate any whole genome sequencing studies. I will also discuss STAAR and STAAR and STAARpipeline, the WGS rare variant analysis pipeline that boosts the power of WGS rare variant association analysis by dynamically incorporating multi-faceted variant functional annotations. Extension of incorporating single-cell data in WGS analysis will also be discussed. I will also discuss ensemble methods that improve the power of rare variant association tests. Cloud-deployment of these resources and tools in several ecosystems will be presented, such as RAP for the UK biobank, AnVIL for the NHGRI Genome Sequencing Program and All of Us, and BioData Catalyst for the NHLBI Trans-omics Precision Medine Program (TOPMed). This talk aims to ignite proactive and thought-provoking discussions, foster collaboration, and cultivate open-minded approaches to advance scientific discovery.|数据科学生态系统包括数据公平、统计学、机器学习和人工智能方法和工具、可解释的数据分析和结果以及可信赖的决策。人工智能的快速发展使数据利用发生了革命性的变化，使机器能够更有效地从数据中学习。统计学是一门从数据中学习同时考虑不确定性的科学，在解决复杂的现实世界问题和促进可信赖的决策方面发挥着关键作用。在这次演讲中，我将以整合统计学、机器学习/人工智能以及基因组和健康科学的全基因组测序研究和生物库分析为例，讨论建立一个端到端可扩展和可解释的数据科学生态系统所面临的挑战和机遇。生物库收集全基因组数据、电子健康记录和流行病学数据。我将通过讨论一些可扩展和可解释的统计学和机器学习/人工智能方法、工具和数据科学资源，用多血统全基因组测序研究和生物库的分析来说明要点。具体来说，首先，数据公平性和多样性是可信赖的数据科学生态系统的关键支柱。在过去的15年中，大约85% 以上的全基因组关联研究样本是欧洲的，这导致了遗传学研究的差异。我将讨论在过去10年中社区在提高基因研究多样性方面所做的努力。我将通过利用欧洲的大型 GWAS 样本量和代表性不足人群的较小样本量，使用转移学习和遗传关联总结统计来预测疾病风险，从而使用数百万个常见基因变体来呈现跨血统多基因风险评分(PRS)。本文还将讨论 PRS 深度学习方法的性能。其次，云平台的可扩展性对于多血统生物库和全基因组研究的大规模经济分析至关重要。我将讨论如何通过 FastSparseGRM 使用可解释的稀疏性来提高云计算的可伸缩性。为了建立一个可解释和强大的端到端生态系统的罕见变异分析的大规模全基因组测序研究和生物库，我将首先介绍 FAVOR，一个多方面的变异功能注释数据库和门户网站的所有可能的90亿个变异整个基因组。我将讨论 FAVOR-GPT，它是 FAVOR 功能注释数据库的 LLM 接口，用于改善用户在导航 FAVOR 和执行变体功能注释查询和变体功能摘要统计计算时的体验。我还将讨论 FAVORannotator，它可以用来对任何全基因组测序研究进行功能性注释。我还将讨论 STAAR 和 STAAR 以及 STAAR 流水线，这是 WGS 稀有变量分析流水线，它通过动态结合多方面的变量功能注释来提高 WGS 稀有变量关联分析的能力。还将讨论将单细胞数据纳入 WGS 分析的扩展。我还将讨论提高稀有变量关联测试能力的集成方法。将介绍这些资源和工具在几个生态系统中的云部署，例如英国生物库的 RAP，NHGRI 基因组测序计划和我们所有人的 AnVIL，以及 NHLBI 反式组学精确医学计划(TOPMed)的 BioData Catalyst。这次讲座的目的是激发积极主动和发人深省的讨论，促进合作，并培养开放的方法，以推动科学发现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empower+an+End-to-end+Scalable+and+Interpretable+Data+Science+Ecosystem+using+Statistics,+AI+and+Domain+Science)|0|
|[Semi-Supervised Learning for Time Series Collected at a Low Sampling Rate](https://doi.org/10.1145/3637528.3672033)|Minyoung Bae, Yooju Shin, Youngeun Nam, Youngseop Lee, JaeGil Lee|Samsung Electronics Co., Ltd., Suwon-si, Republic of Korea; KAIST, Daejeon, Republic of Korea|Although time-series classification has many applications in healthcare and manufacturing, the high cost of data collection and labeling hinders its widespread use. To reduce data collection and labeling costs while maintaining high classification accuracy, we propose a novel problem setting, called semi-supervised learning with low-sampling-rate time series, in which the majority of time series are collected at a low sampling rate and are unlabeled whereas the minority of time series are collected at a high sampling rate and are labeled. For this novel problem scenario, we develop the SemiTSR framework equipped with the super-resolution module and the semi-supervised learning module. Here, low-sampling-rate time series are upsampled precisely, taking periodicity and trend at each timestamp into account, and both labeled and unlabeled high-sampling-rate time series are utilized for training. In particular, consistency regularization between artificially downsampled time series derived from an original high-sampling-rate time series is effective at overcoming limited sampling rates. We demonstrate that SemiTSR significantly outperforms conventional semi-supervised learning techniques by assuring high classification accuracy with low-sampling-rate time series.|尽管时间序列分类在医疗保健和制造业中有着广泛的应用，但是高昂的数据采集和标记成本阻碍了它的广泛应用。为了减少数据收集和标记成本，同时保持高分类准确性，我们提出了一个新的问题设置，称为低采样率时间序列的半监督学习，其中大多数时间序列是以低采样率收集和未标记，而少数时间序列是以高采样率收集和标记。对于这个新的问题场景，我们开发了配备了超分辨率模块和半监督学习模块的 SemitSR 框架。该方法对低采样率时间序列进行精确的上采样，同时考虑每个时间戳的周期性和趋势性，采用标记和未标记的高采样率时间序列进行训练。特别是，人工下采样时间序列之间的一致性正则化源于一个原始的高采样率时间序列是有效的克服有限的采样率。我们证明了 SemitSR 通过保证低采样率时间序列的高分类精度，明显优于传统的半监督学习分类技术。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-Supervised+Learning+for+Time+Series+Collected+at+a+Low+Sampling+Rate)|0|
|[Meta Clustering of Neural Bandits](https://doi.org/10.1145/3637528.3671691)|Yikun Ban, Yunzhe Qi, Tianxin Wei, Lihui Liu, Jingrui He|University of Illinois, Urbana-Champaign, Champaign, IL, USA; University of Illinois at Urbana-Champaign, Champaign, IL, USA; University of Illinois, Urbana Champaign, Champaign, IL, USA|The contextual bandit has been identified as a powerful framework to formulate the recommendation process as a sequential decision-making process, where each item is regarded as an arm and the objective is to minimize the regret of T rounds. In this paper, we study a new problem, Clustering of Neural Bandits, by extending previous work to the arbitrary reward function, to strike a balance between user heterogeneity and user correlations in the recommender system. To solve this problem, we propose a novel algorithm called M-CNB, which utilizes a meta-learner to represent and rapidly adapt to dynamic clusters, along with an informative Upper Confidence Bound (UCB)-based exploration strategy. We provide an instance-dependent performance guarantee for the proposed algorithm that withstands the adversarial context, and we further prove the guarantee is at least as good as state-of-the-art (SOTA) approaches under the same assumptions. In extensive experiments conducted in both recommendation and online classification scenarios, M-CNB outperforms SOTA baselines. This shows the effectiveness of the proposed approach in improving online recommendation and online classification performance.|环境强盗已被确定为一个强大的框架，以制定推荐过程作为一个顺序决策过程，其中每个项目被视为一个手臂，目标是尽量减少 T 轮的遗憾。在这篇文章中，我们研究了一个新的问题，神经盗贼聚类，通过扩展以前的工作到任意奖励函数，来平衡用户异质性和用户相关性的推荐系统。为了解决这一问题，我们提出了一种新的算法 M-CNB，该算法利用元学习器来表示和快速适应动态聚类，同时提出了一种基于信息上置信界(UCB)的探索策略。我们提供了一个实例相关的性能保证提出的算法，抵御对手的背景下，我们进一步证明的保证是至少一样好的国家-最先进的(SOTA)方法在相同的假设条件下。在推荐和在线分类场景中进行的大量实验中，M-CNB 的性能优于 SOTA 基线。这表明了该方法在改善在线推荐和在线分类性能方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta+Clustering+of+Neural+Bandits)|0|
|[Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias](https://doi.org/10.1145/3637528.3671824)|Miaomiao Cai, Lei Chen, Yifan Wang, Haoyue Bai, Peijie Sun, Le Wu, Min Zhang, Meng Wang|DCST, Tsinghua University, Beijing, China; Hefei University of Technology, Hefei, China; DCST, Tsinghua University & Quan Cheng Laboratory, Beijing, China; Tsinghua University, Beijing, China|Collaborative Filtering (CF) typically suffers from the significant challengeof popularity bias due to the uneven distribution of items in real-worlddatasets. This bias leads to a significant accuracy gap between popular andunpopular items. It not only hinders accurate user preference understanding butalso exacerbates the Matthew effect in recommendation systems. To alleviatepopularity bias, existing efforts focus on emphasizing unpopular items orseparating the correlation between item representations and their popularity.Despite the effectiveness, existing works still face two persistent challenges:(1) how to extract common supervision signals from popular items to improve theunpopular item representations, and (2) how to alleviate the representationseparation caused by popularity bias. In this work, we conduct an empiricalanalysis of popularity bias and propose Popularity-Aware Alignment and Contrast(PAAC) to address two challenges. Specifically, we use the common supervisorysignals modeled in popular item representations and propose a novelpopularity-aware supervised alignment module to learn unpopular itemrepresentations. Additionally, we suggest re-weighting the contrastive learningloss to mitigate the representation separation from a popularity-centricperspective. Finally, we validate the effectiveness and rationale of PAAC inmitigating popularity bias through extensive experiments on three real-worlddatasets. Our code is available athttps://github.com/miaomiao-cai2/KDD2024-PAAC.|由于现实世界数据集中项目的分布不均匀，协同过滤(CF)通常会受到流行偏见的严重挑战。这种偏差导致流行和不流行的项目之间的准确性差距很大。它不仅阻碍了准确的用户偏好理解，而且加剧了推荐系统中的马太效应。为了减轻流行偏见，现有的研究集中在强调不受欢迎的项目或者区分项目表示和它们的流行度之间的关系。尽管有效，现有的研究仍然面临两个持续的挑战: (1)如何从流行项目中提取共同的监督信号来改善不流行项目的表征; (2)如何缓解流行偏差造成的表征分离。在这项工作中，我们进行了流行偏差的实证分析，并提出流行意识的对齐和对比(PAAC) ，以解决两个挑战。具体来说，我们使用流行项表示中的公共监督信号，并提出了一种新颖的流行感知监督对齐模块来学习不流行的项表示。此外，我们建议重新权衡对比学习损失，以减轻从流行为中心的观点表征分离。最后，我们通过在三个实际数据集上的大量实验，验证了 PAAC 消除流行偏差的有效性和合理性。我们的代码是可用的 https:// github.com/miaomiao-cai2/kdd2024-paac。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Popularity-Aware+Alignment+and+Contrast+for+Mitigating+Popularity+Bias)|0|
|[Enhancing Contrastive Learning on Graphs with Node Similarity](https://doi.org/10.1145/3637528.3671898)|Hongliang Chi, Yao Ma|Rensselaer Polytechnic Institute, Troy, NY, USA|Graph Neural Networks (GNNs) have achieved great success in learning graph representations and thus facilitating various graph-related tasks. However, most GNN methods adopt a supervised learning setting, which is not always feasible in real-world applications due to the difficulty to obtain labeled data. Hence, graph self-supervised learning has been attracting increasing attention. Graph contrastive learning (GCL) is a representative framework for self-supervised learning. In general, GCL learns node representations by contrasting semantically similar nodes (positive samples) and dissimilar nodes (negative samples) with anchor nodes. Without access to labels, positive samples are typically generated by data augmentation, and negative samples are uniformly sampled from the entire graph, which leads to a sub-optimal objective. Specifically, data augmentation naturally limits the number of positive samples that involve in the process (typically only one positive sample is adopted). On the other hand, the random sampling process would inevitably select false-negative samples (samples sharing the same semantics with the anchor). These issues limit the learning capability of GCL. In this work, we propose an enhanced objective that addresses the aforementioned issues. We first introduce an unachievable ideal objective that contains all positive samples and no false-negative samples. This ideal objective is then transformed into a probabilistic form based on the distributions for sampling positive and negative samples. We then model these distributions with node similarity and derive the enhanced objective. Comprehensive experiments on various datasets demonstrate the effectiveness of the proposed enhanced objective under different settings.|图形神经网络(GNN)在学习图形表示方面取得了巨大的成功，从而为各种图形相关的任务提供了便利。然而，大多数 GNN 方法采用监督式学习设置，这在现实应用中并不总是可行的，因为很难获得标记数据。因此，图的自监督学习越来越受到人们的关注。图形对比学习(GCL)是一种典型的自监督学习框架。通常，GCL 通过对比语义相似的节点(正样本)和不同的节点(负样本)与锚节点来学习节点表示。由于无法获得标签，正面样本通常通过数据增量生成，而负面样本则从整个图中均匀抽取，从而导致次优目标。具体来说，数据增强自然地限制了过程中涉及的阳性样本的数量(通常只采用一个阳性样本)。另一方面，随机抽样过程不可避免地会选择假阴性样本(样本与锚具有相同的语义)。这些问题限制了 GCL 的学习能力。在这项工作中，我们提出了一个解决上述问题的强化目标。我们首先介绍一个不可能实现的理想目标，它包含所有的正样本和没有假阴性样本。然后将这个理想目标转化为基于正负样本抽样分布的概率形式。然后利用节点相似性对这些分布进行建模，得到增强目标。在不同数据集上的综合实验表明了该增强目标在不同设置下的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Contrastive+Learning+on+Graphs+with+Node+Similarity)|0|
|[Fairness in Streaming Submodular Maximization Subject to a Knapsack Constraint](https://doi.org/10.1145/3637528.3671778)|Shuang Cui, Kai Han, Shaojie Tang, Feng Li, Jun Luo|; School of Computer Science and Technology, Soochow University, Suzhou, Jiangsu, China; Nanyang Technological University, Singapore, Singapore; The University of Texas at Dallas, Richardson, TX, USA|Submodular optimization has been identified as a powerful tool for many data mining applications, where a representative subset of moderate size needs to be extracted from a large-scale dataset. In scenarios where data points possess sensitive attributes such as age, gender, or race, it becomes imperative to integrate fairness measures into submodular optimization to mitigate bias and discrimination. In this paper, we study the fundamental problem of fair submodular maximization subject to a knapsack constraint and propose the first streaming algorithm for it with provable performance guarantees for both monotone and non-monotone submodular functions. As a byproduct, we also propose a streaming algorithm for submodular maximization subject to a partition matroid and a knapsack constraint, significantly improving the performance bounds achieved by previous work. We conduct extensive experiments on real-world applications such as movie recommendation, image summarization, and maximum coverage in social networks. The experimental results strongly demonstrate the superiority of our proposed algorithms in terms of both fairness and utility.|子模块优化已被确定为许多数据挖掘应用程序的强大工具，其中需要从大规模数据集中提取中等规模的代表性子集。在数据点具有敏感属性(如年龄、性别或种族)的情况下，必须将公平措施纳入子模块优化，以减少偏见和歧视。本文研究了背包约束下的公平子模极大化问题，提出了第一种具有单调和非单调子模函数性能保证的流算法。作为一个副产品，我们还提出了一种子模块最大化的流算法，该算法受到分区拟阵和背包约束的影响，显著提高了以前的工作所取得的性能界限。我们在真实世界的应用上进行了广泛的实验，比如电影推荐、图片摘要和社交网络的最大覆盖率。实验结果有力地证明了我们提出的算法在公平性和实用性方面的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+in+Streaming+Submodular+Maximization+Subject+to+a+Knapsack+Constraint)|0|
|[AGS-GNN: Attribute-guided Sampling for Graph Neural Networks](https://doi.org/10.1145/3637528.3671940)|Siddhartha Shankar Das, S. M. Ferdous, Mahantesh M. Halappanavar, Edoardo Serra, Alex Pothen|Purdue University, West Lafayette, IN, USA; Boise State University, Boise, ID, USA; Pacific Northwest National Lab., Richland, WA, USA|We propose AGS-GNN, a novel attribute-guided sampling algorithm for Graph Neural Networks (GNNs). AGS-GNN exploits the node features and the connectivity structure of a graph while simultaneously adapting for both homophily and heterophily in graphs. In homophilic graphs, vertices of the same class are more likely to be adjacent, but vertices of different classes tend to be adjacent in heterophilic graphs. GNNs have been successfully applied to homophilic graphs, but their utility to heterophilic graphs remains challenging. The state-of-the-art GNNs for heterophilic graphs use the full neighborhood of a node instead of sampling it, and hence do not scale to large graphs and are not inductive. We develop dual-channel sampling techniques based on feature-similarity and feature-diversity to select subsets of neighbors for a node that capture adaptive information from homophilic and heterophilic neighborhoods. Currently, AGS-GNN is the only algorithm that explicitly controls homophily in the sampled subgraph through similar and diverse neighborhood samples. For diverse neighborhood sampling, we employ submodularity, a novel contribution in this context. We pre-compute the sampling distribution in parallel, achieving the desired scalability. Using an extensive dataset consisting of 35 small (< 100K nodes) and large (- 100K nodes) homophilic and heterophilic graphs, we demonstrate the superiority of AGS-GNN compared to the state-of-the-art approaches. AGS-GNN achieves test accuracy comparable to the best-performing heterophilic GNNs, even outperforming methods that use the entire graph for node classification. AGS-GNN converges faster than methods that sample neighborhoods randomly, and can be incorporated into existing GNN models that employ node or graph sampling.|提出了一种新的图形神经网络属性导向采样算法 AGS-GNN。AGS-GNN 利用图的节点特征和连通结构，同时适应图的同质性和异质性。在同类图中，同类的顶点更容易相邻，但在异类图中，不同类的顶点更容易相邻。GNN 已经成功地应用于同亲图，但是它们在异亲图中的应用仍然具有挑战性。异质图的最新 GNN 使用节点的完全邻域代替抽样，因此不能伸缩到大图，也不能归纳。我们发展了基于特征相似性和特征多样性的双通道采样技术来选择一个节点的邻居子集，从同类和异类邻居中捕获自适应信息。目前，AGS-GNN 算法是唯一一种通过相似和不同的邻域样本显式控制采样子图同调性的算法。对于不同的邻域抽样，我们采用次模块化，这是在这种情况下的一个新的贡献。我们并行地预先计算了采样分布，达到了预期的可扩展性。使用由35个小(< 100K 节点)和大(- 100K 节点)同质和异质图组成的广泛数据集，我们证明了 AGS-GNN 与最先进的方法相比的优越性。AGS-GNN 获得了与性能最好的异质 GNN 相当的测试精度，甚至优于使用整个图进行节点分类的方法。AGS-GNN 比随机抽样邻域的方法收敛得更快，并且可以合并到采用节点或图抽样的现有 GNN 模型中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AGS-GNN:+Attribute-guided+Sampling+for+Graph+Neural+Networks)|0|
|[Estimated Judge Reliabilities for Weighted Bradley-Terry-Luce Are Not Reliable](https://doi.org/10.1145/3637528.3671907)|Andrew F. Dreher, Etienne Vouga, Donald S. Fussell|The University of Texas at Austin, Austin, TX, USA|There are many applications for which we want to learn a latent scale for subjective properties, such as the excitement of a photo or the legibility of a font; however, obtaining human-labeled data is costly and time-consuming. One oft-used method for acquiring these labels, despite the cost being quadratic in the number of items, is the method of pairwise comparisons since this method minimizes the effect of biases and generally can be used effectively outside of a controlled environment. Crowdsourcing appears to be a panacea since online platforms provide affordable access to numerous people, but these participants, judges, vary in diligence and expertise. Several methods have been proposed to assign weights to judges based on their responses relative to everyone else, the goal being to reduce exposure to poor performers, hopefully upgrading the quality of the data. Our research focuses on two natural extensions to the Bradley-Terry-Luce formulation of scaling that jointly optimize for both scale value and judge weights. While both methods appear to perform at least as well as the unweighted formulation on average with well-behaved judges, we report a previously unknown flaw, revealing that the resultant judge weights should not be interpreted as reliabilities. Consequently, these values should not be leveraged for decisions about the judges, such as for active sampling or to validate the participant pool.|有许多应用程序，我们想要了解一个潜在的规模主观属性，如兴奋的照片或字体的可读性; 然而，获取人类标记的数据是昂贵的和耗时的。一个常用的获取这些标签的方法，尽管成本在项目数量上是二次的，是成对比较的方法，因为这种方法最大限度地减少了偏差的影响，通常可以在受控环境之外有效地使用。众包似乎是一种灵丹妙药，因为在线平台为许多人提供了负担得起的访问途径，但这些参与者、法官在勤奋程度和专业知识方面各不相同。已经提出了几种方法，根据法官相对于其他所有人的答复来确定其权重，目的是减少表现不佳的风险，希望能够提高数据的质量。我们的研究集中在两个自然扩展的布拉德利-特里-卢斯公式的尺度，共同优化的标度值和判断权重。虽然这两种方法在表现良好的法官中表现至少和未加权公式一样好，但我们报告了一个以前未知的缺陷，揭示了由此产生的法官权重不应该被解释为可靠性。因此，不应该将这些值用于有关法官的决策，例如用于主动抽样或验证参与者池。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Estimated+Judge+Reliabilities+for+Weighted+Bradley-Terry-Luce+Are+Not+Reliable)|0|
|[Influence Maximization via Graph Neural Bandits](https://doi.org/10.1145/3637528.3671983)|Yuting Feng, Vincent Y. F. Tan, Bogdan Cautis|; CNRS LISN, University of Paris-Saclay, Orsay, France; Department of Mathematics, Department of ECE, National University of Singapore, Singapore, Singapore|We consider a ubiquitous scenario in the study of Influence Maximization(IM), in which there is limited knowledge about the topology of the diffusionnetwork. We set the IM problem in a multi-round diffusion campaign, aiming tomaximize the number of distinct users that are influenced. Leveraging thecapability of bandit algorithms to effectively balance the objectives ofexploration and exploitation, as well as the expressivity of neural networks,our study explores the application of neural bandit algorithms to the IMproblem. We propose the framework IM-GNB (Influence Maximization with GraphNeural Bandits), where we provide an estimate of the users' probabilities ofbeing influenced by influencers (also known as diffusion seeds). This initialestimate forms the basis for constructing both an exploitation graph and anexploration one. Subsequently, IM-GNB handles the exploration-exploitationtradeoff, by selecting seed nodes in real-time using Graph ConvolutionalNetworks (GCN), in which the pre-estimated graphs are employed to refine theinfluencers' estimated rewards in each contextual setting. Through extensiveexperiments on two large real-world datasets, we demonstrate the effectivenessof IM-GNB compared with other baseline methods, significantly improving thespread outcome of such diffusion campaigns, when the underlying network isunknown.|在影响最大化(IM)的研究中，我们考虑了一个无处不在的场景，其中关于扩散网络的拓扑结构的知识是有限的。我们将 IM 问题设置为一个多轮扩散运动，目的是最大限度地增加受影响的不同用户的数量。利用强盗算法的能力来有效地平衡勘探和开发的目标，以及神经网络的表达能力，我们的研究探索了神经强盗算法在 IMN 问题中的应用。我们提出了 IM-GNB (影响最大化与图形神经绑定)的框架，其中我们提供了一个估计的用户的概率受影响者(也称为扩散种子)的影响。这个初始估计是构造开发图和开发图的基础。随后，IM-GNB 通过使用图卷积网络(Graph ConvolutionalNetworks，GCN)实时选择种子节点来处理探索-开发权衡，其中预估图被用于在每个上下文环境中细化影响者的估计奖励。通过在两个大型真实世界数据集上的广泛实验，我们证明了 IM-GNB 与其他基线方法相比的有效性，显着改善了这种扩散运动的传播结果，当底层网络是未知的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Influence+Maximization+via+Graph+Neural+Bandits)|0|
|[A Unified Core Structure in Multiplex Networks: From Finding the Densest Subgraph to Modeling User Engagement](https://doi.org/10.1145/3637528.3672011)|Farnoosh Hashemi, Ali Behrouz|Cornell University, Ithaca, NY, USA|In many complex systems, the interactions between objects span multipleaspects. Multiplex networks are accurate paradigms to model such systems, whereeach edge is associated with a type. A key graph mining primitive is extractingdense subgraphs, and this has led to interesting notions such as K-cores, knownas building blocks of complex networks. Despite recent attempts to extend thenotion of core to multiplex networks, existing studies suffer from a subset ofthe following limitations: They 1) force all nodes to exhibit their high degreein the same set of relation types while in multiplex networks some connectiontypes can be noisy for some nodes, 2) either require high computational cost ormiss the complex information of multiplex networks, and 3) assume the sameimportance for all relation types. We introduce S-core, a novel and unifyingfamily of dense structures in multiplex networks that uses a function S(.) tosummarize the degree vector of each node. We then discuss how one can choose aproper S(.) from the data. To demonstrate the usefulness of S-cores, we focuson finding the densest subgraph as well as modeling user engagement inmultiplex networks. We present a new density measure in multiplex networks anddiscuss its advantages over existing density measures. We show that the problemof finding the densest subgraph in multiplex networks is NP-hard and design anefficient approximation algorithm based on S-cores. Finally, we present a newmathematical model of user engagement in the presence of different relationtypes. Our experiments shows the efficiency and effectiveness of our algorithmsand supports the proposed mathematical model of user engagement.|在许多复杂系统中，对象之间的交互跨越多个方面。多路网络是模拟这种系统的精确范例，其中每个边都与一个类型相关联。一个关键的图挖掘原语是提取稠密子图，这导致了一些有趣的概念，如 K 核，即复杂网络的构建块。尽管最近试图将核心概念扩展到多路网络，但现有的研究存在以下局限性的子集: 1)迫使所有节点在同一组关系类型中表现出高度的高度，而在多路网络中，一些连接类型对于某些节点可能是噪声的，2)要么需要高计算成本，要么忽略多路网络的复杂信息，3)对所有关系类型承担同样的重要性。我们介绍了 S- 核，一个新的和统一的密集结构家族在多路网络中使用一个函数 S (。)汇总每个节点的度向量。然后我们讨论如何选择一个合适的 S (。)从数据中。为了证明 S 核的有效性，我们着重于寻找密度最大的子图，以及在多路网络中建立用户参与模型。提出了一种新的多路网络密度度量方法，并讨论了它相对于现有密度度量方法的优越性。我们证明了在多路网络中寻找最密集子图的问题是 NP 难的，并且设计了一个基于 S 核的高效近似演算法。最后，我们提出了一个新的数学模型的用户参与在不同的关系类型的存在。实验结果表明了该算法的有效性，并支持所提出的用户参与的数学模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Unified+Core+Structure+in+Multiplex+Networks:+From+Finding+the+Densest+Subgraph+to+Modeling+User+Engagement)|0|
|[Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals](https://doi.org/10.1145/3637528.3671833)|Marco Heyden, Vadim Arzamasov, Edouard Fouché, Klemens Böhm|Karlsruhe Institute of Technology, Karlsruhe, Germany|We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a player chooses from K arms with unknown expected rewards and costs. The goal is to maximize the total reward under a budget constraint. A player thus seeks to choose the arm with the highest reward-cost ratio as often as possible. Current approaches for this problem have several issues, which we illustrate. To overcome them, we propose a new upper confidence bound (UCB) sampling policy, ømega-UCB, that uses asymmetric confidence intervals. These intervals scale with the distance between the sample mean and the bounds of a random variable, yielding a more accurate and tight estimation of the reward-cost ratio compared to our competitors. We show that our approach has sublinear instance-dependent regret in general and logarithmic regret for parameter ρ ≥ 1, and that it outperforms existing policies consistently in synthetic and real settings.|我们研究随机预算多臂老虎机(MAB)问题，其中玩家从 k 武器选择未知的预期回报和成本。我们的目标是最大化预算线下的总回报。因此，玩家尽可能多地选择奖励成本比率最高的手臂。目前解决这个问题的方法有几个问题，我们将举例说明。为了克服这些问题，我们提出了一种新的上置信区间(UCB)抽样策略，使用非对称置信区间。这些区间随着样本平均值和随机变量界限之间的距离而变化，与我们的竞争对手相比，可以得到更准确和严格的报酬-成本比率估计。我们证明了我们的方法在一般情况下具有次线性实例依赖遗憾和参数 ρ ≥1的对数遗憾，并且它在合成和实际情况下一致地优于现有的策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Budgeted+Multi-Armed+Bandits+with+Asymmetric+Confidence+Intervals)|0|
|[Can Modifying Data Address Graph Domain Adaptation?](https://doi.org/10.1145/3637528.3672058)|Renhong Huang, Jiarong Xu, Xin Jiang, Ruichuan An, Yang Yang|Zhejiang University & Fudan University, Hangzhou, China; Fudan University, Shanghai, China; Lehigh University, Bethlehem, PA, USA; Xi'an Jiaotong University, Xi'an, China; Zhejiang University, Hangzhou, China|Graph neural networks (GNNs) have demonstrated remarkable success in numerous graph analytical tasks. Yet, their effectiveness is often compromised in real-world scenarios due to distribution shifts, limiting their capacity for knowledge transfer across changing environments or domains. Recently, Unsupervised Graph Domain Adaptation (UGDA) has been introduced to resolve this issue. UGDA aims to facilitate knowledge transfer from a labeled source graph to an unlabeled target graph. Current UGDA efforts primarily focus on model-centric methods, such as employing domain invariant learning strategies and designing model architectures. However, our critical examination reveals the limitations inherent to these model-centric methods, while a data-centric method allowed to modify the source graph provably demonstrates considerable potential. This insight motivates us to explore UGDA from a data-centric perspective. By revisiting the theoretical generalization bound for UGDA, we identify two data-centric principles for UGDA: alignment principle and rescaling principle. Guided by these principles, we propose GraphAlign, a novel UGDA method that generates a small yet transferable graph. By exclusively training a GNN on this new graph with classic Empirical Risk Minimization (ERM), GraphAlign attains exceptional performance on the target graph. Extensive experiments under various transfer scenarios demonstrate the GraphAlign outperforms the best baselines by an average of 2.16%, training on the generated graph as small as 0.25~1% of the original training graph.|图形神经网络(GNN)在许多图形分析任务中取得了显著的成功。然而，在现实世界中，由于分布变化，它们的有效性往往受到影响，限制了它们在不断变化的环境或领域中进行知识转移的能力。近年来，无监督图域自适应技术(UGDA)被引入解决这一问题。UGDA 的目的是促进知识从一个有标记的源图向一个无标记的目标图的转移。目前 UGDA 的工作主要集中在以模型为中心的方法上，如使用领域不变学习策略和设计模型体系结构。然而，我们的批判性研究揭示了这些以模型为中心的方法固有的局限性，而允许修改源图的以数据为中心的方法证明了相当大的潜力。这种洞察力促使我们从以数据为中心的角度探索 UGDA。通过回顾 UGDA 的理论推广界限，我们确定了 UGDA 的两个以数据为中心的原则: 对齐原则和重标度原则。在这些原则的指导下，我们提出了 GraphAlign，一种新颖的 UGDA 方法，它可以生成一个小而可转移的图。通过使用经典的经验风险最小化(ERM)在这个新图上专门训练 GNN，GraphAlign 在目标图上获得了出色的性能。在各种传输场景下进行的大量实验表明，GraphAlign 的性能平均比最佳基线高出2.16% ，在生成的图上进行训练，训练量仅为原始训练图的0.25 ~ 1% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Modifying+Data+Address+Graph+Domain+Adaptation?)|0|
|[Uplift Modelling via Gradient Boosting](https://doi.org/10.1145/3637528.3672019)|Bulat Ibragimov, Anton Vakhrushev|; Sber AI Lab, Moscow, Russian Federation|The Gradient Boosting machine learning ensemble algorithm, well-known for its proficiency and superior performance in intricate machine learning tasks, has encountered limited success in the realm of uplift modeling. Uplift modeling is a challenging task that necessitates a known target for the precise computation of the training gradient. The prevailing two-model strategies, which separately model treatment and control outcomes, are encumbered with limitations as they fail to directly tackle the uplift problem. This paper presents an innovative approach to uplift modeling that employs Gradient Boosting. Unlike previous works, our algorithm utilizes multioutput boosting model and calculates the uplift gradient based on intermediate surrogate predictions and directly models the concealed target. This method circumvents the requirement for a known target and addresses the uplift problem more effectively than existing solutions. Moreover, we broaden the scope of this solution to encompass multitreatment settings, thereby enhancing its applicability. This novel approach not only overcomes the limitations of the traditional two-model strategies but also paves the way for more effective and efficient uplift modeling using Gradient Boosting.|梯度提升机器学习集成算法以其在复杂的机器学习任务中的熟练程度和卓越的性能而闻名，但在提升建模领域却只取得了有限的成功。提升建模是一项具有挑战性的任务，为了精确计算训练梯度，需要一个已知的目标。流行的两个模型的策略，其中单独的模型治疗和控制结果，受到限制，因为他们不能直接解决提升问题。本文提出了一个创新的方法来提升模型的使用梯度提升。与以往的算法不同，该算法采用多输出增强模型，基于中间代理预测计算上升梯度，直接对隐藏目标进行建模。该方法规避了对已知目标的要求，比现有方法更有效地解决了抬升问题。此外，我们扩大了这种解决方案的范围，以包括多种治疗设置，从而增强其适用性。这种新颖的方法不仅克服了传统的双模型策略的局限性，而且为利用梯度提升建立更有效和高效的抬升模型铺平了道路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uplift+Modelling+via+Gradient+Boosting)|0|
|[Mutual Distillation Extracting Spatial-temporal Knowledge for Lightweight Multi-channel Sleep Stage Classification](https://doi.org/10.1145/3637528.3671981)|Ziyu Jia, Haichao Wang, Yucheng Liu, Tianzi Jiang|Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen, China; University of Southern California, Los Angeles, USA; Institute of Automation, Chinese Academy of Science, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China|Sleep stage classification has important clinical significance for the diagnosis of sleep-related diseases. To pursue more accurate sleep stage classification, multi-channel sleep signals are widely used due to the rich spatial-temporal information contained. However, it leads to a great increment in the size and computational costs, which constrain the application of multi-channel sleep models on hardware devices. Knowledge distillation is an effective way to compress models, yet existing knowledge distillation methods cannot fully extract and transfer the spatial-temporal knowledge in the multi-channel sleep signals. To solve the problem, we propose a general knowledge distillation framework for multi-channel sleep stage classification called spatial-temporal mutual distillation. Based on the spatial relationship of human body and the temporal transition rules of sleep signals, the spatial and temporal modules are designed to extract the spatial-temporal knowledge, thus help the lightweight student model learn the rich spatial-temporal knowledge from large-scale teacher model. The mutual distillation framework transfers the spatial-temporal knowledge mutually. Teacher model and student model can learn from each other, further improving the student model. The results on the ISRUC-III and MASS-SS3 datasets show that our proposed framework compresses the sleep models effectively with minimal performance loss and achieves the state-of-the-art performance compared to the baseline methods.|睡眠分期对睡眠相关疾病的诊断具有重要的临床意义。为了追求更准确的睡眠阶段分类，多通道睡眠信号由于包含了丰富的时空信息而被广泛应用。然而，这会导致系统规模和计算成本的大幅度增加，从而限制了多通道睡眠模型在硬件设备上的应用。知识提取是一种有效的模型压缩方法，但现有的知识提取方法不能完全提取和转移多通道睡眠信号中的时空知识。为了解决这个问题，我们提出了一个通用的多通道睡眠阶段分类知识提取框架，称为时空互提取。基于人体的空间关系和睡眠信号的时间转换规则，设计了空间和时间模块来提取时空知识，从而帮助轻量级学生模型从大规模教师模型中学习到丰富的时空知识。相互精馏框架相互传递时空知识。教师模式与学生模式可以相互借鉴，进一步完善学生模式。ISRUC-III 和 MASS-SS3数据集的结果表明，我们提出的框架有效地压缩了睡眠模型，性能损失最小，并达到了最先进的性能相比，基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mutual+Distillation+Extracting+Spatial-temporal+Knowledge+for+Lightweight+Multi-channel+Sleep+Stage+Classification)|0|
|[Masked LoGoNet: Fast and Accurate 3D Image Analysis for Medical Domain](https://doi.org/10.1145/3637528.3672069)|Amin Karimi Monsefi, Payam Karisani, Mengxi Zhou, Stacey Choi, Nathan Doble, Heng Ji, Srinivasan Parthasarathy, Rajiv Ramnath|Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA; Department of Ophthalmology and Visual Science, The Ohio State University, Columbus, OH, USA; Department of Computer Science, University of Illinois Urbana-Champaign, Urbana, IL, USA|Standard modern machine-learning-based imaging methods have faced challenges in medical applications due to the high cost of dataset construction and, thereby, the limited labeled training data available. Additionally, upon deployment, these methods are usually used to process a large volume of data on a daily basis, imposing a high maintenance cost on medical facilities. In this paper, we introduce a new neural network architecture, termed LoGoNet, with a tailored self-supervised learning (SSL) method to mitigate such challenges. LoGoNet integrates a novel feature extractor within a U-shaped architecture, leveraging Large Kernel Attention (LKA) and a dual encoding strategy to capture both long-range and short-range feature dependencies adeptly. This is in contrast to existing methods that rely on increasing network capacity to enhance feature extraction. This combination of novel techniques in our model is especially beneficial in medical image segmentation, given the difficulty of learning intricate and often irregular body organ shapes, such as the spleen. Complementary, we propose a novel SSL method tailored for 3D images to compensate for the lack of large labeled datasets. Our method combines masking and contrastive learning techniques within a multi-task learning framework and is compatible with both Vision Transformer (ViT) and CNN-based models. We demonstrate the efficacy of our methods in numerous tasks across two standard datasets (i.e., BTCV and MSD). Benchmark comparisons with eight state-of-the-art models highlight LoGoNet's superior performance in both inference time and accuracy. Code available at: https://github.com/aminK8/Masked-LoGoNet.|标准的现代机器学习成像方法在医学应用中面临的挑战，由于高成本的数据集建设，从而，有限的标记训练数据可用。此外，在部署时，这些方法通常用于每天处理大量数据，给医疗设施带来高昂的维护成本。在本文中，我们介绍了一种新的神经网络结构，称为 LoGoNet，它采用一种量身定制的自监督学习(SSL)方法来缓解这种挑战。LoGoNet 在 U 形架构中集成了一种新颖的特征提取器，利用大内核注意力(LKA)和双重编码策略来巧妙地捕获长期和短期特征依赖。这与现有的依靠增加网络容量来增强特征提取的方法形成了对比。在我们的模型中，这种新技术的结合在医学图像分割中尤其有益，因为学习复杂且通常不规则的身体器官形状(如脾脏)很困难。作为补充，我们提出了一种新的针对三维图像的 SSL 方法，以弥补缺少大型标记数据集的不足。该方法将掩蔽学习和对比学习技术结合在一个多任务学习框架中，兼容视觉变换器(ViT)和基于 CNN 的模型。我们证明了我们的方法在两个标准数据集(即 BTCV 和 MSD)的许多任务中的有效性。与八个最先进模型的基准比较突出了 LoGoNet 在推断时间和准确性方面的卓越性能。密码:  https://github.com/amink8/masked-logonet。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Masked+LoGoNet:+Fast+and+Accurate+3D+Image+Analysis+for+Medical+Domain)|0|
|[Fast and Accurate Domain Adaptation for Irregular Tensor Decomposition](https://doi.org/10.1145/3637528.3671670)|Junghun Kim, Ka Hyun Park, JunGi Jang, U Kang|University of Illinois at Urbana-Champaign, Illinois, IL, USA; Seoul National University, Seoul, Republic of Korea|Given an irregular tensor from a newly emerging domain, how can we quickly and accurately capture its patterns utilizing existing irregular tensors in multiple domains? The problem is of great importance for various tasks such as finding patterns of a new disease using pre-existing diseases data. This is challenging as new target tensors have limited information due to their recent emergence. Thus, carefully utilizing the existing source tensors for analyzing the target tensor is helpful. PARAFAC2 decomposition is a strong tool for finding the patterns of irregular tensors, and the patterns are used in many applications such as missing value prediction and anomaly detection. However, previous PARAFAC2-based works cannot adaptably handle newly emerging target tensors utilizing the source tensors. In this work, we propose Meta-P2, a fast and accurate domain adaptation method for irregular tensor decomposition. Meta-P2 generates a meta factor matrix from the multiple source domains, by domain adaptation and meta-update steps. Meta-P2 quickly and accurately finds the patterns of the new irregular tensor utilizing the meta factor matrix. Extensive experiments on real-world datasets show that Meta-P2 achieves the best performance in various downstream tasks including missing value prediction and anomaly detection tasks.|假设一个不规则张量来自一个新兴的领域，我们如何能够快速准确地捕捉其模式利用现有的不规则张量在多个领域？这个问题对于各种任务都非常重要，例如利用已有的疾病数据找到新疾病的模式。这是具有挑战性的，因为新的目标张量由于最近的出现而信息有限。因此，仔细利用现有的源张量来分析目标张量是有帮助的。PARAFAC2分解是寻找不规则张量模式的一个强有力的工具，这些模式在许多应用中被使用，例如缺失值预测和异常检测。然而，以往基于 PARAFAC2的工作不能自适应地处理新出现的目标张量利用源张量。在这项工作中，我们提出了 Meta-P2，一个快速和准确的区域自适应方法的不规则张量分解。元 P2通过领域适应和元更新步骤从多个源域生成元因子矩阵。Meta-P2利用元因子矩阵快速准确地找到新的不规则张量的模式。对真实世界数据集的大量实验表明，Meta-p2在各种下游任务(包括缺失值预测和异常检测任务)中取得了最佳性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+and+Accurate+Domain+Adaptation+for+Irregular+Tensor+Decomposition)|0|
|[SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning](https://doi.org/10.1145/3637528.3671845)|Jongha Lee, Sunwoo Kim, Kijung Shin|KAIST, Seoul, Republic of Korea|To detect anomalies in real-world graphs, such as social, email, and financial networks, various approaches have been developed. While they typically assume static input graphs, most real-world graphs grow over time, naturally represented as edge streams. In this context, we aim to achieve three goals: (a) instantly detecting anomalies as they occur, (b) adapting to dynamically changing states, and (c) handling the scarcity of dynamic anomaly labels. In this paper, we propose SLADE (Self-supervised Learning for Anomaly Detection in Edge Streams) for rapid detection of dynamic anomalies in edge streams, without relying on labels. SLADE detects the shifts of nodes into abnormal states by observing deviations in their interaction patterns over time. To this end, it trains a deep neural network to perform two self-supervised tasks: (a) minimizing drift in node representations and (b) generating long-term interaction patterns from short-term ones. Failure in these tasks for a node signals its deviation from the norm. Notably, the neural network and tasks are carefully designed so that all required operations can be performed in constant time (w.r.t. the graph size) in response to each new edge in the input stream. In dynamic anomaly detection across four real-world datasets, SLADE outperforms nine competing methods, even those leveraging label supervision. Our code and datasets are available at https://github.com/jhsk777/SLADE.|为了检测现实世界图表中的异常，如社交、电子邮件和金融网络，已经开发了各种方法。虽然它们通常假设静态输入图，但大多数真实世界的图随着时间的推移而增长，自然地表示为边流。在这种背景下，我们的目标是实现三个目标: (a)在异常发生时即时检测异常，(b)适应动态变化的状态，和(c)处理动态异常标签的稀缺性。在这篇文章中，我们提出了边缘流异常检测的自我监督学习(SLADE)来快速检测边缘流中的动态异常，而不依赖于标签。SLADE 通过观察节点交互模式随时间的变化来检测节点进入异常状态的变化。为此，它训练一个深层神经网络来执行两个自我监督的任务: (a)最小化节点表示的漂移和(b)从短期的产生长期的交互模式。节点在这些任务中的失败表明它偏离了规范。值得注意的是，神经网络和任务都经过了精心设计，以便所有需要的操作都可以在不变的时间内执行(图形大小) ，以响应输入流中的每个新边缘。在跨越四个现实世界数据集的动态异常检测中，SLADE 的表现优于9种竞争方法，甚至优于那些利用标签监督的方法。我们的代码和数据集 https://github.com/jhsk777/slade 可用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SLADE:+Detecting+Dynamic+Anomalies+in+Edge+Streams+without+Labels+via+Self-Supervised+Learning)|0|
|[Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity](https://doi.org/10.1145/3637528.3671835)|Dongyue Li, Aneesh Sharma, Hongyang R. Zhang|Northeastern University, Boston, USA; Google, Mountain View, USA|Multitask learning is a widely used paradigm for training models on diverse tasks, with applications ranging from graph neural networks to language model fine-tuning. Since tasks may interfere with each other, a key notion for modeling their relationships is task affinity. This includes pairwise task affinity, computed among pairs of tasks, and higher-order affinity, computed among subsets of tasks. Naively computing either of them requires repeatedly training on data pooled from various task combinations, which is computationally intensive. We present a new algorithm Grad-TAG that can estimate task affinities without this repeated training. The key idea of Grad-TAG is to train a "base" model for all tasks and then use a linearization technique to estimate the loss of any other model with a specific task combination. The linearization works by computing a gradient-based first-order approximation of the loss, using low-dimensional projections of gradients as features in a logistic regression trained to predict labels for the specific task combination. We show theoretically that the linearized model can provably approximate the loss when the gradient-based approximation is accurate, and also empirically verify that on several large models. Then, given the estimated task affinity matrix, we design a semi-definite program for clustering to group similar tasks that maximize the average density of clusters. We evaluate Grad-TAG's performance across seven datasets, including multi-label classification on graphs, and instruction fine-tuning of language models. Our results show that our task affinity estimates are within 2.7% distance of the true affinities while needing only 3% of FLOPs compared to full training. On our largest graph with 21M edges and 500 labeling tasks, our algorithm delivers an estimate accurate to within 5% of the true affinities, while using only 112.3 GPU hours. Our results show that Grad-TAG achieves excellent performance and runtime tradeoffs compared to existing approaches.|多任务学习是一种广泛应用于不同任务的训练模型，应用范围从图形神经网络到语言模型微调。由于任务之间可能会相互干扰，因此对它们的关系进行建模的一个关键概念是任务相关性。这包括成对任务关联(在任务对之间计算)和高阶关联(在任务子集之间计算)。天真地计算其中任何一个都需要对从各种任务组合中汇集的数据进行反复训练，这是计算密集型的。我们提出了一种新的算法梯度 TAG，可以估计任务的亲和力，而无需这种重复的训练。梯度 TAG 的核心思想是为所有任务训练一个“基本”模型，然后使用线性化技术估计任何其他模型与特定任务组合的损失。线性化的工作原理是通过计算基于梯度的一阶近似损失，使用梯度的低维投影作为特征的 Logit模型训练来预测特定任务组合的标签。从理论上证明了当基于梯度的近似准确时，线性化模型可以有效地逼近损失，并在几个大型模型上进行了实验验证。然后，给出估计的任务亲和矩阵，设计一个半确定的聚类程序，将相似的任务分组，最大化聚类的平均密度。我们评估了 Grad-TAG 在七个数据集上的性能，包括图的多标签分类和语言模型的指令微调。我们的研究结果表明，我们的任务亲和力估计在2.7% 的距离真正的亲和力，而只需要3% 的 FLOP 相比，充分训练。在我们最大的21M 边和500个标记任务的图表中，我们的算法只使用了112.3 GPU 时间，但是估计的精确度在真实亲和力的5% 以内。我们的研究结果表明，与现有的方法相比，Grad-TAG 实现了出色的性能和运行时折衷。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Multitask+Learning+Using+Gradient-based+Estimation+of+Task+Affinity)|0|
|[Truthful Bandit Mechanisms for Repeated Two-stage Ad Auctions](https://doi.org/10.1145/3637528.3671813)|Haoming Li, Yumou Liu, Zhenzhe Zheng, Zhilin Zhang, Jian Xu, Fan Wu|Alibaba Group, Beijing, China; Shanghai Jiao Tong University, Shanghai, China; The Chinese University of Hong Kong, Shenzhen, Shenzhen, China|Online advertising platforms leverage a two-stage auction architecture to deliver personalized ads to users with low latency. The first stage efficiently selects a small subset of promising candidates out of the complete pool of ads. In the second stage, an auction is conducted within the subset to determine the winning ad for display, using click-through-rate predictions from the second-stage machine learning model. In this work, we investigate the online learning process of the first-stage subset selection policy, while ensuring game-theoretic properties in repeated two-stage ad auctions. Specifically, we model the problem as designing a combinatorial bandit mechanism with a general reward function, as well as additional requirements of truthfulness and individual rationality (IR). We establish an O(T) regret lower bound for truthful bandit mechanisms, which demonstrates the challenge of simultaneously achieving allocation efficiency and truthfulness. To circumvent this impossibility result, we introduce truthful α-approximation oracles and evaluate the bandit mechanism through α-approximation regret. Two mechanisms are proposed, both of which are ex-post truthful and ex-post IR. The first mechanism is an explore-then-commit mechanism with regret O(T2/3 ), and the second mechanism achieves an improved O(log T /ΔΦ2) regret where ΔΦ is a distribution-dependent gap, but requires additional assumptions on the oracles and information about the strategic bidders.|在线广告平台利用两阶段拍卖架构向低延迟的用户提供个性化广告。第一阶段有效地从完整的广告库中选出一小部分有前途的候选人。在第二阶段，使用第二阶段机器学习模型的点击率预测，在子集内进行拍卖，以确定用于显示的获胜广告。本文在保证重复两阶段广告拍卖的博弈性质的前提下，研究了第一阶段子集选择策略的在线学习过程。具体地说，我们将这个问题建模为具有一般奖励函数的组合强盗机制的设计，以及对真实性和个体理性的附加要求。我们建立了真实性盗贼机制的 O (T)后悔下限，这表明了同时实现分配效率和真实性的挑战。为了避免这种不可能的结果，我们引入了真实的 α-近似神谕，并通过 α-近似悔恨来评估盗贼的机制。提出了两种机制，即事后真实机制和事后信息检索机制。第一种机制是带有遗憾 O (T2/3)的探索-然后提交机制，第二种机制实现了一个改进的 O (log T/ΔΦ2)遗憾，其中 ΔΦ 是一个分布依赖的缺口，但需要额外的先知假设和关于战略投标人的信息。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Truthful+Bandit+Mechanisms+for+Repeated+Two-stage+Ad+Auctions)|0|
|[Self-Distilled Disentangled Learning for Counterfactual Prediction](https://doi.org/10.1145/3637528.3671782)|Xinshu Li, Mingming Gong, Lina Yao|The University of Melbourne & MBZUAI, Melbourne, Australia; The University of New South Wales, Sydney, Australia; CSIRO's Data61 & The University of New South Wales, Sydney, Australia|The advancements in disentangled representation learning significantlyenhance the accuracy of counterfactual predictions by granting precise controlover instrumental variables, confounders, and adjustable variables. Anappealing method for achieving the independent separation of these factors ismutual information minimization, a task that presents challenges in numerousmachine learning scenarios, especially within high-dimensional spaces. Tocircumvent this challenge, we propose the Self-Distilled Disentanglementframework, referred to as SD^2. Grounded in information theory, it ensurestheoretically sound independent disentangled representations without intricatemutual information estimator designs for high-dimensional representations. Ourcomprehensive experiments, conducted on both synthetic and real-world datasets,confirms the effectiveness of our approach in facilitating counterfactualinference in the presence of both observed and unobserved confounders.|在分离表征学习的进步显着提高准确性的反事实预测授予精确控制工具变量，混杂因素和可调变量。实现这些因素独立分离的一个有吸引力的方法是相互信息最小化，这个任务在许多机器学习场景中提出了挑战，特别是在高维空间中。为了规避这个挑战，我们提出了自我提取的分离框架，称为 SD ^ 2。它以信息论为理论基础，保证了理论上独立的解纠缠表示，而不需要对高维表示进行复杂的互信息估计器设计。我们在合成和真实世界数据集上进行的综合实验证实了我们的方法在促进反事实推理方面的有效性，在观察到和未观察到的混杂因素存在的情况下。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Distilled+Disentangled+Learning+for+Counterfactual+Prediction)|0|
|[Predicting Long-term Dynamics of Complex Networks via Identifying Skeleton in Hyperbolic Space](https://doi.org/10.1145/3637528.3671968)|Ruikun Li, Huandong Wang, Jinghua Piao, Qingmin Liao, Yong Li|Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Electronic Engineering BNRist, Tsinghua University, Beijing, China|Learning complex network dynamics is fundamental for understanding, modeling, and controlling real-world complex systems. Though great efforts have been made to predict the future states of nodes on networks, the capability of capturing long-term dynamics remains largely limited. This is because they overlook the fact that long-term dynamics in complex network are predominantly governed by their inherent low-dimensional manifolds, i.e., skeletons. Therefore, we propose the Dynamics-Invariant Skeleton Neural Network (DiskNet), which identifies skeletons of complex networks based on the renormalization group structure in hyperbolic space to preserve both topological and dynamics properties. Specifically, we first condense complex networks with various dynamics into simple skeletons through physics-informed hyperbolic embeddings. Further, we design graph neural ordinary differential equations to capture the condensed dynamics on the skeletons. Finally, we recover the skeleton networks and dynamics to the original ones using a degree-based super-resolution module. Extensive experiments across three representative dynamics as well as five real-world and two synthetic networks demonstrate the superior performances of the proposed DiskNet, which outperforms the state-of-the-art baselines by an average of 10.18% in terms of long-term prediction accuracy. Code for reproduction is available at: https://github.com/tsinghua-fib-lab/DiskNet.|学习复杂网络动力学是理解、建模和控制现实世界复杂系统的基础。尽管人们在预测网络节点的未来状态方面做出了巨大的努力，但是捕捉长期动态的能力仍然受到很大的限制。这是因为他们忽略了这样一个事实，即复杂网络中的长期动力学主要受其固有的低维流形支配，即骨架。因此，我们提出了动力学不变骨架神经网络(diskNet) ，它基于重整化群的双曲空间结构来识别复杂网络的骨架，以保持拓扑和动力学特性。具体来说，我们首先通过基于物理信息的双曲嵌入将具有各种动力学的复杂网络压缩成简单的骨架。进一步，我们设计图形神经元常微分方程来捕捉骨架上的凝聚动力学。最后，我们使用基于度的超分辨率模型恢复骨架网络和动力学模型。在三个有代表性的动态以及五个真实世界和两个合成网络上进行的广泛实验证明了所提议的 DiskNet 的优越性能，它在长期预测准确性方面比最先进的基线平均高出10.18% 。复制代码可在以下 https://github.com/tsinghua-fib-lab/disknet 找到:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Long-term+Dynamics+of+Complex+Networks+via+Identifying+Skeleton+in+Hyperbolic+Space)|0|
|[Image Similarity Using an Ensemble of Context-Sensitive Models](https://doi.org/10.1145/3637528.3672004)|Zukang Liao, Min Chen|University of Oxford, Oxford, United Kingdom|Image similarity has been extensively studied in computer vision. In recent years, machine-learned models have shown their ability to encode more semantics than traditional multivariate metrics. However, in labelling semantic similarity, assigning a numerical score to a pair of images is impractical, making the improvement and comparisons on the task difficult. In this work, we present a more intuitive approach to build and compare image similarity models based on labelled data in the form of A:R vs B:R, i.e., determining if an image A is closer to a reference image R than another image B. We address the challenges of sparse sampling in the image space (R, A, B) and biases in the models trained with context-based data by using an ensemble model. Our testing results show that the ensemble model constructed performs ~5% better than the best individual context-sensitive models. They also performed better than the models that were directly fine-tuned using mixed imagery data as well as existing deep embeddings, e.g., CLIP [30] and DINO [3]. This work demonstrates that context-based labelling and model training can be effective when an appropriate ensemble approach is used to alleviate the limitation due to sparse sampling.|图像相似性在计算机视觉中得到了广泛的研究。近年来，机器学习模型已经显示出它们比传统的多元度量标准具有更强的语义编码能力。然而，在标注语义相似度时，为一对图像分配一个数值得分是不切实际的，这给任务的改进和比较带来了困难。在这项工作中，我们提出了一个更直观的方法来建立和比较图像相似性模型的基础上的标记数据的形式 A: R 对 B: R，即，确定是否一个图像 A 更接近一个参考图像 R 比另一个图像 B。针对图像空间(R，A，B)的稀疏采样和基于上下文数据训练的模型中的偏差问题，提出了一种集成模型。我们的测试结果表明，所构建的集成模型比最好的个体上下文敏感模型的性能要好约5% 。他们也比使用混合图像数据以及现有的深度嵌入(例如 CLIP [30]和 DINO [3])直接微调的模型表现得更好。这项工作表明，基于上下文的标记和模型训练可以有效地使用适当的集成方法，以减轻由于稀疏抽样的限制。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Image+Similarity+Using+an+Ensemble+of+Context-Sensitive+Models)|0|
|[Neural Collapse Inspired Debiased Representation Learning for Min-max Fairness](https://doi.org/10.1145/3637528.3671902)|Shenyu Lu, Junyi Chai, Xiaoqian Wang|Purdue University, West Lafayette, IN, USA|Although machine learning algorithms demonstrate impressive performance, their trustworthiness remains a critical issue, particularly concerning fairness when implemented in real-world applications. Many notions of group fairness aim to minimize disparities in performance across protected groups. However, it can inadvertently reduce performance in certain groups, leading to sub-optimal outcomes. In contrast, Min-max group fairness notion prioritizes the improvement for the worst-performing group, thereby advocating a utility-promoting approach to fairness. However, it has been proven that existing efforts to achieve Min-max fairness exhibit limited effectiveness. In response to this challenge, we leverage the recently proposed "Neural Collapse'' framework to re-examine Empirical Risk Minimization (ERM) training, specifically investigating the root causes of poor performance in minority groups. The layer-peeled model is employed to decompose a network into two parts: an encoder to learn latent representation, and a subsequent classifier, with a systematic characterization of their training behaviors being conducted. Our analysis reveals that while classifiers achieve maximum separation, the separability of representations is insufficient, particularly for minority groups. This indicates the sub-optimal performance in minority groups stems from less separable representations, rather than classifiers. To tackle this issue, we introduce a novel strategy that incorporates a frozen classifier to directly enhance representation. Furthermore, we introduce two easily implemented loss functions to guide the learning process. The experimental assessments carried out on real-world benchmark datasets spanning the domains of Computer Vision, Natural Language Processing, and Tabular data demonstrate that our approach outperforms existing state-of-the-art methods in promoting the Min-max fairness notion.|尽管机器学习算法表现出了令人印象深刻的性能，但它们的可信性仍然是一个关键问题，特别是在实际应用中实现时的公平性。群体公平的许多概念旨在最大限度地缩小不同受保护群体之间的绩效差距。然而，它可能无意中降低某些群体的绩效，导致次优结果。相比之下，最小-最大群体公平理念优先考虑绩效最差群体的改善，从而提倡效用促进的公平方法。然而，已经证明现有的实现最小最大公平性的努力效果有限。为了应对这一挑战，我们利用最近提出的“神经崩溃”框架来重新审视经验风险最小化(ERM)训练，特别是调查少数群体表现不佳的根本原因。分层剥离模型被用来将网络分解为两部分: 一个编码器来学习潜在表征，一个后续的分类器，系统的角色塑造他们的训练行为被执行。我们的分析表明，虽然量词实现了最大的分离，但表征的可分性是不够的，特别是对于少数群体。这表明少数群体的次优性能源于较少的可分离表示，而不是分类器。为了解决这个问题，我们引入了一个新的策略，包括一个冻结的分类器，直接增强表示。此外，我们还引入了两个易于实现的损失函数来指导学习过程。对计算机视觉、自然语言处理和表格数据领域的现实世界基准数据集进行的实验评估表明，我们的方法在促进最小最大公平概念方面优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Collapse+Inspired+Debiased+Representation+Learning+for+Min-max+Fairness)|0|
|[AdaGMLP: AdaBoosting GNN-to-MLP Knowledge Distillation](https://doi.org/10.1145/3637528.3671699)|Weigang Lu, Ziyu Guan, Wei Zhao, Yaming Yang|Xidian University, Xi'an, Shannxi, China; Xidian University, Xi'an, Shaanxi, China|Graph Neural Networks (GNNs) have revolutionized graph-based machinelearning, but their heavy computational demands pose challenges forlatency-sensitive edge devices in practical industrial applications. Inresponse, a new wave of methods, collectively known as GNN-to-MLP KnowledgeDistillation, has emerged. They aim to transfer GNN-learned knowledge to a moreefficient MLP student, which offers faster, resource-efficient inference whilemaintaining competitive performance compared to GNNs. However, these methodsface significant challenges in situations with insufficient training data andincomplete test data, limiting their applicability in real-world applications.To address these challenges, we propose AdaGMLP, an AdaBoosting GNN-to-MLPKnowledge Distillation framework. It leverages an ensemble of diverse MLPstudents trained on different subsets of labeled nodes, addressing the issue ofinsufficient training data. Additionally, it incorporates a Node Alignmenttechnique for robust predictions on test data with missing or incompletefeatures. Our experiments on seven benchmark datasets with different settingsdemonstrate that AdaGMLP outperforms existing G2M methods, making it suitablefor a wide range of latency-sensitive real-world applications. We havesubmitted our code to the GitHub repository(https://github.com/WeigangLu/AdaGMLP-KDD24).|图形神经网络(GNN)已经给基于图的机器学习带来了革命性的变化，但是它们繁重的计算需求给实际工业应用中的延迟敏感边缘设备带来了挑战。响应，一个新的方法的浪潮，统称为 GNN 到 MLP 知识蒸馏，已经出现。他们的目标是将 GNN 学到的知识传授给一个更有效率的 MLP 学生，MLP 学生能够提供更快速、资源效率更高的推理，同时保持与 GNN 学生相比的竞争力。然而，这些方法在训练数据不足和测试数据不完整的情况下面临着重大挑战，限制了它们在实际应用中的适用性。为了解决这些挑战，我们提出 AdaGMLP，一个 AdaBoosted GNN-to-MLP 知识提取框架。它利用不同的 MLP 学生在不同的标记节点子集上接受训练的集合，解决了训练数据不足的问题。此外，它还结合了节点对齐技术，用于对缺少或不完整特性的测试数据进行健壮的预测。我们在七个不同设置的基准数据集上的实验表明，AdaGMLP 优于现有的 G2M 方法，使其适用于各种对延迟敏感的现实世界应用。我们已经将代码提交给了 GitHub 存储库( https://GitHub.com/weiganglu/adagmlp-kdd24)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaGMLP:+AdaBoosting+GNN-to-MLP+Knowledge+Distillation)|0|
|[Handling Varied Objectives by Online Decision Making](https://doi.org/10.1145/3637528.3671812)|Lanjihong Ma, ZhenYu Zhang, YaoXiang Ding, ZhiHua Zhou|; Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan; State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China|Conventional machine learning typically assume a fixed learning objective throughout the learning process. However, for real-world tasks in open and dynamic environments, objectives can change frequently. For example, in autonomous driving, a car has several default modes, but a user's concern for speed and fuel consumption varies depending on road conditions and personal needs. We formulate this problem as learning with varied objectives (LVO), where the goal is to optimize a dynamic weighted combination of multiple sub-objectives by sequentially selecting actions that incur different losses on these sub-objectives. We propose the VaRons algorithm, which estimates the action-wise performance on each sub-objective and adaptively selects decisions according to the dynamic requirements on different sub-objectives. Further, we extend our approach to cases involving contextual representations and propose the ConVaRons algorithm, assuming parameterized linear structure that links contextual features to the main objective. Both the VaRons and ConVaRons are provably minimax optimal with respect to the time horizon T, with ConVaRons showing better dependency with the number of sub-objectives K. Experiments on dynamic classifier and real-world cluster service allocation tasks validate the effectiveness of our methods and support our theoretical findings.|传统的机器学习通常在整个学习过程中假定一个固定的学习目标。然而，对于开放和动态环境中的实际任务，目标可能会频繁变化。例如，在自动驾驶中，汽车有几种默认模式，但是用户对于速度和油耗的关注取决于路况和个人需求。我们将这个问题表述为具有不同目标(LVO)的学习，其目标是通过依次选择在这些子目标上导致不同损失的行动来优化多个子目标的动态加权组合。我们提出了 VaRons 算法，该算法估计每个子目标的行动性能，并根据不同子目标的动态需求自适应地选择决策。进一步，我们将我们的方法扩展到涉及上下文表示的情况，并提出了 ConVaRons 算法，假设参数化的线性结构，连接上下文特征的主要目标。VaRons 和 ConVaRons 都可证明是最小最优的时间范围 T，与 ConVaRons 显示更好的依赖与子目标的数量 K 的实验动态分类器和现实世界的集群服务分配任务验证了我们的方法的有效性，并支持我们的理论研究结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Handling+Varied+Objectives+by+Online+Decision+Making)|0|
|[Quantifying and Estimating the Predictability Upper Bound of Univariate Numeric Time Series](https://doi.org/10.1145/3637528.3671995)|Jamal Mohammed, Michael H. Böhlen, Sven Helmer|University of Zurich, Zurich, Switzerland|The intrinsic predictability of a given time series indicates how well an (ideal) algorithm could potentially predict it when trained on the time series data. Being able to compute the intrinsic predictability helps the developers of prediction algorithms immensely in deciding whether there is further optimization potential, as it tells them how close they are to what is (theoretically) achievable. We call the intrinsic predictability the predictability upper bound ¶imax and propose a novel method for quantifying and estimating it for univariate numeric time series. So far, this has only been done for symbolic time series, even though most real-world time series are numeric by nature. We base our technique on the close relationship between entropy and predictability, utilizing the entropy rate of a time series to compute ¶imax . Since existing entropy rate estimators, such as those based on the Lempel-Ziv compression algorithm, only work for symbolic data, we develop new estimators using tolerance thresholds for matching numeric values. We demonstrate that ¶imax is an effective upper bound that characterizes the intrinsic predictability of a time series. We give formal proofs and we validate our arguments experimentally by comparing ¶imax with the prediction accuracy of different state-of-the-art models on various real-world datasets from different domains.|给定时间序列的内在可预测性表明(理想的)算法在对时间序列数据进行训练时能够很好地预测它。能够计算内在的可预测性对预测算法的开发人员决定是否存在进一步的优化潜力有很大的帮助，因为它告诉他们离(理论上)可实现的目标有多近。本文将内在可预测性称为可预测性上界 imax，提出了一种新的单变量数值时间序列的可预测性上界的量化和估计方法。到目前为止，这只是针对符号时间序列，尽管大多数现实世界的时间序列本质上是数字的。我们的技术基于熵和可预测性之间的密切关系，利用时间序列的熵率来计算 imax。由于现有的熵速率估计器，例如基于 Lempel-Ziv 压缩算法的熵速率估计器，只对符号数据起作用，因此我们使用容差阈值来对数值进行匹配。我们证明了 imax 是表征时间序列内在可预测性的一个有效上界。我们给出了形式上的证明，并且通过比较 imax 与不同领域的不同现实世界数据集上不同最新模型的预测精度，实验验证了我们的论点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+and+Estimating+the+Predictability+Upper+Bound+of+Univariate+Numeric+Time+Series)|0|
|[Scalable Rule Lists Learning with Sampling](https://doi.org/10.1145/3637528.3671989)|Leonardo Pellegrina, Fabio Vandin|Dept. of Information Engineering, University of Padova, Padova, Italy|Learning interpretable models has become a major focus of machine learningresearch, given the increasing prominence of machine learning in sociallyimportant decision-making. Among interpretable models, rule lists are among thebest-known and easily interpretable ones. However, finding optimal rule listsis computationally challenging, and current approaches are impractical forlarge datasets. We present a novel and scalable approach to learn nearly optimal rule listsfrom large datasets. Our algorithm uses sampling to efficiently obtain anapproximation of the optimal rule list with rigorous guarantees on the qualityof the approximation. In particular, our algorithm guarantees to find a rulelist with accuracy very close to the optimal rule list when a rule list withhigh accuracy exists. Our algorithm builds on the VC-dimension of rule lists,for which we prove novel upper and lower bounds. Our experimental evaluation onlarge datasets shows that our algorithm identifies nearly optimal rule listswith a speed-up up to two orders of magnitude over state-of-the-art exactapproaches. Moreover, our algorithm is as fast as, and sometimes faster than,recent heuristic approaches, while reporting higher quality rule lists. Inaddition, the rules reported by our algorithm are more similar to the rules inthe optimal rule list than the rules from heuristic approaches.|随着机器学习在社会决策中的重要性日益突出，学习可解释模型已经成为机器学习研究的一个主要焦点。在可解释的模型中，规则列表是最著名和易于解释的模型之一。然而，找到最佳的规则列表是计算上的挑战，并且当前的方法对于大型数据集是不切实际的。我们提出了一个新的和可扩展的方法来学习几乎最优的规则列表从大数据集。该算法采用抽样的方法，在严格保证近似质量的前提下，有效地获得了最优规则列表的近似。特别是当存在高精度规则列表时，我们的算法保证能够找到精度非常接近最优规则列表的规则列表。我们的算法建立在规则列表的 VC 维数的基础上，证明了新的上下界。我们在大型数据集上的实验评估表明，我们的算法识别几乎最优的规则列表的速度比最先进的精确方法快两数量级。此外，我们的算法与最近的启发式方法一样快，有时甚至更快，同时报告更高质量的规则列表。此外，我们的算法报告的规则更接近于最优规则列表中的规则，而不是启发式方法中的规则。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Rule+Lists+Learning+with+Sampling)|0|
|[Fredformer: Frequency Debiased Transformer for Time Series Forecasting](https://doi.org/10.1145/3637528.3671928)|Xihao Piao, Zheng Chen, Taichi Murayama, Yasuko Matsubara, Yasushi Sakurai|SANKEN, Osaka University, Osaka, Japan|The Transformer model has shown leading performance in time series forecasting. Nevertheless, in some complex scenarios, it tends to learn low-frequency features in the data and overlook high-frequency features, showing a frequency bias. This bias prevents the model from accurately capturing important high-frequency data features. In this paper, we undertake empirical analyses to understand this bias and discover that frequency bias results from the model disproportionately focusing on frequency features with higher energy. Based on our analysis, we formulate this bias and propose Fredformer, a Transformer-based framework designed to mitigate frequency bias by learning features equally across different frequency bands. This approach prevents the model from overlooking lower amplitude features important for accurate forecasting. Extensive experiments show the effectiveness of our proposed approach, which can outperform other baselines in different real-world time-series datasets. Furthermore, we introduce a lightweight variant of the Fredformer with an attention matrix approximation, which achieves comparable performance but with much fewer parameters and lower computation costs. The code is available at: https://github.com/chenzRG/Fredformer|变压器模型在时间序列预测中表现出领先的性能。然而，在一些复杂的场景中，它倾向于学习数据中的低频特征，而忽略高频特征，表现出频率偏差。这种偏差使模型无法准确地捕获重要的高频数据特征。本文通过实证分析了解这种偏差，发现模型的频率偏差过多地集中在高能量的频率特征上。基于我们的分析，我们制定了这种偏差，并提出了 Fredformer，一个基于变压器的框架，旨在减少频率偏差的学习功能在不同的频段相等。这种方法可以防止模型忽略对于精确预测非常重要的低振幅特征。大量的实验证明了该方法的有效性，在不同的实际时间序列数据集中，该方法的性能优于其他基线。此外，我们还引入了一个轻量级的 Fredform- 注意矩阵近似方法，该方法具有相当的性能，但是参数更少，计算量更小。密码可于以下 https://github.com/chenzrg/fredformer 索取:|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fredformer:+Frequency+Debiased+Transformer+for+Time+Series+Forecasting)|0|
|[ORCDF: An Oversmoothing-Resistant Cognitive Diagnosis Framework for Student Learning in Online Education Systems](https://doi.org/10.1145/3637528.3671988)|Hong Qian, Shuo Liu, Mingjia Li, Bingdong Li, Zhi Liu, Aimin Zhou|; School of Computer Science and Technology, East China Normal University, Shanghai, China|Cognitive diagnosis models (CDMs) are designed to learn students' mastery levels using their response logs. CDMs play a fundamental role in online education systems since they significantly influence downstream applications such as teachers' guidance and computerized adaptive testing. Despite the success achieved by existing CDMs, we find that they suffer from a thorny issue that the learned students' mastery levels are too similar. This issue, which we refer to as oversmoothing, could diminish the CDMs' effectiveness in downstream tasks. CDMs comprise two core parts: learning students' mastery levels and assessing mastery levels by fitting the response logs. This paper contends that the oversmoothing issue arises from that existing CDMs seldom utilize response signals on exercises in the learning part but only use them as labels in the assessing part. To this end, this paper proposes an oversmoothing-resistant cognitive diagnosis framework (ORCDF) to enhance existing CDMs by utilizing response signals in the learning part. Specifically, ORCDF introduces a novel response graph to inherently incorporate response signals as types of edges. Then, ORCDF designs a tailored response-aware graph convolution network (RGC) that effectively captures the crucial response signals within the response graph. Via ORCDF, existing CDMs are enhanced by replacing the input embeddings with the outcome of RGC, allowing for the consideration of response signals on exercises in the learning part. Extensive experiments on real-world datasets show that ORCDF not only helps existing CDMs alleviate the oversmoothing issue but also significantly enhances the models' prediction and interpretability performance. Moreover, the effectiveness of ORCDF is validated in the downstream task of computerized adaptive testing.|认知诊断模型(CDM)的目的是了解学生的掌握水平使用他们的反应日志。清洁发展机制在在线教育系统中发挥着重要作用，因为它们对教师指导和计算机化适应性测试等下游应用具有重要影响。尽管现有的清洁发展机制取得了成功，但我们发现它们存在一个棘手的问题，即学生的掌握水平过于相似。这个我们称之为过度平滑的问题，可能会削弱清洁发展机制在下游任务中的有效性。清洁发展机制包括两个核心部分: 学习学生的掌握水平和通过拟合响应日志评估掌握水平。本文认为，现有的清洁发展机制很少利用学习部分练习的反应信号，而只是在评估部分使用作为标记，从而产生了过度平滑的问题。为此，本文提出了一种抗过平滑认知诊断框架(ORCDF) ，利用学习部分的响应信号来增强现有的 CDM。具体来说，ORCDF 引入了一种新的响应图，将响应信号内在地合并为边的类型。然后，ORCDF 设计一个量身定制的响应感知图卷积网络(RGC) ，有效地捕获响应图中的关键响应信号。通过 ORCDF，现有的清洁发展机制得到了加强，将输入嵌入改为研资局的成果，从而允许在学习部分考虑练习的回应信号。在实际数据集上的大量实验表明，ORCDF 不仅有助于缓解现有 CDM 的过平滑问题，而且显著提高了模型的预测和可解释性能。在计算机自适应测试的下游任务中，验证了 ORCDF 算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ORCDF:+An+Oversmoothing-Resistant+Cognitive+Diagnosis+Framework+for+Student+Learning+in+Online+Education+Systems)|0|
|[LARP: Language Audio Relational Pre-training for Cold-Start Playlist Continuation](https://doi.org/10.1145/3637528.3671772)|Rebecca Salganik, Xiaohao Liu, Yunshan Ma, Jian Kang, TatSeng Chua|National University of Singapore, Singapore, Singapore; University of Rochester, Rochester, NY, USA|As online music consumption increasingly shifts towards playlist-based listening, the task of playlist continuation, in which an algorithm suggests songs to extend a playlist in a personalized and musically cohesive manner, has become vital to the success of music streaming services. Currently, many existing playlist continuation approaches rely on collaborative filtering methods to perform their recommendations. However, such methods will struggle to recommend songs that lack interaction data, an issue known as the cold-start problem. Current approaches to this challenge design complex mechanisms for extracting relational signals from sparse collaborative signals and integrating them into content representations. However, these approaches leave content representation learning out of scope and utilize frozen, pre-trained content models that may not be aligned with the distribution or format of a specific musical setting. Furthermore, even the musical state-of-the-art content modules are either (1) incompatible with the cold-start setting or (2) unable to effectively integrate cross-modal and relational signals. In this paper, we introduce LARP, a multi-modal cold-start playlist continuation model, to effectively overcome these limitations. LARP is a three-stage contrastive learning framework that integrates both multi-modal and relational signals into its learned representations. Our framework uses increasing stages of task-specific abstraction: within-track (language-audio) contrastive loss, track-track contrastive loss, and track-playlist contrastive loss. Experimental results on two publicly available datasets demonstrate the efficacy of LARP over uni-modal and multi-modal models for playlist continuation in a cold-start setting. Finally, this work pioneers the perspective of addressing cold-start recommendation via relational representation learning. Code and dataset are released at: https://github.com/Rsalganik1123/LARP/|随着在线音乐消费越来越多地转向基于播放列表的聆听，播放列表延续的任务已经成为音乐流媒体服务成功的关键。在播放列表延续中，算法建议歌曲以个性化和音乐内聚的方式扩展播放列表。目前，许多现有的播放列表延续方法依赖于协同过滤方法来执行他们的建议。然而，这种方法将很难推荐缺乏交互数据的歌曲，这个问题被称为冷启动问题。目前针对这一挑战的方法设计了复杂的机制，用于从稀疏的协作信号中提取关系信号，并将其集成到内容表示中。然而，这些方法使得内容表示学习脱离了范围，并且使用了冻结的、预先训练的内容模型，这些模型可能与特定音乐环境的分布或格式不一致。此外，即使音乐国家的最先进的内容模块要么(1)与冷启动设置不兼容，要么(2)不能有效地整合跨模态和关系信号。在本文中，我们引入了 LARP，一个多模态的冷启动播放列表延续模型，以有效地克服这些局限性。LARP 是一个三阶段对比学习框架，它将多模态信号和关系信号整合到学习表示中。我们的框架使用了不断增加的特定于任务的抽象阶段: 轨道内(语言-音频)对比度丢失、轨道-轨道对比度丢失和轨道-播放列表对比度丢失。在两个公开数据集上的实验结果证明了 LARP 在冷启动环境下对播放列表延续的单模态和多模态模型的有效性。最后，本文开创了通过关系表示学习解决冷启动推荐问题的先河。代码和数据集在以下 https://github.com/rsalganik1123/larp/发布|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LARP:+Language+Audio+Relational+Pre-training+for+Cold-Start+Playlist+Continuation)|0|
|[CrossLight: Offline-to-Online Reinforcement Learning for Cross-City Traffic Signal Control](https://doi.org/10.1145/3637528.3671927)|Qian Sun, Rui Zha, Le Zhang, Jingbo Zhou, Yu Mei, Zhiling Li, Hui Xiong|; School of Computer Science, University of Science and Technology of China, Hefei, China; Baidu Research, Baidu Inc., Beijing, China; Department of Intelligent Driving Group Business Management, Baidu Inc., Beijing, China; Department of Intelligent Transportation System, Baidu Inc., Beijing, China|The recent advancements in Traffic Signal Control (TSC) have highlighted the potential of Reinforcement Learning (RL) as a promising solution to alleviate traffic congestion. Current research in this area primarily concentrates on either online or offline learning strategies, aiming to create optimized policies for specific cities. Nevertheless, the transferability of these policies to new cities is impeded by constraints such as the limited availability of high-quality data and the expensive and risky exploration process. To this end, in this paper, we present an innovative cross-city Traffic Signal Control (TSC) paradigm called CrossLight. Our approach involves meta training using offline data from source cities and adaptively fine-tuning in the target city. This novel methodology aims to address the challenges of transferring TSC policies across different cities effectively. In our proposed approach, we start by acquiring meta-decision pattern knowledge through trajectory dynamics reconstruction via pre-training in source cities. To address disparities in road network topologies between cities, we dynamically construct city topological structures based on the extracted meta-knowledge during the offline meta-training phase. These structures are then used to distill pattern-structure aware representations of decision trajectories from the source cities. To identify effective initial parameters for the learnable components, we employ the Model-Agnostic Meta-Learning (MAML) framework, a popular meta-learning approach. During adaptive fine-tuning in the target city, we introduce a replay buffer that is iteratively updated using online interactions with a rank and filter mechanism. This mechanism, along with a carefully designed exploration strategy, ensures a balance between exploitation and exploration, thereby fostering both the diversity and quality of the trajectories for fine-tuning. Finally, extensive experiments across four cities validate that CrossLight achieves comparable performance in new cities with minimal fine-tuning iterations, surpassing both existing online and offline methods. This success underscores that our CrossLight framework emerges as a groundbreaking and potent paradigm, offering a feasible and effective solution to the intelligent transportation community.|交通信号控制(TSC)的最新进展凸显了强化学习作为缓解交通交通堵塞的一个有前途的解决方案的潜力。目前该领域的研究主要集中在线上或线下学习策略，旨在为特定城市制定优化政策。然而，这些政策向新城市的转移受到诸如高质量数据有限以及昂贵和危险的勘探过程等制约因素的阻碍。为此，在本文中，我们提出了一个创新的跨城市交通信号控制(TSC)范例称为交叉灯。我们的方法包括使用来自源城市的离线数据进行元培训，并在目标城市进行自适应微调。这种新颖的方法旨在解决在不同城市之间有效转移 TSC 政策的挑战。在我们提出的方法中，我们从获取元决策模式的知识开始，通过轨迹动力学重建通过预训练在源城市。针对城市间道路网络拓扑结构的差异，在离线元训练阶段，基于提取的元知识动态构建城市拓扑结构。然后使用这些结构从源城市中提取决策轨迹的模式结构感知表示。为了确定可学习组件的有效初始参数，我们采用了模型不可知元学习(MAML)框架，这是一种流行的元学习方法。在目标城市的自适应微调过程中，我们引入了一个重放缓冲区，该缓冲区使用带有等级和过滤机制的在线交互进行迭代更新。这一机制连同精心设计的勘探战略，确保了开发和勘探之间的平衡，从而促进了微调轨迹的多样性和质量。最后，在四个城市进行的大量实验证实，CrossLight 在新城市中以最少的微调迭代实现了可比的性能，超过了现有的两种在线和离线方法。这一成功突出表明，我们的 CrossLight 框架是一个开创性的、有力的范例，为智能交通社区提供了一个可行的、有效的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CrossLight:+Offline-to-Online+Reinforcement+Learning+for+Cross-City+Traffic+Signal+Control)|0|
|[Going Where, by Whom, and at What Time: Next Location Prediction Considering User Preference and Temporal Regularity](https://doi.org/10.1145/3637528.3671916)|Tianao Sun, Ke Fu, Weiming Huang, Kai Zhao, Yongshun Gong, Meng Chen|School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; Robinson College of Business, Georgia State University, Atlanta, GA, USA; School of Software, Shandong University, Jinan, China|Next location prediction is a crucial task in human mobility modeling, and is pivotal for many downstream applications like location-based recommendation and transportation planning. Although there has been a large body of research tackling this problem, the usefulness of user preference and temporal regularity remains underrepresented. Specifically, previous studies usually neglect the explicit user preference information entailed from human trajectories and fall short in utilizing the arrival time of next location, as a key determinant on next location. To address these limitations, we propose a Multi-Context aware Location Prediction model (MCLP) to predict next locations for individuals, where it explicitly models user preference and the next arrival time as context. First, we utilize a topic model to extract user preferences for different types of locations from historical human trajectories. Second, we develop an arrival time estimator to construct a robust arrival time embedding based on the multi-head attention mechanism. The two components provide pivotal contextual information for the subsequent prediction. Finally, we utilize the Transformer architecture to mine sequential patterns and integrate multiple contextual information to predict the next locations. Experimental results on two real-world mobility datasets show that our proposed MCLP outperforms baseline methods.|下一步的位置预测是人类流动性建模中的一个关键任务，对于基于位置的推荐和交通规划等许多下游应用来说都是至关重要的。虽然已有大量研究处理这一问题，但用户偏好和时间规律的有用性仍然没有得到充分体现。具体而言，以往的研究往往忽略了人类轨迹所带来的明确的用户偏好信息，而没有充分利用下一个位置的到达时间作为下一个位置的关键决定因素。为了解决这些局限性，我们提出了一个多上下文感知位置预测模型(MCLP)来预测个人的下一个位置，它显式地模拟用户偏好和下一个到达时间作为上下文。首先，我们利用主题模型从历史人类轨迹中提取不同类型位置的用户偏好。其次，提出了一种基于多目标注意机制的鲁棒到达时间估计器，构造了一种鲁棒到达时间嵌入算法。这两个组件为后续预测提供关键的上下文信息。最后，我们利用 former 体系结构来挖掘序列模式，并集成多个上下文信息来预测下一个位置。在两个实际移动数据集上的实验结果表明，我们提出的 MCLP 方法的性能优于基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Going+Where,+by+Whom,+and+at+What+Time:+Next+Location+Prediction+Considering+User+Preference+and+Temporal+Regularity)|0|
|[EcoVal: An Efficient Data Valuation Framework for Machine Learning](https://doi.org/10.1145/3637528.3672068)|Ayush K. Tarun, Vikram S. Chundawat, Murari Mandal, Hong Ming Tan, Bowei Chen, Mohan S. Kankanhalli|Ola Krutrim, Bangalore, India; National University of Singapore, Singapore, Singapore; NUS Business School, National University of Singapore, Singapore, Singapore; RespAI Lab, Bhubaneswar, India; RespAI Lab, Kalinga Institute of Industrial Technology, Bhubaneswar, India; Adam Smith Business School, University of Glasgow, Glasgow, United Kingdom|Quantifying the value of data within a machine learning workflow can play a pivotal role in making more strategic decisions in machine learning initiatives. The existing Shapley value based frameworks for data valuation in machine learning are computationally expensive as they require considerable amount of repeated training of the model to obtain the Shapley value. In this paper, we introduce an efficient data valuation framework EcoVal, to estimate the value of data for machine learning models in a fast and practical manner. Instead of directly working with individual data sample, we determine the value of a cluster of similar data points. This value is further propagated amongst all the member cluster points. We show that the overall value of the data can be determined by estimating the intrinsic and extrinsic value of each data. This is enabled by formulating the performance of a model as aproduction function, a concept which is popularly used to estimate the amount of output based on factors like labor and capital in a traditional free economic market. We provide a formal proof of our valuation technique and elucidate the principles and mechanisms that enable its accelerated performance. We demonstrate the real-world applicability of our method by showcasing its effectiveness for both in-distribution and out-of-sample data. This work addresses one of the core challenges of efficient data valuation at scale in machine learning models. The code is available at https://github.com/respai-lab/ecoval.|对机器学习工作流中的数据价值进行量化，可以在机器学习活动中作出更具战略性的决策方面发挥关键作用。现有的基于 Shapley 值的机器学习数据估值框架计算量很大，因为它们需要对模型进行大量的重复训练才能获得 Shapley 值。本文介绍了一种高效的数据价值评估框架 EcoVal，用于快速、实用地评估机器学习模型的数据价值。我们不直接处理单个数据样本，而是确定类似数据点集群的值。此值将在所有成员群集点之间进一步传播。我们表明，数据的总体价值可以通过估计每个数据的内在和外在价值来确定。这是通过将模型的性能表述为生产函数来实现的，在传统的自由经济市场中，生产函数这一概念被广泛用于根据劳动力和资本等因素来估计产出量。我们为我们的评估技术提供了一个正式的证明，并阐明了使其加速性能的原则和机制。我们通过展示其对分布内和样本外数据的有效性来证明我们的方法在现实世界中的适用性。这项工作解决了在机器学习模型的规模有效的数据估值的核心挑战之一。密码可在 https://github.com/respai-lab/ecoval 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EcoVal:+An+Efficient+Data+Valuation+Framework+for+Machine+Learning)|0|
|[Causal Estimation of Exposure Shifts with Neural Networks and an Application to Inform Air Quality Standards in the US](https://doi.org/10.1145/3637528.3671761)|Mauricio Tec, Kevin Josey, Oladimeji Mudele, Francesca Dominici|Harvard University, Cambridge, MA, USA; Colorado School of Public Health, Aurora, CO, USA|A fundamental task in causal inference is estimating the effect of a distribution shift in the treatment variable. We refer to this problem as shift-response function (SRF) estimation. Existing neural network methods for causal inference lack theoretical guarantees and practical implementations for SRF estimation. In this paper, we introduce Targeted Regularization for Exposure Shifts with Neural Networks (TRESNET), a method to estimate SRFs with robustness and efficiency guarantees. Our contributions are twofold. First, we propose a targeted regularization loss for neural networks with theoretical properties that ensure double robustness and asymptotic efficiency specific to SRF estimation. Second, we extend targeted regularization to support loss functions from the exponential family to accommodate non-continuous outcome distributions (e.g., discrete counts). We conduct benchmark experiments demonstrating TRESNET's broad applicability and competitiveness. We then apply our method to a key policy question in public health to estimate the causal effect of revising the US National Ambient Air Quality Standards (NAAQS) for PM 2.5 from 12 μg/m3 to 9 μg/m3. This change has been recently proposed by the US Environmental Protection Agency (EPA). Our goal is to estimate the reduction in deaths that would result from this anticipated revision using data consisting of 68 million individuals across the U.S.|因果推理的一个基本任务是估计治疗变量中分布偏移的影响。我们把这个问题称为移位响应函数(SRF)估计。现有的神经网络因果推理方法缺乏 SRF 估计的理论保证和实际应用。本文介绍了基于神经网络的曝光位移目标正则化方法(TRESNET) ，这是一种具有鲁棒性和有效性保证的 SRF 估计方法。我们的贡献是双重的。首先，我们提出了一个目标正则化损失的神经网络的理论性质，确保双鲁棒性和渐近效率特定的 SRF 估计。其次，我们扩展有针对性的正则化来支持来自指数族的损失函数，以适应非连续的结果分布(例如，离散计数)。我们进行的基准实验证明了 TRESNET 的广泛适用性和竞争力。然后，我们将我们的方法应用于公共卫生的一个关键政策问题，以估计将美国国家环境空气质量标准(NAAQS)的 PM2.5从12μg/m3修订为9μg/m3的因果效应。美国环境保护署(EPA)最近提出了这一改变。我们的目标是利用全美6800万个人的数据估计这一预期修正可能导致的死亡人数减少。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Estimation+of+Exposure+Shifts+with+Neural+Networks+and+an+Application+to+Inform+Air+Quality+Standards+in+the+US)|0|
|[Online Drift Detection with Maximum Concept Discrepancy](https://doi.org/10.1145/3637528.3672016)|Ke Wan, Yi Liang, Susik Yoon|Fudan University, Shanghai, China; University of Illinois at Urbana-Champaign, Urbana, IL, USA; Korea University, Seoul, Republic of Korea|Continuous learning from an immense volume of data streams becomes exceptionally critical in the internet era. However, data streams often do not conform to the same distribution over time, leading to a phenomenon called concept drift. Since a fixed static model is unreliable for inferring concept-drifted data streams, establishing an adaptive mechanism for detecting concept drift is crucial. Current methods for concept drift detection primarily assume that the labels or error rates of downstream models are given and/or underlying statistical properties exist in data streams. These approaches, however, struggle to address high-dimensional data streams with intricate irregular distribution shifts, which are more prevalent in real-world scenarios. In this paper, we propose MCD-DD, a novel concept drift detection method based on maximum concept discrepancy, inspired by the maximum mean discrepancy. Our method can adaptively identify varying forms of concept drift by contrastive learning of concept embeddings without relying on labels or statistical properties. With thorough experiments under synthetic and real-world scenarios, we demonstrate that the proposed method outperforms existing baselines in identifying concept drifts and enables qualitative analysis with high explainability.|在互联网时代，从海量数据流中不断学习变得尤为重要。然而，随着时间的推移，数据流往往不符合相同的分布，从而导致一种称为概念漂移的现象。由于固定的静态模型对于推断概念漂移数据流是不可靠的，因此建立一个自适应的概念漂移检测机制是至关重要的。目前的概念漂移检测方法主要假设下游模型的标签或错误率已经给出，并且/或者数据流中存在潜在的统计特性。然而，这些方法很难处理具有复杂的不规则分布变化的高维数据流，这种情况在现实世界中更为普遍。本文受最大均值偏差的启发，提出了一种新的基于最大均值偏差的概念漂移检测方法 MCD-DD。该方法通过概念嵌入的对比学习自适应地识别不同形式的概念漂移，而不依赖于标签或统计特性。通过在合成和真实场景下的全面实验，我们证明了该方法在识别概念漂移方面优于现有的基线，并且能够进行高解释性的定性分析。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Drift+Detection+with+Maximum+Concept+Discrepancy)|0|
|[CE-RCFR: Robust Counterfactual Regression for Consensus-Enabled Treatment Effect Estimation](https://doi.org/10.1145/3637528.3672054)|Fan Wang, Chaochao Chen, Weiming Liu, Tianhao Fan, Xinting Liao, Yanchao Tan, Lianyong Qi, Xiaolin Zheng|; College of Computer and Data ScienceCollege of Software, Fuzhou University, Fuzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China|Estimating individual treatment effects (ITE) from observational data is challenging due to the absence of counterfactuals and the treatment selection bias. Prevalent ITE estimation methods tackle these challenges by aligning the treated and controlled distributions in the representational space. However, two critical issues have long been overlooked: (1)Mini-batch sampling sensitivity (MSS) issue, where representation distribution alignment at a mini-batch level is vulnerable to poor sampling cases, such as data imbalance and outliers; (2)Inconsistent representation learning (IRL) issue, where representation learning within a unified backbone network suffers from inconsistent gradient update directions due to the distribution skew between different treatment groups. To resolve these issues, we propose CE-RCFR, a Robust CounterFactual Regression framework for Consensus-Enabled causal effect estimation, including a relaxed distribution discrepancy regularizer (RDDR) module and a consensus-enabled aggregator (CEA) module. Specifically, for the robust representation alignment perspective, RDDR addresses the MSS issue by minimizing unbalanced optimal transport divergence between different treatment groups with a relaxed marginal constraint. For the accurate representation optimization perspective, CEA addresses the IRL issue by resolving the consistent gradient update directions on shared parameters within the backbone network. Extensive experiments demonstrate that CE-RCFR significantly outperforms the state-of-the-art methods in treatment effect estimations.|由于缺乏反事实因素和治疗选择偏倚，从观察数据估计个体治疗效果(ITE)是具有挑战性的。目前流行的 ITE 估计方法通过在表征空间中对齐处理过的和控制过的分布来应对这些挑战。然而，有两个关键问题长期以来一直被忽视: (1)小批量抽样敏感性(MSS)问题，其中表征分布在小批量水平上的比对容易受到不良抽样情况的影响，如数据不平衡和异常值; (2)不一致表征学习(IRL)问题，其中表征学习在一个统一的骨干网络中由于不同处理组之间的分布倾斜而遭受不一致的梯度更新方向。为了解决这些问题，我们提出了 CE-RCFR，一个用于共识支持的因果效应估计的鲁棒反事实回归框架，包括一个松弛的分布差异正则化(RDDR)模块和一个共识支持的聚合器(CEA)模块。具体而言，对于鲁棒表示比对的观点，RDDR 通过最小化不同治疗组之间不平衡的最佳运输分歧，并放松边际约束来解决 MSS 问题。从精确表示优化的角度出发，CEA 通过解决骨干网内共享参数的一致梯度更新方向来解决 IRL 问题。广泛的实验表明，CE-RCFR 在治疗效果评估方面显著优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CE-RCFR:+Robust+Counterfactual+Regression+for+Consensus-Enabled+Treatment+Effect+Estimation)|0|
|[Learning from Emergence: A Study on Proactively Inhibiting the Monosemantic Neurons of Artificial Neural Networks](https://doi.org/10.1145/3637528.3671776)|Jiachuan Wang, Shimin Di, Lei Chen, Charles Wang Wai Ng|The Hong Kong University of Science and Technology, (Guangzhou), Guangzhou, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China|Recently, emergence has received widespread attention from the research community along with the success of large-scale models. Different from the literature, we hypothesize a key factor that promotes the performance during the increase of scale: the reduction of monosemantic neurons that can only form one-to-one correlations with specific features. Monosemantic neurons tend to be sparser and have negative impacts on the performance in large models. Inspired by this insight, we propose an intuitive idea to identify monosemantic neurons and inhibit them. However, achieving this goal is a non-trivial task as there is no unified quantitative evaluation metric and simply banning monosemantic neurons does not promote polysemanticity in neural networks. Therefore, we first propose a new metric to measure the monosemanticity of neurons with the guarantee of efficiency for online computation, then introduce a theoretically supported method to suppress monosemantic neurons and proactively promote the ratios of polysemantic neurons in training neural networks. We validate our conjecture that monosemanticity brings about performance change at different model scales on a variety of neural networks and benchmark datasets in different areas, including language, image, and physics simulation tasks. Further experiments validate our analysis and theory regarding the inhibition of monosemanticity.|近年来，随着大规模模型的成功应用，涌现现象受到了研究界的广泛关注。与文献不同，我们假设一个关键因素，促进性能在规模的增加: 减少单语义神经元，只能形成一对一的相关性与特定的功能。在大型模型中，单义神经元往往比较稀疏，对性能有负面影响。受此启发，我们提出了一个直观的想法来识别和抑制单义神经元。然而，由于没有统一的定量评价指标，单义神经元的禁止并不能提高神经网络的多义性，因此实现这一目标是一项艰巨的任务。因此，我们首先提出了一种新的度量方法来衡量神经元的单语义性，保证了在线计算的有效性，然后介绍了一种理论支持的方法来抑制单语义神经元，并在训练神经网络中主动提高多语义神经元的比率。我们验证了我们的猜想，即单语义在不同的神经网络和不同领域的基准数据集上，包括语言、图像和物理模拟任务，在不同的模型尺度上带来性能变化。进一步的实验验证了我们关于单语义抑制的分析和理论。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+from+Emergence:+A+Study+on+Proactively+Inhibiting+the+Monosemantic+Neurons+of+Artificial+Neural+Networks)|0|
|[POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning](https://doi.org/10.1145/3637528.3671721)|Junxiang Wang, Guangji Bai, Wei Cheng, Zhengzhang Chen, Liang Zhao, Haifeng Chen|Emory University, Atlanta, GA, USA; NEC Labs America, Princeton, NJ, USA|Time series domain adaptation stands as a pivotal and intricate challengewith diverse applications, including but not limited to human activityrecognition, sleep stage classification, and machine fault diagnosis. Despitethe numerous domain adaptation techniques proposed to tackle this complexproblem, they primarily focus on domain adaptation from a single source domain.Yet, it is more crucial to investigate domain adaptation from multiple domainsdue to the potential for greater improvements. To address this, three importantchallenges need to be overcome: 1). The lack of exploration to utilizedomain-specific information for domain adaptation, 2). The difficulty to learndomain-specific information that changes over time, and 3). The difficulty toevaluate learned domain-specific information. In order to tackle thesechallenges simultaneously, in this paper, we introduce PrOmpt-based domaiNDiscrimination (POND), the first framework to utilize prompts for time seriesdomain adaptation. Specifically, to address Challenge 1, we extend the idea ofprompt tuning to time series analysis and learn prompts to capture common anddomain-specific information from all source domains. To handle Challenge 2, weintroduce a conditional module for each source domain to generate prompts fromtime series input data. For Challenge 3, we propose two criteria to select goodprompts, which are used to choose the most suitable source domain for domainadaptation. The efficacy and robustness of our proposed POND model areextensively validated through experiments across 50 scenarios encompassing fourdatasets. Experimental results demonstrate that our proposed POND modeloutperforms all state-of-the-art comparison methods by up to 66% on theF1-score.|时间序列领域适应是一个关键和复杂的挑战与多种应用，包括但不限于人类活动识别，睡眠阶段分类和机器故障诊断。尽管为了解决这个复杂的问题，提出了许多领域自适应技术，但它们主要集中在从单个源领域进行领域自适应。然而，由于存在更大的改进潜力，因此研究来自多个领域的领域适应性更为重要。为了解决这个问题，我们需要克服三个重要的挑战: 1)。缺乏利用特定领域信息进行领域适应的探索，2)。学习随时间变化的特定领域信息的困难，以及3)。评估学习领域特定信息的困难。为了同时解决这些问题，本文介绍了第一个利用提示进行时间序列域适应的框架——基于提示的域识别(POND)。具体来说，为了解决挑战1，我们将提示调优的思想扩展到时间序列分析，并学习提示从所有源域中捕获公共和特定领域的信息。为了处理挑战2，我们为每个源域引入一个条件模块，从时间序列输入数据生成提示。对于挑战3，我们提出了两个选择好提示的标准，用于选择最适合域适应的源域。我们提出的 POND 模型的有效性和鲁棒性通过包含四个数据集的50个场景的实验得到了广泛的验证。实验结果表明，我们提出的 POND 模型优于所有国家的最先进的比较方法，高达66% 的 F1得分。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=POND:+Multi-Source+Time+Series+Domain+Adaptation+with+Information-Aware+Prompt+Tuning)|0|
|[DPSW-Sketch: A Differentially Private Sketch Framework for Frequency Estimation over Sliding Windows](https://doi.org/10.1145/3637528.3671694)|Yiping Wang, Yanhao Wang, Cen Chen|; East China Normal University, Shanghai, China|The sliding window model of computation captures scenarios in which data are continually arriving in the form of a stream, and only the most recent w items are used for analysis. In this setting, an algorithm needs to accurately track some desired statistics over the sliding window using a small space. When data streams contain sensitive information about individuals, the algorithm is also urgently needed to provide a provable guarantee of privacy. In this paper, we focus on the two fundamental problems of privately (1) estimating the frequency of an arbitrary item and (2) identifying the most frequent items (i.e., heavy hitters), in the sliding window model. We propose DPSW-Sketch, a sliding window framework based on the count-min sketch that not only satisfies differential privacy over the stream but also approximates the results for frequency and heavy-hitter queries within bounded errors in sublinear time and space w.r.t. w. Extensive experiments on five real-world and synthetic datasets show that DPSW-Sketch provides significantly better utility-privacy trade-offs than state-of-the-art methods.|计算的滑动窗口模型捕获数据以流的形式不断到达的场景，并且只使用最新的 w 项进行分析。在这种情况下，算法需要使用一个小空间在滑动窗口上精确地跟踪一些所需的统计信息。当数据流包含有关个人的敏感信息时，也迫切需要该算法提供可证明的隐私保证。本文主要研究滑动窗口模型中的两个基本问题: (1)估计任意项目的频率; (2)识别最频繁项目(即重点项目)。我们提出了 DPSW-Sketch，一个基于 count-min 草图的滑动窗口框架，它不仅满足流上的差分隐私，而且在次线性时间和空间的有界错误内，近似于频率和重点查询的结果。在五个真实世界和合成数据集上的大量实验表明，DPSW-Sketch 比最先进的方法提供了明显更好的效用-隐私权衡。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPSW-Sketch:+A+Differentially+Private+Sketch+Framework+for+Frequency+Estimation+over+Sliding+Windows)|0|
|[DFGNN: Dual-frequency Graph Neural Network for Sign-aware Feedback](https://doi.org/10.1145/3637528.3671701)|Yiqing Wu, Ruobing Xie, Zhao Zhang, Xu Zhang, Fuzhen Zhuang, Leyu Lin, Zhanhui Kang, Yongjun Xu|; Tencent, Beijing, China; Institute of Artificial Intelligence, Beihang University & Zhongguancun Laboratory, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|The graph-based recommendation has achieved great success in recent years.However, most existing graph-based recommendations focus on capturing userpreference based on positive edges/feedback, while ignoring negativeedges/feedback (e.g., dislike, low rating) that widely exist in real-worldrecommender systems. How to utilize negative feedback in graph-basedrecommendations still remains underexplored. In this study, we first conducteda comprehensive experimental analysis and found that (1) existing graph neuralnetworks are not well-suited for modeling negative feedback, which acts as ahigh-frequency signal in a user-item graph. (2) The graph-based recommendationsuffers from the representation degeneration problem. Based on the twoobservations, we propose a novel model that models positive and negativefeedback from a frequency filter perspective called Dual-frequency Graph NeuralNetwork for Sign-aware Recommendation (DFGNN). Specifically, in DFGNN, thedesigned dual-frequency graph filter (DGF) captures both low-frequency andhigh-frequency signals that contain positive and negative feedback.Furthermore, the proposed signed graph regularization is applied to maintainthe user/item embedding uniform in the embedding space to alleviate therepresentation degeneration problem. Additionally, we conduct extensiveexperiments on real-world datasets and demonstrate the effectiveness of theproposed model. Codes of our model will be released upon acceptance.|近年来，基于图形的推荐方法取得了巨大的成功。然而，大多数现有的基于图表的推荐关注于基于正面边缘/反馈来获取用户偏好，而忽略了现实中广泛存在的负面边缘/反馈(例如，不喜欢，低评价)。如何在基于图表的推荐中利用负面反馈仍然没有得到充分的探索。在本研究中，我们首先进行了全面的实验分析，发现(1)现有的图形神经网络并不适合建立负反馈模型，因为负反馈在用户项目图中扮演高频信号的角色。(2)基于图的推荐存在表示退化问题。基于这两个观察结果，我们提出了一种新的模型，从频率滤波器的角度模拟正反馈和负反馈，称为双频图神经网络(DFGNN)的符号感知推荐。特别是在 DFGNN，设计的双频图形滤波器(dGF)同时捕获包含正反馈和负反馈的低频和高频信号。在嵌入空间中采用符号图正则化方法保持用户/项目嵌入的一致性，以减少表示退化问题。此外，我们在真实世界的数据集上进行了广泛的实验，并证明了该模型的有效性。我们的型号代码将在验收后发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DFGNN:+Dual-frequency+Graph+Neural+Network+for+Sign-aware+Feedback)|0|
|[Predicting Cascading Failures with a Hyperparametric Diffusion Model](https://doi.org/10.1145/3637528.3672048)|Bin Xiang, Bogdan Cautis, Xiaokui Xiao, Olga Mula, Dusit Niyato, Laks V. S. Lakshmanan|University of Paris-Saclay, CNRS LISN, Saclay, France; Nanyang Technological University, Singapore, Singapore; University of British Columbia, Vancouver, Canada; National University of Singapore, Singapore, Singapore; Eindhoven University of Technology, Eindhoven, Netherlands; CNRSCREATE, Singapore, Singapore|In this paper, we study cascading failures in power grids through the lens ofinformation diffusion models. Similar to the spread of rumors or influence inan online social network, it has been observed that failures (outages) in apower grid can spread contagiously, driven by viral spread mechanisms. Weemploy a stochastic diffusion model that is Markovian (memoryless) and local(the activation of one node, i.e., transmission line, can only be caused by itsneighbors). Our model integrates viral diffusion principles with physics-basedconcepts, by correlating the diffusion weights (contagion probabilities betweentransmission lines) with the hyperparametric Information Cascades (IC) model.We show that this diffusion model can be learned from traces of cascadingfailures, enabling accurate modeling and prediction of failure propagation.This approach facilitates actionable information through well-understood andefficient graph analysis methods and graph diffusion simulations. Furthermore,by leveraging the hyperparametric model, we can predict diffusion and mitigatethe risks of cascading failures even in unseen grid configurations, whereasexisting methods falter due to a lack of training data. Extensive experimentsbased on a benchmark power grid and simulations therein show that our approacheffectively captures the failure diffusion phenomena and guides decisions tostrengthen the grid, reducing the risk of large-scale cascading failures.Additionally, we characterize our model's sample complexity, improving upon theexisting bound.|本文通过信息扩散模型的透镜，研究了电网中的连锁故障。与在线社交网络中谣言或影响的传播类似，已经观察到电网故障(停电)可以通过病毒传播机制传染。我们采用马尔可夫(无记忆)和局部(一个节点的激活，即传输线，只能由它的邻居引起)的随机扩散模型。我们的模型通过将扩散权重(传输线之间的传染概率)与超参数信息级联(IC)模型相关联，将病毒扩散原理与基于物理的概念结合起来。我们表明，这种扩散模型可以从级联故障的痕迹中学习，从而能够准确建模和预测故障传播。这种方法通过充分理解和有效的图分析方法和图扩散模拟促进了可操作的信息。此外，通过利用超参数模型，我们可以预测扩散和减轻级联故障的风险，即使在看不见的网格配置，而现有的方法由于缺乏训练数据而步履蹒跚。基于基准电网的大量实验和仿真表明，我们的方法有效地捕获了故障扩散现象，并指导决策加强电网，减少大规模连锁故障的风险。此外，我们描述了我们的模型的样本复杂性，改进了现有的界限。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Cascading+Failures+with+a+Hyperparametric+Diffusion+Model)|0|
|[FRNet: Frequency-based Rotation Network for Long-term Time Series Forecasting](https://doi.org/10.1145/3637528.3671713)|Xinyu Zhang, Shanshan Feng, Jianghong Ma, Huiwei Lin, Xutao Li, Yunming Ye, Fan Li, Yew Soon Ong|; Harbin Institute of Technology, Shenzhen, China; Centre for Frontier AI Research, ASTAR, Nanyang Technological University, Singapore, Singapore; Hong Kong Polytechnic University, Hong Kong, China|Long-term time series forecasting (LTSF) aims to predict future values for a long time based on historical data. The period term is an essential component of the time series, which is complex yet important for LTSF. Although existing studies have achieved promising results, they still have limitations in modeling dynamic complicated periods. Most studies only focus on static periods with fixed time steps, while very few studies attempt to capture dynamic periods in the time domain. In this paper, we dissect the original time series in time and frequency domains and empirically find that changes in periods are more easily captured and quantified in the frequency domain. Based on this observation, we propose to explore dynamic period features using rotation in the frequency domain. To this end, we develop the frequency-based rotation network (FRNet), a novel LTSF method to effectively capture the features of the dynamic complicated periods. FRNet decomposes the original time series into period and trend components. Based on the complex-valued linear networks, it leverages a period frequency rotation module to predict the period component and a patch frequency rotation module to predict the trend component, respectively. Extensive experiments on seven real-world datasets consistently demonstrate the superiority of FRNet over various state-of-the-art methods. The source code is available at https://github.com/SiriZhang45/FRNet.|长期时间序列预测(LTSF)的目的是根据历史数据预测未来很长一段时间内的价值。周期项是时间序列的一个重要组成部分，对于长期稳定因子来说，时间序列是复杂而重要的。虽然现有的研究已经取得了很好的成果，但是在动态复杂周期的建模方面仍然存在一定的局限性。大多数研究只关注固定时间步长的静态周期，很少有研究试图捕捉时间域中的动态周期。本文从时间和频率两个方面对原始时间序列进行了剖析，发现在频率域更容易捕捉和量化周期的变化。在此基础上，我们提出了在频域中利用旋转来探索动态周期特征的方法。为此，我们发展了基于频率的旋转网络(FRNet) ，一种新的 LTSF 方法来有效地捕捉动态复杂周期的特征。FRNet 将原始时间序列分解为周期分量和趋势分量。在复值线性网络的基础上，利用周期频率旋转模块预测周期分量，利用补丁频率旋转模块预测趋势分量。在七个真实世界数据集上的大量实验一致地证明了 FRNet 相对于各种最先进的方法的优越性。源代码可在 https://github.com/sirizhang45/frnet 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FRNet:+Frequency-based+Rotation+Network+for+Long-term+Time+Series+Forecasting)|0|
|[Hypformer: Exploring Efficient Transformer Fully in Hyperbolic Space](https://doi.org/10.1145/3637528.3672039)|Menglin Yang, Harshit Verma, Delvin Ce Zhang, Jiahong Liu, Irwin King, Rex Ying|Birla Institute of Technology and Science, Hyderabad, India; Yale University, New Haven, CT, USA; The Chinese University of Hong Kong, Hong Kong, China|Hyperbolic geometry have shown significant potential in modeling complex structured data, particularly those with underlying tree-like and hierarchical structures. Despite the impressive performance of various hyperbolic neural networks across numerous domains, research on adapting the Transformer to hyperbolic space remains limited. Previous attempts have mainly focused on modifying self-attention modules in the Transformer. However, these efforts have fallen short of developing a complete hyperbolic Transformer. This stems primarily from: (i) the absence of well-defined modules in hyperbolic space, including linear transformation layers, LayerNorm layers, activation functions, dropout operations, etc. (ii) the quadratic time complexity of the existing hyperbolic self-attention module w.r.t the number of input tokens, which hinders its scalability. To address these challenges, we propose, Hypformer, a novel hyperbolic Transformer based on the Lorentz model of hyperbolic geometry. In Hypformer, we introduce two foundational blocks that define the essential modules of the Transformer in hyperbolic space. Furthermore, we develop a linear self-attention mechanism in hyperbolic space, enabling hyperbolic Transformer to process billion-scale graph data and long-sequence inputs for the first time. Our experimental results confirm the effectiveness and efficiency of \method across various datasets, demonstrating its potential as an effective and scalable solution for large-scale data representation and large models.|双曲几何在建模复杂的结构化数据方面显示出巨大的潜力，特别是那些具有树状结构和层次结构的数据。尽管各种双曲神经网络在许多领域都有着令人印象深刻的性能，但是关于如何使变压器适应双曲空间的研究仍然很有限。以前的尝试主要集中在修改 Transformer 中的自我关注模块。然而，这些努力都没有开发出一个完整的双曲变压器。这主要是由于: (i)双曲空间中缺乏定义明确的模块，包括线性映射层、层规范层、激活函数、辍学操作等。(ii)现有双曲自我注意模块的二次时间复杂性。为了应对这些挑战，我们提出了一种基于洛伦兹双曲几何模型的新型双曲变压器。在 Hypformer，我们介绍了两个基本模块，它们定义了双曲空间变压器的基本模块。此外，我们还在双曲空间中开发了一种线性自我注意机制，使得双曲变压器第一次能够处理数十亿比例的图形数据和长序列输入。我们的实验结果证实了该方法在不同数据集之间的有效性和效率，证明了该方法作为大规模数据表示和大型模型的有效和可扩展的解决方案的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hypformer:+Exploring+Efficient+Transformer+Fully+in+Hyperbolic+Space)|0|
|[Practical Single Domain Generalization via Training-time and Test-time Learning](https://doi.org/10.1145/3637528.3671806)|Shuai Yang, Zhen Zhang, Lichuan Gu||Single domain generalization aims to learn a model that generalizes well to unseen target domains by using a related source domain. However, most existing methods only focus on improving the generalization performance of the model during training, making it difficult to achieve satisfactory performance when deployed in the target domain with large domain shifts. In this paper, we propose a Practical Single Domain Generalization (PSDG) method, which first leverages the knowledge in a source domain to establish a model with good generalization ability in the training phase, and subsequently updates the model to adapt to target domain data using knowledge in the unlabeled target domain during the testing phase. Specifically, during training, PSDG leverages a newly proposed style (e.g., background features) generator named StyIN to generate novel domain data. Moreover, PSDG introduces style-diversity regularization to constantly synthesize distinct styles to expand the coverage of training data, and introduces object-consistency regularization to capture consistency between the currently generated data and the original data, making the model filter style knowledge during training. During testing, PSDG uses a sample-aware and sharpness-aware minimization method to seek for a flat entropy minimum surface for further model optimization by using the knowledge in the unlabeled target domain. Using three real-world datasets the experiments have demonstrated the effectiveness of PSDG, in comparison with several state-of-the-art methods.|单域泛化的目的是学习一个模型，通过使用一个相关的源域很好地泛化到不可见的目标域。然而，现有的方法大多局限于提高模型在训练过程中的泛化性能，这使得在目标区域部署时，当目标区域移动较大时，很难获得令人满意的性能。本文提出了一种实用的单领域泛化(PSDG)方法，该方法首先利用源领域的知识在训练阶段建立一个具有良好泛化能力的模型，然后在测试阶段利用未标记目标领域的知识对模型进行更新以适应目标领域数据。具体来说，在培训期间，PSDG 利用一个新提出的样式(例如，背景特性)生成器 StyIN 来生成新的域数据。此外，PSDG 引入样式多样性正则化技术，不断综合不同的样式，扩大训练数据的覆盖范围; 引入对象一致性正则化技术，捕捉当前生成的数据与原始数据之间的一致性，使模型滤波样式知识在训练过程中得到充分利用。在测试过程中，PSDG 利用未标记目标域中的知识，采用样本感知和锐度感知的最小化方法寻找平坦熵最小曲面，以进一步优化模型。利用三个真实世界的数据集，实验证明了 PSDG 的有效性，并与几种最先进的方法进行了比较。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Single+Domain+Generalization+via+Training-time+and+Test-time+Learning)|0|
|[Rethinking Order Dispatching in Online Ride-Hailing Platforms](https://doi.org/10.1145/3637528.3672028)|Zhaoxing Yang, Haiming Jin, Guiyun Fan, Min Lu, Yiran Liu, Xinlang Yue, Hao Pan, Zhe Xu, Guobin Wu, Qun Li, Xiaotong Wang, Jiecheng Guo|Didi Chuxing, Beijing, China; Shanghai Jiao Tong University, Shanghai, China|Achieving optimal order dispatching has been a long-standing challenge for online ride-hailing platforms. Early methods would make shortsighted matchings as they only consider order prices alone as the edge weights in the driver-order bipartite graph, thus harming the platform's revenue. To address this problem, recent works evaluate the value of the order's destination region to be the long-term income a driver could obtain in average in such region and incorporate it into the order's edge weight to influence the matching results. However, they often result in insufficient driver supplies in many regions, as the values evaluated in different regions vary greatly, mainly because the impact of one region's value on the future number of drivers and revenue in other regions is overlooked. This paper models such impact within a cooperative Markov game, which involves each value's impact over the platform's revenue with the goal to find the optimal region values for revenue maximization. To solve this game, our work proposes a novelgoal-reaching collaboration (GRC) algorithm that realizes credit assignment from a novel goal-reaching perspective, addressing the difficulty for accurate credit assignment with large-scale agents of previous methods and resolving the conflict between credit assignment and offline reinforcement learning. Specifically, during training, GRC predicts the city's future state through an environment model and utilizes a scoring model to rate the predicted states to judge their levels of profitability, where high-scoring states are regarded as the goal states. Then, the policies in the game are updated to promote the city to stay in the goal states for as long as possible. To evaluate GRC, we deploy a baseline policy online in several cities for three weeks to collect real-world dataset. Training and testing results on the collected dataset indicate that our GRC consistently outperforms the baselines in different cities and peak periods.|实现最优订单调度一直是在线叫车平台面临的一个长期挑战。早期的方法只考虑订单价格作为驱动订单二部图中的边缘权重，会造成目光短浅的匹配，从而损害平台的收益。为了解决这个问题，最近的工作评估了订单的目的地区域的价值是驱动程序可以获得的长期收入在这些区域的平均值，并将其纳入订单的边缘权重，以影响匹配结果。然而，它们常常导致许多地区的驱动力供应不足，因为在不同地区评估的价值差异很大，主要是因为一个地区的价值对未来驱动力数量和其他地区的收入的影响被忽视。本文在合作马尔可夫博弈中建立了这种影响的模型，其中涉及到每个价值对平台收入的影响，目的是找到收入最大化的最优区域值。为了解决这个问题，我们的工作提出了一个新的目标达成协作(gc)算法，从一个新的目标达成的角度来实现信用分配，解决了以前方法的大规模代理人准确信用分配的困难，并解决了信用分配和离线强化学习之间的冲突。具体来说，在培训期间，GRC 通过一个环境模型预测城市的未来状态，并利用评分模型对预测状态进行评分，以判断其盈利水平，其中得分较高的状态被视为目标状态。然后，游戏中的政策被更新，以促使城市尽可能长时间地停留在目标状态。为了评估 GRC，我们在几个城市中部署了一个为期三周的在线基线策略来收集真实世界的数据集。对所收集数据集的训练和测试结果表明，我们的 GRC 在不同城市和高峰期的表现始终优于基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Order+Dispatching+in+Online+Ride-Hailing+Platforms)|0|
|[BoKA: Bayesian Optimization based Knowledge Amalgamation for Multi-unknown-domain Text Classification](https://doi.org/10.1145/3637528.3671963)|Linzhu Yu, Huan Li, Ke Chen, Lidan Shou|The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China|With breakthroughs in pretrained language models, a large number of finetuned models specialized in distinct domains have surfaced online. Yet, when faced with a fresh dataset covering multiple (sub)domains, their performance might degrade. Reusing these available finetuned models to train a new model is a more feasible solution than the finetuning method that demands extensive manual labeling. Knowledge Amalgamation (KA) is such a model reusing technique, which derives a new model (termed student model) by amalgamating those trained models (termed teacher models) tailored for distinct domains, bypassing the need for manual labeling. However, when the domains of text samples are unknown, selecting a number of appropriate teacher models (simply called a combination) for reuse becomes complicated. To learn an accurate student model, the classical KA method resorts to manual selections, a process both tedious and inefficient. Our study pioneers the automation of this combination selection process for KA in the fundamental text classification task, an area previously unexplored. In this paper, we introduce BoKA : an automatic knowledge amalgamation framework for identifying a combination that can learn a superior student model without human labor. Through the lens of Bayesian optimization, BoKA iteratively samples a subset of possible combinations for amalgamation instead of manual selections. Furthermore, we introduce a novel KA method tailored for text classification, which guides the student model using both soft and pseudo-hard labels from the teacher models when their predictions are closely aligned; in cases of significant disagreement, it uses randomly generated labels. Experiments on two public multi-domain datasets show that BoKA achieves remarkable efficiency by sampling only up to 5.5% of all potential combinations. Moreover, BoKA is capable of matching or even surpassing leading zero-shot large language models, despite having dozens of times fewer parameters.|随着预先训练语言模型的突破，大量在不同领域专门的微调模型已经在网上浮出水面。然而，当面对覆盖多个(子)域的新数据集时，它们的性能可能会下降。与需要大量人工标记的微调方法相比，重用这些已有的微调模型来训练新模型是一种更可行的解决方案。知识合并(KA)就是这样一种模型重用技术，它通过合并那些为不同领域量身定制的训练模型(称为教师模型) ，绕过人工标记的需要，得到一个新的模型(称为学生模型)。然而，当文本示例的领域是未知的时候，为重用选择一些合适的教师模型(简称为组合)就变得复杂了。为了学习一个准确的学生模型，经典的 KA 方法采用手工选择，这是一个既繁琐又低效的过程。我们的研究开创了自动化的组合选择过程的 KA 在基本文本分类任务，一个领域以前未被探索。在本文中，我们介绍了 BoKA: 一个自动知识融合框架，以确定一个组合，可以学习一个优秀的学生模型没有人工劳动。通过贝叶斯优化的透镜，BoKA 迭代抽样一个子集的可能的组合合并，而不是手工选择。此外，我们还引入了一种适合文本分类的新的 KA 方法，当教师模型的预测紧密一致时，它使用软标签和伪硬标签来引导学生模型; 在出现重大分歧的情况下，它使用随机生成的标签。在两个公开的多领域数据集上进行的实验表明，BoKA 算法只对所有潜在组合的5.5% 进行抽样，就取得了显著的效果。此外，BoKA 能够匹配甚至超越领先的大型语言模型，尽管它的参数少了几十倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BoKA:+Bayesian+Optimization+based+Knowledge+Amalgamation+for+Multi-unknown-domain+Text+Classification)|0|
|[Diverse Intra- and Inter-Domain Activity Style Fusion for Cross-Person Generalization in Activity Recognition](https://doi.org/10.1145/3637528.3671828)|Junru Zhang, Lang Feng, Zhidan Liu, Yuhan Wu, Yang He, Yabo Dong, Duanqing Xu|Shenzhen University, Shenzhen, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, Zhejiang, China|Existing domain generalization (DG) methods for cross-person generalization tasks often face challenges in capturing intra- and inter-domain style diversity, resulting in domain gaps with the target domain. In this study, we explore a novel perspective to tackle this problem, a process conceptualized as domain padding. This proposal aims to enrich the domain diversity by synthesizing intra- and inter-domain style data while maintaining robustness to class labels. We instantiate this concept using a conditional diffusion model and introduce a style-fused sampling strategy to enhance data generation diversity. In contrast to traditional condition-guided sampling, our style-fused sampling strategy allows for the flexible use of one or more random styles to guide data synthesis. This feature presents a notable advancement: it allows for the maximum utilization of possible permutations and combinations among existing styles to generate a broad spectrum of new style instances. Empirical evaluations on a broad range of datasets demonstrate that our generated data achieves remarkable diversity within the domain space. Both intra- and inter-domain generated data have proven to be significant and valuable, contributing to varying degrees of performance enhancements. Notably, our approach outperforms state-of-the-art DG methods in all human activity recognition tasks.|现有的跨人员泛化任务的域泛化方法在捕获域内和域间风格多样性时往往面临挑战，导致与目标域的域差异。在这项研究中，我们探索了一个新的视角来解决这个问题，一个过程概念化为域填充。该方案旨在通过合成域内和域间样式数据来丰富域多样性，同时保持对类别标签的鲁棒性。我们使用一个条件扩散模型来实例化这个概念，并引入一个样式融合抽样策略来增强数据生成的多样性。与传统的条件引导抽样不同，我们的样式融合抽样策略允许灵活地使用一种或多种随机样式来指导数据合成。这个特性提供了一个显著的进步: 它允许最大限度地利用现有样式之间可能的排列和组合，以生成广泛的新样式实例。对大范围数据集的实证评估表明，我们生成的数据在领域空间内实现了显著的多样性。域内和域间生成的数据都被证明是重要和有价值的，有助于不同程度的性能增强。值得注意的是，我们的方法在所有人类活动识别任务中都优于最先进的 DG 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diverse+Intra-+and+Inter-Domain+Activity+Style+Fusion+for+Cross-Person+Generalization+in+Activity+Recognition)|0|
|[Knowledge Distillation with Perturbed Loss: From a Vanilla Teacher to a Proxy Teacher](https://doi.org/10.1145/3637528.3671851)|Rongzhi Zhang, Jiaming Shen, Tianqi Liu, Jialu Liu, Michael Bendersky, Marc Najork, Chao Zhang|Google, New York City, NY, USA; Georgia Institute of Technology, Atlanta, GA, USA|Knowledge distillation is a popular technique to transfer knowledge from a large teacher model to a small student model. Typically, the student learns to imitate the teacher by minimizing the KL divergence of its output distribution with the teacher's output distribution. In this work, we argue that such a learning objective is sub-optimal because there exists a discrepancy between the teacher's output distribution and the ground truth label distribution. Therefore, forcing the student to blindly imitate the unreliable teacher output distribution leads to inferior performance. To this end, we propose a novel knowledge distillation objective PTLoss by first representing the vanilla KL-based distillation loss function via a Maclaurin series and then perturbing the leading-order terms in this series. This perturbed loss implicitly transforms the original teacher into a proxy teacher with a distribution closer to the ground truth distribution. We establish the theoretical connection between this "distribution closeness'' and the student model generalizability, which enables us to select the PTLoss's perturbation coefficients in a principled way. Extensive experiments on six public benchmark datasets demonstrate the effectiveness of PTLoss with teachers of different scales.|知识提取是将知识从大型教师模型转化为小型学生模型的一种流行技术。通常情况下，学生学习模仿教师通过最小化其输出分布的 KL 散度与教师的输出分布。在本研究中，我们认为这样的学习目标是次优的，因为在教师的输出分布和地面真理标签分布之间存在差异。因此，迫使学生盲目模仿不可靠的教师产出分布，导致学习成绩不佳。为此，我们提出了一种新的知识蒸馏目标 PT损失，首先通过 Maclaurin 级数表示基于香草 KL 的蒸馏损失函数，然后扰动该级数的先导项。这种不安的损失隐含地将原来的教师转变为代理教师，代理教师的分布更接近于地面真理分布。我们建立了这种“分布接近度”与学生模型概化性之间的理论联系，从而使我们能够以一种原则性的方式选择 PT损失的扰动系数。在六个公共基准数据集上进行的大量实验证明了 PTloss 在不同尺度教师中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Distillation+with+Perturbed+Loss:+From+a+Vanilla+Teacher+to+a+Proxy+Teacher)|0|
|[Joint Auction in the Online Advertising Market](https://doi.org/10.1145/3637528.3671746)|Zhen Zhang, Weian Li, Yahui Lei, Bingzhe Wang, Zhicheng Zhang, Qi Qi, Qiang Liu, Xingxing Wang|School of Software, Shandong University, Jinan, China; Meituan Inc., Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China|Online advertising is a primary source of income for e-commerce platforms. In the current advertising pattern, the oriented targets are the online store owners who are willing to pay extra fees to enhance the position of their stores. On the other hand, brand suppliers are also desirable to advertise their products in stores to boost brand sales. However, the currently used advertising mode cannot satisfy the demand of both stores and brand suppliers simultaneously. To address this, we innovatively propose a joint advertising model termed ''Joint Auction'', allowing brand suppliers and stores to collaboratively bid for advertising slots, catering to both their needs. However, conventional advertising auction mechanisms are not suitable for this novel scenario. In this paper, we propose JRegNet, a neural network architecture for the optimal joint auction design, to generate mechanisms that can achieve the optimal revenue and guarantee (near-)dominant strategy incentive compatibility and individual rationality. Finally, multiple experiments are conducted on synthetic and real data to demonstrate that our proposed joint auction significantly improves platform's revenue compared to the known baselines.|在线广告是电子商务平台的主要收入来源。在当前的广告模式下，网络商店的定位目标是那些愿意支付额外费用来提高自己店铺地位的网络商店老板。另一方面，品牌供应商也希望在商店里为他们的产品做广告，以促进品牌销售。然而，目前使用的广告模式并不能同时满足商店和品牌供应商的需求。为了解决这个问题，我们创新性地提出了一种名为“联合拍卖”的联合广告模式，允许品牌供应商和商店合作竞标广告位，以满足他们的需求。然而，传统的广告拍卖机制并不适合这种新颖的场景。在这篇文章中，我们提出了一个用于最优联合拍卖设计的神经网络结构—— JregNet，来生成能够实现最优收益和保证(近)主导策略激励相容和个人理性的机制。最后，通过对合成数据和实际数据的多重实验表明，与已知基线相比，本文提出的联合拍卖方案显著提高了平台的收益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Auction+in+the+Online+Advertising+Market)|0|
|[Long-Term Vessel Trajectory Imputation with Physics-Guided Diffusion Probabilistic Model](https://doi.org/10.1145/3637528.3672086)|Zhiwen Zhang, Zipei Fan, Zewu Lv, Xuan Song, Ryosuke Shibasaki|School of Artificial Intelligence, Jilin University, Changchun, China; ; Research & Development Department, LocationMind Inc., Tokyo, Japan|Maritime traffic management increasingly relies on vessel position information provided by terrestrial and satellite networks of the Automatic Identification System (AIS). Unfortunately, the problem of missing AIS data can lead to long-term gaps in vessel trajectory, raising corresponding security concerns regarding collision risks and illicit activities. Existing imputation approaches are often constrained by vehicle-based low-sampling trajectories, hindering their ability to address unique characteristics of maritime transportation systems and long-term missing scenarios. To tackle these challenges, we propose a novel generative framework for long-term vessel trajectory imputation. Our framework considers irregular tracks of vessels, which differ from those of cars due to the absence of a structured road network, and ensures the continuity of multi-point imputed trajectories. Specifically, we first utilize a pre-trained trajectory embedding block to capture patterns of vessel movements. Subsequently, we introduce a diffusion-based model for generating missing trajectories, where observed trajectory modeling with transformer encoding architecture and embeddings of both historical vessel trajectory and external factors serve as conditional information. In particular, we design a physics-guided discriminator in the training stage, which imposes kinematic constraints between locations and angles to improve the continuity of the imputed trajectories. Comprehensive experiments and analysis on a real-world AIS dataset confirm the effectiveness of our proposed approach.|海上交通管理越来越依赖自动识别系统地面和卫星网络提供的船只位置信息。遗憾的是，缺少自动识别系统数据的问题可能导致船舶航线的长期空白，从而引起对碰撞风险和非法活动的相应安全关切。现有的估算方法往往受到基于车辆的低采样轨迹的限制，妨碍了它们处理海上运输系统独特特征和长期缺失情景的能力。为了应对这些挑战，我们提出了一个新的长期船舶轨迹插补生成框架。我们的框架考虑了由于缺乏结构化道路网而不同于汽车的不规则船舶轨迹，并确保了多点估算轨迹的连续性。具体来说，我们首先利用一个预先训练的轨迹嵌入块来捕捉血管运动的模式。随后，我们介绍了一个基于扩散的缺失轨迹生成模型，其中观测轨迹建模与变压器编码结构和嵌入的历史船舶轨迹和外部因素作为条件信息。特别地，我们在训练阶段设计了一个物理导引的鉴别器，它在位置和角度之间施加运动学约束，以改善估计轨迹的连续性。通过对一个实际 AIS 数据集的全面实验和分析，证实了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long-Term+Vessel+Trajectory+Imputation+with+Physics-Guided+Diffusion+Probabilistic+Model)|0|
|[All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining](https://doi.org/10.1145/3637528.3671913)|Haihong Zhao, Aochuan Chen, Xiangguo Sun, Hong Cheng, Jia Li||Large Language Models (LLMs) have revolutionized the fields of computer vision (CV) and natural language processing (NLP). One of the most notable advancements of LLMs is that a single model is trained on vast and diverse datasets spanning multiple domains -- a paradigm we term `All in One'. This methodology empowers LLMs with super generalization capabilities, facilitating an encompassing comprehension of varied data distributions. Leveraging these capabilities, a single LLM demonstrates remarkable versatility across a variety of domains -- a paradigm we term `One for All'. However, applying this idea to the graph field remains a formidable challenge, with cross-domain pretraining often resulting in negative transfer. This issue is particularly important in few-shot learning scenarios, where the paucity of training data necessitates the incorporation of external knowledge sources. In response to this challenge, we propose a novel approach called Graph COordinators for PrEtraining (GCOPE), that harnesses the underlying commonalities across diverse graph datasets to enhance few-shot learning. Our novel methodology involves a unification framework that amalgamates disparate graph datasets during the pretraining phase to distill and transfer meaningful knowledge to target tasks. Extensive experiments across multiple graph datasets demonstrate the superior efficacy of our approach. By successfully leveraging the synergistic potential of multiple graph datasets for pretraining, our work stands as a pioneering contribution to the realm of graph foundational model.|大语言模型(LLM)彻底改变了计算机视觉(CV)和自然语言处理(NLP)领域。LLM 最显著的进步之一是，单个模型是在跨越多个领域的大量多样化数据集上进行训练的——我们称之为“一体化”模式。这种方法赋予 LLM 超级泛化能力，促进对各种数据分布的全面理解。利用这些能力，单个 LLM 在多个领域展示了非凡的多功能性——我们称之为“一个为所有人”的范例。然而，将这种思想应用到图论领域仍然是一个巨大的挑战，跨域预训练常常导致负迁移。这个问题在短期学习情况下尤其重要，因为培训数据不足，必须纳入外部知识来源。为了应对这一挑战，我们提出了一种新的方法，称为图形协调器的预训练(GCOPE) ，利用不同的图形数据集的基本共性，以增强少镜头学习。我们的新方法涉及一个统一的框架，在预训练阶段合并不同的图形数据集，以提取和转移有意义的知识到目标任务。跨多个图形数据集的广泛实验证明了我们的方法的优越功效。通过成功地利用多个图形数据集的协同潜力进行预训练，我们的工作成为对图形基础模型领域的开拓性贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=All+in+One+and+One+for+All:+A+Simple+yet+Effective+Method+towards+Cross-domain+Graph+Pretraining)|0|
|[Multi-source Unsupervised Domain Adaptation on Graphs with Transferability Modeling](https://doi.org/10.1145/3637528.3671829)|Tianxiang Zhao, Dongsheng Luo, Xiang Zhang, Suhang Wang|The Pennsylvania State University, State College, USA; Florida International University, Miami, USA|In this paper, we tackle a new problem ofmulti-source unsupervised domain adaptation (MSUDA) for graphs, where models trained on annotated source domains need to be transferred to the unsupervised target graph for node classification. Due to the discrepancy in distribution across domains, the key challenge is how to select good source instances and how to adapt the model. Diverse graph structures further complicate this problem, rendering previous MSUDA approaches less effective. In this work, we present the framework Selective Multi-source Adaptation for Graph (SelMAG ), with a graph-modeling-based domain selector, a sub-graph node selector, and a bi-level alignment objective for the adaptation. Concretely, to facilitate the identification of informative source data, the similarity across graphs is disentangled and measured with the transferability of a graph-modeling task set, and we use it as evidence for source domain selection. A node selector is further incorporated to capture the variation in transferability of nodes within the same source domain. To learn invariant features for adaptation, we align the target domain to selected source data both at the embedding space by minimizing the optimal transport distance and at the classification level by distilling the label function. Modules are explicitly learned to select informative source data and conduct the alignment in virtual training splits with a meta-learning strategy. Experimental results on five graph datasets show the effectiveness of the proposed method.|针对图的多源无监督域自适应(MSUDA)问题，在节点分类时，需要将经过注释源域训练的模型转移到无监督目标图上。由于不同领域之间的分布差异，关键的挑战是如何选择好的源实例以及如何适应模型。不同的图形结构使这个问题更加复杂，使得以前的 MSUDA 方法效率更低。本文提出了一种基于图模型的多源图选择自适应(SelMAG)框架，该框架包括一个基于图模型的域选择器、一个子图节点选择器和一个用于自适应的双层对齐目标。具体来说，为了方便信息源数据的识别，利用图建模任务集的可转移性对图间的相似性进行了解密和度量，并将其作为源域选择的依据。进一步合并节点选择器以捕获同一源域内节点可转移性的变化。为了学习自适应的不变特征，我们通过最小化最优传输距离在嵌入空间和通过提取标签函数在分类级别将目标域与选定的源数据对齐。模块被明确地学习来选择信息源数据，并使用元学习策略在虚拟训练中进行对齐。在五个图形数据集上的实验结果表明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-source+Unsupervised+Domain+Adaptation+on+Graphs+with+Transferability+Modeling)|0|
|[Bridging and Compressing Feature and Semantic Spaces for Robust Graph Neural Networks: An Information Theory Perspective](https://doi.org/10.1145/3637528.3671870)|Luying Zhong, Renjie Lin, Jiayin Li, Shiping Wang, Zheyi Chen|Fuzhou University, Fuzhou, China; Fujian Normal University, Fuzhou, China|The emerging Graph Convolutional Networks (GCNs) have attracted widespread attention in graph learning, due to their good ability of aggregating the information between higher-order neighbors. However, real-world graph data contains high noise and redundancy, making it hard for GCNs to accurately depict the complete relationships between nodes, which seriously degrades the quality of graph representations. Moreover, existing studies commonly ignore the distribution difference between feature and semantic spaces in graphs, causing inferior model generalization. To address these challenges, we propose DIB-RGCN, a novel robust GCN framework, to explore the optimal graph representation with the guidance of the well-designed dual information bottleneck principle. First, we analyze the reasons for distribution differences and theoretically prove that minimal sufficient representations in specific spaces cannot promise optimal performance for downstream tasks. Next, we design new dual channels to regularize feature and semantic spaces, eliminating the sharing of task-irrelevant information between spaces. Different from existing denoising algorithms that adopt a random dropping manner, we innovatively replace potential noisy features and edges with local neighboring representations. This design lowers edge-specific coefficient assignment, alleviating the interference of original representations while retaining graph structures. Further, we maximize the sharing of task-relevant information between feature and semantic spaces to alleviate the difference between them. Using real-world datasets, extensive experiments demonstrate the robustness of the proposed DIB-RGCN, which outperforms state-of-the-art methods on classification tasks.|新兴的图卷积网络(GCNs)以其良好的高阶邻域信息聚合能力，在图学习中引起了广泛的关注。然而，真实世界的图形数据具有高噪声和冗余性，使得 GCNs 难以准确描述节点之间的完整关系，严重影响了图表示的质量。此外，现有的研究普遍忽视了图中特征空间和语义空间的分布差异，导致模型泛化效果不佳。为了应对这些挑战，我们提出了一种新的鲁棒 GCN 框架 DIB-RGCN，以设计良好的双信息瓶颈原则为指导，探索最优图表示。首先，我们分析了分布差异的原因，并从理论上证明了特定空间中的最小充分表示不能保证下游任务的最优性能。接下来，我们设计了新的双通道来规范特征和语义空间，消除了空间之间任务无关信息的共享。与现有的采用随机降噪方式的去噪算法不同，我们创新地用局部邻域表示来代替潜在的噪声特征和边缘。这种设计降低了边特定的系数分配，减少了原始表示的干扰，同时保留了图的结构。进一步，我们最大化特征空间和语义空间之间任务相关信息的共享，以减轻它们之间的差异。利用真实世界的数据集，大量的实验证明了所提出的 DIB-RGCN 算法的鲁棒性，它在分类任务中的性能优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+and+Compressing+Feature+and+Semantic+Spaces+for+Robust+Graph+Neural+Networks:+An+Information+Theory+Perspective)|0|
|[Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach](https://doi.org/10.1145/3637528.3671921)|Fanwei Zhu, Wendong Xiao, Yao Yu, Zemin Liu, Zulong Chen, Weibin Cai|Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; Hangzhou City University, Hangzhou, China; Syracuse University, Syracuse, USA|Dynamic pricing, which suggests the optimal prices based on the dynamic demands, has received considerable attention in academia and industry. On online hotel booking platforms, room demand fluctuates due to various factors, notably hotel popularity and competition. In this paper, we propose a dynamic pricing approach with popularity and competitiveness-aware demand learning. Specifically, we introduce a novel demand function that incorporates popularity and competitiveness coefficients to comprehensively model the price elasticity of demand. We develop a dynamic demand prediction network that focuses on learning these coefficients in the proposed demand function, enhancing the interpretability and accuracy of price suggestion. The model is trained in a multi-task framework that effectively leverages the correlations of demands among groups of similar hotels to alleviate data sparseness in room-level occupancy prediction. Comprehensive experiments conducted on real-world datasets validate the superiority of our method over state-of-the-art baselines in both demand prediction and dynamic pricing. Our model has been successfully deployed on a popular online travel platform, serving tens of millions of users and hoteliers.|动态定价是指基于动态需求的最优价格，已经受到学术界和工业界的广泛关注。在线酒店预订平台上，客房需求的波动受到多种因素的影响，特别是酒店的受欢迎程度和竞争程度。本文提出了一种基于知名度和竞争力的需求学习的动态定价方法。具体来说，我们引入了一个新的需求函数，将受欢迎程度和竞争力系数结合起来，以全面建立需求的价格弹性模型。我们开发了一个动态的需求预测网络，重点是在建议的需求函数中学习这些系数，提高价格建议的可解释性和准确性。该模型在多任务框架下进行训练，有效地利用了类似酒店群体之间需求的相关性，以缓解客房入住率预测中的数据稀缺性。在实际数据集上进行的综合实验验证了该方法在需求预测和动态定价方面优于最新的基线方法。我们的模式已经成功地部署在一个受欢迎的在线旅游平台上，为数千万用户和酒店管理者服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Hotel+Pricing+at+Online+Travel+Platforms:+A+Popularity+and+Competitiveness+Aware+Demand+Learning+Approach)|0|
|[Repeat-Aware Neighbor Sampling for Dynamic Graph Learning](https://doi.org/10.1145/3637528.3672001)|Tao Zou, Yuhao Mao, Junchen Ye, Bowen Du|; CCSE Lab, Beihang University, Beijing, China; School of Transportation Science and Engineering, Beihang University, Beijing, China|Dynamic graph learning equips the edges with time attributes and allowsmultiple links between two nodes, which is a crucial technology forunderstanding evolving data scenarios like traffic prediction andrecommendation systems. Existing works obtain the evolving patterns mainlydepending on the most recent neighbor sequences. However, we argue that whethertwo nodes will have interaction with each other in the future is highlycorrelated with the same interaction that happened in the past. Onlyconsidering the recent neighbors overlooks the phenomenon of repeat behaviorand fails to accurately capture the temporal evolution of interactions. To fillthis gap, this paper presents RepeatMixer, which considers evolving patterns offirst and high-order repeat behavior in the neighbor sampling strategy andtemporal information learning. Firstly, we define the first-order repeat-awarenodes of the source node as the destination nodes that have interactedhistorically and extend this concept to high orders as nodes in the destinationnode's high-order neighbors. Then, we extract neighbors of the source node thatinteracted before the appearance of repeat-aware nodes with a slide windowstrategy as its neighbor sequence. Next, we leverage both the first andhigh-order neighbor sequences of source and destination nodes to learn temporalpatterns of interactions via an MLP-based encoder. Furthermore, considering thevarying temporal patterns on different orders, we introduce a time-awareaggregation mechanism that adaptively aggregates the temporal representationsfrom different orders based on the significance of their interaction timesequences. Experimental results demonstrate the superiority of RepeatMixer overstate-of-the-art models in link prediction tasks, underscoring theeffectiveness of the proposed repeat-aware neighbor sampling strategy.|动态图学习使边具有时间属性，允许两个节点之间存在多个链接，这是理解流量预测和推荐系统等不断发展的数据场景的关键技术。现有的工作主要依靠最新的邻居序列获得演化模式。然而，我们认为两个节点在未来是否会有相互作用与过去发生的相同的相互作用高度相关。只考虑最近的邻居忽略了重复行为的现象，无法准确地捕捉相互作用的时间演化。为了填补这一空白，本文提出了一种在邻居采样策略和时间信息学习中首先考虑进化模式和高阶重复行为的迭代混合器。首先，我们将源节点的一阶重复感知节点定义为历史上相互作用过的目的节点，并将这一概念扩展为目的节点高阶邻居中的高阶节点。然后，我们以滑动窗口策略作为邻居序列，提取在重复感知节点出现之前相互作用的源节点的邻居。接下来，我们利用源节点和目标节点的第一个和高阶相邻序列，通过基于 MLP 的编码器学习交互的时间模式。在此基础上，针对不同时间序列的时间模式变化，提出了一种时间感知聚合机制，该机制根据不同时间序列的交互重要性，自适应地聚合不同时间序列的时间表示。实验结果表明，本文提出的重复感知邻居采样策略在链路预测任务中具有优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Repeat-Aware+Neighbor+Sampling+for+Dynamic+Graph+Learning)|0|
|[Machine Learning for Clinical Management: From the Lab to the Hospital](https://doi.org/10.1145/3637528.3672497)|Ricard Gavaldà|Amalfi Analytics & Universitat Politècnica de Catalunya, BarcelonaTech (on leave), Barcelona, Spain|Population aging, increasing social demands, and rising costs of treatments are stressing healthcare systems to the point of risking the sustainability of universal and accessible healthcare. A hope in this dismal panorama is that there are large inefficiencies, and so opportunities for getting more from the same resources. To name a few, avoidable hospitalizations, unnecessary medication and tests, and lack of coordination among healthcare agents are estimated to cost several hundred billion euros per year in the EU. Technology can be useful for locating and reducing these inefficiencies, and within technology, the full exploitation of the data that the system collects to record its activity. In this talk, I will review the case for activity data analytics in healthcare, with two main considerations: 1) The need to include information about resources and costs in the models, in addition to clinical knowledge and patient outcomes, and 2) the need to use mostly data that healthcare organizations already collect and is not locked and distributed in silos. Fortunately, data collected for administrative and billing purposes, even though imperfect, partial, and low resolution, can be used to improve efficiency and safety, as well as fairness and equity. I will focus on the work carried out at Amalfi Analytics, a spin-off of my research group at UPC in Barcelona. On the one hand, we have addressed predictive management in hospitals, from influx to the emergency room to availability of surgical areas, beds, and staff. Anticipating activity, needs, and resource availability lets managers improve critical KPIs, e.g. waiting times, but also reduce staff stress, which leads to fewer medical errors and accidents. On the other hand, we have developed a patient cohort analyzer, based mostly on a recent clustering algorithm, that gives experts a fresh view of their patient population and lets them refine protocols and identify high-risk patient groups. This tool has also been used to support territorial planning and resource allocation. These problems have been extensively addressed in the past, but actual penetration of solutions in hospitals is smaller than one could expect. For example, one can find hundreds of papers on predicting influx to emergency rooms or bed demands, but many of them conclude after producing an AUC figure, and even fewer describe a working system that can be exported from the hospital where they were developed to others at an affordable cost. I will describe the approach taken at Amalfi so that hospitals can have such a solution up and running in a few days of work for their IT departments, in what I think is an interesting combination of software engineering and automatic Machine Learning.|人口老龄化、社会需求增加以及治疗成本上升，正在给医疗保健系统带来压力，以至于可能危及全民医疗保健的可持续性。在这个令人沮丧的全景中，一个希望是存在大量的低效率，因此有机会从同样的资源中获得更多。举几个例子，可避免的住院治疗、不必要的药物治疗和检测，以及医疗机构之间缺乏协调，估计每年在欧盟花费数千亿欧元。技术可以有助于查明和减少这些效率低下的情况，并在技术范围内充分利用系统为记录其活动而收集的数据。在这次演讲中，我将回顾医疗保健中活动数据分析的案例，主要考虑两点: 1)除了临床知识和患者结果之外，还需要在模型中包含有关资源和成本的信息; 2)需要使用医疗保健组织已经收集并且没有被锁定和分发的大部分数据。幸运的是，为管理和计费目的收集的数据，即使不完美、不完整和分辨率低，也可以用来提高效率和安全，以及公平和公正。我将专注于在阿马尔菲分析公司进行的工作，这是我在巴塞罗那的 UPC 研究小组的分支。一方面，我们已经解决了医院的预测性管理问题，从流入急诊室到手术区域、病床和工作人员的可用性。预测活动、需求和资源可用性可以让管理者改善关键的关键绩效指标，例如等待时间，但也可以减少员工压力，从而减少医疗差错和事故的发生。另一方面，我们已经开发了一个患者队列分析器，主要基于最近的聚类算法，使专家对他们的患者人口有一个新的看法，并让他们完善方案和确定高风险患者组。这个工具也被用来支持领土规划和资源分配。这些问题在过去已经得到了广泛的解决，但是解决方案在医院的实际渗透比人们预期的要小。例如，可以找到数百篇关于预测急诊室或床位需求的论文，但是其中许多都是在产生 AUC 数据之后得出的结论，更少的论文描述了可以从医院以负担得起的成本开发给其他人的工作系统。我将描述在阿马尔菲采取的方法，这样医院可以有这样一个解决方案，并在几天的工作为他们的信息技术部门运行，我认为这是一个有趣的组合软件工程和自动机器学习。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Machine+Learning+for+Clinical+Management:+From+the+Lab+to+the+Hospital)|0|
|[Metric Decomposition in A/B Tests](https://doi.org/10.1145/3637528.3671556)|Alex Deng, Luke Hagar, Nathaniel T. Stevens, Tatiana Xifara, Amit Gandhi|University of Pennsylvania, Philadelphia, PA, USA; University of Waterloo, Waterloo, ON, Canada; Airbnb, San Francisco, CA, USA; Airbnb, Seattle, WA, USA|More than a decade ago, CUPED (Controlled Experiments Utilizing Pre-Experiment Data) mainstreamed the idea of variance reduction leveraging pre-experiment covariates. Since its introduction, it has been implemented, extended, and modernized by major online experimentation platforms. Despite the wide adoption, it is known by practitioners that the variance reduction rate from CUPED utilizing pre-experimental data varies case by case and has a theoretical limit. In theory, CUPED can be extended to augment a treatment effect estimator utilizing in-experiment data, but practical guidance on how to construct such an augmentation is lacking. In this article, we fill this gap by proposing a new direction for sensitivity improvement via treatment effect augmentation whereby a target metric of interest is decomposed into components with high signal-to-noise disparity. Inference in the context of this decomposition is developed using both frequentist and Bayesian theory. We provide three real world applications demonstrating different flavors of metric decomposition; these applications illustrate the gain in agility metric decomposition yields relative to an un-decomposed analysis.|十多年前，CUPED (利用实验前数据的对照实验)将利用实验前协变量减少方差的想法主流化。自引入以来，它已经被主要的在线实验平台实现、扩展和现代化。尽管被广泛采用，但是从业人员都知道，利用实验前数据的 CUPED 方差减少率因情况而异，并且有一个理论上的限制。理论上，CUPED 可以扩展到利用实验数据来增强治疗效果估计器，但是对于如何构造这样的增强器缺乏实际指导。在本文中，我们填补了这一空白，提出了一个新的方向，通过治疗效果增强灵敏度改进，其中目标度量的兴趣是分解成具有高信噪比的组件。在这种分解的背景下的推理是发展使用频率论和贝叶斯理论。我们提供了三个现实世界中的应用程序，它们演示了不同风格的度量分解; 这些应用程序说明了相对于未分解的分析，敏捷度量分解产量的增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metric+Decomposition+in+A/B+Tests)|0|
|[LASCA: A Large-Scale Stable Customer Segmentation Approach to Credit Risk Assessment](https://doi.org/10.1145/3637528.3671550)|Yongfeng Gu, Yupeng Wu, Huakang Lu, Xingyu Lu, Hong Qian, Jun Zhou, Aimin Zhou|School of Computer Science and Technology, East China Normal University, Shanghai, China; Ant Group, Hangzhou, Zhejiang, China|Customer segmentation plays a crucial role in credit risk assessment by dividing users into specific risk levels based on their credit scores. Previous methods fail to comprehensively consider the stability in the segmentation process, resulting in frequent changes and inconsistencies in users' risk levels over time. This increases potential risks to a company. To this end, this paper at first introduces and formalizes the concept of stability regret in the segmentation process. However, evaluating stability is challenging due to its black-box nature and the computational burden posed by vast user data sets. To address these challenges, this paper proposes a large-scale stable customer segmentation approach named LASCA. LASCA consists of two phases: high-quality dataset construction (HDC) and reliable data-driven optimization (RDO). Specifically, HDC utilizes an evolutionary algorithm to collect high-quality binning solutions. RDO subsequently builds a reliable surrogate model to search for the most stable binning solution based on the collected dataset. Extensive experiments conducted on real-world large-scale datasets (up to 0.8 billion) show that LASCA surpasses the state-of-the-art binning methods in finding the most stable binning solution. Notably, HDC greatly enhances data quality by 50%. RDO efficiently discovers more stable binning solutions with a 36% improvement in stability, accelerating the optimization process by 25 times via data-driven evaluation. Currently, LASCA has been successfully deployed in the large-scale credit risk assessment system of Alipay.|客户细分在信用风险评估中起着至关重要的作用，它根据用户的信用评分将用户划分为特定的风险级别。以往的方法未能全面考虑分割过程的稳定性，导致用户的风险水平随着时间的推移频繁变化和不一致。这增加了公司的潜在风险。为此，本文首先在分割过程中引入并形式化了稳定性遗憾的概念。然而，评估稳定性是具有挑战性的，因为它的黑盒性质和计算负担所造成的海量用户数据集。针对这些挑战，本文提出了一种大规模稳定的客户细分方法 LASCA。LASCA 包括两个阶段: 高质量数据集构建(HDC)和可靠的数据驱动优化(RDO)。具体来说，HDC 使用进化算法来收集高质量的分组解决方案。RDO 随后构建一个可靠的代理模型，以根据收集的数据集搜索最稳定的装箱解决方案。在现实世界的大规模数据集(多达8亿个)上进行的大量实验表明，LASCA 在寻找最稳定的装箱解决方案方面超过了最先进的装箱方法。值得注意的是，HDC 极大地提高了50% 的数据质量。RDO 有效地发现了更稳定的装箱解决方案，其稳定性提高了36% ，通过数据驱动的评估将优化过程加速了25倍。目前，LASCA 已成功应用于支付宝的大规模信用风险评估系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LASCA:+A+Large-Scale+Stable+Customer+Segmentation+Approach+to+Credit+Risk+Assessment)|0|
|[Generative Auto-bidding via Conditional Diffusion Modeling](https://doi.org/10.1145/3637528.3671526)|Jiayan Guo, Yusen Huo, Zhilin Zhang, Tianyu Wang, Chuan Yu, Jian Xu, Bo Zheng, Yan Zhang|Peking University & Alibaba Group, Beijing, China; Alibaba Group, Beijing, China; Peking University, Beijing, China|Auto-bidding plays a crucial role in facilitating online advertising by automatically providing bids for advertisers. Reinforcement learning (RL) has gained popularity for auto-bidding. However, most current RL auto-bidding methods are modeled through the Markovian Decision Process (MDP), which assumes the Markovian state transition. This assumption restricts the ability to perform in long horizon scenarios and makes the model unstable when dealing with highly random online advertising environments. To tackle this issue, this paper introduces AI-Generated Bidding (AIGB), a novel paradigm for auto-bidding through generative modeling. In this paradigm, we propose DiffBid, a conditional diffusion modeling approach for bid generation. DiffBid directly models the correlation between the return and the entire trajectory, effectively avoiding error propagation across time steps in long horizons. Additionally, DiffBid offers a versatile approach for generating trajectories that maximize given targets while adhering to specific constraints. Extensive experiments conducted on the real-world dataset and online A/B test on Alibaba advertising platform demonstrate the effectiveness of DiffBid, achieving 2.81% increase in GMV and 3.36% increase in ROI.|自动竞价通过自动为广告商提供出价，在促进网络广告方面发挥着至关重要的作用。强化学习(RL)在自动竞投中越来越受欢迎。然而，大多数现有的 RL 自动竞价方法是通过马尔科夫决策过程(mDP)建模的，该过程假设 Markovian 政府的过渡。这种假设限制了在长期场景中的执行能力，并使模型在处理高度随机的在线广告环境时变得不稳定。为了解决这一问题，本文提出了一种基于生成模型的自动招标方法——人工智能生成招标(AIGB)。在这个范例中，我们提出了一种条件扩散建模的投标生成方法——迪夫出价。迪夫出价直接建模收益率和整个轨迹之间的相关性，有效地避免了错误传播跨时间步长的长期。此外，迪夫出价提供了一个多功能的方法来生成轨迹，最大限度地给定的目标，同时坚持特定的约束。在阿里巴巴广告平台上对现实世界的数据集和在线 A/B 测试进行了广泛的实验，结果证明了 DiffBid 的有效性，实现了2.81% 的 GMV 增长和3.36% 的投资回报率增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Auto-bidding+via+Conditional+Diffusion+Modeling)|0|
|[Learning Metrics that Maximise Power for Accelerated A/B-Tests](https://doi.org/10.1145/3637528.3671512)|Olivier Jeunen, Aleksei Ustimenko|ShareChat, London, United Kingdom; ShareChat, Edinburgh, United Kingdom|Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent. We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the p-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with over 160 million Monthly Active Users each, totalling over 153 A/B-pairs. Empirical results show that we are able to increase statistical power by up to 78% when using our learnt metrics stand-alone, and by up to 210% when used in tandem with the North Star. Alternatively, we can obtain constant statistical power at a sample size that is down to 12% of what the North Star requires, significantly reducing the cost of experimentation.|在线控制实验是科技公司做出自信决策的重要工具。定义了一个 North Star 指标(如长期收入或用户保留) ，在 A/B 测试中，在这个指标上有统计学显著改善的系统变体可以被认为是优越的。北极星指标通常是延迟和不敏感的。因此，实验的成本很高: 实验需要运行很长时间，即使这样，II 型错误(即假阴性)也很普遍。我们建议通过从短期信号中学习指标来解决这个问题，这些信号可以直接最大限度地利用它们对北极星的统计能力。我们表明，现有的方法容易过度拟合，因为较高的平均度量灵敏度并不意味着改善的 II 型误差，并建议相反，尽量减少在过去的实验日志中产生的度量的 p 值。我们从两个社会媒体应用程序中收集这样的数据集，每个应用程序的每月活跃用户超过1.6亿，总共超过153个 A/B 对。实证结果表明，我们能够增加高达78% 的统计权力时，使用我们的学习指标独立，并高达210% 时，与北极星使用的配合。或者，我们可以在样本大小下降到北极星所需要的12% 时获得恒定的统计功率，大大降低了实验的成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Metrics+that+Maximise+Power+for+Accelerated+A/B-Tests)|0|
|[Interpretable Cascading Mixture-of-Experts for Urban Traffic Congestion Prediction](https://doi.org/10.1145/3637528.3671507)|Wenzhao Jiang, Jindong Han, Hao Liu, Tao Tao, Naiqiang Tan, Hui Xiong|; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, Guangdong, China; Didichuxing Co. Ltd, Beijing, China; The Hong Kong University of Science and Technology, Hong Kong, China|Rapid urbanization has significantly escalated traffic congestion,underscoring the need for advanced congestion prediction services to bolsterintelligent transportation systems. As one of the world's largest ride-hailingplatforms, DiDi places great emphasis on the accuracy of congestion predictionto enhance the effectiveness and reliability of their real-time services, suchas travel time estimation and route planning. Despite numerous efforts havebeen made on congestion prediction, most of them fall short in handlingheterogeneous and dynamic spatio-temporal dependencies (e.g., periodic andnon-periodic congestions), particularly in the presence of noisy and incompletetraffic data. In this paper, we introduce a Congestion PredictionMixture-of-Experts, CP-MoE, to address the above challenges. We first propose asparsely-gated Mixture of Adaptive Graph Learners (MAGLs) with congestion-awareinductive biases to improve the model capacity for efficiently capturingcomplex spatio-temporal dependencies in varying traffic scenarios. Then, wedevise two specialized experts to help identify stable trends and periodicpatterns within the traffic data, respectively. By cascading these experts withMAGLs, CP-MoE delivers congestion predictions in a more robust andinterpretable manner. Furthermore, an ordinal regression strategy is adopted tofacilitate effective collaboration among diverse experts. Extensive experimentson real-world datasets demonstrate the superiority of our proposed methodcompared with state-of-the-art spatio-temporal prediction models. Moreimportantly, CP-MoE has been deployed in DiDi to improve the accuracy andreliability of the travel time estimation system.|快速的城市化使交通堵塞显著升级，这突出表明需要先进的拥堵预测服务来支持智能交通系统。作为全球其中一个最大的网约车平台，滴滴非常重视交通挤塞预测的准确性，以提高其实时服务(例如行车时间估计和路线规划)的成效和可靠性。尽管在拥塞预测方面已经做了大量的工作，但是大多数工作在处理异构和动态的时空依赖性(例如，周期性和非周期性的拥塞)方面仍然存在不足，特别是在存在噪声和不完整的交通数据的情况下。在本文中，我们引入了一个拥塞预测混合专家，CP-MoE，以解决上述挑战。我们首先提出具有拥塞感知偏差的自适应图学习器(MAGL)的门限混合模型，以提高模型能力，有效地捕获不同交通场景中复杂的时空依赖关系。然后，我们分别召集两位专家来帮助识别交通数据中的稳定趋势和周期模式。通过将这些专家与 MAGL 级联，CP-MoE 以更强大和可解释的方式提供拥塞预测。此外，采用有序回归策略促进不同专家之间的有效协作。对实际数据集的大量实验表明，与最先进的时空预测模型相比，本文提出的方法具有优越性。更重要的是，滴滴已部署了运输部，以提高旅行时间估计系统的准确性和可靠性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Cascading+Mixture-of-Experts+for+Urban+Traffic+Congestion+Prediction)|0|
|[False Positives in A/B Tests](https://doi.org/10.1145/3637528.3671631)|Ron Kohavi, Nanyu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=False+Positives+in+A/B+Tests)|0|
|[Causal Machine Learning for Cost-Effective Allocation of Development Aid](https://doi.org/10.1145/3637528.3671551)|Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, Stefan Feuerriegel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Machine+Learning+for+Cost-Effective+Allocation+of+Development+Aid)|0|
|[Chromosomal Structural Abnormality Diagnosis by Homologous Similarity](https://doi.org/10.1145/3637528.3671642)|Juren Li, Fanzhe Fu, Ran Wei, Yifei Sun, Zeyu Lai, Ning Song, Xin Chen, Yang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Chromosomal+Structural+Abnormality+Diagnosis+by+Homologous+Similarity)|0|
|[An Open and Large-Scale Dataset for Multi-Modal Climate Change-aware Crop Yield Predictions](https://doi.org/10.1145/3637528.3671536)|Fudong Lin, Kaleb Guillot, Summer Crawford, Yihe Zhang, Xu Yuan, NianFeng Tzeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Open+and+Large-Scale+Dataset+for+Multi-Modal+Climate+Change-aware+Crop+Yield+Predictions)|0|
|[Modeling User Retention through Generative Flow Networks](https://doi.org/10.1145/3637528.3671531)|Ziru Liu, Shuchang Liu, Bin Yang, Zhenghai Xue, Qingpeng Cai, Xiangyu Zhao, Zijian Zhang, Lantao Hu, Han Li, Peng Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+User+Retention+through+Generative+Flow+Networks)|0|
|[BacktrackSTL: Ultra-Fast Online Seasonal-Trend Decomposition with Backtrack Technique](https://doi.org/10.1145/3637528.3671510)|Haoyu Wang, Hongke Guo, Zhaoliang Zhu, You Zhang, Yu Zhou, Xudong Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BacktrackSTL:+Ultra-Fast+Online+Seasonal-Trend+Decomposition+with+Backtrack+Technique)|0|
|[Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising](https://doi.org/10.1145/3637528.3671529)|Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, Yifan Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Ensemble+Shape+Calibration:+Multi-Field+Post-hoc+Calibration+in+Online+Advertising)|0|
|[GraphStorm: All-in-one Graph Machine Learning Framework for Industry Applications](https://doi.org/10.1145/3637528.3671603)|Da Zheng, Xiang Song, Qi Zhu, Jian Zhang, Theodore Vasiloudis, Runjie Ma, Houyu Zhang, Zichen Wang, Soji Adeshina, Israt Nisa, Alejandro Mottini, Qingjun Cui, Huzefa Rangwala, Belinda Zeng, Christos Faloutsos, George Karypis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphStorm:+All-in-one+Graph+Machine+Learning+Framework+for+Industry+Applications)|0|
|[A Tutorial on Multi-Armed Bandit Applications for Large Language Models](https://doi.org/10.1145/3637528.3671440)|Djallel Bouneffouf, Raphaël Féraud||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tutorial+on+Multi-Armed+Bandit+Applications+for+Large+Language+Models)|0|
|[Domain-Driven LLM Development: Insights into RAG and Fine-Tuning Practices](https://doi.org/10.1145/3637528.3671445)|José Cassio dos Santos Junior, Rachel Hu, Richard Song, Yunfei Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain-Driven+LLM+Development:+Insights+into+RAG+and+Fine-Tuning+Practices)|0|
|[Recent and Upcoming Developments in Randomized Numerical Linear Algebra for Machine Learning](https://doi.org/10.1145/3637528.3671461)|Michal Derezinski, Michael W. Mahoney||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recent+and+Upcoming+Developments+in+Randomized+Numerical+Linear+Algebra+for+Machine+Learning)|0|
|[Graph Machine Learning Meets Multi-Table Relational Data](https://doi.org/10.1145/3637528.3671471)|Quan Gan, Minjie Wang, David Wipf, Christos Faloutsos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Machine+Learning+Meets+Multi-Table+Relational+Data)|0|
|[Systems for Scalable Graph Analytics and Machine Learning: Trends and Methods](https://doi.org/10.1145/3637528.3671472)|Da Yan, Lyuheng Yuan, Akhlaque Ahmad, Chenguang Zheng, Hongzhi Chen, James Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Systems+for+Scalable+Graph+Analytics+and+Machine+Learning:+Trends+and+Methods)|0|
|[Machine Learning in Finance](https://doi.org/10.1145/3637528.3671488)|Leman Akoglu, Nitesh V. Chawla, Josep DomingoFerrer, Eren Kurshan, Senthil Kumar, Vidyut M. Naware, José A. RodríguezSerrano, Isha Chaturvedi, Saurabh Nagrecha, Mahashweta Das, Tanveer A. Faruquie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Machine+Learning+in+Finance)|0|
|[From Word-prediction to Complex Skills: Compositional Thinking and Metacognition in LLMs](https://doi.org/10.1145/3637528.3672193)|Sanjeev Arora||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Word-prediction+to+Complex+Skills:+Compositional+Thinking+and+Metacognition+in+LLMs)|0|
|[GEO: Generative Engine Optimization](https://doi.org/10.1145/3637528.3671900)|Pranjal Aggarwal, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan, Ameet Deshpande||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GEO:+Generative+Engine+Optimization)|0|
|[AI for Nature: From Science to Impact](https://doi.org/10.1145/3637528.3672192)|Tanya Y. BergerWolf||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+for+Nature:+From+Science+to+Impact)|0|
|[Statistical Models of Top-k Partial Orders](https://doi.org/10.1145/3637528.3672014)|Amel Awadelkarim, Johan Ugander||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Statistical+Models+of+Top-k+Partial+Orders)|0|
|[Resilient k-Clustering](https://doi.org/10.1145/3637528.3671888)|Sara Ahmadian, MohammadHossein Bateni, Hossein Esfandiari, Silvio Lattanzi, Morteza Monemizadeh, Ashkan NorouziFard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Resilient+k-Clustering)|0|
|[A Learned Generalized Geodesic Distance Function-Based Approach for Node Feature Augmentation on Graphs](https://doi.org/10.1145/3637528.3671858)|Amitoz Azad, Yuan Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Learned+Generalized+Geodesic+Distance+Function-Based+Approach+for+Node+Feature+Augmentation+on+Graphs)|0|
|[Improved Active Covering via Density-Based Space Transformation](https://doi.org/10.1145/3637528.3671794)|MohammadHossein Bateni, Hossein Esfandiari, Samira HosseinGhorban, Alipasha Montaseri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improved+Active+Covering+via+Density-Based+Space+Transformation)|0|
|[Towards Robust Information Extraction via Binomial Distribution Guided Counterpart Sequence](https://doi.org/10.1145/3637528.3672067)|Yinhao Bai, Yuhua Zhao, Zhixin Han, Hang Gao, Chao Xue, Mengting Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Robust+Information+Extraction+via+Binomial+Distribution+Guided+Counterpart+Sequence)|0|
|[Graph Mamba: Towards Learning on Graphs with State Space Models](https://doi.org/10.1145/3637528.3672044)|Ali Behrouz, Farnoosh Hashemi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Mamba:+Towards+Learning+on+Graphs+with+State+Space+Models)|0|
|[FaultInsight: Interpreting Hyperscale Data Center Host Faults](https://doi.org/10.1145/3637528.3672051)|Tingzhu Bi, Yang Zhang, Yicheng Pan, Yu Zhang, Meng Ma, Xinrui Jiang, Linlin Han, Feng Wang, Xian Liu, Ping Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FaultInsight:+Interpreting+Hyperscale+Data+Center+Host+Faults)|0|
|[Making Temporal Betweenness Computation Faster and Restless](https://doi.org/10.1145/3637528.3671825)|Filippo Brunelli, Pierluigi Crescenzi, Laurent Viennot||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Making+Temporal+Betweenness+Computation+Faster+and+Restless)|0|
|[Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization](https://doi.org/10.1145/3637528.3671707)|Shuzhi Cao, Jianfei Ruan, Bo Dong, Bin Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tackling+Instance-Dependent+Label+Noise+with+Class+Rebalance+and+Geometric+Regularization)|0|
|[DiffusionE: Reasoning on Knowledge Graphs via Diffusion-based Graph Neural Networks](https://doi.org/10.1145/3637528.3671997)|Zongsheng Cao, Jing Li, Zigan Wang, Jinliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiffusionE:+Reasoning+on+Knowledge+Graphs+via+Diffusion-based+Graph+Neural+Networks)|0|
|[Path-based Explanation for Knowledge Graph Completion](https://doi.org/10.1145/3637528.3671683)|Heng Chang, Jiangnan Ye, Alejo LopezAvila, Jinhua Du, Jia Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Path-based+Explanation+for+Knowledge+Graph+Completion)|0|
|[Cluster-Wide Task Slowdown Detection in Cloud System](https://doi.org/10.1145/3637528.3671936)|Feiyi Chen, Yingying Zhang, Lunting Fan, Yuxuan Liang, Guansong Pang, Qingsong Wen, Shuiguang Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cluster-Wide+Task+Slowdown+Detection+in+Cloud+System)|0|
|[Scalable Algorithm for Finding Balanced Subgraphs with Tolerance in Signed Networks](https://doi.org/10.1145/3637528.3671674)|Jingbang Chen, Qiuyang Mang, Hangrui Zhou, Richard Peng, Yu Gao, Chenhao Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Algorithm+for+Finding+Balanced+Subgraphs+with+Tolerance+in+Signed+Networks)|0|
|[QGRL: Quaternion Graph Representation Learning for Heterogeneous Feature Data Clustering](https://doi.org/10.1145/3637528.3671839)|Junyang Chen, Yuzhu Ji, Rong Zou, Yiqun Zhang, Yiuming Cheung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QGRL:+Quaternion+Graph+Representation+Learning+for+Heterogeneous+Feature+Data+Clustering)|0|
|[Can a Deep Learning Model be a Sure Bet for Tabular Prediction?](https://doi.org/10.1145/3637528.3671893)|Jintai Chen, Jiahuan Yan, Qiyuan Chen, Danny Z. Chen, Jian Wu, Jimeng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+a+Deep+Learning+Model+be+a+Sure+Bet+for+Tabular+Prediction?)|0|
|[Profiling Urban Streets: A Semi-Supervised Prediction Model Based on Street View Imagery and Spatial Topology](https://doi.org/10.1145/3637528.3671918)|Meng Chen, Zechen Li, Weiming Huang, Yongshun Gong, Yilong Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Profiling+Urban+Streets:+A+Semi-Supervised+Prediction+Model+Based+on+Street+View+Imagery+and+Spatial+Topology)|0|
|[Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network](https://doi.org/10.1145/3637528.3671965)|Lin Chen, Fengli Xu, Nian Li, Zhenyu Han, Meng Wang, Yong Li, Pan Hui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Model-driven+Meta-structure+Discovery+in+Heterogeneous+Information+Network)|0|
|[Hate Speech Detection with Generalizable Target-aware Fairness](https://doi.org/10.1145/3637528.3671821)|Tong Chen, Danny Wang, Xurong Liang, Marten Risius, Gianluca Demartini, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hate+Speech+Detection+with+Generalizable+Target-aware+Fairness)|0|
|[GraphWiz: An Instruction-Following Language Model for Graph Computational Problems](https://doi.org/10.1145/3637528.3672010)|Nuo Chen, Yuhan Li, Jianheng Tang, Jia Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphWiz:+An+Instruction-Following+Language+Model+for+Graph+Computational+Problems)|0|
|[Calibration of Time-Series Forecasting: Detecting and Adapting Context-Driven Distribution Shift](https://doi.org/10.1145/3637528.3671926)|Mouxiang Chen, Lefei Shen, Han Fu, Zhuo Li, Jianling Sun, Chenghao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibration+of+Time-Series+Forecasting:+Detecting+and+Adapting+Context-Driven+Distribution+Shift)|0|
|[Co-Neighbor Encoding Schema: A Light-cost Structure Encoding Method for Dynamic Link Prediction](https://doi.org/10.1145/3637528.3671770)|Ke Cheng, Linzhi Peng, Junchen Ye, Leilei Sun, Bowen Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-Neighbor+Encoding+Schema:+A+Light-cost+Structure+Encoding+Method+for+Dynamic+Link+Prediction)|0|
|[Resurrecting Label Propagation for Graphs with Heterophily and Label Noise](https://doi.org/10.1145/3637528.3671774)|Yao Cheng, Caihua Shan, Yifei Shen, Xiang Li, Siqiang Luo, Dongsheng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Resurrecting+Label+Propagation+for+Graphs+with+Heterophily+and+Label+Noise)|0|
|[DyGKT: Dynamic Graph Learning for Knowledge Tracing](https://doi.org/10.1145/3637528.3671773)|Ke Cheng, Linzhi Peng, Pengyang Wang, Junchen Ye, Leilei Sun, Bowen Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DyGKT:+Dynamic+Graph+Learning+for+Knowledge+Tracing)|0|
|[Conformal Counterfactual Inference under Hidden Confounding](https://doi.org/10.1145/3637528.3671976)|Zonghao Chen, Ruocheng Guo, JeanFrancois Ton, Yang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conformal+Counterfactual+Inference+under+Hidden+Confounding)|0|
|[Leveraging Pedagogical Theories to Understand Student Learning Process with Graph-based Reasonable Knowledge Tracing](https://doi.org/10.1145/3637528.3671853)|Jiajun Cui, Hong Qian, Bo Jiang, Wei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Pedagogical+Theories+to+Understand+Student+Learning+Process+with+Graph-based+Reasonable+Knowledge+Tracing)|0|
|[Iterative Weak Learnability and Multiclass AdaBoost](https://doi.org/10.1145/3637528.3671842)|InKoo Cho, Jonathan A. Libgober, Cheng Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Iterative+Weak+Learnability+and+Multiclass+AdaBoost)|0|
|[Divide and Denoise: Empowering Simple Models for Robust Semi-Supervised Node Classification against Label Noise](https://doi.org/10.1145/3637528.3671798)|Kaize Ding, Xiaoxiao Ma, Yixin Liu, Shirui Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Divide+and+Denoise:+Empowering+Simple+Models+for+Robust+Semi-Supervised+Node+Classification+against+Label+Noise)|0|
|[Unraveling Block Maxima Forecasting Models with Counterfactual Explanation](https://doi.org/10.1145/3637528.3671923)|Yue Deng, Asadullah Hill Galib, PangNing Tan, Lifeng Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unraveling+Block+Maxima+Forecasting+Models+with+Counterfactual+Explanation)|0|
|[Explanatory Model Monitoring to Understand the Effects of Feature Shifts on Performance](https://doi.org/10.1145/3637528.3671959)|Thomas Decker, Alexander Koebler, Michael Lebacher, Ingo Thon, Volker Tresp, Florian Buettner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explanatory+Model+Monitoring+to+Understand+the+Effects+of+Feature+Shifts+on+Performance)|0|
|[Fast Unsupervised Deep Outlier Model Selection with Hypernetworks](https://doi.org/10.1145/3637528.3672003)|Xueying Ding, Yue Zhao, Leman Akoglu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Unsupervised+Deep+Outlier+Model+Selection+with+Hypernetworks)|0|
|[Enhancing On-Device LLM Inference with Historical Cloud-Based LLM Interactions](https://doi.org/10.1145/3637528.3671679)|Yucheng Ding, Chaoyue Niu, Fan Wu, Shaojie Tang, Chengfei Lyu, Guihai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+On-Device+LLM+Inference+with+Historical+Cloud-Based+LLM+Interactions)|0|
|[IDEA: A Flexible Framework of Certified Unlearning for Graph Neural Networks](https://doi.org/10.1145/3637528.3671744)|Yushun Dong, Binchi Zhang, Zhenyu Lei, Na Zou, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IDEA:+A+Flexible+Framework+of+Certified+Unlearning+for+Graph+Neural+Networks)|0|
|[Unsupervised Alignment of Hypergraphs with Different Scales](https://doi.org/10.1145/3637528.3671955)|Manh Tuan Do, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Alignment+of+Hypergraphs+with+Different+Scales)|0|
|[Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting](https://doi.org/10.1145/3637528.3671961)|Zheng Dong, Renhe Jiang, Haotian Gao, Hangchen Liu, Jinliang Deng, Qingsong Wen, Xuan Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneity-Informed+Meta-Parameter+Learning+for+Spatiotemporal+Time+Series+Forecasting)|0|
|[Representation Learning of Temporal Graphs with Structural Roles](https://doi.org/10.1145/3637528.3671854)|Huaming Du, Long Shi, Xingyan Chen, Yu Zhao, Hegui Zhang, Carl Yang, Fuzhen Zhuang, Gang Kou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+Learning+of+Temporal+Graphs+with+Structural+Roles)|0|
|[Reserving-Masking-Reconstruction Model for Self-Supervised Heterogeneous Graph Representation](https://doi.org/10.1145/3637528.3671719)|Haoran Duan, Cheng Xie, Linyu Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reserving-Masking-Reconstruction+Model+for+Self-Supervised+Heterogeneous+Graph+Representation)|0|
|[Pre-Training Identification of Graph Winning Tickets in Adaptive Spatial-Temporal Graph Neural Networks](https://doi.org/10.1145/3637528.3671912)|Wenying Duan, Tianxiang Fang, Hong Rao, Xiaoxi He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-Training+Identification+of+Graph+Winning+Tickets+in+Adaptive+Spatial-Temporal+Graph+Neural+Networks)|0|
|[Auctions with LLM Summaries](https://doi.org/10.1145/3637528.3672022)|Avinava Dubey, Zhe Feng, Rahul Kidambi, Aranyak Mehta, Di Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Auctions+with+LLM+Summaries)|0|
|[GAugLLM: Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models](https://doi.org/10.1145/3637528.3672035)|Yi Fang, Dongzhe Fan, Daochen Zha, Qiaoyu Tan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAugLLM:+Improving+Graph+Contrastive+Learning+for+Text-Attributed+Graphs+with+Large+Language+Models)|0|
|[CAT: Interpretable Concept-based Taylor Additive Models](https://doi.org/10.1145/3637528.3672020)|Viet Duong, Qiong Wu, Zhengyi Zhou, Hongjue Zhao, Chenxiang Luo, Eric Zavesky, Huaxiu Yao, Huajie Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAT:+Interpretable+Concept-based+Taylor+Additive+Models)|0|
|[SensitiveHUE: Multivariate Time Series Anomaly Detection by Enhancing the Sensitivity to Normal Patterns](https://doi.org/10.1145/3637528.3671919)|Yuye Feng, Wei Zhang, Yao Fu, Weihao Jiang, Jiang Zhu, Wenqi Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SensitiveHUE:+Multivariate+Time+Series+Anomaly+Detection+by+Enhancing+the+Sensitivity+to+Normal+Patterns)|0|
|[Communication-efficient Multi-service Mobile Traffic Prediction by Leveraging Cross-service Correlations](https://doi.org/10.1145/3637528.3671730)|Zhiying Feng, Qiong Wu, Xu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Communication-efficient+Multi-service+Mobile+Traffic+Prediction+by+Leveraging+Cross-service+Correlations)|0|
|[Federated Graph Learning with Structure Proxy Alignment](https://doi.org/10.1145/3637528.3671717)|Xingbo Fu, Zihan Chen, Binchi Zhang, Chen Chen, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Graph+Learning+with+Structure+Proxy+Alignment)|0|
|[Policy-Based Bayesian Active Causal Discovery with Deep Reinforcement Learning](https://doi.org/10.1145/3637528.3671705)|Heyang Gao, Zexu Sun, Hao Yang, Xu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Policy-Based+Bayesian+Active+Causal+Discovery+with+Deep+Reinforcement+Learning)|0|
|[Graph Condensation for Open-World Graph Learning](https://doi.org/10.1145/3637528.3671917)|Xinyi Gao, Tong Chen, Wentao Zhang, Yayong Li, Xiangguo Sun, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Condensation+for+Open-World+Graph+Learning)|0|
|[PATE: Proximity-Aware Time Series Anomaly Evaluation](https://doi.org/10.1145/3637528.3671971)|Ramin Ghorbani, Marcel J. T. Reinders, David M. J. Tax||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PATE:+Proximity-Aware+Time+Series+Anomaly+Evaluation)|0|
|[Hierarchical Neural Constructive Solver for Real-world TSP Scenarios](https://doi.org/10.1145/3637528.3672053)|Yong Liang Goh, Zhiguang Cao, Yining Ma, Yanfei Dong, Mohammed Haroon Dupty, Wee Sun Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Neural+Constructive+Solver+for+Real-world+TSP+Scenarios)|0|
|[An Energy-centric Framework for Category-free Out-of-distribution Node Detection in Graphs](https://doi.org/10.1145/3637528.3671939)|Zheng Gong, Ying Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Energy-centric+Framework+for+Category-free+Out-of-distribution+Node+Detection+in+Graphs)|0|
|[Investigating Out-of-Distribution Generalization of GNNs: An Architecture Perspective](https://doi.org/10.1145/3637528.3671792)|Kai Guo, Hongzhi Wen, Wei Jin, Yaming Guo, Jiliang Tang, Yi Chang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Out-of-Distribution+Generalization+of+GNNs:+An+Architecture+Perspective)|0|
|[HiFGL: A Hierarchical Framework for Cross-silo Cross-device Federated Graph Learning](https://doi.org/10.1145/3637528.3671660)|Zhuoning Guo, Duanyi Yao, Qiang Yang, Hao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiFGL:+A+Hierarchical+Framework+for+Cross-silo+Cross-device+Federated+Graph+Learning)|0|
|[AnyLoss: Transforming Classification Metrics into Loss Functions](https://doi.org/10.1145/3637528.3672017)|Do Heon Han, Nuno Moniz, Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AnyLoss:+Transforming+Classification+Metrics+into+Loss+Functions)|0|
|[Expander Hierarchies for Normalized Cuts on Graphs](https://doi.org/10.1145/3637528.3671978)|Kathrin Hanauer, Monika Henzinger, Robin Münk, Harald Räcke, Maximilian Vötsch||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expander+Hierarchies+for+Normalized+Cuts+on+Graphs)|0|
|[Model-Agnostic Random Weighting for Out-of-Distribution Generalization](https://doi.org/10.1145/3637528.3671762)|Yue He, Pengfei Tian, Renzhe Xu, Xinwei Shen, Xingxuan Zhang, Peng Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Model-Agnostic+Random+Weighting+for+Out-of-Distribution+Generalization)|0|
|[RoutePlacer: An End-to-End Routability-Aware Placer with Graph Neural Network](https://doi.org/10.1145/3637528.3671895)|Yunbo Hou, Haoran Ye, Yingxue Zhang, Siyuan Xu, Guojie Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RoutePlacer:+An+End-to-End+Routability-Aware+Placer+with+Graph+Neural+Network)|0|
|[Is Aggregation the Only Choice? Federated Learning via Layer-wise Model Recombination](https://doi.org/10.1145/3637528.3671722)|Ming Hu, Zhihao Yue, Xiaofei Xie, Cheng Chen, Yihao Huang, Xian Wei, Xiang Lian, Yang Liu, Mingsong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+Aggregation+the+Only+Choice?+Federated+Learning+via+Layer-wise+Model+Recombination)|0|
|[Privacy-Preserved Neural Graph Databases](https://doi.org/10.1145/3637528.3671678)|Qi Hu, Haoran Li, Jiaxin Bai, Zihao Wang, Yangqiu Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserved+Neural+Graph+Databases)|0|
|[EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy](https://doi.org/10.1145/3637528.3671943)|Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, Xuemin Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EntropyStop:+Unsupervised+Deep+Outlier+Detection+with+Loss+Entropy)|0|
|[RC-Mixup: A Data Augmentation Strategy against Noisy Data for Regression Tasks](https://doi.org/10.1145/3637528.3671993)|Seonghyeon Hwang, Minsu Kim, Steven Euijong Whang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RC-Mixup:+A+Data+Augmentation+Strategy+against+Noisy+Data+for+Regression+Tasks)|0|
|[Learn Together Stop Apart: An Inclusive Approach to Ensemble Pruning](https://doi.org/10.1145/3637528.3672018)|Bulat Ibragimov, Gleb Gusev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learn+Together+Stop+Apart:+An+Inclusive+Approach+to+Ensemble+Pruning)|0|
|[Efficient Discovery of Time Series Motifs under both Length Differences and Warping](https://doi.org/10.1145/3637528.3671726)|Makoto Imamura, Takaaki Nakamura||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Discovery+of+Time+Series+Motifs+under+both+Length+Differences+and+Warping)|0|
|[Promoting Fairness and Priority in Selecting k-Winners Using IRV](https://doi.org/10.1145/3637528.3671735)|Md Mouinul Islam, Soroush Vahidi, Baruch Schieber, Senjuti Basu Roy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Promoting+Fairness+and+Priority+in+Selecting+k-Winners+Using+IRV)|0|
|[FreQuant: A Reinforcement-Learning based Adaptive Portfolio Optimization with Multi-frequency Decomposition](https://doi.org/10.1145/3637528.3671668)|Jihyeong Jeon, Jiwon Park, Chanhee Park, U Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FreQuant:+A+Reinforcement-Learning+based+Adaptive+Portfolio+Optimization+with+Multi-frequency+Decomposition)|0|
|[Addressing Prediction Delays in Time Series Forecasting: A Continuous GRU Approach with Derivative Regularization](https://doi.org/10.1145/3637528.3671969)|Sheo Yon Jhin, Seojin Kim, Noseong Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Prediction+Delays+in+Time+Series+Forecasting:+A+Continuous+GRU+Approach+with+Derivative+Regularization)|0|
|[MemMap: An Adaptive and Latent Memory Structure for Dynamic Graph Learning](https://doi.org/10.1145/3637528.3672060)|Shuo Ji, Mingzhe Liu, Leilei Sun, Chuanren Liu, Tongyu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemMap:+An+Adaptive+and+Latent+Memory+Structure+for+Dynamic+Graph+Learning)|0|
|[Tensorized Unaligned Multi-view Clustering with Multi-scale Representation Learning](https://doi.org/10.1145/3637528.3671689)|Jintian Ji, Songhe Feng, Yidong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tensorized+Unaligned+Multi-view+Clustering+with+Multi-scale+Representation+Learning)|0|
|[Killing Two Birds with One Stone: Cross-modal Reinforced Prompting for Graph and Language Tasks](https://doi.org/10.1145/3637528.3671742)|Wenyuan Jiang, Wenwei Wu, Le Zhang, Zixuan Yuan, Jian Xiang, Jingbo Zhou, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Killing+Two+Birds+with+One+Stone:+Cross-modal+Reinforced+Prompting+for+Graph+and+Language+Tasks)|0|
|[Sketch-Based Replay Projection for Continual Learning](https://doi.org/10.1145/3637528.3671714)|Jack Julian, Yun Sing Koh, Albert Bifet||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sketch-Based+Replay+Projection+for+Continual+Learning)|0|
|[RCTD: Reputation-Constrained Truth Discovery in Sybil Attack Crowdsourcing Environment](https://doi.org/10.1145/3637528.3671803)|Xing Jin, Zhihai Gong, Jiuchuan Jiang, Chao Wang, Jian Zhang, Zhen Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RCTD:+Reputation-Constrained+Truth+Discovery+in+Sybil+Attack+Crowdsourcing+Environment)|0|
|[Bivariate Decision Trees: Smaller, Interpretable, More Accurate](https://doi.org/10.1145/3637528.3671903)|Rasul Kairgeldin, Miguel Á. CarreiraPerpiñán||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bivariate+Decision+Trees:+Smaller,+Interpretable,+More+Accurate)|0|
|[CAFO: Feature-Centric Explanation on Time Series Classification](https://doi.org/10.1145/3637528.3671724)|Jaeho Kim, SeokJu Hahn, Yoontae Hwang, Junghye Lee, Seulki Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAFO:+Feature-Centric+Explanation+on+Time+Series+Classification)|0|
|[Gandalf: Learning Label-label Correlations in Extreme Multi-label Classification via Label Features](https://doi.org/10.1145/3637528.3672063)|Siddhant Kharbanda, Devaansh Gupta, Erik Schultheis, Atmadeep Banerjee, ChoJui Hsieh, Rohit Babbar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gandalf:+Learning+Label-label+Correlations+in+Extreme+Multi-label+Classification+via+Label+Features)|0|
|[OntoType: Ontology-Guided and Pre-Trained Language Model Assisted Fine-Grained Entity Typing](https://doi.org/10.1145/3637528.3671745)|Tanay Komarlu, Minhao Jiang, Xuan Wang, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OntoType:+Ontology-Guided+and+Pre-Trained+Language+Model+Assisted+Fine-Grained+Entity+Typing)|0|
|[LeMon: Automating Portrait Generation for Zero-Shot Story Visualization with Multi-Character Interactions](https://doi.org/10.1145/3637528.3671850)|Ziyi Kou, Shichao Pei, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LeMon:+Automating+Portrait+Generation+for+Zero-Shot+Story+Visualization+with+Multi-Character+Interactions)|0|
|[Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Leman Go Indifferent](https://doi.org/10.1145/3637528.3671890)|Lorenz Kummer, Samir Moustafa, Sebastian Schrittwieser, Wilfried N. Gansterer, Nils M. Kriege||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attacking+Graph+Neural+Networks+with+Bit+Flips:+Weisfeiler+and+Leman+Go+Indifferent)|0|
|[Max-Min Diversification with Asymmetric Distances](https://doi.org/10.1145/3637528.3671757)|Iiro Kumpulainen, Florian Adriaens, Nikolaj Tatti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Max-Min+Diversification+with+Asymmetric+Distances)|0|
|[Efficient Topology-aware Data Augmentation for High-Degree Graph Neural Networks](https://doi.org/10.1145/3637528.3671765)|Yurui Lai, Xiaoyang Lin, Renchi Yang, Hongtao Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Topology-aware+Data+Augmentation+for+High-Degree+Graph+Neural+Networks)|0|
|[ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification](https://doi.org/10.1145/3637528.3671862)|XuanMay Thi Le, Ling Luo, Uwe Aickelin, MinhTuan Tran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ShapeFormer:+Shapelet+Transformer+for+Multivariate+Time+Series+Classification)|0|
|[ReCTSi: Resource-efficient Correlated Time Series Imputation via Decoupled Pattern Learning and Completeness-aware Attentions](https://doi.org/10.1145/3637528.3671816)|Zhichen Lai, Dalin Zhang, Huan Li, Dongxiang Zhang, Hua Lu, Christian S. Jensen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReCTSi:+Resource-efficient+Correlated+Time+Series+Imputation+via+Decoupled+Pattern+Learning+and+Completeness-aware+Attentions)|0|
|[Layer-Wise Adaptive Gradient Norm Penalizing Method for Efficient and Accurate Deep Learning](https://doi.org/10.1145/3637528.3671728)|Sunwoo Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Layer-Wise+Adaptive+Gradient+Norm+Penalizing+Method+for+Efficient+and+Accurate+Deep+Learning)|0|
|[Label Learning Method Based on Tensor Projection](https://doi.org/10.1145/3637528.3671671)|Jing Li, Quanxue Gao, Qianqian Wang, Cheng Deng, DeYan Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Label+Learning+Method+Based+on+Tensor+Projection)|0|
|[Physics-informed Neural ODE for Post-disaster Mobility Recovery](https://doi.org/10.1145/3637528.3672027)|Jiahao Li, Huandong Wang, Xinlei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Physics-informed+Neural+ODE+for+Post-disaster+Mobility+Recovery)|0|
|[Causal Subgraph Learning for Generalizable Inductive Relation Prediction](https://doi.org/10.1145/3637528.3671972)|Mei Li, Xiaoguang Liu, Hua Ji, Shuangjia Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Subgraph+Learning+for+Generalizable+Inductive+Relation+Prediction)|0|
|[SimDiff: Simple Denoising Probabilistic Latent Diffusion Model for Data Augmentation on Multi-modal Knowledge Graph](https://doi.org/10.1145/3637528.3671769)|Ran Li, Shimin Di, Lei Chen, Xiaofang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SimDiff:+Simple+Denoising+Probabilistic+Latent+Diffusion+Model+for+Data+Augmentation+on+Multi-modal+Knowledge+Graph)|0|
|[ITPNet: Towards Instantaneous Trajectory Prediction for Autonomous Driving](https://doi.org/10.1145/3637528.3671681)|Rongqing Li, Changsheng Li, Yuhang Li, Hanjie Li, Yi Chen, Ye Yuan, Guoren Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ITPNet:+Towards+Instantaneous+Trajectory+Prediction+for+Autonomous+Driving)|0|
|[InLN: Knowledge-aware Incremental Leveling Network for Dynamic Advertising](https://doi.org/10.1145/3637528.3672032)|Xujia Li, Jingshu Peng, Lei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InLN:+Knowledge-aware+Incremental+Leveling+Network+for+Dynamic+Advertising)|0|
|[Bi-Objective Contract Allocation for Guaranteed Delivery Advertising](https://doi.org/10.1145/3637528.3671752)|Yan Li, Yundu Huang, Wuyang Mao, Furong Ye, Xiang He, Zhonglin Zu, Shaowei Cai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bi-Objective+Contract+Allocation+for+Guaranteed+Delivery+Advertising)|0|
|[Improving Robustness of Hyperbolic Neural Networks by Lipschitz Analysis](https://doi.org/10.1145/3637528.3671875)|Yuekang Li, Yidan Mao, Yifei Yang, Dongmian Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Robustness+of+Hyperbolic+Neural+Networks+by+Lipschitz+Analysis)|0|
|[ZeroG: Investigating Cross-dataset Zero-shot Transferability in Graphs](https://doi.org/10.1145/3637528.3671982)|Yuhan Li, Peisong Wang, Zhixun Li, Jeffrey Xu Yu, Jia Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ZeroG:+Investigating+Cross-dataset+Zero-shot+Transferability+in+Graphs)|0|
|[Rethinking Fair Graph Neural Networks from Re-balancing](https://doi.org/10.1145/3637528.3671826)|Zhixun Li, Yushun Dong, Qiang Liu, Jeffrey Xu Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Fair+Graph+Neural+Networks+from+Re-balancing)|0|
|[MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction](https://doi.org/10.1145/3637528.3672030)|Li Lin, Zhiqiang Lu, Shuai Wang, Yunhuai Liu, Zhiqing Hong, Haotian Wang, Shuai Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MulSTE:+A+Multi-view+Spatio-temporal+Learning+Framework+with+Heterogeneous+Event+Fusion+for+Demand-supply+Prediction)|0|
|[PSMC: Provable and Scalable Algorithms for Motif Conductance Based Graph Clustering](https://doi.org/10.1145/3637528.3671666)|Longlong Lin, Tao Jia, Zeli Wang, Jin Zhao, RongHua Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PSMC:+Provable+and+Scalable+Algorithms+for+Motif+Conductance+Based+Graph+Clustering)|0|
|[CONFIDE: Contextual Finite Difference Modelling of PDEs](https://doi.org/10.1145/3637528.3671676)|Ori Linial, Orly Avner, Dotan Di Castro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CONFIDE:+Contextual+Finite+Difference+Modelling+of+PDEs)|0|
|[CASA: Clustered Federated Learning with Asynchronous Clients](https://doi.org/10.1145/3637528.3671979)|Boyi Liu, Yiming Ma, Zimu Zhou, Yexuan Shi, Shuyuan Li, Yongxin Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CASA:+Clustered+Federated+Learning+with+Asynchronous+Clients)|0|
|[FAST: An Optimization Framework for Fast Additive Segmentation in Transparent ML](https://doi.org/10.1145/3637528.3671996)|Brian Liu, Rahul Mazumder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FAST:+An+Optimization+Framework+for+Fast+Additive+Segmentation+in+Transparent+ML)|0|
|[Asymmetric Beta Loss for Evidence-Based Safe Semi-Supervised Multi-Label Learning](https://doi.org/10.1145/3637528.3671756)|HaoZhe Liu, MingKun Xie, ChenChen Zong, ShengJun Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Asymmetric+Beta+Loss+for+Evidence-Based+Safe+Semi-Supervised+Multi-Label+Learning)|0|
|[An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem](https://doi.org/10.1145/3637528.3671704)|Huaiyuan Liu, Xianzhang Liu, Donghua Yang, Hongzhi Wang, Yingchi Long, Mengtong Ji, Dongjing Miao, Zhiyu Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Unsupervised+Learning+Framework+Combined+with+Heuristics+for+the+Maximum+Minimal+Cut+Problem)|0|
|[ACER: Accelerating Complex Event Recognition via Two-Phase Filtering under Range Bitmap-Based Indexes](https://doi.org/10.1145/3637528.3671814)|Shizhe Liu, Haipeng Dai, Shaoxu Song, Meng Li, Jingsong Dai, Rong Gu, Guihai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACER:+Accelerating+Complex+Event+Recognition+via+Two-Phase+Filtering+under+Range+Bitmap-Based+Indexes)|0|
|[Revisiting Modularity Maximization for Graph Clustering: A Contrastive Learning Perspective](https://doi.org/10.1145/3637528.3671967)|Yunfei Liu, Jintang Li, Yuehe Chen, Ruofan Wu, Ericbk Wang, Jing Zhou, Sheng Tian, Shuheng Shen, Xing Fu, Changhua Meng, Weiqiang Wang, Liang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Modularity+Maximization+for+Graph+Clustering:+A+Contrastive+Learning+Perspective)|0|
|[Graph Data Condensation via Self-expressive Graph Structure Reconstruction](https://doi.org/10.1145/3637528.3671710)|Zhanyu Liu, Chaolv Zeng, Guanjie Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Data+Condensation+via+Self-expressive+Graph+Structure+Reconstruction)|0|
|[Generative Pretrained Hierarchical Transformer for Time Series Forecasting](https://doi.org/10.1145/3637528.3671855)|Zhiding Liu, Jiqian Yang, Mingyue Cheng, Yucong Luo, Zhi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Pretrained+Hierarchical+Transformer+for+Time+Series+Forecasting)|0|
|[AIM: Attributing, Interpreting, Mitigating Data Unfairness](https://doi.org/10.1145/3637528.3671797)|Zhining Liu, Ruizhong Qiu, Zhichen Zeng, Yada Zhu, Hendrik F. Hamann, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AIM:+Attributing,+Interpreting,+Mitigating+Data+Unfairness)|0|
|[High-Dimensional Distributed Sparse Classification with Scalable Communication-Efficient Global Updates](https://doi.org/10.1145/3637528.3672038)|Fred Lu, Ryan R. Curtin, Edward Raff, Francis Ferraro, James Holt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=High-Dimensional+Distributed+Sparse+Classification+with+Scalable+Communication-Efficient+Global+Updates)|0|
|[FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks](https://doi.org/10.1145/3637528.3671834)|Renqiang Luo, Huafei Huang, Shuo Yu, Zhuoyang Han, Estrid He, Xiuzhen Zhang, Feng Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FUGNN:+Harmonizing+Fairness+and+Utility+in+Graph+Neural+Networks)|0|
|[Learning Multi-view Molecular Representations with Structured and Unstructured Knowledge](https://doi.org/10.1145/3637528.3672043)|Yizhen Luo, Kai Yang, Massimo Hong, Xing Yi Liu, Zikun Nie, Hao Zhou, Zaiqing Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Multi-view+Molecular+Representations+with+Structured+and+Unstructured+Knowledge)|0|
|[Cross-Context Backdoor Attacks against Graph Prompt Learning](https://doi.org/10.1145/3637528.3671956)|Xiaoting Lyu, Yufei Han, Wei Wang, Hangwei Qian, Ivor Tsang, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Context+Backdoor+Attacks+against+Graph+Prompt+Learning)|0|
|[PolyFormer: Scalable Node-wise Filters via Polynomial Graph Transformer](https://doi.org/10.1145/3637528.3671849)|Jiahong Ma, Mingguo He, Zhewei Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PolyFormer:+Scalable+Node-wise+Filters+via+Polynomial+Graph+Transformer)|0|
|[Scalable Differentiable Causal Discovery in the Presence of Latent Confounders with Skeleton Posterior](https://doi.org/10.1145/3637528.3672031)|Pingchuan Ma, Rui Ding, Qiang Fu, Jiaru Zhang, Shuai Wang, Shi Han, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Differentiable+Causal+Discovery+in+the+Presence+of+Latent+Confounders+with+Skeleton+Posterior)|0|
|[Graph Anomaly Detection with Few Labels: A Data-Centric Approach](https://doi.org/10.1145/3637528.3671929)|Xiaoxiao Ma, Ruikun Li, Fanzhen Liu, Kaize Ding, Jian Yang, Jia Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Anomaly+Detection+with+Few+Labels:+A+Data-Centric+Approach)|0|
|[A Uniformly Bounded Correlation Function for Spatial Point Patterns](https://doi.org/10.1145/3637528.3671891)|Evgenia Martynova, Johannes Textor||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Uniformly+Bounded+Correlation+Function+for+Spatial+Point+Patterns)|0|
|[Fair Column Subset Selection](https://doi.org/10.1145/3637528.3672005)|Antonis Matakos, Bruno Ordozgoiti, Suhas Thejaswi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Column+Subset+Selection)|0|
|[FLAIM: AIM-based Synthetic Data Generation in the Federated Setting](https://doi.org/10.1145/3637528.3671990)|Samuel Maddock, Graham Cormode, Carsten Maple||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLAIM:+AIM-based+Synthetic+Data+Generation+in+the+Federated+Setting)|0|
|[Interpretable Transformer Hawkes Processes: Unveiling Complex Interactions in Social Networks](https://doi.org/10.1145/3637528.3671720)|Zizhuo Meng, Ke Wan, Yadong Huang, Zhidong Li, Yang Wang, Feng Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Transformer+Hawkes+Processes:+Unveiling+Complex+Interactions+in+Social+Networks)|0|
|[Scaling Training Data with Lossy Image Compression](https://doi.org/10.1145/3637528.3671904)|Katherine L. Mentzer, Andrea Montanari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Training+Data+with+Lossy+Image+Compression)|0|
|[Learning Causal Networks from Episodic Data](https://doi.org/10.1145/3637528.3671999)|Osman Mian, Sarah Mameche, Jilles Vreeken||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Causal+Networks+from+Episodic+Data)|0|
|[Money Never Sleeps: Maximizing Liquidity Mining Yields in Decentralized Finance](https://doi.org/10.1145/3637528.3671942)|Wangze Ni, Yiwei Zhao, Weijie Sun, Lei Chen, Peng Cheng, Chen Jason Zhang, Xuemin Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Money+Never+Sleeps:+Maximizing+Liquidity+Mining+Yields+in+Decentralized+Finance)|0|
|[Mining of Switching Sparse Networks for Missing Value Imputation in Multivariate Time Series](https://doi.org/10.1145/3637528.3671760)|Kohei Obata, Koki Kawabata, Yasuko Matsubara, Yasushi Sakurai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+of+Switching+Sparse+Networks+for+Missing+Value+Imputation+in+Multivariate+Time+Series)|0|
|[Ontology Enrichment for Effective Fine-grained Entity Typing](https://doi.org/10.1145/3637528.3671857)|Siru Ouyang, Jiaxin Huang, Pranav Pillai, Yunyi Zhang, Yu Zhang, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ontology+Enrichment+for+Effective+Fine-grained+Entity+Typing)|0|
|[BTTackler: A Diagnosis-based Framework for Efficient Deep Learning Hyperparameter Optimization](https://doi.org/10.1145/3637528.3671933)|Zhongyi Pei, Zhiyao Cen, Yipeng Huang, Chen Wang, Lin Liu, Philip S. Yu, Mingsheng Long, Jianmin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BTTackler:+A+Diagnosis-based+Framework+for+Efficient+Deep+Learning+Hyperparameter+Optimization)|0|
|[Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection](https://doi.org/10.1145/3637528.3671667)|Yongchan Park, Jongjin Kim, U Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Multidimensional+Partial+Fourier+Transform+with+Automatic+Hyperparameter+Selection)|0|
|[CoMAL: Contrastive Active Learning for Multi-Label Text Classification](https://doi.org/10.1145/3637528.3671754)|Cheng Peng, Haobo Wang, Ke Chen, Lidan Shou, Chang Yao, Runze Wu, Gang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoMAL:+Contrastive+Active+Learning+for+Multi-Label+Text+Classification)|0|
|[TSC: A Simple Two-Sided Constraint against Over-Smoothing](https://doi.org/10.1145/3637528.3671954)|Furong Peng, Kang Liu, Xuan Lu, Yuhua Qian, HongRen Yan, Chao Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TSC:+A+Simple+Two-Sided+Constraint+against+Over-Smoothing)|0|
|[CASH via Optimal Diversity for Ensemble Learning](https://doi.org/10.1145/3637528.3671894)|Pranav Poduval, Sanjay Kumar Patnala, Gaurav Oberoi, Nitish Srivasatava, Siddhartha Asthana||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CASH+via+Optimal+Diversity+for+Ensemble+Learning)|0|
|[Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals](https://doi.org/10.1145/3637528.3671831)|Bardh Prenkaj, Mario VillaizánVallelado, Tobias Leemann, Gjergji Kasneci||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+Evolution,+Explanation,+and+Discernment:+A+Generative+Approach+for+Dynamic+Graph+Counterfactuals)|0|
|[Reimagining Graph Classification from a Prototype View with Optimal Transport: Algorithm and Theorem](https://doi.org/10.1145/3637528.3671696)|Chen Qian, Huayi Tang, Hong Liang, Yong Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reimagining+Graph+Classification+from+a+Prototype+View+with+Optimal+Transport:+Algorithm+and+Theorem)|0|
|[Pre-train and Refine: Towards Higher Efficiency in K-Agnostic Community Detection without Quality Degradation](https://doi.org/10.1145/3637528.3671686)|Meng Qin, Chaorui Zhang, Yu Gao, Weixi Zhang, DitYan Yeung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-train+and+Refine:+Towards+Higher+Efficiency+in+K-Agnostic+Community+Detection+without+Quality+Degradation)|0|
|[RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms](https://doi.org/10.1145/3637528.3672062)|Luis Roque, Carlos Soares, Luís Torgo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RHiOTS:+A+Framework+for+Evaluating+Hierarchical+Time+Series+Forecasting+Algorithms)|0|
|[A Fast Exact Algorithm to Enumerate Maximal Pseudo-cliques in Large Sparse Graphs](https://doi.org/10.1145/3637528.3672066)|Ahsanur Rahman, Kalyan Roy, Ramiza Maliha, Townim Faisal Chowdhury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Fast+Exact+Algorithm+to+Enumerate+Maximal+Pseudo-cliques+in+Large+Sparse+Graphs)|0|
|[CoSLight: Co-optimizing Collaborator Selection and Decision-making to Enhance Traffic Signal Control](https://doi.org/10.1145/3637528.3671998)|Jingqing Ruan, Ziyue Li, Hua Wei, Haoyuan Jiang, Jiaming Lu, Xuantang Xiong, Hangyu Mao, Rui Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoSLight:+Co-optimizing+Collaborator+Selection+and+Decision-making+to+Enhance+Traffic+Signal+Control)|0|
|[A Novel Feature Space Augmentation Method to Improve Classification Performance and Evaluation Reliability](https://doi.org/10.1145/3637528.3671736)|Sakhawat Hossain Saimon, Tanzira Najnin, Jianhua Ruan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Novel+Feature+Space+Augmentation+Method+to+Improve+Classification+Performance+and+Evaluation+Reliability)|0|
|[DPHGNN: A Dual Perspective Hypergraph Neural Networks](https://doi.org/10.1145/3637528.3672047)|Siddhant Saxena, Shounak Ghatak, Raghu Kolla, Debashis Mukherjee, Tanmoy Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPHGNN:+A+Dual+Perspective+Hypergraph+Neural+Networks)|0|
|[Self-Supervised Learning of Time Series Representation via Diffusion Process and Imputation-Interpolation-Forecasting Mask](https://doi.org/10.1145/3637528.3671673)|Zineb Senane, Lele Cao, Valentin Leonhard Buchner, Yusuke Tashiro, Lei You, Pawel Andrzej Herman, Mats Nordahl, Ruibo Tu, Vilhelm von Ehrenheim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Learning+of+Time+Series+Representation+via+Diffusion+Process+and+Imputation-Interpolation-Forecasting+Mask)|0|
|[Self-Explainable Temporal Graph Networks based on Graph Information Bottleneck](https://doi.org/10.1145/3637528.3671962)|Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Explainable+Temporal+Graph+Networks+based+on+Graph+Information+Bottleneck)|0|
|[Offline Imitation Learning with Model-based Reverse Augmentation](https://doi.org/10.1145/3637528.3672059)|JieJing Shao, HaoSen Shi, LanZhe Guo, YuFeng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Imitation+Learning+with+Model-based+Reverse+Augmentation)|0|
|[NeuroCut: A Neural Approach for Robust Graph Partitioning](https://doi.org/10.1145/3637528.3671815)|Rishi Shah, Krishnanshu Jain, Sahil Manchanda, Sourav Medya, Sayan Ranu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeuroCut:+A+Neural+Approach+for+Robust+Graph+Partitioning)|0|
|[Capturing Homogeneous Influence among Students: Hypergraph Cognitive Diagnosis for Intelligent Education Systems](https://doi.org/10.1145/3637528.3672002)|Junhao Shen, Hong Qian, Shuo Liu, Wei Zhang, Bo Jiang, Aimin Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Capturing+Homogeneous+Influence+among+Students:+Hypergraph+Cognitive+Diagnosis+for+Intelligent+Education+Systems)|0|
|[Optimizing OOD Detection in Molecular Graphs: A Novel Approach with Diffusion Models](https://doi.org/10.1145/3637528.3671785)|Xu Shen, Yili Wang, Kaixiong Zhou, Shirui Pan, Xin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+OOD+Detection+in+Molecular+Graphs:+A+Novel+Approach+with+Diffusion+Models)|0|
|[Efficient and Long-Tailed Generalization for Pre-trained Vision-Language Model](https://doi.org/10.1145/3637528.3671945)|JiangXin Shi, Chi Zhang, Tong Wei, YuFeng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Long-Tailed+Generalization+for+Pre-trained+Vision-Language+Model)|0|
|[MSPipe: Efficient Temporal GNN Training via Staleness-Aware Pipeline](https://doi.org/10.1145/3637528.3671844)|Guangming Sheng, Junwei Su, Chao Huang, Chuan Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSPipe:+Efficient+Temporal+GNN+Training+via+Staleness-Aware+Pipeline)|0|
|[LPFormer: An Adaptive Graph Transformer for Link Prediction](https://doi.org/10.1145/3637528.3672025)|Harry Shomer, Yao Ma, Haitao Mao, Juanhui Li, Bo Wu, Jiliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LPFormer:+An+Adaptive+Graph+Transformer+for+Link+Prediction)|0|
|[Orthogonality Matters: Invariant Time Series Representation for Out-of-distribution Classification](https://doi.org/10.1145/3637528.3671768)|Ruize Shi, Hong Huang, Kehan Yin, Wei Zhou, Hai Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Orthogonality+Matters:+Invariant+Time+Series+Representation+for+Out-of-distribution+Classification)|0|
|[CoLiDR: Concept Learning using Aggregated Disentangled Representations](https://doi.org/10.1145/3637528.3671938)|Sanchit Sinha, Guangzhi Xiong, Aidong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoLiDR:+Concept+Learning+using+Aggregated+Disentangled+Representations)|0|
|[On Early Detection of Hallucinations in Factual Question Answering](https://doi.org/10.1145/3637528.3671796)|Ben Snyder, Marius Moisescu, Muhammad Bilal Zafar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Early+Detection+of+Hallucinations+in+Factual+Question+Answering)|0|
|[MAML-en-LLM: Model Agnostic Meta-Training of LLMs for Improved In-Context Learning](https://doi.org/10.1145/3637528.3671905)|Sanchit Sinha, Yuguang Yue, Victor Soto, Mayank Kulkarni, Jianhua Lu, Aidong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAML-en-LLM:+Model+Agnostic+Meta-Training+of+LLMs+for+Improved+In-Context+Learning)|0|
|[Fast Computation for the Forest Matrix of an Evolving Graph](https://doi.org/10.1145/3637528.3671822)|Haoxin Sun, Xiaotian Zhou, Zhongzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Computation+for+the+Forest+Matrix+of+an+Evolving+Graph)|0|
|[Dual-Assessment Driven Pruning: Iterative Optimizing Layer-wise Sparsity for Large Language Model](https://doi.org/10.1145/3637528.3671780)|Qinghui Sun, Weilun Wang, Yanni Zhu, Shenghuan He, Hao Yi, Zehua Cai, Hong Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-Assessment+Driven+Pruning:+Iterative+Optimizing+Layer-wise+Sparsity+for+Large+Language+Model)|0|
|[DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization](https://doi.org/10.1145/3637528.3671878)|Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIVE:+Subgraph+Disagreement+for+Graph+Out-of-Distribution+Generalization)|0|
|[Hierarchical Linear Symbolized Tree-Structured Neural Processes](https://doi.org/10.1145/3637528.3671861)|Jin yang Tai, YiKe Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Linear+Symbolized+Tree-Structured+Neural+Processes)|0|
|[Learning Attributed Graphlets: Predictive Graph Mining by Graphlets with Trainable Attribute](https://doi.org/10.1145/3637528.3671970)|Tajima Shinji, Ren Sugihara, Ryota Kitahara, Masayuki Karasuyama||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Attributed+Graphlets:+Predictive+Graph+Mining+by+Graphlets+with+Trainable+Attribute)|0|
|[HiGPT: Heterogeneous Graph Language Model](https://doi.org/10.1145/3637528.3671987)|Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Long Xia, Dawei Yin, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiGPT:+Heterogeneous+Graph+Language+Model)|0|
|[URRL-IMVC: Unified and Robust Representation Learning for Incomplete Multi-View Clustering](https://doi.org/10.1145/3637528.3671887)|Ge Teng, Ting Mao, Chen Shen, Xiang Tian, Xuesong Liu, Yaowu Chen, Jieping Ye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=URRL-IMVC:+Unified+and+Robust+Representation+Learning+for+Incomplete+Multi-View+Clustering)|0|
|[Rotative Factorization Machines](https://doi.org/10.1145/3637528.3671740)|Zhen Tian, Yuhong Shi, Xiangkun Wu, Wayne Xin Zhao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rotative+Factorization+Machines)|0|
|[Latent Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Model](https://doi.org/10.1145/3637528.3671863)|Yuxing Tian, Aiwen Jiang, Qi Huang, Jian Guo, Yiyan Qi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Latent+Diffusion-based+Data+Augmentation+for+Continuous-Time+Dynamic+Graph+Model)|0|
|[Flexible Graph Neural Diffusion with Latent Class Representation Learning](https://doi.org/10.1145/3637528.3671860)|Liangtian Wan, Huijin Han, Lu Sun, Zixun Zhang, Zhaolong Ning, Xiaoran Yan, Feng Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flexible+Graph+Neural+Diffusion+with+Latent+Class+Representation+Learning)|0|
|[STONE: A Spatio-temporal OOD Learning Framework Kills Both Spatial and Temporal Shifts](https://doi.org/10.1145/3637528.3671680)|Binwu Wang, Jiaming Ma, Pengkun Wang, Xu Wang, Yudong Zhang, Zhengyang Zhou, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STONE:+A+Spatio-temporal+OOD+Learning+Framework+Kills+Both+Spatial+and+Temporal+Shifts)|0|
|[Provable Adaptivity of Adam under Non-uniform Smoothness](https://doi.org/10.1145/3637528.3671718)|Bohan Wang, Yushun Zhang, Huishuai Zhang, Qi Meng, Ruoyu Sun, ZhiMing Ma, TieYan Liu, ZhiQuan Luo, Wei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Provable+Adaptivity+of+Adam+under+Non-uniform+Smoothness)|0|
|[Multi-Scale Detection of Anomalous Spatio-Temporal Trajectories in Evolving Trajectory Datasets](https://doi.org/10.1145/3637528.3671874)|Chenhao Wang, Lisi Chen, Shuo Shang, Christian S. Jensen, Panos Kalnis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Scale+Detection+of+Anomalous+Spatio-Temporal+Trajectories+in+Evolving+Trajectory+Datasets)|0|
|[Global Human-guided Counterfactual Explanations for Molecular Properties via Reinforcement Learning](https://doi.org/10.1145/3637528.3672045)|Danqing Wang, Antonis Antoniades, KhaDinh Luong, Edwin Zhang, Mert Kosan, Jiachen Li, Ambuj Singh, William Yang Wang, Lei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Global+Human-guided+Counterfactual+Explanations+for+Molecular+Properties+via+Reinforcement+Learning)|0|
|[Mastering Long-Tail Complexity on Graphs: Characterization, Learning, and Generalization](https://doi.org/10.1145/3637528.3671880)|Haohui Wang, Baoyu Jing, Kaize Ding, Yada Zhu, Wei Cheng, Si Zhang, Yonghui Fan, Liqing Zhang, Dawei Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mastering+Long-Tail+Complexity+on+Graphs:+Characterization,+Learning,+and+Generalization)|0|
|[Unsupervised Heterogeneous Graph Rewriting Attack via Node Clustering](https://doi.org/10.1145/3637528.3671716)|Haosen Wang, Can Xu, Chenglong Shi, Pengfei Zheng, Shiming Zhang, Minhao Cheng, Hongyang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Heterogeneous+Graph+Rewriting+Attack+via+Node+Clustering)|0|
|[Effective Edge-wise Representation Learning in Edge-Attributed Bipartite Graphs](https://doi.org/10.1145/3637528.3671805)|Hewen Wang, Renchi Yang, Xiaokui Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Edge-wise+Representation+Learning+in+Edge-Attributed+Bipartite+Graphs)|0|
|[FedNLR: Federated Learning with Neuron-wise Learning Rates](https://doi.org/10.1145/3637528.3672042)|Haozhao Wang, Peirong Zheng, Xingshuo Han, Wenchao Xu, Ruixuan Li, Tianwei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedNLR:+Federated+Learning+with+Neuron-wise+Learning+Rates)|0|
|[Robust Predictions with Ambiguous Time Delays: A Bootstrap Strategy](https://doi.org/10.1145/3637528.3671920)|Jiajie Wang, Zhiyuan Jerry Lin, Wen Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Predictions+with+Ambiguous+Time+Delays:+A+Bootstrap+Strategy)|0|
|[A Novel Prompt Tuning for Graph Transformers: Tailoring Prompts to Graph Topologies](https://doi.org/10.1145/3637528.3671804)|Jingchao Wang, Zhengnan Deng, Tongxu Lin, Wenyuan Li, Shaobin Ling||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Novel+Prompt+Tuning+for+Graph+Transformers:+Tailoring+Prompts+to+Graph+Topologies)|0|
|[DyPS: Dynamic Parameter Sharing in Multi-Agent Reinforcement Learning for Spatio-Temporal Resource Allocation](https://doi.org/10.1145/3637528.3672052)|Jingwei Wang, Qianyue Hao, Wenzhen Huang, Xiaochen Fan, Zhentao Tang, Bin Wang, Jianye Hao, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DyPS:+Dynamic+Parameter+Sharing+in+Multi-Agent+Reinforcement+Learning+for+Spatio-Temporal+Resource+Allocation)|0|
|[The Snowflake Hypothesis: Training and Powering GNN with One Node One Receptive Field](https://doi.org/10.1145/3637528.3671766)|Kun Wang, Guohao Li, Shilong Wang, Guibin Zhang, Kai Wang, Yang You, Junfeng Fang, Xiaojiang Peng, Yuxuan Liang, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Snowflake+Hypothesis:+Training+and+Powering+GNN+with+One+Node+One+Receptive+Field)|0|
|[The Heterophilic Snowflake Hypothesis: Training and Empowering GNNs for Heterophilic Graphs](https://doi.org/10.1145/3637528.3671791)|Kun Wang, Guibin Zhang, Xinnan Zhang, Junfeng Fang, Xun Wu, Guohao Li, Shirui Pan, Wei Huang, Yuxuan Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Heterophilic+Snowflake+Hypothesis:+Training+and+Empowering+GNNs+for+Heterophilic+Graphs)|0|
|[CutAddPaste: Time Series Anomaly Detection by Exploiting Abnormal Knowledge](https://doi.org/10.1145/3637528.3671739)|Rui Wang, Xudong Mou, Renyu Yang, Kai Gao, Pin Liu, Chongwei Liu, Tianyu Wo, Xudong Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CutAddPaste:+Time+Series+Anomaly+Detection+by+Exploiting+Abnormal+Knowledge)|0|
|[Advancing Molecule Invariant Representation via Privileged Substructure Identification](https://doi.org/10.1145/3637528.3671886)|Ruijia Wang, Haoran Dai, Cheng Yang, Le Song, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Molecule+Invariant+Representation+via+Privileged+Substructure+Identification)|0|
|[Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement](https://doi.org/10.1145/3637528.3671864)|Yakun Wang, Daixin Wang, Hongrui Liu, Binbin Hu, Yingcui Yan, Qiyang Zhang, Zhiqiang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Long-tailed+Link+Prediction+in+Graph+Neural+Networks+through+Structure+Representation+Enhancement)|0|
|[DiffCrime: A Multimodal Conditional Diffusion Model for Crime Risk Map Inference](https://doi.org/10.1145/3637528.3671843)|Shuliang Wang, Xinyu Pan, Sijie Ruan, Haoyu Han, Ziyu Wang, Hanning Yuan, Jiabao Zhu, Qi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiffCrime:+A+Multimodal+Conditional+Diffusion+Model+for+Crime+Risk+Map+Inference)|0|
|[AsyncET: Asynchronous Representation Learning for Knowledge Graph Entity Typing](https://doi.org/10.1145/3637528.3671832)|YunCheng Wang, Xiou Ge, Bin Wang, C.C. Jay Kuo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AsyncET:+Asynchronous+Representation+Learning+for+Knowledge+Graph+Entity+Typing)|0|
|[Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks](https://doi.org/10.1145/3637528.3671838)|Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, Mingli Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Global+Interactive+Patterns+across+Graphs:+Towards+Interpretable+Graph+Neural+Networks)|0|
|[Self-Supervised Learning for Graph Dataset Condensation](https://doi.org/10.1145/3637528.3671682)|Yuxiang Wang, Xiao Yan, Shiyu Jin, Hao Huang, Quanqing Xu, Qingchen Zhang, Bo Du, Jiawei Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Learning+for+Graph+Dataset+Condensation)|0|
|[From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models](https://doi.org/10.1145/3637528.3671975)|Xumeng Wen, Han Zhang, Shun Zheng, Wei Xu, Jiang Bian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Supervised+to+Generative:+A+Novel+Paradigm+for+Tabular+Deep+Learning+with+Large+Language+Models)|0|
|[Dense Subgraph Discovery Meets Strong Triadic Closure](https://doi.org/10.1145/3637528.3671697)|Chamalee Wickrama Arachchi, Iiro Kumpulainen, Nikolaj Tatti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dense+Subgraph+Discovery+Meets+Strong+Triadic+Closure)|0|
|[FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model](https://doi.org/10.1145/3637528.3671897)|Feijie Wu, Zitao Li, Yaliang Li, Bolin Ding, Jing Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedBiOT:+LLM+Local+Fine-tuning+in+Federated+Learning+without+Full+Model)|0|
|[Neural Manifold Operators for Learning the Evolution of Physical Dynamics](https://doi.org/10.1145/3637528.3671779)|Hao Wu, Kangyu Weng, Shuyi Zhou, Xiaomeng Huang, Wei Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Manifold+Operators+for+Learning+the+Evolution+of+Physical+Dynamics)|0|
|[Distributional Network of Networks for Modeling Data Heterogeneity](https://doi.org/10.1145/3637528.3671994)|Jun Wu, Jingrui He, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributional+Network+of+Networks+for+Modeling+Data+Heterogeneity)|0|
|[Fake News in Sheep's Clothing: Robust Fake News Detection Against LLM-Empowered Style Attacks](https://doi.org/10.1145/3637528.3671977)|Jiaying Wu, Jiafeng Guo, Bryan Hooi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fake+News+in+Sheep's+Clothing:+Robust+Fake+News+Detection+Against+LLM-Empowered+Style+Attacks)|0|
|[Counterfactual Generative Models for Time-Varying Treatments](https://doi.org/10.1145/3637528.3671950)|Shenghao Wu, Wenbin Zhou, Minshuo Chen, Shixiang Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Generative+Models+for+Time-Varying+Treatments)|0|
|[ProCom: A Few-shot Targeted Community Detection Algorithm](https://doi.org/10.1145/3637528.3671749)|Xixi Wu, Kaiyu Xiong, Yun Xiong, Xiaoxin He, Yao Zhang, Yizhu Jiao, Jiawei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ProCom:+A+Few-shot+Targeted+Community+Detection+Algorithm)|0|
|[Cost-Efficient Fraud Risk Optimization with Submodularity in Insurance Claim](https://doi.org/10.1145/3637528.3672012)|Yupeng Wu, Zhibo Zhu, Chaoyi Ma, Hong Qian, Xingyu Lu, Yangwenhui Zhang, Xiaobo Qin, Binjie Fei, Jun Zhou, Aimin Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cost-Efficient+Fraud+Risk+Optimization+with+Submodularity+in+Insurance+Claim)|0|
|[A Deep Prediction Framework for Multi-Source Information via Heterogeneous GNN](https://doi.org/10.1145/3637528.3671966)|Zhen Wu, Jingya Zhou, Jinghui Zhang, Ling Liu, Chizhou Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Deep+Prediction+Framework+for+Multi-Source+Information+via+Heterogeneous+GNN)|0|
|[Fast Computation of Kemeny's Constant for Directed Graphs](https://doi.org/10.1145/3637528.3671859)|Haisong Xia, Zhongzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Computation+of+Kemeny's+Constant+for+Directed+Graphs)|0|
|[FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation](https://doi.org/10.1145/3637528.3671899)|Tong Xia, Abhirup Ghosh, Xinchi Qiu, Cecilia Mascolo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLea:+Addressing+Data+Scarcity+and+Label+Skew+in+Federated+Learning+via+Privacy-preserving+Feature+Augmentation)|0|
|[Motif-Consistent Counterfactuals with Adversarial Refinement for Graph-level Anomaly Detection](https://doi.org/10.1145/3637528.3672050)|Chunjing Xiao, Shikang Pang, Wenxin Tai, Yanlong Huang, Goce Trajcevski, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Motif-Consistent+Counterfactuals+with+Adversarial+Refinement+for+Graph-level+Anomaly+Detection)|0|
|[ReFound: Crafting a Foundation Model for Urban Region Understanding upon Language and Visual Foundations](https://doi.org/10.1145/3637528.3671992)|Congxi Xiao, Jingbo Zhou, Yixiong Xiao, Jizhou Huang, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReFound:+Crafting+a+Foundation+Model+for+Urban+Region+Understanding+upon+Language+and+Visual+Foundations)|0|
|[How to Avoid Jumping to Conclusions: Measuring the Robustness of Outstanding Facts in Knowledge Graphs](https://doi.org/10.1145/3637528.3671763)|Hanhua Xiao, Yuchen Li, Yanhao Wang, Panagiotis Karras, Kyriakos Mouratidis, Natalia Rozalia Avlona||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+to+Avoid+Jumping+to+Conclusions:+Measuring+the+Robustness+of+Outstanding+Facts+in+Knowledge+Graphs)|0|
|[Temporal Prototype-Aware Learning for Active Voltage Control on Power Distribution Networks](https://doi.org/10.1145/3637528.3671790)|Feiyang Xu, Shunyu Liu, Yunpeng Qing, Yihe Zhou, Yuwen Wang, Mingli Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Prototype-Aware+Learning+for+Active+Voltage+Control+on+Power+Distribution+Networks)|0|
|[FlexCare: Leveraging Cross-Task Synergy for Flexible Multimodal Healthcare Prediction](https://doi.org/10.1145/3637528.3671974)|Muhao Xu, Zhenfeng Zhu, Youru Li, Shuai Zheng, Yawei Zhao, Kunlun He, Yao Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FlexCare:+Leveraging+Cross-Task+Synergy+for+Flexible+Multimodal+Healthcare+Prediction)|0|
|[PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection](https://doi.org/10.1145/3637528.3671753)|Ronghui Xu, Hao Miao, Senzhang Wang, Philip S. Yu, Jianxin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PeFAD:+A+Parameter-Efficient+Federated+Framework+for+Time+Series+Anomaly+Detection)|0|
|[ProtoMix: Augmenting Health Status Representation Learning via Prototype-based Mixup](https://doi.org/10.1145/3637528.3671937)|Yongxin Xu, Xinke Jiang, Xu Chu, Yuzhen Xiao, Chaohe Zhang, Hongxin Ding, Junfeng Zhao, Yasha Wang, Bing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ProtoMix:+Augmenting+Health+Status+Representation+Learning+via+Prototype-based+Mixup)|0|
|[FedRoLA: Robust Federated Learning Against Model Poisoning via Layer-based Aggregation](https://doi.org/10.1145/3637528.3671906)|Gang Yan, Hao Wang, Xu Yuan, Jian Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedRoLA:+Robust+Federated+Learning+Against+Model+Poisoning+via+Layer-based+Aggregation)|0|
|[Team up GBDTs and DNNs: Advancing Efficient and Effective Tabular Prediction with Tree-hybrid MLPs](https://doi.org/10.1145/3637528.3671964)|Jiahuan Yan, Jintai Chen, Qianxing Wang, Danny Z. Chen, Jian Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Team+up+GBDTs+and+DNNs:+Advancing+Efficient+and+Effective+Tabular+Prediction+with+Tree-hybrid+MLPs)|0|
|[Efficient Mixture of Experts based on Large Language Models for Low-Resource Data Preprocessing](https://doi.org/10.1145/3637528.3671873)|Mengyi Yan, Yaoshu Wang, Kehan Pang, Min Xie, Jianxin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Mixture+of+Experts+based+on+Large+Language+Models+for+Low-Resource+Data+Preprocessing)|0|
|[An Efficient Subgraph GNN with Provable Substructure Counting Power](https://doi.org/10.1145/3637528.3671731)|Zuoyu Yan, Junru Zhou, Liangcai Gao, Zhi Tang, Muhan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Subgraph+GNN+with+Provable+Substructure+Counting+Power)|0|
|[Towards Test Time Adaptation via Calibrated Entropy Minimization](https://doi.org/10.1145/3637528.3671672)|Hao Yang, Min Wang, Jinshen Jiang, Yun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Test+Time+Adaptation+via+Calibrated+Entropy+Minimization)|0|
|[Noisy Label Removal for Partial Multi-Label Learning](https://doi.org/10.1145/3637528.3671677)|Fuchao Yang, Yuheng Jia, Hui Liu, Yongqiang Dong, Junhui Hou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Noisy+Label+Removal+for+Partial+Multi-Label+Learning)|0|
|[Balanced Confidence Calibration for Graph Neural Networks](https://doi.org/10.1145/3637528.3671741)|Hao Yang, Min Wang, Qi Wang, Mingrui Lao, Yun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balanced+Confidence+Calibration+for+Graph+Neural+Networks)|0|
|[Efficient Decision Rule List Learning via Unified Sequence Submodular Optimization](https://doi.org/10.1145/3637528.3671827)|Linxiao Yang, Jingbang Yang, Liang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Decision+Rule+List+Learning+via+Unified+Sequence+Submodular+Optimization)|0|
|[Effective Clustering on Large Attributed Bipartite Graphs](https://doi.org/10.1145/3637528.3671764)|Renchi Yang, Yidu Wu, Xiaoyang Lin, Qichen Wang, Tsz Nam Chan, Jieming Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Clustering+on+Large+Attributed+Bipartite+Graphs)|0|
|[ReCDA: Concept Drift Adaptation with Representation Enhancement for Network Intrusion Detection](https://doi.org/10.1145/3637528.3672007)|Shuo Yang, Xinran Zheng, Jinze Li, Jinfeng Xu, Xingjun Wang, Edith C. H. Ngai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReCDA:+Concept+Drift+Adaptation+with+Representation+Enhancement+for+Network+Intrusion+Detection)|0|
|[Your Neighbor Matters: Towards Fair Decisions Under Networked Interference](https://doi.org/10.1145/3637528.3671960)|Wenjing Yang, Haotian Wang, Haoxuan Li, Hao Zou, Ruochun Jin, Kun Kuang, Peng Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Your+Neighbor+Matters:+Towards+Fair+Decisions+Under+Networked+Interference)|0|
|[SEBot: Structural Entropy Guided Multi-View Contrastive learning for Social Bot Detection](https://doi.org/10.1145/3637528.3671871)|Yingguang Yang, Qi Wu, Buyun He, Hao Peng, Renyu Yang, Zhifeng Hao, Yong Liao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEBot:+Structural+Entropy+Guided+Multi-View+Contrastive+learning+for+Social+Bot+Detection)|0|
|[AdaRD: An Adaptive Response Denoising Framework for Robust Learner Modeling](https://doi.org/10.1145/3637528.3671684)|Fangzhou Yao, Qi Liu, Linan Yue, Weibo Gao, Jiatong Li, Xin Li, Yuanjing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaRD:+An+Adaptive+Response+Denoising+Framework+for+Robust+Learner+Modeling)|0|
|[RPMixer: Shaking Up Time Series Forecasting with Random Projections for Large Spatial-Temporal Data](https://doi.org/10.1145/3637528.3671881)|ChinChia Michael Yeh, Yujie Fan, Xin Dai, Uday Singh Saini, Vivian Lai, Prince Osei Aboagye, Junpeng Wang, Huiyuan Chen, Yan Zheng, Zhongfang Zhuang, Liang Wang, Wei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RPMixer:+Shaking+Up+Time+Series+Forecasting+with+Random+Projections+for+Large+Spatial-Temporal+Data)|0|
|[Using Self-supervised Learning Can Improve Model Fairness](https://doi.org/10.1145/3637528.3671991)|Sofia Yfantidou, Dimitris Spathis, Marios Constantinides, Athena Vakali, Daniele Quercia, Fahim Kawsar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+Self-supervised+Learning+Can+Improve+Model+Fairness)|0|
|[Self-consistent Deep Geometric Learning for Heterogeneous Multi-source Spatial Point Data Prediction](https://doi.org/10.1145/3637528.3671737)|Dazhou Yu, Xiaoyun Gong, Yun Li, Meikang Qiu, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-consistent+Deep+Geometric+Learning+for+Heterogeneous+Multi-source+Spatial+Point+Data+Prediction)|0|
|[PolygonGNN: Representation Learning for Polygonal Geometries with Heterogeneous Visibility Graph](https://doi.org/10.1145/3637528.3671738)|Dazhou Yu, Yuntong Hu, Yun Li, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PolygonGNN:+Representation+Learning+for+Polygonal+Geometries+with+Heterogeneous+Visibility+Graph)|0|
|[GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing](https://doi.org/10.1145/3637528.3672055)|Chengqing Yu, Fei Wang, Zezhi Shao, Tangwen Qian, Zhao Zhang, Wei Wei, Yongjun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GinAR:+An+End-To-End+Multivariate+Time+Series+Forecasting+Model+Suitable+for+Variable+Missing)|0|
|[RIGL: A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes](https://doi.org/10.1145/3637528.3671711)|Xiaoshan Yu, Chuan Qin, Dazhong Shen, Shangshang Yang, Haiping Ma, Hengshu Zhu, Xingyi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RIGL:+A+Unified+Reciprocal+Approach+for+Tracing+the+Independent+and+Group+Learning+Processes)|0|
|[Unveiling Privacy Vulnerabilities: Investigating the Role of Structure in Graph Data](https://doi.org/10.1145/3637528.3672013)|Hanyang Yuan, Jiarong Xu, Cong Wang, Ziqi Yang, Chunping Wang, Keting Yin, Yang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Privacy+Vulnerabilities:+Investigating+the+Role+of+Structure+in+Graph+Data)|0|
|[Graph Cross Supervised Learning via Generalized Knowledge](https://doi.org/10.1145/3637528.3671830)|Xiangchi Yuan, Yijun Tian, Chunhui Zhang, Yanfang Ye, Nitesh V. Chawla, Chuxu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Cross+Supervised+Learning+via+Generalized+Knowledge)|0|
|[Effective Generation of Feasible Solutions for Integer Programming via Guided Diffusion](https://doi.org/10.1145/3637528.3671783)|Hao Zeng, Jiaqi Wang, Avirup Das, Junying He, Kunpeng Han, Haoyuan Hu, Mingfei Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Generation+of+Feasible+Solutions+for+Integer+Programming+via+Guided+Diffusion)|0|
|[Path-Specific Causal Reasoning for Fairness-aware Cognitive Diagnosis](https://doi.org/10.1145/3637528.3672049)|Dacao Zhang, Kun Zhang, Le Wu, Mi Tian, Richang Hong, Meng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Path-Specific+Causal+Reasoning+for+Fairness-aware+Cognitive+Diagnosis)|0|
|[Brant-X: A Unified Physiological Signal Alignment Framework](https://doi.org/10.1145/3637528.3671953)|Daoze Zhang, Zhizhang Yuan, Junru Chen, Kerui Chen, Yang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Brant-X:+A+Unified+Physiological+Signal+Alignment+Framework)|0|
|[Subspace Selection based Prompt Tuning with Nonconvex Nonsmooth Black-Box Optimization](https://doi.org/10.1145/3637528.3671986)|Haozhen Zhang, Hualin Zhang, Bin Gu, Yi Chang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Subspace+Selection+based+Prompt+Tuning+with+Nonconvex+Nonsmooth+Black-Box+Optimization)|0|
|[Heuristic Learning with Graph Neural Networks: A Unified Framework for Link Prediction](https://doi.org/10.1145/3637528.3671946)|Juzheng Zhang, Lanning Wei, Zhen Xu, Quanming Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heuristic+Learning+with+Graph+Neural+Networks:+A+Unified+Framework+for+Link+Prediction)|0|
|[Asynchronous Vertical Federated Learning for Kernelized AUC Maximization](https://doi.org/10.1145/3637528.3671930)|Ke Zhang, Ganyu Wang, Han Li, Yulong Wang, Hong Chen, Bin Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Asynchronous+Vertical+Federated+Learning+for+Kernelized+AUC+Maximization)|0|
|[Multivariate Log-based Anomaly Detection for Distributed Database](https://doi.org/10.1145/3637528.3671725)|Lingzhe Zhang, Tong Jia, Mengxi Jia, Ying Li, Yong Yang, Zhonghai Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multivariate+Log-based+Anomaly+Detection+for+Distributed+Database)|0|
|[Logical Reasoning with Relation Network for Inductive Knowledge Graph Completion](https://doi.org/10.1145/3637528.3671911)|Qinggang Zhang, Keyu Duan, Junnan Dong, Pai Zheng, Xiao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logical+Reasoning+with+Relation+Network+for+Inductive+Knowledge+Graph+Completion)|0|
|[Towards Adaptive Neighborhood for Advancing Temporal Interaction Graph Modeling](https://doi.org/10.1145/3637528.3671877)|Siwei Zhang, Xi Chen, Yun Xiong, Xixi Wu, Yao Zhang, Yongrui Fu, Yinglong Zhao, Jiawei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Adaptive+Neighborhood+for+Advancing+Temporal+Interaction+Graph+Modeling)|0|
|[Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Networks](https://doi.org/10.1145/3637528.3671665)|Weijia Zhang, Le Zhang, Jindong Han, Hao Liu, Yanjie Fu, Jingbo Zhou, Yu Mei, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Irregular+Traffic+Time+Series+Forecasting+Based+on+Asynchronous+Spatio-Temporal+Graph+Convolutional+Networks)|0|
|[A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist](https://doi.org/10.1145/3637528.3671801)|Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, Longtao Zheng, Xinrun Wang, Bo An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multimodal+Foundation+Agent+for+Financial+Trading:+Tool-Augmented,+Diversified,+and+Generalist)|0|
|[Geometric View of Soft Decorrelation in Self-Supervised Learning](https://doi.org/10.1145/3637528.3671914)|Yifei Zhang, Hao Zhu, Zixing Song, Yankai Chen, Xinyu Fu, Ziqiao Meng, Piotr Koniusz, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+View+of+Soft+Decorrelation+in+Self-Supervised+Learning)|0|
|[Representation Learning of Geometric Trees](https://doi.org/10.1145/3637528.3671688)|Zheng Zhang, Allen Zhang, Ruth Nelson, Giorgio Ascoli, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+Learning+of+Geometric+Trees)|0|
|[Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective](https://doi.org/10.1145/3637528.3671910)|Zhiwei Zhang, Minhua Lin, Enyan Dai, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Graph+Backdoor+Attacks:+A+Distribution-Preserving+Perspective)|0|
|[Learning Flexible Time-windowed Granger Causality Integrating Heterogeneous Interventional Time Series Data](https://doi.org/10.1145/3637528.3672023)|Ziyi Zhang, Shaogang Ren, Xiaoning Qian, Nick Duffield||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Flexible+Time-windowed+Granger+Causality+Integrating+Heterogeneous+Interventional+Time+Series+Data)|0|
|[Algorithmic Fairness Generalization under Covariate and Dependence Shifts Simultaneously](https://doi.org/10.1145/3637528.3671909)|Chen Zhao, Kai Jiang, Xintao Wu, Haoliang Wang, Latifur Khan, Christan Grant, Feng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Algorithmic+Fairness+Generalization+under+Covariate+and+Dependence+Shifts+Simultaneously)|0|
|[VertiMRF: Differentially Private Vertical Federated Data Synthesis](https://doi.org/10.1145/3637528.3671771)|Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, Yaliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VertiMRF:+Differentially+Private+Vertical+Federated+Data+Synthesis)|0|
|[Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs](https://doi.org/10.1145/3637528.3671952)|Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-Training+and+Prompting+for+Few-Shot+Node+Classification+on+Text-Attributed+Graphs)|0|
|[Conformalized Link Prediction on Graph Neural Networks](https://doi.org/10.1145/3637528.3672061)|Tianyi Zhao, Jian Kang, Lu Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conformalized+Link+Prediction+on+Graph+Neural+Networks)|0|
|[GeoMix: Towards Geometry-Aware Data Augmentation](https://doi.org/10.1145/3637528.3671700)|Wentao Zhao, Qitian Wu, Chenxiao Yang, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GeoMix:+Towards+Geometry-Aware+Data+Augmentation)|0|
|[Spuriousness-Aware Meta-Learning for Learning Robust Classifiers](https://doi.org/10.1145/3637528.3672006)|Guangtao Zheng, Wenqian Ye, Aidong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spuriousness-Aware+Meta-Learning+for+Learning+Robust+Classifiers)|0|
|[SiGeo: Sub-One-Shot NAS via Geometry of Loss Landscape](https://doi.org/10.1145/3637528.3671712)|Hua Zheng, KuangHung Liu, Igor Fedorov, Xin Zhang, WenYen Chen, Wei Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SiGeo:+Sub-One-Shot+NAS+via+Geometry+of+Loss+Landscape)|0|
|[Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Broad Physical Dynamics Learning](https://doi.org/10.1145/3637528.3671957)|Zinan Zheng, Yang Liu, Jia Li, Jianhua Yao, Yu Rong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relaxing+Continuous+Constraints+of+Equivariant+Graph+Neural+Networks+for+Broad+Physical+Dynamics+Learning)|0|
|[LogParser-LLM: Advancing Efficient Log Parsing with Large Language Models](https://doi.org/10.1145/3637528.3671810)|Aoxiao Zhong, Dengyao Mo, Guiyang Liu, Jinbu Liu, Qingda Lu, Qi Zhou, Jiesheng Wu, Quanzheng Li, Qingsong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LogParser-LLM:+Advancing+Efficient+Log+Parsing+with+Large+Language+Models)|0|
|[BitLINK: Temporal Linkage of Address Clusters in Bitcoin Blockchain](https://doi.org/10.1145/3637528.3672037)|Sheng Zhong, Abdullah Mueen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BitLINK:+Temporal+Linkage+of+Address+Clusters+in+Bitcoin+Blockchain)|0|
|[Efficient and Effective Implicit Dynamic Graph Neural Network](https://doi.org/10.1145/3637528.3672026)|Yongjian Zhong, Hieu Vu, Tianbao Yang, Bijaya Adhikari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Effective+Implicit+Dynamic+Graph+Neural+Network)|0|
|[CURLS: Causal Rule Learning for Subgroups with Significant Treatment Effect](https://doi.org/10.1145/3637528.3671951)|Jiehui Zhou, Linxiao Yang, Xingyu Liu, Xinyue Gu, Liang Sun, Wei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CURLS:+Causal+Rule+Learning+for+Subgroups+with+Significant+Treatment+Effect)|0|
|[Neural Collapse Anchored Prompt Tuning for Generalizable Vision-Language Models](https://doi.org/10.1145/3637528.3671690)|Didi Zhu, Zexi Li, Min Zhang, Junkun Yuan, Jiashuo Liu, Kun Kuang, Chao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Collapse+Anchored+Prompt+Tuning+for+Generalizable+Vision-Language+Models)|0|
|[Distributed Thresholded Counting with Limited Interaction](https://doi.org/10.1145/3637528.3671868)|Xiaoyi Zhu, Yuxiang Tian, Zengfeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Thresholded+Counting+with+Limited+Interaction)|0|
|[Propagation Structure-Aware Graph Transformer for Robust and Interpretable Fake News Detection](https://doi.org/10.1145/3637528.3672024)|Junyou Zhu, Chao Gao, Ze Yin, Xianghua Li, Jürgen Kurths||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Propagation+Structure-Aware+Graph+Transformer+for+Robust+and+Interpretable+Fake+News+Detection)|0|
|[ControlTraj: Controllable Trajectory Generation with Topology-Constrained Diffusion Model](https://doi.org/10.1145/3637528.3671866)|Yuanshao Zhu, James Jian Qiao Yu, Xiangyu Zhao, Qidong Liu, Yongchao Ye, Wei Chen, Zijian Zhang, Xuetao Wei, Yuxuan Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ControlTraj:+Controllable+Trajectory+Generation+with+Topology-Constrained+Diffusion+Model)|0|
|[One Fits All: Learning Fair Graph Neural Networks for Various Sensitive Attributes](https://doi.org/10.1145/3637528.3672029)|Yuchang Zhu, Jintang Li, Yatao Bian, Zibin Zheng, Liang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One+Fits+All:+Learning+Fair+Graph+Neural+Networks+for+Various+Sensitive+Attributes)|0|
|[Topology-monitorable Contrastive Learning on Dynamic Graphs](https://doi.org/10.1145/3637528.3671777)|Zulun Zhu, Kai Wang, Haoyu Liu, Jintang Li, Siqiang Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topology-monitorable+Contrastive+Learning+on+Dynamic+Graphs)|0|
|[MacroHFT: Memory Augmented Context-aware Reinforcement Learning On High Frequency Trading](https://doi.org/10.1145/3637528.3672064)|Chuqiao Zong, Chaojie Wang, Molei Qin, Lei Feng, Xinrun Wang, Bo An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MacroHFT:+Memory+Augmented+Context-aware+Reinforcement+Learning+On+High+Frequency+Trading)|0|
|[Lessons Learned while Running ML Models in Harsh Environments](https://doi.org/10.1145/3637528.3672499)|Pedro Bizarro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lessons+Learned+while+Running+ML+Models+in+Harsh+Environments)|0|
|[Next-generation Intelligent Assistants for Wearable Devices](https://doi.org/10.1145/3637528.3672500)|Xin Luna Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Next-generation+Intelligent+Assistants+for+Wearable+Devices)|0|
|[Scalable Graph Learning for your Enterprise](https://doi.org/10.1145/3637528.3672501)|Hema Raghavan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Graph+Learning+for+your+Enterprise)|0|
|[Dynamic Pricing for Multi-Retailer Delivery Platforms with Additive Deep Learning and Evolutionary Optimization](https://doi.org/10.1145/3637528.3671634)|Ahmed Abdulaal, Ali Polat, Hari Narayan, Wenrong Zeng, Yimin Yi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Pricing+for+Multi-Retailer+Delivery+Platforms+with+Additive+Deep+Learning+and+Evolutionary+Optimization)|0|
|[Television Discourse Decoded: Comprehensive Multimodal Analytics at Scale](https://doi.org/10.1145/3637528.3671532)|Anmol Agarwal, Pratyush Priyadarshi, Shiven Sinha, Shrey Gupta, Hitkul Jangra, Ponnurangam Kumaraguru, Kiran Garimella||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Television+Discourse+Decoded:+Comprehensive+Multimodal+Analytics+at+Scale)|0|
|[Large Scale Generative AI Text Applied to Sports and Music](https://doi.org/10.1145/3637528.3671542)|Aaron K. Baughman, Eduardo Morales, Rahul Agarwal, Gozde Akay, Rogério Feris, Tony Johnson, Stephen Hammer, Leonid Karlinsky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Scale+Generative+AI+Text+Applied+to+Sports+and+Music)|0|
|[LiGNN: Graph Neural Networks at LinkedIn](https://doi.org/10.1145/3637528.3671566)|Fedor Borisyuk, Shihai He, Yunbo Ouyang, Morteza Ramezani, Peng Du, Xiaochen Hou, Chengming Jiang, Nitin Pasumarthy, Priya Bannur, Birjodh Tiwana, Ping Liu, Siddharth Dangi, Daqi Sun, Zhoutao Pei, Xiao Shi, Sirou Zhu, Qianqi Shen, KuangHsuan Lee, David Stein, Baolei Li, Haichao Wei, Amol Ghoting, Souvik Ghosh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LiGNN:+Graph+Neural+Networks+at+LinkedIn)|0|
|[Diffusion Model-based Mobile Traffic Generation with Open Data for Network Planning and Optimization](https://doi.org/10.1145/3637528.3671544)|Haoye Chai, Tao Jiang, Li Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion+Model-based+Mobile+Traffic+Generation+with+Open+Data+for+Network+Planning+and+Optimization)|0|
|[RareBench: Can LLMs Serve as Rare Diseases Specialists?](https://doi.org/10.1145/3637528.3671576)|Xuanzhong Chen, Xiaohao Mao, Qihan Guo, Lun Wang, Shuyang Zhang, Ting Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RareBench:+Can+LLMs+Serve+as+Rare+Diseases+Specialists?)|0|
|[MARLP: Time-series Forecasting Control for Agricultural Managed Aquifer Recharge](https://doi.org/10.1145/3637528.3671533)|Yuning Chen, Kang Yang, Zhiyu An, Brady Holder, Luke Paloutzian, Khaled M. Bali, Wan Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MARLP:+Time-series+Forecasting+Control+for+Agricultural+Managed+Aquifer+Recharge)|0|
|[Time-Aware Attention-Based Transformer (TAAT) for Cloud Computing System Failure Prediction](https://doi.org/10.1145/3637528.3671547)|Lingfei Deng, Yunong Wang, Haoran Wang, Xuhua Ma, Xiaoming Du, Xudong Zheng, Dongrui Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-Aware+Attention-Based+Transformer+(TAAT)+for+Cloud+Computing+System+Failure+Prediction)|0|
|[FNSPID: A Comprehensive Financial News Dataset in Time Series](https://doi.org/10.1145/3637528.3671629)|Zihan Dong, Xinyu Fan, Zhiyuan Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FNSPID:+A+Comprehensive+Financial+News+Dataset+in+Time+Series)|0|
|[Transportation Marketplace Rate Forecast Using Signature Transform](https://doi.org/10.1145/3637528.3671637)|Haotian Gu, Xin Guo, Timothy L. Jacobs, Philip M. Kaminsky, Xinyu Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transportation+Marketplace+Rate+Forecast+Using+Signature+Transform)|0|
|[Intelligent Agents with LLM-based Process Automation](https://doi.org/10.1145/3637528.3671646)|Yanchu Guan, Dong Wang, Zhixuan Chu, Shiyu Wang, Feiyue Ni, Ruihua Song, Chenyi Zhuang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intelligent+Agents+with+LLM-based+Process+Automation)|0|
|[SentHYMNent: An Interpretable and Sentiment-Driven Model for Algorithmic Melody Harmonization](https://doi.org/10.1145/3637528.3671626)|Stephen Hahn, Jerry Yin, Rico Zhu, Weihan Xu, Yue Jiang, Simon Mak, Cynthia Rudin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SentHYMNent:+An+Interpretable+and+Sentiment-Driven+Model+for+Algorithmic+Melody+Harmonization)|0|
|[FedSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs](https://doi.org/10.1145/3637528.3671545)|Shanshan Han, Baturalp Buyukates, Zijian Hu, Han Jin, Weizhao Jin, Lichao Sun, Xiaoyang Wang, Wenxuan Wu, Chulin Xie, Yuhang Yao, Kai Zhang, Qifan Zhang, Yuhui Zhang, Carlee JoeWong, Salman Avestimehr, Chaoyang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedSecurity:+A+Benchmark+for+Attacks+and+Defenses+in+Federated+Learning+and+Federated+LLMs)|0|
|[Paths2Pair: Meta-path Based Link Prediction in Billion-Scale Commercial Heterogeneous Graphs](https://doi.org/10.1145/3637528.3671563)|Jinquan Hang, Zhiqing Hong, Xinyue Feng, Guang Wang, Guang Yang, Feng Li, Xining Song, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Paths2Pair:+Meta-path+Based+Link+Prediction+in+Billion-Scale+Commercial+Heterogeneous+Graphs)|0|
|[Distributed Harmonization: Federated Clustered Batch Effect Adjustment and Generalization](https://doi.org/10.1145/3637528.3671590)|Bao Hoang, Yijiang Pang, Siqi Liang, Liang Zhan, Paul M. Thompson, Jiayu Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Harmonization:+Federated+Clustered+Batch+Effect+Adjustment+and+Generalization)|0|
|[Explainable and Interpretable Forecasts on Non-Smooth Multivariate Time Series for Responsible Gameplay](https://doi.org/10.1145/3637528.3671657)|Hussain Jagirdar, Rukma Talwadker, Aditya Pareek, Pulkit Agrawal, Tridib Mukherjee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+and+Interpretable+Forecasts+on+Non-Smooth+Multivariate+Time+Series+for+Responsible+Gameplay)|0|
|[Decomposed Attention Segment Recurrent Neural Network for Orbit Prediction](https://doi.org/10.1145/3637528.3671546)|Seungwon Jeong, Soyeon Woo, Daewon Chung, Simon S. Woo, Youjin Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decomposed+Attention+Segment+Recurrent+Neural+Network+for+Orbit+Prediction)|0|
|[RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning](https://doi.org/10.1145/3637528.3671644)|Congyun Jin, Ming Zhang, Weixiao Ma, Yujiao Li, Yingbo Wang, Yabo Jia, Yuliang Du, Tao Sun, Haowen Wang, Cong Fan, Jinjie Gu, Chenfei Chi, Xiangguo Lv, Fangzhou Li, Wei Xue, Yiran Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RJUA-MedDQA:+A+Multimodal+Benchmark+for+Medical+Document+Question+Answering+and+Clinical+Reasoning)|0|
|[Large Scale Hierarchical Industrial Demand Time-Series Forecasting incorporating Sparsity](https://doi.org/10.1145/3637528.3671632)|Harshavardhan Kamarthi, Aditya B. Sasanur, Xinjie Tong, Xingyu Zhou, James Peters, Joe Czyzyk, B. Aditya Prakash||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Scale+Hierarchical+Industrial+Demand+Time-Series+Forecasting+incorporating+Sparsity)|0|
|[Know, Grow, and Protect Net Worth: Using ML for Asset Protection by Preventing Overdraft Fees](https://doi.org/10.1145/3637528.3671628)|Avishek Kumar, Tyson Silver||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Know,+Grow,+and+Protect+Net+Worth:+Using+ML+for+Asset+Protection+by+Preventing+Overdraft+Fees)|0|
|[AutoWebGLM: A Large Language Model-based Web Navigating Agent](https://doi.org/10.1145/3637528.3671620)|Hanyu Lai, Xiao Liu, Iat Long Iong, Shuntian Yao, Yuxuan Chen, Pengbo Shen, Hao Yu, Hanchen Zhang, Xiaohan Zhang, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoWebGLM:+A+Large+Language+Model-based+Web+Navigating+Agent)|0|
|[SEFraud: Graph-based Self-Explainable Fraud Detection via Interpretative Mask Learning](https://doi.org/10.1145/3637528.3671534)|Kaidi Li, Tianmeng Yang, Min Zhou, Jiahao Meng, Shendi Wang, Yihui Wu, Boshuai Tan, Hu Song, Lujia Pan, Fan Yu, Zhenli Sheng, Yunhai Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEFraud:+Graph-based+Self-Explainable+Fraud+Detection+via+Interpretative+Mask+Learning)|0|
|[Harvesting Efficient On-Demand Order Pooling from Skilled Couriers: Enhancing Graph Representation Learning for Refining Real-time Many-to-One Assignments](https://doi.org/10.1145/3637528.3671643)|Yile Liang, Jiuxia Zhao, Donghui Li, Jie Feng, Chen Zhang, Xuetao Ding, Jinghua Hao, Renqing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harvesting+Efficient+On-Demand+Order+Pooling+from+Skilled+Couriers:+Enhancing+Graph+Representation+Learning+for+Refining+Real-time+Many-to-One+Assignments)|0|
|[Hyper-Local Deformable Transformers for Text Spotting on Historical Maps](https://doi.org/10.1145/3637528.3671589)|Yijun Lin, YaoYi Chiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyper-Local+Deformable+Transformers+for+Text+Spotting+on+Historical+Maps)|0|
|[Source Localization for Cross Network Information Diffusion](https://doi.org/10.1145/3637528.3671624)|Chen Ling, Tanmoy Chowdhury, Jie Ji, Sirui Li, Andreas Züfle, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Source+Localization+for+Cross+Network+Information+Diffusion)|0|
|[MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning](https://doi.org/10.1145/3637528.3671609)|Bingchang Liu, Chaoyu Chen, Zi Gong, Cong Liao, Huan Wang, Zhichao Lei, Ming Liang, Dajun Chen, Min Shen, Hailian Zhou, Wei Jiang, Hang Yu, Jianguo Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MFTCoder:+Boosting+Code+LLMs+with+Multitask+Fine-Tuning)|0|
|[Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm](https://doi.org/10.1145/3637528.3671575)|Lei Liu, Xiaoyan Yang, Fangzhou Li, Chenfei Chi, Yue Shen, Shiwei Lyu, Ming Zhang, Xiaowei Ma, Xiangguo Lv, Liya Ma, Zhiqiang Zhang, Wei Xue, Yiran Huang, Jinjie Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Automatic+Evaluation+for+LLMs'+Clinical+Capabilities:+Metric,+Data,+and+Algorithm)|0|
|[DAG: Deep Adaptive and Generative K-Free Community Detection on Attributed Graphs](https://doi.org/10.1145/3637528.3671615)|Chang Liu, Yuwen Yang, Yue Ding, Hongtao Lu, Wenqing Lin, Ziming Wu, Wendong Bi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAG:+Deep+Adaptive+and+Generative+K-Free+Community+Detection+on+Attributed+Graphs)|0|
|[EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis](https://doi.org/10.1145/3637528.3671552)|Zhiwei Liu, Kailai Yang, Qianqian Xie, Tianlin Zhang, Sophia Ananiadou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EmoLLMs:+A+Series+of+Emotional+Large+Language+Models+and+Annotation+Tools+for+Comprehensive+Affective+Analysis)|0|
|[MISP: A Multimodal-based Intelligent Server Failure Prediction Model for Cloud Computing Systems](https://doi.org/10.1145/3637528.3671568)|Xianting Lu, Yunong Wang, Yu Fu, Qi Sun, Xuhua Ma, Xudong Zheng, Cheng Zhuo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MISP:+A+Multimodal-based+Intelligent+Server+Failure+Prediction+Model+for+Cloud+Computing+Systems)|0|
|[Integrating System State into Spatio Temporal Graph Neural Network for Microservice Workload Prediction](https://doi.org/10.1145/3637528.3671508)|Yang Luo, Mohan Gao, Zhemeng Yu, Haoyuan Ge, Xiaofeng Gao, Tengwei Cai, Guihai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+System+State+into+Spatio+Temporal+Graph+Neural+Network+for+Microservice+Workload+Prediction)|0|
|[FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework for Robust Solar Power Forecasting](https://doi.org/10.1145/3637528.3671509)|Ziqing Ma, Wenwei Wang, Tian Zhou, Chao Chen, Bingqing Peng, Liang Sun, Rong Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FusionSF:+Fuse+Heterogeneous+Modalities+in+a+Vector+Quantized+Framework+for+Robust+Solar+Power+Forecasting)|0|
|[Valuing an Engagement Surface using a Large Scale Dynamic Causal Model](https://doi.org/10.1145/3637528.3671604)|Abhimanyu Mukerji, Sushant More, Ashwin Viswanathan Kannan, Lakshmi Ravi, Hua Chen, Naman Kohli, Chris Khawand, Dinesh Mandalapu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Valuing+an+Engagement+Surface+using+a+Large+Scale+Dynamic+Causal+Model)|0|
|[EEG2Rep: Enhancing Self-supervised EEG Representation Through Informative Masked Inputs](https://doi.org/10.1145/3637528.3671600)|Navid Mohammadi Foumani, Geoffrey Mackellar, Soheila Ghane, Saad Irtza, Nam Nguyen, Mahsa Salehi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EEG2Rep:+Enhancing+Self-supervised+EEG+Representation+Through+Informative+Masked+Inputs)|0|
|[Detecting Abnormal Operations in Concentrated Solar Power Plants from Irregular Sequences of Thermal Images](https://doi.org/10.1145/3637528.3671623)|Sukanya Patra, Nicolas Sournac, Souhaib Ben Taieb||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Abnormal+Operations+in+Concentrated+Solar+Power+Plants+from+Irregular+Sequences+of+Thermal+Images)|0|
|[Spatio-Temporal Consistency Enhanced Differential Network for Interpretable Indoor Temperature Prediction](https://doi.org/10.1145/3637528.3671608)|Dekang Qi, Xiuwen Yi, Chengjie Guo, Yanyong Huang, Junbo Zhang, Tianrui Li, Yu Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Consistency+Enhanced+Differential+Network+for+Interpretable+Indoor+Temperature+Prediction)|0|
|[Addressing Shortcomings in Fair Graph Learning Datasets: Towards a New Benchmark](https://doi.org/10.1145/3637528.3671616)|Xiaowei Qian, Zhimeng Guo, Jialiang Li, Haitao Mao, Bingheng Li, Suhang Wang, Yao Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Shortcomings+in+Fair+Graph+Learning+Datasets:+Towards+a+New+Benchmark)|0|
|[Class-incremental Learning for Time Series: Benchmark and Evaluation](https://doi.org/10.1145/3637528.3671581)|Zhongzheng Qiao, Quang Pham, Zhen Cao, Hoang H. Le, Ponnuthurai N. Suganthan, Xudong Jiang, Savitha Ramasamy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Class-incremental+Learning+for+Time+Series:+Benchmark+and+Evaluation)|0|
|[Leveraging Exposure Networks for Detecting Fake News Sources](https://doi.org/10.1145/3637528.3671539)|Maor Reuben, Lisa Friedland, Rami Puzis, Nir Grinberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Exposure+Networks+for+Detecting+Fake+News+Sources)|0|
|[Tackling Concept Shift in Text Classification using Entailment-style Modeling](https://doi.org/10.1145/3637528.3671541)|Sumegh Roychowdhury, Karan Gupta, Siva Rajesh Kasa, Prasanna Srinivasa Murthy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tackling+Concept+Shift+in+Text+Classification+using+Entailment-style+Modeling)|0|
|[Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems](https://doi.org/10.1145/3637528.3671610)|Yu Sha, Shuiping Gou, Bo Liu, Johannes Faber, Ningtao Liu, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Knowledge+Guided+Fault+Intensity+Diagnosis+of+Complex+Industrial+Systems)|0|
|[Lumos: Empowering Multimodal LLMs with Scene Text Recognition](https://doi.org/10.1145/3637528.3671633)|Ashish Shenoy, Yichao Lu, Srihari Jayakumar, Debojeet Chatterjee, Mohsen Moslehpour, Pierce Chuang, Abhay Harpale, Vikas Bhardwaj, Di Xu, Shicong Zhao, Longfang Zhao, Ankit Ramchandani, Xin Luna Dong, Anuj Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lumos:+Empowering+Multimodal+LLMs+with+Scene+Text+Recognition)|0|
|[From Variability to Stability: Advancing RecSys Benchmarking Practices](https://doi.org/10.1145/3637528.3671655)|Valeriy Shevchenko, Nikita Belousov, Alexey Vasilev, Vladimir Zholobov, Artyom Sosedka, Natalia Semenova, Anna Volodkevich, Andrey Savchenko, Alexey Zaytsev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Variability+to+Stability:+Advancing+RecSys+Benchmarking+Practices)|0|
|[Improving Ego-Cluster for Network Effect Measurement](https://doi.org/10.1145/3637528.3671557)|Wentao Su, Weitao Duan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Ego-Cluster+for+Network+Effect+Measurement)|0|
|[Beimingwu: A Learnware Dock System](https://doi.org/10.1145/3637528.3671617)|ZhiHao Tan, JianDong Liu, XiaoDong Bi, Peng Tan, QinCheng Zheng, HaiTian Liu, Yi Xie, XiaoChuan Zou, Yang Yu, ZhiHua Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beimingwu:+A+Learnware+Dock+System)|0|
|[Business Policy Experiments using Fractional Factorial Designs: Consumer Retention on DoorDash](https://doi.org/10.1145/3637528.3671574)|Yixin Tang, Yicong Lin, Navdeep S. Sahni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Business+Policy+Experiments+using+Fractional+Factorial+Designs:+Consumer+Retention+on+DoorDash)|0|
|[TnT-LLM: Text Mining at Scale with Large Language Models](https://doi.org/10.1145/3637528.3671647)|Mengting Wan, Tara Safavi, Sujay Kumar Jauhar, Yujin Kim, Scott Counts, Jennifer Neville, Siddharth Suri, Chirag Shah, Ryen W. White, Longqi Yang, Reid Andersen, Georg Buscher, Dhruv Joshi, Nagu Rangan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TnT-LLM:+Text+Mining+at+Scale+with+Large+Language+Models)|0|
|[Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs](https://doi.org/10.1145/3637528.3671583)|Junjie Wang, Dan Yang, Binbin Hu, Yue Shen, Wen Zhang, Jinjie Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Know+Your+Needs+Better:+Towards+Structured+Understanding+of+Marketer+Demands+with+Analogical+Reasoning+Augmented+LLMs)|0|
|[COMET: NFT Price Prediction with Wallet Profiling](https://doi.org/10.1145/3637528.3671621)|Tianfu Wang, Liwei Deng, Chao Wang, Jianxun Lian, Yue Yan, Nicholas Jing Yuan, Qi Zhang, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COMET:+NFT+Price+Prediction+with+Wallet+Profiling)|0|
|[Neural Optimization with Adaptive Heuristics for Intelligent Marketing System](https://doi.org/10.1145/3637528.3671591)|Changshuai Wei, Benjamin Zelditch, Joyce Chen, Andre Assuncao Silva T. Ribeiro, Jingyi Kenneth Tay, Borja Ocejo Elizondo, Sathiya Keerthi Selvaraj, Aman Gupta, Licurgo Benemann De Almeida||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Optimization+with+Adaptive+Heuristics+for+Intelligent+Marketing+System)|0|
|[On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications](https://doi.org/10.1145/3637528.3671521)|Chengyao Wen, Yin Lou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Finding+Bi-objective+Pareto-optimal+Fraud+Prevention+Rule+Sets+for+Fintech+Applications)|0|
|[Nested Fusion: A Method for Learning High Resolution Latent Structure of Multi-Scale Measurement Data on Mars](https://doi.org/10.1145/3637528.3671596)|Austin P. Wright, Scott Davidoff, Duen Horng Chau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nested+Fusion:+A+Method+for+Learning+High+Resolution+Latent+Structure+of+Multi-Scale+Measurement+Data+on+Mars)|0|
|[TrajRecovery: An Efficient Vehicle Trajectory Recovery Framework based on Urban-Scale Traffic Camera Records](https://doi.org/10.1145/3637528.3671558)|Dongen Wu, Ziquan Fang, Qichen Sun, Lu Chen, Haiyang Hu, Fei Wang, Yunjun Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrajRecovery:+An+Efficient+Vehicle+Trajectory+Recovery+Framework+based+on+Urban-Scale+Traffic+Camera+Records)|0|
|[LaDe: The First Comprehensive Last-mile Express Dataset from Industry](https://doi.org/10.1145/3637528.3671548)|Lixia Wu, Haomin Wen, Haoyuan Hu, Xiaowei Mao, Yutong Xia, Ergang Shan, Jianbin Zheng, Junhong Lou, Yuxuan Liang, Liuqing Yang, Roger Zimmermann, Youfang Lin, Huaiyu Wan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LaDe:+The+First+Comprehensive+Last-mile+Express+Dataset+from+Industry)|0|
|[Xinyu: An Efficient LLM-based System for Commentary Generation](https://doi.org/10.1145/3637528.3671537)|Yiquan Wu, Bo Tang, Chenyang Xi, Yu Yu, Pengyu Wang, Yifei Liu, Kun Kuang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Jie Hu, Peng Cheng, Zhonghao Wang, Yi Wang, Yi Luo, Mingchuan Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Xinyu:+An+Efficient+LLM-based+System+for+Commentary+Generation)|0|
|[DuMapNet: An End-to-End Vectorization System for City-Scale Lane-Level Map Generation](https://doi.org/10.1145/3637528.3671579)|Deguo Xia, Weiming Zhang, Xiyan Liu, Wei Zhang, Chenting Gong, Jizhou Huang, Mengmeng Yang, Diange Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DuMapNet:+An+End-to-End+Vectorization+System+for+City-Scale+Lane-Level+Map+Generation)|0|
|[VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for Enhanced Detection](https://doi.org/10.1145/3637528.3671527)|Fei Xiao, Shaofeng Cai, Gang Chen, H. V. Jagadish, Beng Chin Ooi, Meihui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VecAug:+Unveiling+Camouflaged+Frauds+with+Cohort+Augmentation+for+Enhanced+Detection)|0|
|[Weather Knows What Will Occur: Urban Public Nuisance Events Prediction and Control with Meteorological Assistance](https://doi.org/10.1145/3637528.3671639)|Yi Xie, Tianyu Qiu, Yun Xiong, Xiuqi Huang, Xiaofeng Gao, Chao Chen, Qiang Wang, Haihong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weather+Knows+What+Will+Occur:+Urban+Public+Nuisance+Events+Prediction+and+Control+with+Meteorological+Assistance)|0|
|[Microservice Root Cause Analysis With Limited Observability Through Intervention Recognition in the Latent Space](https://doi.org/10.1145/3637528.3671530)|Zhe Xie, Shenglin Zhang, Yitong Geng, Yao Zhang, Minghua Ma, Xiaohui Nie, Zhenhe Yao, Longlong Xu, Yongqian Sun, Wentao Li, Dan Pei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Microservice+Root+Cause+Analysis+With+Limited+Observability+Through+Intervention+Recognition+in+the+Latent+Space)|0|
|[Understanding the Weakness of Large Language Model Agents within a Complex Android Environment](https://doi.org/10.1145/3637528.3671650)|Mingzhe Xing, Rongkai Zhang, Hui Xue, Qi Chen, Fan Yang, Zhen Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Weakness+of+Large+Language+Model+Agents+within+a+Complex+Android+Environment)|0|
|[XRL-Bench: A Benchmark for Evaluating and Comparing Explainable Reinforcement Learning Techniques](https://doi.org/10.1145/3637528.3671595)|Yu Xiong, Zhipeng Hu, Ye Huang, Runze Wu, Kai Guan, Xingchen Fang, Ji Jiang, Tianze Zhou, Yujing Hu, Haoyu Liu, Tangjie Lyu, Changjie Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XRL-Bench:+A+Benchmark+for+Evaluating+and+Comparing+Explainable+Reinforcement+Learning+Techniques)|0|
|[FedGTP: Exploiting Inter-Client Spatial Dependency in Federated Graph-based Traffic Prediction](https://doi.org/10.1145/3637528.3671613)|Linghua Yang, Wantong Chen, Xiaoxi He, Shuyue Wei, Yi Xu, Zimu Zhou, Yongxin Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedGTP:+Exploiting+Inter-Client+Spatial+Dependency+in+Federated+Graph-based+Traffic+Prediction)|0|
|[OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning](https://doi.org/10.1145/3637528.3671582)|Rui Ye, Wenhao Wang, Jingyi Chai, Dihan Li, Zexi Li, Yinda Xu, Yaxin Du, Yanfeng Wang, Siheng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OpenFedLLM:+Training+Large+Language+Models+on+Decentralized+Private+Data+via+Federated+Learning)|0|
|[PAIL: Performance based Adversarial Imitation Learning Engine for Carbon Neutral Optimization](https://doi.org/10.1145/3637528.3671611)|Yuyang Ye, LuAn Tang, Haoyu Wang, Runlong Yu, Wenchao Yu, Erhu He, Haifeng Chen, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PAIL:+Performance+based+Adversarial+Imitation+Learning+Engine+for+Carbon+Neutral+Optimization)|0|
|[SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing](https://doi.org/10.1145/3637528.3671586)|Changchang Yin, PinYu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey M. Caterino, Ping Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SepsisLab:+Early+Sepsis+Prediction+with+Uncertainty+Quantification+and+Active+Sensing)|0|
|[Pre-trained KPI Anomaly Detection Model Through Disentangled Transformer](https://doi.org/10.1145/3637528.3671522)|Zhaoyang Yu, Changhua Pei, Xin Wang, Minghua Ma, Chetan Bansal, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, Xidao Wen, Jianhui Li, Gaogang Xie, Dan Pei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-trained+KPI+Anomaly+Detection+Model+Through+Disentangled+Transformer)|0|
|[An Offline Meta Black-box Optimization Framework for Adaptive Design of Urban Traffic Light Management Systems](https://doi.org/10.1145/3637528.3671606)|Taeyoung Yun, Kanghoon Lee, Sujin Yun, Ilmyung Kim, WonWoo Jung, MinCheol Kwon, Kyujin Choi, Yoohyeon Lee, Jinkyoo Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Offline+Meta+Black-box+Optimization+Framework+for+Adaptive+Design+of+Urban+Traffic+Light+Management+Systems)|0|
|[OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining](https://doi.org/10.1145/3637528.3672354)|Fanjin Zhang, Shijie Shi, Yifan Zhu, Bo Chen, Yukuo Cen, Jifan Yu, Yelin Chen, Lulu Wang, Qingfei Zhao, Yuqing Cheng, Tianyi Han, Yuwei An, Dan Zhang, Weng Lam Tam, Kun Cao, Yunhe Pang, Xinyu Guan, Huihui Yuan, Jian Song, Xiaoyan Li, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OAG-Bench:+A+Human-Curated+Benchmark+for+Academic+Graph+Mining)|0|
|[Dólares or Dollars? Unraveling the Bilingual Prowess of Financial LLMs Between Spanish and English](https://doi.org/10.1145/3637528.3671554)|Xiao Zhang, Ruoyu Xiang, Chenhan Yuan, Duanyu Feng, Weiguang Han, Alejandro LopezLira, XiaoYang Liu, Meikang Qiu, Sophia Ananiadou, Min Peng, Jimin Huang, Qianqian Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dólares+or+Dollars?+Unraveling+the+Bilingual+Prowess+of+Financial+LLMs+Between+Spanish+and+English)|0|
|[Large Language Model with Curriculum Reasoning for Visual Concept Recognition](https://doi.org/10.1145/3637528.3671653)|Yipeng Zhang, Xin Wang, Hong Chen, Jiapei Fan, Weigao Wen, Hui Xue, Hong Mei, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Model+with+Curriculum+Reasoning+for+Visual+Concept+Recognition)|0|
|[GraSS: Combining Graph Neural Networks with Expert Knowledge for SAT Solver Selection](https://doi.org/10.1145/3637528.3671627)|Zhanguang Zhang, Didier Chételat, Joseph Cotnareanu, Amur Ghose, Wenyi Xiao, HuiLing Zhen, Yingxue Zhang, Jianye Hao, Mark Coates, Mingxuan Yuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraSS:+Combining+Graph+Neural+Networks+with+Expert+Knowledge+for+SAT+Solver+Selection)|0|
|[Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns](https://doi.org/10.1145/3637528.3671587)|Zheyuan Zhang, Zehong Wang, Shifu Hou, Evan Hall, Landon Bachman, Jasmine White, Vincent Galassi, Nitesh V. Chawla, Chuxu Zha, Yanfang Ye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diet-ODIN:+A+Novel+Framework+for+Opioid+Misuse+Detection+with+Interpretable+Dietary+Patterns)|0|
|[TACCO: Task-guided Co-clustering of Clinical Concepts and Patient Visits for Disease Subtyping based on EHR Data](https://doi.org/10.1145/3637528.3671594)|Ziyang Zhang, Hejie Cui, Ran Xu, Yuzhang Xie, Joyce C. Ho, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TACCO:+Task-guided+Co-clustering+of+Clinical+Concepts+and+Patient+Visits+for+Disease+Subtyping+based+on+EHR+Data)|0|
|[DUE: Dynamic Uncertainty-Aware Explanation Supervision via 3D Imputation](https://doi.org/10.1145/3637528.3671641)|Qilong Zhao, Yifei Zhang, Mengdan Zhu, Siyi Gu, Yuyang Gao, Xiaofeng Yang, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DUE:+Dynamic+Uncertainty-Aware+Explanation+Supervision+via+3D+Imputation)|0|
|[Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy](https://doi.org/10.1145/3637528.3671614)|Yao Zhao, Zhitian Xie, Chen Liang, Chenyi Zhuang, Jinjie Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lookahead:+An+Inference+Acceleration+Framework+for+Large+Language+Model+with+Lossless+Generation+Accuracy)|0|
|[Decision Focused Causal Learning for Direct Counterfactual Marketing Optimization](https://doi.org/10.1145/3637528.3672353)|Hao Zhou, Rongxiao Huang, Shaoming Li, Guibin Jiang, Jiaqi Zheng, Bing Cheng, Wei Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decision+Focused+Causal+Learning+for+Direct+Counterfactual+Marketing+Optimization)|0|
|[A Hands-on Introduction to Time Series Classification and Regression](https://doi.org/10.1145/3637528.3671443)|Anthony J. Bagnall, Matthew Middlehurst, Germain Forestier, Ali IsmailFawaz, Antoine Guillaume, David GuijoRubio, Chang Wei Tan, Angus Dempster, Geoffrey I. Webb||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hands-on+Introduction+to+Time+Series+Classification+and+Regression)|0|
|[Multi-modal Data Processing for Foundation Models: Practical Guidances and Use Cases](https://doi.org/10.1145/3637528.3671441)|Daoyuan Chen, Yaliang Li, Bolin Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Data+Processing+for+Foundation+Models:+Practical+Guidances+and+Use+Cases)|0|
|[DARE to Diversify: DAta Driven and Diverse LLM REd Teaming](https://doi.org/10.1145/3637528.3671444)|Manish Nagireddy, Bernat Guillen Pegueroles, Ioana Baldini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DARE+to+Diversify:+DAta+Driven+and+Diverse+LLM+REd+Teaming)|0|
|[Privacy-Preserving Federated Learning using Flower Framework](https://doi.org/10.1145/3637528.3671447)|Mohammad Naseri, Javier FernándezMarqués, Yan Gao, Heng Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Federated+Learning+using+Flower+Framework)|0|
|[Graph Reasoning with LLMs (GReaL)](https://doi.org/10.1145/3637528.3671448)|Anton Tsitsulin, Bryan Perozzi, Bahare Fatemi, Jonathan J. Halcrow||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Reasoning+with+LLMs+(GReaL))|0|
|[Breaking Barriers: A Hands-On Tutorial on AI-Enabled Accessibility to Social Media Content](https://doi.org/10.1145/3637528.3671446)|Julio Villena, Rosa Català, Janine García, Concepción Polo, Yessika Labrador, Francisco delValle, Bhargav Ayyagari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+Barriers:+A+Hands-On+Tutorial+on+AI-Enabled+Accessibility+to+Social+Media+Content)|0|
|[Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text](https://doi.org/10.1145/3637528.3671463)|Sara Abdali, Richard Anarfi, C. J. Barberan, Jia He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoding+the+AI+Pen:+Techniques+and+Challenges+in+Detecting+AI-Generated+Text)|0|
|[Advances in Human Event Modeling: From Graph Neural Networks to Language Models](https://doi.org/10.1145/3637528.3671466)|Songgaojun Deng, Maarten de Rijke, Yue Ning||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advances+in+Human+Event+Modeling:+From+Graph+Neural+Networks+to+Language+Models)|0|
|[Reasoning and Planning with Large Language Models in Code Development](https://doi.org/10.1145/3637528.3671452)|Hao Ding, Ziwei Fan, Ingo Gühring, Gaurav Gupta, Wooseok Ha, Jun Huan, Linbo Liu, Behrooz OmidvarTehrani, Shiqi Wang, Hao Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reasoning+and+Planning+with+Large+Language+Models+in+Code+Development)|0|
|[Sharing is Caring: A Practical Guide to FAIR(ER) Open Data Release](https://doi.org/10.1145/3637528.3671468)|Amelia Henriksen, Miranda Mundt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sharing+is+Caring:+A+Practical+Guide+to+FAIR(ER)+Open+Data+Release)|0|
|[Grounding and Evaluation for Large Language Models: Practical Challenges and Lessons Learned (Survey)](https://doi.org/10.1145/3637528.3671467)|Krishnaram Kenthapadi, Mehrnoosh Sameki, Ankur Taly||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Grounding+and+Evaluation+for+Large+Language+Models:+Practical+Challenges+and+Lessons+Learned+(Survey))|0|
|[A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step Guide](https://doi.org/10.1145/3637528.3671457)|Sunwoo Kim, Soo Yong Lee, Yue Gao, Alessia Antelmi, Mirko Polato, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Survey+on+Hypergraph+Neural+Networks:+An+In-Depth+and+Step-By-Step+Guide)|0|
|[Graph Intelligence with Large Language Models and Prompt Learning](https://doi.org/10.1145/3637528.3671456)|Jia Li, Xiangguo Sun, Yuhan Li, Zhixun Li, Hong Cheng, Jeffrey Xu Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Intelligence+with+Large+Language+Models+and+Prompt+Learning)|0|
|[Foundation Models for Time Series Analysis: A Tutorial and Survey](https://doi.org/10.1145/3637528.3671451)|Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, Qingsong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Foundation+Models+for+Time+Series+Analysis:+A+Tutorial+and+Survey)|0|
|[Symbolic Regression: A Pathway to Interpretability Towards Automated Scientific Discovery](https://doi.org/10.1145/3637528.3671464)|Nour Makke, Sanjay Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Symbolic+Regression:+A+Pathway+to+Interpretability+Towards+Automated+Scientific+Discovery)|0|
|[A Survey of Large Language Models for Graphs](https://doi.org/10.1145/3637528.3671460)|Xubin Ren, Jiabin Tang, Dawei Yin, Nitesh V. Chawla, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Survey+of+Large+Language+Models+for+Graphs)|0|
|[Explainable Artificial Intelligence on Biosignals for Clinical Decision Support](https://doi.org/10.1145/3637528.3671459)|Miriam Cindy Maurer, Jacqueline Michelle Metsch, Philip Hempel, Theresa Bender, Nicolai Spicher, AnneChristin Hauschild||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Artificial+Intelligence+on+Biosignals+for+Clinical+Decision+Support)|0|
|[Urban Foundation Models: A Survey](https://doi.org/10.1145/3637528.3671453)|Weijia Zhang, Jindong Han, Zhao Xu, Hang Ni, Hao Liu, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Urban+Foundation+Models:+A+Survey)|0|
|[Inference Optimization of Foundation Models on AI Accelerators](https://doi.org/10.1145/3637528.3671465)|Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas M. Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inference+Optimization+of+Foundation+Models+on+AI+Accelerators)|0|
|[Automated Mining of Structured Knowledge from Text in the Era of Large Language Models](https://doi.org/10.1145/3637528.3671469)|Yunyi Zhang, Ming Zhong, Siru Ouyang, Yizhu Jiao, Sizhe Zhou, Linyi Ding, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Mining+of+Structured+Knowledge+from+Text+in+the+Era+of+Large+Language+Models)|0|
|[Causal Inference with Latent Variables: Recent Advances and Future Prospectives](https://doi.org/10.1145/3637528.3671450)|Yaochen Zhu, Yinhan He, Jing Ma, Mengxuan Hu, Sheng Li, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Inference+with+Latent+Variables:+Recent+Advances+and+Future+Prospectives)|0|
|[A Survey on Safe Multi-Modal Learning Systems](https://doi.org/10.1145/3637528.3671462)|Tianyi Zhao, Liangliang Zhang, Yao Ma, Lu Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Survey+on+Safe+Multi-Modal+Learning+Systems)|0|
|[Responsible AI Day](https://doi.org/10.1145/3637528.3673867)|Ricardo BaezaYates, Nataly Buslón||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Responsible+AI+Day)|0|
|[Heterogeneous Contrastive Learning for Foundation Models and Beyond](https://doi.org/10.1145/3637528.3671454)|Lecheng Zheng, Baoyu Jing, Zihao Li, Hanghang Tong, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+Contrastive+Learning+for+Foundation+Models+and+Beyond)|0|
|[Equity, Diversity & Inclusion (EDI): Special Day at ACM KDD 2024](https://doi.org/10.1145/3637528.3673870)|Tania Cerquitelli, Amin Mantrach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Equity,+Diversity+&+Inclusion+(EDI):+Special+Day+at+ACM+KDD+2024)|0|
|[Health Day: Building Health AI Ecosystem: From Data Harmonization to Knowledge Discovery](https://doi.org/10.1145/3637528.3673866)|Jake Chen, Peipei Ping||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Health+Day:+Building+Health+AI+Ecosystem:+From+Data+Harmonization+to+Knowledge+Discovery)|0|
|[Overview of ACM SIGKDD 2024 AI4Science4AI Special Day](https://doi.org/10.1145/3637528.3673871)|Wei Ding, Gustau CampsValls||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Overview+of+ACM+SIGKDD+2024+AI4Science4AI+Special+Day)|0|
|[KDD 2024 Special Day - AI for Environment](https://doi.org/10.1145/3637528.3673869)|Karina Gibert, Wee Hyong Tok, Miquel SànchezMarrè||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KDD+2024+Special+Day+-+AI+for+Environment)|0|
|[European Data Science Day: KDD-2024 Special Day](https://doi.org/10.1145/3637528.3673868)|Dunja Mladenic, Dumitru Roman||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=European+Data+Science+Day:+KDD-2024+Special+Day)|0|
|[Generative AI Day](https://doi.org/10.1145/3637528.3673872)|Jie Tang, Yuxiao Dong, Michalis Vazirgiannis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+Day)|0|
|[KDD 2024 Finance Day](https://doi.org/10.1145/3637528.3673865)|Guiling Wang, Daniel Borrajo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KDD+2024+Finance+Day)|0|
|[AdKDD 2024](https://doi.org/10.1145/3637528.3671476)|Abraham Bagherjeiran, Nemanja Djuric, KuangChih Lee, Linsey Pang, Vladan Radosavljevic, Suju Rajan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdKDD+2024)|0|
|[Fragile Earth: Generative and Foundational Models for Sustainable Development](https://doi.org/10.1145/3637528.3671493)|Emre Eftelioglu, Bistra Dilkina, Naoki Abe, Ramakrishnan Kannan, Yuzhou Chen, Yulia R. Gel, Kathleen Buckingham, Auroop R. Ganguly, James Hodson, Jiafu Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragile+Earth:+Generative+and+Foundational+Models+for+Sustainable+Development)|0|
|[Artificial Intelligence and Data Science for Healthcare: Bridging Data-Centric AI and People-Centric Healthcare](https://doi.org/10.1145/3637528.3671497)|Shenda Hong, Daoxin Yin, Gongzheng Tang, Tianfan Fu, Liantao Ma, Junyi Gao, Mengling Feng, Mai Wang, Yu Yang, Fei Wang, Hongfang Liu, Luxia Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Artificial+Intelligence+and+Data+Science+for+Healthcare:+Bridging+Data-Centric+AI+and+People-Centric+Healthcare)|0|
|[TSMO 2024: Two-sided Marketplace Optimization](https://doi.org/10.1145/3637528.3671484)|Mihajlo Grbovic, Vladan Radosavljevic, Minmin Chen, Katerina IliakopoulouZanos, Thanasis Noulas, Amit Goyal, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TSMO+2024:+Two-sided+Marketplace+Optimization)|0|
|[KDD workshop on Evaluation and Trustworthiness of Generative AI Models](https://doi.org/10.1145/3637528.3671481)|Yuan Ling, Shujing Dong, Yarong Feng, Zongyi Joe Liu, George Karypis, Chandan K. Reddy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KDD+workshop+on+Evaluation+and+Trustworthiness+of+Generative+AI+Models)|0|
|[NL2Code-Reasoning and Planning with LLMs for Code Development](https://doi.org/10.1145/3637528.3671505)|Ye Xing, Jun Huan, Wee Hyong Tok, Cong Shen, Johannes Gehrke, Katherine Lin, Arjun Guha, Omer Tripp, Murali Krishna Ramanathan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NL2Code-Reasoning+and+Planning+with+LLMs+for+Code+Development)|0|
