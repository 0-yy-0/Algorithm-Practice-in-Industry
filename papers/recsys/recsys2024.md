# RECSYS2024 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[A Hybrid Multi-Agent Conversational Recommender System with LLM and Search Engine in E-commerce](https://doi.org/10.1145/3640457.3688061)|Guangtao Nie, Rong Zhi, Xiaofan Yan, Yufan Du, Xiangyang Zhang, Jianwei Chen, Mi Zhou, Hongshen Chen, Tianhao Li, Ziguang Cheng, Sulong Xu, Jinghe Hu|JDcom, Beijing, Peoples R China|Multi-agent collaboration is the latest trending method to build conversational recommender systems (CRS), especially with the widespread use of Large Language Models (LLMs) recently. Typically, these systems employ several LLM agents, each serving distinct roles to meet user needs. In an industrial setting, it’s essential for a CRS to exhibit low first token latency (i.e., the time taken from a user’s input until the system outputs its first response token.) and high scalability—for instance, minimizing the number of LLM inferences per user request—to enhance user experience and boost platform profit. For example, JD.com’s baseline CRS features two LLM agents and a search API but suffers from high first token latency and requires two LLM inferences per request (LIPR), hindering its performance. To address these issues, we introduce a Hybrid Multi-Agent Collaborative Recommender System (Hybrid-MACRS). It includes a central agent powered by a fine-tuned proprietary LLM and a search agent combining a related search module with a search engine. This hybrid system notably reduces first token latency by about 70% and cuts the LIPR from 2 to 1. We conducted thorough online A/B testing to confirm this approach’s efficiency.|多智能体协作是构建对话推荐系统（CRS）的最新趋势方法，尤其是在最近大型语言模型（LLMs）广泛应用的背景下。通常，这些系统会部署多个LLM智能体，每个智能体扮演不同的角色以满足用户需求。在工业环境中，CRS必须具备低首词延迟（即从用户输入到系统输出第一个响应词所需的时间）和高可扩展性——例如，尽量减少每个用户请求所需的LLM推理次数——以提升用户体验并增加平台利润。例如，京东的基线CRS包含两个LLM智能体和一个搜索API，但其首词延迟较高，且每个请求需要两次LLM推理（LIPR），这限制了其性能。为了解决这些问题，我们提出了一种混合多智能体协作推荐系统（Hybrid-MACRS）。该系统包括一个由微调后的专有LLM驱动的中心智能体，以及一个结合了相关搜索模块和搜索引擎的搜索智能体。这种混合系统显著降低了首词延迟约70%，并将LIPR从2次减少到1次。我们进行了全面的在线A/B测试，以验证该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hybrid+Multi-Agent+Conversational+Recommender+System+with+LLM+and+Search+Engine+in+E-commerce)|0|
|[Embedding based retrieval for long tail search queries in ecommerce](https://doi.org/10.1145/3640457.3688039)|Akshay Kekuda, Yuyang Zhang, Arun Udayashankar|Best Buy, Appl Machine Learning, Minneapolis, MN 55423 USA|In this abstract we present a series of optimizations we performed on the two-tower model architecture [14], training and evaluation datasets to implement semantic product search at Best Buy. Search queries on bestbuy.com follow the pareto distribution whereby a minority of them account for most searches. This leaves us with a long tail of search queries that have low frequency of issuance. The queries in the long tail suffer from very spare interaction signals. Our current work focuses on building a model to serve the long tail queries. We present a series of optimizations we have done to this model to maximize conversion for the purpose of retrieval from the catalog. The first optimization we present is using a large language model to improve the sparsity of conversion signals. The second optimization is pretraining an off-the-shelf transformer-based model on the Best Buy catalog data. The third optimization we present is on the finetuning front. We use query-to-query pairs in addition to query-to-product pairs and combining the above strategies for finetuning the model. We also demonstrate how merging the weights of these finetuned models improves the evaluation metrics. Finally, we provide a recipe for curating an evaluation dataset for continuous monitoring of model performance with human-in-the-loop evaluation. We found that adding this recall mechanism to our current term match-based recall improved conversion by 3% in an online A/B test.|在本摘要中，我们介绍了一系列针对双塔模型架构[14]的优化措施，以及在Best Buy实施语义产品搜索过程中对训练和评估数据集的改进。Bestbuy.com上的搜索查询遵循帕累托分布，即少数查询占据了大部分搜索量。这导致我们面临大量低频搜索查询的长尾问题。这些长尾查询的交互信号非常稀疏。我们当前的工作重点在于构建一个模型来服务于这些长尾查询。我们展示了一系列针对该模型的优化措施，以最大化从目录中检索的转化率。首先，我们利用大型语言模型来改善转化信号的稀疏性。其次，我们使用Best Buy目录数据对现成的基于Transformer的模型进行预训练。第三，我们在微调方面进行了优化，除了使用查询-产品对之外，还引入了查询-查询对，并结合上述策略对模型进行微调。我们还展示了如何通过合并这些微调模型的权重来提升评估指标。最后，我们提供了一种构建评估数据集的方案，通过人工参与的循环评估来持续监控模型性能。我们发现，在当前基于术语匹配的召回机制中加入这一优化后，在线A/B测试中的转化率提高了3%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+based+retrieval+for+long+tail+search+queries+in+ecommerce)|0|
|[Ranking-Aware Unbiased Post-Click Conversion Rate Estimation via AUC Optimization on Entire Exposure Space](https://doi.org/10.1145/3640457.3688152)|Yu Liu, Qinglin Jia, Shuting Shi, Chuhan Wu, Zhaocheng Du, Zheng Xie, Ruiming Tang, Muyu Zhang, Ming Li|; Huawei Noahs Ark Lab, Beijing, Peoples R China; National Key Laboratory for Novel Software Technology, Nanjing University, China; Huawei Technol Co Ltd, Shenzhen, Peoples R China|Estimating the post-click conversion rate (CVR) accurately in ranking systems is crucial in industrial applications. However, this task is often challenged by data sparsity and selection bias, which hinder accurate ranking. Previous approaches to address these challenges have typically focused on either modeling CVR across the entire exposure space which includes all exposure events, or providing unbiased CVR estimation separately. However, the lack of integration between these objectives has limited the overall performance of CVR estimation. Therefore, there is a pressing need for a method that can simultaneously provide unbiased CVR estimates across the entire exposure space. To achieve it, we formulate the CVR estimation task as an Area Under the Curve (AUC) optimization problem and propose the Entire-space Weighted AUC (EWAUC) framework. EWAUC utilizes sample reweighting techniques to handle selection bias and employs pairwise AUC risk, which incorporates more information from limited clicked data, to handle data sparsity. In order to model CVR across the entire exposure space unbiasedly, EWAUC treats the exposure data as both conversion data and non-conversion data to calculate the loss. The properties of AUC risk guarantee the unbiased nature of the entire space modeling. We provide comprehensive theoretical analysis to validate the unbiased nature of our approach. Additionally, extensive experiments conducted on real-world datasets demonstrate that our approach outperforms state-of-the-art methods in terms of ranking performance for the CVR estimation task.|在排名系统中准确估计点击后转化率（CVR）在工业应用中至关重要。然而，这一任务常常受到数据稀疏性和选择偏差的挑战，这些因素阻碍了准确的排名。以往解决这些挑战的方法通常集中在在整个曝光空间（包括所有曝光事件）中对CVR进行建模，或者分别提供无偏的CVR估计。然而，这些目标之间缺乏整合，限制了CVR估计的整体性能。因此，迫切需要一种能够同时在整个曝光空间提供无偏CVR估计的方法。为了实现这一目标，我们将CVR估计任务表述为曲线下面积（AUC）优化问题，并提出了全空间加权AUC（EWAUC）框架。EWAUC利用样本重加权技术来处理选择偏差，并采用成对AUC风险（从有限的点击数据中获取更多信息）来处理数据稀疏性。为了在整个曝光空间中对CVR进行无偏建模，EWAUC将曝光数据同时视为转化数据和非转化数据来计算损失。AUC风险的性质保证了整个空间建模的无偏性。我们提供了全面的理论分析来验证我们方法的无偏性。此外，在真实世界数据集上进行的大量实验表明，我们的方法在CVR估计任务的排名性能上优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking-Aware+Unbiased+Post-Click+Conversion+Rate+Estimation+via+AUC+Optimization+on+Entire+Exposure+Space)|0|
|[Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Models](https://doi.org/10.1145/3640457.3688118)|Yu Cui, Feng Liu, Pengbo Wang, Bohao Wang, Heng Tang, Yi Wan, Jun Wang, Jiawei Chen|OPPO Co Ltd Shenzhen; University of Electronic Science and Technology of China Chengdu; Zhejiang University Hangzhou|Owing to their powerful semantic reasoning capabilities, Large Language Models (LLMs) have been effectively utilized as recommenders, achieving impressive performance. However, the high inference latency of LLMs significantly restricts their practical deployment. To address this issue, this work investigates knowledge distillation from cumbersome LLM-based recommendation models to lightweight conventional sequential models. It encounters three challenges: 1) the teacher’s knowledge may not always be reliable; 2) the capacity gap between the teacher and student makes it difficult for the student to assimilate the teacher’s knowledge; 3) divergence in semantic space poses a challenge to distill the knowledge from embeddings. To tackle these challenges, this work proposes a novel distillation strategy, DLLM2Rec, specifically tailored for knowledge distillation from LLM-based recommendation models to conventional sequential models. DLLM2Rec comprises: 1) Importance-aware ranking distillation, which filters reliable and student-friendly knowledge by weighting instances according to teacher confidence and student-teacher consistency; 2) Collaborative embedding distillation integrates knowledge from teacher embeddings with collaborative signals mined from the data. Extensive experiments demonstrate the effectiveness of the proposed DLLM2Rec, boosting three typical sequential models with an average improvement of 47.97%, even enabling them to surpass LLM-based recommenders in some cases.|由于大语言模型（LLMs）具有强大的语义推理能力，它们已被有效地用作推荐系统，并取得了令人印象深刻的性能。然而，LLMs的高推理延迟极大地限制了其实际部署。为了解决这一问题，本研究探讨了从基于LLM的复杂推荐模型到轻量级传统序列模型的知识蒸馏。这一过程中面临三个挑战：1）教师模型的知识可能并不总是可靠的；2）教师模型与学生模型之间的能力差距使得学生模型难以吸收教师模型的知识；3）语义空间中的差异给从嵌入中蒸馏知识带来了挑战。为了应对这些挑战，本研究提出了一种新的蒸馏策略DLLM2Rec，专门为从基于LLM的推荐模型到传统序列模型的知识蒸馏而设计。DLLM2Rec包括：1）重要性感知排序蒸馏，通过根据教师模型的置信度和学生模型与教师模型的一致性对实例进行加权，筛选出可靠且适合学生模型的知识；2）协作嵌入蒸馏，将教师模型嵌入中的知识与从数据中挖掘的协作信号相结合。大量实验证明了所提出的DLLM2Rec的有效性，使得三种典型的序列模型平均提升了47.97%，甚至在某些情况下使它们超越了基于LLM的推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distillation+Matters:+Empowering+Sequential+Recommenders+to+Match+the+Performance+of+Large+Language+Models)|0|
|[Dynamic Product Image Generation and Recommendation at Scale for Personalized E-commerce](https://doi.org/10.1145/3640457.3688045)|Ádám Tibor Czapp, Mátyás Jani, Bálint Domián, Balázs Hidasi|Taboola Budapest, Budapest, Hungary|Coupling latent diffusion based image generation with contextual bandits enables the creation of eye-catching personalized product images at scale that was previously either impossible or too expensive. In this paper we showcase how we utilized these technologies to increase user engagement with recommendations in online retargeting campaigns for e-commerce.|将基于潜在扩散模型的图像生成技术与上下文多臂老虎机相结合，使得大规模创建引人注目的个性化产品图像成为可能，这在以前要么是不可能的，要么成本过高。在本文中，我们展示了如何利用这些技术来提高电子商务在线重定向广告活动中推荐内容的用户参与度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Product+Image+Generation+and+Recommendation+at+Scale+for+Personalized+E-commerce)|0|
|[Encouraging Exploration in Spotify Search through Query Recommendations](https://doi.org/10.1145/3640457.3688035)|Henrik Lindstrom, Humberto Jesús Corona Pampín, Enrico Palumbo, Alva Liu|Spotify, Stockholm, Sweden; Spotify, Turin, Italy; Spotify, Amsterdam, Netherlands|At Spotify, search has been traditionally seen as a tool for retrieving content, with the search system optimized for when the user has a specific target in mind. In particular we have relied on an instant search system providing results for each keystroke, which works well for known-item search, when queries are straightforward, and the catalog is small. However, as Spotify’s catalog grows in size and variety, it becomes increasingly difficult for users to define their search intents accurately. Furthermore, as we expand the offering, we need to help users discover more content both when it comes to new content types, e.g. audiobooks, as well as for new content/creators within existing content types. To solve this we have introduced a hybrid Query Recommendation system (QR) that helps the user formulate more complex exploratory search intents, while still serving known-item lookups efficiently. This experience has been rolled out worldwide to all mobile users resulting in an increase in exploratory intent queries of 9% in A/B tests.|在Spotify，搜索传统上被视为一种检索内容的工具，其搜索系统针对用户有明确目标的情况进行了优化。特别是，我们依赖一种即时搜索系统，该系统为每个按键提供结果，这在已知项搜索、查询简单且目录较小的情况下表现良好。然而，随着Spotify目录规模和多样性的增长，用户准确定义搜索意图变得越来越困难。此外，随着我们扩展服务内容，我们需要帮助用户发现更多内容，无论是新内容类型（例如有声书），还是现有内容类型中的新内容/创作者。为了解决这个问题，我们引入了一种混合查询推荐系统（QR），该系统帮助用户制定更复杂的探索性搜索意图，同时仍然高效地服务于已知项查找。这一体验已向全球所有移动用户推出，在A/B测试中，探索性意图查询增加了9%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Encouraging+Exploration+in+Spotify+Search+through+Query+Recommendations)|0|
|[Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems](https://doi.org/10.1145/3640457.3688048)|Timo Wilm, Philipp Normann, Felix Stepprath|OTTO GmbH & Co Kg, Hamburg, Germany|This work introduces MultiTRON, an approach that adapts Pareto front approximation techniques to multi-objective session-based recommender systems using a transformer neural network. Our approach optimizes trade-offs between key metrics such as click-through and conversion rates by training on sampled preference vectors. A significant advantage is that after training, a single model can access the entire Pareto front, allowing it to be tailored to meet the specific requirements of different stakeholders by adjusting an additional input vector that weights the objectives. We validate the model’s performance through extensive offline and online evaluation. For broader application and research, the source code1 is made available. The results confirm the model’s ability to manage multiple recommendation objectives effectively, offering a flexible tool for diverse business needs.|本文介绍了MultiTRON方法，该方法通过将帕累托前沿逼近技术应用于基于会话的多目标推荐系统，并利用Transformer神经网络进行实现。我们的方法通过在采样的偏好向量上进行训练，优化了关键指标（如点击率和转化率）之间的权衡。一个显著的优势在于，训练完成后，单一模型能够访问整个帕累托前沿，通过调整一个额外的输入向量来加权目标，从而使其能够根据不同利益相关者的具体需求进行定制。我们通过广泛的离线和在线评估验证了模型的性能。为了促进更广泛的应用和研究，源代码1已公开发布。结果证实了该模型能够有效管理多个推荐目标，为多样化的业务需求提供了一个灵活的工具。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto+Front+Approximation+for+Multi-Objective+Session-Based+Recommender+Systems)|0|
|[Enhancing Sequential Music Recommendation with Negative Feedback-informed Contrastive Learning](https://doi.org/10.1145/3640457.3688188)|Pavan Seshadri, Shahrzad Shashaani, Peter Knees|TU Wien, Fac Informat, Vienna, Austria; Georgia Inst Technol, Mus Informat Grp, Atlanta, GA 30332 USA|Modern music streaming services are heavily based on recommendation engines to serve content to users. Sequential recommendation—continuously providing new items within a single session in a contextually coherent manner—has been an emerging topic in current literature. User feedback—a positive or negative response to the item presented—is used to drive content recommendations by learning user preferences. We extend this idea to session-based recommendation to provide context-coherent music recommendations by modelling negative user feedback, i.e., skips, in the loss function. We propose a sequence-aware contrastive sub-task to structure item embeddings in session-based music recommendation, such that true next-positive items (ignoring skipped items) are structured closer in the session embedding space, while skipped tracks are structured farther away from all items in the session. This directly affects item rankings using a K-nearest-neighbors search for next-item recommendations, while also promoting the rank of the true next item. Experiments incorporating this task into SoTA methods for sequential item recommendation show consistent performance gains in terms of next-item hit rate, item ranking, and skip down-ranking on three music recommendation datasets, strongly benefiting from the increasing presence of user feedback.|现代音乐流媒体服务在很大程度上依赖于推荐引擎向用户提供内容。顺序推荐——在单个会话中以上下文连贯的方式持续提供新项目——已成为当前文献中的一个新兴主题。用户反馈——对呈现项目的正面或负面响应——通过学习用户偏好来驱动内容推荐。我们将这一思路扩展到基于会话的推荐中，通过在损失函数中建模负面用户反馈（即跳过）来提供上下文连贯的音乐推荐。我们提出了一个序列感知的对比子任务，用于在基于会话的音乐推荐中构建项目嵌入，使得真正的下一个正面项目（忽略跳过的项目）在会话嵌入空间中结构更近，而跳过的曲目则与会话中的所有项目结构更远。这直接影响了使用K近邻搜索进行下一项目推荐时的项目排名，同时也提升了真正下一个项目的排名。将这一任务整合到顺序项目推荐的最先进方法中的实验表明，在三个音乐推荐数据集上，下一项目命中率、项目排名和跳过低排名方面均显示出持续的性能提升，这极大地受益于用户反馈的日益增多。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Sequential+Music+Recommendation+with+Negative+Feedback-informed+Contrastive+Learning)|0|
|[Unleashing the Retrieval Potential of Large Language Models in Conversational Recommender Systems](https://doi.org/10.1145/3640457.3688146)|Ting Yang, Li Chen|Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China|Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through interactive natural language interaction. The recent advent of large language models (LLMs) has revolutionized human engagement in natural conversation, driven by their extensive world knowledge and remarkable natural language understanding and generation capabilities. However, introducing LLMs into CRSs presents new technical challenges. Directly prompting LLMs for recommendation generation requires understanding a large and evolving item corpus, as well as grounding the generated recommendations in the real item space. On the other hand, generating recommendations based on external recommendation engines or directly integrating their suggestions into responses may constrain the overall performance of LLMs, since these engines generally have inferior representation abilities compared to LLMs. To address these challenges, we propose an end-to-end large-scale CRS model, named as ReFICR, a novel LLM-enhanced conversational recommender that empowers a retrievable large language model to perform conversational recommendation by following retrieval and generation instructions through lightweight tuning. By decomposing the complex CRS task into multiple subtasks, we formulate these subtasks into two types of instruction formats: retrieval and generation. The hidden states of ReFICR are utilized for generating text embeddings for retrieval, and simultaneously ReFICR is fine-tuned to handle generation subtasks. We optimize the contrastive objective to enhance text embeddings for retrieval and jointly fine-tune the large language model objective for generation. Our experimental results on public datasets demonstrate that ReFICR significantly outperforms baselines in terms of recommendation accuracy and response quality. Our code is publicly available at the link: https://github.com/yt556677/ReFICR.|对话推荐系统（CRSs）旨在通过交互式的自然语言对话捕捉用户偏好并提供个性化推荐。最近，大型语言模型（LLMs）的出现彻底改变了人类在自然对话中的参与方式，这得益于其广泛的世界知识和卓越的自然语言理解与生成能力。然而，将LLMs引入CRSs也带来了新的技术挑战。直接通过提示LLMs生成推荐需要理解庞大且不断变化的项目语料库，并将生成的推荐与实际项目空间相连接。另一方面，基于外部推荐引擎生成推荐或将其建议直接集成到响应中可能会限制LLMs的整体性能，因为这些引擎的表示能力通常不如LLMs。为了解决这些挑战，我们提出了一种端到端的大规模CRS模型，名为ReFICR，这是一种新型的LLM增强的对话推荐系统，通过轻量级调优使可检索的大型语言模型能够通过遵循检索和生成指令来执行对话推荐。通过将复杂的CRS任务分解为多个子任务，我们将这些子任务制定为两种指令格式：检索和生成。ReFICR的隐藏状态用于生成检索所需的文本嵌入，同时ReFICR经过微调以处理生成子任务。我们优化对比目标以增强检索的文本嵌入，并联合微调大型语言模型的目标以进行生成。我们在公开数据集上的实验结果表明，ReFICR在推荐准确性和响应质量方面显著优于基线模型。我们的代码可在以下链接公开获取：https://github.com/yt556677/ReFICR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unleashing+the+Retrieval+Potential+of+Large+Language+Models+in+Conversational+Recommender+Systems)|0|
|[Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other?](https://doi.org/10.1145/3640457.3688123)|Gustavo Penha, Ali Vardasbi, Enrico Palumbo, Marco De Nadai, Hugues Bouchard|Spotify, Milan, Italy; Spotify, Amsterdam, Netherlands; Spotify, Copenhagen, Denmark; Spotify, Madrid, Spain|Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the breakthroughs of Large Language Models (LLMs), these generative systems can play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items learned by generative recommenders are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.|生成式检索在搜索和推荐领域是一种具有前景的检索范式，它为依赖外部索引和最近邻搜索的传统方法提供了一种替代方案。与这些传统方法不同，生成模型直接将输入与项目ID关联起来。鉴于大语言模型（LLMs）的突破性进展，这些生成系统可以在一个单一模型中集中处理多种信息检索（IR）任务，包括查询理解、检索、推荐、解释、重排序和响应生成等。尽管这种统一的生成式方法在IR系统中引起了越来越多的兴趣，但在文献中，使用单一的多任务模型相较于多个专门模型的优势尚未得到充分验证。本文探讨了在搜索和推荐这两类广泛共存于多个工业在线平台（如Spotify、YouTube和Netflix）的IR任务中，这种统一方法是否以及何时能够超越特定任务模型。先前的研究表明：（1）生成式推荐器学习到的项目潜在表示偏向于流行度；（2）基于内容和基于协同过滤的信息可以改善项目的表示。受此启发，我们的研究基于两个假设进行：[H1]联合训练能够规范化每个项目流行度的估计；[H2]联合训练能够规范化项目的潜在表示，其中搜索捕捉项目的基于内容的特性，而推荐捕捉基于协同过滤的特性。我们通过模拟数据和真实数据的广泛实验验证了[H1]和[H2]是统一搜索和推荐生成模型相较于单任务方法在效果提升中的关键贡献因素。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Search+and+Recommendation+in+Generative+Retrieval:+Does+One+Task+Help+the+Other?)|0|
|[Neighborhood-Based Collaborative Filtering for Conversational Recommendation](https://doi.org/10.1145/3640457.3688191)|Zhouhang Xie, Junda Wu, Hyunsik Jeon, Zhankui He, Harald Steck, Rahul Jha, Dawen Liang, Nathan Kallus, Julian J. McAuley|Netflix Inc, Los Gatos, CA USA; Univ Calif San Diego, La Jolla, CA 92093 USA|Conversational recommender systems (CRS) should understand users’ expressed interests, which are frequently semantically rich and knowledge-intensive. Prior works attempt to address this challenge by using external knowledge bases or parametric knowledge in large language models (LLMs). In this paper, we study a complementary solution, exploiting item knowledge in the training data. We hypothesize that many inference-time user requests can be answered by reusing popular crowd-written answers associated with similar training queries. Following this intuition, we define a class of neighborhood-based CRS that makes recommendations by identifying items commonly associated with similar training dialogue contexts. Experiments on Inspired, Redial, and Reddit-Movie benchmarks show our method outperforms state-of-the-art LLMs with 2 billion parameters, and offers on-par performance to 7 billion parameter models while using over 170 times less GPU memory. We also show neighborhood and model-based predictions can be combined to achieve further performance improvements1.|对话推荐系统（CRS）需要理解用户表达的兴趣，这些兴趣通常具有丰富的语义和知识密集性。先前的研究尝试通过使用外部知识库或大型语言模型（LLMs）中的参数化知识来解决这一挑战。在本文中，我们研究了一种互补的解决方案，即利用训练数据中的项目知识。我们假设许多推理时的用户请求可以通过重用与类似训练查询相关的流行群体编写的答案来回答。基于这一直觉，我们定义了一类基于邻域的CRS，它通过识别与类似训练对话上下文相关的常见项目来进行推荐。在Inspired、Redial和Reddit-Movie基准测试上的实验表明，我们的方法优于具有20亿参数的最先进LLMs，并且在性能上与70亿参数模型相当，同时使用的GPU内存减少了170倍以上。我们还展示了邻域和基于模型的预测可以结合起来，以进一步实现性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighborhood-Based+Collaborative+Filtering+for+Conversational+Recommendation)|0|
|[Enhancing Sequential Music Recommendation with Personalized Popularity Awareness](https://doi.org/10.1145/3640457.3691719)|Davide Abbattista, Vito Walter Anelli, Tommaso Di Noia, Craig MacDonald, Aleksandr Vladimirovich Petrov|Univ Glasgow, Glasgow, Lanark, Scotland; Politecn Bari, Bari, Italy|In the realm of music recommendation, sequential recommender systems have shown promise in capturing the dynamic nature of music consumption. Nevertheless, traditional Transformer-based models, such as SASRec and BERT4Rec, while effective, encounter challenges due to the unique characteristics of music listening habits. In fact, existing models struggle to create a coherent listening experience due to rapidly evolving preferences. Moreover, music consumption is characterized by a prevalence of repeated listening, i.e. users frequently return to their favourite tracks, an important signal that could be framed as individual or personalized popularity. This paper addresses these challenges by introducing a novel approach that incorporates personalized popularity information into sequential recommendation. By combining user-item popularity scores with model-generated scores, our method effectively balances the exploration of new music with the satisfaction of user preferences. Experimental results demonstrate that a Personalized Most Popular recommender, a method solely based on user-specific popularity, outperforms existing state-of-the-art models. Furthermore, augmenting Transformer-based models with personalized popularity awareness yields superior performance, showing improvements ranging from 25.2% to 69.8%. The code for this paper is available at https://github.com/sisinflab/personalized-popularity-awareness.|在音乐推荐领域，序列推荐系统在捕捉音乐消费的动态特性方面展现出潜力。然而，尽管基于Transformer的传统模型（如SASRec和BERT4Rec）在推荐效果上表现优异，但由于音乐收听习惯的独特性，这些模型仍面临一些挑战。事实上，现有模型在用户偏好快速变化的情况下难以提供连贯的收听体验。此外，音乐消费的一个显著特点是重复收听行为的高频出现，即用户经常返回他们喜爱的曲目，这一重要信号可以被视为个体化或个性化的流行度。本文通过引入一种新颖的方法来解决这些挑战，该方法将个性化流行度信息融入序列推荐中。通过将用户-项目流行度得分与模型生成得分相结合，我们的方法有效地平衡了新音乐的探索与用户偏好的满足。实验结果表明，仅基于用户特定流行度的个性化最流行推荐器（Personalized Most Popular recommender）优于现有的最先进模型。此外，通过在基于Transformer的模型中融入个性化流行度感知，性能得到了显著提升，改进幅度在25.2%至69.8%之间。本文的代码可在https://github.com/sisinflab/personalized-popularity-awareness获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Sequential+Music+Recommendation+with+Personalized+Popularity+Awareness)|0|
|[GenUI(ne) CRS: UI Elements and Retrieval-Augmented Generation in Conversational Recommender Systems with LLMs](https://doi.org/10.1145/3640457.3691697)|Ulysse Maes, Lien Michiels, Annelien Smets|Vrije Univ Brussel, IMEC, SMIT, Brussels, Belgium|Previous research has used Large Language Models (LLMs) to develop personalized Conversational Recommender Systems (CRS) with text-based user interfaces (UIs). However, the potential of LLMs to generate interactive graphical elements that enhance user experience remains largely unexplored. To address this gap, we introduce "GenUI(ne) CRS," a novel framework designed to leverage LLMs for adaptive and interactive UIs. Our framework supports domain-specific graphical elements such as buttons and cards, in addition to text-based inputs. It also addresses the common LLM issue of outdated knowledge, known as the "knowledge cut-off," by implementing Retrieval-Augmented Generation (RAG). To illustrate its potential, we developed a prototype movie CRS. This work demonstrates the feasibility of LLM-powered interactive UIs and paves the way for future CRS research, including user experience validation, transparent explanations, and addressing LLM biases.|先前的研究已经利用大型语言模型（LLMs）开发了基于文本用户界面（UI）的个性化对话推荐系统（CRS）。然而，LLMs在生成增强用户体验的交互式图形元素方面的潜力在很大程度上尚未被探索。为了填补这一空白，我们引入了“GenUI(ne) CRS”，这是一个新颖的框架，旨在利用LLMs实现自适应和交互式的UI。我们的框架除了支持基于文本的输入外，还支持特定领域的图形元素，如按钮和卡片。它还通过实施检索增强生成（RAG）来解决LLMs常见的知识过时问题，即“知识截止”问题。为了展示其潜力，我们开发了一个原型电影CRS。这项工作证明了LLM驱动的交互式UI的可行性，并为未来的CRS研究铺平了道路，包括用户体验验证、透明解释以及解决LLM偏见等问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GenUI(ne)+CRS:+UI+Elements+and+Retrieval-Augmented+Generation+in+Conversational+Recommender+Systems+with+LLMs)|0|
|[Biased User History Synthesis for Personalized Long-Tail Item Recommendation](https://doi.org/10.1145/3640457.3688141)|Keshav Balasubramanian, Abdulla Alshabanah, Elan Markowitz, Greg Ver Steeg, Murali Annavaram|Univ Calif Riverside, Riverside, CA 92521 USA; Univ Southern Calif, Los Angeles, CA 90007 USA; Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA USA|Recommendation systems connect users to items and create value chains in the internet economy. Recommendation systems learn from past user-item interaction histories. As such, items that have short interaction histories, either because they are new or not popular, have been shown to be disproportionately under-recommended. This long-tail item problem can exacerbate model bias, and reinforce poor recommendation of tail items. In this paper, we propose biased user history synthesis, to not only address this problem but also achieve better personalization in recommendation systems. As a result, we concurrently improve tail and head item recommendation performance. Our approach is built on a tail item biased User Interaction History (UIH) sampling strategy and a synthesis model that produces an augmented user representation from the sampled user history. We provide a theoretical justification for our approach using information theory and demonstrate through extensive experimentation, that our model outperforms state-of-the-art baselines on tail, head, and overall recommendation. The source code is available at https://github.com/lkp411/BiasedUserHistorySynthesis.|推荐系统在互联网经济中连接用户与项目，并创造价值链。推荐系统通过过去用户与项目交互的历史进行学习。因此，对于那些交互历史较短的项目，无论是由于它们是新项目还是不受欢迎，都显示出被推荐的比例明显偏低。这种长尾项目问题可能会加剧模型偏差，并进一步强化对尾部项目的推荐不足。在本文中，我们提出了有偏用户历史合成方法，不仅解决了这一问题，还在推荐系统中实现了更好的个性化。因此，我们同时提高了尾部项目和头部项目的推荐性能。我们的方法基于一种尾部项目有偏的用户交互历史（UIH）采样策略，以及一个从采样用户历史中生成增强用户表示的合成模型。我们使用信息论为我们的方法提供了理论依据，并通过大量实验证明，我们的模型在尾部、头部以及整体推荐性能上优于现有的最先进基线模型。源代码可在 https://github.com/lkp411/BiasedUserHistorySynthesis 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Biased+User+History+Synthesis+for+Personalized+Long-Tail+Item+Recommendation)|0|
|[SeCor: Aligning Semantic and Collaborative Representations by Large Language Models for Next-Point-of-Interest Recommendations](https://doi.org/10.1145/3640457.3688124)|Shirui Wang, Bohan Xie, Ling Ding, Xiaoying Gao, Jianting Chen, Yang Xiang|Tongji Univ, Shanghai, Peoples R China|The widespread adoption of location-based applications has created a growing demand for point-of-interest (POI) recommendation, which aims to predict a user’s next POI based on their historical check-in data and current location. However, existing methods often struggle to capture the intricate relationships within check-in data. This is largely due to their limitations in representing temporal and spatial information and underutilizing rich semantic features. While large language models (LLMs) offer powerful semantic comprehension to solve them, they are limited by hallucination and the inability to incorporate global collaborative information. To address these issues, we propose a novel method SeCor, which treats POI recommendation as a multi-modal task and integrates semantic and collaborative representations to form an efficient hybrid encoding. SeCor first employs a basic collaborative filtering model to mine interaction features. These embeddings, as one modal information, are fed into LLM to align with semantic representation, leading to efficient hybrid embeddings. To mitigate the hallucination, SeCor recommends based on the hybrid embeddings rather than directly using the LLM’s output text. Extensive experiments on three public real-world datasets show that SeCor outperforms all baselines, achieving improved recommendation performance by effectively integrating collaborative and semantic information through LLMs.|基于位置应用的广泛普及催生了对兴趣点（POI）推荐日益增长的需求，该推荐旨在根据用户的历史签到数据和当前位置预测其下一个POI。然而，现有方法在捕捉签到数据中的复杂关系方面往往存在困难。这主要是由于它们在表示时间和空间信息方面的局限性以及对丰富语义特征的利用不足。虽然大型语言模型（LLMs）提供了强大的语义理解能力来解决这些问题，但它们受到幻觉问题和无法整合全局协作信息的限制。为了应对这些问题，我们提出了一种名为SeCor的新方法，该方法将POI推荐视为多模态任务，并整合语义和协作表示以形成高效的混合编码。SeCor首先采用基本的协同过滤模型来挖掘交互特征。这些嵌入作为一种模态信息被输入到LLM中，以与语义表示对齐，从而生成高效的混合嵌入。为了减轻幻觉问题，SeCor基于混合嵌入进行推荐，而不是直接使用LLM的输出文本。在三个公开的真实世界数据集上进行的大量实验表明，SeCor在所有基线方法中表现优异，通过LLM有效整合协作和语义信息，实现了推荐性能的提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SeCor:+Aligning+Semantic+and+Collaborative+Representations+by+Large+Language+Models+for+Next-Point-of-Interest+Recommendations)|0|
|[Dynamic Stage-aware User Interest Learning for Heterogeneous Sequential Recommendation](https://doi.org/10.1145/3640457.3688103)|Weixin Li, Xiaolin Lin, Weike Pan, Zhong Ming|Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China; Shenzhen Univ, Shenzhen, Peoples R China|Sequential recommendation has been widely used to predict users’ potential preferences by learning their dynamic user interests, for which most previous methods focus on capturing item-level dependencies. Despite the great success, they often overlook the stage-level interest dependencies. In real-world scenarios, user interests tend to be staged, e.g., following an item purchase, a user’s interests may undergo a transition into the subsequent phase. And there are intricate dependencies across different stages. Meanwhile, users’ behaviors are usually heterogeneous, including auxiliary behaviors (e.g., examinations) and target behaviors (e.g., purchases), which imply more fine-grained user interests. However, existing methods have limitations in explicitly modeling the relationships between the different types of behaviors. To address the above issues, we propose a novel framework, i.e., dynamic stage-aware user interest learning (DSUIL), for heterogeneous sequential recommendation, which is the first solution to model user interests in a cross-stage manner. Specifically, our DSUIL consists of four modules: (1) a dynamic graph construction module transforms a heterogeneous sequence into several subgraphs to model user interests in a stage-wise manner; (2) a dynamic graph convolution module dynamically learns item representations in each subgraph; (3) a behavior-aware subgraph representation learning module learns the heterogeneous dependencies between behaviors and aggregates item representations to represent the staged user interests; and (4) an interest evolving pattern extractor learns the users’ overall interests for the item prediction. Extensive experimental results on two public datasets show that our DSUIL performs significantly better than the state-of-the-art methods.|序列推荐通过学习用户的动态兴趣来预测其潜在偏好，已在广泛应用中取得了显著成效。以往的方法大多侧重于捕捉物品级别的依赖关系。尽管这些方法取得了巨大成功，但它们往往忽视了阶段级别的兴趣依赖关系。在现实场景中，用户的兴趣往往是分阶段的，例如，在购买某件物品后，用户的兴趣可能会过渡到下一个阶段。同时，不同阶段之间存在复杂的依赖关系。此外，用户的行为通常是异质的，包括辅助行为（如浏览）和目标行为（如购买），这些行为暗示了更细粒度的用户兴趣。然而，现有方法在显式建模不同类型行为之间的关系方面存在局限性。

为了解决上述问题，我们提出了一种新颖的框架，即**动态阶段感知用户兴趣学习（DSUIL）**，用于异质序列推荐。这是首个以跨阶段方式建模用户兴趣的解决方案。具体而言，我们的DSUIL框架包含四个模块：(1) **动态图构建模块**将异质序列转换为若干子图，以分阶段的方式建模用户兴趣；(2) **动态图卷积模块**动态学习每个子图中的物品表示；(3) **行为感知子图表示学习模块**学习行为之间的异质依赖关系，并聚合物品表示以表征分阶段的用户兴趣；(4) **兴趣演化模式提取器**学习用户的整体兴趣，用于物品预测。在两个公开数据集上的大量实验结果表明，我们的DSUIL框架显著优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Stage-aware+User+Interest+Learning+for+Heterogeneous+Sequential+Recommendation)|0|
|[Bootstrapping Conditional Retrieval for User-to-Item Recommendations](https://doi.org/10.1145/3640457.3688057)|Hongtao Lin, Haoyu Chen, Jaewon Yang, Jiajing Xu|Pinterest, San Francisco, CA 94107 USA|User-to-item retrieval has been an active research area in recommendation system, and two tower models are widely adopted due to model simplicity and serving efficiency. In this work, we focus on a variant called conditional retrieval, where we expect retrieved items to be relevant to a condition (e.g. topic). We propose a method that uses the same training data as standard two tower models but incorporates item-side information as conditions in query. This allows us to bootstrap new conditional retrieval use cases and encourages feature interactions between user and condition. Experiments show that our method can retrieve highly relevant items and outperforms standard two tower models with filters on engagement metrics. The proposed model is deployed to power a topic-based notification feed at Pinterest and led to +0.26% weekly active users.|用户到物品的检索一直是推荐系统中的一个活跃研究领域，双塔模型因其模型简单和服务效率高而被广泛采用。在本研究中，我们关注一种称为条件检索的变体，其中我们希望检索到的物品与某个条件（例如主题）相关。我们提出了一种方法，该方法使用与标准双塔模型相同的训练数据，但在查询中引入物品侧信息作为条件。这使得我们能够引导新的条件检索用例，并促进用户与条件之间的特征交互。实验表明，我们的方法能够检索到高度相关的物品，并在参与度指标上优于带有过滤器的标准双塔模型。所提出的模型已部署在Pinterest中，用于支持基于主题的通知流，并导致每周活跃用户增加了0.26%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bootstrapping+Conditional+Retrieval+for+User-to-Item+Recommendations)|0|
|[Do Not Wait: Learning Re-Ranking Model Without User Feedback At Serving Time in E-Commerce](https://doi.org/10.1145/3640457.3688165)|Yuan Wang, Zhiyu Li, Changshuo Zhang, Sirui Chen, Xiao Zhang, Jun Xu, Quan Lin|Renmin Univ China, Sch Informat, Beijing, Peoples R China; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Alibaba Grp, Hangzhou, Zhejiang, Peoples R China|Recommender systems have been widely used in e-commerce, and re-rankingmodels are playing an increasingly significant role in the domain, whichleverages the inter-item influence and determines the final recommendationlists. Online learning methods keep updating a deployed model with the latestavailable samples to capture the shifting of the underlying data distributionin e-commerce. However, they depend on the availability of real user feedback,which may be delayed by hours or even days, such as item purchases, leading toa lag in model enhancement. In this paper, we propose a novel extension ofonline learning methods for re-ranking modeling, which we term LAST, an acronymfor Learning At Serving Time. It circumvents the requirement of user feedbackby using a surrogate model to provide the instructional signal needed to steermodel improvement. Upon receiving an online request, LAST finds and applies amodel modification on the fly before generating a recommendation result for therequest. The modification is request-specific and transient. It means themodification is tailored to and only to the current request to capture thespecific context of the request. After a request, the modification isdiscarded, which helps to prevent error propagation and stabilizes the onlinelearning procedure since the predictions of the surrogate model may beinaccurate. Most importantly, as a complement to feedback-based online learningmethods, LAST can be seamlessly integrated into existing online learningsystems to create a more adaptive and responsive recommendation experience.Comprehensive experiments, both offline and online, affirm that LASToutperforms state-of-the-art re-ranking models.|推荐系统在电子商务中得到了广泛应用，而重排序模型在该领域正发挥着越来越重要的作用。重排序模型通过利用商品间的影响力来确定最终的推荐列表。在线学习方法通过不断使用最新可用的样本来更新已部署的模型，以捕捉电子商务中潜在数据分布的变化。然而，这些方法依赖于真实用户反馈的可用性，而这些反馈（如商品购买）可能会延迟数小时甚至数天，从而导致模型增强的滞后。本文提出了一种新颖的在线学习方法扩展，用于重排序建模，我们将其称为LAST，即“在服务时学习”（Learning At Serving Time）的缩写。LAST通过使用替代模型提供指导信号来规避用户反馈的需求，从而引导模型改进。在接收到在线请求时，LAST会在生成推荐结果之前动态地找到并应用模型修改。这种修改是特定于请求且临时的，意味着修改是针对且仅针对当前请求的，以捕捉请求的特定上下文。请求结束后，修改将被丢弃，这有助于防止错误传播并稳定在线学习过程，因为替代模型的预测可能不准确。最重要的是，作为基于反馈的在线学习方法的补充，LAST可以无缝集成到现有的在线学习系统中，以创建更具适应性和响应性的推荐体验。全面的离线和在线实验证实，LAST优于最先进的重排序模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+Not+Wait:+Learning+Re-Ranking+Model+Without+User+Feedback+At+Serving+Time+in+E-Commerce)|0|
|[FairCRS: Towards User-oriented Fairness in Conversational Recommendation Systems](https://doi.org/10.1145/3640457.3688150)|Qin Liu, Xuan Feng, Tianlong Gu, Xiaoli Liu|Jinan Univ, Engn Res Ctr Trustworthy AI, Minist Educ, Guangzhou, Guangdong, Peoples R China|Conversational Recommendation Systems (CRSs) enable recommender systems to explicitly acquire user preferences during multi-turn interactions, providing more accurate and personalized recommendations. However, the data imbalance in CRSs, due to inconsistent interaction history among users, may lead to disparate treatment for disadvantaged user groups. In this paper, we investigate the discriminate problems in CRS from the user’s perspective, called as user-oriented fairness. To reveal the unfairness problems of different user groups in CRS, we conduct extensive empirical analyses. To mitigate user unfairness, we propose a user-oriented fairness framework, named FairCRS, which is a model-agnostic framework. In particular, we develop a user-embedding reconstruction mechanism that enriches user embeddings by incorporating more interaction information, and design a user-oriented fairness strategy that optimizes the recommendation quality differences among user groups while alleviating unfairness. Extensive experimental results on English and Chinese datasets show that FairCRS outperforms state-of-the-art CRSs in terms of overall recommendation performance and user fairness.|对话推荐系统（Conversational Recommendation Systems, CRSs）通过在多轮交互中显式获取用户偏好，能够提供更加准确和个性化的推荐。然而，由于用户之间交互历史的不一致性，CRS中的数据不平衡可能导致对弱势用户群体的不公平对待。本文从用户角度研究了CRS中的歧视问题，称为用户导向的公平性。为了揭示CRS中不同用户群体的不公平问题，我们进行了广泛的实证分析。为了缓解用户不公平性，我们提出了一个用户导向的公平性框架，名为FairCRS，这是一个与模型无关的框架。具体而言，我们开发了一种用户嵌入重构机制，通过整合更多的交互信息来丰富用户嵌入，并设计了一种用户导向的公平性策略，在优化用户群体间推荐质量差异的同时缓解不公平性。在英文和中文数据集上的大量实验结果表明，FairCRS在整体推荐性能和用户公平性方面优于现有的最先进CRS。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairCRS:+Towards+User-oriented+Fairness+in+Conversational+Recommendation+Systems)|0|
|[Low Rank Field-Weighted Factorization Machines for Low Latency Item Recommendation](https://doi.org/10.1145/3640457.3688097)|Alex Shtoff, Michael Viderman, Naama HaramatyKrasne, Oren Somekh, Ariel Raviv, Tularam Ban|Yahoo Res, London, England|Factorization machine (FM) variants are widely used in recommendation systems that operate under strict throughput and latency requirements, such as online advertising systems. FMs have two prominent strengths. First, is their ability to model pairwise feature interactions while being resilient to data sparsity by learning factorized representations. Second, their computational graphs facilitate fast inference and training. Moreover, when items are ranked as a part of a query for each incoming user, these graphs facilitate computing the portion stemming from the user and context fields only once per query. Thus, the computational cost for each ranked item is proportional only to the number of fields that vary among the ranked items. Consequently, in terms of inference cost, the number of user or context fields is practically unlimited. More advanced variants of FMs, such as field-aware and field-weighted FMs, provide better accuracy by learning a representation of field-wise interactions, but require computing all pairwise interaction terms explicitly. In particular, the computational cost during inference is proportional to the square of the number of fields, including user, context, and item. When the number of fields is large, this is prohibitive in systems with strict latency constraints, and imposes a limit on the number of user and context fields for a given computational budget. To mitigate this caveat, heuristic pruning of low intensity field interactions is commonly used to accelerate inference. In this work we propose an alternative to the pruning heuristic in field-weighted FMs using a diagonal plus symmetric low-rank decomposition. Our technique reduces the computational cost of inference, by allowing it to be proportional to the number of item fields only. Using a set of experiments on real-world datasets, we show that aggressive rank reduction outperforms similarly aggressive pruning in both accuracy and item recommendation speed. Beyond computational complexity analysis, we corroborate our claim of faster inference experimentally, both via a synthetic test, and by having deployed our solution to a major online advertising system, where we observed significant ranking latency improvements. We have made the code to reproduce the results on public datasets and synthetic tests available at https://github.com/michaelviderman/pytorch-fm.|因子分解机（FM）的变体广泛应用于在严格的吞吐量和延迟要求下运行的推荐系统中，例如在线广告系统。FM有两个显著的优点。首先，它们能够通过因式分解表示来建模特征之间的成对交互，同时对数据稀疏性具有鲁棒性。其次，它们的计算图有利于快速推理和训练。此外，当项目作为每个新用户的查询的一部分进行排序时，这些计算图有助于仅对用户和上下文字段进行一次计算。因此，每个排序项目的计算成本仅与排序项目之间变化的字段数量成比例。因此，就推理成本而言，用户或上下文字段的数量实际上是无限制的。更高级的FM变体，如字段感知和字段加权的FM，通过学习字段间交互的表示提供了更好的准确性，但需要显式计算所有成对交互项。特别是，推理期间的计算成本与字段数量的平方成比例，包括用户、上下文和项目字段。当字段数量较大时，这在具有严格延迟约束的系统中是不可行的，并且对于给定的计算预算，限制了用户和上下文字段的数量。为了缓解这一问题，通常使用低强度字段交互的启发式剪枝来加速推理。在本研究中，我们提出了一种替代字段加权FM中剪枝启发式方法的方法，即使用对角加对称低秩分解。我们的技术通过使推理成本仅与项目字段数量成比例来降低推理的计算成本。通过在真实世界数据集上进行的一系列实验，我们展示了在准确性和项目推荐速度方面，激进的秩减少优于同样激进的剪枝。除了计算复杂性分析外，我们还通过合成测试和将我们的解决方案部署到一个主要的在线广告系统中，实验性地证实了我们关于更快推理的主张，并观察到了显著的排序延迟改进。我们已在https://github.com/michaelviderman/pytorch-fm上提供了用于在公共数据集和合成测试上重现结果的代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low+Rank+Field-Weighted+Factorization+Machines+for+Low+Latency+Item+Recommendation)|0|
|[MLoRA: Multi-Domain Low-Rank Adaptive Network for CTR Prediction](https://doi.org/10.1145/3640457.3688134)|Zhiming Yang, Haining Gao, Dehong Gao, Luwei Yang, Libin Yang, Xiaoyan Cai, Wei Ning, Guannan Zhang||Click-through rate (CTR) prediction is one of the fundamental tasks in the industry, especially in e-commerce, social media, and streaming media. It directly impacts website revenues, user satisfaction, and user retention. However, real-world production platforms often encompass various domains to cater for diverse customer needs. Traditional CTR prediction models struggle in multi-domain recommendation scenarios, facing challenges of data sparsity and disparate data distributions across domains. Existing multi-domain recommendation approaches introduce specific-domain modules for each domain, which partially address these issues but often significantly increase model parameters and lead to insufficient training. In this paper, we propose a Multi-domain Low-Rank Adaptive network (MLoRA) for CTR prediction, where we introduce a specialized LoRA module for each domain. This approach enhances the model's performance in multi-domain CTR prediction tasks and is able to be applied to various deep-learning models. We evaluate the proposed method on several multi-domain datasets. Experimental results demonstrate our MLoRA approach achieves a significant improvement compared with state-of-the-art baselines. Furthermore, we deploy it in the production environment of the Alibaba.COM. The online A/B testing results indicate the superiority and flexibility in real-world production environments. The code of our MLoRA is publicly available.|点击率（CTR）预测是工业界的一项基础任务，尤其在电子商务、社交媒体和流媒体领域。它直接影响网站收入、用户满意度和用户留存率。然而，现实世界的生产平台通常涵盖多个领域，以满足不同客户的需求。传统的CTR预测模型在多领域推荐场景中表现不佳，面临数据稀疏性和跨领域数据分布差异的挑战。现有的多领域推荐方法为每个领域引入了特定领域的模块，虽然部分解决了这些问题，但通常会显著增加模型参数并导致训练不足。在本文中，我们提出了一种用于CTR预测的多领域低秩自适应网络（MLoRA），其中我们为每个领域引入了一个专门的LoRA模块。这种方法增强了模型在多领域CTR预测任务中的性能，并且能够应用于各种深度学习模型。我们在多个多领域数据集上评估了所提出的方法。实验结果表明，与最先进的基线方法相比，我们的MLoRA方法取得了显著的改进。此外，我们在阿里巴巴国际站的生产环境中部署了该方法。在线A/B测试结果表明了它在实际生产环境中的优越性和灵活性。我们的MLoRA代码已公开提供。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MLoRA:+Multi-Domain+Low-Rank+Adaptive+Network+for+CTR+Prediction)|0|
|[Utilizing Non-click Samples via Semi-supervised Learning for Conversion Rate Prediction](https://doi.org/10.1145/3640457.3688151)|Jiahui Huang, Lan Zhang, Junhao Wang, Shanyang Jiang, Dongbo Huang, Cheng Ding, Lan Xu|Univ Sci & Technol China, Hefei, Anhui, Peoples R China; Tencent, Shanghai, Peoples R China|Conversion rate (CVR) prediction is essential in recommender systems, facilitating precise matching between recommended items and users’ preferences. However, the sample selection bias (SSB) and data sparsity (DS) issues pose challenges to accurate prediction. Existing works have proposed the click-through and conversion rate (CTCVR) prediction task which models samples from exposure to ``click and conversion" in entire space and incorporates multi-task learning. This approach has shown efficacy in mitigating these challenges. Nevertheless, it intensifies the false negative sample (FNS) problem. To be more specific, the CTCVR task implicitly treats all the CVR labels of non-click samples as negative, overlooking the possibility that some samples might convert if clicked. This oversight can negatively impact CVR model performance, as empirical analysis has confirmed. To this end, we advocate for discarding the CTCVR task and proposing a Non-click samples Improved Semi-supErvised (NISE) method for conversion rate prediction, where the non-click samples are treated as unlabeled. Our approach aims to predict their probabilities of conversion if clicked, utilizing these predictions as pseudo-labels for further model training. This strategy can help alleviate the FNS problem, and direct modeling of the CVR task across the entire space also mitigates the SSB and DS challenges. Additionally, we conduct multi-task learning by introducing an auxiliary click-through rate prediction task, thereby enhancing embedding layer representations. Our approach is applicable to various multi-task architectures. Comprehensive experiments are conducted on both public and production datasets, demonstrating the superiority of our proposed method in mitigating the FNS challenge and improving the CVR estimation. The implementation code is available at https://github.com/Hjh233/NISE.|转化率（CVR）预测在推荐系统中至关重要，它有助于实现推荐物品与用户偏好的精确匹配。然而，样本选择偏差（SSB）和数据稀疏性（DS）问题对准确预测提出了挑战。现有的研究工作提出了点击转化率（CTCVR）预测任务，该任务在整个空间中从曝光到“点击和转化”对样本进行建模，并结合了多任务学习。这种方法在缓解这些挑战方面显示出有效性。然而，它加剧了假阴性样本（FNS）问题。具体来说，CTCVR任务隐含地将所有未点击样本的CVR标签视为负样本，忽略了某些样本在被点击后可能转化的可能性。实证分析已证实，这种忽视会对CVR模型的性能产生负面影响。为此，我们主张摒弃CTCVR任务，并提出一种针对未点击样本的改进半监督（NISE）方法用于转化率预测，其中未点击样本被视为未标记样本。我们的方法旨在预测这些样本在被点击后的转化概率，并利用这些预测作为伪标签进行进一步的模型训练。这一策略有助于缓解FNS问题，同时在整个空间中直接对CVR任务进行建模也缓解了SSB和DS挑战。此外，我们通过引入辅助的点击率预测任务进行多任务学习，从而增强嵌入层的表示能力。我们的方法适用于各种多任务架构。我们在公开数据集和生产数据集上进行了全面的实验，结果表明所提出的方法在缓解FNS挑战和改进CVR估计方面具有优越性。实现代码可在https://github.com/Hjh233/NISE 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Utilizing+Non-click+Samples+via+Semi-supervised+Learning+for+Conversion+Rate+Prediction)|0|
|[A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios](https://doi.org/10.1145/3640457.3688138)|Christian Ganhör, Marta Moscati, Anna Hausberger, Shah Nawaz, Markus Schedl|Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria|Most recommender systems adopt collaborative filtering (CF) and provide recommendations based on past collective interactions. Therefore, the performance of CF algorithms degrades when few or no interactions are available, a scenario referred to as cold-start. To address this issue, previous work relies on models leveraging both collaborative data and side information on the users or items. Similar to multimodal learning, these models aim at combining collaborative and content representations in a shared embedding space. In this work we propose a novel technique for multimodal recommendation, relying on a multimodal Single-Branch embedding network for Recommendation (SiBraR). Leveraging weight-sharing, SiBraR encodes interaction data as well as multimodal side information using the same single-branch embedding network on different modalities. This makes SiBraR effective in scenarios of missing modality, including cold start. Our extensive experiments on large-scale recommendation datasets from three different recommendation domains (music, movie, and e-commerce) and providing multimodal content information (audio, text, image, labels, and interactions) show that SiBraR significantly outperforms CF as well as state-of-the-art content-based RSs in cold-start scenarios, and is competitive in warm scenarios. We show that SiBraR's recommendations are accurate in missing modality scenarios, and that the model is able to map different modalities to the same region of the shared embedding space, hence reducing the modality gap.|大多数推荐系统采用协同过滤（Collaborative Filtering, CF）方法，并基于过去的集体交互行为提供推荐。因此，当交互数据很少或没有时，CF算法的性能会下降，这种情况被称为冷启动问题。为了解决这一问题，先前的研究依赖于同时利用协同数据和用户或物品的辅助信息的模型。与多模态学习类似，这些模型旨在将协同表示和内容表示结合到一个共享的嵌入空间中。在本研究中，我们提出了一种新的多模态推荐技术，基于一种名为**单分支嵌入网络推荐模型（SiBraR）**的多模态方法。通过权重共享，SiBraR 使用相同的单分支嵌入网络对不同模态的交互数据和多模态辅助信息进行编码。这使得 SiBraR 在模态缺失（包括冷启动）的场景中表现出色。

我们在来自三个不同推荐领域（音乐、电影和电子商务）的大规模推荐数据集上进行了广泛的实验，这些数据集提供了多模态内容信息（音频、文本、图像、标签和交互）。实验结果表明，在冷启动场景下，SiBraR 显著优于 CF 以及当前最先进的基于内容的推荐系统（RS），并且在常规场景下也表现出竞争力。我们证明了 SiBraR 在模态缺失场景下的推荐是准确的，并且该模型能够将不同模态映射到共享嵌入空间的同一区域，从而减少了模态间的差异。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multimodal+Single-Branch+Embedding+Network+for+Recommendation+in+Cold-Start+and+Missing+Modality+Scenarios)|0|
|[Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs](https://doi.org/10.1145/3640457.3688140)|Gleb Mezentsev, Danil Gusak, Ivan V. Oseledets, Evgeny Frolov|Skolkovo Inst Sci & Technol, Moscow, Russia; HSE Univ, Moscow, Russia; Skolkovo Inst Sci & Technol, Artificial Intelligence Res Inst, Moscow, Russia|Scalability issue plays a crucial role in productionizing modern recommender systems. Even lightweight architectures may suffer from high computational overload due to intermediate calculations, limiting their practicality in real-world applications. Specifically, applying full Cross-Entropy (CE) loss often yields state-of-the-art performance in terms of recommendations quality. Still, it suffers from excessive GPU memory utilization when dealing with large item catalogs. This paper introduces a novel Scalable Cross-Entropy (SCE) loss function in the sequential learning setup. It approximates the CE loss for datasets with large-size catalogs, enhancing both time efficiency and memory usage without compromising recommendations quality. Unlike traditional negative sampling methods, our approach utilizes a selective GPU-efficient computation strategy, focusing on the most informative elements of the catalog, particularly those most likely to be false positives. This is achieved by approximating the softmax distribution over a subset of the model outputs through the maximum inner product search. Experimental results on multiple datasets demonstrate the effectiveness of SCE in reducing peak memory usage by a factor of up to 100 compared to the alternatives, retaining or even exceeding their metrics values. The proposed approach also opens new perspectives for large-scale developments in different domains, such as large language models.|可扩展性问题在现代推荐系统的实际应用中起着至关重要的作用。即使是轻量级的架构，也可能由于中间计算过程而遭受高计算负载的困扰，从而限制了其在实际应用中的实用性。具体而言，使用完整的交叉熵（Cross-Entropy, CE）损失函数通常在推荐质量方面能够达到最先进的性能，但在处理大规模商品目录时，它会导致过高的GPU内存占用。本文在序列学习框架下引入了一种新颖的可扩展交叉熵（Scalable Cross-Entropy, SCE）损失函数。它能够在大规模商品目录的数据集上近似CE损失，在不影响推荐质量的前提下，显著提升时间效率和内存使用效率。与传统的负采样方法不同，我们的方法采用了一种选择性的GPU高效计算策略，专注于商品目录中最具信息量的元素，尤其是那些最有可能成为假阳性的元素。这是通过最大内积搜索（Maximum Inner Product Search）对模型输出的子集进行softmax分布的近似来实现的。在多个数据集上的实验结果表明，与替代方法相比，SCE能够将峰值内存使用量减少高达100倍，同时保持甚至超越其性能指标。所提出的方法还为不同领域的大规模开发（如大语言模型）开辟了新的前景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Cross-Entropy+Loss+for+Sequential+Recommendations+with+Large+Item+Catalogs)|0|
|[Transformers Meet ACT-R: Repeat-Aware and Sequential Listening Session Recommendation](https://doi.org/10.1145/3640457.3688139)|VietAnh Tran, Guillaume SalhaGalvan, Bruno Sguerra, Romain Hennequin|Deezer Res, Paris, France|Music streaming services often leverage sequential recommender systems to predict the best music to showcase to users based on past sequences of listening sessions. Nonetheless, most sequential recommendation methods ignore or insufficiently account for repetitive behaviors. This is a crucial limitation for music recommendation, as repeatedly listening to the same song over time is a common phenomenon that can even change the way users perceive this song. In this paper, we introduce PISA (Psychology-Informed Session embedding using ACT-R), a session-level sequential recommender system that overcomes this limitation. PISA employs a Transformer architecture learning embedding representations of listening sessions and users using attention mechanisms inspired by Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics. This approach enables us to capture dynamic and repetitive patterns from user behaviors, allowing us to effectively predict the songs they will listen to in subsequent sessions, whether they are repeated or new ones. We demonstrate the empirical relevance of PISA using both publicly available listening data from Last.fm and proprietary data from Deezer, a global music streaming service, confirming the critical importance of repetition modeling for sequential listening session recommendation. Along with this paper, we publicly release our proprietary dataset to foster future research in this field, as well as the source code of PISA to facilitate its future use.|音乐流媒体服务通常利用序列推荐系统，根据用户过去的听歌序列来预测最适合展示给用户的音乐。然而，大多数序列推荐方法忽视或未能充分考虑到重复行为。这对音乐推荐来说是一个关键的限制，因为随着时间的推移，重复听同一首歌是一种常见现象，甚至可能改变用户对这首歌的感知。本文中，我们提出了PISA（基于ACT-R的心理学启发的会话嵌入），这是一种会话级别的序列推荐系统，克服了这一限制。PISA采用Transformer架构，利用受安德森的ACT-R（自适应控制思维-理性）启发的注意力机制，学习听歌会话和用户的嵌入表示。ACT-R是一种模拟人类信息访问和记忆动态的认知架构。这种方法使我们能够捕捉用户行为中的动态和重复模式，从而有效预测他们在后续会话中将要听的歌曲，无论是重复的还是新的。我们使用Last.fm的公开听歌数据和全球音乐流媒体服务Deezer的专有数据，实证了PISA的相关性，证实了重复建模对于序列听歌会话推荐的重要性。随本文一起，我们公开了我们的专有数据集，以促进该领域的未来研究，并发布了PISA的源代码，以方便其未来的使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transformers+Meet+ACT-R:+Repeat-Aware+and+Sequential+Listening+Session+Recommendation)|0|
|[Embedding Optimization for Training Large-scale Deep Learning Recommendation Systems with EMBark](https://doi.org/10.1145/3640457.3688111)|Shijie Liu, Nan Zheng, Hui Kang, Xavier Simmons, Junjie Zhang, Matthias Langer, Wenjing Zhu, Minseok Lee, Zehuan Wang|NVIDIA DevTech, Shanghai, Peoples R China; NVIDIA DevTech, Beijing, Peoples R China; NVIDIA, Shanghai, Peoples R China; NVIDIA DevTech, Santa Clara, CA USA|Training large-scale deep learning recommendation models (DL-RMs) with embedding tables stretching across multiple GPUs in a cluster presents a unique challenge, demanding the efficient scaling of embedding operations that require substantial memory and network bandwidth within a hierarchical network of GPUs. To tackle this bottleneck, we introduce EMBark-a comprehensive solution aimed at enhancing embedding performance and overall DLRM training throughput at scale. EMBark empowers users to create and customize sharding strategies, and features a highly-automated sharding planner, to accelerate diverse model architectures on different cluster configurations. EMBark groups embedding tables, considering their preferred communication compression method to reduce communication overheads effectively. It embraces efficient data-parallel category distribution, combined with topology-aware hierarchical communication, and pipelining support to maximize the DLRM training throughput. Across four representative DLRM variants (DLRM-DCNv2, T180, T200, and T510), EMBark achieves an average end-to-end training throughput speedup of 1.5x and up to 1.77x over traditional table-row-wise sharding approaches.|在集群中跨多个GPU训练具有嵌入表的大规模深度学习推荐模型（DL-RMs）提出了一个独特的挑战，这要求在GPU的层次网络中高效扩展嵌入操作，这些操作需要大量的内存和网络带宽。为了解决这一瓶颈，我们引入了EMBark——一个旨在提高嵌入性能和大规模DLRM训练吞吐量的综合解决方案。EMBark使用户能够创建和定制分片策略，并配备了一个高度自动化的分片规划器，以加速不同集群配置上的多种模型架构。EMBark根据嵌入表的首选通信压缩方法对其进行分组，以有效减少通信开销。它采用了高效的数据并行类别分布，结合了拓扑感知的层次通信和流水线支持，以最大化DLRM训练吞吐量。在四种代表性的DLRM变体（DLRM-DCNv2、T180、T200和T510）中，EMBark相比传统的表行分片方法，平均端到端训练吞吐量提升了1.5倍，最高可达1.77倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+Optimization+for+Training+Large-scale+Deep+Learning+Recommendation+Systems+with+EMBark)|0|
|[Multi-Behavioral Sequential Recommendation](https://doi.org/10.1145/3640457.3688166)|Shereen Elsayed, Ahmed Rashed, Lars SchmidtThieme|Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; South China Univ Technol, Sch Comp Sci & Technol, Guangzhou 510641, Peoples R China|Modeling time-evolving preferences of users with their sequential item interactions, has attracted increasing attention in many online applications. Hence, sequential recommender systems have been developed to learn the dynamic user interests from the historical interactions for suggesting items. However, the interaction pattern encoding functions in most existing sequential recommender systems have focused on single type of user-item interactions. In many real-life online platforms, user-item interactive behaviors are often multi-typed (e.g., click, add-to-favorite, purchase) with complex cross-type behavior inter-dependencies. Learning from informative representations of users and items based on their multi-typed interaction data, is of great importance to accurately characterize the time-evolving user preference. In this work, we tackle the dynamic user-item relation learning with the awareness of multi-behavior interactive patterns. Towards this end, we propose a new Temporal Graph Transformer (TGT) recommendation framework to jointly capture dynamic short-term and long-range user-item interactive patterns, by exploring the evolving correlations across different types of behaviors. The new TGT method endows the sequential recommendation architecture to distill dedicated knowledge for type-specific behavior relational context and the implicit behavior dependencies. Experiments on the real-world datasets indicate that our method TGT consistently outperforms various state-of-the-art recommendation methods. Our model implementation codes are available at https://github.com/akaxlh/TGT.|随着用户与项目序列交互的时间演化偏好建模在众多在线应用中的重要性日益增加，序列推荐系统应运而生，旨在从历史交互中学习动态用户兴趣以推荐项目。然而，现有的大多数序列推荐系统中的交互模式编码功能主要集中在单一类型的用户-项目交互上。在许多现实生活的在线平台中，用户-项目的交互行为往往是多类型的（例如，点击、收藏、购买），并且具有复杂的跨类型行为相互依赖性。基于多类型交互数据学习用户和项目的信息表示，对于准确刻画时间演化的用户偏好至关重要。在本研究中，我们致力于解决具有多行为交互模式意识的动态用户-项目关系学习问题。为此，我们提出了一种新的时序图变换器（Temporal Graph Transformer, TGT）推荐框架，通过探索不同类型行为之间的演化相关性，共同捕捉动态的短期和长期用户-项目交互模式。新的TGT方法赋予了序列推荐架构提取特定类型行为关系上下文和隐式行为依赖性的专用知识的能力。在真实世界数据集上的实验表明，我们的TGT方法在各种最先进的推荐方法中始终表现出色。我们的模型实现代码可在https://github.com/akaxlh/TGT获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavioral+Sequential+Recommendation)|0|
|[Efficient Inference of Sub-Item Id-based Sequential Recommendation Models with Millions of Items](https://doi.org/10.1145/3640457.3688168)|Aleksandr Vladimirovich Petrov, Craig Macdonald, Nicola Tonellotto|Univ Glasgow, Glasgow, Lanark, Scotland; Univ Pisa, Pisa, Italy|Transformer-based recommender systems, such as BERT4Rec or SASRec, achieve state-of-the-art results in sequential recommendation. However, it is challenging to use these models in production environments with catalogues of millions of items: scaling Transformers beyond a few thousand items is problematic for several reasons, including high model memory consumption and slow inference. In this respect, RecJPQ is a state-of-the-art method of reducing the models' memory consumption; RecJPQ compresses item catalogues by decomposing item IDs into a small number of shared sub-item IDs. Despite reporting the reduction of memory consumption by a factor of up to 50x, the original RecJPQ paper did not report inference efficiency improvements over the baseline Transformer-based models. Upon analysing RecJPQ's scoring algorithm, we find that its efficiency is limited by its use of score accumulators for each item, which prevents parallelisation. In contrast, LightRec (a non-sequential method that uses a similar idea of sub-ids) reported large inference efficiency improvements using an algorithm we call PQTopK. We show that it is also possible to improve RecJPQ-based models' inference efficiency using the PQTopK algorithm. In particular, we speed up RecJPQ-enhanced SASRec by a factor of 4.5x compared to the original SASRec's inference method and by the factor of 1.56x compared to the method implemented in RecJPQ code on a large-scale Gowalla dataset with more than million items. Further, using simulated data, we show that PQTopK remains efficient with catalogues of up to tens of millions of items, removing one of the last obstacles to using Transformer-based models in production environments with large catalogues.|基于Transformer的推荐系统，如BERT4Rec或SASRec，在序列推荐中取得了最先进的结果。然而，在拥有数百万项物品的生产环境中使用这些模型具有挑战性：将Transformer扩展到超过几千项物品存在多个问题，包括高模型内存消耗和推理速度慢。在这方面，RecJPQ是一种减少模型内存消耗的最先进方法；RecJPQ通过将物品ID分解为少量共享的子物品ID来压缩物品目录。尽管RecJPQ论文报告了内存消耗减少高达50倍，但原始RecJPQ论文并未报告相对于基线Transformer模型的推理效率提升。通过分析RecJPQ的评分算法，我们发现其效率受到每个物品使用评分累加器的限制，这阻碍了并行化。相比之下，LightRec（一种使用类似子ID思想的非序列方法）使用我们称为PQTopK的算法报告了大幅的推理效率提升。我们展示了使用PQTopK算法也可以提高基于RecJPQ模型的推理效率。具体而言，我们在包含超过百万项物品的大规模Gowalla数据集上，将RecJPQ增强的SASRec的推理速度比原始SASRec的推理方法提高了4.5倍，比RecJPQ代码中实现的方法提高了1.56倍。此外，使用模拟数据，我们展示了PQTopK在包含多达数千万项物品的目录中仍然高效，消除了在大型目录生产环境中使用基于Transformer模型的最后障碍之一。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Inference+of+Sub-Item+Id-based+Sequential+Recommendation+Models+with+Millions+of+Items)|0|
|[Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations](https://doi.org/10.1145/3640457.3688190)|Anima Singh, Trung Vu, Nikhil Mehta, Raghunandan H. Keshavan, Maheswaran Sathiamoorthy, Yilin Zheng, Lichan Hong, Lukasz Heldt, Li Wei, Devansh Tandon, Ed H. Chi, Xinyang Yi|Google DeepMind, Mountain View, CA 94043 USA; Google, Mountain View, CA 94043 USA|Randomly-hashed item ids are used ubiquitously in recommendation models. However, the learned representations from random hashing prevents generalization across similar items, causing problems of learning unseen and long-tail items, especially when item corpus is large, power-law distributed, and evolving dynamically. In this paper, we propose using content-derived features as a replacement for random ids. We show that simply replacing ID features with content-based embeddings can cause a drop in quality due to reduced memorization capability. To strike a good balance of memorization and generalization, we propose to use Semantic IDs [15], a compact and discrete item representation, as a replacement for random item ids. Semantic IDs are learned from frozen content embeddings using RQ-VAE and thus can capture the hierarchy of concepts in items. Similar to content embeddings, the compactness of Semantic IDs poses a problem of adaption in recommendation models. We propose novel methods for adapting Semantic IDs in industry-scale ranking models, through hashing sub-pieces of of the Semantic-ID sequences. In particular, we find that the SentencePiece model [10] that is commonly used in LLM tokenization outperforms manually crafted pieces such as N-grams. To the end, we evaluate our approaches in a real-world ranking model for YouTube recommendations. Our experiments demonstrate that Semantic IDs can replace the direct use of video IDs by improving the generalization ability on new and long-tail item slices without sacrificing overall model quality.|随机哈希的物品ID在推荐模型中无处不在。然而，从随机哈希中学习到的表示阻碍了相似物品之间的泛化，导致学习未见和长尾物品时出现问题，特别是在物品库庞大、服从幂律分布且动态变化的情况下。本文提出使用内容特征替代随机ID。我们发现，简单地用基于内容的嵌入替代ID特征可能会因记忆能力的降低而导致质量下降。为了在记忆和泛化之间取得良好平衡，我们提出使用语义ID [15] 作为随机物品ID的替代方案。语义ID是通过RQ-VAE从冻结的内容嵌入中学习的，因此能够捕捉物品中的概念层次结构。与内容嵌入类似，语义ID的紧凑性在推荐模型中的适应性方面带来了挑战。我们提出了在工业级排序模型中适应语义ID的新方法，通过对语义ID序列的子片段进行哈希处理来实现。特别是，我们发现常用于大语言模型（LLM）分词中的SentencePiece模型 [10] 在性能上优于手工设计的片段（如N-gram）。最终，我们在YouTube推荐的真实排序模型中评估了我们的方法。实验结果表明，语义ID可以通过提高对新物品和长尾物品的泛化能力来替代直接使用视频ID，而不会牺牲整体模型质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Better+Generalization+with+Semantic+IDs:+A+Case+Study+in+Ranking+for+Recommendations)|0|
|[User Knowledge Prompt for Sequential Recommendation](https://doi.org/10.1145/3640457.3691714)|Yuuki Tachioka|Denso IT Lab, Minato Ku, Tokyo, Japan|The large language model (LLM) based recommendation system is effective for sequential recommendation, because general knowledge of popular items is included in the LLM. To add domain knowledge of items, the conventional method uses a knowledge prompt obtained from the item knowledge graphs and has achieved SOTA performance. However, for personalized recommendation, it is necessary to consider user knowledge, which the conventional method does not fully consider because user knowledge is not included in the item knowledge graphs; thus, we propose a user knowledge prompt, which converts a user knowledge graph into a prompt using the relationship template. The existing prompt denoising framework is extended to prevent hallucination caused by undesirable interactions between knowledge graph prompts. We propose user knowledge prompts of user traits and user preferences and associate relevant items. Experiments on three types of dataset (movie, music, and book) show the significant and consistent improvement of our proposed user knowledge prompt.|基于大规模语言模型（LLM）的推荐系统在序列推荐中表现出色，因为LLM包含了流行项目的通用知识。为了增加项目的领域知识，传统方法使用从项目知识图谱中获取的知识提示（knowledge prompt），并取得了最先进的性能。然而，对于个性化推荐，必须考虑用户知识，而传统方法并未充分考虑这一点，因为用户知识并未包含在项目知识图谱中。因此，我们提出了一种用户知识提示（user knowledge prompt），通过关系模板将用户知识图谱转换为提示。现有的提示去噪框架被扩展，以防止因知识图谱提示之间的不良交互而产生的幻觉。我们提出了用户特征和用户偏好的用户知识提示，并将其与相关项目关联。在三种类型的数据集（电影、音乐和书籍）上进行的实验表明，我们提出的用户知识提示显著且一致地提升了推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Knowledge+Prompt+for+Sequential+Recommendation)|0|
|[Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets](https://doi.org/10.1145/3640457.3691718)|Lukas Wegmeth, Tobias Vente, Joeran Beel|Univ Siegen, Intelligent Syst Grp, Siegen, Germany|The recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets is under-explored. Traditional approaches in recommender systems algorithm selection focus predominantly on rating prediction on explicit feedback datasets, leaving a research gap for ranking prediction on implicit feedback datasets. Algorithm selection is a critical challenge for nearly every practitioner in recommender systems. In this work, we take the first steps toward addressing this research gap. We evaluate the NDCG@10 of 24 recommender systems algorithms, each with two hyperparameter configurations, on 72 recommender systems datasets. We train four optimized machine-learning meta-models and one automated machine-learning meta-model with three different settings on the resulting meta-dataset. Our results show that the predictions of all tested meta-models exhibit a median Spearman correlation ranging from 0.857 to 0.918 with the ground truth. We show that the median Spearman correlation between meta-model predictions and the ground truth increases by an average of 0.124 when the meta-model is optimized to predict the ranking of algorithms instead of their performance. Furthermore, in terms of predicting the best algorithm for an unknown dataset, we demonstrate that the best optimized traditional meta-model, e.g., XGBoost, achieves a recall of 48.6%, outperforming the best tested automated machine learning meta-model, e.g., AutoGluon, which achieves a recall of 47.2%.|在隐式反馈数据集上进行排序预测的推荐系统算法选择问题尚未得到充分探索。传统的推荐系统算法选择方法主要集中在显式反馈数据集上的评分预测，而在隐式反馈数据集上的排序预测方面存在研究空白。对于几乎每一个推荐系统的从业者来说，算法选择都是一个关键的挑战。在本研究中，我们迈出了填补这一研究空白的第一步。我们在72个推荐系统数据集上评估了24种推荐系统算法的NDCG@10指标，每种算法有两种超参数配置。我们在生成的元数据集上训练了四个优化的机器学习元模型和一个自动化机器学习元模型，并采用了三种不同的设置。我们的结果表明，所有测试的元模型的预测结果与真实值的中位数斯皮尔曼相关系数在0.857到0.918之间。我们发现，当元模型被优化为预测算法的排序而不是其性能时，元模型预测与真实值之间的中位数斯皮尔曼相关系数平均增加了0.124。此外，在预测未知数据集的最佳算法方面，我们证明了最佳优化的传统元模型（如XGBoost）的召回率为48.6%，优于测试的最佳自动化机器学习元模型（如AutoGluon），后者的召回率为47.2%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommender+Systems+Algorithm+Selection+for+Ranking+Prediction+on+Implicit+Feedback+Datasets)|0|
|[Personal Values and Community-Centric Environmental Recommender Systems: Enhancing Sustainability Through User Engagement](https://doi.org/10.1145/3640457.3688018)|Bianca Maria Deconcini|Univ Turin, Turin, Italy|The concept of sustainability has become a central focus across multiple sectors, driven by the urgent need to address climate change and protect the environment. Technological advancements and capabilities, together with the emergence of new ecological issues [25], are leading to growing awareness and influencing shifts in multiple areas such as energy, transportation, and waste management. Within this context, the roles of recommender systems represent a promising solution, since people need guidance and occasionally a gentle push to translate their intentions into actions or to bring goals to life [9]. However, existing literature reveals a fragmented landscape, with solutions often addressing specific aspects or recommendation contribution in isolation. Many sustainability interventions focus solely on providing consumption data and environmental insights, while others emphasize learning and behavior change strategies. My doctoral project aims to address this gap by leveraging various approaches to recommender systems and applying them in sustainability contexts, with the goal to build a holistic system that maximizes the contributions of these diverse methods, also integrating user-centric and value-driven perspectives. This research project delves into two distinct facets: energy sustainability and sustainable mobility. The first case centers on enhancing energy efficiency within energy communities through personalized recommendations and engagement strategies. The second facet focuses on reshaping user commuting patterns towards sustainable alternatives, by recommending suitable and more sustainable modes of transportation, such as cycling, carpooling, and public transportation. Both cases share the same objective: align user behaviors with sustainability goals, thereby reducing individual environmental impact and enhancing the sense of belonging to a community, whether this is confined to a group of individuals or pertains to society at large. An innovative comprehensive recommendation system approach is highly beneficial since it can take advantage of all the existing contributions combined in a framework that makes at the same time different types of recommendations: explainable, educative, behavioral and social-aware, addressing the complexities of this multifaceted domain.|可持续发展概念已成为多个领域的核心关注点，这主要是由于应对气候变化和保护环境的迫切需求所推动的。技术进步和能力提升，以及新出现的生态问题[25]，正在促使人们对能源、交通和废物管理等多个领域的意识不断增强，并影响着这些领域的转变。在此背景下，推荐系统的作用代表了一种有前景的解决方案，因为人们需要指导，有时还需要一个温和的推动力，将他们的意图转化为行动或将目标变为现实[9]。然而，现有文献揭示了一个零散的格局，解决方案通常只针对特定方面或孤立的推荐贡献。许多可持续发展干预措施仅专注于提供消费数据和环境洞察，而另一些则强调学习和行为改变策略。我的博士项目旨在通过利用推荐系统的各种方法并将其应用于可持续发展背景中，来解决这一差距，目标是构建一个整体系统，最大限度地发挥这些多样化方法的贡献，同时整合以用户为中心和价值驱动的视角。

该研究项目深入探讨了两个不同的方面：能源可持续性和可持续交通。第一个案例侧重于通过个性化推荐和参与策略提高能源社区内的能源效率。第二个方面则侧重于通过推荐合适且更可持续的交通方式（如骑行、拼车和公共交通）来重塑用户的通勤模式，使其转向可持续的替代方案。这两个案例都共享同一个目标：将用户行为与可持续发展目标保持一致，从而减少个人对环境的影响，并增强对社区的归属感，无论这个社区是局限于一个群体还是涉及整个社会。一个创新的综合推荐系统方法极为有益，因为它可以充分利用现有贡献，并将其结合在一个框架中，同时提供不同类型的推荐：可解释的、教育的、行为的和社会意识的，以应对这一多面领域的复杂性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personal+Values+and+Community-Centric+Environmental+Recommender+Systems:+Enhancing+Sustainability+Through+User+Engagement)|0|
|[Towards Empathetic Conversational Recommender Systems](https://doi.org/10.1145/3640457.3688133)|Xiaoyu Zhang, Ruobing Xie, Yougang Lyu, Xin Xin, Pengjie Ren, Mingfei Liang, Bo Zhang, Zhanhui Kang, Maarten de Rijke, Zhaochun Ren|Leiden Univ, Leiden, Netherlands; Univ Amsterdam, Amsterdam, Netherlands; Tencent, Shenzhen, Guangdong, Peoples R China; Shandong Univ, Jinan, Shandong, Peoples R China|Conversational recommender systems (CRSs) are able to elicit user preferences through multi-turn dialogues. They typically incorporate external knowledge and pre-trained language models to capture the dialogue context. Most CRS approaches, trained on benchmark datasets, assume that the standard items and responses in these benchmarks are optimal. However, they overlook that users may express negative emotions with the standard items and may not feel emotionally engaged by the standard responses. This issue leads to a tendency to replicate the logic of recommenders in the dataset instead of aligning with user needs. To remedy this misalignment, we introduce empathy within a CRS. With empathy we refer to a system's ability to capture and express emotions. We propose an empathetic conversational recommender (ECR) framework. ECR contains two main modules: emotion-aware item recommendation and emotion-aligned response generation. Specifically, we employ user emotions to refine user preference modeling for accurate recommendations. To generate human-like emotional responses, ECR applies retrieval-augmented prompts to fine-tune a pre-trained language model aligning with emotions and mitigating hallucination. To address the challenge of insufficient supervision labels, we enlarge our empathetic data using emotion labels annotated by large language models and emotional reviews collected from external resources. We propose novel evaluation metrics to capture user satisfaction in real-world CRS scenarios. Our experiments on the ReDial dataset validate the efficacy of our framework in enhancing recommendation accuracy and improving user satisfaction.|对话推荐系统（CRS）能够通过多轮对话来获取用户偏好。这类系统通常结合外部知识和预训练语言模型来捕捉对话上下文。大多数基于基准数据集训练的CRS方法假设这些基准中的标准项目和响应是最优的。然而，它们忽视了用户可能对这些标准项目表达负面情绪，并且可能不会因标准响应而感到情感上的投入。这一问题导致系统倾向于复制数据集中推荐逻辑，而不是与用户需求保持一致。为了解决这种不一致性，我们在CRS中引入了共情能力。共情指的是系统捕捉和表达情感的能力。我们提出了一个共情对话推荐（ECR）框架。ECR包含两个主要模块：情感感知的项目推荐和情感对齐的响应生成。具体来说，我们利用用户情绪来优化用户偏好建模，以实现更准确的推荐。为了生成类似人类的情感响应，ECR采用检索增强的提示来微调预训练语言模型，使其与情感对齐并减少幻觉生成。为了解决监督标签不足的挑战，我们通过使用大型语言模型标注的情感标签和从外部资源收集的情感评论来扩展我们的共情数据。我们提出了新的评估指标，以捕捉实际CRS场景中的用户满意度。我们在ReDial数据集上的实验验证了我们框架在提高推荐准确性和提升用户满意度方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Empathetic+Conversational+Recommender+Systems)|0|
|[The Elephant in the Room: Rethinking the Usage of Pre-trained Language Model in Sequential Recommendation](https://doi.org/10.1145/3640457.3688107)|Zekai Qu, Ruobing Xie, Chaojun Xiao, Zhanhui Kang, Xingwu Sun|China Univ Geosci Beijing, Beijing, Peoples R China; Tencent Inc, Beijing, Peoples R China; Tsinghua Univ, Beijing, Peoples R China|Sequential recommendation (SR) has seen significant advancements with the help of Pre-trained Language Models (PLMs). Some PLM-based SR models directly use PLM to encode user historical behavior's text sequences to learn user representations, while there is seldom an in-depth exploration of the capability and suitability of PLM in behavior sequence modeling. In this work, we first conduct extensive model analyses between PLMs and PLM-based SR models, discovering great underutilization and parameter redundancy of PLMs in behavior sequence modeling. Inspired by this, we explore different lightweight usages of PLMs in SR, aiming to maximally stimulate the ability of PLMs for SR while satisfying the efficiency and usability demands of practical systems. We discover that adopting behavior-tuned PLMs for item initializations of conventional ID-based SR models is the most economical framework of PLM-based SR, which would not bring in any additional inference cost but could achieve a dramatic performance boost compared with the original version. Extensive experiments on five datasets show that our simple and universal framework leads to significant improvement compared to classical SR and SOTA PLM-based SR models without additional inference costs. Our code can be found in https://github.com/777pomingzi/Rethinking-PLM-in-RS.|在预训练语言模型（PLMs）的帮助下，序列推荐（SR）取得了显著的进展。一些基于PLM的SR模型直接使用PLM对用户历史行为的文本序列进行编码，以学习用户表示，然而对PLM在行为序列建模中的能力和适用性却鲜有深入探索。在本工作中，我们首先对PLMs和基于PLM的SR模型进行了广泛的模型分析，发现PLMs在行为序列建模中存在严重的未充分利用和参数冗余问题。受此启发，我们探索了PLMs在SR中的不同轻量级使用方法，旨在最大程度地激发PLMs在SR中的能力，同时满足实际系统对效率和可用性的需求。我们发现，将经过行为调优的PLMs用于传统基于ID的SR模型的物品初始化，是最经济的基于PLM的SR框架，它不会带来任何额外的推理成本，但相比原始版本可以实现显著的性能提升。在五个数据集上的大量实验表明，我们的简单且通用的框架相比经典的SR和最先进的基于PLM的SR模型，在不增加推理成本的情况下带来了显著的改进。我们的代码可以在https://github.com/777pomingzi/Rethinking-PLM-in-RS找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Elephant+in+the+Room:+Rethinking+the+Usage+of+Pre-trained+Language+Model+in+Sequential+Recommendation)|0|
|[Fair Reciprocal Recommendation in Matching Markets](https://doi.org/10.1145/3640457.3688130)|Yoji Tomita, Tomohiko Yokoyama||Recommender systems play an increasingly crucial role in shaping people's opportunities, particularly in online dating platforms. It is essential from the user's perspective to increase the probability of matching with a suitable partner while ensuring an appropriate level of fairness in the matching opportunities. We investigate reciprocal recommendation in two-sided matching markets between agents divided into two sides. In our model, a match is considered successful only when both individuals express interest in each other. Additionally, we assume that agents prefer to appear prominently in the recommendation lists presented to those on the other side. We define each agent's opportunity to be recommended and introduce its fairness criterion, envy-freeness, from the perspective of fair division theory. The recommendations that approximately maximize the expected number of matches, empirically obtained by heuristic algorithms, are likely to result in significant unfairness of opportunity. Therefore, there can be a trade-off between maximizing the expected matches and ensuring fairness of opportunity. To address this challenge, we propose a method to find a policy that is close to being envy-free by leveraging the Nash social welfare function. Experiments on synthetic and real-world datasets demonstrate the effectiveness of our approach in achieving both relatively high expected matches and fairness for opportunities of both sides in reciprocal recommender systems.|推荐系统在塑造人们的机会方面发挥着越来越重要的作用，尤其是在在线约会平台中。从用户的角度来看，提高与合适伴侣匹配的概率，同时确保匹配机会的公平性至关重要。我们研究了在双边匹配市场中，将代理分为两方的互惠推荐问题。在我们的模型中，只有当双方都表示对彼此感兴趣时，才认为匹配成功。此外，我们假设代理更倾向于在向对方展示的推荐列表中占据显眼位置。我们从公平分配理论的角度，定义了每个代理的推荐机会，并引入了其公平性标准——无嫉妒性。通过启发式算法经验获得的、近似最大化预期匹配数量的推荐，可能会导致机会的显著不公平。因此，在最大化预期匹配和确保机会公平性之间可能存在权衡。为了解决这一挑战，我们提出了一种利用纳什社会福利函数来找到接近无嫉妒性策略的方法。在合成数据集和真实世界数据集上的实验表明，我们的方法在互惠推荐系统中能够有效实现相对较高的预期匹配和双方的公平机会。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Reciprocal+Recommendation+in+Matching+Markets)|0|
|[CALRec: Contrastive Alignment of Generative LLMs for Sequential Recommendation](https://doi.org/10.1145/3640457.3688121)|Yaoyiran Li, Xiang Zhai, Moustafa Alzantot, Keyi Yu, Ivan Vulic, Anna Korhonen, Mohamed Hammad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CALRec:+Contrastive+Alignment+of+Generative+LLMs+for+Sequential+Recommendation)|0|
|[Scaling Law of Large Sequential Recommendation Models](https://doi.org/10.1145/3640457.3688129)|Gaowei Zhang, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Law+of+Large+Sequential+Recommendation+Models)|0|
|[A Pre-trained Zero-shot Sequential Recommendation Framework via Popularity Dynamics](https://doi.org/10.1145/3640457.3688145)|Junting Wang, Praneet Rathi, Hari Sundaram||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Pre-trained+Zero-shot+Sequential+Recommendation+Framework+via+Popularity+Dynamics)|0|
|[Repeated Padding for Sequential Recommendation](https://doi.org/10.1145/3640457.3688110)|Yizhou Dang, Yuting Liu, Enneng Yang, Guibing Guo, Linying Jiang, Xingwei Wang, Jianzhe Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Repeated+Padding+for+Sequential+Recommendation)|0|
|[From Clicks to Carbon: The Environmental Toll of Recommender Systems](https://doi.org/10.1145/3640457.3688074)|Tobias Vente, Lukas Wegmeth, Alan Said, Joeran Beel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Clicks+to+Carbon:+The+Environmental+Toll+of+Recommender+Systems)|0|
|[DNS-Rec: Data-aware Neural Architecture Search for Recommender Systems](https://doi.org/10.1145/3640457.3688117)|Sheng Zhang, Maolin Wang, Xiangyu Zhao, Ruocheng Guo, Yao Zhao, Chenyi Zhuang, Jinjie Gu, Zijian Zhang, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DNS-Rec:+Data-aware+Neural+Architecture+Search+for+Recommender+Systems)|0|
|[FedLoCA: Low-Rank Coordinated Adaptation with Knowledge Decoupling for Federated Recommendations](https://doi.org/10.1145/3640457.3688112)|Yuchen Ding, Siqing Zhang, Boyu Fan, Wei Sun, Yong Liao, Peng Yuan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedLoCA:+Low-Rank+Coordinated+Adaptation+with+Knowledge+Decoupling+for+Federated+Recommendations)|0|
|[Multi-Objective Recommendation via Multivariate Policy Learning](https://doi.org/10.1145/3640457.3688132)|Olivier Jeunen, Jatin Mandav, Ivan Potapov, Nakul Agarwal, Sourabh Vaid, Wenzhe Shi, Aleksei Ustimenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Objective+Recommendation+via+Multivariate+Policy+Learning)|0|
|[AI-assisted Coding with Cody: Lessons from Context Retrieval and Evaluation for Code Recommendations](https://doi.org/10.1145/3640457.3688060)|Jan Hartman, Hitesh Sagtani, Julie Tibshirani, Rishabh Mehrotra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI-assisted+Coding+with+Cody:+Lessons+from+Context+Retrieval+and+Evaluation+for+Code+Recommendations)|0|
|[Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)](https://doi.org/10.1145/3640457.3688034)|Moumita Bhattacharya, Vito Ostuni, Sudarshan Lamkhede||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Modeling+of+Search+and+Recommendations+Via+an+Unified+Contextual+Recommender+(UniCoRn))|0|
|[Leveraging LLM generated labels to reduce bad matches in job recommendations](https://doi.org/10.1145/3640457.3688043)|Yingchi Pei, Yi Wei Pang, Warren Cai, Nilanjan Sengupta, Dheeraj Toshniwal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+LLM+generated+labels+to+reduce+bad+matches+in+job+recommendations)|0|
|[Toward 100TB Recommendation Models with Embedding Offloading](https://doi.org/10.1145/3640457.3688037)|Intaik Park, Ehsan Ardestani, Damian Reeves, Sarunya Pumma, Henry Tsang, Levy Zhao, Jian He, Joshua Deng, Dennis Van Der Staay, Yu Guo, Paul Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+100TB+Recommendation+Models+with+Embedding+Offloading)|0|
|[LLMs for User Interest Exploration in Large-scale Recommendation Systems](https://doi.org/10.1145/3640457.3688161)|Jianling Wang, Haokai Lu, Yifan Liu, He Ma, Yueqi Wang, Yang Gu, Shuzhou Zhang, Ningren Han, Shuchao Bi, Lexi Baugher, Ed H. Chi, Minmin Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLMs+for+User+Interest+Exploration+in+Large-scale+Recommendation+Systems)|0|
|[It's Not You, It's Me: The Impact of Choice Models and Ranking Strategies on Gender Imbalance in Music Recommendation](https://doi.org/10.1145/3640457.3688163)|Andres Ferraro, Michael D. Ekstrand, Christine Bauer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=It's+Not+You,+It's+Me:+The+Impact+of+Choice+Models+and+Ranking+Strategies+on+Gender+Imbalance+in+Music+Recommendation)|0|
|[Pay Attention to Attention for Sequential Recommendation](https://doi.org/10.1145/3640457.3688164)|Yuli Liu, Min Liu, Xiaojing Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pay+Attention+to+Attention+for+Sequential+Recommendation)|0|
|[GLAMOR: Graph-based LAnguage MOdel embedding for citation Recommendation](https://doi.org/10.1145/3640457.3688171)|Zafar Ali, Guilin Qi, Irfan Ullah, Adam A. Q. Mohammed, Pavlos Kefalas, Khan Muhammad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GLAMOR:+Graph-based+LAnguage+MOdel+embedding+for+citation+Recommendation)|0|
|[Self-Attentive Sequential Recommendations with Hyperbolic Representations](https://doi.org/10.1145/3640457.3688180)|Evgeny Frolov, Tatyana Matveeva, Leyla Mirvakhabova, Ivan V. Oseledets||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Attentive+Sequential+Recommendations+with+Hyperbolic+Representations)|0|
|[It's (not) all about that CTR: A Multi-Stakeholder Perspective on News Recommender Metrics](https://doi.org/10.1145/3640457.3688183)|Hanne Vandenbroucke, Annelien Smets||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=It's+(not)+all+about+that+CTR:+A+Multi-Stakeholder+Perspective+on+News+Recommender+Metrics)|0|
|[Recommending Personalised Targeted Training Adjustments for Marathon Runners](https://doi.org/10.1145/3640457.3688192)|Ciara Feely, Brian Caulfield, Aonghus Lawlor, Barry Smyth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommending+Personalised+Targeted+Training+Adjustments+for+Marathon+Runners)|0|
|[Recommending Healthy and Sustainable Meals exploiting Food Retrieval and Large Language Models](https://doi.org/10.1145/3640457.3688193)|Alessandro Petruzzelli, Cataldo Musto, Michele Ciro Di Carlo, Giovanni Tempesta, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommending+Healthy+and+Sustainable+Meals+exploiting+Food+Retrieval+and+Large+Language+Models)|0|
|[Does It Look Sequential? An Analysis of Datasets for Evaluation of Sequential Recommendations](https://doi.org/10.1145/3640457.3688195)|Anton Klenitskiy, Anna Volodkevich, Anton Pembek, Alexey Vasilev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Does+It+Look+Sequential?+An+Analysis+of+Datasets+for+Evaluation+of+Sequential+Recommendations)|0|
|[TLRec: A Transfer Learning Framework to Enhance Large Language Models for Sequential Recommendation Tasks](https://doi.org/10.1145/3640457.3691710)|Jiaye Lin, Shuang Peng, Zhong Zhang, Peilin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TLRec:+A+Transfer+Learning+Framework+to+Enhance+Large+Language+Models+for+Sequential+Recommendation+Tasks)|0|
|[Leveraging Monte Carlo Tree Search for Group Recommendation](https://doi.org/10.1145/3640457.3691713)|Antonela Tommasel, J. Andres DiazPace||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Monte+Carlo+Tree+Search+for+Group+Recommendation)|0|
|[Supporting Knowledge Workers through Personal Information Assistance with Context-aware Recommender Systems](https://doi.org/10.1145/3640457.3688010)|Mahta Bakhshizadeh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Supporting+Knowledge+Workers+through+Personal+Information+Assistance+with+Context-aware+Recommender+Systems)|0|
|[AI-based Human-Centered Recommender Systems: Empirical Experiments and Research Infrastructure](https://doi.org/10.1145/3640457.3688012)|Ruixuan Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI-based+Human-Centered+Recommender+Systems:+Empirical+Experiments+and+Research+Infrastructure)|0|
|[Learning Personalized Health Recommendations via Offline Reinforcement Learning](https://doi.org/10.1145/3640457.3688021)|Larry Donald Preuett||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Personalized+Health+Recommendations+via+Offline+Reinforcement+Learning)|0|
|[Towards Symbiotic Recommendations: Leveraging LLMs for Conversational Recommendation Systems](https://doi.org/10.1145/3640457.3688023)|Alessandro Petruzzelli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Symbiotic+Recommendations:+Leveraging+LLMs+for+Conversational+Recommendation+Systems)|0|
|[Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction](https://doi.org/10.1145/3640457.3688184)|Yi Wu, Daryl Chang, Jennifer She, Zhe Zhao, Li Wei, Lukasz Heldt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learned+Ranking+Function:+From+Short-term+Behavior+Predictions+to+Long-term+User+Satisfaction)|0|
|[Putting Popularity Bias Mitigation to the Test: A User-Centric Evaluation in Music Recommenders](https://doi.org/10.1145/3640457.3688102)|Robin Ungruh, Karlijn Dinnissen, Anja Volk, Maria Soledad Pera, Hanna Hauptmann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Putting+Popularity+Bias+Mitigation+to+the+Test:+A+User-Centric+Evaluation+in+Music+Recommenders)|0|
|[Discerning Canonical User Representation for Cross-Domain Recommendation](https://doi.org/10.1145/3640457.3688114)|Siqian Zhao, Sherry Sahebi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discerning+Canonical+User+Representation+for+Cross-Domain+Recommendation)|0|
|[Prompt Tuning for Item Cold-start Recommendation](https://doi.org/10.1145/3640457.3688126)|Yuezihan Jiang, Gaode Chen, Wenhan Zhang, Jingchi Wang, Yinjie Jiang, Qi Zhang, Jingjian Lin, Peng Jiang, Kaigui Bian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Tuning+for+Item+Cold-start+Recommendation)|0|
|[A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph](https://doi.org/10.1145/3640457.3688070)|Daniele Malitesta, Claudio Pomo, Vito Walter Anelli, Alberto Carlo Maria Mancino, Tommaso Di Noia, Eugenio Di Sciascio||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Novel+Evaluation+Perspective+on+GNNs-based+Recommender+Systems+through+the+Topology+of+the+User-Item+Graph)|0|
|[Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems](https://doi.org/10.1145/3640457.3688055)|Nikhil Khani, Li Wei, Aniruddh Nath, Shawn Andrews, Shuo Yang, Yang Liu, Pendo Abbo, Maciej Kula, Jarrod Kahn, Zhe Zhao, Lichan Hong, Ed H. Chi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+the+Gap:+Unpacking+the+Hidden+Challenges+in+Knowledge+Distillation+for+Online+Ranking+Systems)|0|
|[Self-Auxiliary Distillation for Sample Efficient Learning in Google-Scale Recommenders](https://doi.org/10.1145/3640457.3688041)|Yin Zhang, Ruoxi Wang, Xiang Li, Tiansheng Yao, Andrew Evdokimov, Jonathan Valverde, Yuan Gao, Jerry Zhang, Evan Ettinger, Ed H. Chi, Derek Zhiyuan Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Auxiliary+Distillation+for+Sample+Efficient+Learning+in+Google-Scale+Recommenders)|0|
|[MODEM: Decoupling User Behavior for Shared-Account Video Recommendations on Large Screen Devices](https://doi.org/10.1145/3640457.3688167)|Jiang Li, Zhen Zhang, Xiang Feng, Muyang Li, Yongqi Liu, Lantao Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MODEM:+Decoupling+User+Behavior+for+Shared-Account+Video+Recommendations+on+Large+Screen+Devices)|0|
|[beeFormer: Bridging the Gap Between Semantic and Interaction Similarity in Recommender Systems](https://doi.org/10.1145/3640457.3691707)|Vojtech Vancura, Pavel Kordík, Milan Straka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=beeFormer:+Bridging+the+Gap+Between+Semantic+and+Interaction+Similarity+in+Recommender+Systems)|0|
|[Enhancing Cross-Domain Recommender Systems with LLMs: Evaluating Bias and Beyond-Accuracy Measures](https://doi.org/10.1145/3640457.3688027)|Thomas Elmar Kolb||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Cross-Domain+Recommender+Systems+with+LLMs:+Evaluating+Bias+and+Beyond-Accuracy+Measures)|0|
|[The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems](https://doi.org/10.1145/3640457.3688158)|Guy Aridor, Duarte Gonçalves, Ruoyan Kong, Daniel Kluver, Joseph A. Konstan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+MovieLens+Beliefs+Dataset:+Collecting+Pre-Choice+Data+for+Online+Recommender+Systems)|0|
|[LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding](https://doi.org/10.1145/3640457.3688135)|Zhizhong Wan, Bin Yin, Junjie Xie, Fei Jiang, Xiang Li, Wei Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LARR:+Large+Language+Model+Aided+Real-time+Scene+Recommendation+with+Semantic+Understanding)|0|
|[Not All Videos Become Outdated: Short-Video Recommendation by Learning to Deconfound Release Interval Bias](https://doi.org/10.1145/3640457.3688113)|Lulu Dong, Guoxiu He, Aixin Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Videos+Become+Outdated:+Short-Video+Recommendation+by+Learning+to+Deconfound+Release+Interval+Bias)|0|
|[Do Recommender Systems Promote Local Music? A Reproducibility Study Using Music Streaming Data](https://doi.org/10.1145/3640457.3688065)|Kristina Matrosova, Lilian Marey, Guillaume SalhaGalvan, Thomas Louail, Olivier Bodini, Manuel Moussallam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+Recommender+Systems+Promote+Local+Music?+A+Reproducibility+Study+Using+Music+Streaming+Data)|0|
|[Improving Adversarial Robustness for Recommendation Model via Cross-Domain Distributional Adversarial Training](https://doi.org/10.1145/3640457.3688116)|Jingyu Chen, Lilin Zhang, Ning Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Adversarial+Robustness+for+Recommendation+Model+via+Cross-Domain+Distributional+Adversarial+Training)|0|
|[Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations](https://doi.org/10.1145/3640457.3688137)|Alessandro Petruzzelli, Cataldo Musto, Lucrezia Laraspata, Ivan Rinaldi, Marco de Gemmis, Pasquale Lops, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Instructing+and+Prompting+Large+Language+Models+for+Explainable+Cross-domain+Recommendations)|0|
|[Touch the Core: Exploring Task Dependence Among Hybrid Targets for Recommendation](https://doi.org/10.1145/3640457.3688101)|Xing Tang, Yang Qiao, Fuyuan Lyu, Dugang Liu, Xiuqiang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Touch+the+Core:+Exploring+Task+Dependence+Among+Hybrid+Targets+for+Recommendation)|0|
|[Scene-wise Adaptive Network for Dynamic Cold-start Scenes Optimization in CTR Prediction](https://doi.org/10.1145/3640457.3688115)|Wenhao Li, Jie Zhou, Chuan Luo, Chao Tang, Kun Zhang, Shixiong Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scene-wise+Adaptive+Network+for+Dynamic+Cold-start+Scenes+Optimization+in+CTR+Prediction)|0|
|[A Multi-modal Modeling Framework for Cold-start Short-video Recommendation](https://doi.org/10.1145/3640457.3688098)|Gaode Chen, Ruina Sun, Yuezihan Jiang, Jiangxia Cao, Qi Zhang, Jingjian Lin, Han Li, Kun Gai, Xinghua Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-modal+Modeling+Framework+for+Cold-start+Short-video+Recommendation)|0|
|[MARec: Metadata Alignment for cold-start Recommendation](https://doi.org/10.1145/3640457.3688125)|Julien Monteil, Volodymyr Vaskovych, Wentao Lu, Anirban Majumder, Anton van den Hengel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MARec:+Metadata+Alignment+for+cold-start+Recommendation)|0|
|[End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling](https://doi.org/10.1145/3640457.3688147)|Zexu Sun, Hao Yang, Dugang Liu, Yunpeng Weng, Xing Tang, Xiuqiang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Cost-Effective+Incentive+Recommendation+under+Budget+Constraint+with+Uplift+Modeling)|0|
|[AIE: Auction Information Enhanced Framework for CTR Prediction in Online Advertising](https://doi.org/10.1145/3640457.3688136)|Yang Yang, Bo Chen, Chenxu Zhu, Menghui Zhu, Xinyi Dai, Huifeng Guo, Muyu Zhang, Zhenhua Dong, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AIE:+Auction+Information+Enhanced+Framework+for+CTR+Prediction+in+Online+Advertising)|0|
|[Right Tool, Right Job: Recommendation for Repeat and Exploration Consumption in Food Delivery](https://doi.org/10.1145/3640457.3688119)|Jiayu Li, Aixin Sun, Weizhi Ma, Peijie Sun, Min Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Right+Tool,+Right+Job:+Recommendation+for+Repeat+and+Exploration+Consumption+in+Food+Delivery)|0|
|[Informfully - Research Platform for Reproducible User Studies](https://doi.org/10.1145/3640457.3688066)|Lucien Heitz, Julian Andrea Croci, Madhav Sachdeva, Abraham Bernstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Informfully+-+Research+Platform+for+Reproducible+User+Studies)|0|
|[RPAF: A Reinforcement Prediction-Allocation Framework for Cache Allocation in Large-Scale Recommender Systems](https://doi.org/10.1145/3640457.3688128)|Shuo Su, Xiaoshuang Chen, Yao Wang, Yulin Wu, Ziqiang Zhang, Kaiqiao Zhan, Ben Wang, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RPAF:+A+Reinforcement+Prediction-Allocation+Framework+for+Cache+Allocation+in+Large-Scale+Recommender+Systems)|0|
|[Analyzing User Preferences and Quality Improvement on Bing's WebPage Recommendation Experience with Large Language Models](https://doi.org/10.1145/3640457.3688062)|Jaidev Shah, Gang Luo, Jialin Liu, Amey Barapatre, Fan Wu, Chuck Wang, Hongzhi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+User+Preferences+and+Quality+Improvement+on+Bing's+WebPage+Recommendation+Experience+with+Large+Language+Models)|0|
|[Enhancing Performance and Scalability of Large-Scale Recommendation Systems with Jagged Flash Attention](https://doi.org/10.1145/3640457.3688040)|Rengan Xu, Junjie Yang, Yifan Xu, Hong Li, Xing Liu, Devashish Shankar, Haoci Zhang, Meng Liu, Boyang Li, Yuxi Hu, Mingwei Tang, Zehua Zhang, Tunhou Zhang, Dai Li, Sijia Chen, GianPaolo Musumeci, Jiaqi Zhai, Bill Zhu, Hong Yan, Srihari Reddy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Performance+and+Scalability+of+Large-Scale+Recommendation+Systems+with+Jagged+Flash+Attention)|0|
|[Enhancing Recommendation Quality of the SASRec Model by Mitigating Popularity Bias](https://doi.org/10.1145/3640457.3688044)|Venkata Harshit Koneru, Xenija Neufeld, Sebastian Loth, Andreas Grün||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Recommendation+Quality+of+the+SASRec+Model+by+Mitigating+Popularity+Bias)|0|
|[Taming the One-Epoch Phenomenon in Online Recommendation System by Two-stage Contrastive ID Pre-training](https://doi.org/10.1145/3640457.3688053)|YiPing Hsu, PoWei Wang, Chantat Eksombatchai, Jiajing Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Taming+the+One-Epoch+Phenomenon+in+Online+Recommendation+System+by+Two-stage+Contrastive+ID+Pre-training)|0|
|[Towards Understanding The Gaps of Offline And Online Evaluation Metrics: Impact of Series vs. Movie Recommendations](https://doi.org/10.1145/3640457.3688056)|Bora Edizel, Tim Sweetser, Ashok Chandrashekar, Kamilia Ahmadi, Puja Das||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Understanding+The+Gaps+of+Offline+And+Online+Evaluation+Metrics:+Impact+of+Series+vs.+Movie+Recommendations)|0|
|[Data Augmentation using Reverse Prompt for Cost-Efficient Cold-Start Recommendation](https://doi.org/10.1145/3640457.3688159)|Genki Kusano||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Augmentation+using+Reverse+Prompt+for+Cost-Efficient+Cold-Start+Recommendation)|0|
|[Positive-Sum Impact of Multistakeholder Recommender Systems for Urban Tourism Promotion and User Utility](https://doi.org/10.1145/3640457.3688173)|Pavel Merinov, Francesco Ricci||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Positive-Sum+Impact+of+Multistakeholder+Recommender+Systems+for+Urban+Tourism+Promotion+and+User+Utility)|0|
|[Calibrating the Predictions for Top-N Recommendations](https://doi.org/10.1145/3640457.3688177)|Masahiro Sato||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibrating+the+Predictions+for+Top-N+Recommendations)|0|
|[CoST: Contrastive Quantization based Semantic Tokenization for Generative Recommendation](https://doi.org/10.1145/3640457.3688178)|Jieming Zhu, Mengqun Jin, Qijiong Liu, Zexuan Qiu, Zhenhua Dong, Xiu Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoST:+Contrastive+Quantization+based+Semantic+Tokenization+for+Generative+Recommendation)|0|
|[Oh, Behave! Country Representation Dynamics Created by Feedback Loops in Music Recommender Systems](https://doi.org/10.1145/3640457.3688187)|Oleg Lesota, Jonas Geiger, Max Walder, Dominik Kowald, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Oh,+Behave!+Country+Representation+Dynamics+Created+by+Feedback+Loops+in+Music+Recommender+Systems)|0|
|[One-class recommendation systems with the hinge pairwise distance loss and orthogonal representations](https://doi.org/10.1145/3640457.3688189)|Ramin Raziperchikolaei, Youngjoo Chung||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-class+recommendation+systems+with+the+hinge+pairwise+distance+loss+and+orthogonal+representations)|0|
|[Is It Really Complementary? Revisiting Behavior-based Labels for Complementary Recommendation](https://doi.org/10.1145/3640457.3691705)|Kai Sugahara, Chihiro Yamasaki, Kazushi Okamoto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+It+Really+Complementary?+Revisiting+Behavior-based+Labels+for+Complementary+Recommendation)|0|
|[Exploratory Analysis of Recommending Urban Parks for Health-Promoting Activities](https://doi.org/10.1145/3640457.3691712)|Linus W. Dietz, Sanja Scepanovic, Ke Zhou, Daniele Quercia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploratory+Analysis+of+Recommending+Urban+Parks+for+Health-Promoting+Activities)|0|
|[Balancing Habit Repetition and New Activity Exploration: A Longitudinal Micro-Randomized Trial in Physical Activity Recommendations](https://doi.org/10.1145/3640457.3691715)|Ine Coppens, Toon De Pessemier, Luc Martens||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Habit+Repetition+and+New+Activity+Exploration:+A+Longitudinal+Micro-Randomized+Trial+in+Physical+Activity+Recommendations)|0|
|[Exploring Coresets for Efficient Training and Consistent Evaluation of Recommender Systems](https://doi.org/10.1145/3640457.3691716)|Zheng Ju, Honghui Du, Elias Z. Tragos, Neil Hurley, Aonghus Lawlor||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Coresets+for+Efficient+Training+and+Consistent+Evaluation+of+Recommender+Systems)|0|
|[Rs4rs: Semantically Find Recent Publications from Top Recommendation System-Related Venues](https://doi.org/10.1145/3640457.3691696)|Tri Kurniawan Wijaya, Edoardo D'Amico, Gábor Fodor, Manuel V. Loureiro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rs4rs:+Semantically+Find+Recent+Publications+from+Top+Recommendation+System-Related+Venues)|0|
|[RePlay: a Recommendation Framework for Experimentation and Production Use](https://doi.org/10.1145/3640457.3691701)|Alexey Vasilev, Anna Volodkevich, Denis Kulandin, Tatiana Bysheva, Anton Klenitskiy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RePlay:+a+Recommendation+Framework+for+Experimentation+and+Production+Use)|0|
|[Conducting Recommender Systems User Studies Using POPROX](https://doi.org/10.1145/3640457.3687092)|Robin Burke, Joseph A. Konstan, Michael D. Ekstrand||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conducting+Recommender+Systems+User+Studies+Using+POPROX)|0|
|[Conducting User Experiments in Recommender Systems](https://doi.org/10.1145/3640457.3687090)|Bart P. Knijnenburg, Edward C. Malthouse||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conducting+User+Experiments+in+Recommender+Systems)|0|
|[Multimodal Representation Learning for High-Quality Recommendations in Cold-Start and Beyond-Accuracy](https://doi.org/10.1145/3640457.3688009)|Marta Moscati||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Representation+Learning+for+High-Quality+Recommendations+in+Cold-Start+and+Beyond-Accuracy)|0|
|[Bias in Book Recommendation](https://doi.org/10.1145/3640457.3688025)|Savvina Daniil||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+in+Book+Recommendation)|0|
|[A New Perspective in Health Recommendations: Integration of Human Pose Estimation](https://doi.org/10.1145/3640457.3688026)|Gaetano Dibenedetto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Perspective+in+Health+Recommendations:+Integration+of+Human+Pose+Estimation)|0|
|[Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models](https://doi.org/10.1145/3640457.3688104)|Yunjia Xi, Weiwen Liu, Jianghao Lin, Xiaoling Cai, Hong Zhu, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Open-World+Recommendation+with+Knowledge+Augmentation+from+Large+Language+Models)|0|
|[Large Language Models as Evaluators for Recommendation Explanations](https://doi.org/10.1145/3640457.3688075)|Xiaoyu Zhang, Yishan Li, Jiayin Wang, Bowen Sun, Weizhi Ma, Peijie Sun, Min Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+as+Evaluators+for+Recommendation+Explanations)|0|
|[ReLand: Integrating Large Language Models' Insights into Industrial Recommenders via a Controllable Reasoning Pool](https://doi.org/10.1145/3640457.3688131)|Changxin Tian, Binbin Hu, Chunjing Gan, Haoyu Chen, Zhuo Zhang, Li Yu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Jiawei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReLand:+Integrating+Large+Language+Models'+Insights+into+Industrial+Recommenders+via+a+Controllable+Reasoning+Pool)|0|
|[Reproducibility of LLM-based Recommender Systems: the Case Study of P5 Paradigm](https://doi.org/10.1145/3640457.3688072)|Pasquale Lops, Antonio Silletti, Marco Polignano, Cataldo Musto, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reproducibility+of+LLM-based+Recommender+Systems:+the+Case+Study+of+P5+Paradigm)|0|
|[A Comparative Analysis of Text-Based Explainable Recommender Systems](https://doi.org/10.1145/3640457.3688069)|Alejandro ArizaCasabona, Ludovico Boratto, Maria Salamó||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Comparative+Analysis+of+Text-Based+Explainable+Recommender+Systems)|0|
|[FLIP: Fine-grained Alignment between ID-based Models and Pretrained Language Models for CTR Prediction](https://doi.org/10.1145/3640457.3688106)|Hangyu Wang, Jianghao Lin, Xiangyang Li, Bo Chen, Chenxu Zhu, Ruiming Tang, Weinan Zhang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLIP:+Fine-grained+Alignment+between+ID-based+Models+and+Pretrained+Language+Models+for+CTR+Prediction)|0|
|[AMBAR: A dataset for Assessing Multiple Beyond-Accuracy Recommenders](https://doi.org/10.1145/3640457.3688067)|Elizabeth Gómez, David Contreras, Ludovico Boratto, Maria Salamó||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AMBAR:+A+dataset+for+Assessing+Multiple+Beyond-Accuracy+Recommenders)|0|
|[The Fault in Our Recommendations: On the Perils of Optimizing the Measurable](https://doi.org/10.1145/3640457.3688144)|Omar Besbes, Yash Kanoria, Akshit Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Fault+in+Our+Recommendations:+On+the+Perils+of+Optimizing+the+Measurable)|0|
|[Fair Augmentation for Graph Collaborative Filtering](https://doi.org/10.1145/3640457.3688064)|Ludovico Boratto, Francesco Fabbri, Gianni Fenu, Mirko Marras, Giacomo Medda||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Augmentation+for+Graph+Collaborative+Filtering)|0|
|[Adaptive Fusion of Multi-View for Graph Contrastive Recommendation](https://doi.org/10.1145/3640457.3688153)|Mengduo Yang, Yi Yuan, Jie Zhou, Meng Xi, Xiaohua Pan, Ying Li, Yangyang Wu, Jinshan Zhang, Jianwei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Fusion+of+Multi-View+for+Graph+Contrastive+Recommendation)|0|
|[One-class Matrix Factorization: Point-Wise Regression-Based or Pair-Wise Ranking-Based?](https://doi.org/10.1145/3640457.3688063)|ShengWei Chen, ChihJen Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-class+Matrix+Factorization:+Point-Wise+Regression-Based+or+Pair-Wise+Ranking-Based?)|0|
|[Unlocking the Hidden Treasures: Enhancing Recommendations with Unlabeled Data](https://doi.org/10.1145/3640457.3688149)|Yuhan Zhao, Rui Chen, Qilong Han, Hongtao Song, Li Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Hidden+Treasures:+Enhancing+Recommendations+with+Unlabeled+Data)|0|
|[Revisiting BPR: A Replicability Study of a Common Recommender System Baseline](https://doi.org/10.1145/3640457.3688073)|Aleksandr Milogradskii, Oleg Lashinin, Alexander P, Marina Ananyeva, Sergey Kolesnikov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+BPR:+A+Replicability+Study+of+a+Common+Recommender+System+Baseline)|0|
|[ReChorus2.0: A Modular and Task-Flexible Recommendation Library](https://doi.org/10.1145/3640457.3688076)|Jiayu Li, Hanyu Li, Zhiyu He, Weizhi Ma, Peijie Sun, Min Zhang, Shaoping Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReChorus2.0:+A+Modular+and+Task-Flexible+Recommendation+Library)|0|
|[A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation](https://doi.org/10.1145/3640457.3688096)|Zixuan Yi, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Unified+Graph+Transformer+for+Overcoming+Isolations+in+Multi-modal+Recommendation)|0|
|[Information-Controllable Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3640457.3688122)|Zirui Guo, Yanhua Yu, Yuling Wang, Kangkang Lu, Zixuan Yang, Liang Pang, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information-Controllable+Graph+Contrastive+Learning+for+Recommendation)|0|
|[MMGCL: Meta Knowledge-Enhanced Multi-view Graph Contrastive Learning for Recommendations](https://doi.org/10.1145/3640457.3688127)|Yuezihan Jiang, Changyu Li, Gaode Chen, Peiyi Li, Qi Zhang, Jingjian Lin, Peng Jiang, Fei Sun, Wentao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMGCL:+Meta+Knowledge-Enhanced+Multi-view+Graph+Contrastive+Learning+for+Recommendations)|0|
|[Reproducibility and Analysis of Scientific Dataset Recommendation Methods](https://doi.org/10.1145/3640457.3688071)|Ornella Irrera, Matteo Lissandrini, Daniele Dell'Aglio, Gianmaria Silvello||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reproducibility+and+Analysis+of+Scientific+Dataset+Recommendation+Methods)|0|
|[ConFit: Improving Resume-Job Matching using Data Augmentation and Contrastive Learning](https://doi.org/10.1145/3640457.3688108)|Xiao Yu, Jinzhong Zhang, Zhou Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ConFit:+Improving+Resume-Job+Matching+using+Data+Augmentation+and+Contrastive+Learning)|0|
|[Unified Denoising Training for Recommendation](https://doi.org/10.1145/3640457.3688109)|Haoyan Chua, Yingpeng Du, Zhu Sun, Ziyan Wang, Jie Zhang, YewSoon Ong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Denoising+Training+for+Recommendation)|0|
|[Context-based Entity Recommendation for Knowledge Workers: Establishing a Benchmark on Real-life Data](https://doi.org/10.1145/3640457.3688068)|Mahta Bakhshizadeh, Heiko Maus, Andreas Dengel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-based+Entity+Recommendation+for+Knowledge+Workers:+Establishing+a+Benchmark+on+Real-life+Data)|0|
|[Improving the Shortest Plank: Vulnerability-Aware Adversarial Training for Robust Recommender System](https://doi.org/10.1145/3640457.3688120)|Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+the+Shortest+Plank:+Vulnerability-Aware+Adversarial+Training+for+Robust+Recommender+System)|0|
|[Accelerating the Surrogate Retraining for Poisoning Attacks against Recommender Systems](https://doi.org/10.1145/3640457.3688148)|Yunfan Wu, Qi Cao, Shuchang Tao, Kaike Zhang, Fei Sun, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+the+Surrogate+Retraining+for+Poisoning+Attacks+against+Recommender+Systems)|0|
|[Co-optimize Content Generation and Consumption in a Large Scale Video Recommendation System](https://doi.org/10.1145/3640457.3688033)|Zhen Zhang, Qingyun Liu, Yuening Li, Sourabh Bansod, Mingyan Gao, Yaping Zhang, Zhe Zhao, Lichan Hong, Ed H. Chi, Shuchao Bi, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-optimize+Content+Generation+and+Consumption+in+a+Large+Scale+Video+Recommendation+System)|0|
|[Entity-Aware Collections Ranking: A Joint Scoring Approach](https://doi.org/10.1145/3640457.3688038)|Sihao Chen, Sheng Li, Youhe Chen, Dong Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity-Aware+Collections+Ranking:+A+Joint+Scoring+Approach)|0|
|[Improving Data Efficiency for Recommenders and LLMs](https://doi.org/10.1145/3640457.3688052)|Noveen Sachdeva, Benjamin Coleman, WangCheng Kang, Jianmo Ni, James Caverlee, Lichan Hong, Ed H. Chi, Derek Zhiyuan Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Data+Efficiency+for+Recommenders+and+LLMs)|0|
|[LyricLure: Mining Catchy Hooks in Song Lyrics to Enhance Music Discovery and Recommendation](https://doi.org/10.1145/3640457.3688049)|Siddharth Sharma, Akshay Shukla, Ajinkya Walimbe, Tarun Sharma, Joaquin Delgado||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LyricLure:+Mining+Catchy+Hooks+in+Song+Lyrics+to+Enhance+Music+Discovery+and+Recommendation)|0|
|[Optimizing for Participation in Recommender System](https://doi.org/10.1145/3640457.3688042)|Yuan Shao, Bibang Liu, Sourabh Bansod, Arnab Bhadury, Mingyan Gao, Yaping Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+for+Participation+in+Recommender+System)|0|
|[Playlist Search Reinvented: LLMs Behind the Curtain](https://doi.org/10.1145/3640457.3688047)|Geetha Sai Aluri, Siddharth Sharma, Tarun Sharma, Joaquin Delgado||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Playlist+Search+Reinvented:+LLMs+Behind+the+Curtain)|0|
|[Privacy Preserving Conversion Modeling in Data Clean Room](https://doi.org/10.1145/3640457.3688054)|Kungang Li, Xiangyi Chen, Ling Leng, Jiajing Xu, Jiankai Sun, Behnam Rezaei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy+Preserving+Conversion+Modeling+in+Data+Clean+Room)|0|
|[Ranking Across Different Content Types: The Robust Beauty of Multinomial Blending](https://doi.org/10.1145/3640457.3688059)|Jan Malte Lichtenberg, Giuseppe Di Benedetto, Matteo Ruffini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking+Across+Different+Content+Types:+The+Robust+Beauty+of+Multinomial+Blending)|0|
|[Scale-Invariant Learning-to-Rank](https://doi.org/10.1145/3640457.3688032)|Alessio Petrozziello, Christian Sommeregger, YeSheen Lim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scale-Invariant+Learning-to-Rank)|0|
|[Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models](https://doi.org/10.1145/3640457.3688051)|Swanand Joshi, Yesu Feng, KoJen Hsiao, Zhe Zhang, Sudarshan Lamkhede||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sliding+Window+Training+-+Utilizing+Historical+Recommender+Systems+Data+for+Foundation+Models)|0|
|[Why the Shooting in the Dark Method Dominates Recommender Systems Practice](https://doi.org/10.1145/3640457.3688029)|David Rohde||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+the+Shooting+in+the+Dark+Method+Dominates+Recommender+Systems+Practice)|0|
|[MAWI Rec: Leveraging Severe Weather Data in Recommendation](https://doi.org/10.1145/3640457.3688157)|Brendan Andrew Duncan, Surya Kallumadi, Taylor BergKirkpatrick, Julian J. McAuley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAWI+Rec:+Leveraging+Severe+Weather+Data+in+Recommendation)|0|
|[Towards Green Recommender Systems: Investigating the Impact of Data Reduction on Carbon Footprint and Algorithm Performances](https://doi.org/10.1145/3640457.3688160)|Giuseppe Spillo, Allegra De Filippo, Cataldo Musto, Michela Milano, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Green+Recommender+Systems:+Investigating+the+Impact+of+Data+Reduction+on+Carbon+Footprint+and+Algorithm+Performances)|0|
|[Promoting Two-sided Fairness with Adaptive Weights for Providers and Customers in Recommendation](https://doi.org/10.1145/3640457.3688169)|Lanling Xu, Zihan Lin, Jinpeng Wang, Sheng Chen, Wayne Xin Zhao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Promoting+Two-sided+Fairness+with+Adaptive+Weights+for+Providers+and+Customers+in+Recommendation)|0|
|[CAPRI-FAIR: Integration of Multi-sided Fairness in Contextual POI Recommendation Framework](https://doi.org/10.1145/3640457.3688170)|Francis Zac dela Cruz, Flora D. Salim, Yonchanok Khaokaew, Jeffrey Chan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAPRI-FAIR:+Integration+of+Multi-sided+Fairness+in+Contextual+POI+Recommendation+Framework)|0|
|[Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems](https://doi.org/10.1145/3640457.3688172)|YanMartin Tamm, Anna Aljanaki||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comparative+Analysis+of+Pretrained+Audio+Representations+in+Music+Recommender+Systems)|0|
|[A Dataset for Adapting Recommender Systems to the Fashion Rental Economy](https://doi.org/10.1145/3640457.3688174)|Karl Audun Kagnes Borgersen, Morten Goodwin, Morten Grundetjern, Jivitesh Sharma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dataset+for+Adapting+Recommender+Systems+to+the+Fashion+Rental+Economy)|0|
|[Societal Sorting as a Systemic Risk of Recommenders](https://doi.org/10.1145/3640457.3688175)|Luke Thorburn, Maria Polukarov, Carmine Ventre||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Societal+Sorting+as+a+Systemic+Risk+of+Recommenders)|0|
|[Revisiting LightGCN: Unexpected Inflexibility, Inconsistency, and A Remedy Towards Improved Recommendation](https://doi.org/10.1145/3640457.3688176)|Geon Lee, Kyungho Kim, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+LightGCN:+Unexpected+Inflexibility,+Inconsistency,+and+A+Remedy+Towards+Improved+Recommendation)|0|
|[Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning](https://doi.org/10.1145/3640457.3688181)|Henri Jamet, Maxime Manderlier, Yash Raj Shrestha, Michalis Vlachos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluation+and+simplification+of+text+difficulty+using+LLMs+in+the+context+of+recommending+texts+in+French+to+facilitate+language+learning)|0|
|[Fairness Matters: A look at LLM-generated group recommendations](https://doi.org/10.1145/3640457.3688182)|Antonela Tommasel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+Matters:+A+look+at+LLM-generated+group+recommendations)|0|
|[EmbSum: Leveraging the Summarization Capabilities of Large Language Models for Content-Based Recommendations](https://doi.org/10.1145/3640457.3688185)|Chiyu Zhang, Yifei Sun, Minghao Wu, Jun Chen, Jie Lei, Muhammad AbdulMageed, Rong Jin, Angli Liu, Ji Zhu, Sem Park, Ning Yao, Bo Long||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EmbSum:+Leveraging+the+Summarization+Capabilities+of+Large+Language+Models+for+Content-Based+Recommendations)|0|
|[Knowledge-Enhanced Multi-Behaviour Contrastive Learning for Effective Recommendation](https://doi.org/10.1145/3640457.3688186)|Zeyuan Meng, Zixuan Yi, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-Enhanced+Multi-Behaviour+Contrastive+Learning+for+Effective+Recommendation)|0|
|[Can Editorial Decisions Impair Journal Recommendations? Analysing the Impact of Journal Characteristics on Recommendation Systems](https://doi.org/10.1145/3640457.3688194)|Elias Entrup, Ralph Ewerth, Anett Hoppe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Editorial+Decisions+Impair+Journal+Recommendations?+Analysing+the+Impact+of+Journal+Characteristics+on+Recommendation+Systems)|0|
|[Democratizing Urban Mobility Through an Open-Source, Multi-Criteria Route Recommendation System](https://doi.org/10.1145/3640457.3691702)|Alexander Eggerth, Javier Argota SánchezVaquerizo, Dirk Helbing, Sachit Mahajan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Democratizing+Urban+Mobility+Through+an+Open-Source,+Multi-Criteria+Route+Recommendation+System)|0|
|[KGGLM: A Generative Language Model for Generalizable Knowledge Graph Representation Learning in Recommendation](https://doi.org/10.1145/3640457.3691703)|Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Mirko Marras, Alessandro Soccol||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGGLM:+A+Generative+Language+Model+for+Generalizable+Knowledge+Graph+Representation+Learning+in+Recommendation)|0|
|[Social Choice for Heterogeneous Fairness in Recommendation](https://doi.org/10.1145/3640457.3691706)|Amanda Aird, Elena Stefancova, Cassidy All, Amy Voida, Martin Homola, Nicholas Mattei, Robin Burke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Social+Choice+for+Heterogeneous+Fairness+in+Recommendation)|0|
|[Less is More: Towards Sustainability-Aware Persuasive Explanations in Recommender Systems](https://doi.org/10.1145/3640457.3691708)|Thi Ngoc Trang Tran, Seda Polat Erdeniz, Alexander Felfernig, Sebastian Lubos, Merfat El Mansi, VietMan Le||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Less+is+More:+Towards+Sustainability-Aware+Persuasive+Explanations+in+Recommender+Systems)|0|
|[Are We Explaining the Same Recommenders? Incorporating Recommender Performance for Evaluating Explainers](https://doi.org/10.1145/3640457.3691709)|Amir Reza Mohammadi, Andreas Peintner, Michael Müller, Eva Zangerle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+We+Explaining+the+Same+Recommenders?+Incorporating+Recommender+Performance+for+Evaluating+Explainers)|0|
|[Understanding Fairness in Recommender Systems: A Healthcare Perspective](https://doi.org/10.1145/3640457.3691711)|Veronica Kecki, Alan Said||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+Fairness+in+Recommender+Systems:+A+Healthcare+Perspective)|0|
|[Multi-Preview Recommendation via Reinforcement Learning](https://doi.org/10.1145/3640457.3691698)|Yang Xu, KuanTing Lai, Pengcheng Xiong, Zhong Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Preview+Recommendation+via+Reinforcement+Learning)|0|
|[A Tool for Explainable Pension Fund Recommendations using Large Language Models](https://doi.org/10.1145/3640457.3691699)|Eduardo Alves da Silva, Leandro Balby Marinho, Edleno Silva de Moura, Altigran Soares da Silva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tool+for+Explainable+Pension+Fund+Recommendations+using+Large+Language+Models)|0|
|[RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations](https://doi.org/10.1145/3640457.3687164)|Johannes Kruse, Kasper Lindskow, Saikishore Kalloori, Marco Polignano, Claudio Pomo, Abhishek Srivastava, Anshuk Uppal, Michael Riis Andersen, Jes Frellsen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecSys+Challenge+2024:+Balancing+Accuracy+and+Editorial+Values+in+News+Recommendations)|0|
|[RecTemp: Temporal Reasoning in Recommendation Systems](https://doi.org/10.1145/3640457.3687096)|Adir Solomon, Tsvi Kuflik, Bracha Shapira, Ido Guy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecTemp:+Temporal+Reasoning+in+Recommendation+Systems)|0|
|[Reflections on Recommender Systems: Past, Present, and Future (INTROSPECTIVES)](https://doi.org/10.1145/3640457.3687101)|Alan Said, Christine Bauer, Eva Zangerle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reflections+on+Recommender+Systems:+Past,+Present,+and+Future+(INTROSPECTIVES))|0|
|[RobustRecSys @ RecSys2024: Design, Evaluation and Deployment of Robust Recommender Systems](https://doi.org/10.1145/3640457.3687106)|Valerio Guarrasi, Federico Siciliano, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RobustRecSys+@+RecSys2024:+Design,+Evaluation+and+Deployment+of+Robust+Recommender+Systems)|0|
|[Deep Recommendation using Graphs](https://doi.org/10.1145/3640457.3687089)|Panagiotis Symeonidis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Recommendation+using+Graphs)|0|
|[Computational Methods for Designing Human-Centered Recommender Systems: A Case Study Approach Intersecting Visual Arts and Healthcare](https://doi.org/10.1145/3640457.3687091)|Bereket Abera Yilma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Computational+Methods+for+Designing+Human-Centered+Recommender+Systems:+A+Case+Study+Approach+Intersecting+Visual+Arts+and+Healthcare)|0|
|[Economics of Recommender Systems](https://doi.org/10.1145/3640457.3687093)|Emilio Calvano, Giacomo Calzolari, Vincenzo Denicolò, Sergio Pastorello||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Economics+of+Recommender+Systems)|0|
|[A Tutorial on Feature Interpretation in Recommender Systems](https://doi.org/10.1145/3640457.3687094)|Zhaocheng Du, Chuhan Wu, Qinglin Jia, Jieming Zhu, Xu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tutorial+on+Feature+Interpretation+in+Recommender+Systems)|0|
|[Bridging Viewpoints in News with Recommender Systems](https://doi.org/10.1145/3640457.3688008)|Jia Hua Jeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Viewpoints+in+News+with+Recommender+Systems)|0|
|[Evaluating the Pros and Cons of Recommender Systems Explanations](https://doi.org/10.1145/3640457.3688011)|Kathrin Wardatzky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+the+Pros+and+Cons+of+Recommender+Systems+Explanations)|0|
|[Explainable Multi-Stakeholder Job Recommender Systems](https://doi.org/10.1145/3640457.3688014)|Roan Schellingerhout||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Multi-Stakeholder+Job+Recommender+Systems)|0|
|[CEERS: Counterfactual Evaluations of Explanations in Recommender Systems](https://doi.org/10.1145/3640457.3688015)|Mikhail Baklanov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CEERS:+Counterfactual+Evaluations+of+Explanations+in+Recommender+Systems)|0|
|[Towards Sustainable Recommendations in Urban Tourism](https://doi.org/10.1145/3640457.3688016)|Pavel Merinov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Sustainable+Recommendations+in+Urban+Tourism)|0|
|[How to Evaluate Serendipity in Recommender Systems: the Need for a Serendiptionnaire](https://doi.org/10.1145/3640457.3688017)|Brett Binst||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+to+Evaluate+Serendipity+in+Recommender+Systems:+the+Need+for+a+Serendiptionnaire)|0|
|[Enhancing Privacy in Recommender Systems through Differential Privacy Techniques](https://doi.org/10.1145/3640457.3688019)|Angela Di Fazio||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Privacy+in+Recommender+Systems+through+Differential+Privacy+Techniques)|0|
|[Fairness Explanations in Recommender Systems](https://doi.org/10.1145/3640457.3688020)|Luan Soares de Souza||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+Explanations+in+Recommender+Systems)|0|
|[Explainable and Faithful Educational Recommendations through Causal Language Modelling via Knowledge Graphs](https://doi.org/10.1145/3640457.3688022)|Neda Afreen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+and+Faithful+Educational+Recommendations+through+Causal+Language+Modelling+via+Knowledge+Graphs)|0|
|[Fairness and Transparency in Music Recommender Systems: Improvements for Artists](https://doi.org/10.1145/3640457.3688024)|Karlijn Dinnissen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+and+Transparency+in+Music+Recommender+Systems:+Improvements+for+Artists)|0|
|[Explainability in Music Recommender System](https://doi.org/10.1145/3640457.3688028)|Shahrzad Shashaani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainability+in+Music+Recommender+System)|0|
|[Short-form Video Needs Long-term Interests: An Industrial Solution for Serving Large User Sequence Models](https://doi.org/10.1145/3640457.3688030)|Yuening Li, Diego Uribe, Chuan He, Jiaxi Tang, Qingyun Liu, Junjie Shan, Ben Most, Kaushik Kalyan, Shuchao Bi, Xinyang Yi, Lichan Hong, Ed H. Chi, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Short-form+Video+Needs+Long-term+Interests:+An+Industrial+Solution+for+Serving+Large+User+Sequence+Models)|0|
|[Explore versus repeat: insights from an online supermarket](https://doi.org/10.1145/3640457.3688050)|Mariagiorgia Agnese Tandoi, Daniela Solis Morales||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explore+versus+repeat:+insights+from+an+online+supermarket)|0|
|[What to compare? Towards understanding user sessions on price comparison platforms](https://doi.org/10.1145/3640457.3691717)|Ahmadou Wagne, Julia Neidhardt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+to+compare?+Towards+understanding+user+sessions+on+price+comparison+platforms)|0|
|[Cross-Domain Latent Factors Sharing via Implicit Matrix Factorization](https://doi.org/10.1145/3640457.3688143)|Abdulaziz Samra, Evgeny Frolov, Alexey Vasilev, Alexander Grigorevskiy, Anton Vakhrushev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Domain+Latent+Factors+Sharing+via+Implicit+Matrix+Factorization)|0|
|[Optimal Baseline Corrections for Off-Policy Contextual Bandits](https://doi.org/10.1145/3640457.3688105)|Shashank Gupta, Olivier Jeunen, Harrie Oosterhuis, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Baseline+Corrections+for+Off-Policy+Contextual+Bandits)|0|
|[Effective Off-Policy Evaluation and Learning in Contextual Combinatorial Bandits](https://doi.org/10.1145/3640457.3688099)|Tatsuhiro Shimizu, Koichi Tanaka, Ren Kishimoto, Haruka Kiyohara, Masahiro Nomura, Yuta Saito||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Off-Policy+Evaluation+and+Learning+in+Contextual+Combinatorial+Bandits)|0|
|["More to Read" at the Los Angeles Times: Solving a Cold Start Problem with LLMs to Improve Story Discovery](https://doi.org/10.1145/3640457.3688031)|Franklin Horn, Aurelia Alston, Won J. You||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="More+to+Read"+at+the+Los+Angeles+Times:+Solving+a+Cold+Start+Problem+with+LLMs+to+Improve+Story+Discovery)|0|
|[Powerful A/B-Testing Metrics and Where to Find Them](https://doi.org/10.1145/3640457.3688036)|Olivier Jeunen, Shubham Baweja, Neeti Pokharna, Aleksei Ustimenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Powerful+A/B-Testing+Metrics+and+Where+to+Find+Them)|0|
|[Δ-OPE: Off-Policy Estimation with Pairs of Policies](https://doi.org/10.1145/3640457.3688162)|Olivier Jeunen, Aleksei Ustimenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Δ-OPE:+Off-Policy+Estimation+with+Pairs+of+Policies)|0|
|[Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation](https://doi.org/10.1145/3640457.3688142)|David Eric Austin, Anton Korikov, Armin Toroghi, Scott Sanner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bayesian+Optimization+with+LLM-Based+Acquisition+Functions+for+Natural+Language+Preference+Elicitation)|0|
|[The Role of Unknown Interactions in Implicit Matrix Factorization - A Probabilistic View](https://doi.org/10.1145/3640457.3688100)|Joey De Pauw, Bart Goethals||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Role+of+Unknown+Interactions+in+Implicit+Matrix+Factorization+-+A+Probabilistic+View)|0|
|[Country-diverted experiments for mitigation of network effects](https://doi.org/10.1145/3640457.3688046)|Lina Lin, Changping Meng, Jennifer Brennan, Jean PougetAbadie, Ningren Han, Shuchao Bi, Yajun Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Country-diverted+experiments+for+mitigation+of+network+effects)|0|
|[Off-Policy Selection for Optimizing Ad Display Timing in Mobile Games (Samsung Instant Plays)](https://doi.org/10.1145/3640457.3688058)|Katarzyna SiudekTkaczuk, Slawomir Kapka, Jedrzej Alchimowicz, Bartlomiej Swoboda, Michal Romaniuk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Selection+for+Optimizing+Ad+Display+Timing+in+Mobile+Games+(Samsung+Instant+Plays))|0|
|[On Interpretability of Linear Autoencoders](https://doi.org/10.1145/3640457.3688179)|Martin Spisák, Radek Bartyzal, Antonín Hoskovec, Ladislav Peska||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Interpretability+of+Linear+Autoencoders)|0|
|[Informed Dataset Selection with 'Algorithm Performance Spaces'](https://doi.org/10.1145/3640457.3691704)|Joeran Beel, Lukas Wegmeth, Lien Michiels, Steffen Schulz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Informed+Dataset+Selection+with+'Algorithm+Performance+Spaces')|0|
|[Stalactite: toolbox for fast prototyping of vertical federated learning systems](https://doi.org/10.1145/3640457.3691700)|Anastasiia Zakharova, Dmitriy Alexandrov, Maria Khodorchenko, Nikolay Butakov, Alexey Vasilev, Maxim Savchenko, Alexander Grigorievskiy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stalactite:+toolbox+for+fast+prototyping+of+vertical+federated+learning+systems)|0|
|[VideoRecSys + LargeRecSys 2024](https://doi.org/10.1145/3640457.3687116)|Khushhall Chandra Mahajan, Amey Porobo Dharwadker, Saurabh Gupta, Brad Schumitsch, Arnab Bhadury, Ding Tong, KoJen Hsiao, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VideoRecSys+++LargeRecSys+2024)|0|
|[Integrating Matrix Factorization with Graph based Models](https://doi.org/10.1145/3640457.3688013)|Rachana Mehta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Matrix+Factorization+with+Graph+based+Models)|0|
