# RECSYS2024 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[A Hybrid Multi-Agent Conversational Recommender System with LLM and Search Engine in E-commerce](https://doi.org/10.1145/3640457.3688061)|Guangtao Nie, Rong Zhi, Xiaofan Yan, Yufan Du, Xiangyang Zhang, Jianwei Chen, Mi Zhou, Hongshen Chen, Tianhao Li, Ziguang Cheng, Sulong Xu, Jinghe Hu|JDcom, Beijing, Peoples R China|Multi-agent collaboration is the latest trending method to build conversational recommender systems (CRS), especially with the widespread use of Large Language Models (LLMs) recently. Typically, these systems employ several LLM agents, each serving distinct roles to meet user needs. In an industrial setting, it’s essential for a CRS to exhibit low first token latency (i.e., the time taken from a user’s input until the system outputs its first response token.) and high scalability—for instance, minimizing the number of LLM inferences per user request—to enhance user experience and boost platform profit. For example, JD.com’s baseline CRS features two LLM agents and a search API but suffers from high first token latency and requires two LLM inferences per request (LIPR), hindering its performance. To address these issues, we introduce a Hybrid Multi-Agent Collaborative Recommender System (Hybrid-MACRS). It includes a central agent powered by a fine-tuned proprietary LLM and a search agent combining a related search module with a search engine. This hybrid system notably reduces first token latency by about 70% and cuts the LIPR from 2 to 1. We conducted thorough online A/B testing to confirm this approach’s efficiency.|多智能体协作是构建对话推荐系统（CRS）的最新趋势方法，尤其是在最近大型语言模型（LLMs）广泛应用的背景下。通常，这些系统会部署多个LLM智能体，每个智能体扮演不同的角色以满足用户需求。在工业环境中，CRS必须具备低首词延迟（即从用户输入到系统输出第一个响应词所需的时间）和高可扩展性——例如，尽量减少每个用户请求所需的LLM推理次数——以提升用户体验并增加平台利润。例如，京东的基线CRS包含两个LLM智能体和一个搜索API，但其首词延迟较高，且每个请求需要两次LLM推理（LIPR），这限制了其性能。为了解决这些问题，我们提出了一种混合多智能体协作推荐系统（Hybrid-MACRS）。该系统包括一个由微调后的专有LLM驱动的中心智能体，以及一个结合了相关搜索模块和搜索引擎的搜索智能体。这种混合系统显著降低了首词延迟约70%，并将LIPR从2次减少到1次。我们进行了全面的在线A/B测试，以验证该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hybrid+Multi-Agent+Conversational+Recommender+System+with+LLM+and+Search+Engine+in+E-commerce)|0|
|[Embedding based retrieval for long tail search queries in ecommerce](https://doi.org/10.1145/3640457.3688039)|Akshay Kekuda, Yuyang Zhang, Arun Udayashankar|Best Buy, Appl Machine Learning, Minneapolis, MN 55423 USA|In this abstract we present a series of optimizations we performed on the two-tower model architecture [14], training and evaluation datasets to implement semantic product search at Best Buy. Search queries on bestbuy.com follow the pareto distribution whereby a minority of them account for most searches. This leaves us with a long tail of search queries that have low frequency of issuance. The queries in the long tail suffer from very spare interaction signals. Our current work focuses on building a model to serve the long tail queries. We present a series of optimizations we have done to this model to maximize conversion for the purpose of retrieval from the catalog. The first optimization we present is using a large language model to improve the sparsity of conversion signals. The second optimization is pretraining an off-the-shelf transformer-based model on the Best Buy catalog data. The third optimization we present is on the finetuning front. We use query-to-query pairs in addition to query-to-product pairs and combining the above strategies for finetuning the model. We also demonstrate how merging the weights of these finetuned models improves the evaluation metrics. Finally, we provide a recipe for curating an evaluation dataset for continuous monitoring of model performance with human-in-the-loop evaluation. We found that adding this recall mechanism to our current term match-based recall improved conversion by 3% in an online A/B test.|在本摘要中，我们介绍了一系列针对双塔模型架构[14]的优化措施，以及在Best Buy实施语义产品搜索过程中对训练和评估数据集的改进。Bestbuy.com上的搜索查询遵循帕累托分布，即少数查询占据了大部分搜索量。这导致我们面临大量低频搜索查询的长尾问题。这些长尾查询的交互信号非常稀疏。我们当前的工作重点在于构建一个模型来服务于这些长尾查询。我们展示了一系列针对该模型的优化措施，以最大化从目录中检索的转化率。首先，我们利用大型语言模型来改善转化信号的稀疏性。其次，我们使用Best Buy目录数据对现成的基于Transformer的模型进行预训练。第三，我们在微调方面进行了优化，除了使用查询-产品对之外，还引入了查询-查询对，并结合上述策略对模型进行微调。我们还展示了如何通过合并这些微调模型的权重来提升评估指标。最后，我们提供了一种构建评估数据集的方案，通过人工参与的循环评估来持续监控模型性能。我们发现，在当前基于术语匹配的召回机制中加入这一优化后，在线A/B测试中的转化率提高了3%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+based+retrieval+for+long+tail+search+queries+in+ecommerce)|0|
|[Ranking-Aware Unbiased Post-Click Conversion Rate Estimation via AUC Optimization on Entire Exposure Space](https://doi.org/10.1145/3640457.3688152)|Yu Liu, Qinglin Jia, Shuting Shi, Chuhan Wu, Zhaocheng Du, Zheng Xie, Ruiming Tang, Muyu Zhang, Ming Li|; Huawei Noahs Ark Lab, Beijing, Peoples R China; Huawei Technol Co Ltd, Shenzhen, Peoples R China; National Key Laboratory for Novel Software Technology, Nanjing University, China|Estimating the post-click conversion rate (CVR) accurately in ranking systems is crucial in industrial applications. However, this task is often challenged by data sparsity and selection bias, which hinder accurate ranking. Previous approaches to address these challenges have typically focused on either modeling CVR across the entire exposure space which includes all exposure events, or providing unbiased CVR estimation separately. However, the lack of integration between these objectives has limited the overall performance of CVR estimation. Therefore, there is a pressing need for a method that can simultaneously provide unbiased CVR estimates across the entire exposure space. To achieve it, we formulate the CVR estimation task as an Area Under the Curve (AUC) optimization problem and propose the Entire-space Weighted AUC (EWAUC) framework. EWAUC utilizes sample reweighting techniques to handle selection bias and employs pairwise AUC risk, which incorporates more information from limited clicked data, to handle data sparsity. In order to model CVR across the entire exposure space unbiasedly, EWAUC treats the exposure data as both conversion data and non-conversion data to calculate the loss. The properties of AUC risk guarantee the unbiased nature of the entire space modeling. We provide comprehensive theoretical analysis to validate the unbiased nature of our approach. Additionally, extensive experiments conducted on real-world datasets demonstrate that our approach outperforms state-of-the-art methods in terms of ranking performance for the CVR estimation task.|在排名系统中准确估计点击后转化率（CVR）在工业应用中至关重要。然而，这一任务常常受到数据稀疏性和选择偏差的挑战，这些因素阻碍了准确的排名。以往解决这些挑战的方法通常集中在在整个曝光空间（包括所有曝光事件）中对CVR进行建模，或者分别提供无偏的CVR估计。然而，这些目标之间缺乏整合，限制了CVR估计的整体性能。因此，迫切需要一种能够同时在整个曝光空间提供无偏CVR估计的方法。为了实现这一目标，我们将CVR估计任务表述为曲线下面积（AUC）优化问题，并提出了全空间加权AUC（EWAUC）框架。EWAUC利用样本重加权技术来处理选择偏差，并采用成对AUC风险（从有限的点击数据中获取更多信息）来处理数据稀疏性。为了在整个曝光空间中对CVR进行无偏建模，EWAUC将曝光数据同时视为转化数据和非转化数据来计算损失。AUC风险的性质保证了整个空间建模的无偏性。我们提供了全面的理论分析来验证我们方法的无偏性。此外，在真实世界数据集上进行的大量实验表明，我们的方法在CVR估计任务的排名性能上优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking-Aware+Unbiased+Post-Click+Conversion+Rate+Estimation+via+AUC+Optimization+on+Entire+Exposure+Space)|0|
|[Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Models](https://doi.org/10.1145/3640457.3688118)|Yu Cui, Feng Liu, Pengbo Wang, Bohao Wang, Heng Tang, Yi Wan, Jun Wang, Jiawei Chen|University of Electronic Science and Technology of China Chengdu; Zhejiang University Hangzhou; OPPO Co Ltd Shenzhen|Owing to their powerful semantic reasoning capabilities, Large Language Models (LLMs) have been effectively utilized as recommenders, achieving impressive performance. However, the high inference latency of LLMs significantly restricts their practical deployment. To address this issue, this work investigates knowledge distillation from cumbersome LLM-based recommendation models to lightweight conventional sequential models. It encounters three challenges: 1) the teacher’s knowledge may not always be reliable; 2) the capacity gap between the teacher and student makes it difficult for the student to assimilate the teacher’s knowledge; 3) divergence in semantic space poses a challenge to distill the knowledge from embeddings. To tackle these challenges, this work proposes a novel distillation strategy, DLLM2Rec, specifically tailored for knowledge distillation from LLM-based recommendation models to conventional sequential models. DLLM2Rec comprises: 1) Importance-aware ranking distillation, which filters reliable and student-friendly knowledge by weighting instances according to teacher confidence and student-teacher consistency; 2) Collaborative embedding distillation integrates knowledge from teacher embeddings with collaborative signals mined from the data. Extensive experiments demonstrate the effectiveness of the proposed DLLM2Rec, boosting three typical sequential models with an average improvement of 47.97%, even enabling them to surpass LLM-based recommenders in some cases.|由于大语言模型（LLMs）具有强大的语义推理能力，它们已被有效地用作推荐系统，并取得了令人印象深刻的性能。然而，LLMs的高推理延迟极大地限制了其实际部署。为了解决这一问题，本研究探讨了从基于LLM的复杂推荐模型到轻量级传统序列模型的知识蒸馏。这一过程中面临三个挑战：1）教师模型的知识可能并不总是可靠的；2）教师模型与学生模型之间的能力差距使得学生模型难以吸收教师模型的知识；3）语义空间中的差异给从嵌入中蒸馏知识带来了挑战。为了应对这些挑战，本研究提出了一种新的蒸馏策略DLLM2Rec，专门为从基于LLM的推荐模型到传统序列模型的知识蒸馏而设计。DLLM2Rec包括：1）重要性感知排序蒸馏，通过根据教师模型的置信度和学生模型与教师模型的一致性对实例进行加权，筛选出可靠且适合学生模型的知识；2）协作嵌入蒸馏，将教师模型嵌入中的知识与从数据中挖掘的协作信号相结合。大量实验证明了所提出的DLLM2Rec的有效性，使得三种典型的序列模型平均提升了47.97%，甚至在某些情况下使它们超越了基于LLM的推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distillation+Matters:+Empowering+Sequential+Recommenders+to+Match+the+Performance+of+Large+Language+Models)|0|
|[Dynamic Product Image Generation and Recommendation at Scale for Personalized E-commerce](https://doi.org/10.1145/3640457.3688045)|Ádám Tibor Czapp, Mátyás Jani, Bálint Domián, Balázs Hidasi|Taboola Budapest, Budapest, Hungary|Coupling latent diffusion based image generation with contextual bandits enables the creation of eye-catching personalized product images at scale that was previously either impossible or too expensive. In this paper we showcase how we utilized these technologies to increase user engagement with recommendations in online retargeting campaigns for e-commerce.|将基于潜在扩散模型的图像生成技术与上下文多臂老虎机相结合，使得大规模创建引人注目的个性化产品图像成为可能，这在以前要么是不可能的，要么成本过高。在本文中，我们展示了如何利用这些技术来提高电子商务在线重定向广告活动中推荐内容的用户参与度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Product+Image+Generation+and+Recommendation+at+Scale+for+Personalized+E-commerce)|0|
|[Encouraging Exploration in Spotify Search through Query Recommendations](https://doi.org/10.1145/3640457.3688035)|Henrik Lindstrom, Humberto Jesús Corona Pampín, Enrico Palumbo, Alva Liu|Spotify, Amsterdam, Netherlands; Spotify, Stockholm, Sweden; Spotify, Turin, Italy|At Spotify, search has been traditionally seen as a tool for retrieving content, with the search system optimized for when the user has a specific target in mind. In particular we have relied on an instant search system providing results for each keystroke, which works well for known-item search, when queries are straightforward, and the catalog is small. However, as Spotify’s catalog grows in size and variety, it becomes increasingly difficult for users to define their search intents accurately. Furthermore, as we expand the offering, we need to help users discover more content both when it comes to new content types, e.g. audiobooks, as well as for new content/creators within existing content types. To solve this we have introduced a hybrid Query Recommendation system (QR) that helps the user formulate more complex exploratory search intents, while still serving known-item lookups efficiently. This experience has been rolled out worldwide to all mobile users resulting in an increase in exploratory intent queries of 9% in A/B tests.|在Spotify，搜索传统上被视为一种检索内容的工具，其搜索系统针对用户有明确目标的情况进行了优化。特别是，我们依赖一种即时搜索系统，该系统为每个按键提供结果，这在已知项搜索、查询简单且目录较小的情况下表现良好。然而，随着Spotify目录规模和多样性的增长，用户准确定义搜索意图变得越来越困难。此外，随着我们扩展服务内容，我们需要帮助用户发现更多内容，无论是新内容类型（例如有声书），还是现有内容类型中的新内容/创作者。为了解决这个问题，我们引入了一种混合查询推荐系统（QR），该系统帮助用户制定更复杂的探索性搜索意图，同时仍然高效地服务于已知项查找。这一体验已向全球所有移动用户推出，在A/B测试中，探索性意图查询增加了9%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Encouraging+Exploration+in+Spotify+Search+through+Query+Recommendations)|0|
|[Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems](https://doi.org/10.1145/3640457.3688048)|Timo Wilm, Philipp Normann, Felix Stepprath|OTTO GmbH & Co Kg, Hamburg, Germany|This work introduces MultiTRON, an approach that adapts Pareto front approximation techniques to multi-objective session-based recommender systems using a transformer neural network. Our approach optimizes trade-offs between key metrics such as click-through and conversion rates by training on sampled preference vectors. A significant advantage is that after training, a single model can access the entire Pareto front, allowing it to be tailored to meet the specific requirements of different stakeholders by adjusting an additional input vector that weights the objectives. We validate the model’s performance through extensive offline and online evaluation. For broader application and research, the source code1 is made available. The results confirm the model’s ability to manage multiple recommendation objectives effectively, offering a flexible tool for diverse business needs.|本文介绍了MultiTRON方法，该方法通过将帕累托前沿逼近技术应用于基于会话的多目标推荐系统，并利用Transformer神经网络进行实现。我们的方法通过在采样的偏好向量上进行训练，优化了关键指标（如点击率和转化率）之间的权衡。一个显著的优势在于，训练完成后，单一模型能够访问整个帕累托前沿，通过调整一个额外的输入向量来加权目标，从而使其能够根据不同利益相关者的具体需求进行定制。我们通过广泛的离线和在线评估验证了模型的性能。为了促进更广泛的应用和研究，源代码1已公开发布。结果证实了该模型能够有效管理多个推荐目标，为多样化的业务需求提供了一个灵活的工具。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto+Front+Approximation+for+Multi-Objective+Session-Based+Recommender+Systems)|0|
|[Enhancing Sequential Music Recommendation with Negative Feedback-informed Contrastive Learning](https://doi.org/10.1145/3640457.3688188)|Pavan Seshadri, Shahrzad Shashaani, Peter Knees|TU Wien, Fac Informat, Vienna, Austria; Georgia Inst Technol, Mus Informat Grp, Atlanta, GA 30332 USA|Modern music streaming services are heavily based on recommendation engines to serve content to users. Sequential recommendation—continuously providing new items within a single session in a contextually coherent manner—has been an emerging topic in current literature. User feedback—a positive or negative response to the item presented—is used to drive content recommendations by learning user preferences. We extend this idea to session-based recommendation to provide context-coherent music recommendations by modelling negative user feedback, i.e., skips, in the loss function. We propose a sequence-aware contrastive sub-task to structure item embeddings in session-based music recommendation, such that true next-positive items (ignoring skipped items) are structured closer in the session embedding space, while skipped tracks are structured farther away from all items in the session. This directly affects item rankings using a K-nearest-neighbors search for next-item recommendations, while also promoting the rank of the true next item. Experiments incorporating this task into SoTA methods for sequential item recommendation show consistent performance gains in terms of next-item hit rate, item ranking, and skip down-ranking on three music recommendation datasets, strongly benefiting from the increasing presence of user feedback.|现代音乐流媒体服务在很大程度上依赖于推荐引擎向用户提供内容。顺序推荐——在单个会话中以上下文连贯的方式持续提供新项目——已成为当前文献中的一个新兴主题。用户反馈——对呈现项目的正面或负面响应——通过学习用户偏好来驱动内容推荐。我们将这一思路扩展到基于会话的推荐中，通过在损失函数中建模负面用户反馈（即跳过）来提供上下文连贯的音乐推荐。我们提出了一个序列感知的对比子任务，用于在基于会话的音乐推荐中构建项目嵌入，使得真正的下一个正面项目（忽略跳过的项目）在会话嵌入空间中结构更近，而跳过的曲目则与会话中的所有项目结构更远。这直接影响了使用K近邻搜索进行下一项目推荐时的项目排名，同时也提升了真正下一个项目的排名。将这一任务整合到顺序项目推荐的最先进方法中的实验表明，在三个音乐推荐数据集上，下一项目命中率、项目排名和跳过低排名方面均显示出持续的性能提升，这极大地受益于用户反馈的日益增多。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Sequential+Music+Recommendation+with+Negative+Feedback-informed+Contrastive+Learning)|0|
|[Unleashing the Retrieval Potential of Large Language Models in Conversational Recommender Systems](https://doi.org/10.1145/3640457.3688146)|Ting Yang, Li Chen|Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China|Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through interactive natural language interaction. The recent advent of large language models (LLMs) has revolutionized human engagement in natural conversation, driven by their extensive world knowledge and remarkable natural language understanding and generation capabilities. However, introducing LLMs into CRSs presents new technical challenges. Directly prompting LLMs for recommendation generation requires understanding a large and evolving item corpus, as well as grounding the generated recommendations in the real item space. On the other hand, generating recommendations based on external recommendation engines or directly integrating their suggestions into responses may constrain the overall performance of LLMs, since these engines generally have inferior representation abilities compared to LLMs. To address these challenges, we propose an end-to-end large-scale CRS model, named as ReFICR, a novel LLM-enhanced conversational recommender that empowers a retrievable large language model to perform conversational recommendation by following retrieval and generation instructions through lightweight tuning. By decomposing the complex CRS task into multiple subtasks, we formulate these subtasks into two types of instruction formats: retrieval and generation. The hidden states of ReFICR are utilized for generating text embeddings for retrieval, and simultaneously ReFICR is fine-tuned to handle generation subtasks. We optimize the contrastive objective to enhance text embeddings for retrieval and jointly fine-tune the large language model objective for generation. Our experimental results on public datasets demonstrate that ReFICR significantly outperforms baselines in terms of recommendation accuracy and response quality. Our code is publicly available at the link: https://github.com/yt556677/ReFICR.|对话推荐系统（CRSs）旨在通过交互式的自然语言对话捕捉用户偏好并提供个性化推荐。最近，大型语言模型（LLMs）的出现彻底改变了人类在自然对话中的参与方式，这得益于其广泛的世界知识和卓越的自然语言理解与生成能力。然而，将LLMs引入CRSs也带来了新的技术挑战。直接通过提示LLMs生成推荐需要理解庞大且不断变化的项目语料库，并将生成的推荐与实际项目空间相连接。另一方面，基于外部推荐引擎生成推荐或将其建议直接集成到响应中可能会限制LLMs的整体性能，因为这些引擎的表示能力通常不如LLMs。为了解决这些挑战，我们提出了一种端到端的大规模CRS模型，名为ReFICR，这是一种新型的LLM增强的对话推荐系统，通过轻量级调优使可检索的大型语言模型能够通过遵循检索和生成指令来执行对话推荐。通过将复杂的CRS任务分解为多个子任务，我们将这些子任务制定为两种指令格式：检索和生成。ReFICR的隐藏状态用于生成检索所需的文本嵌入，同时ReFICR经过微调以处理生成子任务。我们优化对比目标以增强检索的文本嵌入，并联合微调大型语言模型的目标以进行生成。我们在公开数据集上的实验结果表明，ReFICR在推荐准确性和响应质量方面显著优于基线模型。我们的代码可在以下链接公开获取：https://github.com/yt556677/ReFICR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unleashing+the+Retrieval+Potential+of+Large+Language+Models+in+Conversational+Recommender+Systems)|0|
|[Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other?](https://doi.org/10.1145/3640457.3688123)|Gustavo Penha, Ali Vardasbi, Enrico Palumbo, Marco De Nadai, Hugues Bouchard|Spotify, Copenhagen, Denmark; Spotify, Milan, Italy; Spotify, Madrid, Spain; Spotify, Amsterdam, Netherlands|Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the breakthroughs of Large Language Models (LLMs), these generative systems can play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items learned by generative recommenders are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.|生成式检索在搜索和推荐领域是一种具有前景的检索范式，它为依赖外部索引和最近邻搜索的传统方法提供了一种替代方案。与这些传统方法不同，生成模型直接将输入与项目ID关联起来。鉴于大语言模型（LLMs）的突破性进展，这些生成系统可以在一个单一模型中集中处理多种信息检索（IR）任务，包括查询理解、检索、推荐、解释、重排序和响应生成等。尽管这种统一的生成式方法在IR系统中引起了越来越多的兴趣，但在文献中，使用单一的多任务模型相较于多个专门模型的优势尚未得到充分验证。本文探讨了在搜索和推荐这两类广泛共存于多个工业在线平台（如Spotify、YouTube和Netflix）的IR任务中，这种统一方法是否以及何时能够超越特定任务模型。先前的研究表明：（1）生成式推荐器学习到的项目潜在表示偏向于流行度；（2）基于内容和基于协同过滤的信息可以改善项目的表示。受此启发，我们的研究基于两个假设进行：[H1]联合训练能够规范化每个项目流行度的估计；[H2]联合训练能够规范化项目的潜在表示，其中搜索捕捉项目的基于内容的特性，而推荐捕捉基于协同过滤的特性。我们通过模拟数据和真实数据的广泛实验验证了[H1]和[H2]是统一搜索和推荐生成模型相较于单任务方法在效果提升中的关键贡献因素。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Search+and+Recommendation+in+Generative+Retrieval:+Does+One+Task+Help+the+Other?)|0|
|[Neighborhood-Based Collaborative Filtering for Conversational Recommendation](https://doi.org/10.1145/3640457.3688191)|Zhouhang Xie, Junda Wu, Hyunsik Jeon, Zhankui He, Harald Steck, Rahul Jha, Dawen Liang, Nathan Kallus, Julian J. McAuley|Netflix Inc, Los Gatos, CA USA; Univ Calif San Diego, La Jolla, CA 92093 USA|Conversational recommender systems (CRS) should understand users’ expressed interests, which are frequently semantically rich and knowledge-intensive. Prior works attempt to address this challenge by using external knowledge bases or parametric knowledge in large language models (LLMs). In this paper, we study a complementary solution, exploiting item knowledge in the training data. We hypothesize that many inference-time user requests can be answered by reusing popular crowd-written answers associated with similar training queries. Following this intuition, we define a class of neighborhood-based CRS that makes recommendations by identifying items commonly associated with similar training dialogue contexts. Experiments on Inspired, Redial, and Reddit-Movie benchmarks show our method outperforms state-of-the-art LLMs with 2 billion parameters, and offers on-par performance to 7 billion parameter models while using over 170 times less GPU memory. We also show neighborhood and model-based predictions can be combined to achieve further performance improvements1.|对话推荐系统（CRS）需要理解用户表达的兴趣，这些兴趣通常具有丰富的语义和知识密集性。先前的研究尝试通过使用外部知识库或大型语言模型（LLMs）中的参数化知识来解决这一挑战。在本文中，我们研究了一种互补的解决方案，即利用训练数据中的项目知识。我们假设许多推理时的用户请求可以通过重用与类似训练查询相关的流行群体编写的答案来回答。基于这一直觉，我们定义了一类基于邻域的CRS，它通过识别与类似训练对话上下文相关的常见项目来进行推荐。在Inspired、Redial和Reddit-Movie基准测试上的实验表明，我们的方法优于具有20亿参数的最先进LLMs，并且在性能上与70亿参数模型相当，同时使用的GPU内存减少了170倍以上。我们还展示了邻域和基于模型的预测可以结合起来，以进一步实现性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighborhood-Based+Collaborative+Filtering+for+Conversational+Recommendation)|0|
|[Enhancing Sequential Music Recommendation with Personalized Popularity Awareness](https://doi.org/10.1145/3640457.3691719)|Davide Abbattista, Vito Walter Anelli, Tommaso Di Noia, Craig MacDonald, Aleksandr Vladimirovich Petrov|Politecn Bari, Bari, Italy; Univ Glasgow, Glasgow, Lanark, Scotland|In the realm of music recommendation, sequential recommender systems have shown promise in capturing the dynamic nature of music consumption. Nevertheless, traditional Transformer-based models, such as SASRec and BERT4Rec, while effective, encounter challenges due to the unique characteristics of music listening habits. In fact, existing models struggle to create a coherent listening experience due to rapidly evolving preferences. Moreover, music consumption is characterized by a prevalence of repeated listening, i.e. users frequently return to their favourite tracks, an important signal that could be framed as individual or personalized popularity. This paper addresses these challenges by introducing a novel approach that incorporates personalized popularity information into sequential recommendation. By combining user-item popularity scores with model-generated scores, our method effectively balances the exploration of new music with the satisfaction of user preferences. Experimental results demonstrate that a Personalized Most Popular recommender, a method solely based on user-specific popularity, outperforms existing state-of-the-art models. Furthermore, augmenting Transformer-based models with personalized popularity awareness yields superior performance, showing improvements ranging from 25.2% to 69.8%. The code for this paper is available at https://github.com/sisinflab/personalized-popularity-awareness.|在音乐推荐领域，序列推荐系统在捕捉音乐消费的动态特性方面展现出潜力。然而，尽管基于Transformer的传统模型（如SASRec和BERT4Rec）在推荐效果上表现优异，但由于音乐收听习惯的独特性，这些模型仍面临一些挑战。事实上，现有模型在用户偏好快速变化的情况下难以提供连贯的收听体验。此外，音乐消费的一个显著特点是重复收听行为的高频出现，即用户经常返回他们喜爱的曲目，这一重要信号可以被视为个体化或个性化的流行度。本文通过引入一种新颖的方法来解决这些挑战，该方法将个性化流行度信息融入序列推荐中。通过将用户-项目流行度得分与模型生成得分相结合，我们的方法有效地平衡了新音乐的探索与用户偏好的满足。实验结果表明，仅基于用户特定流行度的个性化最流行推荐器（Personalized Most Popular recommender）优于现有的最先进模型。此外，通过在基于Transformer的模型中融入个性化流行度感知，性能得到了显著提升，改进幅度在25.2%至69.8%之间。本文的代码可在https://github.com/sisinflab/personalized-popularity-awareness获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Sequential+Music+Recommendation+with+Personalized+Popularity+Awareness)|0|
|[GenUI(ne) CRS: UI Elements and Retrieval-Augmented Generation in Conversational Recommender Systems with LLMs](https://doi.org/10.1145/3640457.3691697)|Ulysse Maes, Lien Michiels, Annelien Smets|Vrije Univ Brussel, IMEC, SMIT, Brussels, Belgium|Previous research has used Large Language Models (LLMs) to develop personalized Conversational Recommender Systems (CRS) with text-based user interfaces (UIs). However, the potential of LLMs to generate interactive graphical elements that enhance user experience remains largely unexplored. To address this gap, we introduce "GenUI(ne) CRS," a novel framework designed to leverage LLMs for adaptive and interactive UIs. Our framework supports domain-specific graphical elements such as buttons and cards, in addition to text-based inputs. It also addresses the common LLM issue of outdated knowledge, known as the "knowledge cut-off," by implementing Retrieval-Augmented Generation (RAG). To illustrate its potential, we developed a prototype movie CRS. This work demonstrates the feasibility of LLM-powered interactive UIs and paves the way for future CRS research, including user experience validation, transparent explanations, and addressing LLM biases.|先前的研究已经利用大型语言模型（LLMs）开发了基于文本用户界面（UI）的个性化对话推荐系统（CRS）。然而，LLMs在生成增强用户体验的交互式图形元素方面的潜力在很大程度上尚未被探索。为了填补这一空白，我们引入了“GenUI(ne) CRS”，这是一个新颖的框架，旨在利用LLMs实现自适应和交互式的UI。我们的框架除了支持基于文本的输入外，还支持特定领域的图形元素，如按钮和卡片。它还通过实施检索增强生成（RAG）来解决LLMs常见的知识过时问题，即“知识截止”问题。为了展示其潜力，我们开发了一个原型电影CRS。这项工作证明了LLM驱动的交互式UI的可行性，并为未来的CRS研究铺平了道路，包括用户体验验证、透明解释以及解决LLM偏见等问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GenUI(ne)+CRS:+UI+Elements+and+Retrieval-Augmented+Generation+in+Conversational+Recommender+Systems+with+LLMs)|0|
|[Biased User History Synthesis for Personalized Long-Tail Item Recommendation](https://doi.org/10.1145/3640457.3688141)|Keshav Balasubramanian, Abdulla Alshabanah, Elan Markowitz, Greg Ver Steeg, Murali Annavaram|Univ Calif Riverside, Riverside, CA 92521 USA; Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA USA; Univ Southern Calif, Los Angeles, CA 90007 USA|Recommendation systems connect users to items and create value chains in the internet economy. Recommendation systems learn from past user-item interaction histories. As such, items that have short interaction histories, either because they are new or not popular, have been shown to be disproportionately under-recommended. This long-tail item problem can exacerbate model bias, and reinforce poor recommendation of tail items. In this paper, we propose biased user history synthesis, to not only address this problem but also achieve better personalization in recommendation systems. As a result, we concurrently improve tail and head item recommendation performance. Our approach is built on a tail item biased User Interaction History (UIH) sampling strategy and a synthesis model that produces an augmented user representation from the sampled user history. We provide a theoretical justification for our approach using information theory and demonstrate through extensive experimentation, that our model outperforms state-of-the-art baselines on tail, head, and overall recommendation. The source code is available at https://github.com/lkp411/BiasedUserHistorySynthesis.|推荐系统在互联网经济中连接用户与项目，并创造价值链。推荐系统通过过去用户与项目交互的历史进行学习。因此，对于那些交互历史较短的项目，无论是由于它们是新项目还是不受欢迎，都显示出被推荐的比例明显偏低。这种长尾项目问题可能会加剧模型偏差，并进一步强化对尾部项目的推荐不足。在本文中，我们提出了有偏用户历史合成方法，不仅解决了这一问题，还在推荐系统中实现了更好的个性化。因此，我们同时提高了尾部项目和头部项目的推荐性能。我们的方法基于一种尾部项目有偏的用户交互历史（UIH）采样策略，以及一个从采样用户历史中生成增强用户表示的合成模型。我们使用信息论为我们的方法提供了理论依据，并通过大量实验证明，我们的模型在尾部、头部以及整体推荐性能上优于现有的最先进基线模型。源代码可在 https://github.com/lkp411/BiasedUserHistorySynthesis 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Biased+User+History+Synthesis+for+Personalized+Long-Tail+Item+Recommendation)|0|
|[SeCor: Aligning Semantic and Collaborative Representations by Large Language Models for Next-Point-of-Interest Recommendations](https://doi.org/10.1145/3640457.3688124)|Shirui Wang, Bohan Xie, Ling Ding, Xiaoying Gao, Jianting Chen, Yang Xiang|Tongji Univ, Shanghai, Peoples R China|The widespread adoption of location-based applications has created a growing demand for point-of-interest (POI) recommendation, which aims to predict a user’s next POI based on their historical check-in data and current location. However, existing methods often struggle to capture the intricate relationships within check-in data. This is largely due to their limitations in representing temporal and spatial information and underutilizing rich semantic features. While large language models (LLMs) offer powerful semantic comprehension to solve them, they are limited by hallucination and the inability to incorporate global collaborative information. To address these issues, we propose a novel method SeCor, which treats POI recommendation as a multi-modal task and integrates semantic and collaborative representations to form an efficient hybrid encoding. SeCor first employs a basic collaborative filtering model to mine interaction features. These embeddings, as one modal information, are fed into LLM to align with semantic representation, leading to efficient hybrid embeddings. To mitigate the hallucination, SeCor recommends based on the hybrid embeddings rather than directly using the LLM’s output text. Extensive experiments on three public real-world datasets show that SeCor outperforms all baselines, achieving improved recommendation performance by effectively integrating collaborative and semantic information through LLMs.|基于位置应用的广泛普及催生了对兴趣点（POI）推荐日益增长的需求，该推荐旨在根据用户的历史签到数据和当前位置预测其下一个POI。然而，现有方法在捕捉签到数据中的复杂关系方面往往存在困难。这主要是由于它们在表示时间和空间信息方面的局限性以及对丰富语义特征的利用不足。虽然大型语言模型（LLMs）提供了强大的语义理解能力来解决这些问题，但它们受到幻觉问题和无法整合全局协作信息的限制。为了应对这些问题，我们提出了一种名为SeCor的新方法，该方法将POI推荐视为多模态任务，并整合语义和协作表示以形成高效的混合编码。SeCor首先采用基本的协同过滤模型来挖掘交互特征。这些嵌入作为一种模态信息被输入到LLM中，以与语义表示对齐，从而生成高效的混合嵌入。为了减轻幻觉问题，SeCor基于混合嵌入进行推荐，而不是直接使用LLM的输出文本。在三个公开的真实世界数据集上进行的大量实验表明，SeCor在所有基线方法中表现优异，通过LLM有效整合协作和语义信息，实现了推荐性能的提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SeCor:+Aligning+Semantic+and+Collaborative+Representations+by+Large+Language+Models+for+Next-Point-of-Interest+Recommendations)|0|
|[Dynamic Stage-aware User Interest Learning for Heterogeneous Sequential Recommendation](https://doi.org/10.1145/3640457.3688103)|Weixin Li, Xiaolin Lin, Weike Pan, Zhong Ming|Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China; Shenzhen Univ, Shenzhen, Peoples R China|Sequential recommendation has been widely used to predict users’ potential preferences by learning their dynamic user interests, for which most previous methods focus on capturing item-level dependencies. Despite the great success, they often overlook the stage-level interest dependencies. In real-world scenarios, user interests tend to be staged, e.g., following an item purchase, a user’s interests may undergo a transition into the subsequent phase. And there are intricate dependencies across different stages. Meanwhile, users’ behaviors are usually heterogeneous, including auxiliary behaviors (e.g., examinations) and target behaviors (e.g., purchases), which imply more fine-grained user interests. However, existing methods have limitations in explicitly modeling the relationships between the different types of behaviors. To address the above issues, we propose a novel framework, i.e., dynamic stage-aware user interest learning (DSUIL), for heterogeneous sequential recommendation, which is the first solution to model user interests in a cross-stage manner. Specifically, our DSUIL consists of four modules: (1) a dynamic graph construction module transforms a heterogeneous sequence into several subgraphs to model user interests in a stage-wise manner; (2) a dynamic graph convolution module dynamically learns item representations in each subgraph; (3) a behavior-aware subgraph representation learning module learns the heterogeneous dependencies between behaviors and aggregates item representations to represent the staged user interests; and (4) an interest evolving pattern extractor learns the users’ overall interests for the item prediction. Extensive experimental results on two public datasets show that our DSUIL performs significantly better than the state-of-the-art methods.|序列推荐通过学习用户的动态兴趣来预测其潜在偏好，已在广泛应用中取得了显著成效。以往的方法大多侧重于捕捉物品级别的依赖关系。尽管这些方法取得了巨大成功，但它们往往忽视了阶段级别的兴趣依赖关系。在现实场景中，用户的兴趣往往是分阶段的，例如，在购买某件物品后，用户的兴趣可能会过渡到下一个阶段。同时，不同阶段之间存在复杂的依赖关系。此外，用户的行为通常是异质的，包括辅助行为（如浏览）和目标行为（如购买），这些行为暗示了更细粒度的用户兴趣。然而，现有方法在显式建模不同类型行为之间的关系方面存在局限性。

为了解决上述问题，我们提出了一种新颖的框架，即**动态阶段感知用户兴趣学习（DSUIL）**，用于异质序列推荐。这是首个以跨阶段方式建模用户兴趣的解决方案。具体而言，我们的DSUIL框架包含四个模块：(1) **动态图构建模块**将异质序列转换为若干子图，以分阶段的方式建模用户兴趣；(2) **动态图卷积模块**动态学习每个子图中的物品表示；(3) **行为感知子图表示学习模块**学习行为之间的异质依赖关系，并聚合物品表示以表征分阶段的用户兴趣；(4) **兴趣演化模式提取器**学习用户的整体兴趣，用于物品预测。在两个公开数据集上的大量实验结果表明，我们的DSUIL框架显著优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Stage-aware+User+Interest+Learning+for+Heterogeneous+Sequential+Recommendation)|0|
|[Bootstrapping Conditional Retrieval for User-to-Item Recommendations](https://doi.org/10.1145/3640457.3688057)|Hongtao Lin, Haoyu Chen, Jaewon Yang, Jiajing Xu|Pinterest, San Francisco, CA 94107 USA|User-to-item retrieval has been an active research area in recommendation system, and two tower models are widely adopted due to model simplicity and serving efficiency. In this work, we focus on a variant called conditional retrieval, where we expect retrieved items to be relevant to a condition (e.g. topic). We propose a method that uses the same training data as standard two tower models but incorporates item-side information as conditions in query. This allows us to bootstrap new conditional retrieval use cases and encourages feature interactions between user and condition. Experiments show that our method can retrieve highly relevant items and outperforms standard two tower models with filters on engagement metrics. The proposed model is deployed to power a topic-based notification feed at Pinterest and led to +0.26% weekly active users.|用户到物品的检索一直是推荐系统中的一个活跃研究领域，双塔模型因其模型简单和服务效率高而被广泛采用。在本研究中，我们关注一种称为条件检索的变体，其中我们希望检索到的物品与某个条件（例如主题）相关。我们提出了一种方法，该方法使用与标准双塔模型相同的训练数据，但在查询中引入物品侧信息作为条件。这使得我们能够引导新的条件检索用例，并促进用户与条件之间的特征交互。实验表明，我们的方法能够检索到高度相关的物品，并在参与度指标上优于带有过滤器的标准双塔模型。所提出的模型已部署在Pinterest中，用于支持基于主题的通知流，并导致每周活跃用户增加了0.26%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bootstrapping+Conditional+Retrieval+for+User-to-Item+Recommendations)|0|
|[Do Not Wait: Learning Re-Ranking Model Without User Feedback At Serving Time in E-Commerce](https://doi.org/10.1145/3640457.3688165)|Yuan Wang, Zhiyu Li, Changshuo Zhang, Sirui Chen, Xiao Zhang, Jun Xu, Quan Lin|Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Alibaba Grp, Hangzhou, Zhejiang, Peoples R China; Renmin Univ China, Sch Informat, Beijing, Peoples R China|Recommender systems have been widely used in e-commerce, and re-rankingmodels are playing an increasingly significant role in the domain, whichleverages the inter-item influence and determines the final recommendationlists. Online learning methods keep updating a deployed model with the latestavailable samples to capture the shifting of the underlying data distributionin e-commerce. However, they depend on the availability of real user feedback,which may be delayed by hours or even days, such as item purchases, leading toa lag in model enhancement. In this paper, we propose a novel extension ofonline learning methods for re-ranking modeling, which we term LAST, an acronymfor Learning At Serving Time. It circumvents the requirement of user feedbackby using a surrogate model to provide the instructional signal needed to steermodel improvement. Upon receiving an online request, LAST finds and applies amodel modification on the fly before generating a recommendation result for therequest. The modification is request-specific and transient. It means themodification is tailored to and only to the current request to capture thespecific context of the request. After a request, the modification isdiscarded, which helps to prevent error propagation and stabilizes the onlinelearning procedure since the predictions of the surrogate model may beinaccurate. Most importantly, as a complement to feedback-based online learningmethods, LAST can be seamlessly integrated into existing online learningsystems to create a more adaptive and responsive recommendation experience.Comprehensive experiments, both offline and online, affirm that LASToutperforms state-of-the-art re-ranking models.|推荐系统在电子商务中得到了广泛应用，而重排序模型在该领域正发挥着越来越重要的作用。重排序模型通过利用商品间的影响力来确定最终的推荐列表。在线学习方法通过不断使用最新可用的样本来更新已部署的模型，以捕捉电子商务中潜在数据分布的变化。然而，这些方法依赖于真实用户反馈的可用性，而这些反馈（如商品购买）可能会延迟数小时甚至数天，从而导致模型增强的滞后。本文提出了一种新颖的在线学习方法扩展，用于重排序建模，我们将其称为LAST，即“在服务时学习”（Learning At Serving Time）的缩写。LAST通过使用替代模型提供指导信号来规避用户反馈的需求，从而引导模型改进。在接收到在线请求时，LAST会在生成推荐结果之前动态地找到并应用模型修改。这种修改是特定于请求且临时的，意味着修改是针对且仅针对当前请求的，以捕捉请求的特定上下文。请求结束后，修改将被丢弃，这有助于防止错误传播并稳定在线学习过程，因为替代模型的预测可能不准确。最重要的是，作为基于反馈的在线学习方法的补充，LAST可以无缝集成到现有的在线学习系统中，以创建更具适应性和响应性的推荐体验。全面的离线和在线实验证实，LAST优于最先进的重排序模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+Not+Wait:+Learning+Re-Ranking+Model+Without+User+Feedback+At+Serving+Time+in+E-Commerce)|0|
|[FairCRS: Towards User-oriented Fairness in Conversational Recommendation Systems](https://doi.org/10.1145/3640457.3688150)|Qin Liu, Xuan Feng, Tianlong Gu, Xiaoli Liu|Jinan Univ, Engn Res Ctr Trustworthy AI, Minist Educ, Guangzhou, Guangdong, Peoples R China|Conversational Recommendation Systems (CRSs) enable recommender systems to explicitly acquire user preferences during multi-turn interactions, providing more accurate and personalized recommendations. However, the data imbalance in CRSs, due to inconsistent interaction history among users, may lead to disparate treatment for disadvantaged user groups. In this paper, we investigate the discriminate problems in CRS from the user’s perspective, called as user-oriented fairness. To reveal the unfairness problems of different user groups in CRS, we conduct extensive empirical analyses. To mitigate user unfairness, we propose a user-oriented fairness framework, named FairCRS, which is a model-agnostic framework. In particular, we develop a user-embedding reconstruction mechanism that enriches user embeddings by incorporating more interaction information, and design a user-oriented fairness strategy that optimizes the recommendation quality differences among user groups while alleviating unfairness. Extensive experimental results on English and Chinese datasets show that FairCRS outperforms state-of-the-art CRSs in terms of overall recommendation performance and user fairness.|对话推荐系统（Conversational Recommendation Systems, CRSs）通过在多轮交互中显式获取用户偏好，能够提供更加准确和个性化的推荐。然而，由于用户之间交互历史的不一致性，CRS中的数据不平衡可能导致对弱势用户群体的不公平对待。本文从用户角度研究了CRS中的歧视问题，称为用户导向的公平性。为了揭示CRS中不同用户群体的不公平问题，我们进行了广泛的实证分析。为了缓解用户不公平性，我们提出了一个用户导向的公平性框架，名为FairCRS，这是一个与模型无关的框架。具体而言，我们开发了一种用户嵌入重构机制，通过整合更多的交互信息来丰富用户嵌入，并设计了一种用户导向的公平性策略，在优化用户群体间推荐质量差异的同时缓解不公平性。在英文和中文数据集上的大量实验结果表明，FairCRS在整体推荐性能和用户公平性方面优于现有的最先进CRS。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairCRS:+Towards+User-oriented+Fairness+in+Conversational+Recommendation+Systems)|0|
|[Low Rank Field-Weighted Factorization Machines for Low Latency Item Recommendation](https://doi.org/10.1145/3640457.3688097)|Alex Shtoff, Michael Viderman, Naama HaramatyKrasne, Oren Somekh, Ariel Raviv, Tularam Ban|Yahoo Res, London, England|Factorization machine (FM) variants are widely used in recommendation systems that operate under strict throughput and latency requirements, such as online advertising systems. FMs have two prominent strengths. First, is their ability to model pairwise feature interactions while being resilient to data sparsity by learning factorized representations. Second, their computational graphs facilitate fast inference and training. Moreover, when items are ranked as a part of a query for each incoming user, these graphs facilitate computing the portion stemming from the user and context fields only once per query. Thus, the computational cost for each ranked item is proportional only to the number of fields that vary among the ranked items. Consequently, in terms of inference cost, the number of user or context fields is practically unlimited. More advanced variants of FMs, such as field-aware and field-weighted FMs, provide better accuracy by learning a representation of field-wise interactions, but require computing all pairwise interaction terms explicitly. In particular, the computational cost during inference is proportional to the square of the number of fields, including user, context, and item. When the number of fields is large, this is prohibitive in systems with strict latency constraints, and imposes a limit on the number of user and context fields for a given computational budget. To mitigate this caveat, heuristic pruning of low intensity field interactions is commonly used to accelerate inference. In this work we propose an alternative to the pruning heuristic in field-weighted FMs using a diagonal plus symmetric low-rank decomposition. Our technique reduces the computational cost of inference, by allowing it to be proportional to the number of item fields only. Using a set of experiments on real-world datasets, we show that aggressive rank reduction outperforms similarly aggressive pruning in both accuracy and item recommendation speed. Beyond computational complexity analysis, we corroborate our claim of faster inference experimentally, both via a synthetic test, and by having deployed our solution to a major online advertising system, where we observed significant ranking latency improvements. We have made the code to reproduce the results on public datasets and synthetic tests available at https://github.com/michaelviderman/pytorch-fm.|因子分解机（FM）的变体广泛应用于在严格的吞吐量和延迟要求下运行的推荐系统中，例如在线广告系统。FM有两个显著的优点。首先，它们能够通过因式分解表示来建模特征之间的成对交互，同时对数据稀疏性具有鲁棒性。其次，它们的计算图有利于快速推理和训练。此外，当项目作为每个新用户的查询的一部分进行排序时，这些计算图有助于仅对用户和上下文字段进行一次计算。因此，每个排序项目的计算成本仅与排序项目之间变化的字段数量成比例。因此，就推理成本而言，用户或上下文字段的数量实际上是无限制的。更高级的FM变体，如字段感知和字段加权的FM，通过学习字段间交互的表示提供了更好的准确性，但需要显式计算所有成对交互项。特别是，推理期间的计算成本与字段数量的平方成比例，包括用户、上下文和项目字段。当字段数量较大时，这在具有严格延迟约束的系统中是不可行的，并且对于给定的计算预算，限制了用户和上下文字段的数量。为了缓解这一问题，通常使用低强度字段交互的启发式剪枝来加速推理。在本研究中，我们提出了一种替代字段加权FM中剪枝启发式方法的方法，即使用对角加对称低秩分解。我们的技术通过使推理成本仅与项目字段数量成比例来降低推理的计算成本。通过在真实世界数据集上进行的一系列实验，我们展示了在准确性和项目推荐速度方面，激进的秩减少优于同样激进的剪枝。除了计算复杂性分析外，我们还通过合成测试和将我们的解决方案部署到一个主要的在线广告系统中，实验性地证实了我们关于更快推理的主张，并观察到了显著的排序延迟改进。我们已在https://github.com/michaelviderman/pytorch-fm上提供了用于在公共数据集和合成测试上重现结果的代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low+Rank+Field-Weighted+Factorization+Machines+for+Low+Latency+Item+Recommendation)|0|
|[MLoRA: Multi-Domain Low-Rank Adaptive Network for CTR Prediction](https://doi.org/10.1145/3640457.3688134)|Zhiming Yang, Haining Gao, Dehong Gao, Luwei Yang, Libin Yang, Xiaoyan Cai, Wei Ning, Guannan Zhang||Click-through rate (CTR) prediction is one of the fundamental tasks in the industry, especially in e-commerce, social media, and streaming media. It directly impacts website revenues, user satisfaction, and user retention. However, real-world production platforms often encompass various domains to cater for diverse customer needs. Traditional CTR prediction models struggle in multi-domain recommendation scenarios, facing challenges of data sparsity and disparate data distributions across domains. Existing multi-domain recommendation approaches introduce specific-domain modules for each domain, which partially address these issues but often significantly increase model parameters and lead to insufficient training. In this paper, we propose a Multi-domain Low-Rank Adaptive network (MLoRA) for CTR prediction, where we introduce a specialized LoRA module for each domain. This approach enhances the model's performance in multi-domain CTR prediction tasks and is able to be applied to various deep-learning models. We evaluate the proposed method on several multi-domain datasets. Experimental results demonstrate our MLoRA approach achieves a significant improvement compared with state-of-the-art baselines. Furthermore, we deploy it in the production environment of the Alibaba.COM. The online A/B testing results indicate the superiority and flexibility in real-world production environments. The code of our MLoRA is publicly available.|点击率（CTR）预测是工业界的一项基础任务，尤其在电子商务、社交媒体和流媒体领域。它直接影响网站收入、用户满意度和用户留存率。然而，现实世界的生产平台通常涵盖多个领域，以满足不同客户的需求。传统的CTR预测模型在多领域推荐场景中表现不佳，面临数据稀疏性和跨领域数据分布差异的挑战。现有的多领域推荐方法为每个领域引入了特定领域的模块，虽然部分解决了这些问题，但通常会显著增加模型参数并导致训练不足。在本文中，我们提出了一种用于CTR预测的多领域低秩自适应网络（MLoRA），其中我们为每个领域引入了一个专门的LoRA模块。这种方法增强了模型在多领域CTR预测任务中的性能，并且能够应用于各种深度学习模型。我们在多个多领域数据集上评估了所提出的方法。实验结果表明，与最先进的基线方法相比，我们的MLoRA方法取得了显著的改进。此外，我们在阿里巴巴国际站的生产环境中部署了该方法。在线A/B测试结果表明了它在实际生产环境中的优越性和灵活性。我们的MLoRA代码已公开提供。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MLoRA:+Multi-Domain+Low-Rank+Adaptive+Network+for+CTR+Prediction)|0|
|[Utilizing Non-click Samples via Semi-supervised Learning for Conversion Rate Prediction](https://doi.org/10.1145/3640457.3688151)|Jiahui Huang, Lan Zhang, Junhao Wang, Shanyang Jiang, Dongbo Huang, Cheng Ding, Lan Xu|Tencent, Shanghai, Peoples R China; Univ Sci & Technol China, Hefei, Anhui, Peoples R China|Conversion rate (CVR) prediction is essential in recommender systems, facilitating precise matching between recommended items and users’ preferences. However, the sample selection bias (SSB) and data sparsity (DS) issues pose challenges to accurate prediction. Existing works have proposed the click-through and conversion rate (CTCVR) prediction task which models samples from exposure to ``click and conversion" in entire space and incorporates multi-task learning. This approach has shown efficacy in mitigating these challenges. Nevertheless, it intensifies the false negative sample (FNS) problem. To be more specific, the CTCVR task implicitly treats all the CVR labels of non-click samples as negative, overlooking the possibility that some samples might convert if clicked. This oversight can negatively impact CVR model performance, as empirical analysis has confirmed. To this end, we advocate for discarding the CTCVR task and proposing a Non-click samples Improved Semi-supErvised (NISE) method for conversion rate prediction, where the non-click samples are treated as unlabeled. Our approach aims to predict their probabilities of conversion if clicked, utilizing these predictions as pseudo-labels for further model training. This strategy can help alleviate the FNS problem, and direct modeling of the CVR task across the entire space also mitigates the SSB and DS challenges. Additionally, we conduct multi-task learning by introducing an auxiliary click-through rate prediction task, thereby enhancing embedding layer representations. Our approach is applicable to various multi-task architectures. Comprehensive experiments are conducted on both public and production datasets, demonstrating the superiority of our proposed method in mitigating the FNS challenge and improving the CVR estimation. The implementation code is available at https://github.com/Hjh233/NISE.|转化率（CVR）预测在推荐系统中至关重要，它有助于实现推荐物品与用户偏好的精确匹配。然而，样本选择偏差（SSB）和数据稀疏性（DS）问题对准确预测提出了挑战。现有的研究工作提出了点击转化率（CTCVR）预测任务，该任务在整个空间中从曝光到“点击和转化”对样本进行建模，并结合了多任务学习。这种方法在缓解这些挑战方面显示出有效性。然而，它加剧了假阴性样本（FNS）问题。具体来说，CTCVR任务隐含地将所有未点击样本的CVR标签视为负样本，忽略了某些样本在被点击后可能转化的可能性。实证分析已证实，这种忽视会对CVR模型的性能产生负面影响。为此，我们主张摒弃CTCVR任务，并提出一种针对未点击样本的改进半监督（NISE）方法用于转化率预测，其中未点击样本被视为未标记样本。我们的方法旨在预测这些样本在被点击后的转化概率，并利用这些预测作为伪标签进行进一步的模型训练。这一策略有助于缓解FNS问题，同时在整个空间中直接对CVR任务进行建模也缓解了SSB和DS挑战。此外，我们通过引入辅助的点击率预测任务进行多任务学习，从而增强嵌入层的表示能力。我们的方法适用于各种多任务架构。我们在公开数据集和生产数据集上进行了全面的实验，结果表明所提出的方法在缓解FNS挑战和改进CVR估计方面具有优越性。实现代码可在https://github.com/Hjh233/NISE 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Utilizing+Non-click+Samples+via+Semi-supervised+Learning+for+Conversion+Rate+Prediction)|0|
|[A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios](https://doi.org/10.1145/3640457.3688138)|Christian Ganhör, Marta Moscati, Anna Hausberger, Shah Nawaz, Markus Schedl|Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria|Most recommender systems adopt collaborative filtering (CF) and provide recommendations based on past collective interactions. Therefore, the performance of CF algorithms degrades when few or no interactions are available, a scenario referred to as cold-start. To address this issue, previous work relies on models leveraging both collaborative data and side information on the users or items. Similar to multimodal learning, these models aim at combining collaborative and content representations in a shared embedding space. In this work we propose a novel technique for multimodal recommendation, relying on a multimodal Single-Branch embedding network for Recommendation (SiBraR). Leveraging weight-sharing, SiBraR encodes interaction data as well as multimodal side information using the same single-branch embedding network on different modalities. This makes SiBraR effective in scenarios of missing modality, including cold start. Our extensive experiments on large-scale recommendation datasets from three different recommendation domains (music, movie, and e-commerce) and providing multimodal content information (audio, text, image, labels, and interactions) show that SiBraR significantly outperforms CF as well as state-of-the-art content-based RSs in cold-start scenarios, and is competitive in warm scenarios. We show that SiBraR's recommendations are accurate in missing modality scenarios, and that the model is able to map different modalities to the same region of the shared embedding space, hence reducing the modality gap.|大多数推荐系统采用协同过滤（Collaborative Filtering, CF）方法，并基于过去的集体交互行为提供推荐。因此，当交互数据很少或没有时，CF算法的性能会下降，这种情况被称为冷启动问题。为了解决这一问题，先前的研究依赖于同时利用协同数据和用户或物品的辅助信息的模型。与多模态学习类似，这些模型旨在将协同表示和内容表示结合到一个共享的嵌入空间中。在本研究中，我们提出了一种新的多模态推荐技术，基于一种名为**单分支嵌入网络推荐模型（SiBraR）**的多模态方法。通过权重共享，SiBraR 使用相同的单分支嵌入网络对不同模态的交互数据和多模态辅助信息进行编码。这使得 SiBraR 在模态缺失（包括冷启动）的场景中表现出色。

我们在来自三个不同推荐领域（音乐、电影和电子商务）的大规模推荐数据集上进行了广泛的实验，这些数据集提供了多模态内容信息（音频、文本、图像、标签和交互）。实验结果表明，在冷启动场景下，SiBraR 显著优于 CF 以及当前最先进的基于内容的推荐系统（RS），并且在常规场景下也表现出竞争力。我们证明了 SiBraR 在模态缺失场景下的推荐是准确的，并且该模型能够将不同模态映射到共享嵌入空间的同一区域，从而减少了模态间的差异。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multimodal+Single-Branch+Embedding+Network+for+Recommendation+in+Cold-Start+and+Missing+Modality+Scenarios)|0|
|[Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs](https://doi.org/10.1145/3640457.3688140)|Gleb Mezentsev, Danil Gusak, Ivan V. Oseledets, Evgeny Frolov|HSE Univ, Moscow, Russia; Skolkovo Inst Sci & Technol, Moscow, Russia; Skolkovo Inst Sci & Technol, Artificial Intelligence Res Inst, Moscow, Russia|Scalability issue plays a crucial role in productionizing modern recommender systems. Even lightweight architectures may suffer from high computational overload due to intermediate calculations, limiting their practicality in real-world applications. Specifically, applying full Cross-Entropy (CE) loss often yields state-of-the-art performance in terms of recommendations quality. Still, it suffers from excessive GPU memory utilization when dealing with large item catalogs. This paper introduces a novel Scalable Cross-Entropy (SCE) loss function in the sequential learning setup. It approximates the CE loss for datasets with large-size catalogs, enhancing both time efficiency and memory usage without compromising recommendations quality. Unlike traditional negative sampling methods, our approach utilizes a selective GPU-efficient computation strategy, focusing on the most informative elements of the catalog, particularly those most likely to be false positives. This is achieved by approximating the softmax distribution over a subset of the model outputs through the maximum inner product search. Experimental results on multiple datasets demonstrate the effectiveness of SCE in reducing peak memory usage by a factor of up to 100 compared to the alternatives, retaining or even exceeding their metrics values. The proposed approach also opens new perspectives for large-scale developments in different domains, such as large language models.|可扩展性问题在现代推荐系统的实际应用中起着至关重要的作用。即使是轻量级的架构，也可能由于中间计算过程而遭受高计算负载的困扰，从而限制了其在实际应用中的实用性。具体而言，使用完整的交叉熵（Cross-Entropy, CE）损失函数通常在推荐质量方面能够达到最先进的性能，但在处理大规模商品目录时，它会导致过高的GPU内存占用。本文在序列学习框架下引入了一种新颖的可扩展交叉熵（Scalable Cross-Entropy, SCE）损失函数。它能够在大规模商品目录的数据集上近似CE损失，在不影响推荐质量的前提下，显著提升时间效率和内存使用效率。与传统的负采样方法不同，我们的方法采用了一种选择性的GPU高效计算策略，专注于商品目录中最具信息量的元素，尤其是那些最有可能成为假阳性的元素。这是通过最大内积搜索（Maximum Inner Product Search）对模型输出的子集进行softmax分布的近似来实现的。在多个数据集上的实验结果表明，与替代方法相比，SCE能够将峰值内存使用量减少高达100倍，同时保持甚至超越其性能指标。所提出的方法还为不同领域的大规模开发（如大语言模型）开辟了新的前景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Cross-Entropy+Loss+for+Sequential+Recommendations+with+Large+Item+Catalogs)|0|
|[Transformers Meet ACT-R: Repeat-Aware and Sequential Listening Session Recommendation](https://doi.org/10.1145/3640457.3688139)|VietAnh Tran, Guillaume SalhaGalvan, Bruno Sguerra, Romain Hennequin|Deezer Res, Paris, France|Music streaming services often leverage sequential recommender systems to predict the best music to showcase to users based on past sequences of listening sessions. Nonetheless, most sequential recommendation methods ignore or insufficiently account for repetitive behaviors. This is a crucial limitation for music recommendation, as repeatedly listening to the same song over time is a common phenomenon that can even change the way users perceive this song. In this paper, we introduce PISA (Psychology-Informed Session embedding using ACT-R), a session-level sequential recommender system that overcomes this limitation. PISA employs a Transformer architecture learning embedding representations of listening sessions and users using attention mechanisms inspired by Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics. This approach enables us to capture dynamic and repetitive patterns from user behaviors, allowing us to effectively predict the songs they will listen to in subsequent sessions, whether they are repeated or new ones. We demonstrate the empirical relevance of PISA using both publicly available listening data from Last.fm and proprietary data from Deezer, a global music streaming service, confirming the critical importance of repetition modeling for sequential listening session recommendation. Along with this paper, we publicly release our proprietary dataset to foster future research in this field, as well as the source code of PISA to facilitate its future use.|音乐流媒体服务通常利用序列推荐系统，根据用户过去的听歌序列来预测最适合展示给用户的音乐。然而，大多数序列推荐方法忽视或未能充分考虑到重复行为。这对音乐推荐来说是一个关键的限制，因为随着时间的推移，重复听同一首歌是一种常见现象，甚至可能改变用户对这首歌的感知。本文中，我们提出了PISA（基于ACT-R的心理学启发的会话嵌入），这是一种会话级别的序列推荐系统，克服了这一限制。PISA采用Transformer架构，利用受安德森的ACT-R（自适应控制思维-理性）启发的注意力机制，学习听歌会话和用户的嵌入表示。ACT-R是一种模拟人类信息访问和记忆动态的认知架构。这种方法使我们能够捕捉用户行为中的动态和重复模式，从而有效预测他们在后续会话中将要听的歌曲，无论是重复的还是新的。我们使用Last.fm的公开听歌数据和全球音乐流媒体服务Deezer的专有数据，实证了PISA的相关性，证实了重复建模对于序列听歌会话推荐的重要性。随本文一起，我们公开了我们的专有数据集，以促进该领域的未来研究，并发布了PISA的源代码，以方便其未来的使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transformers+Meet+ACT-R:+Repeat-Aware+and+Sequential+Listening+Session+Recommendation)|0|
|[Embedding Optimization for Training Large-scale Deep Learning Recommendation Systems with EMBark](https://doi.org/10.1145/3640457.3688111)|Shijie Liu, Nan Zheng, Hui Kang, Xavier Simmons, Junjie Zhang, Matthias Langer, Wenjing Zhu, Minseok Lee, Zehuan Wang|NVIDIA DevTech, Beijing, Peoples R China; NVIDIA DevTech, Santa Clara, CA USA; NVIDIA DevTech, Shanghai, Peoples R China; NVIDIA, Shanghai, Peoples R China|Training large-scale deep learning recommendation models (DL-RMs) with embedding tables stretching across multiple GPUs in a cluster presents a unique challenge, demanding the efficient scaling of embedding operations that require substantial memory and network bandwidth within a hierarchical network of GPUs. To tackle this bottleneck, we introduce EMBark-a comprehensive solution aimed at enhancing embedding performance and overall DLRM training throughput at scale. EMBark empowers users to create and customize sharding strategies, and features a highly-automated sharding planner, to accelerate diverse model architectures on different cluster configurations. EMBark groups embedding tables, considering their preferred communication compression method to reduce communication overheads effectively. It embraces efficient data-parallel category distribution, combined with topology-aware hierarchical communication, and pipelining support to maximize the DLRM training throughput. Across four representative DLRM variants (DLRM-DCNv2, T180, T200, and T510), EMBark achieves an average end-to-end training throughput speedup of 1.5x and up to 1.77x over traditional table-row-wise sharding approaches.|在集群中跨多个GPU训练具有嵌入表的大规模深度学习推荐模型（DL-RMs）提出了一个独特的挑战，这要求在GPU的层次网络中高效扩展嵌入操作，这些操作需要大量的内存和网络带宽。为了解决这一瓶颈，我们引入了EMBark——一个旨在提高嵌入性能和大规模DLRM训练吞吐量的综合解决方案。EMBark使用户能够创建和定制分片策略，并配备了一个高度自动化的分片规划器，以加速不同集群配置上的多种模型架构。EMBark根据嵌入表的首选通信压缩方法对其进行分组，以有效减少通信开销。它采用了高效的数据并行类别分布，结合了拓扑感知的层次通信和流水线支持，以最大化DLRM训练吞吐量。在四种代表性的DLRM变体（DLRM-DCNv2、T180、T200和T510）中，EMBark相比传统的表行分片方法，平均端到端训练吞吐量提升了1.5倍，最高可达1.77倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+Optimization+for+Training+Large-scale+Deep+Learning+Recommendation+Systems+with+EMBark)|0|
|[Multi-Behavioral Sequential Recommendation](https://doi.org/10.1145/3640457.3688166)|Shereen Elsayed, Ahmed Rashed, Lars SchmidtThieme|Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; South China Univ Technol, Sch Comp Sci & Technol, Guangzhou 510641, Peoples R China; Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada|Modeling time-evolving preferences of users with their sequential item interactions, has attracted increasing attention in many online applications. Hence, sequential recommender systems have been developed to learn the dynamic user interests from the historical interactions for suggesting items. However, the interaction pattern encoding functions in most existing sequential recommender systems have focused on single type of user-item interactions. In many real-life online platforms, user-item interactive behaviors are often multi-typed (e.g., click, add-to-favorite, purchase) with complex cross-type behavior inter-dependencies. Learning from informative representations of users and items based on their multi-typed interaction data, is of great importance to accurately characterize the time-evolving user preference. In this work, we tackle the dynamic user-item relation learning with the awareness of multi-behavior interactive patterns. Towards this end, we propose a new Temporal Graph Transformer (TGT) recommendation framework to jointly capture dynamic short-term and long-range user-item interactive patterns, by exploring the evolving correlations across different types of behaviors. The new TGT method endows the sequential recommendation architecture to distill dedicated knowledge for type-specific behavior relational context and the implicit behavior dependencies. Experiments on the real-world datasets indicate that our method TGT consistently outperforms various state-of-the-art recommendation methods. Our model implementation codes are available at https://github.com/akaxlh/TGT.|随着用户与项目序列交互的时间演化偏好建模在众多在线应用中的重要性日益增加，序列推荐系统应运而生，旨在从历史交互中学习动态用户兴趣以推荐项目。然而，现有的大多数序列推荐系统中的交互模式编码功能主要集中在单一类型的用户-项目交互上。在许多现实生活的在线平台中，用户-项目的交互行为往往是多类型的（例如，点击、收藏、购买），并且具有复杂的跨类型行为相互依赖性。基于多类型交互数据学习用户和项目的信息表示，对于准确刻画时间演化的用户偏好至关重要。在本研究中，我们致力于解决具有多行为交互模式意识的动态用户-项目关系学习问题。为此，我们提出了一种新的时序图变换器（Temporal Graph Transformer, TGT）推荐框架，通过探索不同类型行为之间的演化相关性，共同捕捉动态的短期和长期用户-项目交互模式。新的TGT方法赋予了序列推荐架构提取特定类型行为关系上下文和隐式行为依赖性的专用知识的能力。在真实世界数据集上的实验表明，我们的TGT方法在各种最先进的推荐方法中始终表现出色。我们的模型实现代码可在https://github.com/akaxlh/TGT获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavioral+Sequential+Recommendation)|0|
|[Efficient Inference of Sub-Item Id-based Sequential Recommendation Models with Millions of Items](https://doi.org/10.1145/3640457.3688168)|Aleksandr Vladimirovich Petrov, Craig Macdonald, Nicola Tonellotto|Univ Pisa, Pisa, Italy; Univ Glasgow, Glasgow, Lanark, Scotland|Transformer-based recommender systems, such as BERT4Rec or SASRec, achieve state-of-the-art results in sequential recommendation. However, it is challenging to use these models in production environments with catalogues of millions of items: scaling Transformers beyond a few thousand items is problematic for several reasons, including high model memory consumption and slow inference. In this respect, RecJPQ is a state-of-the-art method of reducing the models' memory consumption; RecJPQ compresses item catalogues by decomposing item IDs into a small number of shared sub-item IDs. Despite reporting the reduction of memory consumption by a factor of up to 50x, the original RecJPQ paper did not report inference efficiency improvements over the baseline Transformer-based models. Upon analysing RecJPQ's scoring algorithm, we find that its efficiency is limited by its use of score accumulators for each item, which prevents parallelisation. In contrast, LightRec (a non-sequential method that uses a similar idea of sub-ids) reported large inference efficiency improvements using an algorithm we call PQTopK. We show that it is also possible to improve RecJPQ-based models' inference efficiency using the PQTopK algorithm. In particular, we speed up RecJPQ-enhanced SASRec by a factor of 4.5x compared to the original SASRec's inference method and by the factor of 1.56x compared to the method implemented in RecJPQ code on a large-scale Gowalla dataset with more than million items. Further, using simulated data, we show that PQTopK remains efficient with catalogues of up to tens of millions of items, removing one of the last obstacles to using Transformer-based models in production environments with large catalogues.|基于Transformer的推荐系统，如BERT4Rec或SASRec，在序列推荐中取得了最先进的结果。然而，在拥有数百万项物品的生产环境中使用这些模型具有挑战性：将Transformer扩展到超过几千项物品存在多个问题，包括高模型内存消耗和推理速度慢。在这方面，RecJPQ是一种减少模型内存消耗的最先进方法；RecJPQ通过将物品ID分解为少量共享的子物品ID来压缩物品目录。尽管RecJPQ论文报告了内存消耗减少高达50倍，但原始RecJPQ论文并未报告相对于基线Transformer模型的推理效率提升。通过分析RecJPQ的评分算法，我们发现其效率受到每个物品使用评分累加器的限制，这阻碍了并行化。相比之下，LightRec（一种使用类似子ID思想的非序列方法）使用我们称为PQTopK的算法报告了大幅的推理效率提升。我们展示了使用PQTopK算法也可以提高基于RecJPQ模型的推理效率。具体而言，我们在包含超过百万项物品的大规模Gowalla数据集上，将RecJPQ增强的SASRec的推理速度比原始SASRec的推理方法提高了4.5倍，比RecJPQ代码中实现的方法提高了1.56倍。此外，使用模拟数据，我们展示了PQTopK在包含多达数千万项物品的目录中仍然高效，消除了在大型目录生产环境中使用基于Transformer模型的最后障碍之一。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Inference+of+Sub-Item+Id-based+Sequential+Recommendation+Models+with+Millions+of+Items)|0|
|[Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations](https://doi.org/10.1145/3640457.3688190)|Anima Singh, Trung Vu, Nikhil Mehta, Raghunandan H. Keshavan, Maheswaran Sathiamoorthy, Yilin Zheng, Lichan Hong, Lukasz Heldt, Li Wei, Devansh Tandon, Ed H. Chi, Xinyang Yi|Google, Mountain View, CA 94043 USA; Google DeepMind, Mountain View, CA 94043 USA|Randomly-hashed item ids are used ubiquitously in recommendation models. However, the learned representations from random hashing prevents generalization across similar items, causing problems of learning unseen and long-tail items, especially when item corpus is large, power-law distributed, and evolving dynamically. In this paper, we propose using content-derived features as a replacement for random ids. We show that simply replacing ID features with content-based embeddings can cause a drop in quality due to reduced memorization capability. To strike a good balance of memorization and generalization, we propose to use Semantic IDs [15], a compact and discrete item representation, as a replacement for random item ids. Semantic IDs are learned from frozen content embeddings using RQ-VAE and thus can capture the hierarchy of concepts in items. Similar to content embeddings, the compactness of Semantic IDs poses a problem of adaption in recommendation models. We propose novel methods for adapting Semantic IDs in industry-scale ranking models, through hashing sub-pieces of of the Semantic-ID sequences. In particular, we find that the SentencePiece model [10] that is commonly used in LLM tokenization outperforms manually crafted pieces such as N-grams. To the end, we evaluate our approaches in a real-world ranking model for YouTube recommendations. Our experiments demonstrate that Semantic IDs can replace the direct use of video IDs by improving the generalization ability on new and long-tail item slices without sacrificing overall model quality.|随机哈希的物品ID在推荐模型中无处不在。然而，从随机哈希中学习到的表示阻碍了相似物品之间的泛化，导致学习未见和长尾物品时出现问题，特别是在物品库庞大、服从幂律分布且动态变化的情况下。本文提出使用内容特征替代随机ID。我们发现，简单地用基于内容的嵌入替代ID特征可能会因记忆能力的降低而导致质量下降。为了在记忆和泛化之间取得良好平衡，我们提出使用语义ID [15] 作为随机物品ID的替代方案。语义ID是通过RQ-VAE从冻结的内容嵌入中学习的，因此能够捕捉物品中的概念层次结构。与内容嵌入类似，语义ID的紧凑性在推荐模型中的适应性方面带来了挑战。我们提出了在工业级排序模型中适应语义ID的新方法，通过对语义ID序列的子片段进行哈希处理来实现。特别是，我们发现常用于大语言模型（LLM）分词中的SentencePiece模型 [10] 在性能上优于手工设计的片段（如N-gram）。最终，我们在YouTube推荐的真实排序模型中评估了我们的方法。实验结果表明，语义ID可以通过提高对新物品和长尾物品的泛化能力来替代直接使用视频ID，而不会牺牲整体模型质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Better+Generalization+with+Semantic+IDs:+A+Case+Study+in+Ranking+for+Recommendations)|0|
|[User Knowledge Prompt for Sequential Recommendation](https://doi.org/10.1145/3640457.3691714)|Yuuki Tachioka|Denso IT Lab, Minato Ku, Tokyo, Japan|The large language model (LLM) based recommendation system is effective for sequential recommendation, because general knowledge of popular items is included in the LLM. To add domain knowledge of items, the conventional method uses a knowledge prompt obtained from the item knowledge graphs and has achieved SOTA performance. However, for personalized recommendation, it is necessary to consider user knowledge, which the conventional method does not fully consider because user knowledge is not included in the item knowledge graphs; thus, we propose a user knowledge prompt, which converts a user knowledge graph into a prompt using the relationship template. The existing prompt denoising framework is extended to prevent hallucination caused by undesirable interactions between knowledge graph prompts. We propose user knowledge prompts of user traits and user preferences and associate relevant items. Experiments on three types of dataset (movie, music, and book) show the significant and consistent improvement of our proposed user knowledge prompt.|基于大规模语言模型（LLM）的推荐系统在序列推荐中表现出色，因为LLM包含了流行项目的通用知识。为了增加项目的领域知识，传统方法使用从项目知识图谱中获取的知识提示（knowledge prompt），并取得了最先进的性能。然而，对于个性化推荐，必须考虑用户知识，而传统方法并未充分考虑这一点，因为用户知识并未包含在项目知识图谱中。因此，我们提出了一种用户知识提示（user knowledge prompt），通过关系模板将用户知识图谱转换为提示。现有的提示去噪框架被扩展，以防止因知识图谱提示之间的不良交互而产生的幻觉。我们提出了用户特征和用户偏好的用户知识提示，并将其与相关项目关联。在三种类型的数据集（电影、音乐和书籍）上进行的实验表明，我们提出的用户知识提示显著且一致地提升了推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Knowledge+Prompt+for+Sequential+Recommendation)|0|
|[Recommender Systems Algorithm Selection for Ranking Prediction on Implicit Feedback Datasets](https://doi.org/10.1145/3640457.3691718)|Lukas Wegmeth, Tobias Vente, Joeran Beel|Univ Siegen, Intelligent Syst Grp, Siegen, Germany|The recommender systems algorithm selection problem for ranking prediction on implicit feedback datasets is under-explored. Traditional approaches in recommender systems algorithm selection focus predominantly on rating prediction on explicit feedback datasets, leaving a research gap for ranking prediction on implicit feedback datasets. Algorithm selection is a critical challenge for nearly every practitioner in recommender systems. In this work, we take the first steps toward addressing this research gap. We evaluate the NDCG@10 of 24 recommender systems algorithms, each with two hyperparameter configurations, on 72 recommender systems datasets. We train four optimized machine-learning meta-models and one automated machine-learning meta-model with three different settings on the resulting meta-dataset. Our results show that the predictions of all tested meta-models exhibit a median Spearman correlation ranging from 0.857 to 0.918 with the ground truth. We show that the median Spearman correlation between meta-model predictions and the ground truth increases by an average of 0.124 when the meta-model is optimized to predict the ranking of algorithms instead of their performance. Furthermore, in terms of predicting the best algorithm for an unknown dataset, we demonstrate that the best optimized traditional meta-model, e.g., XGBoost, achieves a recall of 48.6%, outperforming the best tested automated machine learning meta-model, e.g., AutoGluon, which achieves a recall of 47.2%.|在隐式反馈数据集上进行排序预测的推荐系统算法选择问题尚未得到充分探索。传统的推荐系统算法选择方法主要集中在显式反馈数据集上的评分预测，而在隐式反馈数据集上的排序预测方面存在研究空白。对于几乎每一个推荐系统的从业者来说，算法选择都是一个关键的挑战。在本研究中，我们迈出了填补这一研究空白的第一步。我们在72个推荐系统数据集上评估了24种推荐系统算法的NDCG@10指标，每种算法有两种超参数配置。我们在生成的元数据集上训练了四个优化的机器学习元模型和一个自动化机器学习元模型，并采用了三种不同的设置。我们的结果表明，所有测试的元模型的预测结果与真实值的中位数斯皮尔曼相关系数在0.857到0.918之间。我们发现，当元模型被优化为预测算法的排序而不是其性能时，元模型预测与真实值之间的中位数斯皮尔曼相关系数平均增加了0.124。此外，在预测未知数据集的最佳算法方面，我们证明了最佳优化的传统元模型（如XGBoost）的召回率为48.6%，优于测试的最佳自动化机器学习元模型（如AutoGluon），后者的召回率为47.2%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommender+Systems+Algorithm+Selection+for+Ranking+Prediction+on+Implicit+Feedback+Datasets)|0|
|[Personal Values and Community-Centric Environmental Recommender Systems: Enhancing Sustainability Through User Engagement](https://doi.org/10.1145/3640457.3688018)|Bianca Maria Deconcini|Univ Turin, Turin, Italy|The concept of sustainability has become a central focus across multiple sectors, driven by the urgent need to address climate change and protect the environment. Technological advancements and capabilities, together with the emergence of new ecological issues [25], are leading to growing awareness and influencing shifts in multiple areas such as energy, transportation, and waste management. Within this context, the roles of recommender systems represent a promising solution, since people need guidance and occasionally a gentle push to translate their intentions into actions or to bring goals to life [9]. However, existing literature reveals a fragmented landscape, with solutions often addressing specific aspects or recommendation contribution in isolation. Many sustainability interventions focus solely on providing consumption data and environmental insights, while others emphasize learning and behavior change strategies. My doctoral project aims to address this gap by leveraging various approaches to recommender systems and applying them in sustainability contexts, with the goal to build a holistic system that maximizes the contributions of these diverse methods, also integrating user-centric and value-driven perspectives. This research project delves into two distinct facets: energy sustainability and sustainable mobility. The first case centers on enhancing energy efficiency within energy communities through personalized recommendations and engagement strategies. The second facet focuses on reshaping user commuting patterns towards sustainable alternatives, by recommending suitable and more sustainable modes of transportation, such as cycling, carpooling, and public transportation. Both cases share the same objective: align user behaviors with sustainability goals, thereby reducing individual environmental impact and enhancing the sense of belonging to a community, whether this is confined to a group of individuals or pertains to society at large. An innovative comprehensive recommendation system approach is highly beneficial since it can take advantage of all the existing contributions combined in a framework that makes at the same time different types of recommendations: explainable, educative, behavioral and social-aware, addressing the complexities of this multifaceted domain.|可持续发展概念已成为多个领域的核心关注点，这主要是由于应对气候变化和保护环境的迫切需求所推动的。技术进步和能力提升，以及新出现的生态问题[25]，正在促使人们对能源、交通和废物管理等多个领域的意识不断增强，并影响着这些领域的转变。在此背景下，推荐系统的作用代表了一种有前景的解决方案，因为人们需要指导，有时还需要一个温和的推动力，将他们的意图转化为行动或将目标变为现实[9]。然而，现有文献揭示了一个零散的格局，解决方案通常只针对特定方面或孤立的推荐贡献。许多可持续发展干预措施仅专注于提供消费数据和环境洞察，而另一些则强调学习和行为改变策略。我的博士项目旨在通过利用推荐系统的各种方法并将其应用于可持续发展背景中，来解决这一差距，目标是构建一个整体系统，最大限度地发挥这些多样化方法的贡献，同时整合以用户为中心和价值驱动的视角。

该研究项目深入探讨了两个不同的方面：能源可持续性和可持续交通。第一个案例侧重于通过个性化推荐和参与策略提高能源社区内的能源效率。第二个方面则侧重于通过推荐合适且更可持续的交通方式（如骑行、拼车和公共交通）来重塑用户的通勤模式，使其转向可持续的替代方案。这两个案例都共享同一个目标：将用户行为与可持续发展目标保持一致，从而减少个人对环境的影响，并增强对社区的归属感，无论这个社区是局限于一个群体还是涉及整个社会。一个创新的综合推荐系统方法极为有益，因为它可以充分利用现有贡献，并将其结合在一个框架中，同时提供不同类型的推荐：可解释的、教育的、行为的和社会意识的，以应对这一多面领域的复杂性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personal+Values+and+Community-Centric+Environmental+Recommender+Systems:+Enhancing+Sustainability+Through+User+Engagement)|0|
|[Towards Empathetic Conversational Recommender Systems](https://doi.org/10.1145/3640457.3688133)|Xiaoyu Zhang, Ruobing Xie, Yougang Lyu, Xin Xin, Pengjie Ren, Mingfei Liang, Bo Zhang, Zhanhui Kang, Maarten de Rijke, Zhaochun Ren|Univ Amsterdam, Amsterdam, Netherlands; Leiden Univ, Leiden, Netherlands; Shandong Univ, Jinan, Shandong, Peoples R China; Tencent, Shenzhen, Guangdong, Peoples R China|Conversational recommender systems (CRSs) are able to elicit user preferences through multi-turn dialogues. They typically incorporate external knowledge and pre-trained language models to capture the dialogue context. Most CRS approaches, trained on benchmark datasets, assume that the standard items and responses in these benchmarks are optimal. However, they overlook that users may express negative emotions with the standard items and may not feel emotionally engaged by the standard responses. This issue leads to a tendency to replicate the logic of recommenders in the dataset instead of aligning with user needs. To remedy this misalignment, we introduce empathy within a CRS. With empathy we refer to a system's ability to capture and express emotions. We propose an empathetic conversational recommender (ECR) framework. ECR contains two main modules: emotion-aware item recommendation and emotion-aligned response generation. Specifically, we employ user emotions to refine user preference modeling for accurate recommendations. To generate human-like emotional responses, ECR applies retrieval-augmented prompts to fine-tune a pre-trained language model aligning with emotions and mitigating hallucination. To address the challenge of insufficient supervision labels, we enlarge our empathetic data using emotion labels annotated by large language models and emotional reviews collected from external resources. We propose novel evaluation metrics to capture user satisfaction in real-world CRS scenarios. Our experiments on the ReDial dataset validate the efficacy of our framework in enhancing recommendation accuracy and improving user satisfaction.|对话推荐系统（CRS）能够通过多轮对话来获取用户偏好。这类系统通常结合外部知识和预训练语言模型来捕捉对话上下文。大多数基于基准数据集训练的CRS方法假设这些基准中的标准项目和响应是最优的。然而，它们忽视了用户可能对这些标准项目表达负面情绪，并且可能不会因标准响应而感到情感上的投入。这一问题导致系统倾向于复制数据集中推荐逻辑，而不是与用户需求保持一致。为了解决这种不一致性，我们在CRS中引入了共情能力。共情指的是系统捕捉和表达情感的能力。我们提出了一个共情对话推荐（ECR）框架。ECR包含两个主要模块：情感感知的项目推荐和情感对齐的响应生成。具体来说，我们利用用户情绪来优化用户偏好建模，以实现更准确的推荐。为了生成类似人类的情感响应，ECR采用检索增强的提示来微调预训练语言模型，使其与情感对齐并减少幻觉生成。为了解决监督标签不足的挑战，我们通过使用大型语言模型标注的情感标签和从外部资源收集的情感评论来扩展我们的共情数据。我们提出了新的评估指标，以捕捉实际CRS场景中的用户满意度。我们在ReDial数据集上的实验验证了我们框架在提高推荐准确性和提升用户满意度方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Empathetic+Conversational+Recommender+Systems)|0|
|[The Elephant in the Room: Rethinking the Usage of Pre-trained Language Model in Sequential Recommendation](https://doi.org/10.1145/3640457.3688107)|Zekai Qu, Ruobing Xie, Chaojun Xiao, Zhanhui Kang, Xingwu Sun|Tencent Inc, Beijing, Peoples R China; Tsinghua Univ, Beijing, Peoples R China; China Univ Geosci Beijing, Beijing, Peoples R China|Sequential recommendation (SR) has seen significant advancements with the help of Pre-trained Language Models (PLMs). Some PLM-based SR models directly use PLM to encode user historical behavior's text sequences to learn user representations, while there is seldom an in-depth exploration of the capability and suitability of PLM in behavior sequence modeling. In this work, we first conduct extensive model analyses between PLMs and PLM-based SR models, discovering great underutilization and parameter redundancy of PLMs in behavior sequence modeling. Inspired by this, we explore different lightweight usages of PLMs in SR, aiming to maximally stimulate the ability of PLMs for SR while satisfying the efficiency and usability demands of practical systems. We discover that adopting behavior-tuned PLMs for item initializations of conventional ID-based SR models is the most economical framework of PLM-based SR, which would not bring in any additional inference cost but could achieve a dramatic performance boost compared with the original version. Extensive experiments on five datasets show that our simple and universal framework leads to significant improvement compared to classical SR and SOTA PLM-based SR models without additional inference costs. Our code can be found in https://github.com/777pomingzi/Rethinking-PLM-in-RS.|在预训练语言模型（PLMs）的帮助下，序列推荐（SR）取得了显著的进展。一些基于PLM的SR模型直接使用PLM对用户历史行为的文本序列进行编码，以学习用户表示，然而对PLM在行为序列建模中的能力和适用性却鲜有深入探索。在本工作中，我们首先对PLMs和基于PLM的SR模型进行了广泛的模型分析，发现PLMs在行为序列建模中存在严重的未充分利用和参数冗余问题。受此启发，我们探索了PLMs在SR中的不同轻量级使用方法，旨在最大程度地激发PLMs在SR中的能力，同时满足实际系统对效率和可用性的需求。我们发现，将经过行为调优的PLMs用于传统基于ID的SR模型的物品初始化，是最经济的基于PLM的SR框架，它不会带来任何额外的推理成本，但相比原始版本可以实现显著的性能提升。在五个数据集上的大量实验表明，我们的简单且通用的框架相比经典的SR和最先进的基于PLM的SR模型，在不增加推理成本的情况下带来了显著的改进。我们的代码可以在https://github.com/777pomingzi/Rethinking-PLM-in-RS找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Elephant+in+the+Room:+Rethinking+the+Usage+of+Pre-trained+Language+Model+in+Sequential+Recommendation)|0|
|[Fair Reciprocal Recommendation in Matching Markets](https://doi.org/10.1145/3640457.3688130)|Yoji Tomita, Tomohiko Yokoyama||Recommender systems play an increasingly crucial role in shaping people's opportunities, particularly in online dating platforms. It is essential from the user's perspective to increase the probability of matching with a suitable partner while ensuring an appropriate level of fairness in the matching opportunities. We investigate reciprocal recommendation in two-sided matching markets between agents divided into two sides. In our model, a match is considered successful only when both individuals express interest in each other. Additionally, we assume that agents prefer to appear prominently in the recommendation lists presented to those on the other side. We define each agent's opportunity to be recommended and introduce its fairness criterion, envy-freeness, from the perspective of fair division theory. The recommendations that approximately maximize the expected number of matches, empirically obtained by heuristic algorithms, are likely to result in significant unfairness of opportunity. Therefore, there can be a trade-off between maximizing the expected matches and ensuring fairness of opportunity. To address this challenge, we propose a method to find a policy that is close to being envy-free by leveraging the Nash social welfare function. Experiments on synthetic and real-world datasets demonstrate the effectiveness of our approach in achieving both relatively high expected matches and fairness for opportunities of both sides in reciprocal recommender systems.|推荐系统在塑造人们的机会方面发挥着越来越重要的作用，尤其是在在线约会平台中。从用户的角度来看，提高与合适伴侣匹配的概率，同时确保匹配机会的公平性至关重要。我们研究了在双边匹配市场中，将代理分为两方的互惠推荐问题。在我们的模型中，只有当双方都表示对彼此感兴趣时，才认为匹配成功。此外，我们假设代理更倾向于在向对方展示的推荐列表中占据显眼位置。我们从公平分配理论的角度，定义了每个代理的推荐机会，并引入了其公平性标准——无嫉妒性。通过启发式算法经验获得的、近似最大化预期匹配数量的推荐，可能会导致机会的显著不公平。因此，在最大化预期匹配和确保机会公平性之间可能存在权衡。为了解决这一挑战，我们提出了一种利用纳什社会福利函数来找到接近无嫉妒性策略的方法。在合成数据集和真实世界数据集上的实验表明，我们的方法在互惠推荐系统中能够有效实现相对较高的预期匹配和双方的公平机会。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Reciprocal+Recommendation+in+Matching+Markets)|0|
|[CALRec: Contrastive Alignment of Generative LLMs for Sequential Recommendation](https://doi.org/10.1145/3640457.3688121)|Yaoyiran Li, Xiang Zhai, Moustafa Alzantot, Keyi Yu, Ivan Vulic, Anna Korhonen, Mohamed Hammad|Google, Mountain View, CA 94043 USA; Univ Cambridge, Cambridge, England|Traditional recommender systems such as matrix factorization methods have primarily focused on learning a shared dense embedding space to represent both items and user preferences. Subsequently, sequence models such as RNN, GRUs, and, recently, Transformers have emerged and excelled in the task of sequential recommendation. This task requires understanding the sequential structure present in users’ historical interactions to predict the next item they may like. Building upon the success of Large Language Models (LLMs) in a variety of tasks, researchers have recently explored using LLMs that are pretrained on vast corpora of text for sequential recommendation. To use LLMs for sequential recommendation, both the history of user interactions and the model’s prediction of the next item are expressed in text form. We propose CALRec, a two-stage LLM finetuning framework that finetunes a pretrained LLM in a two-tower fashion using a mixture of two contrastive losses and a language modeling loss: the LLM is first finetuned on a data mixture from multiple domains followed by another round of target domain finetuning. Our model significantly outperforms many state-of-the-art baselines (+37% in Recall@1 and +24% in NDCG@10) and our systematic ablation studies reveal that (i) both stages of finetuning are crucial, and, when combined, we achieve improved performance, and (ii) contrastive alignment is effective among the target domains explored in our experiments.|传统的推荐系统，如矩阵分解方法，主要侧重于学习一个共享的密集嵌入空间来表示物品和用户偏好。随后，序列模型如RNN、GRU以及最近的Transformers相继出现，并在序列推荐任务中表现出色。这一任务需要理解用户历史交互中的序列结构，以预测用户可能喜欢的下一个物品。基于大型语言模型（LLMs）在多种任务中的成功，研究人员最近探索了使用在大量文本语料上预训练的LLMs进行序列推荐。为了将LLMs应用于序列推荐，用户交互历史和模型对下一个物品的预测都以文本形式表达。我们提出了CALRec，这是一个两阶段的LLM微调框架，通过使用两种对比损失和语言建模损失的混合，以双塔方式微调预训练的LLM：首先在来自多个领域的数据混合上进行微调，然后在目标领域进行另一轮微调。我们的模型显著优于许多最先进的基线模型（Recall@1提高了37%，NDCG@10提高了24%），并且我们的系统消融研究表明：(i) 两个阶段的微调都至关重要，当结合使用时，我们实现了性能的提升；(ii) 对比对齐在我们实验探索的目标领域中有效。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CALRec:+Contrastive+Alignment+of+Generative+LLMs+for+Sequential+Recommendation)|0|
|[Scaling Law of Large Sequential Recommendation Models](https://doi.org/10.1145/3640457.3688129)|Gaowei Zhang, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, JiRong Wen|University of California San Diego; WeChat; Renmin University of China Gaoling School of Artificial Intelligence|Scaling of neural networks has recently shown great potential to improve the model capacity in various fields. Specifically, model performance has a power-law relationship with model size or data size, which provides important guidance for the development of large-scale models. However, there is still limited understanding on the scaling effect of user behavior models in recommender systems, where the unique data characteristics (e.g., data scarcity and sparsity) pose new challenges in recommendation tasks. In this work, we focus on investigating the scaling laws in large sequential recommendation models. Specifically, we consider a pure ID-based task formulation, where the interaction history of a user is formatted as a chronological sequence of item IDs. We don't incorporate any side information (e.g., item text), to delve into the scaling law's applicability from the perspective of user behavior. We successfully scale up the model size to 0.8B parameters, making it feasible to explore the scaling effect in a diverse range of model sizes. As the major findings, we empirically show that the scaling law still holds for these trained models, even in data-constrained scenarios. We then fit the curve for scaling law, and successfully predict the test loss of the two largest tested model scales. Furthermore, we examine the performance advantage of scaling effect on five challenging recommendation tasks, considering the unique issues (e.g., cold start, robustness, long-term preference) in recommender systems. We find that scaling up the model size can greatly boost the performance on these challenging tasks, which again verifies the benefits of large recommendation models.|近年来，神经网络的扩展在提升模型能力方面展现出巨大潜力，广泛应用于多个领域。具体而言，模型性能与模型规模或数据规模之间存在幂律关系，这为大规模模型的开发提供了重要指导。然而，在推荐系统中，用户行为模型的扩展效应仍缺乏深入理解，尤其是其独特的数据特性（如数据稀缺性和稀疏性）为推荐任务带来了新的挑战。在本研究中，我们重点探讨了大规模序列推荐模型中的扩展规律。具体来说，我们采用了一种纯基于ID的任务形式，将用户的交互历史格式化为按时间顺序排列的物品ID序列。我们没有引入任何辅助信息（如物品文本），以便从用户行为的角度深入探讨扩展规律的适用性。我们成功将模型规模扩展至8亿个参数，从而能够在多种模型规模下探索扩展效应。作为主要发现，我们通过实验证明，即使在数据受限的场景下，扩展规律仍然适用于这些训练后的模型。随后，我们拟合了扩展规律的曲线，并成功预测了两个最大测试模型规模的测试损失。此外，我们还考察了扩展效应在五个具有挑战性的推荐任务中的性能优势，考虑了推荐系统中的独特问题（如冷启动、鲁棒性、长期偏好）。我们发现，扩大模型规模能够显著提升这些挑战性任务的性能，这再次验证了大规模推荐模型的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Law+of+Large+Sequential+Recommendation+Models)|0|
|[A Pre-trained Zero-shot Sequential Recommendation Framework via Popularity Dynamics](https://doi.org/10.1145/3640457.3688145)|Junting Wang, Praneet Rathi, Hari Sundaram|Univ Illinois, Urbana, IL 61801 USA|This paper proposes a novel pre-trained framework for zero-shot cross-domain sequential recommendation without auxiliary information. While using auxiliary information (e.g., item descriptions) seems promising for cross-domain transfer, a cross-domain adaptation of sequential recommenders can be challenging when the target domain differs from the source domain—item descriptions are in different languages; metadata modalities (e.g., audio, image, and text) differ across source and target domains. If we can learn universal item representations independent of the domain type (e.g., groceries, movies), we can achieve zero-shot cross-domain transfer without auxiliary information. Our critical insight is that user interaction sequences highlight shifting user preferences via the popularity dynamics of interacted items. We present a pre-trained sequential recommendation framework: PrepRec, which utilizes a novel popularity dynamics-aware transformer architecture. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can zero-shot adapt to new application domains and achieve competitive performance compared to state-of-the-art sequential recommender models. In addition, we show that PrepRec complements existing sequential recommenders. With a simple post-hoc interpolation, PrepRec improves the performance of existing sequential recommenders on average by 11.8% in Recall@10 and 22% in NDCG@10. We provide an anonymized implementation of PrepRec at https://github.com/CrowdDynamicsLab/preprec.|本文提出了一种新颖的预训练框架，用于无需辅助信息的零样本跨域序列推荐。虽然使用辅助信息（例如，物品描述）在跨域转移中似乎很有前景，但当目标域与源域不同时——物品描述使用不同的语言；元数据模态（例如，音频、图像和文本）在源域和目标域之间存在差异——序列推荐器的跨域适应可能会面临挑战。如果我们能够学习独立于域类型（例如，杂货、电影）的通用物品表示，我们可以在没有辅助信息的情况下实现零样本跨域转移。我们的关键见解是，用户交互序列通过交互物品的流行度动态突出了用户偏好的变化。我们提出了一个预训练的序列推荐框架：PrepRec，它利用了一种新颖的流行度动态感知的Transformer架构。通过在五个真实世界数据集上的广泛实验，我们展示了PrepRec在没有任何辅助信息的情况下，能够零样本适应新的应用领域，并与最先进的序列推荐模型相比取得竞争性的性能。此外，我们展示了PrepRec对现有序列推荐器的补充作用。通过简单的后验插值，PrepRec将现有序列推荐器在Recall@10和NDCG@10上的性能平均提高了11.8%和22%。我们在https://github.com/CrowdDynamicsLab/preprec 提供了PrepRec的匿名实现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Pre-trained+Zero-shot+Sequential+Recommendation+Framework+via+Popularity+Dynamics)|0|
|[Repeated Padding for Sequential Recommendation](https://doi.org/10.1145/3640457.3688110)|Yizhou Dang, Yuting Liu, Enneng Yang, Guibing Guo, Linying Jiang, Xingwei Wang, Jianzhe Zhao|Northeastern University Shenyang School of Computer Science and Engineering; Software College|Sequential recommendation aims to provide users with personalized suggestions based on their historical interactions. When training sequential models, padding is a widely adopted technique for two main reasons: 1) The vast majority of models can only handle fixed-length sequences; 2) Batch-based training needs to ensure that the sequences in each batch have the same length. The special value 0 is usually used as the padding content, which does not contain the actual information and is ignored in the model calculations. This common-sense padding strategy leads us to a problem that has never been explored in the recommendation field: Can we utilize this idle input space by padding other content to improve model performance and training efficiency further? In this paper, we propose a simple yet effective padding method called Repeated Padding (RepPad). Specifically, we use the original interaction sequences as the padding content and fill it to the padding positions during model training. This operation can be performed a finite number of times or repeated until the input sequences’ length reaches the maximum limit. Our RepPad can be considered as a sequence-level data augmentation strategy. Unlike most existing works, our method contains no trainable parameters or hyperparameters and is a plug-and-play data augmentation operation. Extensive experiments on various categories of sequential models and five real-world datasets demonstrate the effectiveness and efficiency of our approach. The average recommendation performance improvement is up to 60.3% on GRU4Rec and 24.3% on SASRec. We also provide in-depth analysis and explanation of what makes RepPad effective from multiple perspectives. Our datasets and codes are available at https://github.com/KingGugu/RepPad.|序列推荐旨在根据用户的历史交互记录提供个性化的建议。在训练序列模型时，填充是一种广泛采用的技术，主要有两个原因：1）绝大多数模型只能处理固定长度的序列；2）基于批次的训练需要确保每个批次中的序列具有相同的长度。通常使用特殊值0作为填充内容，它不包含实际信息，在模型计算中被忽略。这种常识性的填充策略引出了一个在推荐领域从未被探索过的问题：我们是否可以通过填充其他内容来利用这个空闲的输入空间，以进一步提高模型的性能和训练效率？在本文中，我们提出了一种简单而有效的填充方法，称为重复填充（RepPad）。具体来说，我们使用原始的交互序列作为填充内容，并在模型训练期间将其填充到填充位置。此操作可以执行有限次数或重复进行，直到输入序列的长度达到最大限制。我们的RepPad可以被视为一种序列级的数据增强策略。与大多数现有工作不同，我们的方法不包含可训练的参数或超参数，是一种即插即用的数据增强操作。在各种类别的序列模型和五个真实世界数据集上的大量实验证明了我们方法的有效性和效率。在GRU4Rec上的平均推荐性能提升高达60.3%，在SASRec上为24.3%。我们还从多个角度深入分析和解释了RepPad为何有效。我们的数据集和代码可在https://github.com/KingGugu/RepPad获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Repeated+Padding+for+Sequential+Recommendation)|0|
|[From Clicks to Carbon: The Environmental Toll of Recommender Systems](https://doi.org/10.1145/3640457.3688074)|Tobias Vente, Lukas Wegmeth, Alan Said, Joeran Beel|Univ Siegen, Intelligent Syst Grp, Siegen, Germany; Univ Gothenburg, Gothenburg, Sweden|As global warming soars, the need to assess the environmental impact of research is becoming increasingly urgent. Despite this, few recommender systems research papers address their environmental impact. In this study, we estimate the environmental impact of recommender systems research by reproducing typical experimental pipelines. Our analysis spans 79 full papers from the 2013 and 2023 ACM RecSys conferences, comparing traditional “good old-fashioned AI’’ algorithms with modern deep learning algorithms. We designed and reproduced representative experimental pipelines for both years, measuring energy consumption with a hardware energy meter and converting it to CO2 equivalents. Our results show that papers using deep learning algorithms emit approximately 42 times more CO2 equivalents than papers using traditional methods. On average, a single deep learning-based paper generates 3,297 kilograms of CO2 equivalents—more than the carbon emissions of one person flying from New York City to Melbourne or the amount of CO2 one tree sequesters over 300 years.|随着全球气候变暖日益加剧，评估研究对环境的影响变得越来越紧迫。尽管如此，很少有推荐系统研究论文关注其环境影响。在本研究中，我们通过复现典型的实验流程，估算了推荐系统研究对环境的影响。我们的分析涵盖了2013年和2023年ACM RecSys会议上的79篇完整论文，比较了传统的“经典AI”算法与现代深度学习算法。我们设计并复现了这两年的代表性实验流程，使用硬件能量计测量能耗并将其转换为二氧化碳当量。研究结果表明，使用深度学习算法的论文比使用传统方法的论文排放的二氧化碳当量多出约42倍。平均而言，一篇基于深度学习的论文产生3,297千克的二氧化碳当量——这超过了一个人从纽约市飞往墨尔本的碳排放量，或一棵树在300年内吸收的二氧化碳量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Clicks+to+Carbon:+The+Environmental+Toll+of+Recommender+Systems)|0|
|[DNS-Rec: Data-aware Neural Architecture Search for Recommender Systems](https://doi.org/10.1145/3640457.3688117)|Sheng Zhang, Maolin Wang, Xiangyu Zhao, Ruocheng Guo, Yao Zhao, Chenyi Zhuang, Jinjie Gu, Zijian Zhang, Hongzhi Yin|Jilin Univ, Changchun, Peoples R China; Ant Grp, Hangzhou, Peoples R China; City Univ Hong Kong, Hong Kong, Peoples R China; ByteDance Res, Beijing, Peoples R China; Univ Queensland, Brisbane, Qld, Australia|In the era of data proliferation, efficiently sifting through vast information to extract meaningful insights has become increasingly crucial. This paper addresses the computational overhead and resource inefficiency prevalent in existing Sequential Recommender Systems (SRSs). We introduce an innovative approach combining pruning methods with advanced model designs. Furthermore, we delve into resource-constrained Neural Architecture Search (NAS), an emerging technique in recommender systems, to optimize models in terms of FLOPs, latency, and energy consumption while maintaining or enhancing accuracy. Our principal contribution is the development of a Data-aware Neural Architecture Search for Recommender System (DNS-Rec). DNS-Rec is specifically designed to tailor compact network architectures for attention-based SRS models, thereby ensuring accuracy retention. It incorporates data-aware gates to enhance the performance of the recommendation network by learning information from historical user-item interactions. Moreover, DNS-Rec employs a dynamic resource constraint strategy, stabilizing the search process and yielding more suitable architectural solutions. We demonstrate the effectiveness of our approach through rigorous experiments conducted on three benchmark datasets, which highlight the superiority of DNS-Rec in SRSs. Our findings set a new standard for future research in efficient and accurate recommendation systems, marking a significant step forward in this rapidly evolving field.|在数据激增的时代，高效筛选海量信息以提取有意义的洞察变得日益重要。本文针对现有顺序推荐系统（SRSs）中普遍存在的计算开销和资源效率低下的问题，提出了一种创新的方法，将剪枝技术与先进的模型设计相结合。此外，我们深入探讨了资源受限的神经架构搜索（NAS），这是一种在推荐系统中新兴的技术，旨在保持或提升准确性的同时，优化模型的浮点运算次数（FLOPs）、延迟和能耗。我们的主要贡献是开发了一种面向推荐系统的数据感知神经架构搜索方法（DNS-Rec）。DNS-Rec专门设计用于为基于注意力的SRS模型定制紧凑的网络架构，从而确保准确性的保持。它集成了数据感知门，通过从用户-项目历史交互中学习信息来增强推荐网络的性能。此外，DNS-Rec采用了一种动态资源约束策略，稳定了搜索过程，并生成了更合适的架构解决方案。通过在三个基准数据集上进行的严格实验，我们证明了所提方法的有效性，这些实验突显了DNS-Rec在SRSs中的优越性。我们的研究成果为未来高效且准确的推荐系统研究设立了新标准，标志着这一快速发展领域的重要进步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DNS-Rec:+Data-aware+Neural+Architecture+Search+for+Recommender+Systems)|0|
|[FedLoCA: Low-Rank Coordinated Adaptation with Knowledge Decoupling for Federated Recommendations](https://doi.org/10.1145/3640457.3688112)|Yuchen Ding, Siqing Zhang, Boyu Fan, Wei Sun, Yong Liao, Peng Yuan Zhou|Aarhus Univ, Aarhus, Denmark; Univ Helsinki, Helsinki, Finland; Univ Sci & Technol China, Hefei, Peoples R China|Privacy protection in recommendation systems is gaining increasing attention, for which federated learning has emerged as a promising solution. Current federated recommendation systems grapple with high communication overhead due to sharing dense global embeddings, and also poorly reflect user preferences due to data heterogeneity. To overcome these challenges, we propose a two-stage Federated Low-rank Coordinated Adaptation (FedLoCA) framework to decouple global and client-specific knowledge into low-rank embeddings, which significantly reduces communication overhead while enhancing the system’s ability to capture individual user preferences amidst data heterogeneity. Further, to tackle gradient estimation inaccuracies stemming from data sparsity in federated recommendation systems, we introduce an adversarial gradient projected descent approach in low-rank spaces, which significantly boosts model performance while maintaining robustness. Remarkably, FedLoCA also alleviates performance loss even under the stringent constraints of differential privacy. Extensive experiments on various real-world datasets demonstrate that FedLoCA significantly outperforms existing methods in both recommendation accuracy and communication efficiency.|推荐系统中的隐私保护问题正日益受到关注，联邦学习作为一种有前景的解决方案应运而生。当前的联邦推荐系统面临两大挑战：一是由于共享密集的全局嵌入而导致的高通信开销，二是由于数据异构性而难以准确反映用户偏好。为了克服这些挑战，我们提出了一种两阶段的联邦低秩协同适应框架（FedLoCA），将全局知识和客户端特定知识解耦为低秩嵌入，从而在显著降低通信开销的同时，增强了系统在数据异构性下捕捉个体用户偏好的能力。此外，为了解决联邦推荐系统中因数据稀疏性导致的梯度估计不准确问题，我们在低秩空间中引入了一种对抗性梯度投影下降方法，在保持模型鲁棒性的同时显著提升了模型性能。值得注意的是，即使在差分隐私的严格约束下，FedLoCA也能有效缓解性能损失。我们在多个真实世界数据集上进行的大量实验表明，FedLoCA在推荐准确性和通信效率方面均显著优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedLoCA:+Low-Rank+Coordinated+Adaptation+with+Knowledge+Decoupling+for+Federated+Recommendations)|0|
|[Multi-Objective Recommendation via Multivariate Policy Learning](https://doi.org/10.1145/3640457.3688132)|Olivier Jeunen, Jatin Mandav, Ivan Potapov, Nakul Agarwal, Sourabh Vaid, Wenzhe Shi, Aleksei Ustimenko|ShareChat, London, England; ShareChat, Delhi, India|Real-world recommender systems often need to balance multiple objectives whendeciding which recommendations to present to users. These include behaviouralsignals (e.g. clicks, shares, dwell time), as well as broader objectives (e.g.diversity, fairness). Scalarisation methods are commonly used to handle thisbalancing task, where a weighted average of per-objective reward signalsdetermines the final score used for ranking. Naturally, how these weights arecomputed exactly, is key to success for any online platform. We frame this as adecision-making task, where the scalarisation weights are actions taken tomaximise an overall North Star reward (e.g. long-term user retention orgrowth). We extend existing policy learning methods to the continuousmultivariate action domain, proposing to maximise a pessimistic lower bound onthe North Star reward that the learnt policy will yield. Typical lower boundsbased on normal approximations suffer from insufficient coverage, and wepropose an efficient and effective policy-dependent correction for this. Weprovide guidance to design stochastic data collection policies, as well ashighly sensitive reward signals. Empirical observations from simulations,offline and online experiments highlight the efficacy of our deployed approach.|现实世界中的推荐系统在决定向用户展示哪些推荐内容时，通常需要平衡多个目标。这些目标包括行为信号（例如点击、分享、停留时间）以及更广泛的目标（例如多样性、公平性）。标量化方法通常用于处理这种平衡任务，其中每个目标的奖励信号的加权平均值决定了用于排序的最终得分。显然，如何精确计算这些权重是任何在线平台成功的关键。我们将此任务框架化为一个决策任务，其中标量化权重是为了最大化整体北极星奖励（例如长期用户留存或增长）而采取的行动。我们将现有的策略学习方法扩展到连续多元行动领域，提出最大化学习策略将产生的北极星奖励的悲观下界。基于正态近似的典型下界由于覆盖不足而受到影响，我们为此提出了一种高效且有效的策略依赖校正方法。我们提供了设计随机数据收集策略以及高度敏感的奖励信号的指导。从模拟、离线和在线实验中的经验观察结果突出了我们部署方法的效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Objective+Recommendation+via+Multivariate+Policy+Learning)|0|
|[AI-assisted Coding with Cody: Lessons from Context Retrieval and Evaluation for Code Recommendations](https://doi.org/10.1145/3640457.3688060)|Jan Hartman, Hitesh Sagtani, Julie Tibshirani, Rishabh Mehrotra|Sourcegraph, San Francisco, CA 94104 USA|In this work, we discuss a recently popular type of recommender system: an LLM-based coding assistant. Connecting the task of providing code recommendations in multiple formats to traditional RecSys challenges, we outline several similarities and differences due to domain specifics. We emphasize the importance of providing relevant context to an LLM for this use case and discuss lessons learned from context enhancements offline and online evaluation of such AI-assisted coding systems.|在这项工作中，我们讨论了一种最近流行的推荐系统类型：基于大型语言模型（LLM）的编程助手。通过将提供多种格式的代码推荐任务与传统推荐系统（RecSys）的挑战联系起来，我们概述了由于领域特性而产生的若干相似之处和差异。我们强调了在此用例中为LLM提供相关上下文的重要性，并讨论了从上下文增强中获得的经验教训，包括对这类AI辅助编程系统的离线和在线评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI-assisted+Coding+with+Cody:+Lessons+from+Context+Retrieval+and+Evaluation+for+Code+Recommendations)|0|
|[Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn)](https://doi.org/10.1145/3640457.3688034)|Moumita Bhattacharya, Vito Ostuni, Sudarshan Lamkhede|Netflix Res, Los Gatos, CA 95032 USA|Search and recommendation systems are essential in many services, and they are often developed separately, leading to complex maintenance and technical debt. In this paper, we present a unified deep learning model that efficiently handles key aspects of both tasks.|搜索和推荐系统在许多服务中至关重要，但它们通常被分开开发，导致维护复杂且技术债务积累。在本文中，我们提出了一种统一的深度学习模型，能够高效地处理这两项任务的关键方面。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Modeling+of+Search+and+Recommendations+Via+an+Unified+Contextual+Recommender+(UniCoRn))|0|
|[Leveraging LLM generated labels to reduce bad matches in job recommendations](https://doi.org/10.1145/3640457.3688043)|Yingchi Pei, Yi Wei Pang, Warren Cai, Nilanjan Sengupta, Dheeraj Toshniwal|Indeedcom, Hyderabad, Telangana, India; Indeedcom, Tokyo, Japan; Indeedcom, Singapore, Singapore|Negative signals are increasingly employed to enhance recommendation quality. However, explicit negative feedback is often sparse and may disproportionately reflect the preferences of more vocal users. Commonly used implicit negative feedback, such as impressions without positive interactions, has the limitation of not accurately capturing users’ true negative preferences because users mainly pursue information they consider interesting. In this work, we present an approach that leverages fine-tuned Large Language Models (LLMs) to evaluate recommendation quality and generate negative signals at scale while maintaining cost efficiency. We demonstrate significant improvements in our recommendation systems by deploying a traditional classifier trained using LLM-generated labels.|负面信号正越来越多地被用于提高推荐质量。然而，显式的负面反馈往往较为稀疏，并且可能不成比例地反映出更活跃用户的偏好。常用的隐式负面反馈，例如没有积极互动的展示，存在无法准确捕捉用户真实负面偏好的局限性，因为用户主要追求他们认为有趣的信息。在这项工作中，我们提出了一种方法，利用微调的大型语言模型（LLMs）来评估推荐质量并大规模生成负面信号，同时保持成本效益。我们通过部署一个使用LLM生成标签训练的传统分类器，展示了推荐系统的显著改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+LLM+generated+labels+to+reduce+bad+matches+in+job+recommendations)|0|
|[Toward 100TB Recommendation Models with Embedding Offloading](https://doi.org/10.1145/3640457.3688037)|Intaik Park, Ehsan Ardestani, Damian Reeves, Sarunya Pumma, Henry Tsang, Levy Zhao, Jian He, Joshua Deng, Dennis Van Der Staay, Yu Guo, Paul Zhang|Meta Platforms, Menlo Pk, CA 94025 USA|Training recommendation models become memory-bound with large embedding tables, and fast GPU memory is scarce. In this paper, we explore embedding caches and prefetch pipelines to effectively leverage large but slow host memory for embedding tables. We introduce Locality-Aware Sharding and iterative planning that automatically size caches optimally and produce effective sharding plans. Embedding Offloading, a system that combines all of these components and techniques, is implemented on top of Meta’s open-source libraries, FBGEMM GPU and TorchRec, and it is used to improve scalability and efficiency of industry-scale production models. Embedding Offloading achieved 37x model scale to 100TB model size with only 26% training speed regression.|随着嵌入表规模的增大，训练推荐模型变得受限于内存容量，而快速的GPU内存资源有限。在本文中，我们探索了嵌入缓存和预取流水线技术，以有效利用大容量但速度较慢的主机内存来存储嵌入表。我们提出了局部感知分片（Locality-Aware Sharding）和迭代规划方法，这些方法能够自动优化缓存大小并生成高效的分片方案。嵌入卸载（Embedding Offloading）是一个集成了上述所有组件和技术的系统，它基于Meta的开源库FBGEMM GPU和TorchRec实现，用于提升工业级生产模型的可扩展性和效率。嵌入卸载系统实现了模型规模提升37倍，达到了100TB的模型大小，而训练速度仅下降了26%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+100TB+Recommendation+Models+with+Embedding+Offloading)|0|
|[LLMs for User Interest Exploration in Large-scale Recommendation Systems](https://doi.org/10.1145/3640457.3688161)|Jianling Wang, Haokai Lu, Yifan Liu, He Ma, Yueqi Wang, Yang Gu, Shuzhou Zhang, Ningren Han, Shuchao Bi, Lexi Baugher, Ed H. Chi, Minmin Chen|Google, Mountain View, CA 94043 USA; Google DeepMind, Mountain View, CA 94043 USA|Traditional recommendation systems are subject to a strong feedback loop bylearning from and reinforcing past user-item interactions, which in turn limitsthe discovery of novel user interests. To address this, we introduce a hybridhierarchical framework combining Large Language Models (LLMs) and classicrecommendation models for user interest exploration. The framework controls theinterfacing between the LLMs and the classic recommendation models through"interest clusters", the granularity of which can be explicitly determined byalgorithm designers. It recommends the next novel interests by firstrepresenting "interest clusters" using language, and employs a fine-tuned LLMto generate novel interest descriptions that are strictly within thesepredefined clusters. At the low level, it grounds these generated interests toan item-level policy by restricting classic recommendation models, in this casea transformer-based sequence recommender to return items that fall within thenovel clusters generated at the high level. We showcase the efficacy of thisapproach on an industrial-scale commercial platform serving billions of users.Live experiments show a significant increase in both exploration of novelinterests and overall user enjoyment of the platform.|传统的推荐系统通过学习和强化过去的用户-物品交互，容易陷入强烈的反馈循环，这限制了用户新兴趣的发现。为了解决这一问题，我们引入了一种结合大型语言模型（LLMs）和经典推荐模型的混合分层框架，用于用户兴趣探索。该框架通过“兴趣簇”来控制LLMs和经典推荐模型之间的接口，“兴趣簇”的粒度可以由算法设计者明确确定。该框架首先用语言表示“兴趣簇”，然后使用微调的LLM生成严格限定在这些预定义簇内的新兴趣描述，从而推荐下一个新兴趣。在底层，它通过限制经典推荐模型（在本例中是基于Transformer的序列推荐器）返回属于高层生成的新簇内的物品，将这些生成的兴趣落地为物品级别的策略。我们在一个服务于数十亿用户的工业级商业平台上展示了该方法的有效性。实际实验表明，新兴趣的探索和用户对平台的整体满意度均显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLMs+for+User+Interest+Exploration+in+Large-scale+Recommendation+Systems)|0|
|[It's Not You, It's Me: The Impact of Choice Models and Ranking Strategies on Gender Imbalance in Music Recommendation](https://doi.org/10.1145/3640457.3688163)|Andres Ferraro, Michael D. Ekstrand, Christine Bauer|Drexel Univ, Philadelphia, PA 19104 USA; Pandora Sirius XM, Oakland, CA 94612 USA; Paris Lodron Univ Salzburg, Salzburg, Austria|As recommender systems are prone to various biases, mitigation approaches are needed to ensure that recommendations are fair to various stakeholders. One particular concern in music recommendation is artist gender fairness. Recent work has shown that the gender imbalance in the sector translates to the output of music recommender systems, creating a feedback loop that can reinforce gender biases over time. In this work, we examine that feedback loop to study whether algorithmic strategies or user behavior are a greater contributor to ongoing improvement (or loss) in fairness as models are repeatedly re-trained on new user feedback data. We simulate user interaction and re-training to investigate the effects of ranking strategies and user choice models on gender fairness metrics. We find re-ranking strategies have a greater effect than user choice models on recommendation fairness over time.|由于推荐系统容易受到各种偏见的影响，需要采取缓解措施以确保推荐对各方利益相关者都是公平的。在音乐推荐中，一个特别值得关注的问题是艺术家性别公平性。最近的研究表明，该领域内的性别不平衡会反映在音乐推荐系统的输出中，形成一个反馈循环，随着时间的推移可能会加剧性别偏见。在这项工作中，我们研究了这一反馈循环，以探讨在模型反复使用新用户反馈数据进行重新训练时，算法策略或用户行为对公平性持续改善（或恶化）的贡献更大。我们通过模拟用户交互和重新训练，研究了排名策略和用户选择模型对性别公平性指标的影响。结果表明，随着时间的推移，重新排名策略对推荐公平性的影响大于用户选择模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=It's+Not+You,+It's+Me:+The+Impact+of+Choice+Models+and+Ranking+Strategies+on+Gender+Imbalance+in+Music+Recommendation)|0|
|[Pay Attention to Attention for Sequential Recommendation](https://doi.org/10.1145/3640457.3688164)|Yuli Liu, Min Liu, Xiaojing Liu|Qinghai Univ, Intelligent Comp & Applicat Lab Qinghai Prov, Xining 810016, Peoples R China|Transformer-based approaches have demonstrated remarkable success in various sequence-based tasks. However, traditional self-attention models may not sufficiently capture the intricate dependencies within items in sequential recommendation scenarios. This is due to the lack of explicit emphasis on attention weights, which play a critical role in allocating attention and understanding item-to-item correlations. To better exploit the potential of attention weights and improve the capability of sequential recommendation in learning high-order dependencies, we propose a novel sequential recommendation (SR) approach called attention weight refinement (AWRSR). AWRSR enhances the effectiveness of self-attention by additionally paying attention to attention weights, allowing for more refined attention distributions of correlations among items. We conduct comprehensive experiments on multiple real-world datasets, demonstrating that our approach consistently outperforms state-of-the-art SR models. Moreover, we provide a thorough analysis of AWRSR’s effectiveness in capturing higher-level dependencies. These findings suggest that AWRSR offers a promising new direction for enhancing the performance of self-attention architecture in SR tasks, with potential applications in other sequence-based problems as well.|基于Transformer的方法在各种序列任务中取得了显著的成功。然而，在序列推荐场景中，传统的自注意力模型可能无法充分捕捉项目之间的复杂依赖关系。这主要是因为缺乏对注意力权重的显式强调，而注意力权重在分配注意力和理解项目间相关性方面起着关键作用。为了更好地发挥注意力权重的潜力并提高序列推荐模型在学习高阶依赖关系方面的能力，我们提出了一种新颖的序列推荐方法，称为注意力权重优化（AWRSR）。AWRSR通过额外关注注意力权重来增强自注意力的有效性，从而实现对项目间相关性更精细的注意力分布。我们在多个真实世界的数据集上进行了全面的实验，结果表明我们的方法在性能上始终优于最先进的序列推荐模型。此外，我们对AWRSR在捕捉更高层次依赖关系方面的有效性进行了深入分析。这些发现表明，AWRSR为增强自注意力架构在序列推荐任务中的性能提供了一个有前景的新方向，同时也有可能应用于其他基于序列的问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pay+Attention+to+Attention+for+Sequential+Recommendation)|0|
|[GLAMOR: Graph-based LAnguage MOdel embedding for citation Recommendation](https://doi.org/10.1145/3640457.3688171)|Zafar Ali, Guilin Qi, Irfan Ullah, Adam A. Q. Mohammed, Pavlos Kefalas, Khan Muhammad|Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece; Shaheed Benazir Bhutto Univ, Dept Comp Sci, Sheringal, Pakistan; Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China; Sungkyunkwan Univ, Sch Convergence, Seoul, South Korea|Digital publishing’s exponential growth has created vast scholarly collections. Guiding researchers to relevant resources is crucial, and knowledge graphs (KGs) are key tools for unlocking hidden knowledge. However, current methods focus on external links between concepts, ignoring the rich information within individual papers. Challenges like insufficient multi-relational data, name ambiguity, and cold-start issues further limit existing KG-based methods, failing to capture the intricate attributes of diverse entities. To solve these issues, we propose GLAMOR, a robust KG framework encompassing entities e.g., authors, papers, fields of study, and concepts, along with their semantic interconnections. GLAMOR uses a novel random walk-based KG text generation method and then fine-tunes the language model using the generated text. Subsequently, the acquired context-preserving embeddings facilitate superior top@k predictions. Evaluation results on two public benchmark datasets demonstrate our GLAMOR’s superiority against state-of-the-art methods especially in solving the cold-start problem.|数字出版的指数级增长催生了庞大的学术资源库。如何引导研究者找到相关资源至关重要，而知识图谱（KGs）是挖掘隐藏知识的关键工具。然而，现有方法主要关注概念之间的外部链接，忽略了单篇论文内部的丰富信息。多关系数据不足、名称歧义以及冷启动问题等挑战进一步限制了当前基于知识图谱的方法，使其难以捕捉多样化实体的复杂属性。为解决这些问题，我们提出了GLAMOR，这是一个强大的知识图谱框架，涵盖作者、论文、研究领域和概念等实体及其语义关联。GLAMOR采用了一种基于随机游走的新型知识图谱文本生成方法，随后利用生成的文本对语言模型进行微调。通过这种方式获得的上下文保留嵌入能够显著提升top@k预测的效果。在两个公开基准数据集上的评估结果表明，GLAMOR在解决冷启动问题方面表现尤为突出，优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GLAMOR:+Graph-based+LAnguage+MOdel+embedding+for+citation+Recommendation)|0|
|[Self-Attentive Sequential Recommendations with Hyperbolic Representations](https://doi.org/10.1145/3640457.3688180)|Evgeny Frolov, Tatyana Matveeva, Leyla Mirvakhabova, Ivan V. Oseledets|Skolkovo Inst Sci & Technol, AIRI, Moscow, Russia; HSE Univ, Moscow, Russia; Skolkovo Inst Sci & Technol, Moscow, Russia|In recent years, self-attentive sequential learning models have surpassed conventional collaborative filtering techniques in next-item recommendation tasks. However, Euclidean geometry utilized in these models may not be optimal for capturing a complex structure of behavioral data. Building on recent advances in the application of hyperbolic geometry to collaborative filtering tasks, we propose a novel approach that leverages hyperbolic geometry in the sequential learning setting. Our approach replaces final output of the Euclidean models with a linear predictor in the non-linear hyperbolic space, which increases the representational capacity and improves recommendation quality.|近年来，自注意力序列学习模型在下一项推荐任务中已经超越了传统的协同过滤技术。然而，这些模型中使用的欧几里得几何可能无法最佳地捕捉行为数据的复杂结构。基于最近双曲几何在协同过滤任务中的应用进展，我们提出了一种新颖的方法，在序列学习环境中利用双曲几何。我们的方法将欧几里得模型的最终输出替换为非线性双曲空间中的线性预测器，从而提高了表示能力并改善了推荐质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Attentive+Sequential+Recommendations+with+Hyperbolic+Representations)|0|
|[It's (not) all about that CTR: A Multi-Stakeholder Perspective on News Recommender Metrics](https://doi.org/10.1145/3640457.3688183)|Hanne Vandenbroucke, Annelien Smets|Vrije Univ Brussel, Imec Smit, Brussels, Belgium|Recommender systems are increasingly used by news media organizations. Existing literature examines various aspects of news recommender systems (NRS) from a computational, user-centric, or normative perspective. Yet research advocates studying the complexities of real-world applications around NRS. Recently, a multi-stakeholder approach to NRS has been adopted, allowing to understand different stakeholder perspectives on NRS development and evaluation within the news organization. However, little research has been done on the different key performance indicators (KPIs) and metrics considered valuable by different stakeholders. Based on 11 interviews with professionals from two commercial news publishers, this paper demonstrates that stakeholders prioritize distinct KPIs and metrics related to the reach-engagement-conversion-retention funnel. The evaluation of NRS performance is often limited to short-term metrics like CTR, overlooking the multiplicity of stakeholders involved. Our findings reveal how different purposes, KPIs, and metrics are valued from the journalistic, commercial, and tech logic. In doing so, this paper contributes to the multi-stakeholder approach to NRS, advancing our understanding of the real-world complexity of NRS development and evaluation.|推荐系统在新闻媒体机构中的应用日益广泛。现有文献从计算、用户中心或规范的角度探讨了新闻推荐系统（NRS）的各个方面。然而，研究主张围绕新闻推荐系统的实际应用复杂性进行研究。最近，新闻推荐系统采用了一种多利益相关者的方法，使得人们能够理解新闻机构内不同利益相关者对新闻推荐系统开发和评估的不同视角。然而，关于不同利益相关者认为有价值的关键绩效指标（KPIs）和度量标准的研究却很少。基于对两家商业新闻出版商的11位专业人员的访谈，本文展示了利益相关者优先考虑与触达-参与-转化-留存漏斗相关的不同关键绩效指标和度量标准。新闻推荐系统性能的评估通常局限于点击率（CTR）等短期指标，忽视了所涉及的多重利益相关者。我们的研究结果揭示了从新闻、商业和技术逻辑出发，不同目的、关键绩效指标和度量标准如何被重视。通过这样做，本文为新闻推荐系统的多利益相关者方法做出了贡献，增进了我们对新闻推荐系统开发和评估的实际复杂性的理解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=It's+(not)+all+about+that+CTR:+A+Multi-Stakeholder+Perspective+on+News+Recommender+Metrics)|0|
|[Recommending Personalised Targeted Training Adjustments for Marathon Runners](https://doi.org/10.1145/3640457.3688192)|Ciara Feely, Brian Caulfield, Aonghus Lawlor, Barry Smyth|Univ Coll Dublin, Insight Ctr Data Analyt, Sch Comp Sci, Dublin, Ireland|Preparing for the marathon involves many weeks of dedicated training. Achieving the right balance between building strength and endurance and the need for rest and recovery is a must, if a runner is to arrive at the start-line injury-free and ready to achieve their desired finish-time. However, because most recreational runners rely on generic training plans, they can struggle to find this balance, which can impact their motivation, health, and performance. In this paper, we describe a novel case-based reasoning approach to fine-tuning a runner’s training by recommending training adjustments based on the patterns of similar runners at corresponding points in their marathon training. The approach is designed to target training adjustments that are based on similar runners but with varying race goals, to allow runners to adjust their training for slower or faster finish-times, as their training progresses and motivations change. We evaluate the recommendations produced using a large-scale real-world dataset according to several factors: (i) the plausibility of the recommended training adjustment, (ii) the effectiveness of the adjustment when it comes to achieving a particular performance goal, and (iii) the safety of the adjustment in terms of the degree of risk that it will lead to an injury or otherwise disrupt training. Our findings suggest that plausible, effective, and safe recommendations can be generated for runners when evaluated against a range of race goals.|准备马拉松比赛需要数周时间的专注训练。如果跑者想要在起跑线上无伤且准备好实现他们期望的完赛时间，就必须在增强力量和耐力与休息恢复之间找到适当的平衡。然而，由于大多数业余跑者依赖于通用的训练计划，他们可能难以找到这种平衡，这可能会影响他们的积极性、健康和表现。在本文中，我们描述了一种新颖的基于案例推理的方法，通过根据类似跑者在马拉松训练中相应阶段的模式推荐训练调整，来微调跑者的训练。该方法旨在针对基于类似跑者但具有不同比赛目标的训练调整，以允许跑者在训练进展和动机变化时调整他们的训练，以实现更慢或更快的完赛时间。我们根据几个因素评估了使用大规模真实世界数据集生成的推荐：(i) 推荐训练调整的合理性，(ii) 在实现特定性能目标时调整的有效性，以及 (iii) 调整的安全性，即它导致受伤或干扰训练的风险程度。我们的研究结果表明，当针对一系列比赛目标进行评估时，可以为跑者生成合理、有效且安全的推荐。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommending+Personalised+Targeted+Training+Adjustments+for+Marathon+Runners)|0|
|[Recommending Healthy and Sustainable Meals exploiting Food Retrieval and Large Language Models](https://doi.org/10.1145/3640457.3688193)|Alessandro Petruzzelli, Cataldo Musto, Michele Ciro Di Carlo, Giovanni Tempesta, Giovanni Semeraro|Univ Bari Aldo Moro, Bari, Italy|Given the rising global concerns about healthy nutrition and environmental sustainability, individuals need more and more support in making good choices concerning their daily meals. To this end, in this paper we introduce HeaSE, a framework for Healthy And Sustainable Eating. Given an input recipe, HeaSE identifies healthier and more sustainable meals by exploiting retrieval techniques and large language models. The framework works in two steps. First, it uses food retrieval strategies based on macro-nutrient information to identify candidate alternative meals. This ensures that the substitutions maintain a similar nutritional profile. Next, HeaSE employs large language models to re-rank these potential replacements while considering factors beyond just nutrition, such as the recipe’s environmental impact. In the experimental evaluation, we showed the capabilities of LLMs in identifying more sustainable and healthier alternatives within a set of candidate options. This highlights the potential of these models to guide users towards food choices that are both nutritious and environmentally responsible.|鉴于全球对健康营养和环境可持续性日益增长的关注，个人在做出日常饮食选择时需要越来越多的支持。为此，本文介绍了一种名为HeaSE（健康与可持续饮食）的框架。给定一个输入食谱，HeaSE通过利用检索技术和大型语言模型，识别出更健康、更可持续的饮食方案。该框架分为两个步骤。首先，它基于宏量营养素信息使用食物检索策略来识别候选替代餐食，以确保替代品保持相似的营养特征。接着，HeaSE利用大型语言模型对这些潜在替代品进行重新排序，同时考虑除营养之外的其他因素，如食谱的环境影响。在实验评估中，我们展示了大型语言模型在一组候选选项内识别出更可持续和更健康替代方案的能力。这凸显了这些模型在引导用户选择既营养又对环境负责的食物方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommending+Healthy+and+Sustainable+Meals+exploiting+Food+Retrieval+and+Large+Language+Models)|0|
|[Does It Look Sequential? An Analysis of Datasets for Evaluation of Sequential Recommendations](https://doi.org/10.1145/3640457.3688195)|Anton Klenitskiy, Anna Volodkevich, Anton Pembek, Alexey Vasilev|Sber AI Lab, Moscow, Russia|Sequential recommender systems are an important and demanded area of research. Such systems aim to use the order of interactions in a user's history to predict future interactions. The premise is that the order of interactions and sequential patterns play an essential role. Therefore, it is crucial to use datasets that exhibit a sequential structure to evaluate sequential recommenders properly. We apply several methods based on the random shuffling of the user's sequence of interactions to assess the strength of sequential structure across 15 datasets, frequently used for sequential recommender systems evaluation in recent research papers presented at top-tier conferences. As shuffling explicitly breaks sequential dependencies inherent in datasets, we estimate the strength of sequential patterns by comparing metrics for shuffled and original versions of the dataset. Our findings show that several popular datasets have a rather weak sequential structure.|序列推荐系统是一个重要且需求旺盛的研究领域。此类系统旨在利用用户历史中的交互顺序来预测未来的交互。其前提是交互顺序和序列模式起着至关重要的作用。因此，使用具有序列结构的数据集来正确评估序列推荐系统至关重要。我们基于用户交互序列的随机打乱应用了几种方法，以评估15个数据集中的序列结构强度，这些数据集在最近顶级会议发表的研究论文中经常用于序列推荐系统的评估。由于打乱操作显式地破坏了数据集中固有的序列依赖关系，我们通过比较打乱后和原始版本数据集的指标来估计序列模式的强度。我们的研究结果表明，几个流行的数据集具有较弱的序列结构。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Does+It+Look+Sequential?+An+Analysis+of+Datasets+for+Evaluation+of+Sequential+Recommendations)|0|
|[TLRec: A Transfer Learning Framework to Enhance Large Language Models for Sequential Recommendation Tasks](https://doi.org/10.1145/3640457.3691710)|Jiaye Lin, Shuang Peng, Zhong Zhang, Peilin Zhao|Tsinghua Univ, Beijing, Peoples R China; Zhejiang Lab, Hangzhou, Peoples R China; Tencent AI Lab, Shenzhen, Peoples R China|Recently, Large Language Models (LLMs) have garnered significant attention in recommendation systems, improving recommendation performance through in-context learning or parameter-efficient fine-tuning. However, cross-domain generalization, i.e., model training in one scenario (source domain) but inference in another (target domain), is underexplored. In this paper, we present TLRec, a transfer learning framework aimed at enhancing LLMs for sequential recommendation tasks. TLRec specifically focuses on text inputs to mitigate the challenge of limited transferability across diverse domains, offering promising advantages over traditional recommendation models that heavily depend on unique identities (IDs) like user IDs and item IDs. Moreover, we leverage the source domain data to further enhance LLMs’ performance in the target domain. Initially, we employ powerful closed-source LLMs (e.g., GPT-4) and chain-of-thought techniques to construct instruction tuning data from the third-party scenario (source domain). Subsequently, we apply curriculum learning to fine-tune LLMs for effective knowledge injection and perform recommendations in the target domain. Experimental results demonstrate that TLRec achieves superior performance under the zero-shot and few-shot settings.|最近，大型语言模型（LLMs）在推荐系统中获得了显著关注，通过上下文学习或参数高效微调提升了推荐性能。然而，跨领域泛化，即在一个场景（源领域）中训练模型，但在另一个场景（目标领域）中进行推理，尚未得到充分探索。在本文中，我们提出了TLRec，一个旨在增强LLMs在序列推荐任务中的迁移学习框架。TLRec特别关注文本输入，以缓解不同领域之间可迁移性有限的挑战，相较于传统推荐模型主要依赖于用户ID和物品ID等唯一标识符，TLRec提供了显著的优势。此外，我们利用源领域数据进一步增强LLMs在目标领域中的表现。首先，我们使用强大的闭源LLMs（例如GPT-4）和思维链技术从第三方场景（源领域）构建指令微调数据。随后，我们应用课程学习对LLMs进行微调，以实现有效的知识注入，并在目标领域中进行推荐。实验结果表明，TLRec在零样本和少样本设置下均表现出优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TLRec:+A+Transfer+Learning+Framework+to+Enhance+Large+Language+Models+for+Sequential+Recommendation+Tasks)|0|
|[Leveraging Monte Carlo Tree Search for Group Recommendation](https://doi.org/10.1145/3640457.3691713)|Antonela Tommasel, J. Andres DiazPace|ISISTAN, CONICET UNCPBA, Tandil, Argentina|Group recommenders aim to provide recommendations that satisfy the collective preferences of multiple users, a challenging task due to the diverse individual tastes and conflicting interests to be balanced. This is often accomplished by using aggregation techniques that select items on which the group can agree. Traditional aggregators struggle with these complexities, as items are chosen independently, leading to sub-optimal recommendations lacking diversity, novelty, or fairness. In this paper, we propose an aggregation technique that leverages Monte Carlo Tree Search (MCTS) to enhance group recommendations. MCTS is used to explore and evaluate candidate recommendation sequences to optimize overall group satisfaction. We also investigate the integration of MCTS with LLMs aiming at better understanding interactions between user preferences and recommendation sequences to inform the search. Experimental evaluations, although preliminary, showed that our proposal outperforms existing aggregation techniques in terms of relevance and beyond-accuracy aspects of recommendations. The LLM integration achieved positive results for recommendations’ relevance. Overall, this work highlights the potential of heuristic search techniques to tackle the complexities of group recommendations.|群体推荐系统的目标是为多个用户提供满足其集体偏好的推荐，这是一项具有挑战性的任务，因为需要平衡多样化的个人喜好和冲突的利益。这一任务通常通过使用聚合技术来实现，这些技术选择群体能够达成一致的物品。传统的聚合方法难以应对这些复杂性，因为物品是独立选择的，导致推荐结果缺乏多样性、新颖性或公平性，从而无法达到最优效果。在本文中，我们提出了一种利用蒙特卡洛树搜索（MCTS）来增强群体推荐的聚合技术。MCTS用于探索和评估候选推荐序列，以优化整体群体满意度。我们还研究了将MCTS与大型语言模型（LLMs）结合的方法，旨在更好地理解用户偏好与推荐序列之间的交互，从而为搜索提供信息。尽管实验评估是初步的，但结果表明，我们的方法在推荐的相关性和超越准确性的多个方面优于现有的聚合技术。LLM的集成在推荐相关性方面取得了积极成果。总体而言，这项工作凸显了启发式搜索技术在应对群体推荐复杂性方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Monte+Carlo+Tree+Search+for+Group+Recommendation)|0|
|[Supporting Knowledge Workers through Personal Information Assistance with Context-aware Recommender Systems](https://doi.org/10.1145/3640457.3688010)|Mahta Bakhshizadeh||Recommender systems are extensively employed across various domains to mitigate information overload by providing personalized content. Despite their widespread use in sectors such as streaming, e-commerce, and social networks, utilizing them for personal information assistance is a comparatively novel application. This emerging application aims to develop intelligent systems capable of proactively providing knowledge workers with the most relevant information based on their context to enhance productivity. In this paper, we explore this innovative application by first defining the scope of our study, outlining the key objectives, and introducing the main challenges. We then present our current results and progress, including a comprehensive literature review, the proposal of a framework, the collection of a pioneering dataset, and the establishment of a benchmark for evaluating a recommendation scenario on our published dataset. We also discuss our ongoing efforts and future research directions.|推荐系统广泛应用于各个领域，通过提供个性化内容来缓解信息过载问题。尽管它们在流媒体、电子商务和社交网络等领域得到了广泛应用，但将其用于个人信息辅助仍然是一个相对新颖的应用。这一新兴应用旨在开发智能系统，能够根据知识工作者的情境主动提供最相关的信息，从而提高生产力。在本文中，我们通过首先定义研究范围，概述关键目标，并介绍主要挑战，来探索这一创新应用。接着，我们展示了当前的研究成果和进展，包括全面的文献综述、框架的提出、开创性数据集的收集，以及在我们发布的数据集上建立的推荐场景评估基准。此外，我们还讨论了正在进行的工作和未来的研究方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Supporting+Knowledge+Workers+through+Personal+Information+Assistance+with+Context-aware+Recommender+Systems)|0|
|[AI-based Human-Centered Recommender Systems: Empirical Experiments and Research Infrastructure](https://doi.org/10.1145/3640457.3688012)|Ruixuan Sun|Univ Minnesota, Grouplens Res, Minneapolis, MN 55455 USA|This is a dissertation plan built around human-centered empirical experiments evaluating recommender systems (RecSys). We see this as an important research theme since many AI-based RecSys algorithmic studies lack real human assessment. Therefore, we do not know how they work in the wild that only human experiments can tell us. We split this extended abstract into two parts - 1) A series of individual studies focusing on open questions about different human values or recommendation algorithms. Our completed works include user control over content diversity, user appreciation on DL-RecSys algorithms, and human-LLMRec interaction study. We also propose three future works to understand news recommendation depolarization, personalized news podcast, and interactive user representation; 2) An experimentation infrastructure named POPROX. As a personalized news recommendation platform, it aims to support the longitudinal study needs from the general AI and RecSys research community.|这是一份围绕以人为中心的实证实验评估推荐系统（RecSys）的论文计划。我们认为这是一个重要的研究主题，因为许多基于人工智能的推荐系统算法研究缺乏真实的人类评估。因此，我们不知道它们在现实世界中的表现如何，只有通过人类实验才能告诉我们。我们将此扩展摘要分为两部分：1）一系列专注于不同人类价值观或推荐算法开放问题的独立研究。我们已完成的工作包括用户对内容多样性的控制、用户对深度学习推荐系统算法的评价，以及人类与大型语言模型推荐系统的交互研究。我们还提出了三项未来的研究工作，以理解新闻推荐的去极化、个性化新闻播客以及交互式用户表示；2）一个名为POPROX的实验基础设施。作为一个个性化新闻推荐平台，它旨在支持人工智能和推荐系统研究社区的纵向研究需求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI-based+Human-Centered+Recommender+Systems:+Empirical+Experiments+and+Research+Infrastructure)|0|
|[Learning Personalized Health Recommendations via Offline Reinforcement Learning](https://doi.org/10.1145/3640457.3688021)|Larry Donald Preuett|Univ Washington, Tacoma, WA 98402 USA|The healthcare industry is strained and would benefit from personalized treatment plans for treating various health conditions (e.g., HIV and diabetes). Reinforcement Learning is a promising approach to learning such sequential recommendation systems. However, applying reinforcement learning in the medical domain is challenging due to the lack of adequate evaluation metrics, partial observability, and the inability to explore due to safety concerns. In this line of work, we identify three research directions to improve the applicability of treatment plans learned using offline reinforcement learning.|医疗行业面临着巨大压力，而针对各种健康状况（如HIV和糖尿病）的个性化治疗方案将为其带来显著益处。强化学习是一种有前景的方法，可用于学习此类序列推荐系统。然而，在医疗领域应用强化学习面临诸多挑战，包括缺乏适当的评估指标、部分可观测性以及因安全问题而无法进行探索。在这项工作中，我们确定了三个研究方向，以提高基于离线强化学习所得治疗方案的应用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Personalized+Health+Recommendations+via+Offline+Reinforcement+Learning)|0|
|[Towards Symbiotic Recommendations: Leveraging LLMs for Conversational Recommendation Systems](https://doi.org/10.1145/3640457.3688023)|Alessandro Petruzzelli|Univ Bari Aldo Moro, Dept Comp Sci, Bari, Italy|Traditional recommender systems (RSs) generate suggestions by relying on user preferences and item characteristics. However, they do not to properly involve the user in the decision-making process. This gap is particularly evident in Conversational Recommender Systems (CRSs), where existing methods struggle to facilitate meaningful dialogue and dynamic user interactions. To address this limitation, in my Ph.D. project I will ground on the principles of Symbiotic AI (SAI) to propose a novel approach for CRS. Rather than treating users as passive recipients, this approach aims to engage them in an adaptive dialogue based on their preferences, previous interactions, and personal characteristics, thus fostering collaborative decision-making. To achieve this objective, my research unfolds in three phases. First, I will adapt Large Language Models (LLMs) to effectively handle recommendation tasks in a number of different domains, by also introducing knowledge injection techniques. Second, I will develop a CRS that not only provides accurate recommendations but also offers natural language explanations and responds to user queries, thereby promoting transparency and building user trust. Finally, I will consider users’ personal characteristics to personalize the CRS’s response strategy, ensuring adaptive and effective communication in line with SAI principles.|传统的推荐系统（RSs）通过依赖用户偏好和物品特征来生成推荐建议。然而，这些系统并未充分将用户纳入决策过程。这一不足在对话式推荐系统（CRSs）中尤为明显，现有方法难以促进有意义的对话和动态的用户互动。为了解决这一局限性，在我的博士项目中，我将基于共生人工智能（SAI）的原则，提出一种新的CRS方法。该方法不再将用户视为被动的接收者，而是旨在根据用户的偏好、先前的互动和个人特征，让他们参与到一个自适应的对话中，从而促进协作决策。为实现这一目标，我的研究将分为三个阶段展开。首先，我将调整大型语言模型（LLMs），使其能够有效处理多个不同领域的推荐任务，同时引入知识注入技术。其次，我将开发一个不仅能够提供准确推荐，还能提供自然语言解释并回应用户查询的CRS，从而提升透明度并建立用户信任。最后，我将考虑用户的个人特征，个性化CRS的响应策略，确保符合SAI原则的自适应和有效沟通。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Symbiotic+Recommendations:+Leveraging+LLMs+for+Conversational+Recommendation+Systems)|0|
|[Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction](https://doi.org/10.1145/3640457.3688184)|Yi Wu, Daryl Chang, Jennifer She, Zhe Zhao, Li Wei, Lukasz Heldt|Univ Calif Davis, Davis, CA 95616 USA; Google DeepMind, Mountain View, CA USA; Google Inc, Mountain View, CA 94043 USA|We present the Learned Ranking Function (LRF), a system that takes short-term user-item behavior predictions as input and outputs a slate of recommendations that directly optimizes for long-term user satisfaction. Most previous work is based on optimizing the hyperparameters of a heuristic function. We propose to model the problem directly as a slate optimization problem with the objective of maximizing long-term user satisfaction. We also develop a novel constraint optimization algorithm that stabilizes objective trade-offs for multi-objective optimization. We evaluate our approach with live experiments and describe its deployment on YouTube.|我们提出了学习排序函数（Learned Ranking Function, LRF），该系统以短期用户-物品行为预测作为输入，并输出直接优化长期用户满意度的推荐列表。大多数先前的研究基于优化启发式函数的超参数。我们提出将该问题直接建模为一个列表优化问题，目标是最大化长期用户满意度。我们还开发了一种新颖的约束优化算法，以稳定多目标优化的目标权衡。我们通过在线实验评估了我们的方法，并描述了其在YouTube上的部署情况。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learned+Ranking+Function:+From+Short-term+Behavior+Predictions+to+Long-term+User+Satisfaction)|0|
|[Putting Popularity Bias Mitigation to the Test: A User-Centric Evaluation in Music Recommenders](https://doi.org/10.1145/3640457.3688102)|Robin Ungruh, Karlijn Dinnissen, Anja Volk, Maria Soledad Pera, Hanna Hauptmann|Delft Univ Technol, Delft, Netherlands; Univ Utrecht, Utrecht, Netherlands|Popularity bias is a prominent phenomenon in recommender systems (RS), especially in the music domain. Although popularity bias mitigation techniques are known to enhance the fairness of RS while maintaining their high performance, there is a lack of understanding regarding users’ actual perception of the suggested music. To address this gap, we conducted a user study (n=40) exploring user satisfaction and perception of personalized music recommendations generated by algorithms that explicitly mitigate popularity bias. Specifically, we investigate item-centered and user-centered bias mitigation techniques, aiming to ensure fairness for artists or users, respectively. Results show that neither mitigation technique harms the users’ satisfaction with the recommendation lists despite promoting underrepresented items. However, the item-centered mitigation technique impacts user perception; by promoting less popular items, it reduces users’ familiarity with the items. Lower familiarity evokes discovery—the feeling that the recommendations enrich the user’s taste. We demonstrate that this can ultimately lead to higher satisfaction, highlighting the potential of less-popular recommendations to improve the user experience.|流行度偏差是推荐系统（RS）中一个显著的现象，尤其是在音乐领域。尽管已知缓解流行度偏差的技术可以在保持推荐系统高性能的同时增强其公平性，但关于用户对所推荐音乐的实际感知仍缺乏了解。为了填补这一空白，我们进行了一项用户研究（n=40），探索用户对通过明确缓解流行度偏差的算法生成的个性化音乐推荐的满意度和感知。具体而言，我们研究了以项目为中心和以用户为中心的偏差缓解技术，旨在分别确保对艺术家或用户的公平性。结果表明，尽管推广了代表性不足的项目，但两种缓解技术均未损害用户对推荐列表的满意度。然而，以项目为中心的缓解技术影响了用户的感知；通过推广不太受欢迎的项目，它降低了用户对项目的熟悉度。较低的熟悉度引发了发现感——即推荐丰富了用户品味的感受。我们证明这最终可以带来更高的满意度，突显了不太受欢迎的推荐在改善用户体验方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Putting+Popularity+Bias+Mitigation+to+the+Test:+A+User-Centric+Evaluation+in+Music+Recommenders)|0|
|[Discerning Canonical User Representation for Cross-Domain Recommendation](https://doi.org/10.1145/3640457.3688114)|Siqian Zhao, Sherry Sahebi|SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA|Cross-domain recommender systems (CDRs) aim to enhance recommendation outcomes by information transfer across different domains. Existing CDRs have investigated the learning of both domain-specific and domain-shared user preferences to enhance recommendation performance. However, these models typically allow the disparities between shared and distinct user preferences to emerge freely in any space, lacking sufficient constraints to identify differences between two domains and to ensure that both domains are considered simultaneously. Canonical Correlation Analysis (CCA) has shown promise for transferring information between domains. However, CCA only models domain similarities and fails to capture the potential differences between user preferences in different domains. We propose Discerning Canonical User Representation for Cross-Domain Recommendation (DiCUR-CDR) that learns domain-shared and domain-specific user representations simultaneously considering both domains’ latent spaces. DiCUR-CDR introduces Discerning Canonical Correlation (DisCCA) user representation learning, a novel design of non-linear CCA for mapping user representations. Unlike prior CCA models that only model the domain-shared multivariate representations by finding their linear transformations, DisCCA uses the same transformations to discover the domain-specific representations too. We compare DiCUR-CDR against several state-of-the-art approaches using two real-world datasets and demonstrate the significance of separately learning shared and specific user representations via DisCCA.|跨域推荐系统（CDRs）旨在通过跨不同领域的信息传递来提升推荐效果。现有的CDRs已经探索了学习领域特定和领域共享的用户偏好，以提高推荐性能。然而，这些模型通常允许共享和独特用户偏好之间的差异在任何空间中自由出现，缺乏足够的约束来识别两个领域之间的差异，并确保同时考虑两个领域。典型相关分析（CCA）在领域间信息传递方面显示出潜力。然而，CCA仅建模领域相似性，无法捕捉不同领域中用户偏好之间的潜在差异。我们提出了用于跨域推荐的辨别典型用户表示（DiCUR-CDR），该模型在学习领域共享和领域特定用户表示的同时，考虑了两个领域的潜在空间。DiCUR-CDR引入了辨别典型相关（DisCCA）用户表示学习，这是一种用于映射用户表示的非线性CCA的新设计。与之前仅通过寻找线性变换来建模领域共享的多变量表示的CCA模型不同，DisCCA使用相同的变换来发现领域特定的表示。我们使用两个真实世界的数据集将DiCUR-CDR与几种最先进的方法进行了比较，并展示了通过DisCCA分别学习共享和特定用户表示的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discerning+Canonical+User+Representation+for+Cross-Domain+Recommendation)|0|
|[Prompt Tuning for Item Cold-start Recommendation](https://doi.org/10.1145/3640457.3688126)|Yuezihan Jiang, Gaode Chen, Wenhan Zhang, Jingchi Wang, Yinjie Jiang, Qi Zhang, Jingjian Lin, Peng Jiang, Kaigui Bian|Peking Univ, Beijing, Peoples R China; Kuaishou Technol, Beijing, Peoples R China|The item cold-start problem is crucial for online recommender systems, as the success of the cold-start phase determines whether items can transition into popular ones. Prompt learning, a powerful technique used in natural language processing (NLP) to address zero- or few-shot problems, has been adapted for recommender systems to tackle similar challenges. However, existing methods typically rely on content-based properties or text descriptions for prompting, which we argue may be suboptimal for cold-start recommendations due to 1) semantic gaps with recommender tasks, 2) model bias caused by warm-up items contribute most of the positive feedback to the model, which is the core of the cold-start problem that hinders the recommender quality on cold-start items. We propose to leverage high-value positive feedback, termed pinnacle feedback as prompt information, to simultaneously resolve the above two problems. We experimentally prove that compared to the content description proposed in existing works, the positive feedback is more suitable to serve as prompt information by bridging the semantic gaps. Besides, we propose item-wise personalized prompt networks to encode pinnaclce feedback to relieve the model bias by the positive feedback dominance problem. Extensive experiments on four real-world datasets demonstrate the superiority of our model over state-of-the-art methods. Moreover, PROMO has been successfully deployed on a popular short-video sharing platform, a billion-user scale commercial short-video application, achieving remarkable performance gains across various commercial metrics within cold-start scenarios.|物品冷启动问题对于在线推荐系统至关重要，因为冷启动阶段的成功决定了物品能否转变为热门物品。提示学习（Prompt Learning）是一种在自然语言处理（NLP）中用于解决零样本或少样本问题的强大技术，已被应用于推荐系统以应对类似的挑战。然而，现有方法通常依赖于基于内容的属性或文本描述作为提示信息，我们认为这些方法在冷启动推荐中可能效果不佳，原因在于：1）与推荐任务存在语义鸿沟；2）由于预热物品贡献了大部分正向反馈，导致模型偏差，这是阻碍冷启动物品推荐质量的核心问题。我们提出利用高价值的正向反馈，称为**巅峰反馈**（pinnacle feedback），作为提示信息，以同时解决上述两个问题。我们通过实验证明，与现有工作中提出的内容描述相比，正向反馈通过弥合语义鸿沟，更适合作为提示信息。此外，我们提出了**物品个性化提示网络**（item-wise personalized prompt networks），用于编码巅峰反馈，以缓解由正向反馈主导问题引起的模型偏差。在四个真实世界数据集上的广泛实验表明，我们的模型优于最先进的方法。此外，PROMO 已成功部署在一个流行的短视频分享平台，这是一个拥有十亿级用户的商业短视频应用，在冷启动场景下，在各种商业指标上均取得了显著的性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Tuning+for+Item+Cold-start+Recommendation)|0|
|[A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph](https://doi.org/10.1145/3640457.3688070)|Daniele Malitesta, Claudio Pomo, Vito Walter Anelli, Alberto Carlo Maria Mancino, Tommaso Di Noia, Eugenio Di Sciascio|Politecn Bari, Bari, Italy; Univ Paris Saclay, Cent Supelec, INRIA, Gif Sur Yvette, France|Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation. As the number of GNNs approaches rises, some works have started questioning the theoretical and empirical reasons behind their superior performance. Nevertheless, this investigation still disregards that GNNs treat the recommendation data as a topological graph structure. Building on this assumption, in this work, we provide a novel evaluation perspective on GNNs-based recommendation, which investigates the impact of the graph topology on the recommendation performance. To this end, we select some (topological) properties of the recommendation data and three GNNs-based recommender systems (i.e., LightGCN, DGCF, and SVD-GCN). Then, starting from three popular recommendation datasets (i.e., Yelp2018, Gowalla, and Amazon-Book) we sample them to obtain 1,800 size-reduced datasets that still resemble the original ones but can encompass a wider range of topological structures. We use this procedure to build a large pool of samples for which data characteristics and recommendation performance of the selected GNNs models are measured. Through an explanatory framework, we find strong correspondences between graph topology and GNNs performance, offering a novel evaluation perspective on these models.|近年来，基于图神经网络（GNNs）的推荐系统在推荐领域取得了巨大成功。随着GNN方法的数量不断增加，一些研究开始质疑其卓越性能背后的理论和实证原因。然而，这些研究仍然忽视了GNNs将推荐数据视为拓扑图结构的事实。基于这一假设，在本研究中，我们提供了一个新颖的评估视角，探讨图拓扑对推荐性能的影响。为此，我们选择了推荐数据的一些（拓扑）特性以及三种基于GNNs的推荐系统（即LightGCN、DGCF和SVD-GCN）。然后，从三个流行的推荐数据集（即Yelp2018、Gowalla和Amazon-Book）出发，我们对它们进行采样，获得了1,800个规模缩减的数据集，这些数据集仍然与原始数据集相似，但能够涵盖更广泛的拓扑结构。我们使用这一过程构建了一个庞大的样本池，其中测量了所选GNN模型的数据特征和推荐性能。通过一个解释性框架，我们发现图拓扑与GNN性能之间存在强烈的对应关系，为这些模型提供了一个新颖的评估视角。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Novel+Evaluation+Perspective+on+GNNs-based+Recommender+Systems+through+the+Topology+of+the+User-Item+Graph)|0|
|[Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems](https://doi.org/10.1145/3640457.3688055)|Nikhil Khani, Li Wei, Aniruddh Nath, Shawn Andrews, Shuo Yang, Yang Liu, Pendo Abbo, Maciej Kula, Jarrod Kahn, Zhe Zhao, Lichan Hong, Ed H. Chi|Google LLC, Mountain View, CA 94043 USA; Google DeepMind, Mountain View, CA USA; Univ Calif Davis, Davis, CA 95616 USA|Knowledge Distillation (KD) is a powerful approach for compressing a large model into a smaller, more efficient model, particularly beneficial for latency-sensitive applications like recommender systems. However, current KD research predominantly focuses on Computer Vision (CV) and NLP tasks, overlooking unique data characteristics and challenges inherent to recommender systems. This paper addresses these overlooked challenges, specifically: (1) mitigating data distribution shifts between teacher and student models, (2) efficiently identifying optimal teacher configurations within time and budgetary constraints, and (3) enabling computationally efficient and rapid sharing of teacher labels to support multiple students. We present a robust KD system developed and rigorously evaluated on multiple large-scale personalized video recommendation systems within Google. Our live experiment results demonstrate significant improvements in student model performance while ensuring consistent and reliable generation of high quality teacher labels from a continuous data stream of data.|知识蒸馏（Knowledge Distillation, KD）是一种将大型模型压缩为更小、更高效的模型的有效方法，尤其对于推荐系统等对延迟敏感的应用具有显著优势。然而，当前的KD研究主要集中在计算机视觉（CV）和自然语言处理（NLP）任务上，忽视了推荐系统中独特的数据特征和固有挑战。本文针对这些被忽视的挑战进行了深入探讨，具体包括：（1）缓解教师模型和学生模型之间的数据分布偏移问题，（2）在时间和预算限制内高效识别最优教师模型配置，以及（3）实现教师标签的计算高效和快速共享，以支持多个学生模型。我们提出了一种稳健的KD系统，并在谷歌内部的多个大规模个性化视频推荐系统中进行了开发和严格评估。我们的在线实验结果表明，学生模型的性能得到了显著提升，同时确保了从连续数据流中一致且可靠地生成高质量的教师标签。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+the+Gap:+Unpacking+the+Hidden+Challenges+in+Knowledge+Distillation+for+Online+Ranking+Systems)|0|
|[Self-Auxiliary Distillation for Sample Efficient Learning in Google-Scale Recommenders](https://doi.org/10.1145/3640457.3688041)|Yin Zhang, Ruoxi Wang, Xiang Li, Tiansheng Yao, Andrew Evdokimov, Jonathan Valverde, Yuan Gao, Jerry Zhang, Evan Ettinger, Ed H. Chi, Derek Zhiyuan Cheng|Google Inc, Mountain View, CA USA; Google DeepMind, Mountain View, CA 94043 USA|Industrial recommendation systems process billions of daily user feedback which are complex and noisy. Efficiently uncovering user preference from these signals becomes crucial for high-quality recommendation. We argue that those signals are not inherently equal in terms of their informative value and training ability, which is particularly salient in industrial applications with multi-stage processes (e.g., augmentation, retrieval, ranking). Considering that, in this work, we propose a novel self-auxiliary distillation framework that prioritizes training on high-quality labels, and improves the resolution of low-quality labels through distillation by adding a bilateral branch-based auxiliary task. This approach enables flexible learning from diverse labels without additional computational costs, making it highly scalable and effective for Google-scale recommenders. Our framework consistently improved both offline and online key business metrics across three Google major products. Notably, self-auxiliary distillation proves to be highly effective in addressing the severe signal loss challenge posed by changes such as Apple iOS policy. It further delivered significant improvements in both offline (+17% AUC) and online metrics for a Google Apps recommendation system. This highlights the opportunities of addressing real-world signal loss problems through self-auxiliary distillation techniques.|工业推荐系统每天处理数十亿条用户反馈，这些反馈复杂且充满噪声。从这些信号中高效地挖掘用户偏好对于高质量的推荐至关重要。我们认为，这些信号在信息价值和训练能力方面并非天生平等，这在具有多阶段流程（例如，增强、检索、排序）的工业应用中尤为显著。考虑到这一点，在本工作中，我们提出了一种新颖的自辅助蒸馏框架，该框架优先在高质量标签上进行训练，并通过添加基于双边分支的辅助任务，通过蒸馏提高低质量标签的分辨率。这种方法能够在不增加计算成本的情况下灵活地从多样化的标签中学习，使其对谷歌规模的推荐系统具有高度的可扩展性和有效性。我们的框架在谷歌的三个主要产品中持续改善了离线和在线的关键业务指标。值得注意的是，自辅助蒸馏在应对由苹果iOS政策变化等带来的严重信号丢失挑战方面表现出极高的有效性。它进一步为谷歌应用推荐系统带来了显著的离线和在线指标提升（离线AUC提升17%）。这凸显了通过自辅助蒸馏技术解决现实世界信号丢失问题的巨大潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Auxiliary+Distillation+for+Sample+Efficient+Learning+in+Google-Scale+Recommenders)|0|
|[MODEM: Decoupling User Behavior for Shared-Account Video Recommendations on Large Screen Devices](https://doi.org/10.1145/3640457.3688167)|Jiang Li, Zhen Zhang, Xiang Feng, Muyang Li, Yongqi Liu, Lantao Hu|Kuaishou Technol Co Ltd, Beijing, Peoples R China; Univ Sci & Technol China, Software Engn Inst, Hefei, Peoples R China|In scenarios involving sequence recommendations on large screen devices, such as tablets or TVs, the equipment is often shared among multiple users. This sharing leads to a mixture of behaviors from different users, posing significant challenges to recommendation systems, especially when clear supervisory signals for distinguishing among users are absent. Current solutions tend to either operate in an unsupervised manner or rely on constructed supervisory signals that are not entirely reliable. Moreover, the peculiarities of short video recommendations in this context have not been thoroughly explored in existing research. In response to these challenges, this paper introduces Multi-User Contrastive Decoupling Model (MODEM), a novel short video recommendation model specifically designed for large screen devices. MODEM leverages an attention mechanism, grounded in session segmentation, to disentangle the intertwined user behavior histories. It also discriminates between the impacts of long and short viewing behaviors on short video recommendations by cross-analyzing sequences of both. Furthermore, we have developed a contrastive learning method to oversee the decoupling of user behaviors effectively. Our evaluations demonstrate noticeable improvements through both offline assessments within public datasets and online A/B testing within Kuaishou’s short video recommendation environment on large screen devices. Specifically, our online A/B tests resulted in a 0.55% increase in watch time. These results underscore MODEM’s efficacy in enhancing recommendation quality in shared account contexts.|在涉及平板电脑或电视等大屏幕设备上的序列推荐场景中，设备通常由多个用户共享。这种共享导致不同用户的行为混合在一起，给推荐系统带来了重大挑战，尤其是在缺乏明确的监督信号来区分用户的情况下。当前的解决方案往往以无监督的方式运行，或者依赖于构建的监督信号，但这些信号并不完全可靠。此外，现有研究尚未充分探讨在这种背景下短视频推荐的特性。针对这些挑战，本文提出了多用户对比解耦模型（Multi-User Contrastive Decoupling Model, MODEM），这是一种专为大屏幕设备设计的新型短视频推荐模型。MODEM利用基于会话分割的注意力机制，解耦交织在一起的用户行为历史。它还通过交叉分析长观看行为和短观看行为的序列，区分它们对短视频推荐的影响。此外，我们开发了一种对比学习方法，以有效监督用户行为的解耦。我们的评估表明，通过在公共数据集中的离线评估和在快手大屏幕设备短视频推荐环境中的在线A/B测试，推荐质量得到了显著提升。具体而言，我们的在线A/B测试使观看时间增加了0.55%。这些结果凸显了MODEM在共享账户情境下提升推荐质量的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MODEM:+Decoupling+User+Behavior+for+Shared-Account+Video+Recommendations+on+Large+Screen+Devices)|0|
|[beeFormer: Bridging the Gap Between Semantic and Interaction Similarity in Recommender Systems](https://doi.org/10.1145/3640457.3691707)|Vojtech Vancura, Pavel Kordík, Milan Straka|Charles Univ Prague, Fac Math & Phys, Prague, Czech Republic; Czech Tech Univ, Fac Informat Technol, Prague, Czech Republic|Recommender systems often use text-side information to improve their predictions, especially in cold-start or zero-shot recommendation scenarios, where traditional collaborative filtering approaches cannot be used. Many approaches to text-mining side information for recommender systems have been proposed over recent years, with sentence Transformers being the most prominent one. However, these models are trained to predict semantic similarity without utilizing interaction data with hidden patterns specific to recommender systems. In this paper, we propose beeFormer, a framework for training sentence Transformer models with interaction data. We demonstrate that our models trained with beeFormer can transfer knowledge between datasets while outperforming not only semantic similarity sentence Transformers but also traditional collaborative filtering methods. We also show that training on multiple datasets from different domains accumulates knowledge in a single model, unlocking the possibility of training universal, domain-agnostic sentence Transformer models to mine text representations for recommender systems. We release the source code, trained models, and additional details allowing replication of our experiments at https://github.com/recombee/beeformer.|推荐系统常常利用文本侧信息来提升其预测能力，尤其是在冷启动或零样本推荐场景中，传统的协同过滤方法无法适用。近年来，许多方法被提出用于为推荐系统挖掘文本侧信息，其中句子Transformer模型最为突出。然而，这些模型在训练时主要预测语义相似性，而没有利用推荐系统中特有的隐含交互数据模式。在本文中，我们提出了beeFormer，这是一个利用交互数据训练句子Transformer模型的框架。我们证明了通过beeFormer训练的模型能够在数据集之间传递知识，不仅超越了语义相似性句子Transformer模型，还优于传统的协同过滤方法。我们还展示了在不同领域的多个数据集上进行训练能够在一个模型中积累知识，从而开启了训练通用、领域无关的句子Transformer模型的可能性，以用于挖掘推荐系统中的文本表示。我们在https://github.com/recombee/beeformer上发布了源代码、训练模型以及其他详细信息，以便复现我们的实验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=beeFormer:+Bridging+the+Gap+Between+Semantic+and+Interaction+Similarity+in+Recommender+Systems)|0|
|[Enhancing Cross-Domain Recommender Systems with LLMs: Evaluating Bias and Beyond-Accuracy Measures](https://doi.org/10.1145/3640457.3688027)|Thomas Elmar Kolb|TU Wien, CD Lab Recommender Syst, Vienna, Austria|The research domain of recommender systems is rapidly evolving. Initially, optimization efforts focused primarily on accuracy. However, recent research has highlighted the importance of addressing bias and beyond-accuracy measures such as novelty, diversity, and serendipity. With the rise of multi-domain recommender systems, the need to re-examine bias and beyond-accuracy measures in cross-domain settings has become crucial. Traditional methods face challenges such as cold-start problems, which can potentially be mitigated by leveraging LLMs. This proposed work investigates how LLM-based recommendation methods can enhance cross-domain recommender systems, focusing on identifying, measuring, and mitigating bias while evaluating the impact of beyond-accuracy measures. We aim to provide new insights by comparing traditional and LLM-based systems within a real-world environment encompassing the domains of news, books, and various lifestyle areas. Our research seeks to address the outlined gaps and develop effective evaluation strategies for the unique challenges posed by LLMs in cross-domain recommender systems.|推荐系统研究领域正在快速发展。最初，优化工作主要集中在准确性上。然而，最近的研究强调了解决偏见以及超越准确性指标（如新颖性、多样性和偶然性）的重要性。随着多域推荐系统的兴起，重新审视跨域环境中的偏见和超越准确性指标的需求变得至关重要。传统方法面临着冷启动问题等挑战，而这些问题可能通过利用大型语言模型（LLMs）得到缓解。本研究探讨了基于LLM的推荐方法如何增强跨域推荐系统，重点关注在识别、测量和缓解偏见的同时，评估超越准确性指标的影响。我们旨在通过在实际环境中比较传统和基于LLM的系统，涵盖新闻、书籍和各种生活方式领域，提供新的见解。我们的研究旨在解决所概述的差距，并为LLM在跨域推荐系统中带来的独特挑战开发有效的评估策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Cross-Domain+Recommender+Systems+with+LLMs:+Evaluating+Bias+and+Beyond-Accuracy+Measures)|0|
|[The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems](https://doi.org/10.1145/3640457.3688158)|Guy Aridor, Duarte Gonçalves, Ruoyan Kong, Daniel Kluver, Joseph A. Konstan|UCL, London, England; Univ Minnesota Twin Cities, Minneapolis, MN USA; Northwestern Univ, Evanston, IL 60208 USA|An increasingly important aspect of designing recommender systems involves considering how recommendations will influence consumer choices. This paper addresses this issue by introducing a method for collecting user beliefs about un-experienced goods - a critical predictor of choice behavior. We implemented this method on the MovieLens platform, resulting in a rich dataset that combines user ratings, beliefs, and observed recommendations. We document challenges to such data collection, including selection bias in response and limited coverage of the product space. This unique resource empowers researchers to delve deeper into user behavior and analyze user choices absent recommendations, measure the effectiveness of recommendations, and prototype algorithms that leverage user belief data, ultimately leading to more impactful recommender systems. The dataset can be found at https://grouplens.org/datasets/movielens/ml_belief_2024/.|设计推荐系统时，一个日益重要的方面是考虑推荐如何影响消费者的选择。本文通过引入一种收集用户对未体验商品信念的方法来解决这一问题，这种方法对于预测选择行为至关重要。我们在MovieLens平台上实施了这一方法，从而获得了一个丰富的数据集，该数据集结合了用户评分、信念和观察到的推荐。我们记录了此类数据收集面临的挑战，包括响应中的选择偏差和产品空间的有限覆盖。这一独特资源使研究人员能够更深入地研究用户行为，分析无推荐情况下的用户选择，衡量推荐的有效性，并利用用户信念数据开发算法原型，最终推动更具影响力的推荐系统的诞生。该数据集可在https://grouplens.org/datasets/movielens/ml_belief_2024/找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+MovieLens+Beliefs+Dataset:+Collecting+Pre-Choice+Data+for+Online+Recommender+Systems)|0|
|[LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding](https://doi.org/10.1145/3640457.3688135)|Zhizhong Wan, Bin Yin, Junjie Xie, Fei Jiang, Xiang Li, Wei Lin|Meituan, Beijing, Peoples R China|Click-Through Rate (CTR) prediction is crucial for Recommendation System(RS), aiming to provide personalized recommendation services for users in many aspects such as food delivery, e-commerce and so on. However, traditional RS relies on collaborative signals, which lacks semantic understanding to real-time scenes. We also noticed that a major challenge in utilizing Large Language Models (LLMs) for practical recommendation purposes is their efficiency in dealing with long text input. To break through the problems above, we propose Large Language Model Aided Real-time Scene Recommendation(LARR), adopt LLMs for semantic understanding, utilizing real-time scene information in RS without requiring LLM to process the entire real-time scene text directly, thereby enhancing the efficiency of LLM-based CTR modeling. Specifically, recommendation domain-specific knowledge is injected into LLM and then RS employs an aggregation encoder to build real-time scene information from separate LLM's outputs. Firstly, a LLM is continual pretrained on corpus built from recommendation data with the aid of special tokens. Subsequently, the LLM is fine-tuned via contrastive learning on three kinds of sample construction strategies. Through this step, LLM is transformed into a text embedding model. Finally, LLM's separate outputs for different scene features are aggregated by an encoder, aligning to collaborative signals in RS, enhancing the performance of recommendation model.|点击率（CTR）预测对于推荐系统（RS）至关重要，旨在为外卖、电子商务等多个领域的用户提供个性化推荐服务。然而，传统的推荐系统依赖于协同信号，缺乏对实时场景的语义理解。我们还注意到，利用大型语言模型（LLMs）进行实际推荐的一个主要挑战是其在处理长文本输入时的效率。为了突破上述问题，我们提出了大型语言模型辅助的实时场景推荐（LARR），采用LLMs进行语义理解，在推荐系统中利用实时场景信息，而不需要LLM直接处理整个实时场景文本，从而提高了基于LLM的CTR建模效率。具体来说，推荐领域的特定知识被注入到LLM中，然后推荐系统使用聚合编码器从LLM的单独输出中构建实时场景信息。首先，LLM在推荐数据构建的语料库上通过特殊标记进行持续预训练。随后，通过对比学习在三种样本构建策略上对LLM进行微调。通过这一步，LLM被转化为文本嵌入模型。最后，LLM对不同场景特征的单独输出通过编码器进行聚合，与推荐系统中的协同信号对齐，从而提高了推荐模型的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LARR:+Large+Language+Model+Aided+Real-time+Scene+Recommendation+with+Semantic+Understanding)|0|
|[Not All Videos Become Outdated: Short-Video Recommendation by Learning to Deconfound Release Interval Bias](https://doi.org/10.1145/3640457.3688113)|Lulu Dong, Guoxiu He, Aixin Sun|Nanyang Technol Univ, Coll Comp & Data Sci, Singapore, Singapore; East China Normal Univ, Fac Econ & Management, Shanghai, Peoples R China|Short-video recommender systems often exhibit a biased preference to recently released videos. However, not all videos become outdated; certain classic videos can still attract user's attention. Such bias along temporal dimension can be further aggravated by the matching model between users and videos, because the model learns from preexisting interactions. From real data, we observe that different videos have varying sensitivities to recency in attracting users' attention. Our analysis, based on a causal graph modeling short-video recommendation, suggests that the release interval serves as a confounder, establishing a backdoor path between users and videos. To address this confounding effect, we propose a model-agnostic causal architecture called Learning to Deconfound the Release Interval Bias (LDRI). LDRI enables jointly learning of the matching model and the video recency sensitivity perceptron. In the inference stage, we apply a backdoor adjustment, effectively blocking the backdoor path by intervening on each video. Extensive experiments on two benchmarks demonstrate that LDRI consistently outperforms backbone models and exhibits superior performance against state-of-the-art models. Additional comprehensive analyses confirm the deconfounding capability of LDRI.|短视频推荐系统往往对近期发布的视频表现出偏好。然而，并非所有视频都会过时；某些经典视频仍然能够吸引用户的关注。这种时间维度上的偏见可能会因用户与视频之间的匹配模型而进一步加剧，因为该模型是从已有的交互中学习的。从实际数据中，我们观察到不同视频在吸引用户注意力时对时效性的敏感性各不相同。基于因果图对短视频推荐进行建模的分析表明，发布时间间隔起到了混杂因子的作用，在用户和视频之间建立了一条后门路径。为了解决这种混杂效应，我们提出了一种与模型无关的因果架构，称为学习去混杂发布时间间隔偏差（Learning to Deconfound the Release Interval Bias, LDRI）。LDRI 能够联合学习匹配模型和视频时效敏感性感知器。在推理阶段，我们应用后门调整，通过对每个视频进行干预，有效阻断了后门路径。在两个基准数据集上进行的大量实验表明，LDRI 始终优于骨干模型，并且在性能上超越了现有的最先进模型。额外的综合分析证实了 LDRI 的去混杂能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Videos+Become+Outdated:+Short-Video+Recommendation+by+Learning+to+Deconfound+Release+Interval+Bias)|0|
|[Do Recommender Systems Promote Local Music? A Reproducibility Study Using Music Streaming Data](https://doi.org/10.1145/3640457.3688065)|Kristina Matrosova, Lilian Marey, Guillaume SalhaGalvan, Thomas Louail, Olivier Bodini, Manuel Moussallam|Deezer Res, Paris, France; Telecom Paris, LTCI, Paris, France; CNRS, Geog Cites, Paris, France; USPN, LIPN, Lyon, France|This paper examines the influence of recommender systems on local music representation, discussing prior findings from an empirical study on the LFM-2b public dataset 1. This prior study argued that different recommender systems exhibit algorithmic biases shifting music consumption either towards or against local content. However, LFM-2b users do not reflect the diverse audience of music streaming services. To assess the robustness of this study’s conclusions, we conduct a comparative analysis using proprietary listening data from a global music streaming service, which we publicly release alongside this paper. We observe significant differences in local music consumption patterns between our dataset and LFM-2b, suggesting that caution should be exercised when drawing conclusions on local music based solely on LFM-2b. Moreover, we show that the algorithmic biases exhibited in the original work vary in our dataset, and that several unexplored model parameters can significantly influence these biases and affect the study’s conclusion on both datasets. Finally, we discuss the complexity of accurately labeling local music, emphasizing the risk of misleading conclusions due to unreliable, biased, or incomplete labels. To encourage further research and ensure reproducibility, we have publicly shared our dataset and code.|本文探讨了推荐系统对本地音乐表现的影响，并基于LFM-2b公开数据集1的实证研究讨论了先前的发现。先前的研究认为，不同的推荐系统表现出算法偏差，导致音乐消费向本地内容倾斜或偏离。然而，LFM-2b用户并不能反映音乐流媒体服务的多样化受众。为了评估该研究结论的稳健性，我们使用来自全球音乐流媒体服务的专有收听数据进行了比较分析，并将该数据与本文一同公开发布。我们发现，我们的数据集与LFM-2b在本地音乐消费模式上存在显著差异，这表明仅基于LFM-2b得出关于本地音乐的结论时需要谨慎。此外，我们还发现，原始研究中表现出的算法偏差在我们的数据集中有所不同，并且一些未探索的模型参数可能显著影响这些偏差，从而影响研究在两个数据集上的结论。最后，我们讨论了准确标注本地音乐的复杂性，强调了由于不可靠、有偏见或不完整的标签而导致的误导性结论的风险。为了鼓励进一步研究并确保可重复性，我们已公开分享了我们的数据集和代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+Recommender+Systems+Promote+Local+Music?+A+Reproducibility+Study+Using+Music+Streaming+Data)|0|
|[Improving Adversarial Robustness for Recommendation Model via Cross-Domain Distributional Adversarial Training](https://doi.org/10.1145/3640457.3688116)|Jingyu Chen, Lilin Zhang, Ning Yang|Sichuan Univ, Sch Comp Sci, Chengdu, Peoples R China|Recommendation models based on deep learning are fragile when facing adversarial examples (AE). Adversarial training (AT) is the existing mainstream method to promote the adversarial robustness of recommendation models. However, these AT methods often have two drawbacks. First, they may be ineffective due to the ubiquitous sparsity of interaction data. Second, point-wise perturbation used by these AT methods leads to suboptimal adversarial robustness, because not all examples are equally susceptible to such perturbations. To overcome these issues, we propose a novel method called Cross-domain Distributional Adversarial Training (CDAT) which utilizes a richer auxiliary domain to improve the adversarial robustness of a sparse target domain. CDAT comprises a Domain adversarial network (Dan) and a Cross-domain adversarial example generative network (Cdan). Dan learns a domain-invariant preference distribution which is obtained by aligning user embeddings from two domains and paves the way to leverage the knowledge from another domain for the target domain. Then, by adversarially perturbing the domain-invariant preference distribution under the guidance of a discriminator, Cdan captures an aggressive and imperceptible AE distribution. In this way, CDAT can transfer distributional adversarial robustness from the auxiliary domain to the target domain. The extensive experiments conducted on real datasets demonstrate the remarkable superiority of the proposed CDAT in improving the adversarial robustness of the sparse domain. The codes and datasets are available on https://github.com/HymanLoveGIN/CDAT.|基于深度学习的推荐模型在面对对抗样本（Adversarial Examples, AE）时表现出脆弱性。对抗训练（Adversarial Training, AT）是目前提升推荐模型对抗鲁棒性的主流方法。然而，现有的对抗训练方法通常存在两个缺点。首先，由于交互数据的普遍稀疏性，这些方法可能效果不佳。其次，这些对抗训练方法使用的逐点扰动（Point-wise Perturbation）会导致对抗鲁棒性次优，因为并非所有样本都同样容易受到此类扰动的影响。为了克服这些问题，我们提出了一种名为**跨域分布对抗训练（Cross-domain Distributional Adversarial Training, CDAT）**的新方法，该方法利用一个更丰富的辅助域来提升稀疏目标域的对抗鲁棒性。CDAT 包含一个**域对抗网络（Domain Adversarial Network, Dan）**和一个**跨域对抗样本生成网络（Cross-domain Adversarial Example Generative Network, Cdan）**。Dan 通过对齐来自两个域的用户嵌入，学习一个域不变的用户偏好分布，从而为从辅助域向目标域迁移知识奠定了基础。随后，Cdan 在判别器的指导下，通过对域不变的用户偏好分布进行对抗扰动，生成一种具有攻击性且难以察觉的对抗样本分布。通过这种方式，CDAT 能够将分布对抗鲁棒性从辅助域迁移到目标域。在真实数据集上进行的大量实验表明，CDAT 在提升稀疏域对抗鲁棒性方面具有显著优势。代码和数据集可在 https://github.com/HymanLoveGIN/CDAT 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Adversarial+Robustness+for+Recommendation+Model+via+Cross-Domain+Distributional+Adversarial+Training)|0|
|[Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations](https://doi.org/10.1145/3640457.3688137)|Alessandro Petruzzelli, Cataldo Musto, Lucrezia Laraspata, Ivan Rinaldi, Marco de Gemmis, Pasquale Lops, Giovanni Semeraro|Univ Bari Aldo Moro, Bari, Italy|In this paper, we present a strategy to provide users with explainable cross-domain recommendations (CDR) that exploits large language models (LLMs). Generally speaking, CDR is a task that is hard to tackle, mainly due to data sparsity issues. Indeed, CDR models require a large amount of data labeled in both source and target domains, which are not easy to collect. Accordingly, our approach relies on the intuition that the knowledge that is already encoded in LLMs can be used to more easily bridge the domains and seamlessly provide users with personalized cross-domain suggestions. To this end, we designed a pipeline to: (a) instruct a LLM to handle a CDR task; (b) design a personalized prompt, based on the preferences of the user in a source domain, and a list of items to be ranked in target domain; (c) feed the LLM with the prompt, in both zero-shot and one-shot settings, and process the answer in order to extract the recommendations and a natural language explanation. As shown in the experimental evaluation, our approach beats several established state-of-the-art baselines for CDR in most of the experimental settings, thus showing the effectiveness of LLMs also in this novel and scarcely investigated scenario.|本文提出了一种利用大型语言模型（LLMs）为用户提供可解释的跨域推荐（CDR）的策略。一般来说，CDR任务难以处理，主要是由于数据稀疏性问题。实际上，CDR模型需要在源域和目标域中标注大量数据，而这些数据并不容易收集。因此，我们的方法基于这样一种直觉：LLMs中已经编码的知识可以用来更容易地桥接不同领域，并无缝地为用户提供个性化的跨域推荐。为此，我们设计了一个流程来：（a）指导LLM处理CDR任务；（b）基于用户在源域中的偏好设计个性化提示，并在目标域中提供待排序的项目列表；（c）在零样本和单样本设置下向LLM提供提示，并处理其回答以提取推荐结果和自然语言解释。如实验评估所示，我们的方法在大多数实验设置中击败了几种已建立的CDR最先进基线，从而展示了LLMs在这一新颖且研究较少的场景中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Instructing+and+Prompting+Large+Language+Models+for+Explainable+Cross-domain+Recommendations)|0|
|[Touch the Core: Exploring Task Dependence Among Hybrid Targets for Recommendation](https://doi.org/10.1145/3640457.3688101)|Xing Tang, Yang Qiao, Fuyuan Lyu, Dugang Liu, Xiuqiang He|Guangdong Lab Artificial Intelligence & Digital E, Shenzhen, Peoples R China; Tencent, FiT, Shenzhen, Peoples R China|As user behaviors become complicated on business platforms, online recommendations focus more on how to touch the core conversions, which are highly related to the interests of platforms. These core conversions are usually continuous targets, such as watch time, revenue, and so on, whose predictions can be enhanced by previous discrete conversion actions. Therefore, multi-task learning (MTL) can be adopted as the paradigm to learn these hybrid targets. However, existing works mainly emphasize investigating the sequential dependence among discrete conversion actions, which neglects the complexity of dependence between discrete conversions and the final continuous conversion. Moreover, simultaneously optimizing hybrid tasks with stronger task dependence will suffer from volatile issues where the core regression task might have a larger influence on other tasks. In this paper, we study the MTL problem with hybrid targets for the first time and propose the model named Hybrid Targets Learning Network (HTLNet) to explore task dependence and enhance optimization. Specifically, we introduce label embedding for each task to explicitly transfer the label information among these tasks, which can effectively explore logical task dependence. We also further design the gradient adjustment regime between the final regression task and other classification tasks to enhance the optimization. Extensive experiments on two offline public datasets and one real-world industrial dataset are conducted to validate the effectiveness of HTLNet. Moreover, online A/B tests on the financial recommender system also show that our model has improved significantly. Our implementation is available here1.|随着用户在商业平台上的行为日益复杂，在线推荐系统更加关注如何触及核心转化，这些核心转化与平台的利益高度相关。这些核心转化通常是连续目标，如观看时长、收入等，它们的预测可以通过之前的离散转化行为来增强。因此，多任务学习（MTL）可以被采用为学习这些混合目标的范式。然而，现有的研究主要强调调查离散转化行为之间的序列依赖，忽视了离散转化与最终连续转化之间依赖关系的复杂性。此外，同时优化具有更强任务依赖性的混合任务会面临波动问题，其中核心回归任务可能对其他任务产生更大的影响。在本文中，我们首次研究了混合目标的多任务学习问题，并提出了名为混合目标学习网络（HTLNet）的模型，以探索任务依赖性并增强优化。具体来说，我们为每个任务引入了标签嵌入，以在这些任务之间显式传递标签信息，这可以有效探索逻辑任务依赖性。我们还进一步设计了最终回归任务与其他分类任务之间的梯度调整机制，以增强优化。在两个离线公共数据集和一个真实工业数据集上进行了大量实验，以验证HTLNet的有效性。此外，在金融推荐系统上的在线A/B测试也表明，我们的模型有显著改进。我们的实现可在此处获取1。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Touch+the+Core:+Exploring+Task+Dependence+Among+Hybrid+Targets+for+Recommendation)|0|
|[Scene-wise Adaptive Network for Dynamic Cold-start Scenes Optimization in CTR Prediction](https://doi.org/10.1145/3640457.3688115)|Wenhao Li, Jie Zhou, Chuan Luo, Chao Tang, Kun Zhang, Shixiong Zhao|Meituan, Beijing, Peoples R China; Huazhong Univ Sci & Technol, Beijing, Peoples R China; Beihang Univ, Sch Software, Beijing, Peoples R China; Univ Hong Kong, Hong Kong, Peoples R China|In the realm of modern mobile E-commerce, providing users with nearby commercial service recommendations through location-based online services has become increasingly vital. While machine learning approaches have shown promise in multi-scene recommendation, existing methodologies often struggle to address cold-start problems in unprecedented scenes: the increasing diversity of commercial choices, along with the short online lifespan of scenes, give rise to the complexity of effective recommendations in online and dynamic scenes. In this work, we propose Scene-wise Adaptive Network (SwAN 1), a novel approach that emphasizes high-performance cold-start online recommendations for new scenes. Our approach introduces several crucial capabilities, including scene similarity learning, user-specific scene transition cognition, scene-specific information construction for the new scene, and enhancing the diverged logical information between scenes. We demonstrate SwAN’s potential to optimize dynamic multi-scene recommendation problems by effectively online handling cold-start recommendations for any newly arrived scenes. More encouragingly, SwAN has been successfully deployed in Meituan’s online catering recommendation service, which serves millions of customers per day, and SwAN has achieved a 5.64% CTR index improvement relative to the baselines and a 5.19% increase in daily order volume proportion.|在现代移动电子商务领域，通过基于位置的在线服务为用户提供附近商业服务推荐变得越来越重要。尽管机器学习方法在多场景推荐中展现出了潜力，但现有方法往往难以应对新场景中的冷启动问题：商业选择的日益多样化，以及场景在线生命周期的短暂性，使得在线动态场景中的有效推荐变得复杂。在本研究中，我们提出了一种名为场景自适应网络（SwAN 1）的新方法，该方法强调对新场景进行高性能的冷启动在线推荐。我们的方法引入了几个关键能力，包括场景相似性学习、用户特定场景转移认知、为新场景构建特定场景信息，以及增强场景之间的差异逻辑信息。我们展示了SwAN在优化动态多场景推荐问题方面的潜力，通过有效地在线处理任何新到达场景的冷启动推荐。更令人鼓舞的是，SwAN已成功部署在美团的在线餐饮推荐服务中，该服务每天为数百万客户提供服务，SwAN相对于基线实现了5.64%的点击率指数提升，并且每日订单量比例增加了5.19%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scene-wise+Adaptive+Network+for+Dynamic+Cold-start+Scenes+Optimization+in+CTR+Prediction)|0|
|[A Multi-modal Modeling Framework for Cold-start Short-video Recommendation](https://doi.org/10.1145/3640457.3688098)|Gaode Chen, Ruina Sun, Yuezihan Jiang, Jiangxia Cao, Qi Zhang, Jingjian Lin, Han Li, Kun Gai, Xinghua Zhang|Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China; Kuaishou Technol, Beijing, Peoples R China|Short video has witnessed rapid growth in the past few years in multimedia platforms. To ensure the freshness of the videos, platforms receive a large number of user-uploaded videos every day, making collaborative filtering-based recommender methods suffer from the item cold-start problem (e.g., the new-coming videos are difficult to compete with existing videos). Consequently, increasing efforts tackle the cold-start issue from the content perspective, focusing on modeling the multi-modal preferences of users, a fair way to compete with new-coming and existing videos. However, recent studies ignore the existing gap between multi-modal embedding extraction and user interest modeling as well as the discrepant intensities of user preferences for different modalities. In this paper, we propose M3CSR, a multi-modal modeling framework for cold-start short video recommendation. Specifically, we preprocess content-oriented multi-modal features for items and obtain trainable category IDs by performing clustering. In each modality, we combine modality-specific cluster ID embedding and the mapped original modality feature as modality-specific representation of the item to address the gap. Meanwhile, M3CSR measures the user modality-specific intensity based on the correlation between modality-specific interest and behavioral interest and employs pairwise loss to further decouple user multi-modal interests. Extensive experiments on four real-world datasets demonstrate the superiority of our proposed model. The framework has been deployed on a billion-user scale short video application and has shown improvements in various commercial metrics within cold-start scenarios.|近年来，短视频在多媒体平台上经历了快速增长。为了确保视频的新鲜度，平台每天都会接收到大量用户上传的视频，这使得基于协同过滤的推荐方法面临物品冷启动问题（例如，新上传的视频难以与现有视频竞争）。因此，越来越多的研究从内容角度解决冷启动问题，专注于建模用户的多模态偏好，这是一种公平的方式，使新上传的视频和现有视频能够公平竞争。然而，最近的研究忽略了多模态嵌入提取与用户兴趣建模之间的现有差距，以及用户对不同模态偏好的强度差异。在本文中，我们提出了M3CSR，一个针对冷启动短视频推荐的多模态建模框架。具体来说，我们为物品预处理面向内容的多模态特征，并通过聚类获得可训练的类别ID。在每个模态中，我们将模态特定的聚类ID嵌入与映射的原始模态特征结合，作为物品的模态特定表示，以解决上述差距。同时，M3CSR基于模态特定兴趣与行为兴趣之间的相关性来衡量用户的模态特定强度，并采用成对损失进一步解耦用户的多模态兴趣。在四个真实世界数据集上的大量实验证明了我们提出模型的优越性。该框架已部署在一个拥有十亿级用户的短视频应用中，并在冷启动场景下展示了各种商业指标的提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-modal+Modeling+Framework+for+Cold-start+Short-video+Recommendation)|0|
|[MARec: Metadata Alignment for cold-start Recommendation](https://doi.org/10.1145/3640457.3688125)|Julien Monteil, Volodymyr Vaskovych, Wentao Lu, Anirban Majumder, Anton van den Hengel|Amazon Machine Learning Brisbane; University of Adelaide; Amazon Machine Learning; Amazon Machine Learning Melbourne|For many recommender systems, the primary data source is a historical record of user clicks. The associated click matrix is often very sparse, as the number of users x products can be far larger than the number of clicks. Such sparsity is accentuated in cold-start settings, which makes the efficient use of metadata information of paramount importance. In this work, we propose a simple approach to address cold-start recommendations by leveraging content metadata, Metadata Alignment for cold-start Recommendation (MAREC). We show that this approach can readily augment existing matrix factorization and autoencoder approaches, enabling a smooth transition to top performing algorithms in warmer set-ups. Our experimental results indicate three separate contributions: first, we show that our proposed framework largely beats SOTA results on 4 cold-start datasets with different sparsity and scale characteristics, with gains ranging from +8.4% to +53.8% on reported ranking metrics; second, we provide an ablation study on the utility of semantic features, and proves the additional gain obtained by leveraging such features ranges between +46.8% and +105.5%; and third, our approach is by construction highly competitive in warm set-ups, and we propose a closed-form solution outperformed by SOTA results by only 0.8% on average.|在许多推荐系统中，主要的数据源是用户点击的历史记录。相关的点击矩阵通常非常稀疏，因为用户与产品的数量可能远远超过点击的数量。这种稀疏性在冷启动设置中尤为突出，这使得有效利用元数据信息变得至关重要。在本研究中，我们提出了一种简单的方法，通过利用内容元数据来解决冷启动推荐问题，称为冷启动推荐的元数据对齐（MAREC）。我们展示了这种方法可以轻松地增强现有的矩阵分解和自编码器方法，从而实现向在较热设置中表现最佳的算法的平滑过渡。我们的实验结果表明了三个独立的贡献：首先，我们展示了所提出的框架在四个具有不同稀疏性和规模特征的冷启动数据集上大幅超越了现有的最先进（SOTA）结果，在报告的排名指标上，增益范围从+8.4%到+53.8%；其次，我们对语义特征的效用进行了消融研究，并证明利用这些特征带来的额外增益在+46.8%到+105.5%之间；第三，我们的方法在构建上在较热设置中具有高度竞争力，我们提出的闭式解平均仅比SOTA结果低0.8%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MARec:+Metadata+Alignment+for+cold-start+Recommendation)|0|
|[End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling](https://doi.org/10.1145/3640457.3688147)|Zexu Sun, Hao Yang, Dugang Liu, Yunpeng Weng, Xing Tang, Xiuqiang He|Guangdong Lab Artificial Intelligence & Digital E, Shenzhen, Peoples R China; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Tencent, FiT, Shenzhen, Peoples R China|In modern online platforms, incentives (e.g., discounts, bonus) are essential factors that enhance user engagement and increase platform revenue. Over recent years, uplift modeling has been introduced as a strategic approach to assign incentives to individual customers. Especially in many real-world applications, online platforms can only incentivize customers with specific budget constraints. This problem can be reformulated as the multi-choice knapsack problem (MCKP). The objective of this optimization is to select the optimal incentive for each customer to maximize the return on investment (ROI). Recent works in this field frequently tackle the budget allocation problem using a two-stage approach. However, this solution is confronted with the following challenges: (1) The causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases. (2) There is an optimality gap between the two stages, resulting in inferior sub-optimal allocation performance due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint. To address these challenges, we propose a novel End-to-End Cost-Effective Incentive Recommendation ((EIR)-I-3) model under the budget constraint. Specifically, our methods consist of two modules, i.e., the uplift prediction module and the differentiable allocation module. In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (i.e., monotonic and smooth). We incorporate integer linear programming (ILP) as a differentiable layer input in the differentiable allocation module. Furthermore, we conduct extensive experiments on public and real product datasets, demonstrating that our (EIR)-I-3 improves allocation performance compared to existing two-stage approaches.|在现代在线平台中，激励措施（如折扣、奖励）是增强用户参与度和增加平台收入的关键因素。近年来，提升建模（uplift modeling）作为一种战略方法被引入，用于为个体客户分配激励措施。特别是在许多实际应用中，在线平台只能在特定的预算约束下激励客户。这一问题可以重新表述为多选择背包问题（MCKP）。该优化的目标是为每个客户选择最优激励措施，以最大化投资回报率（ROI）。该领域的最新研究通常采用两阶段方法来解决预算分配问题。然而，这种解决方案面临以下挑战：（1）因果推理方法通常忽略了在线营销中的领域知识，即随着激励的增加，客户的预期响应曲线应该是单调且平滑的。（2）两阶段之间存在最优性差距，由于在有限预算约束下激励推荐信息的丢失，导致次优的分配性能。

为了解决这些挑战，我们提出了一种新颖的端到端成本效益激励推荐模型（(EIR)-I-3），该模型在预算约束下运行。具体而言，我们的方法由两个模块组成，即提升预测模块和可微分分配模块。在提升预测模块中，我们构建了预测头来捕捉相邻处理之间的增量改进，并引入营销领域的约束（即单调性和平滑性）。在可微分分配模块中，我们将整数线性规划（ILP）作为可微分层输入。此外，我们在公开和实际产品数据集上进行了广泛的实验，结果表明，与现有的两阶段方法相比，我们的(EIR)-I-3模型提高了分配性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Cost-Effective+Incentive+Recommendation+under+Budget+Constraint+with+Uplift+Modeling)|0|
|[AIE: Auction Information Enhanced Framework for CTR Prediction in Online Advertising](https://doi.org/10.1145/3640457.3688136)|Yang Yang, Bo Chen, Chenxu Zhu, Menghui Zhu, Xinyi Dai, Huifeng Guo, Muyu Zhang, Zhenhua Dong, Ruiming Tang|Huawei Noahs Ark Lab, Shenzhen, Peoples R China; Huawei Technol Co Ltd, Shenzhen, Peoples R China|Click-Through Rate (CTR) prediction is a fundamental technique for online advertising recommendation and the complex online competitive auction process also brings many difficulties to CTR optimization. Recent studies have shown that introducing posterior auction information contributes to the performance of CTR prediction. However, existing work doesn’t fully capitalize on the benefits of auction information and overlooks the data bias brought by the auction, leading to biased and suboptimal results. To address these limitations, we propose Auction Information Enhanced Framework (AIE) for CTR prediction in online advertising, which delves into the problem of insufficient utilization of auction signals and first reveals the auction bias. Specifically, AIE introduces two pluggable modules, namely Adaptive Market-price Auxiliary Module (AM2) and Bid Calibration Module (BCM), which work collaboratively to excavate the posterior auction signals better and enhance the performance of CTR prediction. Furthermore, the two proposed modules are lightweight, model-agnostic, and friendly to inference latency. Extensive experiments are conducted on a public dataset and an industrial dataset to demonstrate the effectiveness and compatibility of AIE. Besides, a one-month online A/B test in a large-scale advertising platform shows that AIE improves the base model by 5.76% and 2.44% in terms of eCPM and CTR, respectively.|点击率（CTR）预测是在线广告推荐的一项基础技术，而复杂的在线竞争拍卖过程也为CTR优化带来了诸多困难。最近的研究表明，引入后验拍卖信息有助于提升CTR预测的性能。然而，现有工作并未充分利用拍卖信息的优势，并且忽视了拍卖带来的数据偏差，导致结果存在偏差且不够理想。为了解决这些局限性，我们提出了一个用于在线广告CTR预测的拍卖信息增强框架（Auction Information Enhanced Framework, AIE），该框架深入探讨了拍卖信号利用不足的问题，并首次揭示了拍卖偏差。具体而言，AIE引入了两个可插拔模块，即自适应市场价格辅助模块（Adaptive Market-price Auxiliary Module, AM2）和出价校准模块（Bid Calibration Module, BCM），它们协同工作以更好地挖掘后验拍卖信号，从而提升CTR预测的性能。此外，所提出的两个模块轻量级、模型无关，并且对推理延迟友好。我们在一个公共数据集和一个工业数据集上进行了大量实验，以证明AIE的有效性和兼容性。此外，在一个大规模广告平台上进行的为期一个月的在线A/B测试表明，AIE将基础模型在eCPM和CTR方面分别提升了5.76%和2.44%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AIE:+Auction+Information+Enhanced+Framework+for+CTR+Prediction+in+Online+Advertising)|0|
|[Right Tool, Right Job: Recommendation for Repeat and Exploration Consumption in Food Delivery](https://doi.org/10.1145/3640457.3688119)|Jiayu Li, Aixin Sun, Weizhi Ma, Peijie Sun, Min Zhang|Tsinghua Univ, AIR, Beijing, Peoples R China; Tsinghua Univ, Quan Cheng Lab, DCST, Beijing, Peoples R China; Tsinghua Univ, DCST, Beijing, Peoples R China; Nanyang Technol Univ, CCDS, Singapore, Singapore|From e-commerce to music and news, recommender systems are tailored to specific scenarios. While researching generic models applicable to various scenarios is crucial, studying recommendations based on the unique characteristics of a specific and vital scenario holds both research and, more importantly, practical value. In this paper, we focus on store recommendations in the food delivery scenario, which is an intriguing and significant domain with unique behavior patterns and influential factors. First, we offer an in-depth analysis of real-world food delivery data across platforms and countries, revealing that (i) repeat and exploration orders are both noticeable behaviors and (ii) the influences of historical and collaborative situations on repeat and exploration consumption are distinct. Second, based on the observations, we separately design two simple yet effective recommendation models: RepRec for repeat orders and ExpRec for exploration ones. An ensemble module is further proposed to combine recommendations from two models for a unified recommendation list. Finally, experiments are conducted on three datasets spanning three countries across two food delivery platforms. Results demonstrate the superiority of our proposed recommenders on repeat, exploration, and combined recommendation tasks over various baselines. Such simple yet effective approaches will be beneficial for real applications. This work shows that dedicated analyses and methods for domain-specific characteristics are essential for the recommender system studies.|从电子商务到音乐和新闻，推荐系统被定制以适应特定场景。虽然研究适用于各种场景的通用模型至关重要，但基于特定且重要场景的独特特征进行推荐研究不仅具有研究价值，更重要的是具有实际应用价值。在本文中，我们聚焦于外卖场景中的店铺推荐，这是一个有趣且重要的领域，具有独特的行为模式和影响因素。首先，我们对跨平台和跨国家的实际外卖数据进行了深入分析，揭示了以下两点：(i) 重复订单和探索订单都是显著的行为；(ii) 历史情境和协同情境对重复消费和探索消费的影响是不同的。其次，基于这些观察结果，我们分别设计了两个简单但有效的推荐模型：用于重复订单的RepRec和用于探索订单的ExpRec。进一步提出了一个集成模块，将两个模型的推荐结果结合为一个统一的推荐列表。最后，我们在涵盖两个外卖平台、三个国家的三个数据集上进行了实验。结果表明，我们提出的推荐器在重复、探索和综合推荐任务上均优于各种基线模型。这种简单而有效的方法将有益于实际应用。本研究表明，针对特定领域特征的专门分析和方法对于推荐系统研究至关重要。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Right+Tool,+Right+Job:+Recommendation+for+Repeat+and+Exploration+Consumption+in+Food+Delivery)|0|
|[Informfully - Research Platform for Reproducible User Studies](https://doi.org/10.1145/3640457.3688066)|Lucien Heitz, Julian Andrea Croci, Madhav Sachdeva, Abraham Bernstein|Univ Zurich, Dept Informat & Digital Soc Initiat, Zurich, Switzerland; Univ Zurich, Dept Informat, Zurich, Switzerland|This paper presents Informfully, a research platform for content distribution and user studies. Informfully allows to push algorithmically curated text, image, audio, and video content to users and automatically generates a detailed log of their consumption history. As such, it serves as an open-source platform for conducting user experiments to investigate the impact of item recommendations on users’ consumption behavior. The platform was designed to accommodate different experiment types through versatility, ease of use, and scalability. It features three core components: 1) a front end for displaying and interacting with recommended items, 2) a back end for researchers to create and maintain user experiments, and 3) a simple JSON-based exchange format for ranked item recommendations to interface with third-party frameworks. We provide a system overview and outline the three core components of the platform. A sample workflow is shown for conducting field studies incorporating multiple user groups, personalizing recommendations, and measuring the effect of algorithms on user engagement. We present evidence for the versatility, ease of use, and scalability of Informfully by showcasing previous studies that used our platform.|本文介绍了Informfully，一个用于内容分发和用户研究的研究平台。Informfully能够向用户推送算法精选的文本、图像、音频和视频内容，并自动生成详细的用户消费历史日志。因此，它作为一个开源平台，用于进行用户实验，研究项目推荐对用户消费行为的影响。该平台通过多功能性、易用性和可扩展性设计，以适应不同类型的实验。它包含三个核心组件：1）用于显示推荐项目并与之交互的前端，2）供研究人员创建和维护用户实验的后端，以及3）一个基于JSON的简单交换格式，用于与第三方框架对接的排序项目推荐。我们提供了系统概述，并概述了平台的三个核心组件。展示了一个样本工作流程，用于进行包含多个用户组的现场研究、个性化推荐，以及测量算法对用户参与度的影响。通过展示以往使用我们平台的研究，我们证明了Informfully的多功能性、易用性和可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Informfully+-+Research+Platform+for+Reproducible+User+Studies)|0|
|[RPAF: A Reinforcement Prediction-Allocation Framework for Cache Allocation in Large-Scale Recommender Systems](https://doi.org/10.1145/3640457.3688128)|Shuo Su, Xiaoshuang Chen, Yao Wang, Yulin Wu, Ziqiang Zhang, Kaiqiao Zhan, Ben Wang, Kun Gai|; Tsinghua Univ, Beijing, Peoples R China; Kuaishou Technol, Beijing, Peoples R China|Modern recommender systems are built upon computation-intensive infrastructure, and it is challenging to perform real-time computation for each request, especially in peak periods, due to the limited computational resources. Recommending by user-wise result caches is widely used when the system cannot afford a real-time recommendation. However, it is challenging to allocate real-time and cached recommendations to maximize the users' overall engagement. This paper shows two key challenges to cache allocation, i.e., the value-strategy dependency and the streaming allocation. Then, we propose a reinforcement prediction-allocation framework (RPAF) to address these issues. RPAF is a reinforcement-learning-based two-stage framework containing prediction and allocation stages. The prediction stage estimates the values of the cache choices considering the value-strategy dependency, and the allocation stage determines the cache choices for each individual request while satisfying the global budget constraint. We show that the challenge of training RPAF includes globality and the strictness of budget constraints, and a relaxed local allocator (RLA) is proposed to address this issue. Moreover, a PoolRank algorithm is used in the allocation stage to deal with the streaming allocation problem. Experiments show that RPAF significantly improves users' engagement under computational budget constraints.|现代推荐系统建立在计算密集型基础设施之上，由于计算资源有限，对每个请求进行实时计算具有挑战性，尤其是在高峰时段。当系统无法承担实时推荐时，基于用户结果缓存的推荐被广泛使用。然而，如何分配实时推荐和缓存推荐以最大化用户的整体参与度是一个具有挑战性的问题。本文指出了缓存分配中的两个关键挑战，即价值策略依赖性和流式分配。然后，我们提出了一个强化预测-分配框架（RPAF）来解决这些问题。RPAF是一个基于强化学习的两阶段框架，包含预测和分配两个阶段。预测阶段在考虑价值策略依赖性的情况下估计缓存选择的价值，分配阶段则为每个请求确定缓存选择，同时满足全局预算约束。我们指出，训练RPAF的挑战包括全局性和预算约束的严格性，并提出了一种松弛的局部分配器（RLA）来解决这一问题。此外，分配阶段使用了PoolRank算法来处理流式分配问题。实验表明，RPAF在计算预算约束下显著提高了用户的参与度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RPAF:+A+Reinforcement+Prediction-Allocation+Framework+for+Cache+Allocation+in+Large-Scale+Recommender+Systems)|0|
|[Analyzing User Preferences and Quality Improvement on Bing's WebPage Recommendation Experience with Large Language Models](https://doi.org/10.1145/3640457.3688062)|Jaidev Shah, Gang Luo, Jialin Liu, Amey Barapatre, Fan Wu, Chuck Wang, Hongzhi Li|Microsoft AI, Redmond, WA 98052 USA|Explore Further @ Bing (Web Recommendations) is a web-scale query independent webpage-to-webpage recommendation system with an index size of over 200 billion webpages. Due to the significant variability in webpage quality across the web and the reliance of our system on learning soleley user behavior (clicks), our production system was susceptible to serving clickbait and low-quality recommendations. Our team invested several months in developing and shipping several improvements that utilize LLM-generated recommendation quality labels to enhance our ranking stack to improve the nature of the recommendations we show to our users. Another key motivation behind our efforts was to go beyond merely surfacing relevant webpages, focusing instead on prioritizing more useful and authoritative content that delivers value to users based on their implied intent. We demonstrate how large language models (LLMs) offer a powerful tool for product teams to gain deeper insights into shifts in product experience and user behavior following significant improvements or changes to a production system. In this work, to enable our analysis, we also showcase the use of a small language model (SLM) to generate better-quality webpage text features and summaries at scale and describe our approach to mitigating position bias in user interaction logs."|“探索更多@必应”（Web Recommendations）是一个网页规模、查询独立的网页到网页推荐系统，其索引规模超过2000亿个网页。由于网页质量在互联网中存在显著差异，且我们的系统仅依赖用户行为（点击）进行学习，生产系统容易推荐点击诱饵和低质量内容。为此，我们的团队花费了数月时间开发并部署了多项改进措施，利用大语言模型（LLM）生成的推荐质量标签来增强排序系统，从而提升向用户展示的推荐内容的质量。我们努力的另一个关键动机是超越仅仅推荐相关网页，转而优先展示更具实用性和权威性的内容，以根据用户的隐含意图提供价值。我们展示了大语言模型（LLM）如何为产品团队提供强大工具，帮助他们在生产系统发生重大改进或变化后，更深入地洞察产品体验和用户行为的变化。在本研究中，为了支持我们的分析，我们还展示了使用小语言模型（SLM）大规模生成更高质量的网页文本特征和摘要的方法，并描述了我们在用户交互日志中减轻位置偏差的策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+User+Preferences+and+Quality+Improvement+on+Bing's+WebPage+Recommendation+Experience+with+Large+Language+Models)|0|
|[Enhancing Performance and Scalability of Large-Scale Recommendation Systems with Jagged Flash Attention](https://doi.org/10.1145/3640457.3688040)|Rengan Xu, Junjie Yang, Yifan Xu, Hong Li, Xing Liu, Devashish Shankar, Haoci Zhang, Meng Liu, Boyang Li, Yuxi Hu, Mingwei Tang, Zehua Zhang, Tunhou Zhang, Dai Li, Sijia Chen, GianPaolo Musumeci, Jiaqi Zhai, Bill Zhu, Hong Yan, Srihari Reddy|Meta Platforms, Menlo Pk, CA 94025 USA|The integration of hardware accelerators has significantly advanced the capabilities of modern recommendation systems, enabling the exploration of complex ranking paradigms previously deemed impractical. However, the GPU-based computational costs present substantial challenges. In this paper, we demonstrate our development of an efficiency-driven approach to explore these paradigms, moving beyond traditional reliance on native PyTorch modules. We address the specific challenges posed by ranking models' dependence on categorical features, which vary in length and complicate GPU utilization. We introduce Jagged Feature Interaction Kernels, a novel method designed to extract fine-grained insights from long categorical features through efficient handling of dynamically sized tensors. We further enhance the performance of attention mechanisms by integrating Jagged tensors with Flash Attention. Our novel Jagged Flash Attention achieves up to 9x speedup and 22x memory reduction compared to dense attention. Notably, it also outperforms dense flash attention, with up to 3x speedup and 53% more memory efficiency. In production models, we observe 10% QPS improvement and 18% memory savings, enabling us to scale our recommendation systems with longer features and more complex architectures.|硬件加速器的集成显著提升了现代推荐系统的能力，使得探索以往被认为不切实际的复杂排序范式成为可能。然而，基于GPU的计算成本带来了重大挑战。本文中，我们展示了一种以效率为导向的方法的开发，用于探索这些范式，超越了传统对原生PyTorch模块的依赖。我们解决了排序模型对分类特征依赖所带来的具体挑战，这些特征的长度不一，增加了GPU利用的复杂性。我们引入了Jagged Feature Interaction Kernels，这是一种新颖的方法，旨在通过高效处理动态大小的张量，从长分类特征中提取细粒度的洞察。我们进一步通过将Jagged张量与Flash Attention结合，提升了注意力机制的性能。我们新颖的Jagged Flash Attention与密集注意力相比，实现了高达9倍的速度提升和22倍的内存减少。值得注意的是，它还优于密集Flash Attention，实现了高达3倍的速度提升和53%的内存效率提升。在生产模型中，我们观察到10%的QPS提升和18%的内存节省，使我们能够扩展推荐系统，支持更长的特征和更复杂的架构。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Performance+and+Scalability+of+Large-Scale+Recommendation+Systems+with+Jagged+Flash+Attention)|0|
|[Enhancing Recommendation Quality of the SASRec Model by Mitigating Popularity Bias](https://doi.org/10.1145/3640457.3688044)|Venkata Harshit Koneru, Xenija Neufeld, Sebastian Loth, Andreas Grün|ZDF, Mainz, Germany; Accso Accelerated Solut GmbH, Darmstadt, Germany|ZDF is a Public Service Media (PSM) broadcaster in Germany that uses recommender systems on its streaming service platform ZDFmediathek. One of the main use cases within the ZDFmediathek is Next Video, which is currently based on a Self-Attention based Sequential Recommendation model (SASRec). For this use case, we modified the loss function, the sampling method of negative items, and introduced the top-k negative sampling strategy and compared this to the vanilla SASRec model. We show that this not only reduces popularity bias, but also increases clicks and viewing volume compared to that of the vanilla version.|ZDF是德国的一家公共服务媒体（PSM）广播公司，其流媒体服务平台ZDFmediathek使用了推荐系统。ZDFmediathek中的一个主要应用场景是“下一个视频”推荐功能，该功能目前基于自注意力机制的序列推荐模型（SASRec）。针对这一应用场景，我们对损失函数和负样本的采样方法进行了修改，并引入了top-k负采样策略，同时与原始SASRec模型进行了对比。实验结果表明，改进后的模型不仅降低了流行度偏差，还提高了点击率和观看量，相较于原始版本表现更优。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Recommendation+Quality+of+the+SASRec+Model+by+Mitigating+Popularity+Bias)|0|
|[Taming the One-Epoch Phenomenon in Online Recommendation System by Two-stage Contrastive ID Pre-training](https://doi.org/10.1145/3640457.3688053)|YiPing Hsu, PoWei Wang, Chantat Eksombatchai, Jiajing Xu|Pinterest Inc, San Francisco, CA 94107 USA|ID-based embeddings are widely used in web-scale online recommendation systems. However, their susceptibility to overfitting, particularly due to the long-tail nature of data distributions, often limits training to a single epoch, a phenomenon known as the "one-epoch problem." This challenge has driven research efforts to optimize performance within the first epoch by enhancing convergence speed or feature sparsity. In this study, we introduce a novel two-stage training strategy that incorporates a pre-training phase using a minimal model with contrastive loss, enabling broader data coverage for the embedding system. Our offline experiments demonstrate that multi-epoch training during the pre-training phase does not lead to overfitting, and the resulting embeddings improve online generalization when fine-tuned for more complex downstream recommendation tasks. We deployed the proposed system in live traffic at Pinterest, achieving significant site-wide engagement gains.|基于ID的嵌入在网页规模的在线推荐系统中被广泛应用。然而，它们对过拟合的敏感性，特别是由于数据分布的长尾特性，通常限制了训练仅能进行一个周期，这一现象被称为“单周期问题”。这一挑战推动了研究努力，通过提高收敛速度或特征稀疏性来优化第一个周期内的性能。在本研究中，我们引入了一种新颖的两阶段训练策略，该策略包含使用最小模型和对比损失进行预训练的阶段，使嵌入系统能够覆盖更广泛的数据。我们的离线实验表明，在预训练阶段进行多周期训练不会导致过拟合，并且当为更复杂的下游推荐任务进行微调时，生成的嵌入提高了在线泛化能力。我们在Pinterest的实时流量中部署了所提出的系统，实现了显著的网站整体参与度提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Taming+the+One-Epoch+Phenomenon+in+Online+Recommendation+System+by+Two-stage+Contrastive+ID+Pre-training)|0|
|[Towards Understanding The Gaps of Offline And Online Evaluation Metrics: Impact of Series vs. Movie Recommendations](https://doi.org/10.1145/3640457.3688056)|Bora Edizel, Tim Sweetser, Ashok Chandrashekar, Kamilia Ahmadi, Puja Das|Warner Bros Discovery, San Francisco, CA USA; Warner Bros Discovery, Miami, FL 33126 USA; StubHub, New York, NY USA|In the realm of recommender systems research, offline evaluation metrics like NDCG[4], Recall[1], or Precision[1] are often used to measure the impact. On the other hand, common industry practices suggest evaluating new ideas/models through A/B tests where decisions are made based on business metrics like the overall engagement of users. A new model may show improvement in offline metrics but performance loss in online metrics. One reason that leads to this phenomenon is the counterfactual nature of the recommendation problem which can be addressed by off-policy evaluation methods [6][3]. Another reason is the degree of causal connection between offline evaluation metrics and observed online metrics. In this work, we will share our learnings from two set of A/B tests that we conducted at Max1 where we observed a mismatch between online and offline metrics due to a weak causal connection between online and offline metrics. Thanks to learnings from A/B tests, we discovered and quantified the impact of series to movie ratio at recommendations. Our experiments show that there is an optimal amount of series to movies ratio that provides the best possible results for user engagement.|在推荐系统研究领域，离线评估指标如NDCG[4]、Recall[1]或Precision[1]常用于衡量影响。另一方面，行业中的常见做法是通过A/B测试来评估新想法或模型，决策基于用户整体参与度等业务指标。一个新模型可能在离线指标上显示改进，但在在线指标上表现不佳。导致这种现象的一个原因是推荐问题的反事实性质，这可以通过离策略评估方法[6][3]来解决。另一个原因是离线评估指标与观察到的在线指标之间的因果联系程度。在本研究中，我们将分享在Max1进行的两组A/B测试中的经验，我们观察到由于在线和离线指标之间因果联系较弱，导致在线和离线指标之间的不匹配。得益于A/B测试的收获，我们发现并量化了推荐中剧集与电影比例的影响。我们的实验表明，存在一个最佳的剧集与电影比例，能够为用户参与度提供最佳结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Understanding+The+Gaps+of+Offline+And+Online+Evaluation+Metrics:+Impact+of+Series+vs.+Movie+Recommendations)|0|
|[Data Augmentation using Reverse Prompt for Cost-Efficient Cold-Start Recommendation](https://doi.org/10.1145/3640457.3688159)|Genki Kusano|NEC Corp Ltd, Kawasaki, Kanagawa, Japan|Recommendation systems that use auxiliary information such as product names and categories have been proposed to address the cold-start problem. However, these methods do not perform well when we only have insufficient warm-start training data. On the other hand, large language models (LLMs) can perform as effective cold-start recommendation systems even with limited warm-start data. However, they require numerous API calls for inferences, which leads to high operational costs in terms of time and money. This is a significant concern in industrial applications. In this paper, we introduce a new method, RevAug, which leverages LLMs as a data augmentation to enhance cost-efficient cold-start recommendation systems. To generate pseudo-samples, we have reversed the commonly used prompt for an LLM from “Would this user like this item?” to “What kind of items would this user like?”. Generated outputs by this reverse prompt are pseudo-auxiliary information utilized to enhance recommendation systems in the training phase. In numerical experiments with four real-world datasets, RevAug demonstrated superior performance in cold-start settings with limited warm-start data compared to existing methods. Moreover, RevAug significantly reduced API fees and processing time compared to an LLM-based recommendation method.|为解决冷启动问题，已有研究提出了利用产品名称和类别等辅助信息的推荐系统。然而，当仅有少量热启动训练数据时，这些方法表现不佳。另一方面，大型语言模型（LLMs）即使在有限的热启动数据下，也能作为有效的冷启动推荐系统。然而，它们需要大量的API调用进行推理，导致时间和金钱上的高运营成本。这在工业应用中是一个重要问题。本文介绍了一种新方法RevAug，它利用LLMs作为数据增强手段，以提升成本效益高的冷启动推荐系统。为了生成伪样本，我们将LLM常用的提示从“这个用户会喜欢这个物品吗？”反转为“这个用户会喜欢什么样的物品？”。通过这种反转提示生成的输出是伪辅助信息，用于在训练阶段增强推荐系统。在四个真实数据集上的数值实验中，与现有方法相比，RevAug在有限热启动数据的冷启动设置中展示了优越的性能。此外，与基于LLM的推荐方法相比，RevAug显著减少了API费用和处理时间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Augmentation+using+Reverse+Prompt+for+Cost-Efficient+Cold-Start+Recommendation)|0|
|[Positive-Sum Impact of Multistakeholder Recommender Systems for Urban Tourism Promotion and User Utility](https://doi.org/10.1145/3640457.3688173)|Pavel Merinov, Francesco Ricci|Free Univ Bozen Bolzano, Bolzano, Italy|When a multistakeholder recommender system (MRS) is designed to produce sustainable urban tourism promotion, two conflicting goals are of practical interest: (i) to cut down the number of visitors at popular sites and (ii) to satisfy tourists’ preferences, often biased towards popular sites. By modelling the tourists’ limited knowledge of the visited city — an important but often overlooked detail — we simulate interactions between tourists and an MRS that jointly optimises tourist’s utility and promotes less popular sites. Experiments based on data logs collected in three tourist cities reveal that such an MRS can lift tourist’s utility and at the same time reduce the number of visitors at popular sites, manifesting a so-called positive-sum impact. However, a delicate balance is crucial; under- or over-promotion of unpopular sites in the recommendation lists can be adverse to both destination and tourist’s utility.|当设计一个多利益相关者推荐系统（MRS）以促进可持续的城市旅游推广时，两个相互冲突的目标具有实际意义：（i）减少热门景点的游客数量，以及（ii）满足游客的偏好，这些偏好通常偏向于热门景点。通过建模游客对访问城市的有限了解——这是一个重要但经常被忽视的细节——我们模拟了游客与一个MRS之间的互动，该MRS共同优化游客的效用并推广不太受欢迎的景点。基于在三个旅游城市收集的数据日志进行的实验表明，这样的MRS可以提高游客的效用，同时减少热门景点的游客数量，表现出所谓的正和效应。然而，微妙的平衡至关重要；在推荐列表中过度或不足推广不受欢迎的景点可能对目的地和游客的效用都不利。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Positive-Sum+Impact+of+Multistakeholder+Recommender+Systems+for+Urban+Tourism+Promotion+and+User+Utility)|0|
|[Calibrating the Predictions for Top-N Recommendations](https://doi.org/10.1145/3640457.3688177)|Masahiro Sato|FUJIFILM, Akasaka, Tokyo, Japan|Well-calibrated predictions of user preferences are essential for many applications. Since recommender systems typically select the top-N items for users, calibration for those top-N items, rather than for all items, is important. We show that previous calibration methods result in miscalibrated predictions for the top-N items, despite their excellent calibration performance when evaluated on all items. In this work, we address the miscalibration in the top-N recommended items. We first define evaluation metrics for this objective and then propose a generic method to optimize calibration models focusing on the top-N items. It groups the top-N items by their ranks and optimizes distinct calibration models for each group with rank-dependent training weights. We verify the effectiveness of the proposed method for both explicit and implicit feedback datasets, using diverse classes of recommender models.|在许多应用中，用户偏好的良好校准预测至关重要。由于推荐系统通常为用户选择前N个项目，因此对这些前N个项目进行校准，而不是对所有项目进行校准，是非常重要的。我们展示了尽管之前的校准方法在评估所有项目时表现出色，但它们在前N个项目上却导致了校准错误的预测。在这项工作中，我们解决了前N个推荐项目的校准错误问题。我们首先为此目标定义了评估指标，然后提出了一种通用方法来优化专注于前N个项目的校准模型。该方法按排名对前N个项目进行分组，并为每个组优化不同的校准模型，使用依赖于排名的训练权重。我们验证了所提出方法在显式和隐式反馈数据集上的有效性，使用了多种类别的推荐模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibrating+the+Predictions+for+Top-N+Recommendations)|0|
|[CoST: Contrastive Quantization based Semantic Tokenization for Generative Recommendation](https://doi.org/10.1145/3640457.3688178)|Jieming Zhu, Mengqun Jin, Qijiong Liu, Zexuan Qiu, Zhenhua Dong, Xiu Li|; The Chinese University of Hong Kong Hong Kong; Huawei Noah's Ark Lab Shenzhen; Tsinghua University Shenzhen Shenzhen International Graduate School|Embedding-based retrieval serves as a dominant approach to candidate item matching for industrial recommender systems. With the success of generative AI, generative retrieval has recently emerged as a new retrieval paradigm for recommendation, which casts item retrieval as a generation problem. Its model consists of two stages: semantic tokenization and autoregressive generation. The first stage involves item tokenization that constructs discrete semantic tokens to index items, while the second stage autoregressively generates semantic tokens of candidate items. Therefore, semantic tokenization serves as a crucial preliminary step for training generative recommendation models. Existing research usually employs a vector quantizier with reconstruction loss (e.g., RQ-VAE) to obtain semantic tokens of items, but this method fails to capture the essential neighborhood relationships that are vital for effective item modeling in recommender systems. In this paper, we propose a contrastive quantization-based semantic tokenization approach, named CoST, which harnesses both item relationships and semantic information to learn semantic tokens. Our experimental results highlight the significant impact of semantic tokenization on generative recommendation performance, with CoST achieving up to a 43% improvement in Recall@5 and 44% improvement in NDCG@5 on the MIND dataset over previous baselines.|基于嵌入的检索是工业推荐系统中候选物品匹配的主要方法。随着生成式人工智能的成功，生成式检索最近作为一种新的推荐检索范式出现，它将物品检索视为一个生成问题。其模型由两个阶段组成：语义标记化和自回归生成。第一阶段涉及物品标记化，即构建离散的语义标记来索引物品，而第二阶段则自回归地生成候选物品的语义标记。因此，语义标记化是训练生成式推荐模型的关键初步步骤。现有研究通常使用带有重建损失的向量量化器（例如RQ-VAE）来获取物品的语义标记，但这种方法未能捕捉到对推荐系统中有效物品建模至关重要的邻居关系。在本文中，我们提出了一种基于对比量化的语义标记化方法，名为CoST，它利用物品关系和语义信息来学习语义标记。我们的实验结果突出了语义标记化对生成式推荐性能的显著影响，在MIND数据集上，CoST在Recall@5和NDCG@5上分别比之前的基线方法提高了43%和44%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoST:+Contrastive+Quantization+based+Semantic+Tokenization+for+Generative+Recommendation)|0|
|[Oh, Behave! Country Representation Dynamics Created by Feedback Loops in Music Recommender Systems](https://doi.org/10.1145/3640457.3688187)|Oleg Lesota, Jonas Geiger, Max Walder, Dominik Kowald, Markus Schedl|Know Ctr GmbH, Graz, Austria; Johannes Kepler Univ Linz, Linz, Austria|Recent work suggests that music recommender systems are prone to disproportionally frequent recommendations of music from countries more prominently represented in the training data, notably the US. However, it remains unclear to what extent feedback loops in music recommendation influence the dynamics of such imbalance. In this work, we investigate the dynamics of representation of local (i.e., country-specific) and US-produced music in user profiles and recommendations. To this end, we conduct a feedback loop simulation study using the LFM-2b dataset. The results suggest that most of the investigated recommendation models decrease the proportion of music from local artists in their recommendations. Furthermore, we find that models preserving average proportions of US and local music do not necessarily provide country-calibrated recommendations. We also look into popularity calibration and, surprisingly, find that the most popularity-calibrated model in our study (ItemKNN) provides the least country-calibrated recommendations. In addition, users from less represented countries (e.g., Finland) are, in the long term, most affected by the under-representation of their local music in recommendations.|最近的研究表明，音乐推荐系统容易倾向于频繁推荐那些在训练数据中占据主导地位的国家的音乐，尤其是美国的音乐。然而，目前尚不清楚音乐推荐中的反馈循环在多大程度上影响了这种不平衡的动态变化。在本研究中，我们探讨了用户资料和推荐中本地（即特定国家）音乐与美国音乐的代表性动态变化。为此，我们利用LFM-2b数据集进行了反馈循环模拟研究。研究结果表明，大多数被调查的推荐模型在其推荐中减少了来自本地艺术家的音乐比例。此外，我们发现那些保持美国音乐和本地音乐平均比例的模型并不一定提供与国家校准的推荐。我们还研究了流行度校准，令人惊讶的是，我们发现研究中最流行度校准的模型（ItemKNN）提供了最少与国家校准的推荐。此外，长期来看，来自代表性较少国家（如芬兰）的用户最受其本地音乐在推荐中代表性不足的影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Oh,+Behave!+Country+Representation+Dynamics+Created+by+Feedback+Loops+in+Music+Recommender+Systems)|0|
|[One-class recommendation systems with the hinge pairwise distance loss and orthogonal representations](https://doi.org/10.1145/3640457.3688189)|Ramin Raziperchikolaei, Youngjoo Chung|Rakuten Grp Inc, San Mateo, CA 94402 USA|In one-class recommendation systems, the goal is to learn a model from a small set of interacted users and items and then identify the positively-related (i.e., similar) user-item pairs among a large number of pairs with unknown interactions. Most loss functions in the literature rely on dissimilar pairs of users and items, which are selected from the ones with unknown interactions, to obtain better prediction performance. The main issue with this strategy is that it needs a large number of dissimilar pairs, which increases the training time significantly. In this paper, our goal is to only use the similar set to train the models and discard the dissimilar set. We highlight three trivial solutions that the recommendation system models converge to when they are trained only on similar pairs: collapsed and dimensional collapsed solutions. We propose a hinge pairwise loss and an orthogonality term that can be added to the objective functions in the literature to avoid these trivial solutions. We conduct experiments on various tasks on public and real-world datasets, which show that our approach using only similar pairs can be trained several times faster than the state-of-the-art methods while achieving competitive results.|在单类推荐系统中，目标是从一小部分交互过的用户和物品中学习一个模型，然后在大量未知交互的用户-物品对中识别出正相关（即相似）的对。文献中的大多数损失函数依赖于从未知交互对中选择的不同用户-物品对，以获得更好的预测性能。这种策略的主要问题在于它需要大量的不同对，这显著增加了训练时间。在本文中，我们的目标是仅使用相似对来训练模型并舍弃不同对。我们强调了当推荐系统模型仅在相似对上训练时可能收敛到的三种平凡解：坍缩解和维度坍缩解。我们提出了一种铰链成对损失和一个正交性项，可以将其添加到文献中的目标函数中，以避免这些平凡解。我们在公开和真实世界的数据集上进行了各种任务的实验，结果表明，我们仅使用相似对的方法可以比现有技术方法快几倍地训练，同时获得具有竞争力的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-class+recommendation+systems+with+the+hinge+pairwise+distance+loss+and+orthogonal+representations)|0|
|[Is It Really Complementary? Revisiting Behavior-based Labels for Complementary Recommendation](https://doi.org/10.1145/3640457.3691705)|Kai Sugahara, Chihiro Yamasaki, Kazushi Okamoto|Univ Electrocommun, Tokyo, Japan|Complementary recommendation is a type of item-to-item recommendation that recommends what should be purchased together for an item. Previous studies have traditionally used behavior-based labels (BBLs) that are constructed from the co-purchase logs of users for training and evaluation because rigorous label construction for complements is inefficient. However, the fact that many item pairs in BBLs are not functionally complementary, even though they are frequently co-purchased, has been overlooked. This study aimed to re-evaluate the validity of BBLs through functional relationships and provide directions for their improvement. Quantitative analysis using manually annotated function-based labels (FBLs) as correct labels revealed that the accuracy of the complementary recommendations generated by BBLs was below 50%, suggesting potential functional incompatibility within BBLs. Existing models that were trained on BBLs were similarly inaccurate, indicating the unreliability of the evaluations in existing studies. Finally, we proposed a label correction method for BBLs using a small set of FBLs, thereby providing a direction for reliable complementary recommendations.|互补推荐是一种商品对商品的推荐方式，旨在推荐与某商品一起购买的其他商品。以往的研究通常使用基于行为的标签（BBLs），这些标签是从用户的共同购买日志中构建出来的，用于训练和评估，因为为互补商品构建严格的标签效率低下。然而，尽管许多商品对在BBLs中经常被共同购买，但它们实际上在功能上并不互补，这一事实一直被忽视。本研究旨在通过功能关系重新评估BBLs的有效性，并为改进提供方向。使用手动标注的基于功能的标签（FBLs）作为正确标签进行的定量分析显示，BBLs生成的互补推荐准确率低于50%，这表明BBLs内部可能存在功能不兼容的问题。现有的基于BBLs训练的模型同样不准确，表明现有研究中的评估不可靠。最后，我们提出了一种利用少量FBLs对BBLs进行标签校正的方法，从而为可靠的互补推荐提供了方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+It+Really+Complementary?+Revisiting+Behavior-based+Labels+for+Complementary+Recommendation)|0|
|[Exploratory Analysis of Recommending Urban Parks for Health-Promoting Activities](https://doi.org/10.1145/3640457.3691712)|Linus W. Dietz, Sanja Scepanovic, Ke Zhou, Daniele Quercia|Nokia Bell Labs, London, England; Kings Coll London, Dept Informat, London, England|Parks are essential spaces for promoting urban health, and recommender systems could assist individuals in discovering parks for leisure and health-promoting activities. This is particularly important in large cities like London, which has over 1,500 named parks, making it challenging to understand what each park offers. Due to the lack of datasets and the diverse health-promoting activities parks can support (e.g., physical, social, nature-appreciation), it is unclear which recommendation algorithms are best suited for this task. To explore the dynamics of recommending parks for specific activities, we created two datasets: one from a survey of over 250 London residents, and another by inferring visits from over 1 million geotagged Flickr images taken in London parks. Analyzing the geographic patterns of these visits revealed that recommending nearby parks is ineffective, suggesting that this recommendation task is distinct from Point of Interest recommendation. We then tested various recommendation models, identifying a significant popularity bias in the results. Additionally, we found that personalized models have advantages in recommending parks beyond the most popular ones. The data and findings from this study provide a foundation for future research on park recommendations.|公园是促进城市健康的重要空间，而推荐系统可以帮助个人发现适合休闲和健康促进活动的公园。这在像伦敦这样的大城市尤为重要，因为伦敦拥有超过1500个命名公园，这使得了解每个公园提供的服务变得具有挑战性。由于缺乏相关数据集以及公园可以支持的各种健康促进活动（例如，体育活动、社交活动、自然欣赏），目前尚不清楚哪种推荐算法最适合这项任务。为了探索为特定活动推荐公园的动态，我们创建了两个数据集：一个来自对250多名伦敦居民的调查，另一个通过从伦敦公园拍摄的超过100万张带有地理标记的Flickr图像中推断访问情况。分析这些访问的地理模式表明，推荐附近公园是无效的，这表明这项推荐任务与兴趣点推荐不同。随后，我们测试了各种推荐模型，发现结果中存在显著的流行度偏差。此外，我们发现个性化模型在推荐非最热门公园方面具有优势。这项研究的数据和发现为未来公园推荐研究奠定了基础。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploratory+Analysis+of+Recommending+Urban+Parks+for+Health-Promoting+Activities)|0|
|[Balancing Habit Repetition and New Activity Exploration: A Longitudinal Micro-Randomized Trial in Physical Activity Recommendations](https://doi.org/10.1145/3640457.3691715)|Ine Coppens, Toon De Pessemier, Luc Martens|Univ Ghent, IMEC, WAVES, Ghent, Belgium|As repetition of activities can establish habits and exploration of new ones can provide a healthy variety, we investigate how a recommender system for physical activities can optimally balance these two approaches. We conducted an eight-week user study with 62 physically inactive participants who receive personalized repetition and exploration recommendations in a random order. We distinguish between location, workout, and general activities, and collect participants’ subjective perceptions. Our findings indicate that participants initially preferred exploring general activities, but rated repeating recommendations higher after two weeks. By exploring the optimal transition point from exploration to repetition in personalized recommendations, this study contributes to designing more effective recommender systems for health improvement and healthy habit formation.|由于重复活动可以建立习惯，而探索新活动可以提供健康的多样性，我们研究了物理活动推荐系统如何在这两种方法之间实现最佳平衡。我们进行了一项为期八周的用户研究，涉及62名身体活动不足的参与者，他们以随机顺序接收个性化的重复和探索推荐。我们区分了地点、锻炼和一般活动，并收集了参与者的主观感知。我们的研究结果表明，参与者最初更倾向于探索一般活动，但在两周后对重复推荐的评价更高。通过探索个性化推荐中从探索到重复的最佳过渡点，本研究为设计更有效的健康改善和健康习惯养成的推荐系统做出了贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Habit+Repetition+and+New+Activity+Exploration:+A+Longitudinal+Micro-Randomized+Trial+in+Physical+Activity+Recommendations)|0|
|[Exploring Coresets for Efficient Training and Consistent Evaluation of Recommender Systems](https://doi.org/10.1145/3640457.3691716)|Zheng Ju, Honghui Du, Elias Z. Tragos, Neil Hurley, Aonghus Lawlor|Univ Coll Dublin, Insight Ctr Data Analyt, Dublin, Ireland|Recommender systems have achieved remarkable success in various web applications, such as e-commerce, online advertising, and social media, harnessing the power of big data. To attain optimal model performance, recommender systems are typically trained on very large datasets, with substantial numbers of users and items. However, large datasets often present challenges in terms of processing time and computational resources. Coreset selection offers a method for obtaining a reduced yet representative subset from vast datasets, thereby enhancing the efficiency of training machine learning algorithms. Nevertheless, little research has been conducted to explore the practical implications of different coreset selection approaches on the performance of recommender systems algorithms. In this paper, we systematically investigate the impact of various coreset selection techniques. We evaluate the performance of the resulting coresets using inductive recommendation models which allow for consistent evaluations to be performed. The experimental results demonstrate that coreset methods are a powerful and useful approach for obtaining reduced datasets which preserve the properties of the large original dataset and have competitive performance compared to the time required to train with the full dataset.|推荐系统在利用大数据的力量下，在电子商务、在线广告和社交媒体等各种网络应用中取得了显著的成功。为了达到最佳的模型性能，推荐系统通常需要在包含大量用户和物品的非常庞大的数据集上进行训练。然而，大型数据集在处理时间和计算资源方面往往带来挑战。核心集选择提供了一种方法，可以从庞大的数据集中获取一个缩减但具有代表性的子集，从而提高机器学习算法的训练效率。尽管如此，关于不同核心集选择方法对推荐系统算法性能的实际影响的研究却很少。在本文中，我们系统地研究了各种核心集选择技术的影响。我们使用归纳推荐模型来评估生成的核心集的性能，这些模型允许进行一致的评估。实验结果表明，核心集方法是一种强大且有用的方法，用于获取缩减后的数据集，这些数据集保留了大型原始数据集的特性，并且在训练所需时间方面与完整数据集相比具有竞争力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Coresets+for+Efficient+Training+and+Consistent+Evaluation+of+Recommender+Systems)|0|
|[Rs4rs: Semantically Find Recent Publications from Top Recommendation System-Related Venues](https://doi.org/10.1145/3640457.3691696)|Tri Kurniawan Wijaya, Edoardo D'Amico, Gábor Fodor, Manuel V. Loureiro|Huawei Ireland Res Ctr, Dublin, Ireland|Rs4rs is a web application designed to perform semantic search on recent papers from top conferences and journals related to Recommender Systems. Current scholarly search engine tools like Google Scholar, Semantic Scholar, and ResearchGate often yield broad results that fail to target the most relevant high-quality publications. Moreover, manually visiting individual conference and journal websites is a time-consuming process that primarily supports only syntactic searches. Rs4rs addresses these issues by providing a user-friendly platform where researchers can input their topic of interest and receive a list of recent, relevant papers from top Recommender Systems venues. Utilizing semantic search techniques, Rs4rs ensures that the search results are not only precise and relevant but also comprehensive, capturing papers regardless of variations in wording. This tool significantly enhances research efficiency and accuracy, thereby benefitting the research community and public by facilitating access to high-quality, pertinent academic resources in the field of Recommender Systems. Rs4rs is available at https://rs4rs.com.|Rs4rs 是一款专为推荐系统领域设计的网页应用程序，旨在对顶级会议和期刊中的最新论文进行语义搜索。现有的学术搜索引擎工具，如Google Scholar、Semantic Scholar和ResearchGate，往往返回的结果过于宽泛，无法精准定位到最相关的高质量出版物。此外，手动访问各个会议和期刊网站是一个耗时的过程，且主要仅支持基于语法的搜索。Rs4rs通过提供一个用户友好的平台来解决这些问题，研究人员可以在该平台上输入他们感兴趣的主题，并获得来自顶级推荐系统会议和期刊的最新相关论文列表。通过利用语义搜索技术，Rs4rs确保搜索结果不仅精确且相关，还能全面捕捉到不同措辞的论文。这一工具显著提高了研究效率和准确性，从而通过促进对推荐系统领域高质量、相关学术资源的访问，使研究界和公众受益。Rs4rs可通过 https://rs4rs.com 访问。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rs4rs:+Semantically+Find+Recent+Publications+from+Top+Recommendation+System-Related+Venues)|0|
|[RePlay: a Recommendation Framework for Experimentation and Production Use](https://doi.org/10.1145/3640457.3691701)|Alexey Vasilev, Anna Volodkevich, Denis Kulandin, Tatiana Bysheva, Anton Klenitskiy|Sber AI Lab, Moscow, Russia; Sber AmazMe, Moscow, Russia|Using a single tool to build and compare recommender systems significantly reduces the time to market for new models. In addition, the comparison results when using such tools look more consistent. This is why many different tools and libraries for researchers in the field of recommendations have recently appeared. Unfortunately, most of these frameworks are aimed primarily at researchers and require modification for use in production due to the inability to work on large datasets or an inappropriate architecture. In this demo, we present our open-source toolkit RePlay - a framework containing an end-to-end pipeline for building recommender systems, which is ready for production use. RePlay also allows you to use a suitable stack for the pipeline on each stage: Pandas, Polars, or Spark. This allows the library to scale computations and deploy to a cluster. Thus, RePlay allows data scientists to easily move from research mode to production mode using the same interfaces.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RePlay:+a+Recommendation+Framework+for+Experimentation+and+Production+Use)|0|
|[Conducting Recommender Systems User Studies Using POPROX](https://doi.org/10.1145/3640457.3687092)|Robin Burke, Joseph A. Konstan, Michael D. Ekstrand|Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA; Drexel Univ, Dept Informat Sci, Philadelphia, PA USA; Univ Colorado, Dept Informat Sci, Boulder, CO 80309 USA|The Platform for OPen Recommendation and Online eXperimentation (POPROX) is a new resource to allow RecSys researchers to conduct online user research without having to develop all of the necessary infrastructure and recruit users. Our first domain is personalized news recommendations - POPROX 1.0 provides a daily newsletter (with content from the Associated Press) to users who have already consented to participate in research, along with interfaces and protocols to support researchers in conducting studies that assign subsets of users to various experimental algorithms and/or interfaces. The purpose of this tutorial is to introduce the platform and its capabilities to prospective research users while walking through the implementation of a sample experiment so that researchers can proceed to propose and carry out experiments on the POPROX platform.|开放推荐与在线实验平台（POPROX）是一个新资源，旨在使推荐系统（RecSys）研究人员能够进行在线用户研究，而无需开发所有必要的基础设施和招募用户。我们的第一个应用领域是个性化新闻推荐——POPROX 1.0 向已同意参与研究的用户提供每日新闻简报（内容来自美联社），同时提供界面和协议，支持研究人员进行研究，将用户子集分配到各种实验算法和/或界面中。本教程的目的是向潜在的研究用户介绍该平台及其功能，同时通过一个示例实验的实施过程进行演示，以便研究人员能够在 POPROX 平台上提出并开展实验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conducting+Recommender+Systems+User+Studies+Using+POPROX)|0|
|[Conducting User Experiments in Recommender Systems](https://doi.org/10.1145/3640457.3687090)|Bart P. Knijnenburg, Edward C. Malthouse|Clemson Univ, Sch Comp, Clemson, SC 29634 USA; Northwestern Univ, Dept Integrated Mkt Commun, Evanston, IL USA|There is an increasing consensus in the field of recommender systems that we should move beyond the offline evaluation of algorithms towards a more user-centric approach. This tutorial teaches the essential skills involved in conducting user experiments, the scientific approach to user-centric evaluation. Such experiments are essential in uncovering how and why the user experience of recommender systems comes about.|在推荐系统领域，越来越多的共识认为，我们应该超越算法的离线评估，转向更加以用户为中心的方法。本教程教授了进行用户实验所涉及的基本技能，这是以用户为中心评估的科学方法。此类实验对于揭示推荐系统用户体验如何及为何产生至关重要。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conducting+User+Experiments+in+Recommender+Systems)|0|
|[Multimodal Representation Learning for High-Quality Recommendations in Cold-Start and Beyond-Accuracy](https://doi.org/10.1145/3640457.3688009)|Marta Moscati|Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria|Recommender systems (RS) traditionally leverage the large amount of user-item interaction data. This exposes RS to a lower recommendation quality in cold-start scenarios, as well as to a low recommendation quality in terms of beyond-accuracy evaluation metrics. State-of-the-art (SotA) models for cold-start scenarios rely on the use of side information on the items or the users, therefore relating recommendation to multimodal machine learning (ML). However, the most recent techniques from multimodal ML are often not applied to the domain of recommendation. Additionally, the evaluation of SotA multimodal RS often neglects beyond-accuracy aspects of recommendation. In this work, we outline research into designing novel multimodal RS based on SotA multimodal ML architectures for cold-start recommendation, and their evaluation and benchmark with preexisting multimodal RS in terms of accuracy and beyond-accuracy aspects of recommendation quality.|传统的推荐系统（RS）主要依赖于大量的用户-项目交互数据。然而，这导致推荐系统在冷启动场景下的推荐质量较低，同时在超越准确性评估指标方面的推荐质量也不高。针对冷启动场景的最先进（SotA）模型依赖于使用项目或用户的辅助信息，从而将推荐与多模态机器学习（ML）联系起来。然而，多模态ML领域的最新技术往往未被应用于推荐领域。此外，对SotA多模态推荐系统的评估常常忽视了推荐质量中超越准确性的方面。在本研究中，我们概述了基于SotA多模态ML架构设计新型多模态推荐系统的研究，并在推荐质量的准确性和超越准确性方面对现有多模态推荐系统进行了评估和基准测试。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Representation+Learning+for+High-Quality+Recommendations+in+Cold-Start+and+Beyond-Accuracy)|0|
|[Bias in Book Recommendation](https://doi.org/10.1145/3640457.3688025)|Savvina Daniil|UCL, London, England; Shahid Beheshti Univ, Tajrish, Iran; Univ Southern Calif, Los Angeles, CA 90007 USA|Recent studies have shown that recommendation systems commonly suffer from popularity bias. Popularity bias refers to the problem that popular items (i.e., frequently rated items) are recommended frequently while less popular items are recommended rarely or not at all. Researchers adopted two approaches to examining popularity bias: (i) from the users' perspective, by analyzing how far a recommendation system deviates from user's expectations in receiving popular items, and (ii) by analyzing the amount of exposure that long-tail items receive, measured by overall catalog coverage and novelty. In this paper, we examine the first point of view in the book domain, although the findings may be applied to other domains as well. To this end, we analyze the well-known Book-Crossing dataset and define three user groups based on their tendency towards popular items (i.e., Niche, Diverse, Bestseller-focused). Further, we evaluate the performance of nine state-of-the-art recommendation algorithms and two baselines (i.e., Random, MostPop) from both the accuracy (e.g., NDCG, Precision, Recall) and popularity bias perspectives. Our results indicate that most state-of-the-art recommendation algorithms suffer from popularity bias in the book domain, and fail to meet users' expectations with Niche and Diverse tastes despite having a larger profile size. Conversely, Bestseller-focused users are more likely to receive high-quality recommendations, both in terms of fairness and personalization. Furthermore, our study shows a tradeoff between personalization and unfairness of popularity bias in recommendation algorithms for users belonging to the Diverse and Bestseller groups, that is, algorithms with high capability of personalization suffer from the unfairness of popularity bias.|近期的研究表明，推荐系统普遍存在流行度偏差问题。流行度偏差指的是推荐系统倾向于频繁推荐热门物品（即被频繁评分的物品），而较少或不推荐不太受欢迎的物品。研究者们采用了两种方法来研究流行度偏差：（1）从用户的角度出发，分析推荐系统在推荐热门物品时与用户期望的偏离程度；（2）通过分析长尾物品的曝光量，以整体目录覆盖率和新颖性为衡量标准。本文在图书领域中探讨了第一种观点，尽管研究结果也可能适用于其他领域。为此，我们分析了著名的Book-Crossing数据集，并根据用户对热门物品的倾向性将其分为三个用户组（即小众用户、多样化用户和畅销书偏好用户）。此外，我们从准确性（如NDCG、精确率、召回率）和流行度偏差两个角度评估了九种先进的推荐算法和两种基线算法（即随机推荐、最热门推荐）的性能。我们的结果表明，在图书领域中，大多数先进的推荐算法都存在流行度偏差问题，并且尽管用户画像规模较大，这些算法仍未能满足小众和多样化用户的期望。相反，畅销书偏好用户更有可能在公平性和个性化方面获得高质量的推荐。此外，我们的研究表明，对于属于多样化用户组和畅销书偏好用户组的用户，推荐算法在个性化和流行度偏差的不公平性之间存在权衡，即个性化能力强的算法更容易受到流行度偏差的不公平性影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+in+Book+Recommendation)|0|
|[A New Perspective in Health Recommendations: Integration of Human Pose Estimation](https://doi.org/10.1145/3640457.3688026)|Gaetano Dibenedetto|Univ Bari Aldo Moro, Dept Comp Sci, Bari, Italy|In recent years, there has been a growing interest in multimodal and multi-source data due to their ability to introduce heterogeneous information. Studies have demonstrated that combining such information enhances the performance of Recommender Systems across various scenarios. In the context of Health Recommendation Systems (HRS), different types of data are utilized, primarily focusing on patient-based information, but data from Pose Estimations (PE) are not incorporated. The objective of my Ph.D. is to investigate methods to design and develop HRS that treat the PE as one of the input sources, taking into account aspects such as privacy concerns and balancing the trade-off between system quality and responsiveness. By leveraging the combination of diverse information sources, I intend to create a new model in the area of HRS capable of providing more precise and explainable recommendations.|近年来，多模态和多源数据因其能够引入异构信息而受到越来越多的关注。研究表明，结合此类信息可以提高推荐系统在各种场景下的性能。在健康推荐系统（HRS）的背景下，主要利用基于患者的不同类型数据，但尚未纳入来自姿态估计（PE）的数据。我的博士研究目标是探索设计和开发HRS的方法，将PE作为输入源之一，同时考虑隐私问题，并平衡系统质量和响应性之间的权衡。通过利用多种信息源的组合，我旨在HRS领域创建一个新的模型，能够提供更精确和可解释的推荐。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Perspective+in+Health+Recommendations:+Integration+of+Human+Pose+Estimation)|0|
|[Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models](https://doi.org/10.1145/3640457.3688104)|Yunjia Xi, Weiwen Liu, Jianghao Lin, Xiaoling Cai, Hong Zhu, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu|Huawei Noahs Ark Lab, Shenzhen, Peoples R China; Huawei, Consumer Business Grp, Shenzhen, Peoples R China; Huawei Noahs Ark Lab, Shanghai, Peoples R China; Shanghai Jiao Tong Univ, Shanghai, Peoples R China|Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.|推荐系统在各种在线服务中扮演着至关重要的角色。然而，其在特定封闭领域内单独训练和部署的孤立性质限制了其获取开放世界知识的能力。最近，大型语言模型（LLMs）的出现通过编码广泛的世界知识并展示推理能力，显示出弥合这一差距的潜力。尽管如此，之前直接使用LLMs作为推荐器的尝试无法满足工业推荐系统的推理延迟需求。在本研究中，我们提出了一种名为KAR的开放世界知识增强推荐框架，利用大型语言模型从LLMs中获取两种外部知识——用户偏好的推理知识和项目的实际知识。我们引入了因子化提示来引发对用户偏好的准确推理。生成的推理和实际知识通过混合专家适配器有效地转换和压缩成增强向量，以便与推荐任务兼容。获得的向量可以直接用于增强任何推荐模型的性能。我们还通过预处理和预存储来自LLM的知识来确保高效的推理。大量实验表明，KAR显著优于最先进的基线，并且与广泛的推荐算法兼容。我们将KAR部署到华为的新闻和音乐推荐平台，并在在线A/B测试中分别获得了7%和1.7%的提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Open-World+Recommendation+with+Knowledge+Augmentation+from+Large+Language+Models)|0|
|[Large Language Models as Evaluators for Recommendation Explanations](https://doi.org/10.1145/3640457.3688075)|Xiaoyu Zhang, Yishan Li, Jiayin Wang, Bowen Sun, Weizhi Ma, Peijie Sun, Min Zhang|Tsinghua Univ, Beijing, Peoples R China|The explainability of recommender systems has attracted significant attention in academia and industry. Many efforts have been made for explainable recommendations, yet evaluating the quality of the explanations remains a challenging and unresolved issue. In recent years, leveraging LLMs as evaluators presents a promising avenue in Natural Language Processing tasks (e.g., sentiment classification, information extraction), as they perform strong capabilities in instruction following and common-sense reasoning. However, evaluating recommendation explanatory texts is different from these NLG tasks, as its criteria are related to human perceptions and are usually subjective. In this paper, we investigate whether LLMs can serve as evaluators of recommendation explanations. To answer the question, we utilize real user feedback on explanations given from previous work and additionally collect third-party annotations and LLM evaluations. We design and apply a 3-level meta-evaluation strategy to measure the correlation between evaluator labels and the ground truth provided by users. Our experiments reveal that LLMs, such as GPT4, can provide comparable evaluations with appropriate prompts and settings. We also provide further insights into combining human labels with the LLM evaluation process and utilizing ensembles of multiple heterogeneous LLM evaluators to enhance the accuracy and stability of evaluations. Our study verifies that utilizing LLMs as evaluators can be an accurate, reproducible and cost-effective solution for evaluating recommendation explanation texts. Our code is available here1.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+as+Evaluators+for+Recommendation+Explanations)|0|
|[ReLand: Integrating Large Language Models' Insights into Industrial Recommenders via a Controllable Reasoning Pool](https://doi.org/10.1145/3640457.3688131)|Changxin Tian, Binbin Hu, Chunjing Gan, Haoyu Chen, Zhuo Zhang, Li Yu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Jiawei Chen|Ant Grp, Hangzhou, Zhejiang, Peoples R China; Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China|Recently, Large Language Models (LLMs) have shown significant potential in addressing the isolation issues faced by recommender systems. However, despite performance comparable to traditional recommenders, the current methods are cost-prohibitive for industrial applications. Consequently, existing LLM-based methods still need to catch up regarding effectiveness and efficiency. To tackle the above challenges, we present an LLM-enhanced recommendation framework named ReLand, which leverages Retrieval to effortlessly integrate Large language models’ insights into industrial recommenders. Specifically, ReLand employs LLMs to perform generative recommendations on sampled users (a.k.a., seed users), thereby constructing an LLM Reasoning Pool. Subsequently, we leverage retrieval to attach reliable recommendation rationales for the entire user base, ultimately effectively improving recommendation performance. Extensive offline and online experiments validate the effectiveness of ReLand. Since January 2024, ReLand has been deployed in the recommender system of Alipay, achieving statistically significant improvements of 3.19% in CTR and 1.08% in CVR.|近年来，大型语言模型（LLMs）在解决推荐系统面临的孤立问题方面展现出显著潜力。然而，尽管其性能可与传统推荐系统相媲美，但现有方法在工业应用中的成本过高。因此，现有的基于LLM的方法在效果和效率方面仍有待提升。为应对上述挑战，我们提出了一种名为ReLand的LLM增强推荐框架，该框架通过检索机制轻松将大型语言模型的洞察力融入工业推荐系统中。具体而言，ReLand利用LLM对抽样用户（即种子用户）进行生成式推荐，从而构建一个LLM推理池。随后，我们通过检索机制为整个用户群体附加可靠的推荐依据，最终有效提升推荐性能。大量离线和在线实验验证了ReLand的有效性。自2024年1月起，ReLand已在支付宝的推荐系统中部署，实现了点击率（CTR）显著提升3.19%和转化率（CVR）显著提升1.08%的成果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReLand:+Integrating+Large+Language+Models'+Insights+into+Industrial+Recommenders+via+a+Controllable+Reasoning+Pool)|0|
|[Reproducibility of LLM-based Recommender Systems: the Case Study of P5 Paradigm](https://doi.org/10.1145/3640457.3688072)|Pasquale Lops, Antonio Silletti, Marco Polignano, Cataldo Musto, Giovanni Semeraro|Univ Bari Aldo Moro, Bari, Italy|Recommender systems can significantly benefit from the availability of pre-trained large language models (LLMs), which can serve as a basic mechanism for generating recommendations based on detailed user and item data, such as text descriptions, user reviews, and metadata. On the one hand, this new generation of LLM-based recommender systems paves the way for dealing with traditional limitations, such as cold-start and data sparsity. Still, on the other hand, this poses fundamental challenges for their accountability. Reproducing experiments in the new context of LLM-based recommender systems is challenging for several reasons. New approaches are published at an unprecedented pace, which makes difficult to have a clear picture of the main protocols and good practices in the experimental evaluation. Moreover, the lack of proper frameworks for LLM-based recommendation development and evaluation makes the process of benchmarking models complex and uncertain. In this work, we discuss the main issues encountered when trying to reproduce P5 (Pretrain, Personalized Prompt, and Prediction Paradigm), one of the first works unifying different recommendation tasks in a shared language modeling and natural language generation framework. Starting from this study, we have developed LaikaLLM, a framework for training and evaluating LLMs, specifically for the recommendation task. It has been used to perform several experiments to assess the impact of using different LLMs, different personalization strategies, and a novel set of more informative prompts on the overall performance of recommendations in a fully reproducible environment.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reproducibility+of+LLM-based+Recommender+Systems:+the+Case+Study+of+P5+Paradigm)|0|
|[A Comparative Analysis of Text-Based Explainable Recommender Systems](https://doi.org/10.1145/3640457.3688069)|Alejandro ArizaCasabona, Ludovico Boratto, Maria Salamó|Univ Barcelona, CLiC UBICS, Barcelona, Spain; Univ Cagliari, Cagliari, Italy|One way to increase trust among users towards recommender systems is to provide the recommendation along with a textual explanation. In the literature, extraction-based, generation-based, and, more recently, hybrid solutions based on retrieval-augmented generation have been proposed to tackle the problem of text-based explainable recommendation. However, the use of different datasets, preprocessing steps, target explanations, baselines, and evaluation metrics complicates the reproducibility and state-of-the-art assessment of previous work among different model categories for successful advancements in the field. Our aim is to provide a comprehensive analysis of text-based explainable recommender systems by setting up a well-defined benchmark that accommodates generation-based, extraction-based, and hybrid approaches. Also, we enrich the existing evaluation of explainability and text quality of the explanations with a novel definition of feature hallucination. Our experiments on three real-world datasets unveil hidden behaviors and confirm several claims about model patterns. Our source code and preprocessed datasets are available at https://github.com/alarca94/text-exp-recsys24.|提高用户对推荐系统信任度的一种方法是，在提供推荐的同时附带文本解释。在文献中，已经提出了基于提取、基于生成的方法，以及最近提出的基于检索增强生成的混合解决方案，以解决基于文本的可解释推荐问题。然而，由于使用了不同的数据集、预处理步骤、目标解释、基线模型和评估指标，使得不同模型类别之间的可重复性和最新成果评估变得复杂，从而阻碍了该领域的成功进展。我们的目标是通过建立一个明确的基准，全面分析基于文本的可解释推荐系统，该基准适用于基于生成、基于提取以及混合方法。此外，我们通过引入特征幻觉的新定义，丰富了现有对解释可解释性和文本质量的评估。我们在三个真实世界数据集上的实验揭示了隐藏的行为，并证实了关于模型模式的若干主张。我们的源代码和预处理数据集可在 https://github.com/alarca94/text-exp-recsys24 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Comparative+Analysis+of+Text-Based+Explainable+Recommender+Systems)|0|
|[FLIP: Fine-grained Alignment between ID-based Models and Pretrained Language Models for CTR Prediction](https://doi.org/10.1145/3640457.3688106)|Hangyu Wang, Jianghao Lin, Xiangyang Li, Bo Chen, Chenxu Zhu, Ruiming Tang, Weinan Zhang, Yong Yu|Huawei Noahs Ark Lab, Shenzhen, Peoples R China; Shanghai Jiao Tong Univ, Shanghai, Peoples R China|Click-through rate (CTR) prediction plays as a core function module in various personalized online services. The traditional ID-based models for CTR prediction take as inputs the one-hot encoded ID features of tabular modality, which capture the collaborative signals via feature interaction modeling. But the one-hot encoding discards the semantic information included in the textual features. Recently, the emergence of Pretrained Language Models (PLMs) has given rise to another paradigm, which takes as inputs the sentences of textual modality obtained by hard prompt templates and adopts PLMs to extract the semantic knowledge. However, PLMs often face challenges in capturing field-wise collaborative signals and distinguishing features with subtle textual differences. In this paper, to leverage the benefits of both paradigms and meanwhile overcome their limitations, we propose to conduct Fine-grained feature-level ALignment between ID-based Models and Pretrained Language Models (FLIP) for CTR prediction. Unlike most methods that solely rely on global views through instance-level contrastive learning, we design a novel jointly masked tabular/language modeling task to learn fine-grained alignment between tabular IDs and word tokens. Specifically, the masked data of one modality (i.e., IDs and tokens) has to be recovered with the help of the other modality, which establishes the feature-level interaction and alignment via sufficient mutual information extraction between dual modalities. Moreover, we propose to jointly finetune the ID-based model and PLM by adaptively combining the output of both models, thus achieving superior performance in downstream CTR prediction tasks. Extensive experiments on three real-world datasets demonstrate that FLIP outperforms SOTA baselines, and is highly compatible with various ID-based models and PLMs. The code is available12.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLIP:+Fine-grained+Alignment+between+ID-based+Models+and+Pretrained+Language+Models+for+CTR+Prediction)|0|
|[AMBAR: A dataset for Assessing Multiple Beyond-Accuracy Recommenders](https://doi.org/10.1145/3640457.3688067)|Elizabeth Gómez, David Contreras, Ludovico Boratto, Maria Salamó||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AMBAR:+A+dataset+for+Assessing+Multiple+Beyond-Accuracy+Recommenders)|0|
|[The Fault in Our Recommendations: On the Perils of Optimizing the Measurable](https://doi.org/10.1145/3640457.3688144)|Omar Besbes, Yash Kanoria, Akshit Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Fault+in+Our+Recommendations:+On+the+Perils+of+Optimizing+the+Measurable)|0|
|[Fair Augmentation for Graph Collaborative Filtering](https://doi.org/10.1145/3640457.3688064)|Ludovico Boratto, Francesco Fabbri, Gianni Fenu, Mirko Marras, Giacomo Medda||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Augmentation+for+Graph+Collaborative+Filtering)|0|
|[Adaptive Fusion of Multi-View for Graph Contrastive Recommendation](https://doi.org/10.1145/3640457.3688153)|Mengduo Yang, Yi Yuan, Jie Zhou, Meng Xi, Xiaohua Pan, Ying Li, Yangyang Wu, Jinshan Zhang, Jianwei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Fusion+of+Multi-View+for+Graph+Contrastive+Recommendation)|0|
|[One-class Matrix Factorization: Point-Wise Regression-Based or Pair-Wise Ranking-Based?](https://doi.org/10.1145/3640457.3688063)|ShengWei Chen, ChihJen Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-class+Matrix+Factorization:+Point-Wise+Regression-Based+or+Pair-Wise+Ranking-Based?)|0|
|[Unlocking the Hidden Treasures: Enhancing Recommendations with Unlabeled Data](https://doi.org/10.1145/3640457.3688149)|Yuhan Zhao, Rui Chen, Qilong Han, Hongtao Song, Li Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Hidden+Treasures:+Enhancing+Recommendations+with+Unlabeled+Data)|0|
|[Revisiting BPR: A Replicability Study of a Common Recommender System Baseline](https://doi.org/10.1145/3640457.3688073)|Aleksandr Milogradskii, Oleg Lashinin, Alexander P, Marina Ananyeva, Sergey Kolesnikov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+BPR:+A+Replicability+Study+of+a+Common+Recommender+System+Baseline)|0|
|[ReChorus2.0: A Modular and Task-Flexible Recommendation Library](https://doi.org/10.1145/3640457.3688076)|Jiayu Li, Hanyu Li, Zhiyu He, Weizhi Ma, Peijie Sun, Min Zhang, Shaoping Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReChorus2.0:+A+Modular+and+Task-Flexible+Recommendation+Library)|0|
|[A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation](https://doi.org/10.1145/3640457.3688096)|Zixuan Yi, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Unified+Graph+Transformer+for+Overcoming+Isolations+in+Multi-modal+Recommendation)|0|
|[Information-Controllable Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3640457.3688122)|Zirui Guo, Yanhua Yu, Yuling Wang, Kangkang Lu, Zixuan Yang, Liang Pang, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information-Controllable+Graph+Contrastive+Learning+for+Recommendation)|0|
|[MMGCL: Meta Knowledge-Enhanced Multi-view Graph Contrastive Learning for Recommendations](https://doi.org/10.1145/3640457.3688127)|Yuezihan Jiang, Changyu Li, Gaode Chen, Peiyi Li, Qi Zhang, Jingjian Lin, Peng Jiang, Fei Sun, Wentao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMGCL:+Meta+Knowledge-Enhanced+Multi-view+Graph+Contrastive+Learning+for+Recommendations)|0|
|[Reproducibility and Analysis of Scientific Dataset Recommendation Methods](https://doi.org/10.1145/3640457.3688071)|Ornella Irrera, Matteo Lissandrini, Daniele Dell'Aglio, Gianmaria Silvello||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reproducibility+and+Analysis+of+Scientific+Dataset+Recommendation+Methods)|0|
|[ConFit: Improving Resume-Job Matching using Data Augmentation and Contrastive Learning](https://doi.org/10.1145/3640457.3688108)|Xiao Yu, Jinzhong Zhang, Zhou Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ConFit:+Improving+Resume-Job+Matching+using+Data+Augmentation+and+Contrastive+Learning)|0|
|[Unified Denoising Training for Recommendation](https://doi.org/10.1145/3640457.3688109)|Haoyan Chua, Yingpeng Du, Zhu Sun, Ziyan Wang, Jie Zhang, YewSoon Ong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Denoising+Training+for+Recommendation)|0|
|[Context-based Entity Recommendation for Knowledge Workers: Establishing a Benchmark on Real-life Data](https://doi.org/10.1145/3640457.3688068)|Mahta Bakhshizadeh, Heiko Maus, Andreas Dengel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-based+Entity+Recommendation+for+Knowledge+Workers:+Establishing+a+Benchmark+on+Real-life+Data)|0|
|[Improving the Shortest Plank: Vulnerability-Aware Adversarial Training for Robust Recommender System](https://doi.org/10.1145/3640457.3688120)|Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+the+Shortest+Plank:+Vulnerability-Aware+Adversarial+Training+for+Robust+Recommender+System)|0|
|[Accelerating the Surrogate Retraining for Poisoning Attacks against Recommender Systems](https://doi.org/10.1145/3640457.3688148)|Yunfan Wu, Qi Cao, Shuchang Tao, Kaike Zhang, Fei Sun, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+the+Surrogate+Retraining+for+Poisoning+Attacks+against+Recommender+Systems)|0|
|[Co-optimize Content Generation and Consumption in a Large Scale Video Recommendation System](https://doi.org/10.1145/3640457.3688033)|Zhen Zhang, Qingyun Liu, Yuening Li, Sourabh Bansod, Mingyan Gao, Yaping Zhang, Zhe Zhao, Lichan Hong, Ed H. Chi, Shuchao Bi, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-optimize+Content+Generation+and+Consumption+in+a+Large+Scale+Video+Recommendation+System)|0|
|[Entity-Aware Collections Ranking: A Joint Scoring Approach](https://doi.org/10.1145/3640457.3688038)|Sihao Chen, Sheng Li, Youhe Chen, Dong Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity-Aware+Collections+Ranking:+A+Joint+Scoring+Approach)|0|
|[Improving Data Efficiency for Recommenders and LLMs](https://doi.org/10.1145/3640457.3688052)|Noveen Sachdeva, Benjamin Coleman, WangCheng Kang, Jianmo Ni, James Caverlee, Lichan Hong, Ed H. Chi, Derek Zhiyuan Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Data+Efficiency+for+Recommenders+and+LLMs)|0|
|[LyricLure: Mining Catchy Hooks in Song Lyrics to Enhance Music Discovery and Recommendation](https://doi.org/10.1145/3640457.3688049)|Siddharth Sharma, Akshay Shukla, Ajinkya Walimbe, Tarun Sharma, Joaquin Delgado||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LyricLure:+Mining+Catchy+Hooks+in+Song+Lyrics+to+Enhance+Music+Discovery+and+Recommendation)|0|
|[Optimizing for Participation in Recommender System](https://doi.org/10.1145/3640457.3688042)|Yuan Shao, Bibang Liu, Sourabh Bansod, Arnab Bhadury, Mingyan Gao, Yaping Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+for+Participation+in+Recommender+System)|0|
|[Playlist Search Reinvented: LLMs Behind the Curtain](https://doi.org/10.1145/3640457.3688047)|Geetha Sai Aluri, Siddharth Sharma, Tarun Sharma, Joaquin Delgado||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Playlist+Search+Reinvented:+LLMs+Behind+the+Curtain)|0|
|[Privacy Preserving Conversion Modeling in Data Clean Room](https://doi.org/10.1145/3640457.3688054)|Kungang Li, Xiangyi Chen, Ling Leng, Jiajing Xu, Jiankai Sun, Behnam Rezaei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy+Preserving+Conversion+Modeling+in+Data+Clean+Room)|0|
|[Ranking Across Different Content Types: The Robust Beauty of Multinomial Blending](https://doi.org/10.1145/3640457.3688059)|Jan Malte Lichtenberg, Giuseppe Di Benedetto, Matteo Ruffini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking+Across+Different+Content+Types:+The+Robust+Beauty+of+Multinomial+Blending)|0|
|[Scale-Invariant Learning-to-Rank](https://doi.org/10.1145/3640457.3688032)|Alessio Petrozziello, Christian Sommeregger, YeSheen Lim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scale-Invariant+Learning-to-Rank)|0|
|[Sliding Window Training - Utilizing Historical Recommender Systems Data for Foundation Models](https://doi.org/10.1145/3640457.3688051)|Swanand Joshi, Yesu Feng, KoJen Hsiao, Zhe Zhang, Sudarshan Lamkhede||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sliding+Window+Training+-+Utilizing+Historical+Recommender+Systems+Data+for+Foundation+Models)|0|
|[Why the Shooting in the Dark Method Dominates Recommender Systems Practice](https://doi.org/10.1145/3640457.3688029)|David Rohde||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+the+Shooting+in+the+Dark+Method+Dominates+Recommender+Systems+Practice)|0|
|[MAWI Rec: Leveraging Severe Weather Data in Recommendation](https://doi.org/10.1145/3640457.3688157)|Brendan Andrew Duncan, Surya Kallumadi, Taylor BergKirkpatrick, Julian J. McAuley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAWI+Rec:+Leveraging+Severe+Weather+Data+in+Recommendation)|0|
|[Towards Green Recommender Systems: Investigating the Impact of Data Reduction on Carbon Footprint and Algorithm Performances](https://doi.org/10.1145/3640457.3688160)|Giuseppe Spillo, Allegra De Filippo, Cataldo Musto, Michela Milano, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Green+Recommender+Systems:+Investigating+the+Impact+of+Data+Reduction+on+Carbon+Footprint+and+Algorithm+Performances)|0|
|[Promoting Two-sided Fairness with Adaptive Weights for Providers and Customers in Recommendation](https://doi.org/10.1145/3640457.3688169)|Lanling Xu, Zihan Lin, Jinpeng Wang, Sheng Chen, Wayne Xin Zhao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Promoting+Two-sided+Fairness+with+Adaptive+Weights+for+Providers+and+Customers+in+Recommendation)|0|
|[CAPRI-FAIR: Integration of Multi-sided Fairness in Contextual POI Recommendation Framework](https://doi.org/10.1145/3640457.3688170)|Francis Zac dela Cruz, Flora D. Salim, Yonchanok Khaokaew, Jeffrey Chan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAPRI-FAIR:+Integration+of+Multi-sided+Fairness+in+Contextual+POI+Recommendation+Framework)|0|
|[Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems](https://doi.org/10.1145/3640457.3688172)|YanMartin Tamm, Anna Aljanaki||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comparative+Analysis+of+Pretrained+Audio+Representations+in+Music+Recommender+Systems)|0|
|[A Dataset for Adapting Recommender Systems to the Fashion Rental Economy](https://doi.org/10.1145/3640457.3688174)|Karl Audun Kagnes Borgersen, Morten Goodwin, Morten Grundetjern, Jivitesh Sharma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dataset+for+Adapting+Recommender+Systems+to+the+Fashion+Rental+Economy)|0|
|[Societal Sorting as a Systemic Risk of Recommenders](https://doi.org/10.1145/3640457.3688175)|Luke Thorburn, Maria Polukarov, Carmine Ventre||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Societal+Sorting+as+a+Systemic+Risk+of+Recommenders)|0|
|[Revisiting LightGCN: Unexpected Inflexibility, Inconsistency, and A Remedy Towards Improved Recommendation](https://doi.org/10.1145/3640457.3688176)|Geon Lee, Kyungho Kim, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+LightGCN:+Unexpected+Inflexibility,+Inconsistency,+and+A+Remedy+Towards+Improved+Recommendation)|0|
|[Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning](https://doi.org/10.1145/3640457.3688181)|Henri Jamet, Maxime Manderlier, Yash Raj Shrestha, Michalis Vlachos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluation+and+simplification+of+text+difficulty+using+LLMs+in+the+context+of+recommending+texts+in+French+to+facilitate+language+learning)|0|
|[Fairness Matters: A look at LLM-generated group recommendations](https://doi.org/10.1145/3640457.3688182)|Antonela Tommasel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+Matters:+A+look+at+LLM-generated+group+recommendations)|0|
|[EmbSum: Leveraging the Summarization Capabilities of Large Language Models for Content-Based Recommendations](https://doi.org/10.1145/3640457.3688185)|Chiyu Zhang, Yifei Sun, Minghao Wu, Jun Chen, Jie Lei, Muhammad AbdulMageed, Rong Jin, Angli Liu, Ji Zhu, Sem Park, Ning Yao, Bo Long||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EmbSum:+Leveraging+the+Summarization+Capabilities+of+Large+Language+Models+for+Content-Based+Recommendations)|0|
|[Knowledge-Enhanced Multi-Behaviour Contrastive Learning for Effective Recommendation](https://doi.org/10.1145/3640457.3688186)|Zeyuan Meng, Zixuan Yi, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-Enhanced+Multi-Behaviour+Contrastive+Learning+for+Effective+Recommendation)|0|
|[Can Editorial Decisions Impair Journal Recommendations? Analysing the Impact of Journal Characteristics on Recommendation Systems](https://doi.org/10.1145/3640457.3688194)|Elias Entrup, Ralph Ewerth, Anett Hoppe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Editorial+Decisions+Impair+Journal+Recommendations?+Analysing+the+Impact+of+Journal+Characteristics+on+Recommendation+Systems)|0|
|[Democratizing Urban Mobility Through an Open-Source, Multi-Criteria Route Recommendation System](https://doi.org/10.1145/3640457.3691702)|Alexander Eggerth, Javier Argota SánchezVaquerizo, Dirk Helbing, Sachit Mahajan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Democratizing+Urban+Mobility+Through+an+Open-Source,+Multi-Criteria+Route+Recommendation+System)|0|
|[KGGLM: A Generative Language Model for Generalizable Knowledge Graph Representation Learning in Recommendation](https://doi.org/10.1145/3640457.3691703)|Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Mirko Marras, Alessandro Soccol||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGGLM:+A+Generative+Language+Model+for+Generalizable+Knowledge+Graph+Representation+Learning+in+Recommendation)|0|
|[Social Choice for Heterogeneous Fairness in Recommendation](https://doi.org/10.1145/3640457.3691706)|Amanda Aird, Elena Stefancova, Cassidy All, Amy Voida, Martin Homola, Nicholas Mattei, Robin Burke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Social+Choice+for+Heterogeneous+Fairness+in+Recommendation)|0|
|[Less is More: Towards Sustainability-Aware Persuasive Explanations in Recommender Systems](https://doi.org/10.1145/3640457.3691708)|Thi Ngoc Trang Tran, Seda Polat Erdeniz, Alexander Felfernig, Sebastian Lubos, Merfat El Mansi, VietMan Le||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Less+is+More:+Towards+Sustainability-Aware+Persuasive+Explanations+in+Recommender+Systems)|0|
|[Are We Explaining the Same Recommenders? Incorporating Recommender Performance for Evaluating Explainers](https://doi.org/10.1145/3640457.3691709)|Amir Reza Mohammadi, Andreas Peintner, Michael Müller, Eva Zangerle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+We+Explaining+the+Same+Recommenders?+Incorporating+Recommender+Performance+for+Evaluating+Explainers)|0|
|[Understanding Fairness in Recommender Systems: A Healthcare Perspective](https://doi.org/10.1145/3640457.3691711)|Veronica Kecki, Alan Said||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+Fairness+in+Recommender+Systems:+A+Healthcare+Perspective)|0|
|[Multi-Preview Recommendation via Reinforcement Learning](https://doi.org/10.1145/3640457.3691698)|Yang Xu, KuanTing Lai, Pengcheng Xiong, Zhong Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Preview+Recommendation+via+Reinforcement+Learning)|0|
|[A Tool for Explainable Pension Fund Recommendations using Large Language Models](https://doi.org/10.1145/3640457.3691699)|Eduardo Alves da Silva, Leandro Balby Marinho, Edleno Silva de Moura, Altigran Soares da Silva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tool+for+Explainable+Pension+Fund+Recommendations+using+Large+Language+Models)|0|
|[RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations](https://doi.org/10.1145/3640457.3687164)|Johannes Kruse, Kasper Lindskow, Saikishore Kalloori, Marco Polignano, Claudio Pomo, Abhishek Srivastava, Anshuk Uppal, Michael Riis Andersen, Jes Frellsen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecSys+Challenge+2024:+Balancing+Accuracy+and+Editorial+Values+in+News+Recommendations)|0|
|[RecTemp: Temporal Reasoning in Recommendation Systems](https://doi.org/10.1145/3640457.3687096)|Adir Solomon, Tsvi Kuflik, Bracha Shapira, Ido Guy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecTemp:+Temporal+Reasoning+in+Recommendation+Systems)|0|
|[Reflections on Recommender Systems: Past, Present, and Future (INTROSPECTIVES)](https://doi.org/10.1145/3640457.3687101)|Alan Said, Christine Bauer, Eva Zangerle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reflections+on+Recommender+Systems:+Past,+Present,+and+Future+(INTROSPECTIVES))|0|
|[RobustRecSys @ RecSys2024: Design, Evaluation and Deployment of Robust Recommender Systems](https://doi.org/10.1145/3640457.3687106)|Valerio Guarrasi, Federico Siciliano, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RobustRecSys+@+RecSys2024:+Design,+Evaluation+and+Deployment+of+Robust+Recommender+Systems)|0|
|[Deep Recommendation using Graphs](https://doi.org/10.1145/3640457.3687089)|Panagiotis Symeonidis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Recommendation+using+Graphs)|0|
|[Computational Methods for Designing Human-Centered Recommender Systems: A Case Study Approach Intersecting Visual Arts and Healthcare](https://doi.org/10.1145/3640457.3687091)|Bereket Abera Yilma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Computational+Methods+for+Designing+Human-Centered+Recommender+Systems:+A+Case+Study+Approach+Intersecting+Visual+Arts+and+Healthcare)|0|
|[Economics of Recommender Systems](https://doi.org/10.1145/3640457.3687093)|Emilio Calvano, Giacomo Calzolari, Vincenzo Denicolò, Sergio Pastorello||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Economics+of+Recommender+Systems)|0|
|[A Tutorial on Feature Interpretation in Recommender Systems](https://doi.org/10.1145/3640457.3687094)|Zhaocheng Du, Chuhan Wu, Qinglin Jia, Jieming Zhu, Xu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tutorial+on+Feature+Interpretation+in+Recommender+Systems)|0|
|[Bridging Viewpoints in News with Recommender Systems](https://doi.org/10.1145/3640457.3688008)|Jia Hua Jeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Viewpoints+in+News+with+Recommender+Systems)|0|
|[Evaluating the Pros and Cons of Recommender Systems Explanations](https://doi.org/10.1145/3640457.3688011)|Kathrin Wardatzky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+the+Pros+and+Cons+of+Recommender+Systems+Explanations)|0|
|[Explainable Multi-Stakeholder Job Recommender Systems](https://doi.org/10.1145/3640457.3688014)|Roan Schellingerhout||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Multi-Stakeholder+Job+Recommender+Systems)|0|
|[CEERS: Counterfactual Evaluations of Explanations in Recommender Systems](https://doi.org/10.1145/3640457.3688015)|Mikhail Baklanov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CEERS:+Counterfactual+Evaluations+of+Explanations+in+Recommender+Systems)|0|
|[Towards Sustainable Recommendations in Urban Tourism](https://doi.org/10.1145/3640457.3688016)|Pavel Merinov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Sustainable+Recommendations+in+Urban+Tourism)|0|
|[How to Evaluate Serendipity in Recommender Systems: the Need for a Serendiptionnaire](https://doi.org/10.1145/3640457.3688017)|Brett Binst||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+to+Evaluate+Serendipity+in+Recommender+Systems:+the+Need+for+a+Serendiptionnaire)|0|
|[Enhancing Privacy in Recommender Systems through Differential Privacy Techniques](https://doi.org/10.1145/3640457.3688019)|Angela Di Fazio||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Privacy+in+Recommender+Systems+through+Differential+Privacy+Techniques)|0|
|[Fairness Explanations in Recommender Systems](https://doi.org/10.1145/3640457.3688020)|Luan Soares de Souza||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+Explanations+in+Recommender+Systems)|0|
|[Explainable and Faithful Educational Recommendations through Causal Language Modelling via Knowledge Graphs](https://doi.org/10.1145/3640457.3688022)|Neda Afreen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+and+Faithful+Educational+Recommendations+through+Causal+Language+Modelling+via+Knowledge+Graphs)|0|
|[Fairness and Transparency in Music Recommender Systems: Improvements for Artists](https://doi.org/10.1145/3640457.3688024)|Karlijn Dinnissen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+and+Transparency+in+Music+Recommender+Systems:+Improvements+for+Artists)|0|
|[Explainability in Music Recommender System](https://doi.org/10.1145/3640457.3688028)|Shahrzad Shashaani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainability+in+Music+Recommender+System)|0|
|[Short-form Video Needs Long-term Interests: An Industrial Solution for Serving Large User Sequence Models](https://doi.org/10.1145/3640457.3688030)|Yuening Li, Diego Uribe, Chuan He, Jiaxi Tang, Qingyun Liu, Junjie Shan, Ben Most, Kaushik Kalyan, Shuchao Bi, Xinyang Yi, Lichan Hong, Ed H. Chi, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Short-form+Video+Needs+Long-term+Interests:+An+Industrial+Solution+for+Serving+Large+User+Sequence+Models)|0|
|[Explore versus repeat: insights from an online supermarket](https://doi.org/10.1145/3640457.3688050)|Mariagiorgia Agnese Tandoi, Daniela Solis Morales||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explore+versus+repeat:+insights+from+an+online+supermarket)|0|
|[What to compare? Towards understanding user sessions on price comparison platforms](https://doi.org/10.1145/3640457.3691717)|Ahmadou Wagne, Julia Neidhardt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+to+compare?+Towards+understanding+user+sessions+on+price+comparison+platforms)|0|
|[Cross-Domain Latent Factors Sharing via Implicit Matrix Factorization](https://doi.org/10.1145/3640457.3688143)|Abdulaziz Samra, Evgeny Frolov, Alexey Vasilev, Alexander Grigorevskiy, Anton Vakhrushev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Domain+Latent+Factors+Sharing+via+Implicit+Matrix+Factorization)|0|
|[Optimal Baseline Corrections for Off-Policy Contextual Bandits](https://doi.org/10.1145/3640457.3688105)|Shashank Gupta, Olivier Jeunen, Harrie Oosterhuis, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Baseline+Corrections+for+Off-Policy+Contextual+Bandits)|0|
|[Effective Off-Policy Evaluation and Learning in Contextual Combinatorial Bandits](https://doi.org/10.1145/3640457.3688099)|Tatsuhiro Shimizu, Koichi Tanaka, Ren Kishimoto, Haruka Kiyohara, Masahiro Nomura, Yuta Saito||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Off-Policy+Evaluation+and+Learning+in+Contextual+Combinatorial+Bandits)|0|
|["More to Read" at the Los Angeles Times: Solving a Cold Start Problem with LLMs to Improve Story Discovery](https://doi.org/10.1145/3640457.3688031)|Franklin Horn, Aurelia Alston, Won J. You||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="More+to+Read"+at+the+Los+Angeles+Times:+Solving+a+Cold+Start+Problem+with+LLMs+to+Improve+Story+Discovery)|0|
|[Powerful A/B-Testing Metrics and Where to Find Them](https://doi.org/10.1145/3640457.3688036)|Olivier Jeunen, Shubham Baweja, Neeti Pokharna, Aleksei Ustimenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Powerful+A/B-Testing+Metrics+and+Where+to+Find+Them)|0|
|[Δ-OPE: Off-Policy Estimation with Pairs of Policies](https://doi.org/10.1145/3640457.3688162)|Olivier Jeunen, Aleksei Ustimenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Δ-OPE:+Off-Policy+Estimation+with+Pairs+of+Policies)|0|
|[Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation](https://doi.org/10.1145/3640457.3688142)|David Eric Austin, Anton Korikov, Armin Toroghi, Scott Sanner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bayesian+Optimization+with+LLM-Based+Acquisition+Functions+for+Natural+Language+Preference+Elicitation)|0|
|[The Role of Unknown Interactions in Implicit Matrix Factorization - A Probabilistic View](https://doi.org/10.1145/3640457.3688100)|Joey De Pauw, Bart Goethals||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Role+of+Unknown+Interactions+in+Implicit+Matrix+Factorization+-+A+Probabilistic+View)|0|
|[Country-diverted experiments for mitigation of network effects](https://doi.org/10.1145/3640457.3688046)|Lina Lin, Changping Meng, Jennifer Brennan, Jean PougetAbadie, Ningren Han, Shuchao Bi, Yajun Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Country-diverted+experiments+for+mitigation+of+network+effects)|0|
|[Off-Policy Selection for Optimizing Ad Display Timing in Mobile Games (Samsung Instant Plays)](https://doi.org/10.1145/3640457.3688058)|Katarzyna SiudekTkaczuk, Slawomir Kapka, Jedrzej Alchimowicz, Bartlomiej Swoboda, Michal Romaniuk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Selection+for+Optimizing+Ad+Display+Timing+in+Mobile+Games+(Samsung+Instant+Plays))|0|
|[On Interpretability of Linear Autoencoders](https://doi.org/10.1145/3640457.3688179)|Martin Spisák, Radek Bartyzal, Antonín Hoskovec, Ladislav Peska||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Interpretability+of+Linear+Autoencoders)|0|
|[Informed Dataset Selection with 'Algorithm Performance Spaces'](https://doi.org/10.1145/3640457.3691704)|Joeran Beel, Lukas Wegmeth, Lien Michiels, Steffen Schulz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Informed+Dataset+Selection+with+'Algorithm+Performance+Spaces')|0|
|[Stalactite: toolbox for fast prototyping of vertical federated learning systems](https://doi.org/10.1145/3640457.3691700)|Anastasiia Zakharova, Dmitriy Alexandrov, Maria Khodorchenko, Nikolay Butakov, Alexey Vasilev, Maxim Savchenko, Alexander Grigorievskiy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stalactite:+toolbox+for+fast+prototyping+of+vertical+federated+learning+systems)|0|
|[VideoRecSys + LargeRecSys 2024](https://doi.org/10.1145/3640457.3687116)|Khushhall Chandra Mahajan, Amey Porobo Dharwadker, Saurabh Gupta, Brad Schumitsch, Arnab Bhadury, Ding Tong, KoJen Hsiao, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VideoRecSys+++LargeRecSys+2024)|0|
|[Integrating Matrix Factorization with Graph based Models](https://doi.org/10.1145/3640457.3688013)|Rachana Mehta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Matrix+Factorization+with+Graph+based+Models)|0|
