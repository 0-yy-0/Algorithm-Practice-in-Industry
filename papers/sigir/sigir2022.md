# SIGIR2022 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Hypergraph Contrastive Collaborative Filtering](https://doi.org/10.1145/3477495.3532058)|Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, Jimmy X. Huang|University of Hong Kong, Hong Kong, Hong Kong; Baidu, Beijing, China; York University, Toronto, Canada; South China University Of Technology, Guangzhou, China; Wilfrid Laurier University, Waterloo, Canada|Collaborative Filtering (CF) has emerged as fundamental paradigms for parameterizing users and items into latent representation space, with their correlative patterns from interaction data. Among various CF techniques, the development of GNN-based recommender systems, e.g., PinSage and LightGCN, has offered the state-of-the-art performance. However, two key challenges have not been well explored in existing solutions: i) The over-smoothing effect with deeper graph-based CF architecture, may cause the indistinguishable user representations and degradation of recommendation results. ii) The supervision signals (i.e., user-item interactions) are usually scarce and skewed distributed in reality, which limits the representation power of CF paradigms. To tackle these challenges, we propose a new self-supervised recommendation framework Hypergraph Contrastive Collaborative Filtering (HCCF) to jointly capture local and global collaborative relations with a hypergraph-enhanced cross-view contrastive learning architecture. In particular, the designed hypergraph structure learning enhances the discrimination ability of GNN-based CF paradigm, in comprehensively capturing the complex high-order dependencies among users. Additionally, our HCCF model effectively integrates the hypergraph structure encoding with self-supervised learning to reinforce the representation quality of recommender systems, based on the hypergraph self-discrimination. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over various state-of-the-art recommendation methods, and the robustness against sparse user interaction data. The implementation codes are available at https://github.com/akaxlh/HCCF.|协同过滤(CF)已经成为将用户和项目参数化为潜在表征空间的基本范例，其相关模式来自交互数据。在各种 CF 技术中，基于 GNN 的推荐系统(如 PinSage 和 LightGCN)的开发提供了最先进的性能。然而，在现有的解决方案中，有两个关键的挑战还没有得到很好的探索: i)基于更深层次的基于图的 CF 架构的过度平滑效应，可能导致难以区分的用户表示和推荐结果的退化。监督信号(即用户-项目交互)在现实生活中往往是稀缺的、偏态分布的，这限制了 CF 范式的表示能力。为了应对这些挑战，我们提出了一个新的自我监督推荐框架 Hypergraph 对比度协同过滤(hCCF) ，通过一个超图增强的跨视图对比度学习架构，联合捕捉本地和全球的协作关系。特别是，所设计的超图结构学习提高了基于 GNN 的 CF 范式的识别能力，能够全面捕获用户之间复杂的高阶依赖关系。此外，我们的 HCCF 模型有效地将超图结构编码与自监督学习相结合，以增强基于超图自辨识的推荐系统的表示质量。在三个基准数据集上的大量实验表明，该模型优于各种最新的推荐方法，并且对稀疏用户交互数据具有鲁棒性。实施守则可于 https://github.com/akaxlh/hccf 索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hypergraph+Contrastive+Collaborative+Filtering)|22|
|[Are Graph Augmentations Necessary?: Simple Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3477495.3531937)|Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, Quoc Viet Hung Nguyen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+Graph+Augmentations+Necessary?:+Simple+Graph+Contrastive+Learning+for+Recommendation)|20|
|[From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective](https://doi.org/10.1145/3477495.3531857)|Thibault Formal, Carlos Lassance, Benjamin Piwowarski, Stéphane Clinchant|Naver Labs Europe / Sorbonne Université, ISIR, Meylan, France; Sorbonne Université, ISIR / CNRS, Paris, France; Naver Labs Europe, Meylan, France|Neural retrievers based on dense representations combined with Approximate Nearest Neighbors search have recently received a lot of attention, owing their success to distillation and/or better sampling of examples for training -- while still relying on the same backbone architecture. In the meantime, sparse representation learning fueled by traditional inverted indexing techniques has seen a growing interest, inheriting from desirable IR priors such as explicit lexical matching. While some architectural variants have been proposed, a lesser effort has been put in the training of such models. In this work, we build on SPLADE -- a sparse expansion-based retriever -- and show to which extent it is able to benefit from the same training improvements as dense models, by studying the effect of distillation, hard-negative mining as well as the Pre-trained Language Model initialization. We furthermore study the link between effectiveness and efficiency, on in-domain and zero-shot settings, leading to state-of-the-art results in both scenarios for sufficiently expressive models.|基于密集表示结合近似最近邻搜索的神经检索器最近受到了很多关注，因为它们的成功归功于提取和/或更好的训练样本采样——同时仍然依赖于相同的骨干架构。与此同时，传统的反向索引技术所激发的稀疏表示学习受到了越来越多的关注，它继承了外显词汇匹配等可取的信息检索先验。虽然已经提出了一些体系结构变体，但在这类模型的培训方面投入的努力较少。在这项工作中，我们建立在 SPLADE ——一个基于稀疏扩展的检索器——的基础上，通过研究蒸馏、硬负面挖掘以及预训练语言模型初始化的效果，展示了它在多大程度上能够从与密集模型相同的训练改进中受益。我们进一步研究了效率和效果之间的联系，在领域内和零射击设置，导致国家的最先进的结果，在两种情况下充分表达模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Distillation+to+Hard+Negative+Sampling:+Making+Sparse+Neural+IR+Models+More+Effective)|10|
|[Multi-level Cross-view Contrastive Learning for Knowledge-aware Recommender System](https://doi.org/10.1145/3477495.3532025)|Ding Zou, Wei Wei, XianLing Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, Xin Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-level+Cross-view+Contrastive+Learning+for+Knowledge-aware+Recommender+System)|10|
|[Knowledge Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3477495.3532009)|Yuhao Yang, Chao Huang, Lianghao Xia, Chenliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Contrastive+Learning+for+Recommendation)|10|
|[Meta-Knowledge Transfer for Inductive Knowledge Graph Embedding](https://doi.org/10.1145/3477495.3531757)|Mingyang Chen, Wen Zhang, Yushan Zhu, Hongting Zhou, Zonggang Yuan, Changliang Xu, Huajun Chen|Zhejiang University, Hangzhou, China; Huawei Technologies Co., Ltd., Nanjing, China; Zhejiang University & Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Hangzhou, China; State Key Laboratory of Media Convergence Production Technology and Systems, Beijing, China|Knowledge graphs (KGs) consisting of a large number of triples have become widespread recently, and many knowledge graph embedding (KGE) methods are proposed to embed entities and relations of a KG into continuous vector spaces. Such embedding methods simplify the operations of conducting various in-KG tasks (e.g., link prediction) and out-of-KG tasks (e.g., question answering). They can be viewed as general solutions for representing KGs. However, existing KGE methods are not applicable to inductive settings, where a model trained on source KGs will be tested on target KGs with entities unseen during model training. Existing works focusing on KGs in inductive settings can only solve the inductive relation prediction task. They can not handle other out-of-KG tasks as general as KGE methods since they don't produce embeddings for entities. In this paper, to achieve inductive knowledge graph embedding, we propose a model MorsE, which does not learn embeddings for entities but learns transferable meta-knowledge that can be used to produce entity embeddings. Such meta-knowledge is modeled by entity-independent modules and learned by meta-learning. Experimental results show that our model significantly outperforms corresponding baselines for in-KG and out-of-KG tasks in inductive settings.|由大量三元组构成的知识图(KG)近年来得到了广泛的应用，为了将 KG 的实体和关系嵌入到连续向量空间中，提出了许多知识图嵌入(KGE)方法。这种嵌入方法简化了进行各种内 KG 任务(例如，链接预测)和外 KG 任务(例如，问题回答)的操作。他们可以被视为代表幼稚园的一般解决方案。然而，现有的 KGE 方法不适用于归纳环境，在这种情况下，以源幼儿园为培训对象的模型将在模型培训过程中看不到实体的目标幼儿园中进行测试。现有的针对归纳环境下幼儿园的工作只能解决归纳关系预测任务。它们不能像 KGE 方法那样处理其他超出 KG 的任务，因为它们不为实体生成嵌入。为了实现归纳知识图的嵌入，本文提出了一种 MorsE 模型，该模型不学习实体的嵌入，而是学习可转移的元知识，从而生成实体的嵌入。这种元知识由独立于实体的模块建模，并通过元学习来学习。实验结果表明，在感应环境下，我们的模型对于在 KG 内和在 KG 外的任务的性能明显优于相应的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Knowledge+Transfer+for+Inductive+Knowledge+Graph+Embedding)|8|
|[CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems](https://doi.org/10.1145/3477495.3531959)|Mohammadmehdi Naghiaei, Hossein A. Rahmani, Yashar Deldjoo|Polytechnic University of Bari, Bari, Italy; University of Southern California, California, CA, USA; University College London, London, United Kingdom|Recently, there has been a rising awareness that when machine learning (ML) algorithms are used to automate choices, they may treat/affect individuals unfairly, with legal, ethical, or economic consequences. Recommender systems are prominent examples of such ML systems that assist users in making high-stakes judgments. A common trend in the previous literature research on fairness in recommender systems is that the majority of works treat user and item fairness concerns separately, ignoring the fact that recommender systems operate in a two-sided marketplace. In this work, we present an optimization-based re-ranking approach that seamlessly integrates fairness constraints from both the consumer and producer-side in a joint objective framework. We demonstrate through large-scale experiments on 8 datasets that our proposed method is capable of improving both consumer and producer fairness without reducing overall recommendation quality, demonstrating the role algorithms may play in minimizing data biases.|最近，人们越来越意识到，当机器学习(ML)算法被用于自动选择时，它们可能会不公平地对待/影响个人，产生法律、道德或经济后果。推荐系统是这种机器学习系统的突出例子，它可以帮助用户做出高风险的判断。在以往关于推荐系统公平性的文献研究中，一个普遍的趋势是，大多数研究将用户和项目的公平性问题分开处理，忽略了推荐系统在双边市场中运行的事实。在这项工作中，我们提出了一个基于优化的重新排序方法，在一个联合目标框架中无缝地整合来自消费者和生产者方面的公平约束。我们通过在8个数据集上的大规模实验证明了我们提出的方法能够在不降低整体推荐质量的情况下提高消费者和生产者的公平性，并且证明了算法在最小化数据偏差方面可能发挥的作用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CPFair:+Personalized+Consumer+and+Producer+Fairness+Re-ranking+for+Recommender+Systems)|7|
|[Curriculum Learning for Dense Retrieval Distillation](https://doi.org/10.1145/3477495.3531791)|Hansi Zeng, Hamed Zamani, Vishwa Vinay|Adobe Research, Bangalore, AA, India; University of Massachusetts Amherst, Amherst, MA, USA|Recent work has shown that more effective dense retrieval models can be obtained by distilling ranking knowledge from an existing base re-ranking model. In this paper, we propose a generic curriculum learning based optimization framework called CL-DRD that controls the difficulty level of training data produced by the re-ranking (teacher) model. CL-DRD iteratively optimizes the dense retrieval (student) model by increasing the difficulty of the knowledge distillation data made available to it. In more detail, we initially provide the student model coarse-grained preference pairs between documents in the teacher's ranking, and progressively move towards finer-grained pairwise document ordering requirements. In our experiments, we apply a simple implementation of the CL-DRD framework to enhance two state-of-the-art dense retrieval models. Experiments on three public passage retrieval datasets demonstrate the effectiveness of our proposed framework.|最近的研究表明，从现有的基础重排序模型中提取排序知识可以获得更有效的稠密检索模型。本文提出了一个基于课程学习的通用优化框架 CL-DRD，该框架控制重新排序(教师)模型产生的训练数据的难易程度。CL-DRD 通过增加提供给它的知识提取数据的难度，迭代优化了密集检索(学生)模型。更详细地说，我们首先在教师排名中提供文档之间的学生模型粗粒度偏好对，然后逐步向更细粒度的成对文档排序需求转移。在我们的实验中，我们应用了一个简单的 CL-DRD 框架实现来增强两个最先进的稠密检索模型。在三个公共通道检索数据集上的实验证明了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curriculum+Learning+for+Dense+Retrieval+Distillation)|7|
|[Constructing Better Evaluation Metrics by Incorporating the Anchoring Effect into the User Model](https://doi.org/10.1145/3477495.3531953)|Nuo Chen, Fan Zhang, Tetsuya Sakai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constructing+Better+Evaluation+Metrics+by+Incorporating+the+Anchoring+Effect+into+the+User+Model)|7|
|[Graph Trend Filtering Networks for Recommendation](https://doi.org/10.1145/3477495.3531985)|Wenqi Fan, Xiaorui Liu, Wei Jin, Xiangyu Zhao, Jiliang Tang, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Trend+Filtering+Networks+for+Recommendation)|6|
|[An Efficiency Study for SPLADE Models](https://doi.org/10.1145/3477495.3531833)|Carlos Lassance, Stéphane Clinchant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficiency+Study+for+SPLADE+Models)|6|
|[Improving Conversational Recommender Systems via Transformer-based Sequential Modelling](https://doi.org/10.1145/3477495.3531852)|Jie Zou, Evangelos Kanoulas, Pengjie Ren, Zhaochun Ren, Aixin Sun, Cheng Long|[email protected]; Shandong University, Qingdao, China; University of Amsterdam, Amsterdam, Netherlands|In Conversational Recommender Systems (CRSs), conversations usually involve a set of related items and entities e.g., attributes of items. These items and entities are mentioned in order following the development of a dialogue. In other words, potential sequential dependencies exist in conversations. However, most of the existing CRSs neglect these potential sequential dependencies. In this paper, we propose a Transformer-based sequential conversational recommendation method, named TSCR, which models the sequential dependencies in the conversations to improve CRS. We represent conversations by items and entities, and construct user sequences to discover user preferences by considering both mentioned items and entities. Based on the constructed sequences, we deploy a Cloze task to predict the recommended items along a sequence. Experimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines.|在会话推荐系统(CRS)中，会话通常涉及一组相关的项目和实体，例如，项目的属性。这些项目和实体将在对话发展之后按顺序提及。换句话说，潜在的顺序依赖性存在于会话中。然而，大多数现有的 CRS 忽略了这些潜在的顺序依赖关系。本文提出了一种基于变压器的顺序会话推荐方法 TSCR，该方法通过建立会话中的顺序依赖关系来改进 CRS。我们通过条目和实体表示会话，并通过考虑上述条目和实体构造用户序列来发现用户偏好。基于构造的序列，我们部署完形填空任务来预测一个序列中推荐的项目。实验结果表明，我们的 TSCR 模型明显优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Conversational+Recommender+Systems+via+Transformer-based+Sequential+Modelling)|5|
|[BERT-ER: Query-specific BERT Entity Representations for Entity Ranking](https://doi.org/10.1145/3477495.3531944)|Shubham Chatterjee, Laura Dietz|University of New Hampshire, Durham, NH, USA|Entity-oriented search systems often learn vector representations of entities via the introductory paragraph from the Wikipedia page of the entity. As such representations are the same for every query, our hypothesis is that the representations are not ideal for IR tasks. In this work, we present BERT Entity Representations (BERT-ER) which are query-specific vector representations of entities obtained from text that describes how an entity is relevant for a query. Using BERT-ER in a downstream entity ranking system, we achieve a performance improvement of 13-42% (Mean Average Precision) over a system that uses the BERT embedding of the introductory paragraph from Wikipedia on two large-scale test collections. Our approach also outperforms entity ranking systems using entity embeddings from Wikipedia2Vec, ERNIE, and E-BERT. We show that our entity ranking system using BERT-ER can increase precision at the top of the ranking by promoting relevant entities to the top. With this work, we release our BERT models and query-specific entity embeddings fine-tuned for the entity ranking task.|面向实体的搜索系统通常通过实体的 Wikipedia 页面中的介绍性段落学习实体的向量表示。由于这种表示对于每个查询都是相同的，我们的假设是，这种表示对于 IR 任务来说并不理想。在这项工作中，我们提出了 BERT 实体表示(BERT-ER) ，它是从文本中获得的实体的特定于查询的向量表示，描述了一个实体如何与一个查询相关。在下游实体排名系统中使用 BERT-ER，我们比在两个大规模测试集合中使用 BERT 嵌入的介绍性段落的系统获得了13-42% 的性能提高(均值平均精度)。我们的方法也优于使用 Wikipedia2Vec、 ERNIE 和 E-BERT 的实体嵌入的实体排序系统。结果表明，使用 BERT-ER 的实体排名系统可以通过将相关实体提升到顶端来提高排名的精度。通过这项工作，我们发布了我们的 BERT 模型和针对实体排序任务的查询特定实体嵌入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BERT-ER:+Query-specific+BERT+Entity+Representations+for+Entity+Ranking)|5|
|[Reduce, Reuse, Recycle: Green Information Retrieval Research](https://doi.org/10.1145/3477495.3531766)|Harrisen Scells, Shengyao Zhuang, Guido Zuccon|The University of Queensland, Brisbane, QLD, Australia|Recent advances in Information Retrieval utilise energy-intensive hardware to produce state-of-the-art results. In areas of research highly related to Information Retrieval, such as Natural Language Processing and Machine Learning, there have been efforts to quantify and reduce the power and emissions produced by methods that depend on such hardware. Research that is conscious of the environmental impacts of its experimentation and takes steps to mitigate some of these impacts is considered 'Green'. Given the continuous demand for more data and power-hungry techniques, Green research is likely to become more important within the broader research community. Therefore, within the Information Retrieval community, the consequences of non-Green (in other words, Red) research should at least be considered and acknowledged. As such, the aims of this perspective paper are fourfold: (1) to review the Green literature not only for Information Retrieval but also for related domains in order to identify transferable Green techniques; (2) to provide measures for quantifying the power usage and emissions of Information Retrieval research; (3) to report the power usage and emission impacts for various current IR methods; and (4) to provide a framework to guide Green Information Retrieval research, taking inspiration from 'reduce, reuse, recycle' waste management campaigns, including salient examples from the literature that implement these concepts.|最近在信息检索方面的进展利用能源密集型硬件来产生最先进的结果。在与信息检索高度相关的研究领域，如自然语言处理和机器学习，一直在努力量化和减少依赖这些硬件的方法所产生的功率和排放。意识到实验对环境的影响并采取措施减轻其中一些影响的研究被认为是“绿色”的。鉴于对更多数据和耗电技术的持续需求，绿色研究可能在更广泛的研究领域变得更加重要。因此，在信息检索社区内，非绿色(换句话说，红色)研究的后果至少应该被考虑和承认。因此，本文件的目的有四个: (1)不仅为信息检索而且为相关领域查阅绿色文献，以便确定可转用的绿色技术; (2)提供量化信息检索研究的用电量和排放量的措施; (3)报告各种现行红外线方法的用电量和排放影响; (4)提供一个框架，以指导绿色信息检索研究，从“减少、再使用、回收”废物管理运动中获得启发，包括实施这些概念的文献中的突出例子。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reduce,+Reuse,+Recycle:+Green+Information+Retrieval+Research)|5|
|[On-Device Next-Item Recommendation with Self-Supervised Knowledge Distillation](https://doi.org/10.1145/3477495.3531775)|Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Guandong Xu, Quoc Viet Hung Nguyen|University of Technology Sydney, Sydney, NSW, Australia; Baidu Inc., Beijing, China; Griffith University, Gold Coast, Australia; The University of Queensland, Brisbane, QLD, Australia|Session-based recommender systems (SBR) are becoming increasingly popular because they can predict user interests without relying on long-term user profile and support login-free recommendation. Modern recommender systems operate in a fully server-based fashion. To cater to millions of users, the frequent model maintaining and the high-speed processing for concurrent user requests are required, which comes at the cost of a huge carbon footprint. Meanwhile, users need to upload their behavior data even including the immediate environmental context to the server, raising the public concern about privacy. On-device recommender systems circumvent these two issues with cost-conscious settings and local inference. However, due to the limited memory and computing resources, on-device recommender systems are confronted with two fundamental challenges: (1) how to reduce the size of regular models to fit edge devices? (2) how to retain the original capacity? Previous research mostly adopts tensor decomposition techniques to compress regular recommendation models with low compression rates so as to avoid drastic performance degradation. In this paper, we explore ultra-compact models for next-item recommendation, by loosing the constraint of dimensionality consistency in tensor decomposition. To compensate for the capacity loss caused by compression, we develop a self-supervised knowledge distillation framework which enables the compressed model (student) to distill the essential information lying in the raw data, and improves the long-tail item recommendation through an embedding-recombination strategy with the original model (teacher). The extensive experiments on two benchmarks demonstrate that, with 30x size reduction, the compressed model almost comes with no accuracy loss, and even outperforms its uncompressed counterpart. The code is released at https://github.com/xiaxin1998/OD-Rec.|基于会话的推荐系统正变得越来越流行，因为它们可以预测用户的兴趣而不依赖于长期的用户配置文件和支持免登录的推荐。现代推荐系统以完全基于服务器的方式运行。为了满足数百万用户的需求，需要频繁的模型维护和对并发用户请求的高速处理，这需要付出巨大的碳足印。与此同时，用户需要上传他们的行为数据，甚至包括即时的环境背景到服务器，引起公众对隐私的关注。设备上的推荐系统通过成本意识设置和本地推断来规避这两个问题。然而，由于有限的内存和计算资源，设备上的推荐系统面临着两个基本的挑战: (1)如何减少常规模型的大小，以适应边缘设备？(2)如何保留原有能力？以往的研究大多采用张量分解技术对低压缩率的常规推荐模型进行压缩，以避免性能的急剧下降。本文通过放松张量分解中维度一致性的约束，探索了下一项推荐的超紧模型。为了弥补压缩带来的容量损失，提出了一种自监督知识提取框架，使压缩模型(学生)能够提取原始数据中的关键信息，并通过与原始模型(教师)的嵌入-重组策略改进长尾项目推荐。在两个基准上的大量实验表明，在缩小了30倍尺寸的情况下，压缩模型几乎没有精度损失，甚至优于未压缩模型。密码在 https://github.com/xiaxin1998/od-rec 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On-Device+Next-Item+Recommendation+with+Self-Supervised+Knowledge+Distillation)|5|
|[DisenCDR: Learning Disentangled Representations for Cross-Domain Recommendation](https://doi.org/10.1145/3477495.3531967)|Jiangxia Cao, Xixun Lin, Xin Cong, Jing Ya, Tingwen Liu, Bin Wang|Institute of Information Engineering, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China; Xiaomi Inc., Beijing, China|Data sparsity is a long-standing problem in recommender systems. To alleviate it, Cross-Domain Recommendation (CDR) has attracted a surge of interests, which utilizes the rich user-item interaction information from the related source domain to improve the performance on the sparse target domain. Recent CDR approaches pay attention to aggregating the source domain information to generate better user representations for the target domain. However, they focus on designing more powerful interaction encoders to learn both domains simultaneously, but fail to model different user preferences of different domains. Particularly, domain-specific preferences of the source domain usually provide useless information to enhance the performance in the target domain, and directly aggregating the domain-shared and domain-specific information together maybe hurts target domain performance. This work considers a key challenge of CDR: How do we transfer shared information across domains? Grounded in the information theory, we propose DisenCDR, a novel model to disentangle the domain-shared and domain-specific information. To reach our goal, we propose two mutual-information-based disentanglement regularizers. Specifically, an exclusive regularizer aims to enforce the user domain-shared representations and domain-specific representations encoding exclusive information. An information regularizer is to encourage the user domain-shared representations encoding predictive information for both domains. Based on them, we further derive a tractable bound of our disentanglement objective to learn desirable disentangled representations. Extensive experiments show that DisenCDR achieves significant improvements over state-of-the-art baselines on four real-world datasets.|数据稀疏是推荐系统中一个长期存在的问题。为了解决这一问题，跨域推荐技术(CDR)引起了人们的极大兴趣，它利用来自相关源域的丰富的用户项交互信息来提高稀疏目标域的性能。最近的 CDR 方法注重聚合源域信息，以便为目标域生成更好的用户表示。然而，他们专注于设计更强大的交互编码器来同时学习这两个域，但未能建模不同域的不同用户偏好。特别地，源域的特定领域偏好通常提供无用的信息来提高目标域的性能，直接将共享的和特定领域的信息聚合在一起可能会损害目标域的性能。这项工作认为 CDR 的一个关键挑战是: 我们如何跨域传输共享信息？在信息论的基础上，提出了一种新的区分领域共享信息和特定领域信息的模型 DisenCDR。为了达到这个目标，我们提出了两个基于互信息的解纠缠正则化器。具体地说，独占正则化程序旨在强制用户域共享表示和编码独占信息的特定于域的表示。信息正则化器是鼓励用户域共享表示，对两个域的预测信息进行编码。在此基础上，我们进一步推导出我们的解纠缠目标的一个易处理的界，以学习理想的解纠缠表示。大量的实验表明，DisenCDR 在四个真实世界的数据集上比最先进的基线获得了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DisenCDR:+Learning+Disentangled+Representations+for+Cross-Domain+Recommendation)|5|
|[Personalized Fashion Compatibility Modeling via Metapath-guided Heterogeneous Graph Learning](https://doi.org/10.1145/3477495.3532038)|Weili Guan, Fangkai Jiao, Xuemeng Song, Haokun Wen, ChungHsing Yeh, Xiaojun Chang|University of Technology Sydney, Sydney, NSW, Australia; Monash University, Melbourne, VIC, Australia; Shandong University, Qingdao, China|Fashion Compatibility Modeling (FCM) is a new yet challenging task, which aims to automatically access the matching degree among a set of complementary items. Most of existing methods evaluate the fashion compatibility from the common perspective, but overlook the user's personal preference. Inspired by this, a few pioneers study the Personalized Fashion Compatibility Modeling (PFCM). Despite their significance, these PFCM methods mainly concentrate on the user and item entities, as well as their interactions, but ignore the attribute entities, which contain rich semantics. To address this problem, we propose to fully explore the related entities and their relations involved in PFCM to boost the PFCM performance. This is, however, non-trivial due to the heterogeneous contents of different entities, embeddings for new users, and various high-order relations. Towards these ends, we present a novel metapath-guided personalized fashion compatibility modeling, dubbed as MG-PFCM. In particular, we creatively build a heterogeneous graph to unify the three types of entities (i.e., users, items, and attributes) and their relations (i.e., user-item interactions, item-item matching relations, and item-attribute association relations). Thereafter, we design a multi-modal content-oriented user embedding module to learn user representations by inheriting the contents of their interacted items. Meanwhile, we define the user-oriented and item-oriented metapaths, and perform the metapath-guided heterogeneous graph learning to enhance the user and item embeddings. In addition, we introduce the contrastive regularization to improve the model performance. We conduct extensive experiments on the real-world benchmark dataset, which verifies the superiority of our proposed scheme over several cutting-edge baselines. As a byproduct, we have released our source codes to benefit other researchers.|时尚相容性建模(FCM)是一项新兴的具有挑战性的任务，其目标是自动获取一组互补项之间的匹配度。大多数现有的方法从一般的角度评估时尚兼容性，但是忽略了用户的个人偏好。受此启发，一些先驱者开始研究个性化时尚兼容性建模(PFCM)。尽管其重要性，这些 PFCM 方法主要集中在用户和项目实体，以及它们的交互，但是忽略了属性实体，其中包含丰富的语义。为了解决这一问题，我们建议充分探讨 PFCM 中涉及的相关实体及其关系，以提高 PFCM 的性能。然而，由于不同实体的内容异构、新用户的嵌入以及各种高阶关系，这是非常重要的。为此，我们提出了一种新的元路径引导的个性化时尚兼容性模型，称为 MG-PFCM。特别是，我们创造性地构建了一个异构图来统一三种类型的实体(即用户、项目和属性)及其关系(即用户-项目交互、项目-项目匹配关系和项目-属性关系)。然后，我们设计了一个面向多模态内容的用户嵌入模块，通过继承用户交互项的内容来学习用户表示。同时，定义了面向用户和面向项目的元路径，并通过元路径引导的异构图学习来增强用户和项目的嵌入。此外，为了提高模型的性能，我们引入了对比正则化方法。我们在现实世界的基准数据集上进行了广泛的实验，验证了我们提出的方案相对于几个前沿基线的优越性。作为一个副产品，我们已经发布了我们的源代码，以利于其他研究人员。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Fashion+Compatibility+Modeling+via+Metapath-guided+Heterogeneous+Graph+Learning)|5|
|[Explainable Fairness in Recommendation](https://doi.org/10.1145/3477495.3531973)|Yingqiang Ge, Juntao Tan, Yan Zhu, Yinglong Xia, Jiebo Luo, Shuchang Liu, Zuohui Fu, Shijie Geng, Zelong Li, Yongfeng Zhang|Rutgers University, New Brunswick, NJ, USA; University of Rochester, Rochester, NY, USA; Meta Platforms, Inc., palo alto, CA, USA|Existing research on fairness-aware recommendation has mainly focused on the quantification of fairness and the development of fair recommendation models, neither of which studies a more substantial problem--identifying the underlying reason of model disparity in recommendation. This information is critical for recommender system designers to understand the intrinsic recommendation mechanism and provides insights on how to improve model fairness to decision makers. Fortunately, with the rapid development of Explainable AI, we can use model explainability to gain insights into model (un)fairness. In this paper, we study the problem ofexplainable fairness, which helps to gain insights about why a system is fair or unfair, and guides the design of fair recommender systems with a more informed and unified methodology. Particularly, we focus on a common setting with feature-aware recommendation and exposure unfairness, but the proposed explainable fairness framework is general and can be applied to other recommendation settings and fairness definitions. We propose a Counterfactual Explainable Fairness framework, called CEF, which generates explanations about model fairness that can improve the fairness without significantly hurting the performance. The CEF framework formulates an optimization problem to learn the "minimal'' change of the input features that changes the recommendation results to a certain level of fairness. Based on the counterfactual recommendation result of each feature, we calculate an explainability score in terms of the fairness-utility trade-off to rank all the feature-based explanations, and select the top ones as fairness explanations. Experimental results on several real-world datasets validate that our method is able to effectively provide explanations to the model disparities and these explanations can achieve better fairness-utility trade-off when using them for recommendation than all the baselines.|现有关于公平意识推荐的研究主要集中在公平性的量化和公平推荐模型的发展两个方面，这两个方面都没有研究更实质性的问题——确定推荐模型差异的根本原因。这些信息对于推荐系统设计者理解内在的推荐机制至关重要，并为如何提高模型对决策者的公平性提供了见解。幸运的是，随着可解释人工智能的快速发展，我们可以利用模型可解释性来深入了解模型(非)公平性。本文通过对解释公平问题的研究，有助于深入了解一个系统为什么是公平或不公平的，并以一种更为知情和统一的方法论指导公平推荐系统的设计。特别地，我们关注的是一个具有特征感知推荐和暴露不公平性的公共设置，但是提出的可解释公平性框架是通用的，可以应用于其他推荐设置和公平性定义。我们提出了一个反事实可解释的公平性框架，称为 CEF，它生成了对模型公平性的解释，可以在不严重损害绩效的情况下提高公平性。基金框架制定了一个最佳化问题，让学生了解输入功能的「最小」改变，会令推荐结果有一定程度的公平性。基于每个特征的反事实推荐结果，以公平-效用权衡的方式计算可解释性得分，对所有基于特征的解释进行排序，并选择最高的解释作为公平解释。在实际数据集上的实验结果验证了该方法能够有效地解释模型间的差异，并且这些解释在使用它们进行推荐时能够比所有基线更好地实现公平-效用的权衡。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Fairness+in+Recommendation)|5|
|[Measuring Fairness in Ranked Results: An Analytical and Empirical Comparison](https://doi.org/10.1145/3477495.3532018)|Amifa Raj, Michael D. Ekstrand|Boise State University, Boise, ID, USA|Information access systems, such as search and recommender systems, often use ranked lists to present results believed to be relevant to the user's information need. Evaluating these lists for their fairness along with other traditional metrics provides a more complete understanding of an information access system's behavior beyond accuracy or utility constructs. To measure the (un)fairness of rankings, particularly with respect to the protected group(s) of producers or providers, several metrics have been proposed in the last several years. However, an empirical and comparative analyses of these metrics showing the applicability to specific scenario or real data, conceptual similarities, and differences is still lacking. We aim to bridge the gap between theoretical and practical ap-plication of these metrics. In this paper we describe several fair ranking metrics from the existing literature in a common notation, enabling direct comparison of their approaches and assumptions, and empirically compare them on the same experimental setup and data sets in the context of three information access tasks. We also provide a sensitivity analysis to assess the impact of the design choices and parameter settings that go in to these metrics and point to additional work needed to improve fairness measurement.|信息访问系统，例如搜索和推荐系统，经常使用排名列表来显示被认为与用户信息需求相关的结果。评估这些列表的公平性以及其他传统指标，可以更全面地了解信息访问系统的行为，而不仅仅是准确性或效用结构。为了衡量排名的(不)公平性，特别是对于受保护的生产者或提供者群体，在过去几年中已经提出了几个指标。然而，对这些指标的实证和比较分析表明适用于具体情景或实际数据，概念上的相似性和差异仍然缺乏。我们的目标是弥合这些指标的理论和实际应用之间的差距。在本文中，我们描述了几个公平排序度量从现有的文献在一个共同的符号，使直接比较他们的方法和假设，并经验比较他们在相同的实验设置和数据集在三个信息访问任务的背景下。我们还提供了一个敏感度分析来评估设计选择和参数设置对这些指标的影响，并指出改善公平性度量所需的额外工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Fairness+in+Ranked+Results:+An+Analytical+and+Empirical+Comparison)|5|
|[Webformer: Pre-training with Web Pages for Information Retrieval](https://doi.org/10.1145/3477495.3532086)|Yu Guo, Zhengyi Ma, Jiaxin Mao, Hongjin Qian, Xinyu Zhang, Hao Jiang, Zhao Cao, Zhicheng Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Webformer:+Pre-training+with+Web+Pages+for+Information+Retrieval)|5|
|[BARS: Towards Open Benchmarking for Recommender Systems](https://doi.org/10.1145/3477495.3531723)|Jieming Zhu, Quanyu Dai, Liangcai Su, Rong Ma, Jinyang Liu, Guohao Cai, Xi Xiao, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BARS:+Towards+Open+Benchmarking+for+Recommender+Systems)|5|
|[V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation](https://doi.org/10.1145/3477495.3532076)|Xuemeng Song, Liqiang Jing, Dengtian Lin, Zhongzhou Zhao, Haiqing Chen, Liqiang Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=V2P:+Vision-to-Prompt+based+Multi-Modal+Product+Summary+Generation)|5|
|[A Weakly Supervised Propagation Model for Rumor Verification and Stance Detection with Multiple Instance Learning](https://doi.org/10.1145/3477495.3531930)|Ruichao Yang, Jing Ma, Hongzhan Lin, Wei Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Weakly+Supervised+Propagation+Model+for+Rumor+Verification+and+Stance+Detection+with+Multiple+Instance+Learning)|5|
|[Positive, Negative and Neutral: Modeling Implicit Feedback in Session-based News Recommendation](https://doi.org/10.1145/3477495.3532040)|Shansan Gong, Kenny Q. Zhu|Shanghai Jiao Tong University, Shanghai, China|News recommendation for anonymous readers is a useful but challenging task for many news portals, where interactions between readers and articles are limited within a temporary login session. Previous works tend to formulate session-based recommendation as a next item prediction task, while they neglect the implicit feedback from user behaviors, which indicates what users really like or dislike. Hence, we propose a comprehensive framework to model user behaviors through positive feedback (i.e., the articles they spend more time on) and negative feedback (i.e., the articles they choose to skip without clicking in). Moreover, the framework implicitly models the user using their session start time, and the article using its initial publishing time, in what we call neutral feedback. Empirical evaluation on three real-world news datasets shows the framework's promising performance of more accurate, diverse and even unexpectedness recommendations than other state-of-the-art session-based recommendation approaches.|对于许多新闻门户网站来说，为匿名读者推荐新闻是一项有用但具有挑战性的任务，因为在临时登录会话中，读者和文章之间的交互受到限制。以往的研究倾向于将基于会话的推荐作为下一个项目的预测任务，而忽略了来自用户行为的隐性反馈，这表明用户真正喜欢或不喜欢什么。因此，我们提出了一个全面的框架，通过积极反馈(即，他们花费更多时间的文章)和消极反馈(即，他们选择不点击跳过的文章)来模拟用户行为。此外，框架使用用户的会话开始时间隐式地对用户进行建模，并使用文章的初始发布时间隐式地对文章进行建模，我们称之为中性反馈。对三个真实世界新闻数据集的实证评估表明，与其他基于会话的最新推荐方法相比，该框架具有更准确、更多样、甚至更出人意料的推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Positive,+Negative+and+Neutral:+Modeling+Implicit+Feedback+in+Session-based+News+Recommendation)|4|
|[Multi-Behavior Sequential Transformer Recommender](https://doi.org/10.1145/3477495.3532023)|Enming Yuan, Wei Guo, Zhicheng He, Huifeng Guo, Chengkai Liu, Ruiming Tang|Noah's Ark Lab, Huawei, Shenzhen, China; Tsinghua University, Beijing, China; Shanghai Jiao Tong University, Shanghai, China|In most real-world recommender systems, users interact with items in a sequential and multi-behavioral manner. Exploring the fine-grained relationship of items behind the users' multi-behavior interactions is critical in improving the performance of recommender systems. Despite the great successes, existing methods seem to have limitations on modelling heterogeneous item-level multi-behavior dependencies, capturing diverse multi-behavior sequential dynamics, or alleviating data sparsity problems. In this paper, we show it is possible to derive a framework to address all the above three limitations. The proposed framework MB-STR, a Multi-Behavior Sequential Transformer Recommender, is equipped with the multi-behavior transformer layer (MB-Trans), the multi-behavior sequential pattern generator (MB-SPG) and the behavior-aware prediction module (BA-Pred). Compared with a typical transformer, we design MB-Trans to capture multi-behavior heterogeneous dependencies as well as behavior-specific semantics, propose MB-SPG to encode the diverse sequential patterns among multiple behaviors, and incorporate BA-Pred to better leverage multi-behavior supervision. Comprehensive experiments on three real-world datasets show the effectiveness of MB-STR by significantly boosting the recommendation performance compared with various competitive baselines. Further ablation studies demonstrate the superiority of different modules of MB-STR.|在大多数现实世界的推荐系统中，用户以一种顺序和多行为的方式与项目交互。探索用户多行为交互背后的细粒度关系对于提高推荐系统的性能至关重要。尽管取得了巨大的成功，但现有的方法似乎在建模异构项目级多行为依赖、捕获多种多行为顺序动态或缓解数据稀疏问题方面存在局限性。在本文中，我们展示了推导一个框架来解决上述三个限制是可能的。提出的多行为顺序变压器推荐系统框架 MB-STR 具有多行为顺序变压器层(MB-Trans)、多行为顺序模式发生器(MB-SPG)和行为感知预测模块(BA-Pred)。与典型的变压器相比，我们设计 MB-Trans 来捕获多行为异构依赖和行为特定的语义，提出 MB-SPG 来编码多行为之间的不同序列模式，并结合 BA-Pred 来更好地利用多行为监督。在三个实际数据集上的综合实验表明，与不同的竞争基线相比，MB-STR 能够显著提高推荐性能。进一步的消融研究证明了 MB-STR 不同模块的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavior+Sequential+Transformer+Recommender)|4|
|[News Recommendation with Candidate-aware User Modeling](https://doi.org/10.1145/3477495.3531778)|Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang|Microsoft Research Asia, Beijing, China; Tsinghua University, Beijing, China|News recommendation aims to match news with personalized user interest. Existing methods for news recommendation usually model user interest from historical clicked news without the consideration of candidate news. However, each user usually has multiple interests, and it is difficult for these methods to accurately match a candidate news with a specific user interest. In this paper, we present a candidate-aware user modeling method for personalized news recommendation, which can incorporate candidate news into user modeling for better matching between candidate news and user interest. We propose a candidate-aware self-attention network that uses candidate news as clue to model candidate-aware global user interest. In addition, we propose a candidate-aware CNN network to incorporate candidate news into local behavior context modeling and learn candidate-aware short-term user interest. Besides, we use a candidate-aware attention network to aggregate previously clicked news weighted by their relevance with candidate news to build candidate-aware user representation. Experiments on real-world datasets show the effectiveness of our method in improving news recommendation performance.|新闻推荐旨在使新闻与个性化的用户兴趣相匹配。现有的新闻推荐方法通常根据历史点击新闻建立用户兴趣模型，而不考虑候选新闻。然而，每个用户通常有多个兴趣，这些方法很难准确地匹配一个候选新闻和一个特定的用户兴趣。提出了一种基于候选者感知的个性化新闻推荐用户建模方法，该方法将候选新闻融入到用户建模中，以更好地匹配候选新闻和用户兴趣。我们提出了一个以候选新闻为线索的候选感知自我注意网络，该网络对全球候选感知用户兴趣进行建模。此外，我们提出了一个候选人感知的 CNN 网络，将候选人新闻纳入本地行为上下文建模，并学习候选人感知的短期用户兴趣。此外，我们利用一个候选人感知的注意网络来聚合先前点击过的新闻，并根据它们与候选人新闻的相关性来加权，从而建立一个候选人感知的用户表示。在实际数据集上的实验结果表明了该方法在提高新闻推荐性能方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=News+Recommendation+with+Candidate-aware+User+Modeling)|4|
|[Price DOES Matter!: Modeling Price and Interest Preferences in Session-based Recommendation](https://doi.org/10.1145/3477495.3532043)|Xiaokun Zhang, Bo Xu, Liang Yang, Chenliang Li, Fenglong Ma, Haifeng Liu, Hongfei Lin|Wuhan University, Wuhan, China; Dalian University of Technology, Dalian, China; Pennsylvania State University, Pennsylvania, PA, USA|Session-based recommendation aims to predict items that an anonymous user would like to purchase based on her short behavior sequence. The current approaches towards session-based recommendation only focus on modeling users' interest preferences, while they all ignore a key attribute of an item, i.e., the price. Many marketing studies have shown that the price factor significantly influences users' behaviors and the purchase decisions of users are determined by both price and interest preferences simultaneously. However, it is nontrivial to incorporate price preferences for session-based recommendation. Firstly, it is hard to handle heterogeneous information from various features of items to capture users' price preferences. Secondly, it is difficult to model the complex relations between price and interest preferences in determining user choices. To address the above challenges, we propose a novel method Co-guided Heterogeneous Hypergraph Network (CoHHN) for session-based recommendation. Towards the first challenge, we devise a heterogeneous hypergraph to represent heterogeneous information and rich relations among them. A dual-channel aggregating mechanism is then designed to aggregate various information in the heterogeneous hypergraph. After that, we extract users' price preferences and interest preferences via attention layers. As to the second challenge, a co-guided learning scheme is designed to model the relations between price and interest preferences and enhance the learning of each other. Finally, we predict user actions based on item features and users' price and interest preferences. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed CoHHN. Further analysis reveals the significance of price for session-based recommendation.|基于会话的推荐旨在根据匿名用户的短行为序列预测其想要购买的商品。当前基于会话的推荐方法只关注于建模用户的兴趣偏好，而他们都忽略了一个项目的关键属性，即价格。许多市场研究表明，价格因素对用户行为有显著影响，用户的购买决策同时由价格和利益偏好决定。然而，为基于会话的推荐引入价格偏好并非易事。首先，很难处理来自商品不同特征的异构信息来捕捉用户的价格偏好;。其次，在决定用户选择时，很难建立价格和利益偏好之间的复杂关系模型。针对上述挑战，我们提出了一种基于会话的协同引导异构超图网络(CoHHN)的推荐方法。针对第一个挑战，我们设计了一个异构超图来表示异构信息和它们之间的丰富关系。然后设计了一种双通道聚集机制来聚集异构超图中的各种信息。然后，通过注意层提取用户的价格偏好和兴趣偏好。针对第二个挑战，设计了一个共同导向学习方案，以建立价格和兴趣偏好之间的关系模型，并加强相互之间的学习。最后，根据商品特征以及用户的价格和兴趣偏好对用户行为进行预测。在三个真实世界数据集上的大量实验证明了所提出的 CoHHN 算法的有效性。进一步的分析揭示了基于会话的推荐价格的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Price+DOES+Matter!:+Modeling+Price+and+Interest+Preferences+in+Session-based+Recommendation)|4|
|[CORE: Simple and Effective Session-based Recommendation within Consistent Representation Space](https://doi.org/10.1145/3477495.3531955)|Yupeng Hou, Binbin Hu, Zhiqiang Zhang, Wayne Xin Zhao|Renmin University of China & Beijing Academy of Artificial Intelligence, Beijing, China; Ant Group, Hangzhou, China; Renmin University of China, Beijing, China|Session-based Recommendation (SBR) refers to the task of predicting the next item based on short-term user behaviors within an anonymous session. However, session embedding learned by a non-linear encoder is usually not in the same representation space as item embeddings, resulting in the inconsistent prediction issue while recommending items. To address this issue, we propose a simple and effective framework named CORE, which can unify the representation space for both the encoding and decoding processes. Firstly, we design a representation-consistent encoder that takes the linear combination of input item embeddings as session embedding, guaranteeing that sessions and items are in the same representation space. Besides, we propose a robust distance measuring method to prevent overfitting of embeddings in the consistent representation space. Extensive experiments conducted on five public real-world datasets demonstrate the effectiveness and efficiency of the proposed method. The code is available at: https://github.com/RUCAIBox/CORE.|基于会话的推荐(Session-based 汪汪)是指基于匿名会话中的短期用户行为来预测下一个项目的任务。然而，非线性编码器学习的会话嵌入通常与项目嵌入不在同一表示空间，在推荐项目时会产生不一致的预测问题。为了解决这个问题，我们提出了一个简单有效的框架 CORE，它可以统一编码和解码过程的表示空间。首先，我们设计了一个表示一致的编码器，将输入项嵌入的线性组合作为会话嵌入，保证会话和项处于相同的表示空间。此外，我们提出了一种鲁棒的距离测量方法，以防止过拟合嵌入在一致的表示空间。在五个公共实际数据集上进行的大量实验表明了该方法的有效性和高效性。密码可于以下 https://github.com/rucaibox/core 索取:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CORE:+Simple+and+Effective+Session-based+Recommendation+within+Consistent+Representation+Space)|4|
|[Unlearning Protected User Attributes in Recommendations with Adversarial Training](https://doi.org/10.1145/3477495.3531820)|Christian Ganhör, David Penz, Navid Rekabsaz, Oleg Lesota, Markus Schedl|Johannes Kepler University Linz & Linz Institute of Technology, Linz, Austria; Johannes Kepler University Linz & TU Wien, Linz and Vienna, Austria; Johannes Kepler University Linz, Linz, Austria|Collaborative filtering algorithms capture underlying consumption patterns, including the ones specific to particular demographics or protected information of users, e.g., gender, race, and location. These encoded biases can influence the decision of a recommendation system (RS) towards further separation of the contents provided to various demographic subgroups, and raise privacy concerns regarding the disclosure of users' protected attributes. In this work, we investigate the possibility and challenges of removing specific protected information of users from the learned interaction representations of a RS algorithm, while maintaining its effectiveness. Specifically, we incorporate adversarial training into the state-of-the-art MultVAE architecture, resulting in a novel model, Adversarial Variational Auto-Encoder with Multinomial Likelihood (Adv-MultVAE), which aims at removing the implicit information of protected attributes while preserving recommendation performance. We conduct experiments on the MovieLens-1M and LFM-2b-DemoBias datasets, and evaluate the effectiveness of the bias mitigation method based on the inability of external attackers in revealing the users' gender information from the model. Comparing with baseline MultVAE, the results show that Adv-MultVAE, with marginal deterioration in performance (w.r.t. NDCG and recall), largely mitigates inherent biases in the model on both datasets.|协同过滤算法捕捉潜在的消费模式，包括特定人群或受保护的用户信息，如性别、种族和地点。这些编码偏差可以影响推荐系统(RS)对进一步分离提供给不同人口亚群的内容的决策，并引起关于用户受保护属性披露的隐私问题。在这项工作中，我们研究的可能性和挑战，删除具体的保护信息的用户从学习交互表示的 RS 算法，同时保持其有效性。具体而言，我们将对抗性训练纳入最先进的 MultVAE 体系结构，产生了一种新的模型，具有多项式似然的对抗性变分自动编码器(Adv-MultVAE) ，其目的是消除受保护属性的隐含信息，同时保持推荐性能。我们在 MovieLens-1M 和 LFM-2b-DemoBias 数据集上进行了实验，评估了基于外部攻击者无法从模型中揭示用户性别信息的偏差缓解方法的有效性。与基线 MultVAE 相比，结果显示 Adv-MultVAE 的性能边际恶化(w.r.t.NDCG 和召回)在很大程度上减轻了两个数据集上模型的固有偏差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlearning+Protected+User+Attributes+in+Recommendations+with+Adversarial+Training)|4|
|[Deep Multi-Representational Item Network for CTR Prediction](https://doi.org/10.1145/3477495.3531845)|Jihai Zhang, Fangquan Lin, Cheng Yang, Wei Wang|Alibaba Group, Hangzhou, China|Click-through rate (CTR) prediction is essential in the modelling of a recommender system. Previous studies mainly focus on user behavior modelling, while few of them consider candidate item representations. This makes the models strongly dependent on user representations, and less effective when user behavior is sparse. Furthermore, most existing works regard the candidate item as one fixed embedding and ignore the multi-representational characteristics of the item. To handle the above issues, we propose a Deep multi-Representational Item NetworK (DRINK) for CTR prediction. Specifically, to tackle the sparse user behavior problem, we construct a sequence of interacting users and timestamps to represent the candidate item; to dynamically capture the characteristics of the item, we propose a transformer-based multi-representational item network consisting of a multi-CLS representation submodule and contextualized global item representation submodule. In addition, we propose to decouple the time information and item behavior to avoid information overwhelming. Outputs of the above components are concatenated and fed into a MLP layer to fit the CTR. We conduct extensive experiments on real-world datasets of Amazon and the results demonstrate the effectiveness of the proposed model.|点进率(CTR)预测是建立推荐系统模型的关键。以往的研究主要集中在用户行为建模，而很少考虑候选项表示。这使得模型强烈地依赖于用户表示，并且在用户行为稀疏时效率较低。此外，现有的大多数作品都将候选项作为一个固定的嵌入，而忽略了项目的多重表征特征。针对上述问题，本文提出了一种基于深度多表征项目网络(DRINK)的点击率预测方法。为了解决稀疏用户行为问题，我们构造了一个交互用户序列和时间戳来表示候选项目; 为了动态捕获候选项目的特征，我们提出了一个基于变换器的多表示项目网络，该网络由一个多 CLS 表示子模块和上下文化的全局项目表示子模块组成。此外，我们建议解耦的时间信息和项目行为，以避免信息铺天盖地。上述组件的输出被连接并输入 MLP 层以适应 CTR。我们在亚马逊的实际数据集上进行了广泛的实验，实验结果证明了该模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Multi-Representational+Item+Network+for+CTR+Prediction)|4|
|[GETNext: Trajectory Flow Map Enhanced Transformer for Next POI Recommendation](https://doi.org/10.1145/3477495.3531983)|Song Yang, Jiamou Liu, Kaiqi Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GETNext:+Trajectory+Flow+Map+Enhanced+Transformer+for+Next+POI+Recommendation)|4|
|[ReCANet: A Repeat Consumption-Aware Neural Network for Next Basket Recommendation in Grocery Shopping](https://doi.org/10.1145/3477495.3531708)|Mozhdeh Ariannezhad, Sami Jullien, Ming Li, Min Fang, Sebastian Schelter, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReCANet:+A+Repeat+Consumption-Aware+Neural+Network+for+Next+Basket+Recommendation+in+Grocery+Shopping)|4|
|[A Review-aware Graph Contrastive Learning Framework for Recommendation](https://doi.org/10.1145/3477495.3531927)|Jie Shuai, Kun Zhang, Le Wu, Peijie Sun, Richang Hong, Meng Wang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Review-aware+Graph+Contrastive+Learning+Framework+for+Recommendation)|4|
|[H-ERNIE: A Multi-Granularity Pre-Trained Language Model for Web Search](https://doi.org/10.1145/3477495.3531986)|Xiaokai Chu, Jiashu Zhao, Lixin Zou, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=H-ERNIE:+A+Multi-Granularity+Pre-Trained+Language+Model+for+Web+Search)|4|
|[GERE: Generative Evidence Retrieval for Fact Verification](https://doi.org/10.1145/3477495.3531827)|Jiangui Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GERE:+Generative+Evidence+Retrieval+for+Fact+Verification)|4|
|[Towards Feature Selection for Ranking and Classification Exploiting Quantum Annealers](https://doi.org/10.1145/3477495.3531755)|Maurizio Ferrari Dacrema, Fabio Moroni, Riccardo Nembrini, Nicola Ferro, Guglielmo Faggioli, Paolo Cremonesi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Feature+Selection+for+Ranking+and+Classification+Exploiting+Quantum+Annealers)|4|
|[Continual Learning Dialogue Systems - Learning during Conversation](https://doi.org/10.1145/3477495.3532677)|Sahisnu Mazumder, Bing Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Learning+Dialogue+Systems+-+Learning+during+Conversation)|4|
|[Conversational Information Seeking: Theory and Application](https://doi.org/10.1145/3477495.3532678)|Jeffrey Dalton, Sophie Fischer, Paul Owoicho, Filip Radlinski, Federico Rossetto, Johanne R. Trippas, Hamed Zamani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Information+Seeking:+Theory+and+Application)|4|
|[MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset](https://doi.org/10.1145/3477495.3531744)|Dan Saattrup Nielsen, Ryan McConville||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MuMiN:+A+Large-Scale+Multilingual+Multimodal+Fact-Checked+Misinformation+Social+Network+Dataset)|4|
|[A Non-Factoid Question-Answering Taxonomy](https://doi.org/10.1145/3477495.3531926)|Valeria Bolotova, Vladislav Blinov, Falk Scholer, W. Bruce Croft, Mark Sanderson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Non-Factoid+Question-Answering+Taxonomy)|4|
|[A Multitask Framework for Sentiment, Emotion and Sarcasm aware Cyberbullying Detection from Multi-modal Code-Mixed Memes](https://doi.org/10.1145/3477495.3531925)|Krishanu Maity, Prince Jha, Sriparna Saha, Pushpak Bhattacharyya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multitask+Framework+for+Sentiment,+Emotion+and+Sarcasm+aware+Cyberbullying+Detection+from+Multi-modal+Code-Mixed+Memes)|4|
|[MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale Recommendation Scenarios](https://doi.org/10.1145/3477495.3531733)|Xiaofeng Pan, Ming Li, Jing Zhang, Keren Yu, Hong Wen, Luping Wang, Chengjun Mao, Bo Cao|Alibaba Group, Hangzhou, China; The University of Sydney, Sydney, NSW, China|Different from large-scale platforms such as Taobao and Amazon, CVR modeling in small-scale recommendation scenarios is more challenging due to the severe Data Distribution Fluctuation (DDF) issue. DDF prevents existing CVR models from being effective since 1) several months of data are needed to train CVR models sufficiently in small scenarios, leading to considerable distribution discrepancy between training and online serving; and 2) e-commerce promotions have significant impacts on small scenarios, leading to distribution uncertainty of the upcoming time period. In this work, we propose a novel CVR method named MetaCVR from a perspective of meta learning to address the DDF issue. Firstly, a base CVR model which consists of a Feature Representation Network (FRN) and output layers is designed and trained sufficiently with samples across months. Then we treat time periods with different data distributions as different occasions and obtain positive and negative prototypes for each occasion using the corresponding samples and the pre-trained FRN. Subsequently, a Distance Metric Network (DMN) is devised to calculate the distance metrics between each sample and all prototypes to facilitate mitigating the distribution uncertainty. At last, we develop an Ensemble Prediction Network (EPN) which incorporates the output of FRN and DMN to make the final CVR prediction. In this stage, we freeze the FRN and train the DMN and EPN with samples from recent time period, therefore effectively easing the distribution discrepancy. To the best of our knowledge, this is the first study of CVR prediction targeting the DDF issue in small-scale recommendation scenarios. Experimental results on real-world datasets validate the superiority of our MetaCVR and online A/B test also shows our model achieves impressive gains of 11.92% on PCVR and 8.64% on GMV.|与淘宝和亚马逊等大型平台不同，由于数据分布波动(DDF)问题严重，小规模推荐场景下的 CVR 建模更具挑战性。DDF 阻止了现有的 CVR 模型的有效性，因为1)需要几个月的数据来充分训练 CVR 模型在小场景中，导致训练和在线服务之间的相当大的分布差异; 2)电子商务促销对小场景有重大影响，导致即将到来的时间段的分布不确定性。本文从元学习的角度出发，提出了一种新的 CVR 方法 MetaCVR 来解决 DDF 问题。首先，设计了一个由特征表示网络(FRN)和输出层组成的基本 CVR 模型，并对该模型进行了数月的样本训练。然后将不同时间段的数据分布视为不同的场合，利用相应的样本和预先训练好的 FRN，得到每个场合的正负原型。随后，设计了一个距离度量网络(DMN)来计算每个样本和所有原型之间的距离度量，以减少分布的不确定性。最后，我们开发了一个集成预测网络(EPN) ，将 FRN 和 DMN 的输出结合起来进行 CVR 的最终预测。在这一阶段，我们冻结 FRN，并用最近时间段的样本训练 DMN 和 EPN，从而有效地缓解了分布差异。据我们所知，这是第一个针对小规模推荐场景中 DDF 问题的 CVR 预测研究。在实际数据集上的实验结果验证了我们的 MetaCVR 模型的优越性，在线 A/B 测试也表明我们的模型在 PCVR 和 GMV 上分别取得了令人印象深刻的11.92% 和8.64% 的增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaCVR:+Conversion+Rate+Prediction+via+Meta+Learning+in+Small-Scale+Recommendation+Scenarios)|3|
|[Can Clicks Be Both Labels and Features?: Unbiased Behavior Feature Collection and Uncertainty-aware Learning to Rank](https://doi.org/10.1145/3477495.3531948)|Tao Yang, Chen Luo, Hanqing Lu, Parth Gupta, Bing Yin, Qingyao Ai|University of Utah, Salt Lake City, UT, USA; Amazon Search, Palo Alto, CA, USA|Using implicit feedback collected from user clicks as training labels for learning-to-rank algorithms is a well-developed paradigm that has been extensively studied and used in modern IR systems. Using user clicks as ranking features, on the other hand, has not been fully explored in existing literature. Despite its potential in improving short-term system performance, whether the incorporation of user clicks as ranking features is beneficial for learning-to-rank systems in the long term is still questionable. Two of the most important problems are (1) the explicit bias introduced by noisy user behavior, and (2) the implicit bias, which we refer to as the exploitation bias, introduced by the dynamic training and serving of learning-to-rank systems with behavior features. In this paper, we explore the possibility of incorporating user clicks as both training labels and ranking features for learning to rank. We formally investigate the problems in feature collection and model training, and propose a counterfactual feature projection function and a novel uncertainty-aware learning to rank framework. Experiments on public datasets show that ranking models learned with the proposed framework can significantly outperform models built with raw click features and algorithms that rank items without considering model uncertainty.|使用从用户点击收集的隐式反馈作为学习到排序算法的训练标签是一个发展良好的范例，已经在现代 IR 系统中得到了广泛的研究和应用。使用用户点击作为排名功能，另一方面，还没有充分探讨现有的文献。尽管它在提高短期系统性能方面具有潜力，但是从长远来看，将用户点击作为排名功能的结合是否有利于学习排名系统仍然值得怀疑。其中最重要的两个问题是: (1)噪声用户行为引入的显性偏差和(2)具有行为特征的学习排序系统的动态训练和服务引入的隐性偏差，我们称之为剥削偏差。在这篇文章中，我们探讨了将用户点击作为训练标签和排名特征来学习排名的可能性。我们正式研究了特征收集和模型训练中的问题，提出了一种反事实特征投影函数和一种新的不确定性学习排序框架。对公共数据集的实验表明，使用所提出的框架学习的排序模型可以显著优于使用原始点击特征和算法建立的模型，这些模型不考虑模型的不确定性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Clicks+Be+Both+Labels+and+Features?:+Unbiased+Behavior+Feature+Collection+and+Uncertainty-aware+Learning+to+Rank)|3|
|[User-Centric Conversational Recommendation with Multi-Aspect User Modeling](https://doi.org/10.1145/3477495.3532074)|Shuokai Li, Ruobing Xie, Yongchun Zhu, Xiang Ao, Fuzhen Zhuang, Qing He|Institute of Artificial Intelligence, Beihang University, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; WeChat Search Application Department, Tencent, Beijing, China|Conversational recommender systems (CRS) aim to provide highquality recommendations in conversations. However, most conventional CRS models mainly focus on the dialogue understanding of the current session, ignoring other rich multi-aspect information of the central subjects (i.e., users) in recommendation. In this work, we highlight that the user's historical dialogue sessions and look-alike users are essential sources of user preferences besides the current dialogue session in CRS. To systematically model the multi-aspect information, we propose a User-Centric Conversational Recommendation (UCCR) model, which returns to the essence of user preference learning in CRS tasks. Specifically, we propose a historical session learner to capture users' multi-view preferences from knowledge, semantic, and consuming views as supplements to the current preference signals. A multi-view preference mapper is conducted to learn the intrinsic correlations among different views in current and historical sessions via self-supervised objectives. We also design a temporal look-alike user selector to understand users via their similar users. The learned multi-aspect multi-view user preferences are then used for the recommendation and dialogue generation. In experiments, we conduct comprehensive evaluations on both Chinese and English CRS datasets. The significant improvements over competitive models in both recommendation and dialogue generation verify the superiority of UCCR.|会话推荐系统(CRS)旨在提供高质量的会话推荐。然而，大多数传统的 CRS 模型主要侧重于对当前会话的对话理解，而忽略了推荐中心主体(即用户)的其他丰富的多方面信息。在这项工作中，我们强调用户的历史对话会话和外观相似的用户是用户偏好的重要来源，除了当前的对话会话在 CRS。为了系统地建立多方面信息的模型，本文提出了一种以用户为中心的会话推荐(UCCR)模型，该模型回归了 CRS 任务中用户偏好学习的本质。具体来说，我们提出了一个历史会话学习者来捕捉用户的多视图偏好，从知识，语义和消费观点作为补充的当前偏好信号。通过自监督目标，提出了一种多视点偏好映射算法，用于研究当前会议和历史会议中不同视点之间的内在相关性。我们还设计了一个时间外观相似的用户选择器，通过相似的用户来理解用户。然后利用所学习的多方面多视图用户偏好进行推荐和对话生成。在实验中，我们对中英文 CRS 数据集进行了综合评价。在推荐和对话生成方面对竞争模式的重大改进证明了 UCCR 的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-Centric+Conversational+Recommendation+with+Multi-Aspect+User+Modeling)|3|
|[When Multi-Level Meets Multi-Interest: A Multi-Grained Neural Model for Sequential Recommendation](https://doi.org/10.1145/3477495.3532081)|Yu Tian, Jianxin Chang, Yanan Niu, Yang Song, Chenliang Li|Wuhan University, Wuhan, China; Kuaishou.com, Beijing, China|Sequential recommendation aims at identifying the next item that is preferred by a user based on their behavioral history. Compared to conventional sequential models that leverage attention mechanisms and RNNs, recent efforts mainly follow two directions for improvement: multi-interest learning and graph convolutional aggregation. Specifically, multi-interest methods such as ComiRec and MIMN, focus on extracting different interests for a user by performing historical item clustering, while graph convolution methods including TGSRec and SURGE elect to refine user preferences based on multilevel correlations between historical items. Unfortunately, neither of them realizes that these two types of solutions can mutually complement each other, by aggregating multi-level user preference to achieve more precise multi-interest extraction for a better recommendation. To this end, in this paper, we propose a unified multi-grained neural model (named MGNM) via a combination of multi-interest learning and graph convolutional aggregation. Concretely, MGNM first learns the graph structure and information aggregation paths of the historical items for a user. It then performs graph convolution to derive item representations in an iterative fashion, in which the complex preferences at different levels can be well captured. Afterwards, a novel sequential capsule network is proposed to inject the sequential patterns into the multi-interest extraction process, leading to a more precise interest learning in a multi-grained manner. Experiments on three real-world datasets from different scenarios demonstrate the superiority of MGNM against several state-of-the-art baselines. The performance gain over the best baseline is up to 27.10% and 25.17% in terms of [email protected] and [email protected] respectively, which is one of the largest gains in recent development of sequential recommendation. Further analysis also demonstrates that MGNM is robust and effective at user preference understanding at multi-grained levels.|顺序推荐的目的是根据用户的行为历史来确定他们喜欢的下一个项目。与利用注意机制和 RNN 的传统序列模型相比，最近的努力主要遵循两个改进方向: 多兴趣学习和图卷积聚合。具体来说，ComiRec 和 MIMN 等多兴趣方法侧重于通过对历史项目进行聚类来为用户提取不同的兴趣，而 TGSRec 和 SurGE 等图形卷积方法则选择基于历史项目之间的多级相关性来改进用户偏好。不幸的是，他们都没有意识到这两种解决方案可以相互补充，通过聚合多级用户偏好来实现更精确的多兴趣提取以获得更好的推荐。为此，本文将多兴趣学习和图卷积聚合相结合，提出了一种统一的多粒度神经网络模型(MGNM)。具体来说，MGNM 首先为用户学习历史项的图形结构和信息聚合路径。然后，它执行图形卷积，以迭代的方式派生项表示，在这种方式中，可以很好地捕获不同级别的复杂首选项。然后，提出了一种新的序列胶囊网络，将序列模式引入到多兴趣提取过程中，从而实现多粒度的兴趣学习。通过对来自不同场景的三个真实世界数据集的实验，证明了 MGNM 算法对几个最新基线的优越性。就[ email protected ]和[ email protected ]而言，超过最佳基线的性能提升分别高达27.10% 和25.17% ，这是最近顺序推荐发展中最大的提升之一。进一步的分析还表明，MGNM 在多粒度级别上对用户偏好的理解是健壮的和有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Multi-Level+Meets+Multi-Interest:+A+Multi-Grained+Neural+Model+for+Sequential+Recommendation)|3|
|[AutoGSR: Neural Architecture Search for Graph-based Session Recommendation](https://doi.org/10.1145/3477495.3531940)|Jingfan Chen, Guanghui Zhu, Haojun Hou, Chunfeng Yuan, Yihua Huang|Nanjing University, Nanjing, China|Session-based recommendation aims to predict next click action (e.g., item) of anonymous users based on a fixed number of previous actions. Recently, Graph Neural Networks (GNNs) have shown superior performance in various applications. Inspired by the success of GNNs, tremendous endeavors have been devoted to introduce GNNs into session-based recommendation and have achieved significant results. Nevertheless, due to the highly diverse types of potential information in sessions, existing GNNs-based methods perform differently on different session datasets, leading to the need for efficient design of neural networks adapted to various session recommendation scenarios. To address this problem, we propose Automated neural architecture search for Graph-based Session Recommendation, namely AutoGSR, a framework that provides a practical and general solution to automatically find the optimal GNNs-based session recommendation model. In AutoGSR, we propose two novel GNN operations to build an expressive and compact search space. Building upon the search space, we employ a differentiable search algorithm to search for the optimal graph neural architecture. Furthermore, to consider all types of session information together, we propose to learn the item meta knowledge, which acts as a priori knowledge for guiding the optimization of final session representations. Comprehensive experiments on three real-world datasets demonstrate that AutoGSR is able to find effective neural architectures and achieve state-of-the-art results. To the best of our knowledge, we are the first to study the neural architecture search for the session-based recommendation.|基于会话的推荐旨在预测匿名用户的下一次点击操作(例如，条目) ，该推荐基于一个固定数量的以前的操作。近年来，图形神经网络(GNN)在各种应用中表现出了优越的性能。在 GNN 取得成功的启发下，为将 GNN 引入会议建议作出了巨大努力，并取得了重大成果。然而，由于会议中潜在信息的类型多种多样，现有的基于全球导航系统的方法在不同的会议数据集上表现不同，因此需要有效设计适应各种会议推荐情景的神经网络。为了解决这个问题，我们提出了基于图的会话推荐的自动神经网络体系结构搜索，即 AutoGSR，这个框架提供了一个实用的和通用的解决方案来自动找到最佳的基于 GNN 的会话推荐模型。在 AutoGSR 中，我们提出了两种新的 GNN 操作来构建一个表达式的、紧凑的搜索空间。在搜索空间的基础上，采用可微搜索算法来搜索最优的图神经网络结构。此外，为了一起考虑所有类型的会话信息，我们建议学习项目元知识，它作为指导最终会话表示优化的先验知识。对三个实际数据集的综合实验表明，AutoGSR 能够找到有效的神经结构，并取得最先进的结果。据我们所知，我们是第一个研究神经结构搜索的会话为基础的建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoGSR:+Neural+Architecture+Search+for+Graph-based+Session+Recommendation)|3|
|[How Does Feedback Signal Quality Impact Effectiveness of Pseudo Relevance Feedback for Passage Retrieval](https://doi.org/10.1145/3477495.3531822)|Hang Li, Ahmed Mourad, Bevan Koopman, Guido Zuccon|CSIRO, Brisbane, QLD, Australia; The University of Queensland, Brisbane, QLD, Australia|Pseudo-Relevance Feedback (PRF) assumes that the top results retrieved by a first-stage ranker are relevant to the original query and uses them to improve the query representation for a second round of retrieval. This assumption however is often not correct: some or even all of the feedback documents may be irrelevant. Indeed, the effectiveness of PRF methods may well depend on the quality of the feedback signal and thus on the effectiveness of the first-stage ranker. This aspect however has received little attention before. In this paper we control the quality of the feedback signal and measure its impact on a range of PRF methods, including traditional bag-of-words methods (Rocchio), and dense vector-based methods (learnt and not learnt). Our results show the important role the quality of the feedback signal plays on the effectiveness of PRF methods. Importantly, and surprisingly, our analysis reveals that not all PRF methods are the same when dealing with feedback signals of varying quality. These findings are critical to gain a better understanding of the PRF methods and of which and when they should be used, depending on the feedback signal quality, and set the basis for future research in this area.|伪相关反馈(PRF)假设第一阶段排序器检索到的最高结果与原始查询相关，并利用这些结果改善查询表示以进行第二轮检索。然而，这种假设往往是不正确的: 一些甚至所有的反馈文档可能是不相关的。事实上，PRF 方法的有效性很大程度上取决于反馈信号的质量，因此也取决于第一阶段排序器的有效性。然而，这方面以前很少受到关注。在本文中，我们控制反馈信号的质量，并测量其对一系列 PRF 方法的影响，包括传统的词袋方法(Rocchio)和基于密集向量的方法(学习和不学习)。结果表明，反馈信号的质量对 PRF 方法的有效性起着重要作用。重要的是，令人惊讶的是，我们的分析表明，并非所有的 PRF 方法是相同的，当处理不同质量的反馈信号。这些发现对于更好地理解 PRF 方法以及根据反馈信号的质量，什么时候应该使用这些方法是至关重要的，并且为这一领域的未来研究奠定了基础。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Does+Feedback+Signal+Quality+Impact+Effectiveness+of+Pseudo+Relevance+Feedback+for+Passage+Retrieval)|3|
|[Revisiting Two-tower Models for Unbiased Learning to Rank](https://doi.org/10.1145/3477495.3531837)|Le Yan, Zhen Qin, Honglei Zhuang, Xuanhui Wang, Michael Bendersky, Marc Najork|Google, Mountain View, CA, USA|Two-tower architecture is commonly used in real-world systems for Unbiased Learning to Rank (ULTR), where a Deep Neural Network (DNN) tower models unbiased relevance predictions, while another tower models observation biases inherent in the training data like user clicks. This two-tower architecture introduces inductive biases to allow more efficient use of limited observational logs and better generalization during deployment than single-tower architecture that may learn spurious correlations between relevance predictions and biases. However, despite their popularity, it is largely neglected in the literature that existing two-tower models assume that the joint distribution of relevance prediction and observation probabilities are completely factorizable. In this work, we revisit two-tower models for ULTR. We rigorously show that the factorization assumption can be too strong for real-world user behaviors, and existing methods may easily fail under slightly milder assumptions. We then propose several novel ideas that consider a wider spectrum of user behaviors while still under the two-tower framework to maintain simplicity and generalizability. Our concerns of existing two-tower models and the effectiveness of our proposed methods are validated on both controlled synthetic and large-scale real-world datasets.|双塔架构通常用于现实世界的无偏学习排名(ULTR)系统，其中一个深度神经网络(DNN)塔模型无偏相关性预测，而另一个塔模型观察偏差固有的训练数据，如用户点击。与单塔架构相比，这种双塔架构引入了归纳偏差，以便更有效地使用有限的观测日志，并在部署期间更好地进行概括，而单塔架构可以学习相关性预测和偏差之间的伪相关性。然而，尽管现有的双塔模型很流行，但它们大多被忽视了，现有的双塔模型假定相关预测和观测概率的联合分布是完全可分解的。在这项工作中，我们重新讨论了 ULTR 的双塔模型。我们严格地证明了因子分解假设对于真实世界的用户行为来说可能过于强烈，并且在稍微温和的假设下，现有的方法可能很容易失败。然后，我们提出了几个新的想法，考虑更广泛的用户行为，同时仍然在双塔框架下，以保持简单性和普遍性。我们对现有的双塔模型的关注和我们提出的方法的有效性是在受控的合成和大规模的真实世界数据集上得到验证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Two-tower+Models+for+Unbiased+Learning+to+Rank)|3|
|[Mitigating Bias in Search Results Through Contextual Document Reranking and Neutrality Regularization](https://doi.org/10.1145/3477495.3531891)|George Zerveas, Navid Rekabsaz, Daniel Cohen, Carsten Eickhoff|Brown University, Providence, RI, USA; Johannes Kepler University Linz & Linz Institute of Technology, Linz, Austria|Societal biases can influence Information Retrieval system results, and conversely, search results can potentially reinforce existing societal biases. Recent research has therefore focused on developing methods for quantifying and mitigating bias in search results and applied them to contemporary retrieval systems that leverage transformer-based language models. In the present work, we expand this direction of research by considering bias mitigation within a framework for contextual document embedding reranking. In this framework, the transformer-based query encoder is optimized for relevance ranking through a list-wise objective, by jointly scoring for the same query a large set of candidate document embeddings in the context of one another, instead of in isolation. At the same time, we impose a regularization loss which penalizes highly scoring documents that deviate from neutrality with respect to a protected attribute (e.g., gender). Our approach for bias mitigation is end-to-end differentiable and efficient. Compared to the existing alternatives for deep neural retrieval architectures, which are based on adversarial training, we demonstrate that it can attain much stronger bias mitigation/fairness. At the same time, for the same amount of bias mitigation, it offers significantly better relevance performance (utility). Crucially, our method allows for a more finely controllable and predictable intensity of bias mitigation, which is essential for practical deployment in production systems.|社会偏见可以影响信息检索系统的结果，相反，搜索结果可能会加强现有的社会偏见。因此，最近的研究侧重于开发用于量化和减轻搜索结果偏差的方法，并将其应用于利用基于转换器的语言模型的当代检索系统。在本文的工作中，我们扩展了这个研究方向，在上下文文档嵌入重排序的框架内考虑了偏差缓解。在这个框架中，基于转换器的查询编码器通过列表目标优化相关性排序，为同一个查询联合评分一大组候选文档嵌入在另一个上下文中，而不是孤立。与此同时，我们强制规范化的损失，惩罚高得分的文件偏离中立方面的保护属性(例如，性别)。我们的减少偏差的方法是端到端可微和有效的。与已有的基于对抗训练的深度神经检索结构相比，我们证明了该结构可以获得更强的偏差缓解/公平性。同时，对于相同数量的偏差缓解，它提供了明显更好的相关性能(效用)。至关重要的是，我们的方法允许更精细地控制和可预测的偏差缓解强度，这对于生产系统中的实际部署是必不可少的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Bias+in+Search+Results+Through+Contextual+Document+Reranking+and+Neutrality+Regularization)|3|
|[Curriculum Contrastive Context Denoising for Few-shot Conversational Dense Retrieval](https://doi.org/10.1145/3477495.3531961)|Kelong Mao, Zhicheng Dou, Hongjin Qian|Renmin University of China & Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China; Renmin University of China, Beijing, China|Conversational search is a crucial and promising branch in information retrieval. In this paper, we reveal that not all historical conversational turns are necessary for understanding the intent of the current query. The redundant noisy turns in the context largely hinder the improvement of search performance. However, enhancing the context denoising ability for conversational search is quite challenging due to data scarcity and the steep difficulty for simultaneously learning conversational query encoding and context denoising. To address these issues, in this paper, we present a novel Curriculum cOntrastive conTExt Denoising framework, COTED, towards few-shot conversational dense retrieval. Under a curriculum training order, we progressively endow the model with the capability of context denoising via contrastive learning between noised samples and denoised samples generated by a new conversation data augmentation strategy. Three curriculums tailored to conversational search are exploited in our framework. Extensive experiments on two few-shot conversational search datasets, i.e., CAsT-19 and CAsT-20, validate the effectiveness and superiority of our method compared with the state-of-the-art baselines.|会话搜索是信息检索中一个重要而有前途的分支。本文揭示了并非所有的历史会话转折都是理解当前查询意图的必要条件。上下文中的冗余噪声转折很大程度上阻碍了搜索性能的提高。然而，由于数据的稀缺性和同时学习会话查询编码和上下文去噪的困难性，提高会话搜索的上下文去噪能力是一个相当具有挑战性的问题。为了解决这些问题，本文提出了一种新的课程对比语境去噪框架 COTED，该框架旨在实现少镜头的会话密集检索。在课程训练顺序下，我们逐步赋予该模型通过对比学习去除噪声样本和通过一种新的会话数据增强策略产生的去噪样本的上下文去噪能力。在我们的框架中开发了三个适合会话搜索的课程。在两个少量会话搜索数据集，即 CAsT-19和 CAsT-20上的广泛实验验证了我们的方法与最先进的基线相比的有效性和优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curriculum+Contrastive+Context+Denoising+for+Few-shot+Conversational+Dense+Retrieval)|3|
|[Decoupled Side Information Fusion for Sequential Recommendation](https://doi.org/10.1145/3477495.3531963)|Yueqi Xie, Peilin Zhou, Sunghun Kim|Upstage, Hong Kong, Hong Kong; HKUST, Hong Kong, Hong Kong|Side information fusion for sequential recommendation (SR) aims to effectively leverage various side information to enhance the performance of next-item prediction. Most state-of-the-art methods build on self-attention networks and focus on exploring various solutions to integrate the item embedding and side information embeddings before the attention layer. However, our analysis shows that the early integration of various types of embeddings limits the expressiveness of attention matrices due to a rank bottleneck and constrains the flexibility of gradients. Also, it involves mixed correlations among the different heterogeneous information resources, which brings extra disturbance to attention calculation. Motivated by this, we propose Decoupled Side Information Fusion for Sequential Recommendation (DIF-SR), which moves the side information from the input to the attention layer and decouples the attention calculation of various side information and item representation. We theoretically and empirically show that the proposed solution allows higher-rank attention matrices and flexible gradients to enhance the modeling capacity of side information fusion. Also, auxiliary attribute predictors are proposed to further activate the beneficial interaction between side information and item representation learning. Extensive experiments on four real-world datasets demonstrate that our proposed solution stably outperforms state-of-the-art SR models. Further studies show that our proposed solution can be readily incorporated into current attention-based SR models and significantly boost performance. Our source code is available at https://github.com/AIM-SE/DIF-SR.|序贯推荐侧信息融合是为了有效地利用各种侧信息来提高下一个项目的预测性能。大多数最新的方法都是建立在自我注意网络的基础上，着重于探索各种解决方案，以整合注意层之前的项目嵌入和侧信息嵌入。然而，我们的分析表明，由于等级瓶颈的存在，各种嵌入类型的早期集成限制了注意矩阵的表达能力，同时也限制了梯度的灵活性。此外，它还涉及到不同异质信息资源之间的混合相关，给注意计算带来额外的干扰。在此基础上，提出了基于解耦的序贯推荐侧信息融合方法(DIF-SR) ，该方法将侧信息从输入层移动到注意层，并对各侧信息的注意计算和项目表示进行解耦。理论和实验结果表明，该方法允许高阶注意矩阵和灵活的梯度，提高了侧向信息融合的建模能力。同时，提出了辅助属性预测器，以进一步激活侧信息与项目表征学习之间的有益交互作用。在四个真实世界数据集上的大量实验表明，我们提出的解决方案稳定地优于最先进的 SR 模型。进一步的研究表明，我们提出的解决方案可以很容易地纳入目前的注意为基础的 SR 模型，并显着提高性能。我们的源代码可以在 https://github.com/aim-se/dif-sr 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Side+Information+Fusion+for+Sequential+Recommendation)|3|
|[Is News Recommendation a Sequential Recommendation Task?](https://doi.org/10.1145/3477495.3531862)|Chuhan Wu, Fangzhao Wu, Tao Qi, Chenliang Li, Yongfeng Huang|York University, Toronto, Canada; Renmin University of China, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|For sequential recommendation, it is essential to capture and predict future or long-term user preference for generating accurate recommendation over time. To improve the predictive capacity, we adopt reinforcement learning (RL) for developing effective sequential recommenders. However, user-item interaction data is likely to be sparse, complicated and time-varying. It is not easy to directly apply RL techniques to improve the performance of sequential recommendation.

Inspired by the availability of knowledge graph (KG), we propose a novel Knowledge-guidEd Reinforcement Learning model (KERL for short) for fusing KG information into a RL framework for sequential recommendation. Specifically, we formalize the sequential recommendation task as a Markov Decision Process (MDP), and make three major technical extensions in this framework, including state representation, reward function and learning algorithm. First, we propose to enhance the state representations with KG information considering both exploitation and exploration. Second, we carefully design a composite reward function that is able to compute both sequence- and knowledge-level rewards. Third, we propose a new algorithm for more effectively learning the proposed model. To our knowledge, it is the first time that knowledge information has been explicitly discussed and utilized in RL-based sequential recommenders, especially for the exploration process. Extensive experiment results on both next-item and next-session recommendation tasks show that our model can significantly outperform the baselines on four real-world datasets.|对于连续推荐，必须捕获和预测未来或长期的用户偏好，以便随着时间的推移产生准确的推荐。为了提高预测能力，我们采用强化学习(RL)来开发有效的顺序推荐系统。然而，用户项交互数据可能是稀疏的、复杂的和时变的。直接应用 RL 技术来提高顺序推荐的性能并不容易。受到知识图表(kG)的启发，我们提出了一种新的知识引导强化学习模型(简称 KERL) ，用于将 kG 信息融合到一个 RL 框架中，用于连续推荐。具体来说，我们将顺序推荐任务形式化为一个马可夫决策过程(mDP) ，并在这个框架中进行了三个主要的技术扩展，包括状态表示、奖励函数和学习算法。首先，我们提出了利用 KG 信息同时考虑开发和探索的方法来增强状态表示。其次，我们仔细设计了一个复合奖励函数，它能够计算序列和知识水平的奖励。第三，我们提出了一个新的算法，以更有效地学习所提出的模型。据我们所知，知识信息首次被明确地讨论和利用在基于 RL 的顺序推荐系统中，特别是在探索过程中。对下一个项目和下一个会话推荐任务的大量实验结果表明，我们的模型可以显著优于四个真实世界数据集的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+News+Recommendation+a+Sequential+Recommendation+Task?)|3|
|[Dual Contrastive Network for Sequential Recommendation](https://doi.org/10.1145/3477495.3531918)|Guanyu Lin, Chen Gao, Yinfeng Li, Yu Zheng, Zhiheng Li, Depeng Jin, Yong Li|Tsinghua University, Beijing, China|Widely applied in today's recommender systems, sequential recommendation predicts the next interacted item for a given user via his/her historical item sequence. However, sequential recommendation suffers data sparsity issue like most recommenders. To extract auxiliary signals from the data, some recent works exploit self-supervised learning to generate augmented data via dropout strategy, which, however, leads to sparser sequential data and obscure signals. In this paper, we propose D ual C ontrastive N etwork (DCN) to boost sequential recommendation, from a new perspective of integrating auxiliary user-sequence for items. Specifically, we propose two kinds of contrastive learning. The first one is the dual representation contrastive learning that minimizes the distances between embeddings and sequence-representations of users/items. The second one is the dual interest contrastive learning which aims to self-supervise the static interest with the dynamic interest of next item prediction via auxiliary training. We also incorporate the auxiliary task of predicting next user for a given item's historical user sequence, which can capture the trends of items preferred by certain types of users. Experiments on benchmark datasets verify the effectiveness of our proposed method. Further ablation study also illustrates the boosting effect of the proposed components upon different sequential models.|顺序推荐在当今的推荐系统中被广泛应用，它通过用户的历史项目顺序来预测给定用户的下一个交互项目。然而，与大多数推荐程序一样，顺序推荐也存在数据稀疏的问题。为了从数据中提取辅助信号，最近的一些工作利用自监督学习通过丢失策略生成增强数据，但是这样会导致序列数据更稀疏，信号更模糊。本文从集成项目辅助用户序列的新角度出发，提出了 D-C 对比 N 网络(DCN)来增强序列推荐。具体来说，我们提出了两种对比学习。第一种是双重表示对比学习，它最小化了嵌入和用户/项目序列表示之间的距离。第二种是双兴趣对比学习，目的是通过辅助训练对静态兴趣和下一项预测的动态兴趣进行自我监督。我们还结合了辅助任务，即预测给定项目的历史用户序列的下一个用户，这可以捕获某些类型的用户喜欢的项目的趋势。在基准数据集上的实验验证了该方法的有效性。进一步的消融研究也说明了所提出的组件对不同序列模型的增强效应。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Contrastive+Network+for+Sequential+Recommendation)|3|
|[PKG: A Personal Knowledge Graph for Recommendation](https://doi.org/10.1145/3477495.3531671)|Yu Yang, Jiangxu Lin, Xiaolian Zhang, Meng Wang|Huawei Technologies Co. Ltd., Shenzhen, China; Southeast University, Nanjing, China|Mobile internet users generate personal data on the devices all the time in this era. In this paper, we demonstrate a novel system for integrating the data of a user from different sources into a Personal Knowledge Graph, i.e., PKG. We show how a user's intention can be detected and how the personal data can be aligned and connected by the user behaviors. The constructed PKG allows the system makes reasonable and accurate recommendations for users by a "neural + symbolic'' approach across different services. Our system is shown in https://youtu.be/hWuo8KCDrto.|在这个时代，移动互联网用户一直在设备上生成个人数据。在本文中，我们展示了一个新的系统来整合来自不同来源的用户的数据到一个个人知识图，即 PKG。我们展示了如何检测用户的意图，以及如何通过用户行为来校准和连接个人数据。构建的 PKG 允许系统通过“神经 + 符号”的方法跨越不同的服务为用户提供合理和准确的建议。我们的系统以 https://youtu.be/hwuo8kcdrto 显示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PKG:+A+Personal+Knowledge+Graph+for+Recommendation)|3|
|[Co-training Disentangled Domain Adaptation Network for Leveraging Popularity Bias in Recommenders](https://doi.org/10.1145/3477495.3531952)|Zhihong Chen, Jiawei Wu, Chenliang Li, Jingxu Chen, Rong Xiao, Binqiang Zhao|Wuhan University, Wuhan, China; Alibaba Group, Hangzhou, China|Recommender system usually faces popularity bias. From the popularity distribution shift perspective, the normal paradigm trained on exposed items (most are hot items) identifies that recommending popular items more frequently can achieve lower loss, thus injecting popularity information into item property embedding, e.g., id embedding. From the long-tail distribution shift perspective, the sparse interactions of long-tail items lead to insufficient learning of them. The resultant distribution discrepancy between hot and long-tail items would not only inherit the bias, but also amplify the bias. Existing work addresses this issue with inverse propensity scoring (IPS) or causal embeddings. However, we argue that not all popularity biases mean bad effects, i.e., some items show higher popularity due to better quality or conform to current trends, which deserve more recommendations. Blindly seeking unbiased learning may inhibit high-quality or fashionable items. To make better use of the popularity bias, we propose a co-training disentangled domain adaptation network (CD$^2$AN), which can co-train both biased and unbiased models. Specifically, for popularity distribution shift, CD$^2$AN disentangles item property representation and popularity representation from item property embedding. For long-tail distribution shift, we introduce additional unexposed items (most are long-tail items) to align the distribution of hot and long-tail item property representations. Further, from the instances perspective, we carefully design the item similarity regularization to learn comprehensive item representation, which encourages item pairs with more effective co-occurrences patterns to have more similar item property representations. Based on offline evaluations and online A/B tests, we show that CD$^2$AN outperforms the existing debiased solutions. Currently, CD$^2$AN has been successfully deployed at Mobile Taobao App and handling major online traffic.|推荐系统通常面临受欢迎程度的偏见。从受欢迎度分布转移的角度来看，通常对曝光项目(大多数是热门项目)进行训练的范式认为，更频繁地推荐受欢迎项目可以获得更低的损失，从而将受欢迎信息注入项目属性嵌入，例如，ID 嵌入。从长尾分布偏移的角度来看，长尾项目之间稀疏的交互作用导致对它们的学习不足。由此产生的热点项目与长尾项目之间的分布差异不仅会继承偏差，而且会放大偏差。现有的工作解决这个问题的逆倾向评分(IPS)或因果嵌入。然而，我们认为并非所有的流行偏见都意味着负面影响，例如，一些项目由于质量更好或符合当前趋势而显示出更高的流行度，这值得更多的推荐。盲目追求无偏见的学习可能会抑制高质量或时尚的项目。为了更好地利用流行度偏差，我们提出了一种协同训练的去纠缠域自适应网络(CD $^ 2 $AN) ，它可以同时训练有偏和无偏模型。具体地说，对于流行度分布转移，CD $^ 2 $AN 将项目属性表示和流行度表示从项目属性嵌入中分离出来。对于长尾分布转移，我们引入了额外的未公开项(大多数是长尾项)来对齐热点和长尾项属性表示的分布。此外，从实例的角度，我们仔细设计了项目相似性正则化，以学习综合项目表示，鼓励具有更有效的共现模式的项目对具有更多相似的项目属性表示。基于离线评估和在线 A/B 测试，我们表明 CD $^ 2 $AN 优于现有的去偏解决方案。目前，CD $^ 2 $AN 已经成功部署在移动淘宝应用程序上，并处理主要的在线流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-training+Disentangled+Domain+Adaptation+Network+for+Leveraging+Popularity+Bias+in+Recommenders)|3|
|[Multi-Level Interaction Reranking with User Behavior History](https://doi.org/10.1145/3477495.3532026)|Yunjia Xi, Weiwen Liu, Jieming Zhu, Xilong Zhao, Xinyi Dai, Ruiming Tang, Weinan Zhang, Rui Zhang, Yong Yu|Huawei Noah's Ark Lab, Shenzhen, China; ruizhang.info, Shenzhen, China; Shanghai Jiao Tong University, Shanghai, China|As the final stage of the multi-stage recommender system (MRS), reranking directly affects users' experience and satisfaction, thus playing a critical role in MRS. Despite the improvement achieved in the existing work, three issues are yet to be solved. First, users' historical behaviors contain rich preference information, such as users' long and short-term interests, but are not fully exploited in reranking. Previous work typically treats items in history equally important, neglecting the dynamic interaction between the history and candidate items. Second, existing reranking models focus on learning interactions at the item level while ignoring the fine-grained feature-level interactions. Lastly, estimating the reranking score on the ordered initial list before reranking may lead to the early scoring problem, thereby yielding suboptimal reranking performance. To address the above issues, we propose a framework named Multi-level Interaction Reranking (MIR). MIR combines low-level cross-item interaction and high-level set-to-list interaction, where we view the candidate items to be reranked as a set and the users' behavior history in chronological order as a list. We design a novel SLAttention structure for modeling the set-to-list interactions with personalized long-short term interests. Moreover, feature-level interactions are incorporated to capture the fine-grained influence among items. We design MIR in such a way that any permutation of the input items would not change the output ranking, and we theoretically prove it. Extensive experiments on three public and proprietary datasets show that MIR significantly outperforms the state-of-the-art models using various ranking and utility metrics.|作为多阶段推荐系统(MRS)的最后阶段，重新排名直接影响用户的体验和满意度，因此在 MRS 中发挥着关键作用。尽管现有工作已有所改善，但仍有三个问题有待解决。首先，用户的历史行为包含了丰富的偏好信息，如用户的长期和短期兴趣，但在重新排序时没有得到充分的利用。以往的研究通常认为历史条目同等重要，而忽视了历史条目与候选条目之间的动态互动。其次，现有的重新排序模型侧重于项目层面的学习交互，而忽略了细粒度的特征层面的交互。最后，在重新排序之前估计排序初始列表上的重新排序得分可能会导致早期得分问题，从而产生次优的重新排序性能。为了解决上述问题，我们提出了一个名为多级交互重排(MIR)的框架。MIR 结合了低层次的跨项目交互和高层次的集合-列表交互，我们将待重新排序的候选项作为一个集合，将用户的行为历史按照时间顺序作为一个列表。我们设计了一个新颖的空间注意结构，用于建模具有个性化长期短期兴趣的集合列表交互。此外，特征层次的交互作用被合并来捕获项目之间的细粒度影响。我们设计 MIR 的方法使得输入项的任何排列都不会改变输出的排名，并且我们从理论上证明了这一点。对三个公共和专有数据集的大量实验表明，使用各种排名和效用指标，MIR 显著优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Level+Interaction+Reranking+with+User+Behavior+History)|3|
|[RankFlow: Joint Optimization of Multi-Stage Cascade Ranking Systems as Flows](https://doi.org/10.1145/3477495.3532050)|Jiarui Qin, Jiachen Zhu, Bo Chen, Zhirong Liu, Weiwen Liu, Ruiming Tang, Rui Zhang, Yong Yu, Weinan Zhang|Huawei Noah's Ark Lab, Shenzhen, China; ruizhang.info, Shenzhen, China; Shanghai Jiao Tong University, Shanghai, China|Building a multi-stage cascade ranking system is a commonly used solution to balance the efficiency and effectiveness in modern information retrieval (IR) applications, such as recommendation and web search. Despite the popularity in practice, the literature specific on multi-stage cascade ranking systems is relatively scarce. The common practice is to train rankers of each stage independently using the same user feedback data (a.k.a., impression data), disregarding the data flow and the possible interactions between stages. This straightforward solution could lead to a sub-optimal system because of the sample selection bias (SSB) issue, which is especially damaging for cascade rankers due to the negative effect accumulated in the multiple stages. Worse still, the interactions between the rankers of each stage are not fully exploited. This paper provides an elaborate analysis of this commonly used solution to reveal its limitations. By studying the essence of cascade ranking, we propose a joint training framework named RankFlow to alleviate the SSB issue and exploit the interactions between the cascade rankers, which is the first systematic solution for this topic. We propose a paradigm of training cascade rankers that emphasizes the importance of fitting rankers on stage-specific data distributions instead of the unified user feedback distribution. We design the RankFlow framework based on this paradigm: The training data of each stage is generated by its preceding stages while the guidance signals not only come from the logs but its successors. Extensive experiments are conducted on various IR scenarios, including recommendation, web search and advertisement. The results verify the efficacy and superiority of RankFlow.|建立一个多阶段的级联排名系统是现代信息检索应用(如推荐和网络搜索)中一个常用的平衡效率和有效性的解决方案。尽管在实践中很流行，但是关于多级级联排序系统的文献相对较少。通常的做法是使用相同的用户反馈数据(也就是印象数据)独立训练每个阶段的排名，忽略数据流和阶段之间可能的交互作用。由于样本选择偏差(SSB)问题，这种直接的解决方案可能会导致系统的次优化，而由于多阶段累积的负面效应，SSB 问题对级联排序尤其有害。更糟糕的是，每个阶段的排名之间的相互作用没有得到充分利用。本文对这种常用的解决方案进行了详细的分析，以揭示其局限性。通过研究级联排序的本质，提出了一种联合训练框架 RankFlow 来缓解 SSB 问题，并利用级联排序器之间的相互作用，这是本课题的第一个系统解决方案。我们提出了一个训练级联排名的范式，强调拟合排名的重要性阶段特定的数据分布，而不是统一的用户反馈分布。在此基础上，我们设计了 RankFlow 框架: 每个阶段的训练数据由前一阶段生成，而制导信号不仅来自日志，还来自后一阶段。在不同的信息检索场景中进行了广泛的实验，包括推荐、网络搜索和广告。结果验证了 RankFlow 的有效性和优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RankFlow:+Joint+Optimization+of+Multi-Stage+Cascade+Ranking+Systems+as+Flows)|3|
|[Towards Suicide Ideation Detection Through Online Conversational Context](https://doi.org/10.1145/3477495.3532068)|Ramit Sawhney, Shivam Agarwal, Atula Tejaswi Neerkaje, Nikolaos Aletras, Preslav Nakov, Lucie Flek|Qatar Computing Research Institute, HBKU, Doha, Qatar; Georgia Institute of Technology & Conversational AI and Social Analytics (CAISA) Lab, University of Marburg, Atlanta, GA, USA; University of Illinois at Urbana-Champaign & Conversational AI and Social Analytics (CAISA) Lab, University of Marburg, Urbana-Champaign, IL, USA; Conversational AI and Social Analytics (CAISA) Lab, University of Marburg, Marburg, Germany; University of Sheffield, Sheffield, United Kingdom|Social media enable users to share their feelings and emotional struggles. They also offer an opportunity to provide community support to suicidal users. Recent studies on suicide risk assessment have explored the user's historic timeline and information from their social network to analyze their emotional state. However, such methods often require a large amount of user-centric data. A less intrusive alternative is to only use conversation trees arising from online community responses. Modeling such online conversations between the community and a person in distress is an important context for understanding that person's mental state. However, it is not trivial to model the vast number of conversation trees on social media, since each comment has a diverse influence on a user in distress. Typically, a handful of comments/posts receive a significantly high number of replies, which results in scale-free dynamics in the conversation tree. Moreover, psychological studies suggested that it is important to capture the fine-grained temporal irregularities in the release of vast volumes of comments, since suicidal users react quickly to online community support. Building on these limitations and psychological studies, we propose HCN, a Hyperbolic Conversation Network, which is a less user-intrusive method for suicide ideation detection. HCN leverages the hyperbolic space to represent the scale-free dynamics of online conversations. Through extensive quantitative, qualitative, and ablative experiments on real-world Twitter data, we find that HCN outperforms state-of-the art methods, while using 98% less user-specific data, and while maintaining a 74% lower carbon footprint and a 94% smaller model size. We also find that the comments within the first half an hour are most important to identify at-risk users.|社交媒体使用户能够分享他们的感受和情感挣扎。他们还提供了一个机会，为自杀使用者提供社区支持。最近有关自杀风险评估的研究探讨了使用者的历史时间线和来自他们的社交网络的信息，以分析他们的情绪状态。然而，这样的方法通常需要大量以用户为中心的数据。一个较少干扰的替代方法是只使用在线社区响应中产生的对话树。在社区和一个处于困境中的人之间建立这样的在线对话模型是理解这个人的精神状态的重要环境。然而，在社交媒体上建立大量的对话树并非易事，因为每条评论都会对处于困境中的用户产生不同的影响。通常，少量的评论/帖子会收到大量的回复，这导致了会话树中的无标度动态。此外，心理学研究表明，重要的是捕捉细粒度的时间不规则的发布大量的评论，因为自杀用户反应迅速在线社区支持。在这些局限性和心理学研究的基础上，我们提出了双曲对话网络 HCN，这是一种用户侵入性较低的自杀意念检测方法。HCN 利用双曲空间来表现在线对话的无标度动态。通过对真实世界的 Twitter 数据进行广泛的定量、定性和消融实验，我们发现 HCN 的表现优于最先进的方法，同时使用的用户特定数据减少了98% ，同时保持了74% 的低碳足印和94% 的小模型尺寸。我们还发现，在前半个小时内的评论对于识别高危用户是最重要的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Suicide+Ideation+Detection+Through+Online+Conversational+Context)|3|
|[Socially-aware Dual Contrastive Learning for Cold-Start Recommendation](https://doi.org/10.1145/3477495.3531780)|Jing Du, Zesheng Ye, Lina Yao, Bin Guo, Zhiwen Yu|The University of New South Wales, Sydney, NSW, Australia; Northwestern Polytechnical University, Xi'an, Shaanxi, China|Social recommendation with Graph Neural Networks(GNNs) learns to represent cold users by fusing user-user social relations with user-item interactions, thereby alleviating the cold-start problem associated with recommender systems. Despite being well adapted to social relations and user-item interactions, these supervised models are still susceptible to popularity bias. Contrastive learning helps resolve this dilemma by identifying the properties that distinguish positive from negative samples. In its previous combinations with recommender systems, social relationships and cold-start cases in this context are not considered. Also, they primarily focus on collaborative features between users and items, leaving the similarity between items under-utilized. In this work, we propose socially-aware dual contrastive learning for cold-start recommendation, where cold users can be modeled in the same way as warm users. To take full advantage of social relations, we create dynamic node embeddings for each user by aggregating information from different neighbors according to each different query item, in the form of user-item pairs. We further design a dual-branch self-supervised contrastive objective to account for user-item collaborative features and item-item mutual information, respectively. On one hand, our framework eliminates popularity bias with proper negative sampling in contrastive learning, without extra ground-truth supervision. On the other hand, we extend previous contrastive learning methods to provide a solution to cold-start problem with social relations included. Extensive experiments on two real-world social recommendation datasets demonstrate its effectiveness.|图形神经网络的社会推荐学习通过融合用户-用户社会关系和用户-项目交互来表示冷用户，从而缓解推荐系统的冷启动问题。尽管这些被监督的模型很好地适应了社会关系和用户项目交互，但是仍然容易受到流行偏见的影响。对比学习有助于解决这一困境，识别的属性，区分积极的样本和消极的样本。在其以往与推荐系统的结合中，社会关系和这方面的冷启动案例没有得到考虑。此外，他们主要关注用户和项目之间的协作特性，而没有充分利用项目之间的相似性。在这项工作中，我们提出了具有社会意识的双重对比学习的冷启动推荐，其中冷用户可以按照与暖用户相同的方式建模。为了充分利用社会关系，我们根据不同的查询项目，以用户-项目对的形式聚合来自不同邻居的信息，为每个用户创建动态节点嵌入。进一步设计了一个双分支自监督对比目标，分别考虑了用户项目的协同特征和项目项目间的相互信息。一方面，我们的框架消除了流行偏见与适当的负面抽样在对比学习，没有额外的地面真相监督。另一方面，我们扩展了以往的对比学习方法，提供了一个解决冷启动问题，其中包括社会关系。在两个真实世界的社交推荐数据集上进行的大量实验证明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Socially-aware+Dual+Contrastive+Learning+for+Cold-Start+Recommendation)|3|
|[A Multi-Task Based Neural Model to Simulate Users in Goal Oriented Dialogue Systems](https://doi.org/10.1145/3477495.3531814)|To Eun Kim, Aldo Lipani|University College London, London, United Kingdom|A human-like user simulator that anticipates users' satisfaction scores, actions, and utterances can help goal-oriented dialogue systems in evaluating the conversation and refining their dialogue strategies. However, little work has experimented with user simulators which can generate users' utterances. In this paper, we propose a deep learning-based user simulator that predicts users' satisfaction scores and actions while also jointly generating users' utterances in a multi-task manner. In particular, we show that 1) the proposed deep text-to-text multi-task neural model achieves state-of-the-art performance in the users' satisfaction scores and actions prediction tasks, and 2) in an ablation analysis, user satisfaction score prediction, action prediction, and utterance generation tasks can boost the performance with each other via positive transfers across the tasks. The source code and model checkpoints used for the experiments run in this paper are available at the following weblink: \urlhttps://github.com/kimdanny/user-simulation-t5.|一个类人的用户模拟器，可以预测用户的满意度分数、行为和话语，可以帮助目标导向的对话系统评估对话和完善他们的对话策略。然而，很少有工作已经试验用户模拟器，可以产生用户的话语。在本文中，我们提出了一个基于深度学习的用户模拟器，预测用户的满意度分数和行为，同时也联合生成用户的话语在多任务的方式。实验结果表明: (1)本文提出的深度文本-文本多任务神经模型在用户满意度分数和行为预测任务方面达到了最高水平; (2)在消融分析方面，用户满意度分数预测、行为预测和话语生成任务可以通过任务之间的正向传递相互提高性能。本文中用于实验的源代码和模型检查点可以在以下网站找到: urlhttps:// github.com/kimdanny/user-simulation-t5。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Task+Based+Neural+Model+to+Simulate+Users+in+Goal+Oriented+Dialogue+Systems)|3|
|[Investigating Accuracy-Novelty Performance for Graph-based Collaborative Filtering](https://doi.org/10.1145/3477495.3532005)|Minghao Zhao, Le Wu, Yile Liang, Lei Chen, Jian Zhang, Qilin Deng, Kai Wang, Xudong Shen, Tangjie Lv, Runze Wu|Hefei University of Technology, Hefei, China; Fuxi AI Lab, NetEase Games, Hangzhou, China; Zhejiang University of Technology, Hangzhou, China|Recent years have witnessed the great accuracy performance of graph-based Collaborative Filtering (CF) models for recommender systems. By taking the user-item interaction behavior as a graph, these graph-based CF models borrow the success of Graph Neural Networks (GNN), and iteratively perform neighborhood aggregation to propagate the collaborative signals. While conventional CF models are known for facing the challenges of the popularity bias that favors popular items, one may wonder "Whether the existing graph-based CF models alleviate or exacerbate the popularity bias of recommender systems?" To answer this question, we first investigate the two-fold performances w.r.t. accuracy and novelty for existing graph-based CF methods. The empirical results show that symmetric neighborhood aggregation adopted by most existing graph-based CF models exacerbates the popularity bias and this phenomenon becomes more serious as the depth of graph propagation increases. Further, we theoretically analyze the cause of popularity bias for graph-based CF. Then, we propose a simple yet effective plugin, namely r-AdjNorm, to achieve an accuracy-novelty trade-off by controlling the normalization strength in the neighborhood aggregation process. Meanwhile, r-AdjNorm can be smoothly applied to the existing graph-based CF backbones without additional computation. Finally, experimental results on three benchmark datasets show that our proposed method can improve novelty without sacrificing accuracy under various graph-based CF backbones.|近年来，基于图形的协同过滤(CF)模型在推荐系统中的准确性表现非常出色。这些基于图的协同过程模型借鉴了图神经网络(GNN)的成功之处，以用户项交互行为为图形，迭代地进行邻域聚合来传播协同信号。虽然传统的 CF 模型面临着流行偏好的挑战，有人可能会问: “现有的基于图表的 CF 模型是否减轻或加剧了推荐系统的流行偏好?”为了回答这个问题，我们首先研究了现有的基于图的 CF 方法的双重性能。实验结果表明，现有的基于图的 CF 模型所采用的对称邻域聚集加剧了流行偏差，并且随着图的传播深度的增加，这种现象变得更加严重。进一步从理论上分析了基于图的流行度偏差产生的原因，提出了一种简单有效的插件 r-AdjNorm，通过控制邻域聚合过程中的归一化强度来实现精度-新颖性的权衡。同时，r-AdjNorm 可以顺利地应用于现有的基于图的 CF 骨干，而不需要额外的计算。最后，在三个基准数据集上的实验结果表明，在不同的基于图的 CF 骨架下，本文提出的方法可以在不牺牲精度的前提下提高新颖性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Accuracy-Novelty+Performance+for+Graph-based+Collaborative+Filtering)|3|
|[Learning to Denoise Unreliable Interactions for Graph Collaborative Filtering](https://doi.org/10.1145/3477495.3531889)|Changxin Tian, Yuexiang Xie, Yaliang Li, Nan Yang, Wayne Xin Zhao|Alibaba Group, Hangzhou, China; Alibaba Group, Bellevue, WA, USA; Renmin University of China, Beijing, China|Recently, graph neural networks (GNN) have been successfully applied to recommender systems as an effective collaborative filtering (CF) approach. However, existing GNN-based CF models suffer from noisy user-item interaction data, which seriously affects the effectiveness and robustness in real-world applications. Although there have been several studies on data denoising in recommender systems, they either neglect direct intervention of noisy interaction in the message-propagation of GNN, or fail to preserve the diversity of recommendation when denoising. To tackle the above issues, this paper presents a novel GNN-based CF model, named Robust Graph Collaborative Filtering (RGCF), to denoise unreliable interactions for recommendation. Specifically, RGCF consists of a graph denoising module and a diversity preserving module. The graph denoising module is designed for reducing the impact of noisy interactions on the representation learning of GNN, by adopting both a hard denoising strategy (i.e., discarding interactions that are confidently estimated as noise) and a soft denoising strategy (i.e., assigning reliability weights for each remaining interaction). In the diversity preserving module, we build up a diversity augmented graph and propose an auxiliary self-supervised task based on mutual information maximization (MIM) for enhancing the denoised representation and preserving the diversity of recommendation. These two modules are integrated in a multi-task learning manner that jointly improves the recommendation performance. We conduct extensive experiments on three real-world datasets and three synthesized datasets. Experiment results show that RGCF is more robust against noisy interactions and achieves significant improvement compared with baseline models.|最近，图形神经网络(GNN)已成功应用于推荐系统，作为一种有效的协同过滤(CF)方法。然而，现有的基于 GNN 的 CF 模型存在着用户项交互数据的噪声，严重影响了实际应用的有效性和鲁棒性。对于推荐系统中的数据去噪问题，目前已经有了一些研究，但是这些研究要么忽略了噪声交互对 GNN 信息传播的直接干预，要么在去噪时未能保持推荐信息的多样性。为了解决上述问题，本文提出了一种新的基于 GNN 的 CF 模型，称为鲁棒图协同过滤(rgCF) ，用于去除不可靠的推荐交互。具体来说，RGCF 由图的去噪模块和多样性保持模块组成。图形去噪模块是为了减少噪声交互对 GNN 表示学习的影响而设计的，它采用了硬去噪策略(即放弃可信地估计为噪声的交互)和软去噪策略(即为每个剩余交互指定可靠性权重)。在多样性保持模块中，我们建立了一个多样性增强图，并提出了一个基于互信息最大化(MIM)的辅助自监督任务，以提高去噪表示和保持推荐的多样性。这两个模块以多任务学习方式集成，共同提高了推荐性能。我们在三个真实数据集和三个合成数据集上进行了广泛的实验。实验结果表明，与基线模型相比，RGCF 对噪声干扰具有更强的鲁棒性，并取得了显著的改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Denoise+Unreliable+Interactions+for+Graph+Collaborative+Filtering)|3|
|[DAWAR: Diversity-aware Web APIs Recommendation for Mashup Creation based on Correlation Graph](https://doi.org/10.1145/3477495.3531962)|Wenwen Gong, Xuyun Zhang, Yifei Chen, Qiang He, Amin Beheshti, Xiaolong Xu, Chao Yan, Lianyong Qi|Qufu Normal University & Nanjing University, Rizhao, China; Swinburne University of Technology, Melbourne, VIC, Australia; Macquarie University, Sydney, NSW, Australia; Nanjing University of Information Science and Technology, Nanjing, China; Qufu Normal University, Rizhao, China; China Agricultural University, Beijing, China|With the ever-increasing popularity of microservice architecture, a considerable number of enterprises or organizations have encapsulated their complex business services into various lightweight functions as published them accessible APIs (Application Programming Interfaces). Through keyword search, a software developer could select a set of APIs from a massive number of candidates to implement the functions of a complex mashup, which reduces the development cost significantly. However, traditional keyword search methods for APIs often suffer from several critical issues such as functional compatibility and limited diversity in search results, which may lead to mashup creation failures and lower development productivity. To deal with these challenges, this paper designs DAWAR, a diversity-aware Web APIs recommendation approach that finds diversified and compatible APIs for mashup creation. Specifically, the APIs recommendation problem for mashup creating is modelled as a graph search problem that aims to find the minimal group Steiner trees in a correlation graph of APIs. DAWAR innovatively employs the determinantal point processes to diversify the recommended results. Empirical evaluation is performed on commonly-used real-world datasets, and the statistic results show that DAWAR is able to achieve significant improvements in terms of recommendation diversity, accuracy, and compatibility.|随着微服务体系结构的日益普及，相当数量的企业或组织已经将其复杂的业务服务封装成各种轻量级功能，并将其发布为可访问的 API (应用程序编程接口)。通过关键字搜索，软件开发人员可以从大量候选 API 中选择一组 API 来实现复杂 mashup 的功能，这大大降低了开发成本。然而，用于 API 的传统关键字搜索方法经常遇到一些关键问题，如功能兼容性和搜索结果的多样性有限，这可能导致 mashup 创建失败和开发效率降低。为了应对这些挑战，本文设计了 DAWAR，这是一种多样性感知的 Web API 推荐方法，它为 mashup 创建寻找多样性和兼容的 API。具体来说，用于 mashup 创建的 API 推荐问题被建模为一个图搜索问题，其目的是在 API 的相关图中找到最小组 Steiner 树。DAWAR 创新地使用决定点过程来使推荐的结果多样化。对现实世界中常用的数据集进行了实证评估，统计结果表明，DAWAR 在推荐多样性、准确性和兼容性方面都有显著的提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAWAR:+Diversity-aware+Web+APIs+Recommendation+for+Mashup+Creation+based+on+Correlation+Graph)|3|
|[Post Processing Recommender Systems with Knowledge Graphs for Recency, Popularity, and Diversity of Explanations](https://doi.org/10.1145/3477495.3532041)|Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Mirko Marras|University of Cagliari, Cagliari, Italy|Existing explainable recommender systems have mainly modeled relationships between recommended and already experienced products, and shaped explanation types accordingly (e.g., movie "x" starred by actress "y" recommended to a user because that user watched other movies with "y" as an actress). However, none of these systems has investigated the extent to which properties of a single explanation (e.g., the recency of interaction with that actress) and of a group of explanations for a recommended list (e.g., the diversity of the explanation types) can influence the perceived explaination quality. In this paper, we conceptualized three novel properties that model the quality of the explanations (linking interaction recency, shared entity popularity, and explanation type diversity) and proposed re-ranking approaches able to optimize for these properties. Experiments on two public data sets showed that our approaches can increase explanation quality according to the proposed properties, fairly across demographic groups, while preserving recommendation utility. The source code and data are available at https://github.com/giacoballoccu/explanation-quality-recsys.|现有的可解释推荐系统主要模拟推荐产品和已经有经验的产品之间的关系，并相应地形成解释类型(例如，由女演员“ y”主演的电影“ x”被推荐给用户，因为该用户观看了其他以“ y”为女演员的电影)。然而，这些系统都没有研究单一解释(例如，与女演员互动的近期性)和推荐列表的一组解释(例如，解释类型的多样性)的特性在多大程度上影响感知的解释质量。在本文中，我们概念化了三个新的性质来模拟解释的质量(连接互动的新近性，共享实体的流行性和解释类型的多样性) ，并提出了重新排序的方法，能够优化这些性质。对两个公共数据集的实验表明，我们的方法可以提高解释质量根据建议的性质，相当跨人口组，同时保留推荐效用。源代码和数据可在 https://github.com/giacoballoccu/explanation-quality-recsys 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post+Processing+Recommender+Systems+with+Knowledge+Graphs+for+Recency,+Popularity,+and+Diversity+of+Explanations)|3|
|[Learning Graph-based Disentangled Representations for Next POI Recommendation](https://doi.org/10.1145/3477495.3532012)|Zhaobo Wang, Yanmin Zhu, Haobing Liu, Chunyang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Graph-based+Disentangled+Representations+for+Next+POI+Recommendation)|3|
|[AutoLossGen: Automatic Loss Function Generation for Recommender Systems](https://doi.org/10.1145/3477495.3531941)|Zelong Li, Jianchao Ji, Yingqiang Ge, Yongfeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoLossGen:+Automatic+Loss+Function+Generation+for+Recommender+Systems)|3|
|[MGPolicy: Meta Graph Enhanced Off-policy Learning for Recommendations](https://doi.org/10.1145/3477495.3532021)|Xiangmeng Wang, Qian Li, Dianer Yu, Zhichao Wang, Hongxu Chen, Guandong Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MGPolicy:+Meta+Graph+Enhanced+Off-policy+Learning+for+Recommendations)|3|
|[Privacy-Preserving Synthetic Data Generation for Recommendation Systems](https://doi.org/10.1145/3477495.3532044)|Fan Liu, Zhiyong Cheng, Huilin Chen, Yinwei Wei, Liqiang Nie, Mohan S. Kankanhalli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Synthetic+Data+Generation+for+Recommendation+Systems)|3|
|[Self-Guided Learning to Denoise for Robust Recommendation](https://doi.org/10.1145/3477495.3532059)|Yunjun Gao, Yuntao Du, Yujia Hu, Lu Chen, Xinjun Zhu, Ziquan Fang, Baihua Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Guided+Learning+to+Denoise+for+Robust+Recommendation)|3|
|[Faster Learned Sparse Retrieval with Guided Traversal](https://doi.org/10.1145/3477495.3531774)|Antonio Mallia, Joel Mackenzie, Torsten Suel, Nicola Tonellotto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Faster+Learned+Sparse+Retrieval+with+Guided+Traversal)|3|
|[Analysing the Robustness of Dual Encoders for Dense Retrieval Against Misspellings](https://doi.org/10.1145/3477495.3531818)|Georgios Sidiropoulos, Evangelos Kanoulas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analysing+the+Robustness+of+Dual+Encoders+for+Dense+Retrieval+Against+Misspellings)|3|
|[Cross-Probe BERT for Fast Cross-Modal Search](https://doi.org/10.1145/3477495.3531826)|Tan Yu, Hongliang Fei, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Probe+BERT+for+Fast+Cross-Modal+Search)|3|
|[DH-HGCN: Dual Homogeneity Hypergraph Convolutional Network for Multiple Social Recommendations](https://doi.org/10.1145/3477495.3531828)|Jiadi Han, Qian Tao, Yufei Tang, Yuhan Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DH-HGCN:+Dual+Homogeneity+Hypergraph+Convolutional+Network+for+Multiple+Social+Recommendations)|3|
|[To Interpolate or not to Interpolate: PRF, Dense and Sparse Retrievers](https://doi.org/10.1145/3477495.3531884)|Hang Li, Shuai Wang, Shengyao Zhuang, Ahmed Mourad, Xueguang Ma, Jimmy Lin, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=To+Interpolate+or+not+to+Interpolate:+PRF,+Dense+and+Sparse+Retrievers)|3|
|[Selective Fairness in Recommendation via Prompts](https://doi.org/10.1145/3477495.3531913)|Yiqing Wu, Ruobing Xie, Yongchun Zhu, Fuzhen Zhuang, Xiang Ao, Xu Zhang, Leyu Lin, Qing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Selective+Fairness+in+Recommendation+via+Prompts)|3|
|[ReLoop: A Self-Correction Continual Learning Loop for Recommender Systems](https://doi.org/10.1145/3477495.3531922)|Guohao Cai, Jieming Zhu, Quanyu Dai, Zhenhua Dong, Xiuqiang He, Ruiming Tang, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReLoop:+A+Self-Correction+Continual+Learning+Loop+for+Recommender+Systems)|3|
|[SoChainDB: A Database for Storing and Retrieving Blockchain-Powered Social Network Data](https://doi.org/10.1145/3477495.3531735)|Hoang H. Nguyen, Dmytro Bozhkov, Zahra Ahmadi, NhatMinh Nguyen, ThanhNam Doan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SoChainDB:+A+Database+for+Storing+and+Retrieving+Blockchain-Powered+Social+Network+Data)|3|
|[From Little Things Big Things Grow: A Collection with Seed Studies for Medical Systematic Review Literature Search](https://doi.org/10.1145/3477495.3531748)|Shuai Wang, Harrisen Scells, Justin Clark, Bevan Koopman, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Little+Things+Big+Things+Grow:+A+Collection+with+Seed+Studies+for+Medical+Systematic+Review+Literature+Search)|3|
|[Assessing Student's Dynamic Knowledge State by Exploring the Question Difficulty Effect](https://doi.org/10.1145/3477495.3531939)|Shuanghong Shen, Zhenya Huang, Qi Liu, Yu Su, Shijin Wang, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Student's+Dynamic+Knowledge+State+by+Exploring+the+Question+Difficulty+Effect)|3|
|[MetaCare++: Meta-Learning with Hierarchical Subtyping for Cold-Start Diagnosis Prediction in Healthcare Data](https://doi.org/10.1145/3477495.3532020)|Yanchao Tan, Carl Yang, Xiangyu Wei, Chaochao Chen, Weiming Liu, Longfei Li, Jun Zhou, Xiaolin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaCare++:+Meta-Learning+with+Hierarchical+Subtyping+for+Cold-Start+Diagnosis+Prediction+in+Healthcare+Data)|3|
|[Generalizing to the Future: Mitigating Entity Bias in Fake News Detection](https://doi.org/10.1145/3477495.3531816)|Yongchun Zhu, Qiang Sheng, Juan Cao, Shuokai Li, Danding Wang, Fuzhen Zhuang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalizing+to+the+Future:+Mitigating+Entity+Bias+in+Fake+News+Detection)|3|
|[ORCAS-I: Queries Annotated with Intent using Weak Supervision](https://doi.org/10.1145/3477495.3531737)|Daria Alexander, Wojciech Kusa, Arjen P. de Vries||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ORCAS-I:+Queries+Annotated+with+Intent+using+Weak+Supervision)|3|
|[Unified Dialog Model Pre-training for Task-Oriented Dialog Understanding and Generation](https://doi.org/10.1145/3477495.3532069)|Wanwei He, Yinpei Dai, Min Yang, Jian Sun, Fei Huang, Luo Si, Yongbin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Dialog+Model+Pre-training+for+Task-Oriented+Dialog+Understanding+and+Generation)|3|
|[Introducing Problem Schema with Hierarchical Exercise Graph for Knowledge Tracing](https://doi.org/10.1145/3477495.3532004)|Hanshuang Tong, Zhen Wang, Yun Zhou, Shiwei Tong, Wenyuan Han, Qi Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Introducing+Problem+Schema+with+Hierarchical+Exercise+Graph+for+Knowledge+Tracing)|3|
|[A Flexible Framework for Offline Effectiveness Metrics](https://doi.org/10.1145/3477495.3531924)|Alistair Moffat, Joel Mackenzie, Paul Thomas, Leif Azzopardi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Flexible+Framework+for+Offline+Effectiveness+Metrics)|3|
|[Incorporating Context Graph with Logical Reasoning for Inductive Relation Prediction](https://doi.org/10.1145/3477495.3531996)|Qika Lin, Jun Liu, Fangzhi Xu, Yudai Pan, Yifan Zhu, Lingling Zhang, Tianzhe Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Context+Graph+with+Logical+Reasoning+for+Inductive+Relation+Prediction)|3|
|[Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion](https://doi.org/10.1145/3477495.3531992)|Xiang Chen, Ningyu Zhang, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, Fei Huang, Luo Si, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hybrid+Transformer+with+Multi-level+Fusion+for+Multimodal+Knowledge+Graph+Completion)|3|
|[HTKG: Deep Keyphrase Generation with Neural Hierarchical Topic Guidance](https://doi.org/10.1145/3477495.3531990)|Yuxiang Zhang, Tao Jiang, Tianyu Yang, Xiaoli Li, Suge Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HTKG:+Deep+Keyphrase+Generation+with+Neural+Hierarchical+Topic+Guidance)|3|
|[Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning](https://doi.org/10.1145/3477495.3532016)|Fangzhi Xu, Jun Liu, Qika Lin, Yudai Pan, Lingling Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logiformer:+A+Two-Branch+Graph+Transformer+Network+for+Interpretable+Logical+Reasoning)|3|
|[Constrained Sequence-to-Tree Generation for Hierarchical Text Classification](https://doi.org/10.1145/3477495.3531765)|Chao Yu, Yi Shen, Yue Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constrained+Sequence-to-Tree+Generation+for+Hierarchical+Text+Classification)|3|
|[Answering Count Queries with Explanatory Evidence](https://doi.org/10.1145/3477495.3531870)|Shrestha Ghosh, Simon Razniewski, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Answering+Count+Queries+with+Explanatory+Evidence)|3|
|[Space4HGNN: A Novel, Modularized and Reproducible Platform to Evaluate Heterogeneous Graph Neural Network](https://doi.org/10.1145/3477495.3531720)|Tianyu Zhao, Cheng Yang, Yibo Li, Quan Gan, Zhenyi Wang, Fengqi Liang, Huan Zhao, Yingxia Shao, Xiao Wang, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Space4HGNN:+A+Novel,+Modularized+and+Reproducible+Platform+to+Evaluate+Heterogeneous+Graph+Neural+Network)|3|
|[NeuralKG: An Open Source Library for Diverse Representation Learning of Knowledge Graphs](https://doi.org/10.1145/3477495.3531669)|Wen Zhang, Xiangnan Chen, Zhen Yao, Mingyang Chen, Yushan Zhu, Hongtao Yu, Yufeng Huang, Yajing Xu, Ningyu Zhang, Zezhong Xu, Zonggang Yuan, Feiyu Xiong, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeuralKG:+An+Open+Source+Library+for+Diverse+Representation+Learning+of+Knowledge+Graphs)|3|
|[Deep Knowledge Graph Representation Learning for Completion, Alignment, and Question Answering](https://doi.org/10.1145/3477495.3532679)|Soumen Chakrabarti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Knowledge+Graph+Representation+Learning+for+Completion,+Alignment,+and+Question+Answering)|3|
|[HIEN: Hierarchical Intention Embedding Network for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531988)|Zuowu Zheng, Changwang Zhang, Xiaofeng Gao, Guihai Chen|Tencent Inc., Shenzhen, China; Shanghai Jiao Tong University, Shanghai, China|Click-through rate (CTR) prediction plays an important role in online advertising and recommendation systems, which aims at estimating the probability of a user clicking on a specific item. Feature interaction modeling and user interest modeling methods are two popular domains in CTR prediction, and they have been studied extensively in recent years. However, these methods still suffer from two limitations. First, traditional methods regard item attributes as ID features, while neglecting structure information and relation dependencies among attributes. Second, when mining user interests from user-item interactions, current models ignore user intents and item intents for different attributes, which lacks interpretability. Based on this observation, in this paper, we propose a novel approach Hierarchical Intention Embedding Network (HIEN), which considers dependencies of attributes based on bottom-up tree aggregation in the constructed attribute graph. HIEN also captures user intents for different item attributes as well as item intents based on our proposed hierarchical attention mechanism. Extensive experiments on both public and production datasets show that the proposed model significantly outperforms the state-of-the-art methods. In addition, HIEN can be applied as an input module to state-of-the-art CTR prediction methods, bringing further performance lift for these existing models that might already be intensively used in real systems.|在在线广告和推荐系统中，点进率预测(ctrl)扮演着重要的角色，其目的是估计用户点击特定项目的概率。特征交互建模和用户兴趣建模是 CTR 预测的两个热门领域，近年来得到了广泛的研究。然而，这些方法仍然存在两个局限性。首先，传统的方法把项目属性看作 ID 特征，而忽略了结构信息和属性之间的关系依赖。其次，当从用户-项目交互中挖掘用户兴趣时，目前的模型忽略了不同属性的用户意图和项目意图，缺乏可解释性。在此基础上，本文提出了一种新的层次意图嵌入网络(HIEN)方法，该方法在构造的属性图中考虑基于自底向上树聚集的属性依赖关系。HIEN 还根据我们提出的分层注意机制捕获不同项目属性的用户意图以及项目意图。在公共数据集和生产数据集上的大量实验表明，所提出的模型明显优于最先进的方法。此外，HIEN 还可以作为最先进的 CTR 预测方法的输入模块，为这些可能已经在实际系统中广泛使用的现有模型带来进一步的性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HIEN:+Hierarchical+Intention+Embedding+Network+for+Click-Through+Rate+Prediction)|2|
|[Neural Query Synthesis and Domain-Specific Ranking Templates for Multi-Stage Clinical Trial Matching](https://doi.org/10.1145/3477495.3531853)|Ronak Pradeep, Yilin Li, Yuetong Wang, Jimmy Lin|University of Waterloo, Waterloo, ON, Canada; University of Waterloo, Waterloo, Canada|In this work, we propose an effective multi-stage neural ranking system for the clinical trial matching problem. First, we introduce NQS, a neural query synthesis method that leverages a zero-shot document expansion model to generate multiple sentence-long queries from lengthy patient descriptions. These queries are independently issued to a search engine and the results are fused. We find that on the TREC 2021 Clinical Trials Track, this method outperforms strong traditional baselines like BM25 and BM25 + RM3 by about 12 points in [email protected] , a relative improvement of 34%. This simple method is so effective that even a state-of-the-art neural relevance ranking method trained on the medical subset of MS MARCO passage, when reranking the results of NQS, fails to improve on the ranked list. Second, we introduce a two-stage neural reranking pipeline trained on clinical trial matching data using tailored ranking templates. In this setting, we can train a pointwise reranker using just 1.1k positive examples and obtain effectiveness improvements over NQS by 24 points. This end-to-end multi-stage system demonstrates a 20% relative effectiveness gain compared to the second-best submission at TREC 2021, making it an important step towards better automated clinical trial matching.|在这项工作中，我们提出了一个有效的多阶段神经排序系统的临床试验匹配问题。首先，我们介绍了 NQS，这是一种神经查询合成方法，它利用一个零拍文档扩展模型，从冗长的患者描述中生成多个句子长的查询。这些查询被独立地发送给搜索引擎，并且结果被融合。我们发现，在 TREC 2021临床试验跟踪中，这种方法比强大的传统基线如 BM25和 BM25 + RM3在[ email protected ]中高出约12分，相对提高了34% 。这种简单的方法是如此有效，以至于即使是在 MS MARCO 通道的医学子集上训练的最先进的神经相关性排序方法，在对 NQS 的结果重新排序时，也不能改进排序列表。其次，我们介绍了一个两阶段的神经重新排序管道训练临床试验匹配数据使用定制的排序模板。在这种情况下，我们可以训练一个点态的重新排序使用只有1.1 k 正的例子，并获得24点的有效性改进超过 NQS。这种端到端的多阶段系统与 TREC 2021年第二好的提交相比，显示出20% 的相对有效性增益，这使得它朝着更好的自动化临床试验匹配迈出了重要的一步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Query+Synthesis+and+Domain-Specific+Ranking+Templates+for+Multi-Stage+Clinical+Trial+Matching)|2|
|[Improving Contrastive Learning of Sentence Embeddings with Case-Augmented Positives and Retrieved Negatives](https://doi.org/10.1145/3477495.3531823)|Wei Wang, Liangzhu Ge, Jingqiao Zhang, Cheng Yang|Alibaba Group, Hangzhou, China|Following SimCSE, contrastive learning based methods have achieved the state-of-the-art (SOTA) performance in learning sentence embeddings. However, the unsupervised contrastive learning methods still lag far behind the supervised counterparts. We attribute this to the quality of positive and negative samples, and aim to improve both. Specifically, for positive samples, we propose switch-case augmentation to flip the case of the first letter of randomly selected words in a sentence. This is to counteract the intrinsic bias of pre-trained token embeddings to frequency, word cases and subwords. For negative samples, we sample hard negatives from the whole dataset based on a pre-trained language model. Combining the above two methods with SimCSE, our proposed Contrastive learning with Augmented and Retrieved Data for Sentence embedding (CARDS) method significantly surpasses the current SOTA on STS benchmarks in the unsupervised setting.|继 SimCSE 之后，基于对比学习的方法在学习句子嵌入方面取得了先进的性能。然而，无监督对比学习方法仍然远远落后于有监督对比学习方法。我们将此归因于阳性和阴性样本的质量，并致力于改善这两种情况。特别地，对于正样本，我们提出开关格增强来翻转句子中随机选择的单词的第一个字母的情况。这是为了抵消预先训练的标记嵌入对频率、词例和子词的内在偏差。对于阴性样本，我们基于预训练语言模型从整个数据集中抽取硬阴性样本。将上述两种方法与 SimCSE 相结合，我们提出的对比学习与增强和检索数据的句子嵌入(CARDS)方法显着超过目前的 SOTA 的 STS 基准在无监督的设置。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Contrastive+Learning+of+Sentence+Embeddings+with+Case-Augmented+Positives+and+Retrieved+Negatives)|2|
|[Diversity Vs Relevance: A Practical Multi-objective Study in Luxury Fashion Recommendations](https://doi.org/10.1145/3477495.3531866)|João Sá, Vanessa Queiroz Marinho, Ana Rita Magalhães, Tiago Lacerda, Diogo Gonçalves|Farfetch, London, United Kingdom|Personalized algorithms focusing uniquely on accuracy might provide highly relevant recommendations, but the recommended items could be too similar to current users' preferences. Therefore, recommenders might prevent users from exploring new products and brands (filter bubbles). This is especially critical for luxury fashion recommendations because luxury shoppers expect to discover exclusive and rare items. Thus, recommender systems for fashion need to consider diversity and elevate the shopping experience by recommending new brands and products from the catalog. In this work, we explored a handful of diversification strategies to rerank the output of a relevance-focused recommender system. Subsequently, we conducted a multi-objective offline experiment optimizing for relevance and diversity simultaneously. We measured diversity with commonly used metrics such as coverage, serendipity, and neighborhood distance, whereas, for relevance, we selected ranking metrics such as recall. The best diversification strategy offline improved user engagement by 2% in click-through rate and presented an uplift of 46% in distinct brands recommended when AB tested against real users. These results reinforced the importance of considering accuracy and diversity metrics when developing a recommender system.|专注于准确性的个性化算法可能会提供高度相关的推荐，但推荐的项目可能与当前用户的偏好过于相似。因此，推荐者可能会阻止用户探索新的产品和品牌(过滤气泡)。这对于奢侈品时尚推荐来说尤其重要，因为奢侈品消费者希望发现独一无二的稀有物品。因此，时尚推荐系统需要考虑多样性，并通过推荐目录中的新品牌和产品来提升购物体验。在这项工作中，我们探索了一些多样化策略，以重新排列以相关性为中心的推荐系统的产出。随后，我们进行了多目标离线实验，同时对相关性和多样性进行了优化。我们使用常用的指标(如覆盖率、意外发现和邻近距离)来衡量多样性，而对于相关性，我们选择了排名指标(如回忆)。线下最佳多样化策略提高了2% 的用户参与点进率，当 AB 公司对真实用户进行测试时，推荐的不同品牌的用户参与度提高了46% 。这些结果强调了在开发推荐系统时考虑准确性和多样性指标的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diversity+Vs+Relevance:+A+Practical+Multi-objective+Study+in+Luxury+Fashion+Recommendations)|2|
|[Exploiting Variational Domain-Invariant User Embedding for Partially Overlapped Cross Domain Recommendation](https://doi.org/10.1145/3477495.3531975)|Weiming Liu, Xiaolin Zheng, Jiajie Su, Mengling Hu, Yanchao Tan, Chaochao Chen|Zhejiang University, Hangzhou, China|Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge to solve the cold-start problem in recommender systems. Most of the existing CDR models assume that both the source and target domains share the same overlapped user set for knowledge transfer. However, only few proportion of users simultaneously activate on both the source and target domains in practical CDR tasks. In this paper, we focus on the Partially Overlapped Cross-Domain Recommendation (POCDR) problem, that is, how to leverage the information of both the overlapped and non-overlapped users to improve recommendation performance. Existing approaches cannot fully utilize the useful knowledge behind the non-overlapped users across domains, which limits the model performance when the majority of users turn out to be non-overlapped. To address this issue, we propose an end-to-end Dual-autoencoder with Variational Domain-invariant Embedding Alignment (VDEA) model, a cross-domain recommendation framework for the POCDR problem, which utilizes dual variational autoencoders with both local and global embedding alignment for exploiting domain-invariant user embedding. VDEA first adopts variational inference to capture collaborative user preferences, and then utilizes Gromov-Wasserstein distribution co-clustering optimal transport to cluster the users with similar rating interaction behaviors. Our empirical studies on Douban and Amazon datasets demonstrate that VDEA significantly outperforms the state-of-the-art models, especially under the POCDR setting.|跨域推荐(CDR)是一种利用不同领域知识解决推荐系统冷启动问题的方法。现有的 CDR 模型大多假设源域和目标域共享相同的重叠用户集进行知识转移。然而，在实际的 CDR 任务中，只有少数用户在源域和目标域同时激活。本文主要研究部分重叠跨域推荐(POCDR)问题，即如何利用重叠用户和非重叠用户的信息来提高推荐性能。现有的方法不能充分利用跨领域非重叠用户背后的有用知识，这限制了大多数用户不重叠时的模型性能。针对这一问题，本文提出了一种基于变分域不变嵌入对齐(VDEA)模型的端到端双变分自动编码器，该模型利用具有局部和全局嵌入对齐的双变分自动编码器进行域不变用户嵌入。VDEA 首先采用变分推理获取协同用户偏好，然后利用 Gromov-Wasserstein 分布协聚类最优传输对具有相似评分交互行为的用户进行聚类。我们对 Douban 和亚马逊数据集的实证研究表明，VDEA 显著优于最先进的模型，特别是在 POCDR 设置下。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Variational+Domain-Invariant+User+Embedding+for+Partially+Overlapped+Cross+Domain+Recommendation)|2|
|[Variational Reasoning about User Preferences for Conversational Recommendation](https://doi.org/10.1145/3477495.3532077)|Zhaochun Ren, Zhi Tian, Dongdong Li, Pengjie Ren, Liu Yang, Xin Xin, Huasheng Liang, Maarten de Rijke, Zhumin Chen|WeChat, Tencent, Shenzhen, China; University of Amsterdam, Amsterdam, Netherlands; Shandong University, Qingdao, China|Conversational recommender systems (CRSs) provide recommendations through interactive conversations. CRSs typically provide recommendations through relatively straightforward interactions, where the system continuously inquires about a user's explicit attribute-aware preferences and then decides which items to recommend. In addition, topic tracking is often used to provide naturally sounding responses. However, merely tracking topics is not enough to recognize a user's real preferences in a dialogue. In this paper, we address the problem of accurately recognizing and maintaining user preferences in CRSs. Three challenges come with this problem: (1) An ongoing dialogue only provides the user's short-term feedback; (2) Annotations of user preferences are not available; and (3) There may be complex semantic correlations among items that feature in a dialogue. We tackle these challenges by proposing an end-to-end variational reasoning approach to the task of conversational recommendation. We model both long-term preferences and short-term preferences as latent variables with topical priors for explicit long-term and short-term preference exploration, respectively. We use an efficient stochastic gradient variational Bayesian (SGVB) estimator for optimizing the derived evidence lower bound. A policy network is then used to predict topics for a clarification utterance or items for a recommendation response. The use of explicit sequences of preferences with multi-hop reasoning in a heterogeneous knowledge graph helps to provide more accurate conversational recommendation results. Extensive experiments conducted on two benchmark datasets show that our proposed method outperforms state-of-the-art baselines in terms of both objective and subjective evaluation metric|会话推荐系统(CRS)通过交互式对话提供推荐。CRS 通常通过相对简单的交互提供推荐，系统不断地查询用户的明确的属性感知偏好，然后决定推荐哪些项目。此外，主题跟踪通常用于提供听起来很自然的回答。但是，仅仅跟踪主题不足以识别用户在对话中的真实偏好。在本文中，我们解决了准确识别和维护用户偏好的问题。这个问题带来了三个挑战: (1)持续的对话只提供用户的短期反馈; (2)用户偏好的注释不可用; (3)对话中的项目之间可能存在复杂的语义关联。我们通过提出一种端到端的变分推理方法来解决这些挑战。我们将长期偏好和短期偏好分别建模为具有主题先验的潜在变量，用于显性长期和短期偏好探索。我们使用一个有效的随机梯度变分贝叶斯(SGVB)估计器来优化导出的证据下界。然后使用策略网络来预测澄清话语的主题或推荐响应的项目。在异构知识图中使用多跳推理的显式偏好序列有助于提供更准确的会话推荐结果。在两个基准数据集上进行的大量实验表明，我们提出的方法在客观和主观评价指标方面都优于最先进的基准|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Variational+Reasoning+about+User+Preferences+for+Conversational+Recommendation)|2|
|[Analyzing and Simulating User Utterance Reformulation in Conversational Recommender Systems](https://doi.org/10.1145/3477495.3531936)|Shuo Zhang, MuChun Wang, Krisztian Balog|Bloomberg, London, United Kingdom; University of Science and Technology of China, Hefei, China; University of Stavanger, Stavanger, Norway|User simulation has been a cost-effective technique for evaluating conversational recommender systems. However, building a human-like simulator is still an open challenge. In this work, we focus on how users reformulate their utterances when a conversational agent fails to understand them. First, we perform a user study, involving five conversational agents across different domains, to identify common reformulation types and their transition relationships. A common pattern that emerges is that persistent users would first try to rephrase, then simplify, before giving up. Next, to incorporate the observed reformulation behavior in a user simulator, we introduce the task of reformulation sequence generation: to generate a sequence of reformulated utterances with a given intent (rephrase or simplify). We develop methods by extending transformer models guided by the reformulation type and perform further filtering based on estimated reading difficulty. We demonstrate the effectiveness of our approach using both automatic and human evaluation.|用户仿真已经成为评估会话推荐系统的一种经济有效的技术。然而，建立一个类似人的模拟器仍然是一个公开的挑战。在这项工作中，我们的重点是如何用户重新组织他们的话语时，一个会话代理无法理解他们。首先，我们进行了一个用户研究，涉及五个不同领域的会话代理，以确定常见的重构类型及其转换关系。出现的一种常见模式是，持久用户在放弃之前会首先尝试重新措辞，然后进行简化。接下来，为了在用户模拟器中整合观察到的重新表述行为，我们引入了重新表述序列生成的任务: 生成具有给定意图(重新表述或简化)的重新表述话语序列。我们发展的方法，扩展变压器模型指导下的重新公式类型和进一步滤波的基础上估计读取困难。我们使用自动评估和人工评估证明了我们的方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+and+Simulating+User+Utterance+Reformulation+in+Conversational+Recommender+Systems)|2|
|[Learning to Infer User Implicit Preference in Conversational Recommendation](https://doi.org/10.1145/3477495.3531844)|Chenhao Hu, Shuhua Huang, Yansen Zhang, Yubao Liu|Sun Yat-Sen University & Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China|Conversational recommender systems (CRS) enable traditional recommender systems to interact with users by asking questions about attributes and recommending items. The attribute-level and item-level feedback of users can be utilized to estimate users' preferences. However, existing works do not fully exploit the advantage of explicit item feedback --- they only use the item feedback in rather implicit ways such as updating the latent user and item representation. Since CRS has multiple chances to interact with users, leveraging the context in the conversation may help infer users' implicit feedback (e.g., some specific attributes) when recommendations get rejected. To address the limitations of existing methods, we propose a new CRS framework called Conversational Recommender with Implicit Feedback (CRIF). CRIF formulates the conversational recommendation scheme as a four-phase process consisting of offline representation learning, tracking, decision, and inference. In the inference module, by fully utilizing the relation between users' attribute-level and item-level feedback, our method can explicitly deduce users' implicit preferences. Therefore, CRIF is able to achieve more accurate user preference estimation. Besides, in the decision module, to better utilize the attribute-level and item-level feedback, we adopt inverse reinforcement learning to learn a flexible decision strategy that selects the suitable action at each conversation turn. Through extensive experiments on four benchmark CRS datasets, we validate the effectiveness of our approach, which significantly outperforms the state-of-the-art CRS methods.|会话推荐系统(CRS)使得传统的推荐系统能够通过询问关于属性的问题和推荐项目与用户进行交互。用户的属性级反馈和项目级反馈可以用来估计用户的偏好。然而，现有的作品并没有充分利用显式项目反馈的优势——他们只是以相当隐式的方式使用项目反馈，比如更新潜在用户和项目表示。由于 CRS 有多个与用户交互的机会，当推荐被拒绝时，利用会话中的上下文可能有助于推断用户的隐式反馈(例如，一些特定的属性)。为了解决现有方法的局限性，我们提出了一个新的 CRS 框架，称为隐式反馈会话推荐(CRIF)。CRIF 将会话推荐方案设计为离线表征学习、跟踪、决策和推理四个阶段。在推理模块中，通过充分利用用户属性级反馈和项目级反馈之间的关系，可以明确推断出用户的隐性偏好。因此，CRIF 能够实现更准确的用户偏好估计。此外，在决策模块中，为了更好地利用属性级别和项目级别的反馈，我们采用逆向强化学习学习灵活的决策策略，在每次谈话转折点选择合适的行动。通过对四个基准 CRS 数据集的大量实验，我们验证了该方法的有效性，其性能明显优于目前最先进的 CRS 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Infer+User+Implicit+Preference+in+Conversational+Recommendation)|2|
|[Recognizing Medical Search Query Intent by Few-shot Learning](https://doi.org/10.1145/3477495.3531789)|Yaqing Wang, Song Wang, Yanyan Li, Dejing Dou|Baidu Inc., Beijing, China; Baidu Inc. & University of Virginia, Beijing, China|Online healthcare services can provide unlimited and in-time medical information to users, which promotes social goods and breaks the barriers of locations. However, understanding the user intents behind the medical related queries is a challenging problem. Medical search queries are usually short and noisy, lack strict syntactic structure, and also require professional background to understand the medical terms. The medical intents are fine-grained, making them hard to recognize. In addition, many intents only have a few labeled data. To handle these problems, we propose a few-shot learning method for medical search query intent recognition called MEDIC. We extract co-click queries from user search logs as weak supervision to compensate for the lack of labeled data. We also design a new query encoder which learns to represent queries as a combination of semantic knowledge recorded in an external medical knowledge graph, syntactic knowledge which marks the grammatical role of each word in the query, and generic knowledge which is captured by language models pretrained from large-scale text corpus. Experimental results on a real medical search query intent recognition dataset validate the effectiveness of MEDIC.|在线医疗服务可以向用户提供无限制和及时的医疗信息，促进社会商品，打破地理位置的障碍。然而，理解医疗相关查询背后的用户意图是一个具有挑战性的问题。医学检索查询通常短小而嘈杂，缺乏严格的句法结构，而且需要专业背景才能理解医学术语。医学意图是细粒度的，很难识别。此外，许多意图只有少量带标签的数据。针对这些问题，本文提出了一种基于少镜头学习的医学搜索查询意图识别方法 MEDIC。我们从用户搜索日志中提取共同点击查询作为薄弱的监督，以弥补标记数据的缺乏。我们还设计了一种新的查询编码器，该编码器学习将外部医学知识图中记录的语义知识、标记查询中每个词语法角色的句法知识以及从大规模文本语料库中预先训练的语言模型获取的通用知识组合起来来表示查询。在一个真实的医学搜索查询意图识别数据集上的实验结果验证了 MEDIC 算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recognizing+Medical+Search+Query+Intent+by+Few-shot+Learning)|2|
|[PERD: Personalized Emoji Recommendation with Dynamic User Preference](https://doi.org/10.1145/3477495.3531779)|Xuanzhi Zheng, Guoshuai Zhao, Li Zhu, Xueming Qian|Xi'an Jiaotong University, Xi'an, China|Emoji recommendation is an important task to help users find appropriate emojis from thousands of candidates based on a short tweet text. Traditional emoji recommendation methods lack personalized recommendation and ignore user historical information in selecting emojis. In this paper, we propose a personalized emoji recommendation with dynamic user preference (PERD) which contains a text encoder and a personalized attention mechanism. In text encoder, a BERT model is contained to learn dense and low-dimensional representations of tweets. In personalized attention, user dynamic preferences are learned according to semantic and sentimental similarity between historical tweets and the tweet which is waiting for emoji recommendation. Informative historical tweets are selected and highlighted. Experiments are carried out on two real-world datasets from Sina Weibo and Twitter. Experimental results validate the superiority of our approach on personalized emoji recommendation.|表情符号推荐是一项重要的任务，它可以帮助用户根据一条短短的推文从数千名候选人中找到合适的表情符号。传统的表情符号推荐方法缺乏个性化推荐，在选择表情符号时忽略了用户的历史信息。本文提出了一种基于动态用户偏好的个性化表情推荐(PERD) ，它包含一个文本编码器和一个个性化的注意机制。在文本编码器中，BERT 模型用于学习 tweet 的稠密和低维表示。在个性化关注中，根据历史推文和等待表情推荐的推文之间的语义和情感相似性来学习用户的动态偏好。选择并突出显示信息丰富的历史 tweet。实验是在来自新浪微博和推特的两个真实世界的数据集上进行的。实验结果验证了该方法在个性化表情符号推荐中的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PERD:+Personalized+Emoji+Recommendation+with+Dynamic+User+Preference)|2|
|[Sequential/Session-based Recommendations: Challenges, Approaches, Applications and Opportunities](https://doi.org/10.1145/3477495.3532685)|Shoujin Wang, Qi Zhang, Liang Hu, Xiuzhen Zhang, Yan Wang, Charu Aggarwal|RMIT University, Melbourne, Australia; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; RMIT University & Macquarie University, Melbourne , Australia; Macquarie University, Sydney , Australia; Tongji University, Shanghai , China; DeepBlue Academy of Sciences, Shanghai, China|In recent years, sequential recommender systems (SRSs) and session-based recommender systems (SBRSs) have emerged as a new paradigm of RSs to capture users' short-term but dynamic preferences for enabling more timely and accurate recommendations. Although SRSs and SBRSs have been extensively studied, there are many inconsistencies in this area caused by the diverse descriptions, settings, assumptions and application domains. There is no work to provide a unified framework and problem statement to remove the commonly existing and various inconsistencies in the area of SR/SBR. There is a lack of work to provide a comprehensive and systematic demonstration of the data characteristics, key challenges, most representative and state-of-the-art approaches, typical real- world applications and important future research directions in the area. This work aims to fill in these gaps so as to facilitate further research in this exciting and vibrant area.|近年来，顺序推荐系统(SRS)和基于会话的推荐系统(SBRS)已经成为一种新的 RSS 模式，它们可以捕获用户短期的动态偏好，从而实现更及时、更准确的推荐。尽管 SRS 和 SBRS 已经得到了广泛的研究，但是由于描述、设置、假设和应用领域的不同，在这个领域还存在着许多不一致之处。目前还没有提供一个统一的框架和问题说明来消除 SR/SBR 领域中普遍存在的各种不一致之处。目前缺乏对数据特征、主要挑战、最具代表性和最先进的方法、典型的现实世界应用和该领域未来重要研究方向进行全面和系统的论证的工作。这项工作旨在填补这些空白，以促进在这个令人兴奋和充满活力的领域的进一步研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential/Session-based+Recommendations:+Challenges,+Approaches,+Applications+and+Opportunities)|2|
|[Probabilistic Permutation Graph Search: Black-Box Optimization for Fairness in Ranking](https://doi.org/10.1145/3477495.3532045)|Ali Vardasbi, Fatemeh Sarvi, Maarten de Rijke|University of Amsterdam, Amsterdam, Netherlands|There are several measures for fairness in ranking, based on different underlying assumptions and perspectives. \acPL optimization with the REINFORCE algorithm can be used for optimizing black-box objective functions over permutations. In particular, it can be used for optimizing fairness measures. However, though effective for queries with a moderate number of repeating sessions, \acPL optimization has room for improvement for queries with a small number of repeating sessions. In this paper, we present a novel way of representing permutation distributions, based on the notion of permutation graphs. Similar to~\acPL, our distribution representation, called~\acPPG, can be used for black-box optimization of fairness. Different from~\acPL, where pointwise logits are used as the distribution parameters, in~\acPPG pairwise inversion probabilities together with a reference permutation construct the distribution. As such, the reference permutation can be set to the best sampled permutation regarding the objective function, making~\acPPG suitable for both deterministic and stochastic rankings. Our experiments show that~\acPPG, while comparable to~\acPL for larger session repetitions (i.e., stochastic ranking), improves over~\acPL for optimizing fairness metrics for queries with one session (i.e., deterministic ranking). Additionally, when accurate utility estimations are available, e.g., in tabular models, the performance of \acPPG in fairness optimization is significantly boosted compared to lower quality utility estimations from a learning to rank model, leading to a large performance gap with PL. Finally, the pairwise probabilities make it possible to impose pairwise constraints such as "item $d_1$ should always be ranked higher than item $d_2$.'' Such constraints can be used to simultaneously optimize the fairness metric and control another objective such as ranking performance.|根据不同的基本假设和观点，有几种衡量排名公平性的方法。使用 REINFORCE 算法的 acPL 优化可以用于优化黑盒目标函数。特别是可以用来优化公平性措施。然而，尽管对于具有中等数量重复会话的查询有效，但是对于具有少量重复会话的查询，acPL 优化还有改进的空间。本文基于置换图的概念，提出了一种表示置换分布的新方法。与 ~ acPL 类似，我们的分布表示(称为 ~ acPPG)可以用于公平性的黑盒优化。与以逐点对数作为分布参数的 ~ acPPG 不同，在 ~ acPPG 中成对反演概率与参考置换构成分布。因此，对于目标函数，可以将参考排序设置为最佳采样排序，使 ~ acPPG 既适用于确定性排序，也适用于随机排序。我们的实验表明 ~ acPPG 在较大的会话重复(即随机排名)方面与 ~ acPL 相当，但在优化一个会话查询(即确定性排名)的公平性指标方面优于 ~ acPL。此外，当准确的效用估计可用时，例如在表格模型中，acPPG 在公平优化中的表现显着提高，与来自学习到等级模型的较低质量效用估计相比，导致与 PL 的巨大性能差距。最后，成对概率使得可以施加成对约束，例如“项 $d _ 1 $应该总是排在项 $d _ 2 $之前”这种约束可以用来同时优化公平性度量和控制另一个目标，如排名性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Probabilistic+Permutation+Graph+Search:+Black-Box+Optimization+for+Fairness+in+Ranking)|2|
|[Less is More: Reweighting Important Spectral Graph Features for Recommendation](https://doi.org/10.1145/3477495.3532014)|Shaowen Peng, Kazunari Sugiyama, Tsunenori Mine|Kyushu University, Fukuoka, Japan; Kyoto University, Kyoto, Japan|As much as Graph Convolutional Networks (GCNs) have shown tremendous success in recommender systems and collaborative filtering (CF), the mechanism of how they, especially the core components (\textiti.e., neighborhood aggregation) contribute to recommendation has not been well studied. To unveil the effectiveness of GCNs for recommendation, we first analyze them in a spectral perspective and discover two important findings: (1) only a small portion of spectral graph features that emphasize the neighborhood smoothness and difference contribute to the recommendation accuracy, whereas most graph information can be considered as noise that even reduces the performance, and (2) repetition of the neighborhood aggregation emphasizes smoothed features and filters out noise information in an ineffective way. Based on the two findings above, we propose a new GCN learning scheme for recommendation by replacing neihgborhood aggregation with a simple yet effective Graph Denoising Encoder (GDE), which acts as a band pass filter to capture important graph features. We show that our proposed method alleviates the over-smoothing and is comparable to an indefinite-layer GCN that can take any-hop neighborhood into consideration. Finally, we dynamically adjust the gradients over the negative samples to expedite model training without introducing additional complexity. Extensive experiments on five real-world datasets show that our proposed method not only outperforms state-of-the-arts but also achieves 12x speedup over LightGCN.|尽管图形卷积网络在推荐系统和协同过滤(CF)方面取得了巨大的成功，但其核心组件(textititi.e. 邻域聚合)对推荐的贡献机制还没有得到很好的研究。为了揭示 GCNs 在推荐中的有效性，我们首先从谱的角度分析它们，发现两个重要的结果: (1)只有一小部分强调邻域平滑和差异的谱图特征有助于推荐精度，而大多数图形信息可以被视为噪声，甚至降低性能; (2)重复的邻域聚合强调平滑的特征，并以无效的方式过滤掉噪声信息。基于以上两个发现，我们提出了一种新的 GCN 推荐学习方案，用一种简单而有效的图形去噪编码器(GDE)代替邻域聚合，GDE 作为带通滤波器来捕捉重要的图形特征。结果表明，我们提出的方法减轻了过度平滑，并可比拟一个不确定层 GCN，可以考虑任何跳邻居。最后，我们动态调整负样本上的梯度，以加快模型训练而不引入额外的复杂性。在五个真实世界数据集上的大量实验表明，我们提出的方法不仅优于最新技术，而且比 LightGCN 提高了12倍的速度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Less+is+More:+Reweighting+Important+Spectral+Graph+Features+for+Recommendation)|2|
|[Interpolative Distillation for Unifying Biased and Debiased Recommendation](https://doi.org/10.1145/3477495.3532002)|Sihao Ding, Fuli Feng, Xiangnan He, Jinqiu Jin, Wenjie Wang, Yong Liao, Yongdong Zhang|University of Science and Technology of China, Hefei, China; National University of Singapore, Singapore, China; University of Science and Technology of China & CCCD Key Lab of MCT, Hefei, China|Most recommender systems evaluate model performance offline through either: 1) normal biased test on factual interactions; or 2) debiased test with records from the randomized controlled trial. In fact, both tests only reflect part of the whole picture: factual interactions are collected from the recommendation policy, fitting them better implies benefiting the platform with higher click or conversion rate; in contrast, debiased test eliminates system-induced biases and thus is more reflective of user true preference. Nevertheless, we find that existing models exhibit trade-off on the two tests, and there lacks methods that perform well on both tests. In this work, we aim to develop a win-win recommendation method that is strong on both tests. It is non-trivial, since it requires to learn a model that can make accurate prediction in both factual environment (ie normal biased test) and counterfactual environment (ie debiased test). Towards the goal, we perform environment-aware recommendation modeling by considering both environments. In particular, we propose an Interpolative Distillation (InterD) framework, which interpolates the biased and debiased models at user-item pair level by distilling a student model. We conduct experiments on three real-world datasets with both tests. Empirical results justify the rationality and effectiveness of InterD, which stands out on both tests especially demonstrates remarkable gains on less popular items.|大多数推荐系统通过以下两种方式评估模型的离线性能: 1)对实际交互进行正常偏向测试; 或者2)利用随机对照试验记录进行偏向测试。事实上，这两个测试只反映了整体情况的一部分: 实际的交互是从推荐策略中收集的，更好地适应它们意味着更高的点击率或转化率有利于平台; 相反，去偏向测试消除了系统引起的偏见，因此更能反映用户的真实偏好。尽管如此，我们发现现有的模型在两个测试中表现出了折衷，并且缺乏在两个测试中都表现良好的方法。在这项工作中，我们的目标是开发一个双赢的推荐方法，在两个测试中都很强。它是非平凡的，因为它需要学习一个模型，可以作出准确的预测既在事实环境(即正常偏向测试)和反事实环境(即去偏向测试)。为了实现这个目标，我们通过考虑两种环境来执行环境感知的推荐建模。特别地，我们提出了一个插值蒸馏(InterD)框架，它通过提取学生模型在用户项目对水平上插值有偏和无偏模型。我们用这两个测试在三个真实世界的数据集上进行实验。实证结果证明了 InterD 的合理性和有效性，它在两个测试中都表现突出，尤其是在不太受欢迎的项目上表现出显著的收益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpolative+Distillation+for+Unifying+Biased+and+Debiased+Recommendation)|2|
|[Enhancing Hypergraph Neural Networks with Intent Disentanglement for Session-based Recommendation](https://doi.org/10.1145/3477495.3531794)|Yinfeng Li, Chen Gao, Hengliang Luo, Depeng Jin, Yong Li|Meituan Inc., Beijing, China; Tsinghua University, Beijing, China|Session-based recommendation (SBR) aims at the next-item prediction with a short behavior session. Existing solutions fail to address two main challenges: 1) user interests are shown as dynamically coupled intents, and 2) sessions always contain noisy signals. To address them, in this paper, we propose a hypergraph-based solution, HIDE. Specifically, HIDE first constructs a hypergraph for each session to model the possible interest transitions from distinct perspectives. HIDE then disentangles the intents under each item click in micro and macro manners. In the micro-disentanglement, we perform intent-aware embedding propagation on session hypergraph to adaptively activate disentangled intents from noisy data. In the macro-disentanglement, we introduce an auxiliary intent-classification task to encourage the independence of different intents. Finally, we generate the intent-specific representations for the given session to make the final recommendation. Benchmark evaluations demonstrate the significant performance gain of our HIDE over the state-of-the-art methods.|基于会话的推荐(SBR)针对具有短行为会话的下一项预测。现有的解决方案未能解决两个主要挑战: 1)用户兴趣以动态耦合意图的形式显示，2)会话总是包含噪声信号。为了解决这些问题，本文提出了一种基于超图的解决方案—— HIDE。具体来说，HIDE 首先为每个会话构造一个超图，从不同的角度对可能的兴趣转换进行建模。然后隐藏解开每个项目下的微观和宏观方式点击的意图。在微分离中，我们在会话超图上进行意图感知的嵌入传播，以自适应地激活噪声数据中的意图。在宏观分离中，我们引入了一个辅助的意图分类任务，以鼓励不同意图的独立性。最后，我们为给定的会话生成特定于意图的表示以提出最终的建议。基准评估显示了我们的 HIDE 相对于最先进的方法的显著性能增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Hypergraph+Neural+Networks+with+Intent+Disentanglement+for+Session-based+Recommendation)|2|
|[Generative Adversarial Framework for Cold-Start Item Recommendation](https://doi.org/10.1145/3477495.3531897)|Hao Chen, Zefan Wang, Feiran Huang, Xiao Huang, Yue Xu, Yishi Lin, Peng He, Zhoujun Li|Jinan University, Guangzhou, China; Beihang University, Beijing, China; The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Alibaba Group, Hangzhou, China; Tencent Inc., Shenzhen, China|The cold-start problem has been a long-standing issue in recommendation. Embedding-based recommendation models provide recommendations by learning embeddings for each user and item from historical interactions. Therefore, such embedding-based models perform badly for cold items which haven't emerged in the training set. The most common solutions are to generate the cold embedding for the cold item from its content features. However, the cold embeddings generated from contents have different distribution as the warm embeddings are learned from historical interactions. In this case, current cold-start methods are facing an interesting seesaw phenomenon, which improves the recommendation of either the cold items or the warm items but hurts the opposite ones. To this end, we propose a general framework named Generative Adversarial Recommendation (GAR). By training the generator and the recommender adversarially, the generated cold item embeddings can have similar distribution as the warm embeddings that can even fool the recommender. Simultaneously, the recommender is fine-tuned to correctly rank the "fake'' warm embeddings and the real warm embeddings. Consequently, the recommendation of the warms and the colds will not influence each other, thus avoiding the seesaw phenomenon. Additionally, GAR could be applied to any off-the-shelf recommendation model. Experiments on two datasets present that GAR has strong overall recommendation performance in cold-starting both the CF-based model (improved by over 30.18%) and the GNN-based model (improved by over 17.78%).|冷启动问题一直是建议中的一个长期存在的问题。基于嵌入的推荐模型通过从历史交互中学习每个用户和项目的嵌入来提供推荐。因此，这种基于嵌入的模型对于训练集中没有出现的冷项目表现很差。最常见的解决方案是根据冷藏项目的内容特征生成冷藏嵌入。然而，由内容所产生的冷嵌体在历史互动中学习到的热嵌体，其分布是不同的。在这种情况下，目前的冷启动方法正面临着一个有趣的跷跷板现象，这改善了推荐的冷项目或温暖的项目，但伤害了相反的。为此，我们提出了一个名为生成对抗性建议(GAR)的通用框架。通过对生成器和推荐器进行对抗性训练，生成的冷嵌入项可以像暖嵌入项一样具有相似的分布，甚至可以欺骗推荐器。同时，对推荐进行微调，以正确排列“假的”暖嵌入和真正的暖嵌入。因此，建议的温暖和寒冷将不会相互影响，从而避免跷跷板现象。此外，GAR 可以应用于任何现成的推荐模型。在两个数据集上的实验表明，GAR 在冷启动基于 CF 的模型(改进超过30.18%)和基于 GNN 的模型(改进超过17.78%)方面具有很强的总体推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Adversarial+Framework+for+Cold-Start+Item+Recommendation)|2|
|[Dynamics-Aware Adaptation for Reinforcement Learning Based Cross-Domain Interactive Recommendation](https://doi.org/10.1145/3477495.3531969)|Junda Wu, Zhihui Xie, Tong Yu, Handong Zhao, Ruiyi Zhang, Shuai Li|Adobe Research, San Jose, CA, USA; New York University, New York, NY, USA; Shanghai Jiao Tong University, Shanghai, China|Interactive recommender systems (IRS) have received wide attention in recent years. To capture users' dynamic preferences and maximize their long-term engagement, IRS are usually formulated as reinforcement learning (RL) problems. Despite the promise to solve complex decision-making problems, RL-based methods generally require a large amount of online interaction, restricting their applications due to economic considerations. One possible direction to alleviate this issue is cross-domain recommendation that aims to leverage abundant logged interaction data from a source domain (e.g., adventure genre in movie recommendation) to improve the recommendation quality in the target domain (e.g., crime genre). Nevertheless, prior studies mostly focus on adapting the static representations of users/items. Few have explored how the temporally dynamic user-item interaction patterns transform across domains. Motivated by the above consideration, we propose DACIR, a novel Doubly-Adaptive deep RL-based framework for Cross-domain Interactive Recommendation. We first pinpoint how users behave differently in two domains and highlight the potential to leverage the shared user dynamics to boost IRS. To transfer static user preferences across domains, DACIR enforces consistency of item representation by aligning embeddings into a shared latent space. In addition, given the user dynamics in IRS, DACIR calibrates the dynamic interaction patterns in two domains via reward correlation. Once the double adaptation narrows the cross-domain gap, we are able to learn a transferable policy for the target recommender by leveraging logged data. Experiments on real-world datasets validate the superiority of our approach, which consistently achieves significant improvements over the baselines.|交互式推荐系统(IRS)近年来受到了广泛的关注。为了捕捉用户的动态偏好并最大化他们的长期参与，IRS 通常被定义为强化学习(RL)问题。尽管有望解决复杂的决策问题，但基于 RL 的方法通常需要大量的在线交互，出于经济考虑，限制了它们的应用。缓解这个问题的一个可能的方向是跨域推荐，旨在利用来自源域的大量日志交互数据(例如，电影推荐中的冒险类型)来提高目标域的推荐质量(例如，犯罪类型)。尽管如此，以往的研究主要集中在调整用户/项目的静态表征。很少有人研究过时态动态的用户项交互模式如何跨域转换。基于上述考虑，我们提出了一种新的基于双重自适应深度 RL 的跨域交互推荐框架 DACIR。我们首先精确地指出用户在两个领域中的不同行为，并强调利用共享用户动态来提高 IRS 的潜力。为了跨域传输静态用户首选项，DACIR 通过将嵌入对齐到共享的潜在空间来实现项表示的一致性。此外，给定 IRS 中的用户动态，DACIR 通过奖励相关校正两个域中的动态交互模式。一旦双重适应缩小了跨域间的差距，我们就能够通过利用已记录的数据为目标推荐程序学习一种可转移的策略。在实际数据集上的实验验证了该方法的优越性，在基线上取得了明显的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamics-Aware+Adaptation+for+Reinforcement+Learning+Based+Cross-Domain+Interactive+Recommendation)|2|
|[A Study of Cross-Session Cross-Device Search Within an Academic Digital Library](https://doi.org/10.1145/3477495.3531929)|Sebastian Gomes, Miriam Boon, Orland Hoeber|University of Regina, Regina, SK, Canada|Information seeking in an academic digital library is complex in nature, often spanning multiple search sessions. Resuming academic search tasks requires significant cognitive effort as searchers must re-acquaint themselves with previous search session activities and previously discovered documents before resuming their search. Further, some academic searchers may find it convenient to initiate such searches on their mobile devices during short gaps in time (e.g., between classes), and resume them later in a desktop environment when they can use the extra screen space and more convenient document storage capabilities of their computers. To support such searching, we have developed an academic digital library search interface that assists searchers in managing cross-session search tasks even when moving between mobile and desktop environments. Using a controlled laboratory study we compared our approach (Dilex) to a standard academic digital library search interface. We found increased user engagement in both the initial (mobile) and resumed (desktop) search activities, and that participants spent more time on the search results pages and had an increased degree of interaction with information and personalization features during the resumed tasks. These results provide evidence that the participants were able to make effective use of the visualization features in Dilex, which enabled them to readily resume their search tasks and stay engaged in the search activities. This work represents an example of how semi-automatic search task/session management and visualization features can support cross-session search, and how designing for both mobile and desktop use can support cross-device search.|学术数字图书馆的信息搜索本质上是复杂的，通常跨越多个搜索环节。恢复学术搜索任务需要大量的认知努力，因为搜索者必须在恢复搜索之前重新熟悉以前的搜索会话活动和以前发现的文档。此外，部分学术搜寻人士可能会觉得在短时间内(例如课间)在流动装置上进行这类搜寻比较方便，稍后当他们可以使用电脑额外的屏幕空间和更方便的文件储存功能时，便可在桌面环境中继续进行这类搜寻。为了支持这种搜索，我们开发了一个学术数字图书馆搜索界面，协助搜索人员管理跨会话搜索任务，即使在移动和桌面环境之间移动。使用一个受控的实验室研究，我们比较了我们的方法(Dilex)与标准的学术数字图书馆搜索界面。我们发现，用户在初始(移动)和恢复(桌面)搜索活动中的参与度都有所提高，参与者在搜索结果页面上花费的时间更多，在恢复任务期间与信息和个性化功能的交互程度也有所提高。这些结果证明参与者能够有效地利用 Dilex 的可视化功能，使他们能够随时恢复搜索任务并继续参与搜索活动。这项工作代表了一个半自动搜索任务/会话管理和可视化特性如何支持跨会话搜索的例子，以及如何设计为移动和桌面使用都可以支持跨设备搜索。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Study+of+Cross-Session+Cross-Device+Search+Within+an+Academic+Digital+Library)|2|
|[Locality-Sensitive State-Guided Experience Replay Optimization for Sparse Rewards in Online Recommendation](https://doi.org/10.1145/3477495.3532015)|Xiaocong Chen, Lina Yao, Julian J. McAuley, Weili Guan, Xiaojun Chang, Xianzhi Wang|University of New South Wales, Sydney, NSW, Australia; Monash University, Melbourne, VIC, Australia; University of Technology Sydney, Sydney, NSW, Australia; University of California, San Diego, San Diego, CA, USA|Online recommendation requires handling rapidly changing user preferences. Deep reinforcement learning (DRL) is an effective means of capturing users' dynamic interest during interactions with recommender systems. Generally, it is challenging to train a DRL agent in online recommender systems because of the sparse rewards caused by the large action space (e.g., candidate item space) and comparatively fewer user interactions. Leveraging experience replay (ER) has been extensively studied to conquer the issue of sparse rewards. However, they adapt poorly to the complex environment of online recommender systems and are inefficient in learning an optimal strategy from past experience. As a step to filling this gap, we propose a novel state-aware experience replay model, in which the agent selectively discovers the most relevant and salient experiences and is guided to find the optimal policy for online recommendations. In particular, a locality-sensitive hashing method is proposed to selectively retain the most meaningful experience at scale and a prioritized reward-driven strategy is designed to replay more valuable experiences with higher chance. We formally show that the proposed method guarantees the upper and lower bound on experience replay and optimizes the space complexity, as well as empirically demonstrate our model's superiority to several existing experience replay methods over three benchmark simulation platforms.|在线推荐需要处理快速变化的用户首选项。深度强化学习(DRL)是在与推荐系统交互时捕捉用户动态兴趣的有效手段。一般来说，在在线推荐系统中训练 DRL 代理是一个挑战，因为大的动作空间(例如候选项空间)和相对较少的用户交互造成了稀疏的奖励。杠杆经验重放(ER)已被广泛研究，以克服稀疏奖励的问题。然而，它们不能很好地适应在线推荐系统的复杂环境，并且在从过去的经验中学习最佳策略方面效率低下。作为填补这一空白的一个步骤，我们提出了一个新的状态感知经验重放模型，其中代理人选择性地发现最相关和突出的经验，并指导寻找最佳策略的在线推荐。特别是，一个局部性敏感哈希的方法被提出来选择性地保留大规模的最有意义的经验，一个优先奖励驱动的策略被设计来回放更有价值的经验和更高的机会。在三个基准仿真平台上，我们正式证明了该方法保证了经验重放的上下界，优化了空间复杂度，并且实证证明了该模型相对于现有的几种经验重放方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Locality-Sensitive+State-Guided+Experience+Replay+Optimization+for+Sparse+Rewards+in+Online+Recommendation)|2|
|[An Attribute-Driven Mirror Graph Network for Session-based Recommendation](https://doi.org/10.1145/3477495.3531935)|Siqi Lai, Erli Meng, Fan Zhang, Chenliang Li, Bin Wang, Aixin Sun|Wuhan University, Wuhan, China; Xiaomi.com, Beijing, China; Nanyang Technological University, Singapore, Singapore, Singapore|Session-based recommendation (SBR) aims to predict a user's next clicked item based on an anonymous yet short interaction sequence. Previous SBR models, which rely only on the limited short-term transition information without utilizing extra valuable knowledge, have suffered a lot from the problem of data sparsity. This paper proposes a novel mirror graph enhanced neural model for session-based recommendation (MGS), to exploit item attribute information over item embeddings for more accurate preference estimation. Specifically, MGS utilizes two kinds of graphs to learn item representations. One is a session graph generated from the user interaction sequence describing users' preference based on transition patterns. Another is a mirror graph built by an attribute-aware module that selects the most attribute-representative information for each session item by integrating items' attribute information. We applied an iterative dual refinement mechanism to propagate information between the session and mirror graphs. To further guide the training process of the attribute-aware module, we also introduce a contrastive learning strategy that compares two mirror graphs generated for the same session by randomly sampling the attribute-same neighbors. Experiments on three real-world datasets exhibit that the performance of MGS surpasses many state-of-the-art models.|基于会话(Session-based)的推荐(SBR)旨在基于一个匿名但很短的交互序列来预测用户的下一个点击项目。以往的 SBR 模型仅仅依赖于有限的短期转换信息，而没有利用额外的有价值的知识，已经遭受了很多数据稀疏的问题。提出了一种新的基于会话推荐(MGS)的镜像图增强神经网络模型，利用项目属性信息对项目嵌入进行更精确的偏好估计。具体来说，MGS 利用两种图来学习项目表示。一个是由用户交互序列生成的会话图，描述基于转换模式的用户偏好。另一个是由属性感知模块构建的镜像图，该模块通过集成会话项的属性信息来为每个会话项选择最具代表性的属性信息。我们应用一个迭代对偶精化机制来传播会话和镜像图之间的信息。为了进一步指导属性感知模块的训练过程，我们还引入了一种对比学习策略，通过对属性相同的邻居进行随机抽样，比较同一会话中生成的两个镜像图。在三个实际数据集上的实验表明，MGS 的性能优于许多最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Attribute-Driven+Mirror+Graph+Network+for+Session-based+Recommendation)|2|
|[FUM: Fine-grained and Fast User Modeling for News Recommendation](https://doi.org/10.1145/3477495.3531790)|Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang|Microsoft Research Asia, Beijing, China; Tsinghua University, Beijing, China; Tsinghua Unvisersity, Beijing, China|User modeling is important for news recommendation. Existing methods usually first encode user's clicked news into news embeddings independently and then aggregate them into user embedding. However, the word-level interactions across different clicked news from the same user, which contain rich detailed clues to infer user interest, are ignored by these methods. In this paper, we propose a fine-grained and fast user modeling framework (FUM) to model user interest from fine-grained behavior interactions for news recommendation. The core idea of FUM is to concatenate the clicked news into a long document and transform user modeling into a document modeling task with both intra-news and inter-news word-level interactions. Since vanilla transformer cannot efficiently handle long document, we apply an efficient transformer named Fastformer to model fine-grained behavior interactions. Extensive experiments on two real-world datasets verify that FUM can effectively and efficiently model user interest for news recommendation.|用户建模对新闻推荐非常重要。现有方法通常首先将用户点击新闻独立编码为新闻嵌入，然后将其聚合为用户嵌入。但是，这些方法忽略了来自同一用户的不同点击新闻之间的词级交互，这些新闻包含丰富的细节线索来推断用户的兴趣。在本文中，我们提出了一个细粒度和快速的用户建模框架(FUM)来模型用户的兴趣从细粒度的行为交互的新闻推荐。FUM 的核心思想是将点击的新闻连接到一个长文档中，并将用户建模转换为具有内部新闻和内部新闻字级交互的文档建模任务。由于普通的转换器不能有效地处理长文档，因此我们应用一个名为 Fastformer 的高效转换器来对细粒度的行为交互进行建模。在两个实际数据集上的大量实验证明，FUM 可以有效地为新闻推荐建立用户兴趣模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FUM:+Fine-grained+and+Fast+User+Modeling+for+News+Recommendation)|2|
|[Experiments on Generalizability of User-Oriented Fairness in Recommender Systems](https://doi.org/10.1145/3477495.3531718)|Hossein A. Rahmani, Mohammadmehdi Naghiaei, Mahdi Dehghan, Mohammad Aliannejadi|University of Southern California, California, CA, USA; Shahid Beheshti University, Tehran, Iran; University of Amsterdam, Amsterdam, Netherlands; University College London, London, United Kingdom|Recent work in recommender systems mainly focuses on fairness in recommendations as an important aspect of measuring recommendations quality. A fairness-aware recommender system aims to treat different user groups similarly. Relevant work on user-oriented fairness highlights the discriminant behavior of fairness-unaware recommendation algorithms towards a certain user group, defined based on users' activity level. Typical solutions include proposing a user-centered fairness re-ranking framework applied on top of a base ranking model to mitigate its unfair behavior towards a certain user group i.e., disadvantaged group. In this paper, we re-produce a user-oriented fairness study and provide extensive experiments to analyze the dependency of their proposed method on various fairness and recommendation aspects, including the recommendation domain, nature of the base ranking model, and user grouping method. Moreover, we evaluate the final recommendations provided by the re-ranking framework from both user- (e.g., NDCG, user-fairness) and item-side (e.g., novelty, item-fairness) metrics. We discover interesting trends and trade-offs between the model's performance in terms of different evaluation metrics. For instance, we see that the definition of the advantaged/disadvantaged user groups plays a crucial role in the effectiveness of the fairness algorithm and how it improves the performance of specific base ranking models. Finally, we highlight some important open challenges and future directions in this field. We release the data, evaluation pipeline, and the trained models publicly on https://github.com/rahmanidashti/FairRecSys.|推荐系统最近的工作主要侧重于推荐的公平性，这是衡量推荐质量的一个重要方面。公平意识推荐系统的目标是对不同的用户群体采取类似的对待方式。面向用户的公平性的相关工作强调了公平性无意识推荐算法对特定用户群的区分行为，这种区分行为是根据用户的活动水平来定义的。典型的解决方案包括提出一种以用户为中心的公平性重新排序框架，该框架应用于基本排序模型之上，以减轻其对特定用户群体(即弱势群体)的不公平行为。本文重现了一个面向用户的公平性研究，并通过大量实验分析了他们提出的方法对各种公平性和推荐方面的依赖性，包括推荐域、基本排名模型的性质和用户分组方法。此外，我们从用户(如 NDCG，用户公平性)和项目方(如新颖性，项目公平性)指标评估重新排名框架提供的最终建议。我们发现了一些有趣的趋势，以及模型在不同评估指标方面的表现之间的权衡。例如，我们发现优势/劣势用户群的定义对于公平算法的有效性以及如何提高特定基本排序模型的性能起着至关重要的作用。最后，我们强调一些重要的公开挑战和未来的方向在这一领域。我们在 https://github.com/rahmanidashti/fairrecsys 上公布数据、评估流程和训练有素的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Experiments+on+Generalizability+of+User-Oriented+Fairness+in+Recommender+Systems)|2|
|[Geometric Disentangled Collaborative Filtering](https://doi.org/10.1145/3477495.3531982)|Yiding Zhang, Chaozhuo Li, Xing Xie, Xiao Wang, Chuan Shi, Yuming Liu, Hao Sun, Liangjie Zhang, Weiwei Deng, Qi Zhang|Microsoft Research Asia, Beijing, China; Microsoft, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|Learning informative representations of users and items from the historical interactions is crucial to collaborative filtering (CF). Existing CF approaches usually model interactions solely within the Euclidean space. However, the sophisticated user-item interactions inherently present highly non-Euclidean anatomy with various types of geometric patterns (i.e., tree-likeness and cyclic structures). The Euclidean-based models may be inadequate to fully uncover the intent factors beneath such hybrid-geometry interactions. To remedy this deficiency, in this paper, we study the novel problem of Geometric Disentangled Collaborative Filtering (GDCF), which aims to reveal and disentangle the latent intent factors across multiple geometric spaces. A novel generative GDCF model is proposed to learn geometric disentangled representations by inferring the high-level concepts associated with user intentions and various geometries. Empirically, our proposal is extensively evaluated over five real-world datasets, and the experimental results demonstrate the superiority of GDCF.|从历史交互中学习用户和项目的信息表示对于协同过滤(CF)至关重要。现有的 CF 方法通常仅在欧几里得空间内模拟交互作用。然而，复杂的用户-项目交互本质上呈现出高度非欧几里德解剖学和各种几何模式(例如，树状结构和循环结构)。基于欧几里得的模型可能不足以完全揭示这种混合几何相互作用下的意图因素。为了弥补这一不足，本文研究了几何解缠协同过滤(gdCF)这一新问题，旨在揭示和解缠跨多个几何空间的潜在意图因素。提出了一种新的生成性 GDCF 模型，通过推导与用户意图和各种几何形状相关的高层概念来学习几何分离表示。实验结果证明了 GDCF 算法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+Disentangled+Collaborative+Filtering)|2|
|[Generating Clarifying Questions with Web Search Results](https://doi.org/10.1145/3477495.3531981)|Ziliang Zhao, Zhicheng Dou, Jiaxin Mao, JiRong Wen|Beijing Key Laboratory of Big Data Management and Analysis Methods & Key Laboratory of Data Engineering and Knowledge Engineering, MOE, Beijing, China; Renmin University of China, Beijing, China|Asking clarifying questions is an interactive way to effectively clarify user intent. When a user submits a query, the search engine will return a clarifying question with several clickable items of sub-intents for clarification. According to the existing definition, the key to asking high-quality questions is to generate good descriptions for submitted queries and provided items. However, existing methods mainly based on static knowledge bases are difficult to find descriptions for many queries because of the lack of entities within these queries and their corresponding items. For such a query, it is unable to generate an informative question. To alleviate this problem, we propose leveraging top search results of the query to help generate better descriptions because we deem that the top retrieved documents contain rich and relevant contexts of the query. Specifically, we first design a rule-based algorithm to extract description candidates from search results and rank them by various human-designed features. Then, we apply an learning-to-rank model and another generative model for generalization and further improve the quality of clarifying questions. Experimental results show that our proposed methods can generate more readable and informative questions compared with existing methods. The results prove that search results can be utilized to improve users' search experience for search clarification in conversational search systems.|提出澄清问题是一种有效澄清用户意图的互动方式。当用户提交查询时，搜索引擎将返回一个澄清问题，其中包含若干可单击的子意图项以便澄清。根据现有的定义，提出高质量问题的关键是为提交的查询和提供的项目生成良好的描述。然而，现有的基于静态知识库的查询方法由于缺乏查询实体及其对应的项目，很难为许多查询找到描述。对于这样的查询，它无法生成提供信息的问题。为了缓解这个问题，我们建议利用查询的顶部搜索结果来帮助生成更好的描述，因为我们认为顶部检索的文档包含查询的丰富和相关的上下文。具体来说，我们首先设计了一个基于规则的算法，从搜索结果中提取描述候选者，并根据各种人工设计的特征对它们进行排序。然后，我们应用一个学习排序模型和另一个生成模型进行归纳，进一步提高澄清问题的质量。实验结果表明，与现有方法相比，本文提出的方法能够产生更具可读性和信息性的问题。实验结果表明，在会话搜索系统中，利用搜索结果可以提高用户的搜索体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Clarifying+Questions+with+Web+Search+Results)|2|
|[Enhancing CTR Prediction with Context-Aware Feature Representation Learning](https://doi.org/10.1145/3477495.3531970)|Fangye Wang, Yingxu Wang, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, Ning Gu|Fudan University, Shanghai, China; Microsoft Research Asia, Shanghai, China; Independent, Seattle, WA, USA|CTR prediction has been widely used in the real world. Many methods model feature interaction to improve their performance. However, most methods only learn a fixed representation for each feature without considering the varying importance of each feature under different contexts, resulting in inferior performance. Recently, several methods tried to learn vector-level weights for feature representations to address the fixed representation issue. However, they only produce linear transformations to refine the fixed feature representations, which are still not flexible enough to capture the varying importance of each feature under different contexts. In this paper, we propose a novel module named Feature Refinement Network (FRNet), which learns context-aware feature representations at bit-level for each feature in different contexts. FRNet consists of two key components: 1) Information Extraction Unit (IEU), which captures contextual information and cross-feature relationships to guide context-aware feature refinement; and 2) Complementary Selection Gate (CSGate), which adaptively integrates the original and complementary feature representations learned in IEU with bit-level weights. Notably, FRNet is orthogonal to existing CTR methods and thus can be applied in many existing methods to boost their performance. Comprehensive experiments are conducted to verify the effectiveness, efficiency, and compatibility of FRNet.|CTR 预测在现实世界中得到了广泛的应用。许多方法对特征交互进行建模以提高其性能。然而，大多数方法只学习每个特征的固定表示，而不考虑每个特征在不同环境下的不同重要性，导致性能较差。最近，一些方法尝试学习特征表示的矢量级权重，以解决固定表示问题。然而，它们仅仅产生线性变换来细化固定特征表示，这些线性变换仍然不够灵活，不足以捕获不同上下文环境下每个特征的不同重要性。本文提出了一种新颖的特征精化网络(FRNet)模型，该模型能够在不同的上下文环境下对每个特征进行位级的上下文感知特征表示。FRNet 由两个关键组成部分组成: 1)信息抽取单元(IEU) ，它捕获上下文信息和跨特征关系，以指导上下文感知特征细化; 2)补充选择门(CSGate) ，它自适应地将在 IEU 中学到的原始和补充特征表示与位级权重结合起来。值得注意的是，FRNet 与现有的 CTR 方法是正交的，因此可以应用在许多现有的方法中来提高它们的性能。通过综合实验验证了 FRNet 的有效性、高效性和兼容性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+CTR+Prediction+with+Context-Aware+Feature+Representation+Learning)|2|
|[Joint Multisided Exposure Fairness for Recommendation](https://doi.org/10.1145/3477495.3532007)|Haolun Wu, Bhaskar Mitra, Chen Ma, Fernando Diaz, Xue Liu|McGill University, Montréal, PQ, Canada; Canadian CIFAR AI Chair & Google, Montréal, PQ, Canada; Microsoft, Montréal, PQ, Canada; City University of Hong Kong, Hong Kong SAR, Hong Kong|Prior research on exposure fairness in the context of recommender systems has focused mostly on disparities in the exposure of individual or groups of items to individual users of the system. The problem of how individual or groups of items may be systemically under or over exposed to groups of users, or even all users, has received relatively less attention. However, such systemic disparities in information exposure can result in observable social harms, such as withholding economic opportunities from historically marginalized groups (allocative harm) or amplifying gendered and racialized stereotypes (representational harm). Previously, Diaz et al. developed the expected exposure metric---that incorporates existing user browsing models that have previously been developed for information retrieval---to study fairness of content exposure to individual users. We extend their proposed framework to formalize a family of exposure fairness metrics that model the problem jointly from the perspective of both the consumers and producers. Specifically, we consider group attributes for both types of stakeholders to identify and mitigate fairness concerns that go beyond individual users and items towards more systemic biases in recommendation. Furthermore, we study and discuss the relationships between the different exposure fairness dimensions proposed in this paper, as well as demonstrate how stochastic ranking policies can be optimized towards said fairness goals.|以往关于推荐系统中曝光公平性的研究主要侧重于系统个别用户对个别或组别项目的曝光方面的差异。个人或项目组如何可能系统地暴露于一组用户甚至所有用户之下或过度暴露于这些用户之下的问题，受到的关注相对较少。然而，这种信息暴露的系统性差异可能导致可观察到的社会危害，如阻止历史上被边缘化的群体获得经济机会(分配伤害)或放大性别和种族化的刻板印象(代表性伤害)。此前，迪亚兹等人开发了预期的曝光度量标准——该标准结合了以前为信息检索开发的现有用户浏览模型——以研究内容曝光对个人用户的公平性。我们扩展了他们提出的框架，从消费者和生产者的角度建立了一系列的暴露公平度量模型。具体来说，我们考虑两种类型的利益相关者的群体属性，以确定和减轻超越个人用户和项目的建议中更系统的偏见的公平性问题。此外，我们还研究和讨论了本文提出的不同暴露公平维度之间的关系，并论证了随机排序策略是如何朝着公平目标进行优化的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Multisided+Exposure+Fairness+for+Recommendation)|2|
|[Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction](https://doi.org/10.1145/3477495.3531772)|Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, Xueqi Cheng|ICT, CAS & University of Chinese Academy of Sciences, Beijing, China|Dense retrieval has shown promising results in many information retrieval (IR) related tasks, whose foundation is high-quality text representation learning for effective search. Some recent studies have shown that autoencoder-based language models are able to boost the dense retrieval performance using a weak decoder. However, we argue that 1) it is not discriminative to decode all the input texts and, 2) even a weak decoder has the bypass effect on the encoder. Therefore, in this work, we introduce a novel contrastive span prediction task to pre-train the encoder alone, but still retain the bottleneck ability of the autoencoder. In this way, we can 1) learn discriminative text representations efficiently with the group-wise contrastive learning over spans and, 2) avoid the bypass effect of the decoder thoroughly. Comprehensive experiments over publicly available retrieval benchmark datasets show that our approach can outperform existing pre-training methods for dense retrieval significantly.|密集检索在许多与信息检索(IR)相关的任务中显示出有希望的结果，其基础是高质量的文本表示学习，以便有效地搜索。最近的一些研究表明，基于自动编码器的语言模型能够通过弱解码器提高密集检索性能。然而，我们认为: 1)解码所有的输入文本是没有区别的，2)即使是弱解码器对编码器也有旁路效应。因此，本文提出了一种新的对比跨度预测任务来单独对编码器进行预训练，同时保留了自动编码器的瓶颈能力。这样，我们可以1)利用跨区域的分组对比学习有效地学习歧视性文本表示，2)彻底避免解码器的旁路效应。对公开检索基准数据集的综合实验表明，该方法在密集检索方面的性能明显优于现有的预训练方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-train+a+Discriminative+Text+Encoder+for+Dense+Retrieval+via+Contrastive+Span+Prediction)|2|
|[CenterCLIP: Token Clustering for Efficient Text-Video Retrieval](https://doi.org/10.1145/3477495.3531950)|Shuai Zhao, Linchao Zhu, Xiaohan Wang, Yi Yang|Zhejiang University, Hangzhou, China; University of Technology Sydney, Sydney, NSW, Australia|Recently, large-scale pre-training methods like CLIP have made great progress in multi-modal research such as text-video retrieval. In CLIP, transformers are vital for modeling complex multi-modal relations. However, in the vision transformer of CLIP, the essential visual tokenization process, which produces discrete visual token sequences, generates many homogeneous tokens due to the redundancy nature of consecutive and similar frames in videos. This significantly increases computation costs and hinders the deployment of video retrieval models in web applications. In this paper, to reduce the number of redundant video tokens, we design a multi-segment token clustering algorithm to find the most representative tokens and drop the non-essential ones. As the frame redundancy occurs mostly in consecutive frames, we divide videos into multiple segments and conduct segment-level clustering. Center tokens from each segment are later concatenated into a new sequence, while their original spatial-temporal relations are well maintained. We instantiate two clustering algorithms to efficiently find deterministic medoids and iteratively partition groups in high dimensional space. Through this token clustering and center selection procedure, we successfully reduce computation costs by removing redundant visual tokens. This method further enhances segment-level semantic alignment between video and text representations, enforcing the spatio-temporal interactions of tokens from within-segment frames. Our method, coined as CenterCLIP, surpasses existing state-of-the-art by a large margin on typical text-video benchmarks, while reducing the training memory cost by 35% and accelerating the inference speed by 14% at the best case. The code is available at https://github.com/mzhaoshuai/CenterCLIP https://github.com/mzhaoshuai/CenterCLIP.|近年来，CLIP 等大规模预训练方法在文本-视频检索等多模态研究方面取得了很大进展。在 CLIP 中，变压器对于建立复杂的多模态关系至关重要。然而，在 CLIP 的视觉转换器中，由于视频中连续帧和相似帧的冗余性，产生离散视觉标记序列的基本视觉标记化过程会产生许多同质标记。这大大增加了计算成本，并阻碍了在 Web 应用程序中部署视频检索模型。为了减少冗余视频令牌的数量，本文设计了一种多段令牌聚类算法来寻找最有代表性的令牌并去除非必需的令牌。由于帧冗余主要发生在连续的帧中，我们将视频分割成多个片段，进行片段级聚类。来自每个片段的中心标记后来被连接成一个新的序列，同时它们原来的时空关系得到很好的保持。我们实例化了两个聚类算法，以有效地发现确定性中介体和迭代划分群在高维空间。通过这种令牌聚类和中心选择过程，我们成功地消除了冗余的可视令牌，降低了计算成本。该方法进一步增强了视频和文本表示之间的分段级语义对齐，增强了分段帧内标记的时空交互作用。我们的方法被称为 CenterCLIP，它在典型的文本视频基准测试上大大超越了现有的最新技术，同时降低了35% 的训练记忆成本，并且在最好的情况下加快了14% 的推理速度。密码可在 https://github.com/mzhaoshuai/centerclip  https://github.com/mzhaoshuai/centerclip 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CenterCLIP:+Token+Clustering+for+Efficient+Text-Video+Retrieval)|2|
|[ProFairRec: Provider Fairness-aware News Recommendation](https://doi.org/10.1145/3477495.3532046)|Tao Qi, Fangzhao Wu, Chuhan Wu, Peijie Sun, Le Wu, Xiting Wang, Yongfeng Huang, Xing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ProFairRec:+Provider+Fairness-aware+News+Recommendation)|2|
|[Rethinking Reinforcement Learning for Recommendation: A Prompt Perspective](https://doi.org/10.1145/3477495.3531714)|Xin Xin, Tiago Pimentel, Alexandros Karatzoglou, Pengjie Ren, Konstantina Christakopoulou, Zhaochun Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Reinforcement+Learning+for+Recommendation:+A+Prompt+Perspective)|2|
|[Alleviating Spurious Correlations in Knowledge-aware Recommendations through Counterfactual Generator](https://doi.org/10.1145/3477495.3531934)|Shanlei Mu, Yaliang Li, Wayne Xin Zhao, Jingyuan Wang, Bolin Ding, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Alleviating+Spurious+Correlations+in+Knowledge-aware+Recommendations+through+Counterfactual+Generator)|2|
|[HAKG: Hierarchy-Aware Knowledge Gated Network for Recommendation](https://doi.org/10.1145/3477495.3531987)|Yuntao Du, Xinjun Zhu, Lu Chen, Baihua Zheng, Yunjun Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HAKG:+Hierarchy-Aware+Knowledge+Gated+Network+for+Recommendation)|2|
|[Entity-aware Transformers for Entity Search](https://doi.org/10.1145/3477495.3531971)|Emma J. Gerritse, Faegheh Hasibi, Arjen P. de Vries||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity-aware+Transformers+for+Entity+Search)|2|
|[CharacterBERT and Self-Teaching for Improving the Robustness of Dense Retrievers on Queries with Typos](https://doi.org/10.1145/3477495.3531951)|Shengyao Zhuang, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CharacterBERT+and+Self-Teaching+for+Improving+the+Robustness+of+Dense+Retrievers+on+Queries+with+Typos)|2|
|[Thinking inside The Box: Learning Hypercube Representations for Group Recommendation](https://doi.org/10.1145/3477495.3532066)|Tong Chen, Hongzhi Yin, Jing Long, Quoc Viet Hung Nguyen, Yang Wang, Meng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Thinking+inside+The+Box:+Learning+Hypercube+Representations+for+Group+Recommendation)|2|
|[Multi-modal Graph Contrastive Learning for Micro-video Recommendation](https://doi.org/10.1145/3477495.3532027)|Zixuan Yi, Xi Wang, Iadh Ounis, Craig MacDonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Graph+Contrastive+Learning+for+Micro-video+Recommendation)|2|
|[InPars: Unsupervised Dataset Generation for Information Retrieval](https://doi.org/10.1145/3477495.3531863)|Luiz Henrique Bonifacio, Hugo Abonizio, Marzieh Fadaee, Rodrigo Frassetto Nogueira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InPars:+Unsupervised+Dataset+Generation+for+Information+Retrieval)|2|
|[Addressing Gender-related Performance Disparities in Neural Rankers](https://doi.org/10.1145/3477495.3531882)|Shirin Seyedsalehi, Amin Bigdeli, Negar Arabzadeh, Morteza Zihayat, Ebrahim Bagheri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Gender-related+Performance+Disparities+in+Neural+Rankers)|2|
|[State Encoders in Reinforcement Learning for Recommendation: A Reproducibility Study](https://doi.org/10.1145/3477495.3531716)|Jin Huang, Harrie Oosterhuis, Bunyamin Cetinkaya, Thijs Rood, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=State+Encoders+in+Reinforcement+Learning+for+Recommendation:+A+Reproducibility+Study)|2|
|[Wikimarks: Harvesting Relevance Benchmarks from Wikipedia](https://doi.org/10.1145/3477495.3531731)|Laura Dietz, Shubham Chatterjee, Connor Lennox, Sumanta Kashyapi, Pooja Oza, Ben Gamari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wikimarks:+Harvesting+Relevance+Benchmarks+from+Wikipedia)|2|
|[Gender Fairness in Information Retrieval Systems](https://doi.org/10.1145/3477495.3532680)|Amin Bigdeli, Negar Arabzadeh, Shirin Seyedsalehi, Morteza Zihayat, Ebrahim Bagheri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gender+Fairness+in+Information+Retrieval+Systems)|2|
|[Fairness of Exposure in Light of Incomplete Exposure Estimation](https://doi.org/10.1145/3477495.3531977)|Maria Heuss, Fatemeh Sarvi, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+of+Exposure+in+Light+of+Incomplete+Exposure+Estimation)|2|
|[Few-Shot Stance Detection via Target-Aware Prompt Distillation](https://doi.org/10.1145/3477495.3531979)|Yan Jiang, Jinhua Gao, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-Shot+Stance+Detection+via+Target-Aware+Prompt+Distillation)|2|
|[Unsupervised Belief Representation Learning with Information-Theoretic Variational Graph Auto-Encoders](https://doi.org/10.1145/3477495.3532072)|Jinning Li, Huajie Shao, Dachun Sun, Ruijie Wang, Yuchen Yan, Jinyang Li, Shengzhong Liu, Hanghang Tong, Tarek F. Abdelzaher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Belief+Representation+Learning+with+Information-Theoretic+Variational+Graph+Auto-Encoders)|2|
|[Towards Motivational and Empathetic Response Generation in Online Mental Health Support](https://doi.org/10.1145/3477495.3531912)|Tulika Saha, Vaibhav Gakhreja, Anindya Sundar Das, Souhitya Chakraborty, Sriparna Saha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Motivational+and+Empathetic+Response+Generation+in+Online+Mental+Health+Support)|2|
|[Multimodal Entity Linking with Gated Hierarchical Fusion and Contrastive Training](https://doi.org/10.1145/3477495.3531867)|Peng Wang, Jiangheng Wu, Xiaohang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Entity+Linking+with+Gated+Hierarchical+Fusion+and+Contrastive+Training)|2|
|[Tag-assisted Multimodal Sentiment Analysis under Uncertain Missing Modalities](https://doi.org/10.1145/3477495.3532064)|Jiandian Zeng, Tianyi Liu, Jiantao Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tag-assisted+Multimodal+Sentiment+Analysis+under+Uncertain+Missing+Modalities)|2|
|[Enhancing Zero-Shot Stance Detection via Targeted Background Knowledge](https://doi.org/10.1145/3477495.3531807)|Qinglin Zhu, Bin Liang, Jingyi Sun, Jiachen Du, Lanjun Zhou, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Zero-Shot+Stance+Detection+via+Targeted+Background+Knowledge)|2|
|[Relation-Guided Few-Shot Relational Triple Extraction](https://doi.org/10.1145/3477495.3531831)|Xin Cong, Jiawei Sheng, Shiyao Cui, Bowen Yu, Tingwen Liu, Bin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relation-Guided+Few-Shot+Relational+Triple+Extraction)|2|
|[Summarizing Legal Regulatory Documents using Transformers](https://doi.org/10.1145/3477495.3531872)|Svea Klaus, Ria Van Hecke, Kaweh Djafari Naini, Ismail Sengor Altingovde, Juan BernabéMoreno, Enrique HerreraViedma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Summarizing+Legal+Regulatory+Documents+using+Transformers)|2|
|[An Inspection of the Reproducibility and Replicability of TCT-ColBERT](https://doi.org/10.1145/3477495.3531721)|Xiao Wang, Sean MacAvaney, Craig Macdonald, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Inspection+of+the+Reproducibility+and+Replicability+of+TCT-ColBERT)|2|
|[MET-Meme: A Multimodal Meme Dataset Rich in Metaphors](https://doi.org/10.1145/3477495.3532019)|Bo Xu, Tingting Li, Junzhe Zheng, Mehdi Naseriparsa, Zhehuan Zhao, Hongfei Lin, Feng Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MET-Meme:+A+Multimodal+Meme+Dataset+Rich+in+Metaphors)|2|
|[Fostering Coopetition While Plugging Leaks: The Design and Implementation of the MS MARCO Leaderboards](https://doi.org/10.1145/3477495.3531725)|Jimmy Lin, Daniel Campos, Nick Craswell, Bhaskar Mitra, Emine Yilmaz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fostering+Coopetition+While+Plugging+Leaks:+The+Design+and+Implementation+of+the+MS+MARCO+Leaderboards)|2|
|[Too Many Relevants: Whither Cranfield Test Collections?](https://doi.org/10.1145/3477495.3531728)|Ellen M. Voorhees, Nick Craswell, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Too+Many+Relevants:+Whither+Cranfield+Test+Collections?)|2|
|[Document Expansion Baselines and Learned Sparse Lexical Representations for MS MARCO V1 and V2](https://doi.org/10.1145/3477495.3531749)|Xueguang Ma, Ronak Pradeep, Rodrigo Frassetto Nogueira, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Document+Expansion+Baselines+and+Learned+Sparse+Lexical+Representations+for+MS+MARCO+V1+and+V2)|2|
|[ClueWeb22: 10 Billion Web Documents with Rich Information](https://doi.org/10.1145/3477495.3536321)|Arnold Overwijk, Chenyan Xiong, Jamie Callan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ClueWeb22:+10+Billion+Web+Documents+with+Rich+Information)|2|
|[User-Aware Multi-Interest Learning for Candidate Matching in Recommenders](https://doi.org/10.1145/3477495.3532073)|Zheng Chai, Zhihong Chen, Chenliang Li, Rong Xiao, Houyi Li, Jiawei Wu, Jingxu Chen, Haihong Tang|Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; Wuhan University, Wuhan, China|Recommender systems have become a fundamental service in most E-Commerce platforms, in which the matching stage aims to retrieve potentially relevant candidate items to users for further ranking. Recently, some efforts on extracting multi-interests from user's historical behaviors have demonstrated superior performance. However, the historical behaviors are not noise-free due to the possible misclicks or disturbances. Existing works mainly overlook the fact that the interests of a user are not only reflected by the historical behaviors, but also inherently regulated by the profile information. Hence, we are interested in exploiting the benefit of user profile in multi-interest learning to enhance candidate matching performance. To this end, a user-aware multi-interest learning framework (named UMI) is proposed in this paper to exploit both user profile and behavior information for candidate matching. Specifically, UMI consists of two main components: dual-attention routing and interest refinement. In the dual-attention routing, we firstly introduce a user-guided attention network to identify the important historical items with respect to the user profile. Then, the resultant importance weights are leveraged via the dual-attentive capsule network to extract the user's multi-interests. Afterwards, the extracted interests are utilized to highlight the corresponding user profile features for interest refinement, such that different user profiles can be incorporated into interest learning for diverse user preference understanding. Besides, to improve the model's discriminative capacity, we further devise a harder-negatives strategy to support model optimization. Extensive experiments show that UMI significantly outperforms state-of-the-art multi-interest modeling alternatives. Currently, UMI has been successfully deployed at Taobao App in Alibaba, serving hundreds of millions of users.|推荐系统已经成为大多数电子商务平台的基本服务，其中匹配阶段的目的是检索潜在的相关候选项目，以便用户进一步排名。最近，一些从用户历史行为中提取多重利益的尝试已经显示出了卓越的性能。然而，由于可能的错误或干扰，历史行为并不是无噪声的。现有的研究工作主要忽视了用户的利益不仅反映在历史行为上，而且内在地受到个人资料信息的调节。因此，我们有兴趣在多兴趣学习中利用用户资料的好处来提高候选人匹配性能。为此，本文提出了一种基于用户感知的多兴趣学习框架(UMI) ，该框架利用用户信息和行为信息进行候选人匹配。具体来说，UMI 包括两个主要组成部分: 双注意路由和兴趣细化。在双注意路由中，我们首先引入一个用户引导的注意网络来识别与用户资料相关的重要历史项目。然后，通过双注意胶囊网络利用得到的重要性权重来提取用户的多重兴趣。然后利用提取出的兴趣特征突出相应的用户兴趣特征进行兴趣细化，从而将不同的用户兴趣特征融入到兴趣学习中以获得不同的用户偏好理解。此外，为了提高模型的判别能力，我们进一步设计了一个较难否定的策略来支持模型优化。大量的实验表明，UMI 明显优于最先进的多重兴趣建模方案。目前，用户界面已经在阿里巴巴的淘宝应用上成功部署，为数亿用户提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-Aware+Multi-Interest+Learning+for+Candidate+Matching+in+Recommenders)|1|
|[ESCM2: Entire Space Counterfactual Multi-Task Model for Post-Click Conversion Rate Estimation](https://doi.org/10.1145/3477495.3531972)|Hao Wang, TaiWei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu, Ruopeng Li, Wei Chu|Ant Group, Hangzhou, China|Accurate estimation of post-click conversion rate is critical for building recommender systems, which has long been confronted with sample selection bias and data sparsity issues. Methods in the Entire Space Multi-task Model (ESMM) family leverage the sequential pattern of user actions, \ie $impression\rightarrow click \rightarrow conversion$ to address data sparsity issue. However, they still fail to ensure the unbiasedness of CVR estimates. In this paper, we theoretically demonstrate that ESMM suffers from the following two problems: (1) Inherent Estimation Bias (IEB) for CVR estimation, where the CVR estimate is inherently higher than the ground truth; (2) Potential Independence Priority (PIP) for CTCVR estimation, where ESMM might overlook the causality from click to conversion. To this end, we devise a principled approach named Entire Space Counterfactual Multi-task Modelling (ESCM$^2$), which employs a counterfactual risk miminizer as a regularizer in ESMM to address both IEB and PIP issues simultaneously. Extensive experiments on offline datasets and online environments demonstrate that our proposed ESCM$^2$ can largely mitigate the inherent IEB and PIP issues and achieve better performance than baseline models.|准确估计点击后的转换率是建立推荐系统的关键，长期以来推荐系统一直面临样本选择偏差和数据稀疏问题。整个空间多任务模型(ESMM)家族中的方法利用了用户操作的顺序模式，例如: $pressionright-tarrow 单击 right-tarrow 转换 $来解决数据稀疏问题。然而，他们仍然不能确保 CVR 估计的公正性。在本文中，我们从理论上证明了 ESMM 存在以下两个问题: (1) CVR 估计的内在估计偏差(IEB) ，其中 CVR 估计固有地高于地面真值; (2) CTCVR 估计的潜在独立优先级(PIP) ，其中 ESMM 可能忽略从点击到转换的因果关系。为此，我们设计了一种名为“整个空间反事实多任务建模”(ESCM $^ 2 $)的原则性方法，该方法使用反事实风险模拟器作为 ESMM 中的规则化器，同时解决 IEB 和 PIP 问题。在离线数据集和在线环境上的大量实验表明，我们提出的 ESCM $^ 2 $可以在很大程度上缓解内在的 IEB 和 PIP 问题，并取得比基线模型更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ESCM2:+Entire+Space+Counterfactual+Multi-Task+Model+for+Post-Click+Conversion+Rate+Estimation)|1|
|[Single-shot Embedding Dimension Search in Recommender System](https://doi.org/10.1145/3477495.3532060)|Liang Qu, Yonghong Ye, Ningzhi Tang, Lixin Zhang, Yuhui Shi, Hongzhi Yin|WeChat, Tencent, Shenzhen, China; The University of Queensland, Brisbane, QLD, Australia; Southern University of Science and Technology, Shenzhen, China|As a crucial component of most modern deep recommender systems, feature embedding maps high-dimensional sparse user/item features into low-dimensional dense embeddings. However, these embeddings are usually assigned a unified dimension, which suffers from the following issues: (1) high memory usage and computation cost. (2) sub-optimal performance due to inferior dimension assignments. In order to alleviate the above issues, some works focus on automated embedding dimension search by formulating it as hyper-parameter optimization or embedding pruning problems. However, they either require well-designed search space for hyperparameters or need time-consuming optimization procedures. In this paper, we propose a Single-Shot Embedding Dimension Search method, called SSEDS, which can efficiently assign dimensions for each feature field via a single-shot embedding pruning operation while maintaining the recommendation accuracy of the model. Specifically, it introduces a criterion for identifying the importance of each embedding dimension for each feature field. As a result, SSEDS could automatically obtain mixed-dimensional embeddings by explicitly reducing redundant embedding dimensions based on the corresponding dimension importance ranking and the predefined parameter budget. Furthermore, the proposed SSEDS is model-agnostic, meaning that it could be integrated into different base recommendation models. The extensive offline experiments are conducted on two widely used public datasets for CTR (Click Through Rate) prediction task, and the results demonstrate that SSEDS can still achieve strong recommendation performance even if it has reduced 90% parameters. Moreover, SSEDS has also been deployed on the WeChat Subscription platform for practical recommendation services. The 7-day online A/B test results show that SSEDS can significantly improve the performance of the online recommendation model while reducing resource consumption.|作为现代深度推荐系统的重要组成部分，特征嵌入将高维稀疏用户/项目特征映射为低维密集嵌入。然而，这些嵌入通常被分配一个统一的维度，这受到以下问题: (1)高内存使用和计算成本。(2)由于尺寸分配不合理而导致性能次优。为了解决上述问题，一些工作将嵌入维搜索问题转化为超参数优化问题或嵌入剪枝问题。然而，它们要么需要设计良好的超参数搜索空间，要么需要耗时的优化过程。本文提出了一种单镜头嵌入维度搜索方法 SSEDS，该方法通过单镜头嵌入剪枝操作，可以有效地为每个特征域分配维度，同时保持模型的推荐精度。具体地说，它引入了一个标准来识别每个特征字段的每个嵌入维的重要性。因此，SSEDS 可以根据相应的维重要性排序和预定义的参数预算，通过显式地减少冗余嵌入维数来自动获得混合维嵌入。此外，提出的 SSEDS 是模型无关的，这意味着它可以集成到不同的基本推荐模型中。在两个广泛使用的公共数据集上进行了广泛的离线实验，结果表明，即使 SSEDS 减少了90% 的参数，仍然可以获得很好的推荐性能。此外，SSEDS 还被部署在微信订阅平台上，提供实用的推荐服务。为期7天的在线 A/B 测试结果表明，SSEDS 在降低资源消耗的同时，可以显著提高在线推荐模型的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Single-shot+Embedding+Dimension+Search+in+Recommender+System)|1|
|[Zero-shot Query Contextualization for Conversational Search](https://doi.org/10.1145/3477495.3531769)|Antonios Minas Krasakis, Andrew Yates, Evangelos Kanoulas|University of Amsterdam, Amsterdam, Netherlands|Current conversational passage retrieval systems cast conversational search into ad-hoc search by using an intermediate query resolution step that places the user's question in context of the conversation. While the proposed methods have proven effective, they still assume the availability of large-scale question resolution and conversational search datasets. To waive the dependency on the availability of such data, we adapt a pre-trained token-level dense retriever on ad-hoc search data to perform conversational search with no additional fine-tuning. The proposed method allows to contextualize the user question within the conversation history, but restrict the matching only between question and potential answer. Our experiments demonstrate the effectiveness of the proposed approach. We also perform an analysis that provides insights of how contextualization works in the latent space, in essence introducing a bias towards salient terms from the conversation.|当前的会话文本检索系统通过使用一个中间查询解析步骤，将用户的问题置于会话上下文中，从而将会话搜索转换为特定搜索。虽然提出的方法已被证明是有效的，但它们仍然假设大规模的问题解决和会话搜索数据集的可用性。为了摆脱对这些数据可用性的依赖，我们在自组织搜索数据上采用了一个预先训练的令牌级密集检索器来执行会话搜索，而不需要进行额外的微调。该方法允许在会话历史中上下文化用户问题，但只限制问题和潜在答案之间的匹配。实验证明了该方法的有效性。我们还进行了一个分析，提供了如何在潜在空间的情境化工作的见解，在本质上引入了一个从会话突出术语的偏见。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Query+Contextualization+for+Conversational+Search)|1|
|[DisenCTR: Dynamic Graph-based Disentangled Representation for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531851)|Yifan Wang, Yifang Qin, Fang Sun, Bo Zhang, Xuyang Hou, Ke Hu, Jia Cheng, Jun Lei, Ming Zhang|Meituan, Beijing, China; Peking University, Beijing, China|Click-through rate (CTR) prediction plays a critical role in recommender systems and other applications. Recently, modeling user behavior sequences attracts much attention and brings great improvements in the CTR field. Many existing works utilize attention mechanism or recurrent neural networks to exploit user interest from the sequence, but fail to recognize the simple truth that a user's real-time interests are inherently diverse and fluid. In this paper, we propose DisenCTR, a novel dynamic graph-based disentangled representation framework for CTR prediction. The key novelty of our method compared with existing approaches is to model evolving diverse interests of users. Specifically, we construct a time-evolving user-item interaction graph induced by historical interactions. And based on the rich dynamics supplied by the graph, we propose a disentangled graph representation module to extract diverse user interests. We further exploit the fluidity of user interests and model the temporal effect of historical behaviors using Mixture of Hawkes Process. Extensive experiments on three real-world datasets demonstrate the superior performance of our method comparing to state-of-the-art approaches.|在推荐系统和其他应用程序中，点进率(ctrl)预测起着至关重要的作用。近年来，用户行为序列建模引起了人们的广泛关注，并在 CTR 领域得到了很大的发展。现有的许多作品利用注意机制或反复神经网络从序列中挖掘用户兴趣，但未能认识到用户的实时兴趣具有内在的多样性和流动性这一简单事实。本文提出了一种新的基于动态图的分离表示框架 DisenCTR，用于 CTR 预测。与现有方法相比，我们的方法的关键新颖之处在于对用户的不同兴趣进行建模。具体来说，我们构造了一个由历史交互作用引起的时间演化的用户-项目交互图。基于图所提供的丰富的动态性，我们提出了一个分离的图表示模块来提取不同的用户兴趣。进一步利用用户兴趣的流动性，利用霍克斯过程混合模型对历史行为的时间效应进行建模。在三个真实世界数据集上的大量实验表明，与最先进的方法相比，我们的方法具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DisenCTR:+Dynamic+Graph-based+Disentangled+Representation+for+Click-Through+Rate+Prediction)|1|
|[BERT-based Dense Intra-ranking and Contextualized Late Interaction via Multi-task Learning for Long Document Retrieval](https://doi.org/10.1145/3477495.3531856)|Minghan Li, Éric Gaussier|Univ. Grenoble Alpes, CNRS, LIG, Grenoble, France|Combining query tokens and document tokens and inputting them to pre-trained transformer models like BERT, an approach known as interaction-based, has shown state-of-the-art effectiveness for information retrieval. However, the computational complexity of this approach is high due to the online self-attention computation. In contrast, dense retrieval methods in representation-based approaches are known to be efficient, however less effective. A tradeoff between the two is reached with late interaction methods like ColBERT, which attempt to benefit from both approaches: contextualized token embeddings can be pre-calculated over BERT for fine-grained effective interaction while preserving efficiency. However, despite its success in passage retrieval, it's not straightforward to use this approach for long document retrieval. In this paper, we propose a cascaded late interaction approach using a single model for long document retrieval. Fast intra-ranking by dot product is used to select relevant passages, then fine-grained interaction of pre-stored token embeddings is used to generate passage scores which are aggregated to the final document score. Multi-task learning is used to train a BERT model to optimize both a dot product and a fine-grained interaction loss functions. Our experiments reveal that the proposed approach obtains near state-of-the-art level effectiveness while being efficient on such collections as TREC 2019.|将查询令牌和文档令牌结合起来，并将它们输入到像 BERT 这样的经过预先训练的转换器模型中，这种方法被称为基于交互的方法，已经显示出对于信息检索的最先进的有效性。然而，由于在线自注意计算，这种方法的计算复杂度很高。相比之下，基于表示的方法中的密集检索方法已知是有效的，但是效率较低。这两种方法之间的折衷是通过 ColBERT 这样的后期交互方法实现的，它们试图从两种方法中受益: 上下文化的令牌嵌入可以在 BERT 上预先计算出细粒度的有效交互，同时保持效率。然而，尽管这种方法在文章检索方面取得了成功，但是要长时间地使用这种方法并不是一件简单的文献检索。在这篇文章中，我们提出了一个级联的晚期交互方法，使用单一模型的长期文献检索。首先利用点乘快速内排序来选择相关段落，然后利用预存储令牌嵌入的细粒度交互来生成段落分数，并将这些分数聚合为最终的文档分数。多任务学习用于训练 BERT 模型，以优化网点积和细粒度交互损失函数。我们的实验表明，所提出的方法获得接近最先进水平的效率，同时对 TREC 2019这样的集合是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BERT-based+Dense+Intra-ranking+and+Contextualized+Late+Interaction+via+Multi-task+Learning+for+Long+Document+Retrieval)|1|
|[RESETBERT4Rec: A Pre-training Model Integrating Time And User Historical Behavior for Sequential Recommendation](https://doi.org/10.1145/3477495.3532054)|Qihang Zhao|University of Science and Technology of China & JD AI Research, Hefei & Shanghai, China|Sequential recommendation methods are very important in modern recommender systems because they can well capture users' dynamic interests from their interaction history, and make accurate recommendations for users, thereby helping enterprises succeed in business. However, despite the great success of existing sequential recommendation-based methods, they focus too much on item-level modeling of users' click history and lack information about the user's entire click history (such as click order, click time, etc.). To tackle this problem, inspired by recent advances in pre-training techniques in the field of natural language processing, we build a new pre-training task based on the original BERT pre-training framework and incorporate temporal information. Specifically, we propose a new model called the RE arrange S equence prE -training and T ime embedding model via BERT for sequential R ecommendation (RESETBERT4Rec ) \footnoteThis work was completed during JD internship., it further captures the information of the user's whole click history by adding a rearrange sequence prediction task to the original BERT pre-training framework, while it integrates different views of time information. Comprehensive experiments on two public datasets as well as one e-commerce dataset demonstrate that RESETBERT4Rec achieves state-of-the-art performance over existing baselines.|序贯推荐方法在现代推荐系统中具有重要意义，因为它能够很好地从用户的交互历史中捕捉用户的动态兴趣，为用户提供准确的推荐，从而帮助企业获得成功。然而，尽管现有的基于顺序推荐的方法取得了巨大的成功，但它们过于关注用户点击历史的项目级建模，缺乏关于用户整个点击历史的信息(如点击顺序、点击时间等)。为了解决这一问题，受自然语言处理领域预训练技术的最新进展的启发，我们在原有的 BERT 预训练框架的基础上，结合时间信息构建了一个新的预训练任务。具体来说，我们提出了一个新的模型，称为 RE 安排 S 序列预训练和 T 时间嵌入模型，通过 BERT 进行顺序 R 推荐(RESETBERT4Rec)注释这项工作是在 JD 实习期间完成的，它通过在原有的 BERT 预训练框架中增加一个重排序列预测任务，进一步获取用户的整个点击历史信息，同时整合不同的时间信息视图。对两个公共数据集和一个电子商务数据集的综合实验表明，RESETBERT4Rec 在现有的基线上取得了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RESETBERT4Rec:+A+Pre-training+Model+Integrating+Time+And+User+Historical+Behavior+for+Sequential+Recommendation)|1|
|[Clustering based Behavior Sampling with Long Sequential Data for CTR Prediction](https://doi.org/10.1145/3477495.3531829)|Yuren Zhang, Enhong Chen, Binbin Jin, Hao Wang, Min Hou, Wei Huang, Runlong Yu|Huawei Cloud Computing Technologies Co., Ltd., Hangzhou, Zhejiang, China; University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, Anhui, China|Click-through rate (CTR) prediction is fundamental in many industrial applications, such as online advertising and recommender systems. With the development of the online platforms, the sequential user behaviors grow rapidly, bringing us great opportunity to better understand user preferences.However, it is extremely challenging for existing sequential models to effectively utilize the entire behavior history of each user. First, there is a lot of noise in such long histories, which can seriously hurt the prediction performance. Second, feeding the long behavior sequence directly results in infeasible inference time and storage cost. In order to tackle these challenges, in this paper we propose a novel framework, which we name as User Behavior Clustering Sampling (UBCS). In UBCS, short sub-sequences will be obtained from the whole user history sequence with two cascaded modules: (i) Behavior Sampling module samples short sequences related to candidate items using a novel sampling method which takes relevance and temporal information into consideration; (ii) Item Clustering module clusters items into a small number of cluster centroids, mitigating the impact of noise and improving efficiency. Then, the sampled short sub-sequences will be fed into the CTR prediction module for efficient prediction. Moreover, we conduct a self-supervised consistency pre-training task to extract user persona preference and optimize the sampling module effectively. Experiments on real-world datasets demonstrate the superiority and efficiency of our proposed framework.|在许多工业应用中，如在线广告和推荐系统中，点进率(ctrl)预测是基础。随着在线平台的发展，连续用户行为迅速增长，为我们更好地理解用户偏好带来了巨大的机遇。然而，对于现有的顺序模型来说，有效地利用每个用户的整个行为历史是极具挑战性的。首先，在如此长的历史中存在大量的噪声，这会严重影响预测性能。其次，长行为序列直接导致不可行的推理时间和存储成本。为了应对这些挑战，本文提出了一个新的框架，我们称之为用户行为聚类抽样(UBCS)。在 UBCS 中，通过两个级联模块从整个用户历史序列中获取短子序列: (1)行为采样模块采用一种新的考虑相关性和时间信息的采样方法对与候选项相关的短子序列进行采样; (2)项目聚类模块将项目聚类为少量的聚类质心，减少噪声的影响，提高效率。然后，将采样的短子序列输入 CTR 预测模块进行有效预测。此外，我们进行了自我监督的一致性预训练任务，以提取用户的人物偏好，并有效地优化抽样模块。在实际数据集上的实验表明了该框架的优越性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clustering+based+Behavior+Sampling+with+Long+Sequential+Data+for+CTR+Prediction)|1|
|[Matching Search Result Diversity with User Diversity Acceptance in Web Search Sessions](https://doi.org/10.1145/3477495.3531880)|Jiqun Liu, Fangyuan Han|Xiamen University, Xiamen, China; The University of Oklahoma, Norman, OK, USA|Promoting diversity in ranking while maintaining the relevance of ranked results is critical for enhancing human-centered search systems. While existing ranking algorithm and diversity IR metrics provide a solid basis for evaluating and improving search result diversification in offline experiments, it misses out possible divergences and temporal changes of users' levels of Diversity Acceptance, which in this work refers to the extent to which users actually prefer to interact with topically diversified search results. To address this gap between offline evaluations and users' expectations, we proposed an intuitive diversity acceptance measure and ran experiments for diversity acceptance prediction and diversity-aware re-ranking based on datasets from both controlled lab and naturalistic settings. Our results demonstrate that: 1) user diversity acceptance change across different query segments and session contexts, and can be predicted from search interaction signals; 2) our diversity-aware re-ranking algorithm utilizing predicted diversity acceptance and estimated relevance labels can effectively minimize the gap between diversity acceptance and result diversity, while maintaining SERP relevance levels. Our research presents an initial attempt on balancing user needs, result diversity, and SERP relevance in sessions and highlights the importance of studying diversity acceptance in promoting effective result diversification.|促进排名的多样性，同时保持排名结果的相关性，对于加强以人为中心的搜索系统至关重要。虽然现有的排名算法和多样性 IR 指标为评估和改善离线实验中的搜索结果多样性提供了坚实的基础，但它忽略了用户多样性接受水平的可能的分歧和时间变化，这在本文中指的是用户实际上更喜欢与主题多样化的搜索结果交互的程度。为了解决离线评估和用户期望之间的差距，我们提出了一个直观的多样性接受度量，并进行了基于受控实验室和自然环境数据集的多样性接受预测和多样性感知重新排序的实验。研究结果表明: 1)用户多样性接受度在不同查询段和会话上下文之间的变化，可以通过搜索交互信号进行预测; 2)我们的多样性感知重排算法利用预测的多样性接受度和估计的相关标签，可以有效地最小化多样性接受度和结果多样性之间的差距，同时保持 SERP 相关水平。我们的研究提出了在会议中平衡用户需求、结果多样性和 SERP 相关性的初步尝试，并强调了研究多样性接受在促进有效结果多样化中的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Matching+Search+Result+Diversity+with+User+Diversity+Acceptance+in+Web+Search+Sessions)|1|
|[Distill-VQ: Learning Retrieval Oriented Vector Quantization By Distilling Knowledge from Dense Embeddings](https://doi.org/10.1145/3477495.3531799)|Shitao Xiao, Zheng Liu, Weihao Han, Jianjin Zhang, Defu Lian, Yeyun Gong, Qi Chen, Fan Yang, Hao Sun, Yingxia Shao, Xing Xie||Vector quantization (VQ) based ANN indexes, such as Inverted File System (IVF) and Product Quantization (PQ), have been widely applied to embedding based document retrieval thanks to the competitive time and memory efficiency. Originally, VQ is learned to minimize the reconstruction loss, i.e., the distortions between the original dense embeddings and the reconstructed embeddings after quantization. Unfortunately, such an objective is inconsistent with the goal of selecting ground-truth documents for the input query, which may cause severe loss of retrieval quality. Recent works identify such a defect, and propose to minimize the retrieval loss through contrastive learning. However, these methods intensively rely on queries with ground-truth documents, whose performance is limited by the insufficiency of labeled data. In this paper, we propose Distill-VQ, which unifies the learning of IVF and PQ within a knowledge distillation framework. In Distill-VQ, the dense embeddings are leveraged as "teachers'', which predict the query's relevance to the sampled documents. The VQ modules are treated as the "students'', which are learned to reproduce the predicted relevance, such that the reconstructed embeddings may fully preserve the retrieval result of the dense embeddings. By doing so, Distill-VQ is able to derive substantial training signals from the massive unlabeled data, which significantly contributes to the retrieval quality. We perform comprehensive explorations for the optimal conduct of knowledge distillation, which may provide useful insights for the learning of VQ based ANN index. We also experimentally show that the labeled data is no longer a necessity for high-quality vector quantization, which indicates Distill-VQ's strong applicability in practice. The evaluations are performed on MS MARCO and Natural Questions benchmarks, where Distill-VQ notably outperforms the SOTA VQ methods in Recall and MRR. Our code is avaliable at https://github.com/staoxiao/LibVQ.|基于向量量化(vQ)的人工神经网络索引，例如倒置文件系统(IVF)和产品量化(PQ) ，由于具有竞争性的时间和存储效率，已被广泛应用于基于嵌入的文献检索。最初，学习 VQ 来最小化重构损失，即原始密集嵌入和量化后重构嵌入之间的失真。遗憾的是，这样的目标不符合为输入查询选择地面真实文档的目标，这可能导致检索质量的严重损失。最近的工作发现了这一缺陷，并提出通过对比学习来最小化检索损失。然而，这些方法主要依赖于对地面真相文档的查询，其性能受到标记数据不足的限制。在本文中，我们提出了提取 VQ，它在一个知识提取框架内将 IVF 和 PQ 的学习结合起来。在蒸馏 VQ 中，密集嵌入被用作“教师”，用于预测查询与采样文档的相关性。将 VQ 模块视为“学生”，学习再现预测的相关性，使得重构嵌入能够完全保留密集嵌入的检索结果。通过这种方法，DistilVQ 能够从海量的未标记数据中提取出大量的训练信号，从而大大提高了检索质量。本文对知识提取的最优化进行了全面的探索，为基于矢量量化的神经网络指标的学习提供了有益的启示。我们还通过实验表明，标记数据不再是高质量向量量化的必要条件，这表明蒸馏 VQ 在实践中的强大适用性。评估是在微软 MARCO 和自然问题基准上进行的，其中蒸馏 VQ 明显优于召回和 MRR 中的 SOTA VQ 方法。我们的代码 https://github.com/staoxiao/libvq 可用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distill-VQ:+Learning+Retrieval+Oriented+Vector+Quantization+By+Distilling+Knowledge+from+Dense+Embeddings)|1|
|[Neural Pseudo-Relevance Feedback Models for Sparse and Dense Retrieval](https://doi.org/10.1145/3477495.3531685)|Xiao Wang|University of Glasgow, Glasgow, Scotland, United Kingdom|Pseudo-relevance feedback mechanisms have long served as an effective technique to improve the retrieval effectiveness in information retrieval. Recently, large pre-trained language models, such as T5 and BERT, have shown a strong capacity to capture the latent traits of texts. Given the success of these models, we seek to study the capacity of these models for query reformulation. In addition, the BERT models have demonstrated further promise for dense retrieval, where the query and documents are encoded into the contextualised embeddings and relevant documents are retrieved by conducting the semantic matching operation. Although the success of pseudo-relevance feedback for sparse retrieval is well documented, effective pseudo-relevance feedback approaches for dense retrieval paradigm are still in their infancy. Thus, we are concerned with excavating the potential of the pseudo-relevance feedback information combined with the large pre-trained models to conduct effective query reformulation operating on both sparse retrieval and dense retrieval.|长期以来，伪相关反馈机制一直是提高信息检索检索效率的有效方法。近年来，大型的预训练语言模型，如 T5和 BERT，已经显示出很强的捕捉文本潜在特征的能力。鉴于这些模型的成功，我们寻求研究这些模型的查询重构能力。此外，BERT 模型还进一步展示了密集检索的前景，其中查询和文档被编码到上下文嵌入中，相关文档通过进行语义匹配操作进行检索。虽然伪相关反馈在稀疏检索方面的成功已有文献记载，但有效的伪相关反馈方法在密集检索范式中仍处于起步阶段。因此，我们致力于挖掘伪相关反馈信息与大型预训练模型相结合的潜力，对稀疏检索和密集检索进行有效的查询重构。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Pseudo-Relevance+Feedback+Models+for+Sparse+and+Dense+Retrieval)|1|
|[Neighbour Interaction based Click-Through Rate Prediction via Graph-masked Transformer](https://doi.org/10.1145/3477495.3532031)|Erxue Min, Yu Rong, Tingyang Xu, Yatao Bian, Da Luo, Kangyi Lin, Junzhou Huang, Sophia Ananiadou, Peilin Zhao|Weixin Open Platform, Tencent, Guangzhou, UNK, China; Tencent AI lab, Shenzhen, UNK, China; University of Texas at Arlington, Arlington, UNK, USA; University of Manchester, Manchester, UNK, United Kingdom; The University of Manchester, Manchester, UNK, United Kingdom; Tencent AI Lab, Shenzhen, UNK, China|Click-Through Rate (CTR) prediction, which aims to estimate the probability that a user will click an item, is an essential component of online advertising. Existing methods mainly attempt to mine user interests from users' historical behaviours, which contain users' directly interacted items. Although these methods have made great progress, they are often limited by the recommender system's direct exposure and inactive interactions, and thus fail to mine all potential user interests. To tackle these problems, we propose Neighbor-Interaction based CTR prediction (NI-CTR), which considers this task under a Heterogeneous Information Network (HIN) setting. In short, Neighbor-Interaction based CTR prediction involves the local neighborhood of the target user-item pair in the HIN to predict their linkage. In order to guide the representation learning of the local neighbourhood, we further consider different kinds of interactions among the local neighborhood nodes from both explicit and implicit perspective, and propose a novel Graph-Masked Transformer (GMT) to effectively incorporates these kinds of interactions to produce highly representative embeddings for the target user-item pair. Moreover, in order to improve model robustness against neighbour sampling, we enforce a consistency regularization loss over the neighbourhood embedding. We conduct extensive experiments on two real-world datasets with millions of instances and the experimental results show that our proposed method outperforms state-of-the-art CTR models significantly. Meanwhile, the comprehensive ablation studies verify the effectiveness of every component of our model. Furthermore, we have deployed this framework on the WeChat Official Account Platform with billions of users. The online A/B tests demonstrate an average CTR improvement of 21.9% against all online baselines.|点进率预测是在线广告的一个重要组成部分，其目的是估计用户点击某个项目的概率。现有的方法主要是从用户的历史行为中挖掘用户兴趣，这些历史行为包含了用户直接交互的项目。尽管这些方法已经取得了很大的进步，但它们往往受到推荐系统直接暴露和非活动交互的限制，因此无法挖掘所有潜在的用户兴趣。为了解决这些问题，我们提出了基于邻居交互的点击率预测(NI-CTR) ，它考虑了异构信息网络(HIN)环境下的任务。简而言之，基于邻域交互的 CTR 预测涉及到 HIN 中目标用户-项目对的局部邻域来预测它们之间的联系。为了指导局部邻域的表示学习，我们进一步从显式和隐式两个角度考虑局部邻域节点之间的不同交互，并提出了一种新的图掩盖变换器(GMT) ，以有效地整合这些交互，为目标用户项对产生高度代表性的嵌入。此外，为了提高模型对邻域采样的鲁棒性，我们对邻域嵌入增加了一个一致性正则化损失。我们在两个实际数据集上进行了大量的实验，实验结果表明，我们提出的方法明显优于最先进的 CTR 模型。同时，综合烧蚀研究验证了模型各组成部分的有效性。此外，我们已经在微信官方账号平台上部署了这个框架，拥有数十亿用户。在线 A/B 测试显示，与所有在线基线相比，点击率平均提高了21.9% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighbour+Interaction+based+Click-Through+Rate+Prediction+via+Graph-masked+Transformer)|1|
|[Why Don't You Click: Understanding Non-Click Results in Web Search with Brain Signals](https://doi.org/10.1145/3477495.3532082)|Ziyi Ye, Xiaohui Xie, Yiqun Liu, Zhihong Wang, Xuancheng Li, Jiaji Li, Xuesong Chen, Min Zhang, Shaoping Ma|Tsinghua University, Beijing, China; The Chinese University of Hong Kong, Shenzhen, Shenzhen, China|Web search heavily relies on click-through behavior as an essential feedback signal for performance evaluation and improvement. Traditionally, click is usually treated as a positive implicit feedback signal of relevance or usefulness, while non-click is regarded as a signal of irrelevance or uselessness. However, there are many cases where users satisfy their information need with the contents shown on the Search Engine Result Page (SERP). This raises the problem of measuring the usefulness of non-click results and modeling user satisfaction in such circumstances. For a long period, understanding non-click results is challenging owing to the lack of user interactions. In recent years, the rapid development of neuroimaging technologies constitutes a paradigm shift in various industries, e.g., search, entertainment, and education. Therefore, we benefit from these technologies and apply them to bridge the gap between the human mind and the external search system in non-click situations. To this end, we analyze the differences in brain signals between the examination of non-click search results in different usefulness levels. Inspired by these findings, we conduct supervised learning tasks to estimate the usefulness of non-click results with brain signals and conventional information (i.e., content and context factors). Furthermore, we devise two re-ranking methods, i.e., a Personalized Method (PM) and a Generalized Intent modeling Method (GIM), for search result re-ranking with the estimated usefulness. Results show that it is feasible to utilize brain signals to improve usefulness estimation performance and enhance human-computer interactions by search result re-ranking.|网络搜索在很大程度上依赖于点击行为作为性能评估和改进的重要反馈信号。传统上，点击通常被视为相关性或有用性的积极隐性反馈信号，而非点击则被视为无关性或无用性的信号。但是，在许多情况下，用户使用搜索引擎结果页(SERP)上显示的内容来满足他们的信息需求。这就提出了测量非点击结果的有用性以及在这种情况下建立用户满意度模型的问题。长期以来，由于缺乏用户交互，理解非点击结果是一项挑战。近年来，神经影像技术的快速发展构成了搜索、娱乐和教育等多个行业的范式转变。因此，我们从这些技术中受益，并应用它们在非点击情况下架起人类思维和外部搜索系统之间的桥梁。为此，我们分析了不同有用性水平的非点击检索结果在大脑信号方面的差异。受这些发现的启发，我们进行了一些监督式学习的任务，用大脑信号和传统信息(即内容和上下文因素)来评估非点击结果的有用性。此外，我们设计了两个重新排序的方法，即个性化方法(PM)和广义意图建模方法(GIM) ，用于搜索结果的重新排序与估计的有用性。实验结果表明，利用大脑信号进行搜索结果重排可以提高有用性估计性能，增强人机交互。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+Don't+You+Click:+Understanding+Non-Click+Results+in+Web+Search+with+Brain+Signals)|1|
|[Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation](https://doi.org/10.1145/3477495.3531989)|Nicholas Lim, Bryan Hooi, SeeKiong Ng, Yong Liang Goh, Renrong Weng, Rui Tan|GrabTaxi Holdings, Singapore, Singapore; National University of Singapore, Singapore, Singapore|Learning which Point-of-Interest (POI) a user will visit next is a challenging task for personalized recommender systems due to the large search space of possible POIs in the region. A recurring problem among existing works that makes it difficult to learn and perform well is the sparsity of the User-POI matrix. In this paper, we propose our Hierarchical Multi-Task Graph Recurrent Network (HMT-GRN) approach, which alleviates the data sparsity problem by learning different User-Region matrices of lower sparsities in a multi-task setting. We then perform a Hierarchical Beam Search (HBS) on the different region and POI distributions to hierarchically reduce the search space with increasing spatial granularity and predict the next POI. Our HBS provides efficiency gains by reducing the search space, resulting in speedups of 5 to 7 times over an exhaustive approach. In addition, we also propose a novel selectivity layer to predict if the next POI has been visited before by the user to balance between personalization and exploration. Experimental results on two real-world Location-Based Social Network (LBSN) datasets show that our model significantly outperforms baseline and the state-of-the-art methods.|由于该地区可能存在的 POI 搜索空间很大，因此了解用户下一步将访问哪个 POI 对于个性化推荐系统来说是一项具有挑战性的任务。现有作品中反复出现的一个难以学习和执行的问题是 User-POI 矩阵的稀疏性。本文提出了一种分层多任务图回归网络(HMT-GRN)方法，通过在多任务环境下学习不同稀疏度较低的用户区域矩阵来解决数据稀疏问题。然后对不同区域和 POI 分布进行分层束搜索(HBS) ，随着空间粒度的增加逐步减少搜索空间，并预测下一个 POI。我们的 HBS 通过减少搜索空间提供了效率增益，在一个详尽的方法中导致5到7倍的加速。此外，我们还提出了一个新的选择层来预测下一个 POI 是否已经被用户访问过，以便在个性化和探索之间取得平衡。在两个实际的基于位置的社会网络(LBSN)数据集上的实验结果表明，我们的模型明显优于基线和最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Multi-Task+Graph+Recurrent+Network+for+Next+POI+Recommendation)|1|
|[Progressive Self-Attention Network with Unsymmetrical Positional Encoding for Sequential Recommendation](https://doi.org/10.1145/3477495.3531800)|Yuehua Zhu, Bo Huang, Shaohua Jiang, Muli Yang, Yanhua Yang, Wenliang Zhong|AntGroup, Hangzhou, China; Xidian University, Xian, China|In real-world recommendation systems, the preferences of users are often affected by long-term constant interests and short-term temporal needs. The recently proposed Transformer-based models have proved superior in the sequential recommendation, modeling temporal dynamics globally via the remarkable self-attention mechanism. However, all equivalent item-item interactions in original self-attention are cumbersome, failing to capture the drifting of users' local preferences, which contain abundant short-term patterns. In this paper, we propose a novel interpretable convolutional self-attention, which efficiently captures both short- and long-term patterns with a progressive attention distribution. Specifically, a down-sampling convolution module is proposed to segment the overall long behavior sequence into a series of local subsequences. Accordingly, the segments are interacted with each item in the self-attention layer to produce locality-aware contextual representations, during which the quadratic complexity in original self-attention is reduced to nearly linear complexity. Moreover, to further enhance the robust feature learning in the context of Transformers, an unsymmetrical positional encoding strategy is carefully designed. Extensive experiments are carried out on real-world datasets, \eg ML-1M, Amazon Books, and Yelp, indicating that the proposed method outperforms the state-of-the-art methods w.r.t. both effectiveness and efficiency.|在实际的推荐系统中，用户的偏好往往受到长期不变的利益和短期的时间需求的影响。最近提出的变压器为基础的模型已被证明优越的顺序推荐，建模全球时间动态通过显着的自我注意机制。然而，原始自我注意中的所有等效项目-项目交互都是繁琐的，未能捕捉到用户本地偏好的漂移，其中包含了丰富的短期模式。在本文中，我们提出了一种新的可解释的卷积自我注意，有效地捕捉短期和长期的模式与逐步注意分布。特别地，提出了一种下采样卷积模块，将整个长行为序列分割成一系列局部子序列。相应地，这些片段与自我注意层中的每个项目相互作用，产生具有局部感知的上下文表征，在此过程中，原始自我注意的二次复杂度降低到接近线性复杂度。此外，为了进一步提高变压器环境下的鲁棒性特征学习，设计了一种非对称的位置编码策略。在现实世界的数据集上进行了大量的实验，例如 ML-1M，Amazon Books 和 Yelp，表明所提出的方法在效率和效果上都优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Self-Attention+Network+with+Unsymmetrical+Positional+Encoding+for+Sequential+Recommendation)|1|
|[A New Sequential Prediction Framework with Spatial-temporal Embedding](https://doi.org/10.1145/3477495.3531846)|Jihai Zhang, Fangquan Lin, Cheng Yang, Wei Jiang|Alibaba Group, Hangzhou, China|Sequential prediction is one of the key components in recommendation. In online e-commerce recommendation system, user behavior consists of the sequential visiting logs and item behavior contains the interacted user list in order. Most of the existing state-of-the-art sequential prediction methods only consider the user behavior while ignoring the item behavior. In addition, we find that user behavior varies greatly at different time, and most existing models fail to characterize the rich temporal information. To address the above problems, we propose a transformer-based spatial-temporal recommendation framework (STEM). In the STEM framework, we first utilize attention mechanisms to model user behavior and item behavior, and then exploit spatial and temporal information through a transformer-based model. The STEM framework, as a plug-in, is able to be incorporated into many neural network-based sequential recommendation methods to improve performance. We conduct extensive experiments on three real-world Amazon datasets. The results demonstrate the effectiveness of our proposed framework.|序贯预测是推荐系统的关键组成部分之一。在在线电子商务推荐系统中，用户行为由顺序访问日志组成，项目行为按顺序包含交互式用户列表。现有的大多数最先进的顺序预测方法只考虑用户行为，而忽略项目行为。此外，我们发现用户行为在不同的时间变化很大，现有的模型不能刻画丰富的时间信息。为了解决上述问题，我们提出了一个基于变压器的时空推荐框架(STEM)。在 STEM 框架中，我们首先利用注意机制对用户行为和项目行为进行建模，然后通过一个基于转换器的模型来利用空间和时间信息。STEM 框架作为一个插件，能够被整合到许多基于神经网络的顺序推荐方法中，以提高性能。我们在三个真实的亚马逊数据集上进行了广泛的实验。仿真结果表明了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Sequential+Prediction+Framework+with+Spatial-temporal+Embedding)|1|
|[Mitigating the Filter Bubble While Maintaining Relevance: Targeted Diversification with VAE-based Recommender Systems](https://doi.org/10.1145/3477495.3531890)|Zhaolin Gao, Tianshu Shen, Zheda Mai, Mohamed Reda Bouadjenek, Isaac Waller, Ashton Anderson, Ron Bodkin, Scott Sanner|University of Toronto, Toronto, ON, Canada; Vector Institute for Artificial Intelligence, Toronto, ON, Canada; Deakin University, Geelong, Australia; Optimy AI, Toronto, ON, Canada|Online recommendation systems are prone to create filter bubbles, whereby users are only recommended content narrowly aligned with their historical interests. In the case of media recommendation, this can reinforce political polarization by recommending topical content (e.g., on the economy) at one extreme end of the political spectrum even though this topic has broad coverage from multiple political viewpoints that would provide a more balanced and informed perspective for the user. Historically, Maximal Marginal Relevance (MMR) has been used to diversify result lists and even mitigate filter bubbles, but suffers from three key drawbacks: (1)~MMR directly sacrifices relevance for diversity, (2)~MMR typically diversifies across all content and not just targeted dimensions (e.g., political polarization), and (3)~MMR is inefficient in practice due to the need to compute pairwise similarities between recommended items. To simultaneously address these limitations, we propose a novel methodology that trains Concept Activation Vectors (CAVs) for targeted topical dimensions (e.g., political polarization). We then modulate the latent embeddings of user preferences in a state-of-the-art VAE-based recommender system to diversify along the targeted dimension while preserving topical relevance across orthogonal dimensions. Our experiments show that our Targeted Diversification VAE-based Collaborative Filtering (TD-VAE-CF) methodology better preserves relevance of content to user preferences across a range of diversification levels in comparison to both untargeted and targeted variations of Maximum Marginal Relevance (MMR); TD-VAE-CF is also much more computationally efficient than the post-hoc re-ranking approach of MMR.|在线推荐系统容易产生过滤气泡，用户只能被推荐与他们的历史兴趣狭窄地一致的内容。就媒体推荐而言，这可能会加剧政治两极分化，推荐政治光谱一端的主题内容(例如经济) ，尽管这个主题有多种政治观点的广泛覆盖，可以为用户提供一个更加平衡和知情的视角。从历史上看，最大边际相关(MMR)一直被用来使结果列表多样化，甚至减轻过滤器泡沫，但遭受三个关键的缺点: (1) ~ MMR 直接牺牲相关性的多样性，(2) ~ MMR 通常多样化跨所有内容，而不仅仅是有针对性的维度(例如，政治极化) ，和(3) ~ MMR 在实践中是低效的，因为需要计算推荐项目之间的成对相似性。为了同时解决这些局限性，我们提出了一种新的方法，训练概念激活向量(CAV)的目标主题维度(例如，政治极化)。然后，我们调整潜在的嵌入用户偏好在一个国家的最先进的 VAE 为基础的推荐系统，以多样化沿着目标的维度，同时保持跨正交维度的主题相关性。我们的实验表明，我们的基于目标多样化 VAE 的协同过滤(TD-VAE-CF)方法更好地保留了多样化水平范围内的用户偏好的内容相关性，与非目标和有针对性的最大边际相关性(MMR)变化相比，TD-VAE-CF 也比 MMR 的事后重新排序方法计算效率高得多。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+the+Filter+Bubble+While+Maintaining+Relevance:+Targeted+Diversification+with+VAE-based+Recommender+Systems)|1|
|[Modality-Balanced Embedding for Video Retrieval](https://doi.org/10.1145/3477495.3531899)|Xun Wang, Bingqing Ke, Xuanping Li, Fangyu Liu, Mingyu Zhang, Xiao Liang, Qiushi Xiao||Video search has become the main routine for users to discover videos relevant to a text query on large short-video sharing platforms. During training a query-video bi-encoder model using online search logs,\textit we identify a modality bias phenomenon that the video encoder almost entirely relies on text matching, neglecting other modalities of the videos such as vision, audio, \etc This modality imbalance results from a) modality gap: the relevance between a query and a video text is much easier to learn as the query is also a piece of text, with the same modality as the video text; b) data bias: most training samples can be solved solely by text matching. Here we share our practices to improve the first retrieval stage including our solution for the modality imbalance issue. We propose \modelname (short for Modality Balanced Video Retrieval) with two key components: manually generated modality-shuffled (MS) samples and a dynamic margin (DM) based on visual relevance. They can encourage the video encoder to pay balanced attentions to each modality. Through extensive experiments on a real world dataset, we show empirically that our method is both effective and efficient in solving modality bias problem. We have also deployed our ~\modelname~ in a large video platform and observed statistically significant boost over a highly optimized baseline in an A/B test and manual GSB evaluations.|视频搜索已成为用户在大型短视频分享平台上发现与文本查询相关的视频的主要程序。在使用在线搜索日志(texttit)对查询-视频双编码器模型进行训练时，我们发现了一种模态偏差现象，即视频编码器几乎完全依赖于文本匹配，而忽略了视频的其他模态，如视觉、音频等。这种模态偏差源于: a)模态差异: 查询和视频文本之间的相关性更容易学习，因为查询也是一段文本，具有与视频文本相同的模态; b)数据偏差: 大多数训练样本可以单独通过文本匹配来解决。在这里，我们分享我们的做法，以改善第一个检索阶段，包括我们的解决方案的形式不平衡的问题。提出了一种基于视觉相关性的动态边界检索模型，该模型由两个关键部分组成: 手动生成的模态混合样本(MS)和动态边界(DM)。它们可以鼓励视频编码器对每种模式给予均衡的关注。通过对实际数据集的大量实验，证明了该方法在解决模态偏差问题上的有效性。我们还在一个大型视频平台上部署了我们的“模型名”，并在 A/B 测试和手动 GSB 评估中观察到统计学上显著提高了高度优化的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modality-Balanced+Embedding+for+Video+Retrieval)|1|
|[Expanded Lattice Embeddings for Spoken Document Retrieval on Informal Meetings](https://doi.org/10.1145/3477495.3531921)|Esaú VillatoroTello, Srikanth R. Madikeri, Petr Motlícek, Aravind Ganapathiraju, Alexei V. Ivanov|Idiap Research Institute, Martigny, Switzerland; Uniphore Software Systems Inc., Palo Alto, CA, USA|In this paper, we evaluate different alternatives to process richer forms of Automatic Speech Recognition (ASR) output based on lattice expansion algorithms for Spoken Document Retrieval (SDR). Typically, SDR systems employ ASR transcripts to index and retrieve relevant documents. However, ASR errors negatively affect the retrieval performance. Multiple alternative hypotheses can also be used to augment the input to document retrieval to compensate for the erroneous one-best hypothesis. In Weighted Finite State Transducer-based ASR systems, using the n-best output (i.e. the top "n'' scoring hypotheses) for the retrieval task is common, since they can easily be fed to a traditional Information Retrieval (IR) pipeline. However, the n-best hypotheses are terribly redundant, and do not sufficiently encapsulate the richness of the ASR output, which is represented as an acyclic directed graph called the lattice. In particular, we utilize the lattice's constrained minimum path cover to generate a minimum set of hypotheses that serve as input to the reranking phase of IR. The novelty of our proposed approach is the incorporation of the lattice as an input for neural reranking by considering a set of hypotheses that represents every arc in the lattice. The obtained hypotheses are encoded through sentence embeddings using BERT-based models, namely SBERT and RoBERTa, and the final ranking of the retrieved segments is obtained with a max-pooling operation over the computed scores among the input query and the hypotheses set. We present our evaluation on the publicly available AMI meeting corpus. Our results indicate that the proposed use of hypotheses from the expanded lattice improves the SDR performance significantly over the n-best ASR output.|在这篇文章中，我们评估了处理更丰富形式的自动语音识别(ASR)输出的不同方案，这些方案是基于文献检索的格展开算法。通常，SDR 系统使用 ASR 记录来索引和检索相关文档。但是，ASR 错误会对检索性能产生负面影响。多重替代假设也可以用来增加对文献检索的输入，以弥补错误的最佳假设。在基于加权有限状态转换器的 ASR 系统中，对于检索任务使用 n 个最佳输出(即顶部的“ n”评分假设)是很常见的，因为它们可以很容易地提供给传统的信息检索(IR)流水线。然而，n 个最佳假设是非常多余的，并且没有充分封装 ASR 输出的丰富性，ASR 输出被表示为一个称为格的非循环有向图。特别地，我们利用格子的约束最小路覆盖生成一组最小假设，作为 IR 重新排序阶段的输入。我们提出的方法的新颖之处在于，通过考虑一组代表格子中每个弧的假设，将格子作为神经重新排序的输入。所得到的假设通过使用基于 BERT 的模型(即 SBERT 和 RoBERTa)的句子嵌入进行编码，并且通过对输入查询和假设集之间计算得分的最大池操作获得检索段的最终排序。我们提出了我们的评价公开可用的 AMI 会议语料库。我们的结果表明，提出的假设使用从扩展格提高软件无线电性能显着超过 n 最佳的 ASR 输出。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expanded+Lattice+Embeddings+for+Spoken+Document+Retrieval+on+Informal+Meetings)|1|
|[Improving Item Cold-start Recommendation via Model-agnostic Conditional Variational Autoencoder](https://doi.org/10.1145/3477495.3531902)|Xu Zhao, Yi Ren, Ying Du, Shenzheng Zhang, Nian Wang|Tencent News, Beijing, China|Embedding & MLP has become a paradigm for modern large-scale recommendation system. However, this paradigm suffers from the cold-start problem which will seriously compromise the ecological health of recommendation systems. This paper attempts to tackle the item cold-start problem by generating enhanced warmed-up ID embeddings for cold items with historical data and limited interaction records. From the aspect of industrial practice, we mainly focus on the following three points of item cold-start: 1) How to conduct cold-start without additional data requirements and make strategy easy to be deployed in online recommendation scenarios. 2) How to leverage both historical records and constantly emerging interaction data of new items. 3) How to model the relationship between item ID and side information stably from interaction data. To address these problems, we propose a model-agnostic Conditional Variational Autoencoder based Recommendation(CVAR) framework with some advantages including compatibility on various backbones, no extra requirements for data, utilization of both historical data and recent emerging interactions. CVAR uses latent variables to learn a distribution over item side information and generates desirable item ID embeddings using a conditional decoder. The proposed method is evaluated by extensive offline experiments on public datasets and online A/B tests on Tencent News recommendation platform, which further illustrate the advantages and robustness of CVAR.|嵌入式 MLP 已经成为现代大规模推荐系统的典范。然而，这种模式受到冷启动问题的影响，这将严重损害推荐系统的生态健康。本文试图利用历史数据和有限的交互记录为冷藏物品生成增强的预热 ID 嵌入，从而解决物品冷启动问题。从工业实践的角度出发，重点研究了项目冷启动的三个方面: 1)如何在不增加额外数据需求的情况下进行冷启动，使策略易于在在线推荐场景中部署。2)如何利用历史记录和新项目不断涌现的交互数据。3)如何从交互数据中稳定地建立项目 ID 与侧信息之间的关系模型。为了解决这些问题，我们提出了一个基于模型无关的条件变分自动编码器推荐(CVAR)框架，该框架具有一些优点，包括在不同骨干上的兼容性，对数据没有额外的要求，利用历史数据和最近出现的交互。CVAR 使用潜变量学习项目边信息的分布，并使用条件解码器生成所需的项目 ID 嵌入。该方法通过在公共数据集上的大量离线实验和在腾讯新闻推荐平台上的在线 A/B 测试进行了评估，进一步说明了 CVAR 的优势和稳健性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Item+Cold-start+Recommendation+via+Model-agnostic+Conditional+Variational+Autoencoder)|1|
|[Multi-Faceted Global Item Relation Learning for Session-Based Recommendation](https://doi.org/10.1145/3477495.3532024)|Qilong Han, Chi Zhang, Rui Chen, Riwei Lai, Hongtao Song, Li Li|Harbin Engineering University, Harbin, China; University of Delaware, Newark, DE, USA|As an emerging paradigm, session-based recommendation is aimed at recommending the next item based on a set of anonymous sessions. Effectively representing a session that is normally a short interaction sequence renders a major technical challenge. In view of the limitations of pioneering studies that explore collaborative information from other sessions, in this paper we propose a new direction to enhance session representations by learning multi-faceted session-independent global item relations. In particular, we identify three types of advantageous global item relations, including negative relations that have not been studied before, and propose different graph construction methods to capture such relations. We then devise a novel multi-faceted global item relation (MGIR) model to encode different relations using different aggregation layers and generate enhanced session representations by fusing positive and negative relations. Our solution is flexible to accommodate new item relations and can easily integrate existing session representation learning methods to generate better representations from global relation enhanced session information. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over a large number of state-of-the-art methods. Specifically, we show that learning negative relations is critical for session-based recommendation.|作为一种新兴的模式，基于会议的建议旨在根据一组匿名会议推荐下一个项目。有效地表示一个通常是短交互序列的会话会带来重大的技术挑战。针对开拓性研究在探索其他会议协作信息方面的局限性，本文提出了一个通过学习多方面会议独立的全局项目关系来增强会议表征的新方向。特别地，我们确定了三种有利的全局项目关系，包括以前没有研究过的负关系，并提出了不同的图构造方法来捕获这些关系。然后设计了一个新的多方面全局项目关系(MGIR)模型，利用不同的聚合层对不同的关系进行编码，并通过融合正负关系生成增强的会话表示。我们的解决方案是灵活的，以适应新的项目关系，可以很容易地集成现有的会话表示学习方法，从全局关系增强会话信息生成更好的表示。在三个基准数据集上的大量实验表明，我们的模型优于大量的最先进的方法。具体来说，我们表明，学习负关系是至关重要的会话为基础的推荐。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Faceted+Global+Item+Relation+Learning+for+Session-Based+Recommendation)|1|
|[Item Similarity Mining for Multi-Market Recommendation](https://doi.org/10.1145/3477495.3531839)|Jiangxia Cao, Xin Cong, Tingwen Liu, Bin Wang|Xiaomi AI Lab, Xiaomi Inc., Beijing, China; Institute of Information Engineering, CAS & UCAS, Beijing, China|Real-world web applications such as Amazon and Netflix often provide services in multiple countries and regions (i.e., markets) around the world. Generally, different markets share similar item sets while containing different amounts of interaction data. Some markets are data-scarce and others are data-rich and leveraging those data from similar and data-rich auxiliary markets could enhance the data-scarce markets. In this paper, we explore multi-market recommendation (MMR), and propose a novel model called M$^3$Rec to improve all markets recommendation simultaneously. Since items play the role to bridge different markets, we argue that mining the similarities among items is the key point of MMR. Our M^3Rec preprocess two global item similarities: intra- and inter- market similarities. Specifically, we first learn the second-order intra-market similarity by adopting linear models with closed-form solutions, and then capture the high-order inter-market similarity by the random walk. Afterward, we incorporate the global item similarities for each local market. We conduct extensive experiments on five public available markets and compare with several state-of-the-art methods. Detailed experimental results demonstrate the effectiveness of our proposed method.|现实世界的网络应用程序，如亚马逊和 Netflix，通常在世界各地的多个国家和地区(即市场)提供服务。通常，不同的市场共享相似的项目集，同时包含不同数量的交互数据。一些市场数据稀缺，另一些市场数据丰富，利用类似和数据丰富的辅助市场的数据可以加强数据稀缺市场。在本文中，我们探讨了多市场推荐(MMR) ，并提出了一种新的模型 M $^ 3 $Rec 来同时改进所有市场的推荐。由于产品在不同市场之间起着桥梁作用，我们认为挖掘产品之间的相似性是 MMR 的关键所在。我们的 M ^ 3Rec 预处理两个全球项目的相似性: 市场内部和市场间的相似性。具体来说，我们首先通过采用具有封闭解的线性模型来学习二阶市场内部相似性，然后通过随机游走来获取高阶市场内部相似性。然后，我们为每个当地市场整合全球产品的相似性。我们在五个公开市场上进行了广泛的实验，并与几种最先进的方法进行了比较。详细的实验结果证明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item+Similarity+Mining+for+Multi-Market+Recommendation)|1|
|[Interpreting Patient Descriptions using Distantly Supervised Similar Case Retrieval](https://doi.org/10.1145/3477495.3532003)|Israa Alghanmi, Luis Espinosa Anke, Steven Schockaert|Cardiff University, Cardiff, United Kingdom|Biomedical natural language processing often involves the interpretation of patient descriptions, for instance for diagnosis or for recommending treatments. Current methods, based on biomedical language models, have been found to struggle with such tasks. Moreover, retrieval augmented strategies have only had limited success, as it is rare to find sentences which express the exact type of knowledge that is needed for interpreting a given patient description. For this reason, rather than attempting to retrieve explicit medical knowledge, we instead propose to rely on a nearest neighbour strategy. First, we retrieve text passages that are similar to the given patient description, and are thus likely to describe patients in similar situations, while also mentioning some hypothesis (e.g.\ a possible diagnosis of the patient). We then judge the likelihood of the hypothesis based on the similarity of the retrieved passages. Identifying similar cases is challenging, however, as descriptions of similar patients may superficially look rather different, among others because they often contain an abundance of irrelevant details. To address this challenge, we propose a strategy that relies on a distantly supervised cross-encoder. Despite its conceptual simplicity, we find this strategy to be effective in practice.|生物医学自然语言处理通常涉及对患者描述的解释，例如用于诊断或推荐治疗。目前的方法，基于生物医学语言模型，已被发现与这样的任务斗争。此外，提取增强策略只取得了有限的成功，因为很少能找到表达解释给定患者描述所需的确切知识类型的句子。基于这个原因，我们不尝试检索显性医学知识，而是建议依赖于最近邻策略。首先，我们检索与给定患者描述相似的文本段落，因此可能描述处于相似情况的患者，同时也提到一些假设(例如患者的可能诊断)。然后，我们根据检索到的段落的相似性来判断假设的可能性。然而，鉴别相似病例是具有挑战性的，因为对相似病例的描述可能在表面上看起来相当不同，因为它们往往包含大量不相关的细节。为了应对这一挑战，我们提出了一种依赖于远程监督交叉编码器的策略。尽管其概念简单，我们发现这种策略在实践中是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpreting+Patient+Descriptions+using+Distantly+Supervised+Similar+Case+Retrieval)|1|
|[Towards Explainable Search Results: A Listwise Explanation Generator](https://doi.org/10.1145/3477495.3532067)|Puxuan Yu, Razieh Rahimi, James Allan|University of Massachusetts Amherst, Amherst, MA, USA|It has been shown that the interpretability of search results is enhanced when query aspects covered by documents are explicitly provided. However, existing work on aspect-oriented explanation of search results explains each document independently. These explanations thus cannot describe the differences between documents. This issue is also true for existing models on query aspect generation. Furthermore, these models provide a single query aspect for each document, even though documents often cover multiple query aspects. To overcome these limitations, we propose LiEGe, an approach that jointly explains all documents in a search result list. LiEGe provides semantic representations at two levels of granularity -- documents and their tokens -- using different interaction signals including cross-document interactions. These allow listwise modeling of a search result list as well as the generation of coherent explanations for documents. To appropriately explain documents that cover multiple query aspects, we introduce two settings for search result explanation: comprehensive and novelty explanation generation. LiEGe is trained and evaluated for both settings. We evaluate LiEGe on datasets built from Wikipedia and real query logs of the Bing search engine. Our experimental results demonstrate that LiEGe outperforms all baselines, with improvements that are substantial and statistically significant.|研究表明，如果明确提供文件所涉查询方面，搜索结果的可解释性就会得到提高。但是，现有的面向方面的搜索结果解释工作独立地解释每个文档。因此，这些解释无法描述文档之间的差异。对于生成查询方面的现有模型，也存在这个问题。此外，这些模型为每个文档提供单个查询方面，即使文档通常包含多个查询方面。为了克服这些限制，我们提出了 LiEGe，一种联合解释搜索结果列表中所有文档的方法。LiEGe 使用不同的交互信号(包括跨文档交互)在两个粒度级别(文档及其标记)提供语义表示。它们允许对搜索结果列表进行列表建模，以及为文档生成连贯的解释。为了恰当地解释涵盖多个查询方面的文档，我们引入了两种用于搜索结果解释的设置: 全面解释生成和新颖解释生成。对 LiEGe 进行了两种设置的培训和评估。我们根据维基百科建立的数据集和 Bing 搜索引擎的实际查询日志来评估 LiEGe。我们的实验结果表明，LiEGe 的性能优于所有基线，具有实质性的改进和统计学意义。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Explainable+Search+Results:+A+Listwise+Explanation+Generator)|1|
|[Bit-aware Semantic Transformer Hashing for Multi-modal Retrieval](https://doi.org/10.1145/3477495.3531947)|Wentao Tan, Lei Zhu, Weili Guan, Jingjing Li, Zhiyong Cheng|University of Electronic Science and Technology of China, Chengdu, China; Shandong Artificial Intelligence Institute, Jinan, China; Monash University, Clayton, Australia; Shandong Normal University, Jinan, China|Multi-modal hashing learns binary hash codes with extremely low storage cost and high retrieval speed. It can support efficient multi-modal retrieval well. However, most existing methods still suffer from three important problems: 1) Limited semantic representation capability with shallow learning. 2) Mandatory feature-level multi-modal fusion ignores heterogeneous multi-modal semantic gaps. 3) Direct coarse pairwise semantic preserving cannot effectively capture the fine-grained semantic correlations. For solving these problems, in this paper, we propose a Bit-aware Semantic Transformer Hashing (BSTH) framework to excavate bit-wise semantic concepts and simultaneously align the heterogeneous modalities for multi-modal hash learning on the concept-level. Specifically, the bit-wise implicit semantic concepts are learned with the transformer in a self-attention manner, which can achieve implicit semantic alignment on the fine-grained concept-level and reduce the heterogeneous modality gaps. Then, the concept-level multi-modal fusion is performed to enhance the semantic representation capability of each implicit concept and the fused concept representations are further encoded to the corresponding hash bits via bit-wise hash functions. Further, to supervise the bit-aware transformer module, a label prototype learning module is developed to learn prototype embeddings for all categories that capture the explicit semantic correlations on the category-level by considering the co-occurrence priors. Experiments on three widely tested multi-modal retrieval datasets demonstrate the superiority of the proposed method from various aspects.|多模态哈希学习二进制哈希码具有极低的存储成本和极高的检索速度。它能很好地支持有效的多模态检索。然而，现有的大多数方法仍然存在三个重要问题: 1)语义表示能力有限，浅层学习。2)强制特征级多模态融合忽略异质多模态语义缺口。3)直接粗对语义保持不能有效地捕获细粒度的语义关联。为了解决这些问题，本文提出了一种比特感知的语义变换哈希(BSTH)框架来挖掘比特感知的语义概念，同时在概念层次上对多模态哈希学习的异构模式进行校准。具体来说，通过变换器以自我注意的方式学习位隐含语义概念，可以在细粒度的概念水平上实现隐含语义对齐，减少异质情态差异。然后进行概念级多模态融合以提高每个隐式概念的语义表示能力，并通过逐位哈希函数将融合后的概念表示进一步编码到相应的哈希位。此外，为了监督位感知转换器模块，开发了一个标签原型学习模块来学习所有类别的原型嵌入，这些类别通过考虑共现先验在类别层面上捕获显式的语义相关性。在三个被广泛测试的多模态检索数据集上的实验从各个方面证明了该方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bit-aware+Semantic+Transformer+Hashing+for+Multi-modal+Retrieval)|1|
|[Multimodal Disentanglement Variational AutoEncoders for Zero-Shot Cross-Modal Retrieval](https://doi.org/10.1145/3477495.3532028)|Jialin Tian, Kai Wang, Xing Xu, Zuo Cao, Fumin Shen, Heng Tao Shen|Meituan, Shanghai, China; University of Electronic Science and Technology of China, Chengdu, China|Zero-Shot Cross-Modal Retrieval (ZS-CMR) has recently drawn increasing attention as it focuses on a practical retrieval scenario, i.e., the multimodal test set consists of unseen classes that are disjoint with seen classes in the training set. The recently proposed methods typically adopt the generative model as the main framework to learn a joint latent embedding space to alleviate the modality gap. Generally, these methods largely rely on auxiliary semantic embeddings for knowledge transfer across classes and unconsciously neglect the effect of the data reconstruction manner in the adopted generative model. To address this issue, we propose a novel ZS-CMR model termed Multimodal Disentanglement Variational AutoEncoders (MDVAE), which consists of two coupled disentanglement variational autoencoders (DVAEs) and a fusion-exchange VAE (FVAE). Specifically, DVAE is developed to disentangle the original representations of each modality into modality-invariant and modality-specific features. FVAE is designed to fuse and exchange information of multimodal data by the reconstruction and alignment process without pre-extracted semantic embeddings. Moreover, an advanced counter-intuitive cross-reconstruction scheme is further proposed to enhance the informativeness and generalizability of the modality-invariant features for more effective knowledge transfer. The comprehensive experiments on four image-text retrieval and two image-sketch retrieval datasets consistently demonstrate that our method establishes the new state-of-the-art performance.|零拍交叉模态检索(Zero-Shot Cross-Modal Retrieval，ZS-CMR)近年来受到越来越多的关注，因为它集中在一个实际的检索场景，即多模态测试集包含不相交的看不见的类和训练集中的看得见的类。最近提出的方法通常采用生成模型作为主要框架，学习一个联合潜在嵌入空间，以缓解模态差距。一般而言，这些方法主要依赖于辅助语义嵌入来跨类别传递知识，而无意识地忽略了所采用的生成模型中数据重构方式的影响。为了解决这个问题，我们提出了一种新的 ZS-CMR 模型，称为多模态解缠变分自动编码器(MDVAE) ，它由两个耦合的解缠变分自动编码器(DVAE)和一个融合交换 VAE (FVAE)组成。具体来说，DVAE 的开发是为了将每种模态的原始表示分解为模态不变和模态特定的特征。FVAE 通过重构和对齐过程实现多模态数据信息的融合和交换，不需要预先提取语义嵌入。进一步提出了一种改进的反直观交叉重构方案，以提高模态不变特征的信息量和泛化能力，实现更有效的知识转移。在四个图像文本检索和两个图像素描检索数据集上的综合实验表明，该方法建立了新的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Disentanglement+Variational+AutoEncoders+for+Zero-Shot+Cross-Modal+Retrieval)|1|
|[User-controllable Recommendation Against Filter Bubbles](https://doi.org/10.1145/3477495.3532075)|Wenjie Wang, Fuli Feng, Liqiang Nie, TatSeng Chua|Shandong University, Qingdao, China; National University of Singapore, Singapore, Singapore; University of Science and Technology of China, Hefei, China|Recommender systems usually face the issue of filter bubbles: over-recommending homogeneous items based on user features and historical interactions. Filter bubbles will grow along the feedback loop and inadvertently narrow user interests. Existing work usually mitigates filter bubbles by incorporating objectives apart from accuracy such as diversity and fairness. However, they typically sacrifice accuracy, hurting model fidelity and user experience. Worse still, users have to passively accept the recommendation strategy and influence the system in an inefficient manner with high latency, e.g., keeping providing feedback (e.g., like and dislike) until the system recognizes the user intention. This work proposes a new recommender prototype called User-Controllable Recommender System (UCRS), which enables users to actively control the mitigation of filter bubbles. Functionally, 1) UCRS can alert users if they are deeply stuck in filter bubbles. 2) UCRS supports four kinds of control commands for users to mitigate the bubbles at different granularities. 3) UCRS can respond to the controls and adjust the recommendations on the fly. The key to adjusting lies in blocking the effect of out-of-date user representations on recommendations, which contains historical information inconsistent with the control commands. As such, we develop a causality-enhanced User-Controllable Inference (UCI) framework, which can quickly revise the recommendations based on user controls in the inference stage and utilize counterfactual inference to mitigate the effect of out-of-date user representations. Experiments on three datasets validate that the UCI framework can effectively recommend more desired items based on user controls, showing promising performance w.r.t. both accuracy and diversity.|推荐系统通常面临过滤气泡的问题: 过度推荐基于用户特征和历史交互的同类项目。过滤气泡会沿着反馈回路增长，不经意间会缩小用户的兴趣。现有的工作通常通过将目标与准确性(如多样性和公平性)相结合来减少过滤泡沫。然而，他们通常牺牲准确性，损害模型的保真度和用户体验。更糟糕的是，用户必须被动地接受推荐策略，并以高延迟的低效方式影响系统，例如，不断提供反馈(例如，喜欢和不喜欢) ，直到系统认识到用户的意图。这项工作提出了一个新的推荐原型，称为用户可控推荐系统(UCRS) ，它使用户能够积极控制过滤气泡的缓解。在功能上，1) UCRS 可以提醒用户，如果他们深深陷入过滤泡。2) UCRS 支持四种控制命令，用户可以根据不同的粒度缓解气泡。3) UCRS 可以对控制措施做出响应，并在运行中调整建议。调整的关键在于阻止过时的用户表示对建议的影响，其中包含与控制命令不一致的历史信息。因此，我们开发了一个因果关系增强的用户可控推理(UCI)框架，它可以在推理阶段快速修改基于用户控制的推荐，并利用反事实推理来减轻过时用户表示的影响。在三个数据集上的实验验证了 UCI 框架基于用户控件能够有效地推荐更多期望的项目，在准确性和多样性方面都显示出良好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-controllable+Recommendation+Against+Filter+Bubbles)|1|
|[Evaluation of Herd Behavior Caused by Population-scale Concept Drift in Collaborative Filtering](https://doi.org/10.1145/3477495.3531792)|Chenglong Ma, Yongli Ren, Pablo Castells, Mark Sanderson|Universidad Autónoma de Madrid, Madrid , Spain; RMIT University, Melbourne, VIC, Australia|Concept drift in stream data has been well studied in machine learning applications. In the field of recommender systems, this issue is also widely observed, as known as temporal dynamics in user behavior. Furthermore, in the context of COVID-19 pandemic related contingencies, people shift their behavior patterns extremely and tend to imitate others' opinions. The changes in user behavior may not be always rational. Thus, irrational behavior may impair the knowledge learned by the algorithm. It can cause herd effects and aggravate the popularity bias in recommender systems due to the irrational behavior of users. However, related research usually pays attention to the concept drift of individuals and overlooks the synergistic effect among users in the same social group. We conduct a study on user behavior to detect the collaborative concept drifts among users. Also, we empirically study the increase of experience of individuals can weaken herding effects. Our results suggest the CF models are highly impacted by the herd behavior and our findings could provide useful implications for the design of future recommender algorithms.|流数据中的概念漂移已经在机器学习应用中得到了很好的研究。在推荐系统领域，这个问题也被广泛观察到，被称为用户行为的时间动态。此外，在与2019冠状病毒疾病相关的突发事件中，人们的行为模式会发生极大的变化，并倾向于模仿他人的观点。用户行为的变化可能并不总是理性的。因此，非理性行为可能会损害算法所学到的知识。在推荐系统中，由于用户的非理性行为，会引起羊群效应，加剧推荐系统的受欢迎程度偏差。然而，相关研究往往关注个体的概念漂移，忽视了同一社会群体中用户之间的协同效应。本文以用户行为为研究对象，检测用户之间的协作概念漂移。同时，我们实证研究了个体经验的增加会削弱羊群效应。我们的研究结果表明 CF 模型受到群体行为的高度影响，我们的研究结果可以为未来推荐算法的设计提供有用的启示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluation+of+Herd+Behavior+Caused+by+Population-scale+Concept+Drift+in+Collaborative+Filtering)|1|
|[A 'Pointwise-Query, Listwise-Document' based Query Performance Prediction Approach](https://doi.org/10.1145/3477495.3531821)|Suchana Datta, Sean MacAvaney, Debasis Ganguly, Derek Greene|Univ Coll Dublin, Dublin, Ireland; Univ Glasgow, Glasgow, Lanark, Scotland|The task of Query Performance Prediction (QPP) in Information Retrieval (IR) involves predicting the relative effectiveness of a search system for a given input query. Supervised approaches for QPP, such as NeuralQPP [24] are often trained on pairs of queries to capture their relative retrieval performance. However, point-wise approaches, such as the recently proposed BERT-QPP [1], are generally preferable for efficiency reasons. In this paper, we propose a novel end-to-end neural cross-encoder-based approach that is trained pointwise on individual queries, but listwise over the top ranked documents (split into chunks). In contrast to prior work, the network is then trained to predict the number of relevant documents in each chunk for a given query. Our method is thus a split-n-merge technique that instead of predicting the likely number of relevant documents in the top-k [1], rather predicts the number of relevant documents for each fixed chunk size p (p < k) and then aggregates them for QPP on top-k. Experiments demonstrate that our method is significantly more effective than other supervised and unsupervised QPP approaches yielding improvements of up to 30% on the TREC-DL'20 dataset and by nearly 9% for the MS MARCO Dev set.|查询性能预测的任务(QPP)在信息检索(IR)包括预测一个给定输入查询的搜索系统的相对有效性。QPP 的有监督的方法，如 NeuralQPP [24] ，经常在查询对上进行训练，以捕获它们的相对检索性能。然而，出于效率的考虑，最近提出的 BERT-QPP [1]等逐点方法通常是可取的。在本文中，我们提出了一种新的端到端神经交叉编码器为基础的方法，是点式训练的个别查询，但列表上的排名最高的文档(分成块)。与先前的工作相反，网络然后被训练来预测给定查询的每个块中相关文档的数量。因此，我们的方法是一种拆分-n-merge 技术，它不是预测 top-k [1]中相关文档的可能数量，而是预测每个固定块大小 p (p < k)的相关文档的数量，然后将它们聚合为 top-k 上的 QPP。实验表明，我们的方法比其他有监督和无监督的 QPP 方法显着更有效，在 TREC-DL’20数据集上提高了30% ，在 MS MARCO Dev 集上提高了近9% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+'Pointwise-Query,+Listwise-Document'+based+Query+Performance+Prediction+Approach)|1|
|[AHP: Learning to Negative Sample for Hyperedge Prediction](https://doi.org/10.1145/3477495.3531836)|Hyunjin Hwang, Seungwoo Lee, Chanyoung Park, Kijung Shin|KAIST, Daejeon, Republic of Korea; KAIST, Seoul, Republic of Korea|Hypergraphs (i.e., sets of hyperedges) naturally represent group relations (e.g., researchers co-authoring a paper and ingredients used together in a recipe), each of which corresponds to a hyperedge (i.e., a subset of nodes). Predicting future or missing hyperedges bears significant implications for many applications (e.g., collaboration and recipe recommendation). What makes hyperedge prediction particularly challenging is the vast number of non-hyperedge subsets, which grows exponentially with the number of nodes. Since it is prohibitive to use all of them as negative examples for model training, it is inevitable to sample a very small portion of them, and to this end, heuristic sampling schemes have been employed. However, trained models suffer from poor generalization capability for examples of different natures. In this paper, we propose AHP, an adversarial training-based hyperedge-prediction method. It learns to sample negative examples without relying on any heuristic schemes. Using six real hypergraphs, we show that AHP generalizes better to negative examples of various natures. It yields up to 28.2% higher AUROC than the best existing methods and often even outperforms its variants with sampling schemes tailored to test sets.|超图(即超边集合)自然地表示群体关系(例如，研究人员共同撰写一篇论文和一个食谱中的成分) ，每一个都对应于一个超边(即节点的子集)。预测未来或缺失的超边界对于许多应用程序(例如，协作和菜谱推荐)具有重要意义。使得超边缘预测特别具有挑战性的是大量的非超边缘子集，它们随着节点的数量呈指数增长。由于在模型训练中禁止使用所有的负例子，因此不可避免地需要对其中的一小部分进行抽样，为此，采用了启发式抽样方案。然而，经过训练的模型对于不同性质的例子的泛化能力较差。本文提出了一种基于对抗训练的 AHP 超边缘预测方法。它学习不依赖任何启发式方案来抽样否定的例子。利用六个实超图，我们证明了层次分析法能够更好地推广各种性质的负例子。与现有的最佳方法相比，它的 AUROC 提高了28.2% ，而且通常在根据测试集量身定制的抽样方案上甚至优于其变体。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AHP:+Learning+to+Negative+Sample+for+Hyperedge+Prediction)|1|
|[Interactive Query Clarification and Refinement via User Simulation](https://doi.org/10.1145/3477495.3531871)|Pierre Erbacher, Ludovic Denoyer, Laure Soulier|Sorbonne Université, Paris, France|When users initiate search sessions, their query are often ambiguous or might lack of context; this resulting in non-efficient document ranking. Multiple approaches have been proposed by the Information Retrieval community to add context and retrieve documents aligned with users' intents. While some work focus on query disambiguation using users' browsing history, a recent line of work proposes to interact with users by asking clarification questions or/and proposing clarification panels. However, these approaches count either a limited number (i.e., 1) of interactions with user or log-based interactions. In this paper, we propose and evaluate a fully simulated query clarification framework allowing multi-turn interactions between IR systems and user agents.|当用户启动搜索会话时，他们的查询通常是模棱两可的，或者可能缺乏上下文; 这导致文档排序效率低下。信息检索社区提出了多种方法来添加上下文和检索符合用户意图的文档。虽然一些工作侧重于利用用户的浏览历史消除查询歧义，但最近的一项工作建议通过提出澄清问题或/和提出澄清面板与用户进行交互。但是，这些方法只计算与用户或基于日志的交互的有限数量(即1)。本文提出并评估了一个完全模拟的查询澄清框架，该框架允许信息检索系统和用户代理之间进行多次交互。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interactive+Query+Clarification+and+Refinement+via+User+Simulation)|1|
|[Explainable Session-based Recommendation with Meta-path Guided Instances and Self-Attention Mechanism](https://doi.org/10.1145/3477495.3531895)|Jiayin Zheng, Juanyun Mai, Yanlong Wen|Nankai University, Tianjin, China|Session-based recommendation (SR) gains increasing popularity because it helps greatly maintain users' privacy. Aside from its efficacy, explainability is also critical for developing a successful SR model, since it can improve the persuasiveness of the results, the users' satisfaction, and the debugging efficiency. However, the majority of current SR models are unexplainable and even those that claim to be interpretable cannot provide clear and convincing explanations of users' intentions and how they influence the models' decisions. To solve this problem, in this research, we propose a meta-path guided model which uses path instances to capture item dependencies, explicitly reveal the underlying motives, and illustrate the entire reasoning process. To begin with, our model explores meta-path guided instances and leverages the multi-head self-attention mechanism to disclose the hidden motivations beneath these path instances. To comprehensively model the user interest and interest shifting, we search paths in both adjacent and non-adjacent items. Then, we update item representations by incorporating the user-item interactions and meta-path-based context sequentially. Compared with recent strong baselines, our method is competent to the SOTA performance on three datasets and meanwhile provides sound and clear explanations.|基于会话的推荐(SR)越来越受欢迎，因为它极大地保护了用户的隐私。除了功效之外，可解释性对于建立一个成功的 SR 模型也是至关重要的，因为它可以提高结果的说服力、用户的满意度和调试效率。然而，目前大多数 SR 模型是无法解释的，甚至那些声称可以解释的模型也不能提供清晰和令人信服的解释，说明用户的意图以及他们如何影响模型的决策。为了解决这一问题，本研究提出了一个元路径引导模型，该模型利用路径实例来捕获项目依赖，明确揭示项目依赖背后的动机，并说明整个推理过程。首先，我们的模型探索元路径引导实例，并利用多头自我关注机制来揭示这些路径实例下隐藏的动机。为了对用户兴趣和兴趣转移进行综合建模，我们在相邻和非相邻项目中搜索路径。然后，通过合并用户-项目交互和基于元路径的上下文顺序更新项目表示。与最近的强基线相比，我们的方法能够胜任三个数据集的 SOTA 性能，同时提供了合理而清晰的解释。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Session-based+Recommendation+with+Meta-path+Guided+Instances+and+Self-Attention+Mechanism)|1|
|[QSG Transformer: Transformer with Query-Attentive Semantic Graph for Query-Focused Summarization](https://doi.org/10.1145/3477495.3531901)|Choongwon Park, Youngjoong Ko|Sungkyunkwan University, Suwon-si, Gyeonggi-do, Republic of Korea|Query-Focused Summarization (QFS) is a task that aims to extract essential information from a long document and organize it into a summary that can answer a query. Recently, Transformer-based summarization models have been widely used in QFS. However, the simple Transformer architecture cannot utilize the relationships between distant words and information from a query directly. In this study, we propose the QSG Transformer, a novel QFS model that leverages structure information on Query-attentive Semantic Graph (QSG) to address these issues. Specifically, in the QSG Transformer, QSG node representation is improved by a proposed query-attentive graph attention network, which spreads the information of the query node into QSG using Personalized PageRank, and it is used to generate a summary that better reflects the information from the relationships of a query and document. The proposed method is evaluated on two QFS datasets, and it achieves superior performances over the state-of-the-art models.|查询聚焦摘要(Query-Focus Summarization，QFS)是一项任务，旨在从长文档中提取重要信息，并将其组织成可以回答查询的摘要。近年来，基于变压器的汇总模型在 QFS 中得到了广泛的应用。但是，简单的 Transformer 体系结构不能直接利用远程单词和来自查询的信息之间的关系。在这项研究中，我们提出了 QSG 转换器，一个新的 QFS 模型，利用查询注意语义图(QSG)的结构信息来解决这些问题。提出了一种基于查询-注意图注意网络的 QSG 节点表示方法，该方法利用个性化 PageRank 将查询节点的信息扩展到 QSG 中，生成能够更好地反映查询和文档关系信息的摘要。在两个 QFS 数据集上对该方法进行了评估，结果表明该方法的性能优于现有的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QSG+Transformer:+Transformer+with+Query-Attentive+Semantic+Graph+for+Query-Focused+Summarization)|1|
|[Next Point-of-Interest Recommendation with Auto-Correlation Enhanced Multi-Modal Transformer Network](https://doi.org/10.1145/3477495.3531905)|Yanjun Qin, Yuchen Fang, Haiyong Luo, Fang Zhao, Chenxing Wang|Institute of Computing Technology Chinese Academy Of Sciences, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|Next Point-of-Interest (POI) recommendation is a pivotal issue for researchers in the field of location-based social networks. While many recent efforts show the effectiveness of recurrent neural network-based next POI recommendation algorithms, several important challenges have not been well addressed yet: (i) The majority of previous models only consider the dependence of consecutive visits, while ignoring the intricate dependencies of POIs in traces; (ii) The nature of hierarchical and the matching of sub-sequence in POI sequences are hardly model in prior methods; (iii) Most of the existing solutions neglect the interactions between two modals of POI and the density category. To tackle the above challenges, we propose an auto-correlation enhanced multi-modal Transformer network (AutoMTN) for the next POI recommendation. Particularly, AutoMTN uses the Transformer network to explicitly exploits connections of all the POIs along the trace. Besides, to discover the dependencies at the sub-sequence level and attend to cross-modal interactions between POI and category sequences, we replace self-attention in Transformer with the auto-correlation mechanism and design a multi-modal network. Experiments results on two real-world datasets demonstrate the ascendancy of AutoMTN contra state-of-the-art methods in the next POI recommendation.|下一个兴趣点(POI)推荐是基于位置的社交网络研究领域的一个关键问题。尽管最近的许多努力显示了基于循环神经网络的下一个 POI 推荐算法的有效性，但是一些重要的挑战还没有得到很好的解决: (i)以前的大多数模型只考虑连续访问的依赖性，而忽略了跟踪中 POI 的复杂依赖性; (ii) POI 序列中分层的性质和子序列的匹配在以前的方法中几乎不是模型; (iii)大多数现有的解决方案忽略了 POI 的两个模态和密度类别之间的相互作用。为了应对上述挑战，我们提出了一个自相关增强型多模态变压器网络(AutoMTN)作为下一个 POI 建议。特别是，AutoMTN 使用 Transformer 网络显式地利用跟踪过程中所有 POI 的连接。此外，为了发现子序列层次上的依赖关系，并处理 POI 与类别序列之间的跨模态交互作用，我们用自相关机制取代了主变压器中的自注意机制，并设计了一个多模态网络。在两个实际数据集上的实验结果表明，AutoMTN 方法在下一个 POI 推荐中占优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Next+Point-of-Interest+Recommendation+with+Auto-Correlation+Enhanced+Multi-Modal+Transformer+Network)|1|
|[Neutralizing Popularity Bias in Recommendation Models](https://doi.org/10.1145/3477495.3531907)|Guipeng Xv, Chen Lin, Hui Li, Jinsong Su, Weiyao Ye, Yewang Chen|Huaqiao University, Xiamen, China; Xiamen University, Xiamen, China|Most existing recommendation models learn vectorized representations for items, i.e., item embeddings to make predictions. Item embeddings inherit popularity bias from the data, which leads to biased recommendations. We use this observation to design two simple and effective strategies, which can be flexibly plugged into different backbone recommendation models, to learn popularity neutral item representations. One strategy isolates popularity bias in one embedding direction and neutralizes the popularity direction post-training. The other strategy encourages all embedding directions to be disentangled and popularity neutral. We demonstrate that the proposed strategies outperform state-of-the-art debiasing methods on various real-world datasets, and improve recommendation quality of shallow and deep backbone models.|大多数现有的推荐模型学习项目的向量化表示，即项目嵌入来进行预测。项目嵌入从数据中继承了受欢迎程度的偏差，从而导致偏差推荐。利用这一观察结果，我们设计了两个简单有效的策略，可以灵活地插入到不同的骨干推荐模型中，来学习流行度中性的项目表示。一种策略是在一个嵌入方向上隔离流行偏差，在训练后中和流行方向。另一种策略鼓励所有的嵌入方向都是分离的和流行中性的。实验结果表明，所提出的策略优于现有的各种实际数据集的去偏方法，提高了浅层和深层骨架模型的推荐质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neutralizing+Popularity+Bias+in+Recommendation+Models)|1|
|[ROGUE: A System for Exploratory Search of GANs](https://doi.org/10.1145/3477495.3531675)|Yang Liu, Alan Medlar, Dorota Glowacka|University of Helsinki, Helsinki, Finland|Image retrieval from generative adversarial networks (GANs) is challenging for several reasons. First, there are no clear mappings between the GAN's latent space and useful semantic features, making it difficult for users to navigate. Second, the number of unique images that can be generated is exceptionally high, taxing the scaling properties of existing search algorithms. In this article, we present ROGUE, a system to support exploratory search of images generated from GANs. We demonstrate how to implement features that are commonly found in exploratory search interfaces, such as faceted search and relevance feedback, in the context of GAN search. We additionally use reinforcement learning to help users navigate the image space [8], trading off exploration (showing diverse images) and exploitation (showing images predicted to receive positive relevance feedback). Finally, we present a usability study where participants were situated in the role of a casting director who needs to explore actors' headshots for an upcoming movie. The system obtained an average SUS score of 72.8 and all participants reported being either satisfied or very satisfied with the images they identified with the system. The system is shown in this accompanying video: https://vimeo.com/680036160.|基于生成对抗网络(GAN)的图像检索是一个具有挑战性的问题。首先，在 GAN 的潜在空间和有用的语义特性之间没有清晰的映射，这使得用户很难导航。其次，可以生成的独特图像的数量异常之高，这对现有搜索算法的缩放特性造成了压力。在本文中，我们提出了 ROGUE，一个系统，以支持探索性搜索的图像生成的 GAN。我们将演示如何在广域网搜索环境中实现探索性搜索界面中常见的特性，例如分面搜索和关联反馈搜索。此外，我们还使用强化学习来帮助用户浏览图片空间，在探索(显示不同的图片)和利用(显示预计会收到正面关联反馈的图片)之间进行权衡。最后，我们提出了一个可用性研究，其中的参与者位于一个角色的选角导演谁需要探索演员的头像为即将到来的电影。该系统获得的 SUS 平均分为72.8分，所有参与者报告说，他们对系统识别的图像要么感到满意，要么非常满意。该系统在下面的视频中显示:  https://vimeo.com/680036160。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ROGUE:+A+System+for+Exploratory+Search+of+GANs)|1|
|[Searching for a New and Better Future of Work](https://doi.org/10.1145/3477495.3532088)|Jaime Teevan|Microsoft, Redmond, WA, USA|Search engines were one of the first intelligent cloud-based applications that people used to get things done, and they have since become an extremely important productivity tool. This is in part because much of what a person is doing when they search is thinking. Search engines do not merely support that thinking, however, but can also actually shape it. For example, some search results are more likely to spur learning than others and influence a person's future queries [1]. This means that as information retrieval researchers the new approaches that we develop can actively shape the future of work. The world is now in the middle of the most significant change to work practices in a generation, and it is one that will make search technology even more central to work in the years to come. For the past several millennia, space was the primary technology that people used to get things done. The coming Hybrid Work Era, however, will be shaped by digital technology. The recent rapid shift to remote work significantly accelerated the digital transformation already underway at many companies, and new types of work-related data are now being generated at an unprecedented rate. For example, the use of meeting recordings in Microsoft Stream has more than doubled from March 2020 to February 2022 [2]. Knowledge exists in this newly captured data, but figuring out how to make sense of it is overwhelming. The information retrieval community knows how to process large amounts of data, build usable intelligent systems, and learn from behavioral data, and we have a unique opportunity right now to apply this expertise to new corpora and in new scenarios in a meaningful way. In this talk I will give an overview of what research tells us about emerging work practices, and explore how the SIGIR community can build on these findings to help create a new - and better - future of work.|搜索引擎是人们用来完成工作的第一批基于云的智能应用程序之一，自那以后，它们已经成为极其重要的生产力工具。这在一定程度上是因为一个人在搜索时所做的大部分事情都是在思考。然而，搜索引擎不仅仅支持这种想法，而且实际上还可以塑造这种想法。例如，一些搜索结果比其他结果更有可能刺激学习，并影响一个人未来的查询[1]。这意味着，作为信息检索研究人员，我们开发的新方法可以积极地塑造未来的工作。这个世界现在正处于一代人以来最重大的工作实践变革之中，这将使搜索技术在未来几年的工作中变得更加重要。在过去的几千年里，太空是人们用来完成任务的主要技术。然而，即将到来的混合工作时代将由数字技术塑造。最近向远程工作的迅速转变极大地加速了许多公司已经在进行的数字化转变，现在正以前所未有的速度产生新类型的与工作有关的数据。例如，从2020年3月到2022年2月，微软 Stream 会议录音的使用量增加了一倍多[2]。知识存在于这些新捕获的数据中，但是弄清楚如何理解这些数据是非常困难的。信息检索社区知道如何处理大量的数据，构建可用的智能系统，并从行为数据中学习，我们现在有一个独特的机会，可以将这些专业知识以一种有意义的方式应用到新的语料库和新的场景中。在这个演讲中，我将概述研究告诉我们的新兴工作实践，并探讨 SIGIR 社区如何能够建立在这些发现的基础上，帮助创造一个新的、更好的工作未来。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Searching+for+a+New+and+Better+Future+of+Work)|1|
|[INMO: A Model-Agnostic and Scalable Module for Inductive Collaborative Filtering](https://doi.org/10.1145/3477495.3532000)|Yunfan Wu, Qi Cao, Huawei Shen, Shuchang Tao, Xueqi Cheng|Institute of Computing Technology, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Collaborative filtering is one of the most common scenarios and popular research topics in recommender systems. Among existing methods, latent factor models, i.e., learning a specific embedding for each user/item by reconstructing the observed interaction matrix, have shown excellent performances. However, such user-specific and item-specific embeddings are intrinsically transductive, making it difficult for them to deal with new users and new items unseen during training. Besides, the number of model parameters heavily depends on the number of all users and items, restricting their scalability to real-world applications. To solve the above challenges, in this paper, we propose a novel model-agnostic and scalable Inductive Embedding Module for collaborative filtering, namely INMO. INMO generates the inductive embeddings for users (items) by characterizing their interactions with some template items (template users), instead of employing an embedding lookup table. Under the theoretical analysis, we further propose an effective indicator for the selection of template users and template items. Our proposed INMO can be attached to existing latent factor models as a pre-module, inheriting the expressiveness of backbone models, while bringing the inductive ability and reducing model parameters. We validate the generality of INMO by attaching it to Matrix Factorization (MF) and LightGCN, which are two representative latent factor models for collaborative filtering. Extensive experiments on three public benchmarks demonstrate the effectiveness and efficiency of INMO in both transductive and inductive recommendation scenarios.|协同过滤是推荐系统中最常见的场景和流行的研究主题之一。在已有的方法中，潜因子模型(即通过重构观察到的交互矩阵学习每个用户/项目的特定嵌入)表现出了良好的性能。然而，这种特定于用户和特定于项目的嵌入在本质上具有传导性，使他们难以处理培训期间看不到的新用户和新项目。此外，模型参数的数量很大程度上取决于所有用户和项目的数量，限制了它们对现实应用程序的可伸缩性。为了解决上述挑战，本文提出了一种新颖的模型无关性和可扩展性的感应嵌入模块，即 INMO 协同过滤。INMO 通过描述用户与某些模板项(模板用户)的交互来为用户(项)生成归纳嵌入，而不是使用嵌入查找表。在理论分析的基础上，进一步提出了模板用户和模板项选择的有效指标。我们提出的 INMO 可以作为一个预模块附加到现有的潜因子模型，继承骨干模型的表达能力，同时带来归纳能力和减少模型参数。我们通过将 INMO 附加到矩阵分解(MF)和 LightGCN (这两个是协同过滤的两个代表性潜在因素模型)来验证 INMO 的普遍性。对三个公共基准进行的广泛试验表明，INMO 在推导和归纳推荐两种情况下都具有有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=INMO:+A+Model-Agnostic+and+Scalable+Module+for+Inductive+Collaborative+Filtering)|1|
|[Conversational Question Answering on Heterogeneous Sources](https://doi.org/10.1145/3477495.3531815)|Philipp Christmann, Rishiraj Saha Roy, Gerhard Weikum|Max Planck Institute for Informatics, Saarbrücken, Germany|Conversational question answering (ConvQA) tackles sequential information needs where contexts in follow-up questions are left implicit. Current ConvQA systems operate over homogeneous sources of information: either a knowledge base (KB), or a text corpus, or a collection of tables. This paper addresses the novel issue of jointly tapping into all of these together, this way boosting answer coverage and confidence. We present CONVINSE, an end-to-end pipeline for ConvQA over heterogeneous sources, operating in three stages: i) learning an explicit structured representation of an incoming question and its conversational context, ii) harnessing this frame-like representation to uniformly capture relevant evidences from KB, text, and tables, and iii) running a fusion-in-decoder model to generate the answer. We construct and release the first benchmark, ConvMix, for ConvQA over heterogeneous sources, comprising 3000 real-user conversations with 16000 questions, along with entity annotations, completed question utterances, and question paraphrases. Experiments demonstrate the viability and advantages of our method, compared to state-of-the-art baselines.|会话问题回答(ConvQA)处理后续问题中的上下文隐含的连续信息需求。当前的 ConvQA 系统是在同一信息源上运行的: 知识库(KB)、文本语料库或表集合。本文提出了一个新颖的问题，即共同利用所有这些问题，这样可以提高答案的覆盖面和信心。我们提出 CONVINSE，一种针对异构来源的 ConvQA 端到端管道，分三个阶段进行操作: i)学习传入问题及其会话上下文的显式结构化表示，ii)利用这种框架样表示来统一地从知识库，文本和表格中捕获相关证据，以及 iii)运行融合解码模型来生成答案。我们构建并发布了第一个基准，ConvMix，用于异构来源的 ConvQA，包括3000个实际用户对话和16000个问题，以及实体注释，完成的问题语句和问题转述。与最先进的基线相比，实验证明了我们方法的可行性和优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Question+Answering+on+Heterogeneous+Sources)|1|
|[COSPLAY: Concept Set Guided Personalized Dialogue Generation Across Both Party Personas](https://doi.org/10.1145/3477495.3531957)|Chen Xu, Piji Li, Wei Wang, Haoran Yang, Siyun Wang, Chuangbai Xiao|Tsinghua University, Beijing, AA, China; The Chinese University of Hong Kong, Hong Kong, AA, China; Tencent AI Lab, Shenzhen, AA, China; Beijing University of Technology, Beijing, AA, China; University of Southern California, Los Angeles, AA, USA|Maintaining a consistent persona is essential for building a human-like conversational model. However, the lack of attention to the partner makes the model more egocentric: they tend to show their persona by all means such as twisting the topic stiffly, pulling the conversation to their own interests regardless, and rambling their persona with little curiosity to the partner. In this work, we propose COSPLAY(COncept Set guided PersonaLized dialogue generation Across both partY personas) that considers both parties as a "team": expressing self-persona while keeping curiosity toward the partner, leading responses around mutual personas, and finding the common ground. Specifically, we first represent self-persona, partner persona and mutual dialogue all in the concept sets. Then, we propose the Concept Set framework with a suite of knowledge-enhanced operations to process them such as set algebras, set expansion, and set distance. Based on these operations as medium, we train the model by utilizing 1) concepts of both party personas, 2) concept relationship between them, and 3) their relationship to the future dialogue. Extensive experiments on a large public dataset, Persona-Chat, demonstrate that our model outperforms state-of-the-art baselines for generating less egocentric, more human-like, and higher quality responses in both automatic and human evaluations.|保持一致的人物角色对于构建类似人类的会话模型至关重要。然而，缺乏对伴侣的关注使得这种模式更加自我中心: 他们倾向于通过各种方式来展示自己的角色，比如僵硬地扭曲话题，不顾一切地把谈话拉向自己的兴趣，对伴侣毫无好奇心地胡扯自己的角色。在这项工作中，我们提出 COSPLAY (概念集引导的个性化对话生成跨越双方角色) ，认为双方是一个“团队”: 表达自我角色，同时保持对伴侣的好奇心，引导对相互角色的反应，并找到共同点。具体来说，我们首先在概念集中表现自我人格、伴侣人格和相互对话。然后，我们提出了概念集框架和一套知识增强操作来处理它们，例如集代数、集展开和集距离。基于这些操作作为媒介，我们利用1)双方角色的概念，2)他们之间的概念关系，3)他们与未来对话的关系来训练模型。在一个大型公共数据集“人物聊天”上进行的大量实验表明，我们的模型在自动和人工评估中产生更少的自我中心，更多的人性化和更高质量的响应方面优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COSPLAY:+Concept+Set+Guided+Personalized+Dialogue+Generation+Across+Both+Party+Personas)|1|
|[KETCH: Knowledge Graph Enhanced Thread Recommendation in Healthcare Forums](https://doi.org/10.1145/3477495.3532008)|Limeng Cui, Dongwon Lee|The Pennsylvania State University, University Park, PA, USA|Health thread recommendation methods aim to suggest the most relevant existing threads for a user. Most of the existing methods tend to rely on modeling the post contents to retrieve relevant answers. However, some posts written by users with different clinical conditions can be lexically similar, as unrelated diseases (e.g., Angina and Osteoporosis) may have the same symptoms (e.g., back pain), yet irrelevant threads to a user. Therefore, it is critical to not only consider the connections between users and threads, but also the descriptions of users' symptoms and clinical conditions. In this paper, towards this problem of thread recommendation in online healthcare forums, we propose a knowledge graph enhanced Threads Recommendation (KETCH) model, which leverages graph neural networks to model the interactions among users and threads, and learn their representations. In our model, the users, threads and posts are three types of nodes in a graph, linked through their associations. KETCH uses the message passing strategy by aggregating information along with the network. In addition, we introduce a knowledge-enhanced attention mechanism to capture the latent conditions and symptoms. We also apply the method to the task of predicting the side effects of drugs, to show that KETCH has the potential to complement the medical knowledge graph. Comparing with the best results of seven competing methods, in terms of MRR, KETCH outperforms all methods by at least 0.125 on the MedHelp dataset, 0.048 on the Patient dataset and 0.092 on HealthBoards dataset, respectively. We release the source code of KETCH at: https://github.com/cuilimeng/KETCH.|健康线程推荐方法旨在为用户推荐最相关的现有线程。现有的大多数方法倾向于依赖于对文章内容进行建模来检索相关的答案。然而，不同临床状况的用户写的一些帖子在词汇上可能是相似的，因为不相关的疾病(如心绞痛和骨质疏松症)可能有相同的症状(如背痛) ，但对用户来说是不相关的。因此，不仅要考虑用户和线程之间的连接，还要考虑用户症状和临床状况的描述。针对在线医疗论坛中的线程推荐问题，提出了一种知识图增强型线程推荐(KETCH)模型，该模型利用图神经网络对用户和线程之间的交互进行建模，并学习用户和线程之间的表示。在我们的模型中，用户、线程和帖子是图中的三种类型的节点，通过它们的关联进行链接。KETCH 通过将信息与网络一起聚合来使用消息传递策略。此外，我们还引入了一种知识增强的注意机制来捕捉潜在的条件和症状。我们还将该方法应用于预测药物副作用的任务，表明 KETCH 具有补充医学知识图谱的潜力。与七种竞争方法的最佳结果相比，就 MRR 而言，KETCH 在 MedHelp 数据集上至少优于所有方法0.125，在患者数据集上优于0.048，在 HealthBoards 数据集上优于0.092。我们在 https://github.com/cuilimeng/KETCH 发布 KETCH 的源代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KETCH:+Knowledge+Graph+Enhanced+Thread+Recommendation+in+Healthcare+Forums)|1|
|[Explainable Legal Case Matching via Inverse Optimal Transport-based Rationale Extraction](https://doi.org/10.1145/3477495.3531974)|Weijie Yu, Zhongxiang Sun, Jun Xu, Zhenhua Dong, Xu Chen, Hongteng Xu, JiRong Wen|Huawei Noah's Ark Lab, Shenzhen, China; Renmin University of China, Beijing, China|As an essential operation of legal retrieval, legal case matching plays a central role in intelligent legal systems. This task has a high demand on the explainability of matching results because of its critical impacts on downstream applications --- the matched legal cases may provide supportive evidence for the judgments of target cases and thus influence the fairness and justice of legal decisions. Focusing on this challenging task, we propose a novel and explainable method, namely IOT-Match, with the help of computational optimal transport, which formulates the legal case matching problem as an inverse optimal transport (IOT) problem. Different from most existing methods, which merely focus on the sentence-level semantic similarity between legal cases, our IOT-Match learns to extract rationales from paired legal cases based on both semantics and legal characteristics of their sentences. The extracted rationales are further applied to generate faithful explanations and conduct matching. Moreover, the proposed IOT-Match is robust to the alignment label insufficiency issue commonly in practical legal case matching tasks, which is suitable for both supervised and semi-supervised learning paradigms. To demonstrate the superiority of our IOT-Match method and construct a benchmark of explainable legal case matching task, we not only extend the well-known Challenge of AI in Law (CAIL) dataset but also build a new Explainable Legal cAse Matching (ELAM) dataset, which contains lots of legal cases with detailed and explainable annotations. Experiments on these two datasets show that our IOT-Match outperforms state-of-the-art methods consistently on matching prediction, rationale extraction, and explanation generation.|法律案件匹配作为法律检索的一项基本操作，在智能法律系统中起着核心作用。这项任务对匹配结果的解释性要求很高，因为它对下游应用产生了重要影响——匹配的法律案件可以为目标案件的判决提供支持性证据，从而影响法律判决的公正性和正义性。针对这一具有挑战性的任务，我们提出了一种新颖的解释方法，即物联网匹配(IOT-Match) ，借助于计算最优传输，将法律案例匹配问题表述为一个逆最优传输(IOT)问题。不同于现有的方法，我们的 IOT-Match 仅仅着眼于法律案件之间的句子层面的语义相似性，而是学习从成对的法律案件中根据其句子的语义和法律特征提取理据。提取的理论基础进一步应用于产生忠实的解释和进行匹配。此外，建议的物联网匹配对于实际案例匹配任务中常见的校准标签不足问题具有稳健性，适用于监督范式和半监督学习范式。为了证明我们的物联网匹配方法的优越性，构建一个可解释的法律案例匹配任务的基准，我们不仅扩展了著名的 CAIL 数据集，而且建立了一个新的可解释的法律案例匹配(ELAM)数据集，其中包含了大量的法律案例和详细的可解释的注释。在这两个数据集上的实验表明，我们的 IOT-Match 方法在匹配预测、理论提取和解释生成方面都优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Legal+Case+Matching+via+Inverse+Optimal+Transport-based+Rationale+Extraction)|1|
|[Optimizing Generalized Gini Indices for Fairness in Rankings](https://doi.org/10.1145/3477495.3532035)|Virginie Do, Nicolas Usunier|Meta AI Research, Paris, France; Meta AI Research & Université Paris Dauphine-PSL, Paris, France|There is growing interest in designing recommender systems that aim at being fair towards item producers or their least satisfied users. Inspired by the domain of inequality measurement in economics, this paper explores the use of generalized Gini welfare functions (GGFs) as a means to specify the normative criterion that recommender systems should optimize for. GGFs weight individuals depending on their ranks in the population, giving more weight to worse-off individuals to promote equality. Depending on these weights, GGFs minimize the Gini index of item exposure to promote equality between items, or focus on the performance on specific quantiles of least satisfied users. GGFs for ranking are challenging to optimize because they are non-differentiable. We resolve this challenge by leveraging tools from non-smooth optimization and projection operators used in differentiable sorting. We present experiments using real datasets with up to 15k users and items, which show that our approach obtains better trade-offs than the baselines on a variety of recommendation tasks and fairness criteria.|人们对设计推荐系统越来越感兴趣，这种系统旨在公平对待项目生产者或其最不满意的用户。受经济学中不平等测度领域的启发，本文探讨了广义基尼福利函数(GGFs)作为指定推荐系统优化标准的一种方法。GGFs 根据个体在人口中的等级来衡量个体的重量，将更多的重量赋予经济状况较差的个体，以促进平等。根据这些权重，GGFs 最小化项目曝光的基尼指数，以促进项目之间的平等，或者关注最不满意用户的特定分位数的性能。用于排名的 GGF 很难优化，因为它们是不可微的。我们通过利用非光滑优化工具和可微排序中使用的投影运算符来解决这一挑战。我们提出的实验使用真实的数据集多达15000个用户和项目，这表明我们的方法获得更好的权衡比基线的各种推荐任务和公平性标准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Generalized+Gini+Indices+for+Fairness+in+Rankings)|1|
|[Video Moment Retrieval from Text Queries via Single Frame Annotation](https://doi.org/10.1145/3477495.3532078)|Ran Cui, Tianwen Qian, Pai Peng, Elena Daskalaki, Jingjing Chen, Xiaowei Guo, Huyang Sun, YuGang Jiang|Fudan University, Shanghai, China; bilibili, Shanghai, China; The Australian National University, Canberra, Australia|Video moment retrieval aims at finding the start and end timestamps of a moment (part of a video) described by a given natural language query. Fully supervised methods need complete temporal boundary annotations to achieve promising results, which is costly since the annotator needs to watch the whole moment. Weakly supervised methods only rely on the paired video and query, but the performance is relatively poor. In this paper, we look closer into the annotation process and propose a new paradigm called "glance annotation". This paradigm requires the timestamp of only one single random frame, which we refer to as a "glance", within the temporal boundary of the fully supervised counterpart. We argue this is beneficial because comparing to weak supervision, trivial cost is added yet more potential in performance is provided. Under the glance annotation setting, we propose a method named as Video moment retrieval via Glance Annotation (ViGA) based on contrastive learning. ViGA cuts the input video into clips and contrasts between clips and queries, in which glance guided Gaussian distributed weights are assigned to all clips. Our extensive experiments indicate that ViGA achieves better results than the state-of-the-art weakly supervised methods by a large margin, even comparable to fully supervised methods in some cases.|视频矩检索的目的是查找给定的自然语言查询所描述的矩(视频的一部分)的开始和结束时间戳。完全监督的方法需要完整的时间边界注释来获得有希望的结果，这是昂贵的，因为注释者需要观察整个时刻。弱监督方法只依赖于配对视频和查询，但性能相对较差。在本文中，我们仔细研究了注释过程，并提出了一个新的范式称为“一瞥注释”。这个范例只需要一个随机帧的时间戳，我们称之为“一瞥”，在完全监督的对应物的时间边界内。我们认为这是有益的，因为相对于薄弱的监督，微不足道的成本增加了更多的性能潜力提供。在目视注释设置下，提出了一种基于对比学习的目视注释视频矩检索方法。ViGA 将输入的视频剪切成片段，并在片段和查询之间进行对比，给所有片段分配目视导引的高斯分布权值。我们的大量实验表明，ViGA 比最先进的弱监督方法获得了更好的结果，甚至在某些情况下可以与全监督方法相媲美。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Video+Moment+Retrieval+from+Text+Queries+via+Single+Frame+Annotation)|1|
|[You Need to Read Again: Multi-granularity Perception Network for Moment Retrieval in Videos](https://doi.org/10.1145/3477495.3532083)|Xin Sun, Xuan Wang, Jialin Gao, Qiong Liu, Xi Zhou|CloudWalk Technology Co., Ltd, Shanghai, China; Shanghai Jiaotong University, Shanghai, China; Peking University, Beijing, China|Moment retrieval in videos is a challenging task that aims to retrieve the most relevant video moment in an untrimmed video given a sentence description. Previous methods tend to perform self-modal learning and cross-modal interaction in a coarse manner, which neglect fine-grained clues contained in video content, query context, and their alignment. To this end, we propose a novel Multi-Granularity Perception Network (MGPN) that perceives intra-modality and inter-modality information at a multi-granularity level. Specifically, we formulate moment retrieval as a multi-choice reading comprehension task and integrate human reading strategies into our framework. A coarse-grained feature encoder and a co-attention mechanism are utilized to obtain a preliminary perception of intra-modality and inter-modality information. Then a fine-grained feature encoder and a conditioned interaction module are introduced to enhance the initial perception inspired by how humans address reading comprehension problems. Moreover, to alleviate the huge computation burden of some existing methods, we further design an efficient choice comparison module and reduce the hidden size with imperceptible quality loss. Extensive experiments on Charades-STA, TACoS, and ActivityNet Captions datasets demonstrate that our solution outperforms existing state-of-the-art methods.|视频中的瞬间检索是一项具有挑战性的任务，其目的是在给定句子描述的未修剪视频中检索最相关的视频瞬间。以往的方法倾向于以粗糙的方式进行自模态学习和跨模态交互，忽略了视频内容、查询上下文及其对齐中包含的细粒度线索。为此，我们提出了一种新的多粒度感知网络(MGPN) ，它在多粒度级别上感知模式内和模式间的信息。具体来说，我们把瞬间提取作为一项多项选择的阅读理解任务，并将人类阅读策略整合到我们的框架中。利用粗粒度特征编码器和共注意机制获得初步的模式内和模式间信息感知。然后引入细粒度特征编码器和条件交互模块，以增强受人类处理阅读理解问题启发而产生的初始感知。此外，为了减轻现有方法的巨大计算负担，我们进一步设计了一个有效的选择比较模块，减少了隐藏的大小和不易察觉的质量损失。对 Charades-STA、 TACoS 和 ActivityNet Captions 数据集的大量实验表明，我们的解决方案优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Need+to+Read+Again:+Multi-granularity+Perception+Network+for+Moment+Retrieval+in+Videos)|1|
|[Personalized Abstractive Opinion Tagging](https://doi.org/10.1145/3477495.3532037)|Mengxue Zhao, Yang Yang, Miao Li, Jingang Wang, Wei Wu, Pengjie Ren, Maarten de Rijke, Zhaochun Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Abstractive+Opinion+Tagging)|1|
|[Contrastive Learning with Hard Negative Entities for Entity Set Expansion](https://doi.org/10.1145/3477495.3531954)|Yinghui Li, Yangning Li, Yuxin He, Tianyu Yu, Ying Shen, HaiTao Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+with+Hard+Negative+Entities+for+Entity+Set+Expansion)|1|
|[EFLEC: Efficient Feature-LEakage Correction in GNN based Recommendation Systems](https://doi.org/10.1145/3477495.3531770)|Ishaan Kumar, Yaochen Hu, Yingxue Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFLEC:+Efficient+Feature-LEakage+Correction+in+GNN+based+Recommendation+Systems)|1|
|[P3 Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning](https://doi.org/10.1145/3477495.3531786)|Xiaomeng Hu, Shi Yu, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu, Ge Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=P3+Ranker:+Mitigating+the+Gaps+between+Pre-training+and+Ranking+Fine-tuning+with+Prompt-based+Learning+and+Pre-finetuning)|1|
|[Empowering Next POI Recommendation with Multi-Relational Modeling](https://doi.org/10.1145/3477495.3531801)|Zheng Huang, Jing Ma, Yushun Dong, Natasha Zhang Foutz, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Next+POI+Recommendation+with+Multi-Relational+Modeling)|1|
|[Learning Trustworthy Web Sources to Derive Correct Answers and Reduce Health Misinformation in Search](https://doi.org/10.1145/3477495.3531812)|Dake Zhang, Amir Vakili Tahami, Mustafa Abualsaud, Mark D. Smucker||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Trustworthy+Web+Sources+to+Derive+Correct+Answers+and+Reduce+Health+Misinformation+in+Search)|1|
|[On Optimizing Top-K Metrics for Neural Ranking Models](https://doi.org/10.1145/3477495.3531849)|Rolf Jagerman, Zhen Qin, Xuanhui Wang, Michael Bendersky, Marc Najork||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Optimizing+Top-K+Metrics+for+Neural+Ranking+Models)|1|
|[Identifying Argumentative Questions in Web Search Logs](https://doi.org/10.1145/3477495.3531864)|Yamen Ajjour, Pavel Braslavski, Alexander Bondarenko, Benno Stein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Argumentative+Questions+in+Web+Search+Logs)|1|
|[An MLP-based Algorithm for Efficient Contrastive Graph Recommendations](https://doi.org/10.1145/3477495.3531874)|Siwei Liu, Iadh Ounis, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+MLP-based+Algorithm+for+Efficient+Contrastive+Graph+Recommendations)|1|
|[Entity-Conditioned Question Generation for Robust Attention Distribution in Neural Information Retrieval](https://doi.org/10.1145/3477495.3531878)|Revanth Gangi Reddy, Md. Arafat Sultan, Martin Franz, Avirup Sil, Heng Ji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity-Conditioned+Question+Generation+for+Robust+Attention+Distribution+in+Neural+Information+Retrieval)|1|
|[C3: Continued Pretraining with Contrastive Weak Supervision for Cross Language Ad-Hoc Retrieval](https://doi.org/10.1145/3477495.3531886)|Eugene Yang, Suraj Nair, Ramraj Chandradevan, Rebecca IglesiasFlores, Douglas W. Oard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=C3:+Continued+Pretraining+with+Contrastive+Weak+Supervision+for+Cross+Language+Ad-Hoc+Retrieval)|1|
|[A Meta-learning Approach to Fair Ranking](https://doi.org/10.1145/3477495.3531892)|Yuan Wang, Zhiqiang Tao, Yi Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Meta-learning+Approach+to+Fair+Ranking)|1|
|[Where Does the Performance Improvement Come From?: - A Reproducibility Concern about Image-Text Retrieval](https://doi.org/10.1145/3477495.3531715)|Jun Rao, Fei Wang, Liang Ding, Shuhan Qi, Yibing Zhan, Weifeng Liu, Dacheng Tao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Where+Does+the+Performance+Improvement+Come+From?:+-+A+Reproducibility+Concern+about+Image-Text+Retrieval)|1|
|[Competitive Search](https://doi.org/10.1145/3477495.3532771)|Oren Kurland, Moshe Tennenholtz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Competitive+Search)|1|
|[A Dataset for Sentence Retrieval for Open-Ended Dialogues](https://doi.org/10.1145/3477495.3531727)|Itay Harel, Hagai Taitelbaum, Idan Szpektor, Oren Kurland||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dataset+for+Sentence+Retrieval+for+Open-Ended+Dialogues)|1|
|[iRec: An Interactive Recommendation Framework](https://doi.org/10.1145/3477495.3531754)|Thiago Silva, Nícollas Silva, Heitor Werneck, Carlos Mito, Adriano C. M. Pereira, Leonardo Rocha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iRec:+An+Interactive+Recommendation+Framework)|1|
|[RecDelta: An Interactive Dashboard on Top-k Recommendation for Cross-model Evaluation](https://doi.org/10.1145/3477495.3531674)|YiShyuan Chiang, YuZe Liu, ChenFeng Tsai, JingKai Lou, MingFeng Tsai, ChuanJu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecDelta:+An+Interactive+Dashboard+on+Top-k+Recommendation+for+Cross-model+Evaluation)|1|
|[Asyncval: A Toolkit for Asynchronously Validating Dense Retriever Checkpoints During Training](https://doi.org/10.1145/3477495.3531658)|Shengyao Zhuang, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Asyncval:+A+Toolkit+for+Asynchronously+Validating+Dense+Retriever+Checkpoints+During+Training)|1|
|[TaskMAD: A Platform for Multimodal Task-Centric Knowledge-Grounded Conversational Experimentation](https://doi.org/10.1145/3477495.3531679)|Alessandro Speggiorin, Jeffrey Dalton, Anton Leuski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TaskMAD:+A+Platform+for+Multimodal+Task-Centric+Knowledge-Grounded+Conversational+Experimentation)|1|
|[IRVILAB: Gamified Searching on Multilingual Wikipedia](https://doi.org/10.1145/3477495.3531662)|Paavo Arvola, Tuulikki Alamettälä||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IRVILAB:+Gamified+Searching+on+Multilingual+Wikipedia)|1|
|[Improving Efficiency and Robustness of Transformer-based Information Retrieval Systems](https://doi.org/10.1145/3477495.3532681)|Edmon Begoli, Sudarshan Srinivasan, Maria Mahbub||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Efficiency+and+Robustness+of+Transformer-based+Information+Retrieval+Systems)|1|
|[Self-Supervised Learning for Recommender System](https://doi.org/10.1145/3477495.3532684)|Chao Huang, Xiang Wang, Xiangnan He, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Learning+for+Recommender+System)|1|
|[ReNeuIR: Reaching Efficiency in Neural Information Retrieval](https://doi.org/10.1145/3477495.3531704)|Sebastian Bruch, Claudio Lucchese, Franco Maria Nardini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReNeuIR:+Reaching+Efficiency+in+Neural+Information+Retrieval)|1|
|[Generating Knowledge-based Explanation for Recommendation from Review](https://doi.org/10.1145/3477495.3531683)|Zuoxi Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Knowledge-based+Explanation+for+Recommendation+from+Review)|1|
|[Improving Fairness and Transparency for Artists in Music Recommender Systems](https://doi.org/10.1145/3477495.3531681)|Karlijn Dinnissen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Fairness+and+Transparency+for+Artists+in+Music+Recommender+Systems)|1|
|[Exploring Modular Task Decomposition in Cross-domain Named Entity Recognition](https://doi.org/10.1145/3477495.3531976)|Xinghua Zhang, Bowen Yu, Yubin Wang, Tingwen Liu, Taoyu Su, Hongbo Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Modular+Task+Decomposition+in+Cross-domain+Named+Entity+Recognition)|1|
|[Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification](https://doi.org/10.1145/3477495.3531984)|Kai Zhang, Qi Liu, Zhenya Huang, Mingyue Cheng, Kun Zhang, Mengdi Zhang, Wei Wu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Adaptive+Semantic+Transfer+for+Cross-domain+Sentiment+Classification)|1|
|[Hybrid CNN Based Attention with Category Prior for User Image Behavior Modeling](https://doi.org/10.1145/3477495.3531854)|Xin Chen, Qingtao Tang, Ke Hu, Yue Xu, Shihang Qiu, Jia Cheng, Jun Lei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hybrid+CNN+Based+Attention+with+Category+Prior+for+User+Image+Behavior+Modeling)|1|
|[When Online Meets Offline: Exploring Periodicity for Travel Destination Prediction](https://doi.org/10.1145/3477495.3531859)|Wanjie Tao, Liangyue Li, Chen Chen, Zulong Chen, Hong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Online+Meets+Offline:+Exploring+Periodicity+for+Travel+Destination+Prediction)|1|
|[Modeling User Behavior With Interaction Networks for Spam Detection](https://doi.org/10.1145/3477495.3531875)|Prabhat Agarwal, Manisha Srivastava, Vishwakarma Singh, Charles Rosenberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+User+Behavior+With+Interaction+Networks+for+Spam+Detection)|1|
|[ArchivalQA: A Large-scale Benchmark Dataset for Open-Domain Question Answering over Historical News Collections](https://doi.org/10.1145/3477495.3531734)|Jiexin Wang, Adam Jatowt, Masatoshi Yoshikawa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ArchivalQA:+A+Large-scale+Benchmark+Dataset+for+Open-Domain+Question+Answering+over+Historical+News+Collections)|1|
|[Structure and Semantics Preserving Document Representations](https://doi.org/10.1145/3477495.3532062)|Natraj Raman, Sameena Shah, Manuela Veloso||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structure+and+Semantics+Preserving+Document+Representations)|1|
|[Aspect Feature Distillation and Enhancement Network for Aspect-based Sentiment Analysis](https://doi.org/10.1145/3477495.3531938)|Rui Liu, Jiahao Cao, Nannan Sun, Lei Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aspect+Feature+Distillation+and+Enhancement+Network+for+Aspect-based+Sentiment+Analysis)|1|
|[Detecting Frozen Phrases in Open-Domain Question Answering](https://doi.org/10.1145/3477495.3531793)|Mostafa Yadegari, Ehsan Kamalloo, Davood Rafiei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Frozen+Phrases+in+Open-Domain+Question+Answering)|1|
|[Understanding User Satisfaction with Task-oriented Dialogue Systems](https://doi.org/10.1145/3477495.3531798)|Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+User+Satisfaction+with+Task-oriented+Dialogue+Systems)|1|
|[On Survivorship Bias in MS MARCO](https://doi.org/10.1145/3477495.3531832)|Prashansa Gupta, Sean MacAvaney||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Survivorship+Bias+in+MS+MARCO)|1|
|[Bias Mitigation for Evidence-aware Fake News Detection by Causal Intervention](https://doi.org/10.1145/3477495.3531850)|Junfei Wu, Qiang Liu, Weizhi Xu, Shu Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+Mitigation+for+Evidence-aware+Fake+News+Detection+by+Causal+Intervention)|1|
|[Preference Enhanced Social Influence Modeling for Network-Aware Cascade Prediction](https://doi.org/10.1145/3477495.3532042)|Likang Wu, Hao Wang, Enhong Chen, Zhi Li, Hongke Zhao, Jianhui Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preference+Enhanced+Social+Influence+Modeling+for+Network-Aware+Cascade+Prediction)|1|
|[Users and Contemporary SERPs: A (Re-)Investigation](https://doi.org/10.1145/3477495.3531719)|Nirmal Roy, David Maxwell, Claudia Hauff||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Users+and+Contemporary+SERPs:+A+(Re-)Investigation)|1|
|[ReMeDi: Resources for Multi-domain, Multi-service, Medical Dialogues](https://doi.org/10.1145/3477495.3531809)|Guojun Yan, Jiahuan Pei, Pengjie Ren, Zhaochun Ren, Xin Xin, Huasheng Liang, Maarten de Rijke, Zhumin Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReMeDi:+Resources+for+Multi-domain,+Multi-service,+Medical+Dialogues)|1|
|[Online DATEing: A Web Interface for Temporal Annotations](https://doi.org/10.1145/3477495.3531670)|Dennis Aumiller, Satya Almasian, David Pohl, Michael Gertz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+DATEing:+A+Web+Interface+for+Temporal+Annotations)|1|
|[Few-shot Node Classification on Attributed Networks with Graph Meta-learning](https://doi.org/10.1145/3477495.3531978)|Yonghao Liu, Mengyu Li, Ximing Li, Fausto Giunchiglia, Xiaoyue Feng, Renchu Guan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+Node+Classification+on+Attributed+Networks+with+Graph+Meta-learning)|1|
|[Co-clustering Interactions via Attentive Hypergraph Neural Network](https://doi.org/10.1145/3477495.3531868)|Tianchi Yang, Cheng Yang, Luhao Zhang, Chuan Shi, Maodi Hu, Huaijun Liu, Tao Li, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-clustering+Interactions+via+Attentive+Hypergraph+Neural+Network)|1|
|[Mutual Disentanglement Learning for Joint Fine-Grained Sentiment Classification and Controllable Text Generation](https://doi.org/10.1145/3477495.3532029)|Hao Fei, Chenliang Li, Donghong Ji, Fei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mutual+Disentanglement+Learning+for+Joint+Fine-Grained+Sentiment+Classification+and+Controllable+Text+Generation)|1|
|[Learning Disentangled Representations for Counterfactual Regression via Mutual Information Minimization](https://doi.org/10.1145/3477495.3532011)|Mingyuan Cheng, Xinru Liao, Quan Liu, Bin Ma, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Disentangled+Representations+for+Counterfactual+Regression+via+Mutual+Information+Minimization)|1|
|[L3E-HD: A Framework Enabling Efficient Ensemble in High-Dimensional Space for Language Tasks](https://doi.org/10.1145/3477495.3531761)|Fangxin Liu, Haomin Li, Xiaokang Yang, Li Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=L3E-HD:+A+Framework+Enabling+Efficient+Ensemble+in+High-Dimensional+Space+for+Language+Tasks)|1|
|[Graph Capsule Network with a Dual Adaptive Mechanism](https://doi.org/10.1145/3477495.3531764)|Xiangping Zheng, Xun Liang, Bo Wu, Yuhui Guo, Xuan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Capsule+Network+with+a+Dual+Adaptive+Mechanism)|1|
|[Training Entire-Space Models for Target-oriented Opinion Words Extraction](https://doi.org/10.1145/3477495.3531768)|Yuncong Li, Fang Wang, ShengHua Zhong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Training+Entire-Space+Models+for+Target-oriented+Opinion+Words+Extraction)|1|
|[Point Prompt Tuning for Temporally Language Grounding](https://doi.org/10.1145/3477495.3531795)|Yawen Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Point+Prompt+Tuning+for+Temporally+Language+Grounding)|1|
|[What Makes a Good Podcast Summary?](https://doi.org/10.1145/3477495.3531802)|Rezvaneh Rezapour, Sravana Reddy, Rosie Jones, Ian Soboroff||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+Makes+a+Good+Podcast+Summary?)|1|
|[BSAL: A Framework of Bi-component Structure and Attribute Learning for Link Prediction](https://doi.org/10.1145/3477495.3531804)|Bisheng Li, Min Zhou, Shengzhong Zhang, Menglin Yang, Defu Lian, Zengfeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BSAL:+A+Framework+of+Bi-component+Structure+and+Attribute+Learning+for+Link+Prediction)|1|
|[Tensor-based Graph Modularity for Text Data Clustering](https://doi.org/10.1145/3477495.3531834)|Rafika Boutalbi, Mira Ait Saada, Anastasiia Iurshina, Steffen Staab, Mohamed Nadif||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tensor-based+Graph+Modularity+for+Text+Data+Clustering)|1|
|[GraphAD: A Graph Neural Network for Entity-Wise Multivariate Time-Series Anomaly Detection](https://doi.org/10.1145/3477495.3531848)|Xu Chen, Qiu Qiu, Changshan Li, Kunqing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphAD:+A+Graph+Neural+Network+for+Entity-Wise+Multivariate+Time-Series+Anomaly+Detection)|1|
|[Lightweight Meta-Learning for Low-Resource Abstractive Summarization](https://doi.org/10.1145/3477495.3531908)|Taehun Huh, Youngjoong Ko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lightweight+Meta-Learning+for+Low-Resource+Abstractive+Summarization)|1|
|[Task-Oriented Dialogue System as Natural Language Generation](https://doi.org/10.1145/3477495.3531920)|Weizhi Wang, Zhirui Zhang, Junliang Guo, Yinpei Dai, Boxing Chen, Weihua Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Oriented+Dialogue+System+as+Natural+Language+Generation)|1|
|[Where Do Queries Come From?](https://doi.org/10.1145/3477495.3531711)|Marwah Alaofi, Luke Gallagher, Dana McKay, Lauren L. Saling, Mark Sanderson, Falk Scholer, Damiano Spina, Ryen W. White||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Where+Do+Queries+Come+From?)|1|
|[OVQA: A Clinically Generated Visual Question Answering Dataset](https://doi.org/10.1145/3477495.3531724)|Yefan Huang, Xiaoli Wang, Feiyan Liu, Guofeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OVQA:+A+Clinically+Generated+Visual+Question+Answering+Dataset)|1|
|[Monant Medical Misinformation Dataset: Mapping Articles to Fact-Checked Claims](https://doi.org/10.1145/3477495.3531726)|Ivan Srba, Branislav Pecher, Matús Tomlein, Róbert Móro, Elena Stefancova, Jakub Simko, Mária Bieliková||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Monant+Medical+Misinformation+Dataset:+Mapping+Articles+to+Fact-Checked+Claims)|1|
|[ViQuAE, a Dataset for Knowledge-based Visual Question Answering about Named Entities](https://doi.org/10.1145/3477495.3531753)|Paul Lerner, Olivier Ferret, Camille Guinaudeau, Hervé Le Borgne, Romaric Besançon, José G. Moreno, Jesús LovónMelgarejo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ViQuAE,+a+Dataset+for+Knowledge-based+Visual+Question+Answering+about+Named+Entities)|1|
|[DIANES: A DEI Audit Toolkit for News Sources](https://doi.org/10.1145/3477495.3531660)|Xiaoxiao Shang, Zhiyuan Peng, Qiming Yuan, Sabiq Khan, Lauren Xie, Yi Fang, Subramaniam Vincent||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIANES:+A+DEI+Audit+Toolkit+for+News+Sources)|1|
|[NAS-CTR: Efficient Neural Architecture Search for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3532030)|Guanghui Zhu, Feng Cheng, Defu Lian, Chunfeng Yuan, Yihua Huang|Nanjing University, Nanjing, China; University of Science and Technology of China, Hefei, China|Click-Through Rate (CTR) prediction has been widely used in many machine learning tasks such as online advertising and personalization recommendation. Unfortunately, given a domain-specific dataset, searching effective feature interaction operations and combinations from a huge candidate space requires significant expert experience and computational costs. Recently, Neural Architecture Search (NAS) has achieved great success in discovering high-quality network architectures automatically. However, due to the diversity of feature interaction operations and combinations, the existing NAS-based work that treats the architecture search as a black-box optimization problem over a discrete search space suffers from low efficiency. Therefore, it is essential to explore a more efficient architecture search method. To achieve this goal, we propose NAS-CTR, a differentiable neural architecture search approach for CTR prediction. First, we design a novel and expressive architecture search space and a continuous relaxation scheme to make the search space differentiable. Second, we formulate the architecture search for CTR prediction as a joint optimization problem with discrete constraints on architectures and leverage proximal iteration to solve the constrained optimization problem. Additionally, a straightforward yet effective method is proposed to eliminate the aggregation of skip connections. Extensive experimental results reveal that NAS-CTR can outperform the SOTA human-crafted architectures and other NAS-based methods in both test accuracy and search efficiency.|点进率预测已经广泛应用于许多机器学习任务，例如在线广告和个性化推荐。不幸的是，给定一个特定领域的数据集，从一个巨大的候选空间中搜索有效的特征交互操作和组合需要大量的专家经验和计算成本。近年来，神经网络体系结构搜索(NAS)在自动发现高质量的网络体系结构方面取得了巨大的成功。然而，由于功能交互操作和组合的多样性，现有的基于 NAS 的工作将体系结构搜索视为离散搜索空间上的黑盒子最佳化问题，效率低下。因此，有必要探索一种更有效的体系结构搜索方法。为了实现这一目标，我们提出了 NAS-CTR，一种用于 CTR 预测的可微分神经结构搜索方法。首先，我们设计了一个新颖的、具有表现力的体系结构搜索空间和一个连续松弛方案，使搜索空间具有可微性。其次，我们将 CTR 预测的体系结构搜索描述为一个联合最佳化问题，对体系结构进行离散约束，并利用近端迭代来解决约束最佳化问题。此外，提出了一种简单而有效的方法来消除跳跃连接的聚集。大量的实验结果表明，NAS-CTR 在测试精度和搜索效率方面都优于 SOTA 人工架构和其他基于 NAS 的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NAS-CTR:+Efficient+Neural+Architecture+Search+for+Click-Through+Rate+Prediction)|0|
|[Learning to Enrich Query Representation with Pseudo-Relevance Feedback for Cross-lingual Retrieval](https://doi.org/10.1145/3477495.3532013)|Ramraj Chandradevan, Eugene Yang, Mahsa Yarmohammadi, Eugene Agichtein|Emory University, Atlanta, GA, USA; Johns Hopkins University, Baltimore, MD, USA|Cross-lingual information retrieval (CLIR) aims to provide access to information across languages. Recent pre-trained multilingual language models brought large improvements to the natural language tasks, including cross-lingual adhoc retrieval. However, pseudo-relevance feedback (PRF), a family of techniques for improving ranking using the contents of top initially retrieved items, has not been explored with neural CLIR retrieval models. Two of the challenges are incorporating feedback from long documents, and cross-language knowledge transfer. To address these challenges, we propose a novel neural CLIR architecture, NCLPRF, capable of incorporating PRF feedback from multiple potentially long documents, which enables improvements to query representation in the shared semantic space between query and document languages. The additional information that the feedback documents provide in a target language, can enrich the query representation, bringing it closer to relevant documents in the embedding space. The proposed model performance across three CLIR test collections in Chinese, Russian, and Persian languages, exhibits significant improvements over traditional and SOTA neural CLIR baselines across all three collections.|跨语言信息检索(CLIR)旨在提供跨语言的信息获取途径。最近预先训练的多语言模型给自然语言任务带来了很大的改进，包括跨语言的即席检索。然而，伪相关反馈(PRF)作为一种利用最初检索项目的内容来提高排名的技术，尚未在神经元 CLIR 检索模型中得到应用。其中两个挑战是整合来自长文档的反馈，以及跨语言的知识转移。为了应对这些挑战，我们提出了一个新的神经 CLIR 架构，NCLPRF，能够合并来自多个潜在的长文档的 PRF 反馈，这使得查询语言和文档语言之间的共享语义空间中的查询表示得到改进。反馈文档以目标语言提供的附加信息可以丰富查询表示，使其更接近嵌入空间中的相关文档。在中文，俄文和波斯语的三个 CLIR 测试集合中，所提出的模型性能比所有三个集合中的传统和 SOTA 神经 CLIR 基线都有显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Enrich+Query+Representation+with+Pseudo-Relevance+Feedback+for+Cross-lingual+Retrieval)|0|
|[Incorporating Retrieval Information into the Truncation of Ranking Lists for Better Legal Search](https://doi.org/10.1145/3477495.3531998)|Yixiao Ma, Qingyao Ai, Yueyue Wu, Yunqiu Shao, Yiqun Liu, Min Zhang, Shaoping Ma|University of Utah, Salt Lake City, UT, USA; Tsinghua University, Beijing, China|The truncation of ranking lists predicted by retrieval models is vital to ensure users' search experience. Particularly, in specific vertical domains where documents are usually complicated and extensive (e.g., legal cases), the cost of browsing results is much higher than traditional IR tasks (e.g., Web search) and setting a reasonable cut-off position is quite necessary. While it is straightforward to apply existing result list truncation approaches to legal case retrieval, the effectiveness of these methods is limited because they only focus on simple document statistics and usually fail to capture the context information of documents in the ranking list. These existing efforts also treat result list truncation as an isolated task instead of a component in the entire ranking process, limiting the usage of truncation in practical systems. To tackle these limitations, we propose LeCut, a ranking list truncation model for legal case retrieval. LeCut utilizes contextual features of the retrieval task to capture the semantic-level similarity between documents and decides the best cut-off position with attention mechanisms. We further propose a Joint Optimization of Truncation and Reranking (JOTR) framework based on LeCut to improve the performance of truncation and retrieval tasks simultaneously. Comparison against competitive baselines on public benchmark datasets demonstrates the effectiveness of LeCut and JOTR. A case study is conducted to visualize the cut-off positions of LeCut and the process of how JOTR improves both retrieval and truncation tasks.|检索模型预测的排名列表的截断对于保证用户的搜索体验至关重要。特别是，在特定的垂直领域，文档通常是复杂和广泛的(例如，法律案件) ，浏览结果的成本远远高于传统的 IR 任务(例如，网络搜索) ，设置一个合理的截止位置是非常必要的。虽然将现有的结果清单截断方法应用于法律案件检索很简单，但这些方法的有效性有限，因为它们只侧重于简单的文件统计，通常无法捕捉排名清单中文件的上下文信息。这些现有的工作还将结果列表截断视为一个孤立的任务，而不是整个排序过程中的一个组件，从而限制了截断在实际系统中的使用。为了解决这些局限性，我们提出了 LeCut，一种用于法律案例检索的排序列表截断模型。LeCut 利用检索任务的上下文特征来捕获文档之间的语义级相似性，并通过注意机制确定最佳截止位置。进一步提出了一种基于 LeCut 的联合优化截断与重排(JOTR)框架，以同时提高截断与检索任务的性能。与公共基准数据集的竞争基线进行比较，可以证明 LeCut 和 JOTR 的有效性。通过案例研究，可视化 LeCut 的截止位置以及 JOTR 如何改进检索和截断任务的过程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Retrieval+Information+into+the+Truncation+of+Ranking+Lists+for+Better+Legal+Search)|0|
|[Ada-Ranker: A Data Distribution Adaptive Ranking Paradigm for Sequential Recommendation](https://doi.org/10.1145/3477495.3531931)|Xinyan Fan, Jianxun Lian, Wayne Xin Zhao, Zheng Liu, Chaozhuo Li, Xing Xie|Microsoft Research Asia, Beijing, China; Renmin University of China, Beijing, China|A large-scale recommender system usually consists of recall and ranking modules. The goal of ranking modules (aka rankers) is to elaborately discriminate users' preference on item candidates proposed by recall modules. With the success of deep learning techniques in various domains, we have witnessed the mainstream rankers evolve from traditional models to deep neural models. However, the way that we design and use rankers remains unchanged: offline training the model, freezing the parameters, and deploying it for online serving. Actually, the candidate items are determined by specific user requests, in which underlying distributions (e.g., the proportion of items for different categories, the proportion of popular or new items) are highly different from one another in a production environment. The classical parameter-frozen inference manner cannot adapt to dynamic serving circumstances, making rankers' performance compromised. In this paper, we propose a new training and inference paradigm, termed as Ada-Ranker, to address the challenges of dynamic online serving. Instead of using parameter-frozen models for universal serving, Ada-Ranker can adaptively modulate parameters of a ranker according to the data distribution of the current group of item candidates. We first extract distribution patterns from the item candidates. Then, we modulate the ranker by the patterns to make the ranker adapt to the current data distribution. Finally, we use the revised ranker to score the candidate list. In this way, we empower the ranker with the capacity of adapting from a global model to a local model which better handles the current task. As a first study, we examine our Ada-Ranker paradigm in the sequential recommendation scenario. Experiments on three datasets demonstrate that Ada-Ranker can effectively enhance various base sequential models and also outperform a comprehensive set of competitive baselines.|一个大规模的推荐系统通常包括召回和排名模块。排序模块(又称排序器)的目标是精心区分用户对召回模块提出的候选项的偏好。随着深度学习技术在各个领域的成功，我们目睹了主流的排名从传统模型演变为深度神经模型。然而，我们设计和使用排名的方式保持不变: 离线训练模型，冻结参数，并部署它在线服务。实际上，候选项是由特定的用户请求决定的，在这种情况下，底层分布(例如，不同类别的项目比例，流行项目或新项目的比例)在生产环境中彼此之间差异很大。传统的参数冻结推理方式不能适应动态服务环境，使得排序器的性能受到影响。在本文中，我们提出了一个新的训练和推理范式，称为 Ada-Ranker，以解决动态在线服务的挑战。Ada-Ranker 可以根据当前项目候选者组的数据分布自适应地调整排序器的参数，而不必使用通用服务的参数冻结模型。我们首先从候选项中提取分布模式。然后，根据模式对排序器进行调整，使排序器适应当前的数据分布。最后，我们使用修改后的排名对候选人列表进行评分。通过这种方式，我们赋予排名者从全球模型到更好地处理当前任务的局部模型的适应能力。作为第一个研究，我们在顺序推荐场景中检查我们的 Ada-Ranker 范式。在三个数据集上的实验表明，Ada-Ranker 能够有效地增强各种基本序列模型，并且表现优于一组综合的竞争基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ada-Ranker:+A+Data+Distribution+Adaptive+Ranking+Paradigm+for+Sequential+Recommendation)|0|
|[Retrieval and Recommendation Systems at the Crossroads of Artificial Intelligence, Ethics, and Regulation](https://doi.org/10.1145/3477495.3532683)|Markus Schedl, Emilia Gómez, Elisabeth Lex|Graz University of Technology, Graz, Austria; European Commission, Joint Research Centre and Universitat Pompeu Fabra, Seville/Barcelona, Spain; Johannes Kepler University Linz & Linz Institue of Technology, Linz, Austria|This tutorial aims at providing its audience an interdisciplinary overview about the topics of fairness and non-discrimination, diversity, and transparency of AI systems, tailored to the research fields of information retrieval and recommender systems. By means of this tutorial, we would like to equip the mostly technical audience of SIGIR with the necessary understanding of the ethical implications of their research and development on the one hand, and of recent political and legal regulations that address the aforementioned challenges on the other hand.|本教程旨在为读者提供一个关于人工智能系统的公平性和非歧视性、多样性和透明度等主题的跨学科概述，适用于信息检索和推荐系统的研究领域。通过本教程，我们希望让 SIGIR 的大多数技术读者一方面了解他们的研究和发展的道德影响，另一方面了解解决上述挑战的最新政治和法律法规。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval+and+Recommendation+Systems+at+the+Crossroads+of+Artificial+Intelligence,+Ethics,+and+Regulation)|0|
|[Adversarial Filtering Modeling on Long-term User Behavior Sequences for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531788)|Xiaochen Li, Jian Liang, Xialong Liu, Yu Zhang|Alibaba Group, Beijing, China; Lazada Group, Beijing, China|Rich user behavior information is of great importance for capturing and understanding user interest in click-through rate (CTR) prediction. To improve the richness, collecting long-term behaviors becomes a typical approach in academy and industry but at the cost of increasing online storage and latency. Recently, researchers have proposed several approaches to shorten long-term behavior sequence and then model user interests. These approaches reduce online cost efficiently but do not well handle the noisy information in long-term user behavior, which may deteriorate the performance of CTR prediction significantly. To obtain better cost/performance trade-off, we propose a novel Adversarial Filtering Model (ADFM) to model long-term user behavior. ADFM uses a hierarchical aggregation representation to compress raw behavior sequence and then learns to remove useless behavior information with an adversarial filtering mechanism. The selected user behaviors are fed into interest extraction module for CTR prediction. Experimental results on public datasets and industrial dataset demonstrate that our method achieves significant improvements over state-of-the-art models.|丰富的用户行为信息对于捕捉和理解用户对点进率预测的兴趣非常重要。为了提高丰富性，收集长期行为成为学术界和工业界的一种典型方法，但代价是增加在线存储和延迟。最近，研究人员提出了几种方法来缩短长期行为序列，然后模型用户的兴趣。这些方法有效地降低了在线成本，但不能很好地处理长期用户行为中的噪声信息，这可能会严重影响 CTR 预测的性能。为了获得更好的性价比，我们提出了一种新的对抗过滤模型(ADFM)来模拟长期用户行为。ADFM 使用分层聚合表示来压缩原始行为序列，然后学习使用对抗性过滤机制去除无用的行为信息。将选定的用户行为反馈到兴趣提取模块中进行点击率预测。在公共数据集和工业数据集上的实验结果表明，该方法比现有的模型有明显的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Filtering+Modeling+on+Long-term+User+Behavior+Sequences+for+Click-Through+Rate+Prediction)|0|
|[LoL: A Comparative Regularization Loss over Query Reformulation Losses for Pseudo-Relevance Feedback](https://doi.org/10.1145/3477495.3532017)|Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, Xueqi Cheng|Data Intelligence System Research Center, Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China; Tsinghua University, Beijing, China; Data Intelligence System Research Center, Institute of Computing Technology, CAS, Beijing, China|Pseudo-relevance feedback (PRF) has proven to be an effective query reformulation technique to improve retrieval accuracy. It aims to alleviate the mismatch of linguistic expressions between a query and its potential relevant documents. Existing PRF methods independently treat revised queries originating from the same query but using different numbers of feedback documents, resulting in severe query drift. Without comparing the effects of two different revisions from the same query, a PRF model may incorrectly focus on the additional irrelevant information increased in the more feedback, and thus reformulate a query that is less effective than the revision using the less feedback. Ideally, if a PRF model can distinguish between irrelevant and relevant information in the feedback, the more feedback documents there are, the better the revised query will be. To bridge this gap, we propose the Loss-over-Loss (LoL) framework to compare the reformulation losses between different revisions of the same query during training. Concretely, we revise an original query multiple times in parallel using different amounts of feedback and compute their reformulation losses. Then, we introduce an additional regularization loss on these reformulation losses to penalize revisions that use more feedback but gain larger losses. With such comparative regularization, the PRF model is expected to learn to suppress the extra increased irrelevant information by comparing the effects of different revised queries. Further, we present a differentiable query reformulation method to implement this framework. This method revises queries in the vector space and directly optimizes the retrieval performance of query vectors, applicable for both sparse and dense retrieval models. Empirical evaluation demonstrates the effectiveness and robustness of our method for two typical sparse and dense retrieval models.|伪相关反馈(PRF)已被证明是一种有效的查询重构技术，以提高检索的准确性。它旨在缓解查询与潜在相关文档之间的语言表达不匹配问题。现有的 PRF 方法独立处理来自同一查询但使用不同数量的反馈文档的修改查询，导致严重的查询漂移。如果不比较来自同一查询的两个不同修订的效果，PRF 模型可能会错误地关注更多反馈中增加的附加不相关信息，从而使用更少的反馈重新表述比修订更低效的查询。理想情况下，如果 PRF 模型能够区分反馈中的不相关信息和相关信息，那么反馈文档越多，修改后的查询就越好。为了弥补这一差距，我们提出了损失超过损失(LoL)框架来比较同一查询在培训期间不同修订版本之间的重构损失。具体来说，我们使用不同数量的反馈并行多次修改原始查询，并计算它们的重新表述损失。然后，我们引入一个额外的正则化损失对这些重制损失，以惩罚修订使用更多的反馈，但获得更大的损失。通过这种比较正则化，PRF 模型可以通过比较不同修订查询的效果来抑制额外增加的不相关信息。进一步，我们提出了一个可微查询重构方法来实现这个框架。该方法对向量空间中的查询进行修正，直接优化查询向量的检索性能，适用于稀疏和密集检索模型。实验结果表明，该方法对两种典型的稀疏和密集检索模型具有较好的鲁棒性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LoL:+A+Comparative+Regularization+Loss+over+Query+Reformulation+Losses+for+Pseudo-Relevance+Feedback)|0|
|[Determinantal Point Process Likelihoods for Sequential Recommendation](https://doi.org/10.1145/3477495.3531965)|Yuli Liu, Christian J. Walder, Lexing Xie|Data61, CSIRO & Australian National University, Canberra, Australia; Australian National University & Data61, CSIRO, Canberra, Australia|Sequential recommendation is a popular task in academic research and close to real-world application scenarios, where the goal is to predict the next action(s) of the user based on his/her previous sequence of actions. In the training process of recommender systems, the loss function plays an essential role in guiding the optimization of recommendation models to generate accurate suggestions for users. However, most existing sequential recommendation tech- niques focus on designing algorithms or neural network architectures, and few efforts have been made to tailor loss functions that fit naturally into the practical application scenario of sequential recommender systems. Ranking-based losses, such as cross-entropy and Bayesian Personalized Ranking (BPR) are widely used in the sequential recommendation area. We argue that such objective functions suffer from two inherent drawbacks: i) the dependencies among elements of a sequence are overlooked in these loss formulations; ii) instead of balancing accuracy (quality) and diversity, only generating accurate results has been over emphasized. We therefore propose two new loss functions based on the Determinantal Point Process (DPP) likelihood, that can be adaptively applied to estimate the subsequent item or items. The DPP-distributed item set captures natural dependencies among temporal actions, and a quality vs. diversity decomposition of the DPP kernel pushes us to go beyond accuracy-oriented loss functions. Experimental results using the proposed loss functions on three real-world datasets show marked improvements over state-of-the-art sequential recommendation methods in both quality and diversity metrics.|顺序推荐是学术研究中的一个热门任务，它接近于真实的应用场景，其目标是根据用户以前的操作顺序预测他/她的下一个操作。在推荐系统的培训过程中，损失函数对于指导推荐模型的优化，为用户提供准确的建议起着至关重要的作用。然而，现有的顺序推荐技术大多侧重于设计算法或神经网络体系结构，很少有人努力去调整自然适合顺序推荐系统实际应用场景的损失函数。基于排序的损失，如交叉熵和贝叶斯个性化排序(BPR)被广泛应用于序列推荐领域。我们认为这样的目标函数有两个固有的缺点: i)在这些损失公式中忽略了序列元素之间的依赖关系; ii)没有平衡准确性(质量)和多样性，只有产生准确的结果被过分强调。因此，我们提出两个新的基于行列式点过程(DPP)可能性的损失函数，可以自适应地应用于估计随后的项目。DPP 分布式项目集捕获时间操作之间的自然依赖关系，DPP 内核的质量与多样性分解促使我们超越面向准确性的损失函数。在三个实际数据集上使用提出的损失函数的实验结果显示，在质量和多样性度量方面，该方法比最先进的顺序推荐方法有明显的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Determinantal+Point+Process+Likelihoods+for+Sequential+Recommendation)|0|
|[Re-weighting Negative Samples for Model-Agnostic Matching](https://doi.org/10.1145/3477495.3532053)|Jiazhen Lou, Hong Wen, Fuyu Lv, Jing Zhang, Tengfei Yuan, Zhao Li|Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; The University of Sydney, Darlington, NSW, Australia|Recommender Systems (RS), as an efficient tool to discover users' interested items from a very large corpus, has attracted more and more attention from academia and industry. As the initial stage of RS, large-scale matching is fundamental yet challenging. A typical recipe is to learn user and item representations with a two-tower architecture and then calculate the similarity score between both representation vectors, which however still struggles in how to properly deal with negative samples. In this paper, we find that the common practice that randomly sampling negative samples from the entire space and treating them equally is not an optimal choice, since the negative samples from different sub-spaces at different stages have different importance to a matching model. To address this issue, we propose a novel method named Unbiased Model-Agnostic Matching Approach (UMA2). It consists of two basic modules including 1) General Matching Model (GMM), which is model-agnostic and can be implemented as any embedding-based two-tower models; and 2) Negative Samples Debias Network (NSDN), which discriminates negative samples by borrowing the idea of Inverse Propensity Weighting (IPW) and re-weighs the loss in GMM. UMA$^2$ seamlessly integrates these two modules in an end-to-end multi-task learning framework. Extensive experiments on both real-world offline dataset and online A/B test demonstrate its superiority over state-of-the-art methods.|推荐系统(RS)作为一种从庞大的语料库中发现用户感兴趣的项目的有效工具，越来越受到学术界和业界的关注。作为遥感的初始阶段，大规模匹配是一个基础性的挑战。一个典型的方法是使用双塔体系结构学习用户和项目表示，然后计算两个表示向量之间的相似度得分，但是如何正确处理负样本仍然是一个难题。在本文中，我们发现从整个空间中随机抽取负样本并平等对待它们的常见做法并不是最优选择，因为不同阶段不同子空间中的负样本对匹配模型的重要性不同。为了解决这一问题，我们提出了一种新的方法——无偏模型-不可知匹配方法(UMA2)。它包括两个基本模块: 1)通用匹配模型(GMM) ，该模型与模型无关，可以作为任何嵌入式双塔模型实现; 2)负样本偏差网络(NSDN) ，该网络借助逆倾向加权(IPW)的思想对负样本进行判别，并在 GMM 中重新权衡损失。UMA $^ 2 $在端到端多任务学习框架中无缝地集成了这两个模块。通过对现实世界离线数据集和在线 A/B 测试的大量实验，证明了该方法优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Re-weighting+Negative+Samples+for+Model-Agnostic+Matching)|0|
|[Item-Provider Co-learning for Sequential Recommendation](https://doi.org/10.1145/3477495.3531756)|Lei Chen, Jingtao Ding, Min Yang, Chengming Li, Chonggang Song, Lingling Yi|Sun Yat-sen University, Shenzhen, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Tencent Inc., Shenzhen, China|Sequential recommender systems (SRSs) have become a research hotspot recently due to its powerful ability in capturing users' dynamic preferences. The key idea behind SRSs is to model the sequential dependencies over the user-item interactions. However, we argue that users' preferences are not only determined by their view or purchase items but also affected by the item-providers with which users have interacted. For instance, in a short-video scenario, a user may click on a video because he/she is attracted to either the video content or simply the video-providers as the vloggers are his/her idols. Motivated by the above observations, in this paper, we propose IPSRec, a novel Item-Provider co-learning framework for Sequential Recommendation. Specifically, we propose two representation learning methods (single-steam and cross-stream) to learn comprehensive item and user representations based on the user's historical item sequence and provider sequence. Then, contrastive learning is employed to further enhance the user embeddings in a self-supervised manner, which treats the representations of a specific user learned from the item side as well as the item-provider side as the positive pair and treats the representations of different users in the batch as the negative samples. Extensive experiments on three real-world SRS datasets demonstrate that IPSRec achieves substantially better results than the strong competitors. For reproducibility, our code and data are available at https://github.com/siat-nlp/IPSRec.|顺序推荐系统(SRS)由于具有捕获用户动态偏好的强大功能，近年来成为研究的热点。SRS 背后的关键思想是在用户-项目交互之间建立顺序依赖关系模型。然而，我们认为用户的偏好不仅取决于他们的观点或购买项目，而且还受到项目供应商的用户已经互动。例如，在一个短视频场景中，用户可能会点击一个视频，因为他/她要么被视频内容吸引，要么被视频提供商吸引，因为视频博客是他/她的偶像。基于上述观察，本文提出了一种新的项目提供者协同学习的序贯推荐框架 IPSRec。具体来说，我们提出了两种表示学习方法(单蒸汽和跨流)来学习综合项目和用户表示基于用户的历史项目序列和提供者序列。然后，采用对比学习的方法，以自监督的方式进一步增强用户嵌入，将从项目侧和项目提供者侧学习到的特定用户的表征视为正对，将批处理中不同用户的表征视为负样本。对三个实际 SRS 数据集的大量实验表明，IPSRec 比强大的竞争对手获得了更好的结果。为确保重复性，我们的代码和数据可在 https://github.com/siat-nlp/ipsrec 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item-Provider+Co-learning+for+Sequential+Recommendation)|0|
|[Inconsistent Ranking Assumptions in Medical Search and Their Downstream Consequences](https://doi.org/10.1145/3477495.3531898)|Daniel Cohen, Kevin Du, Bhaskar Mitra, Laura Mercurio, Navid Rekabsaz, Carsten Eickhoff|Brown Univ, Alpert Med Sch, Providence, RI 02912 USA; Microsoft, Montreal, PQ, Canada; Johannes Kepler Univ Linz, Linz, Austria; Brown Univ, Providence, RI 02912 USA|Given a query, neural retrieval models predict point estimates of relevance for each document; however, a significant drawback of relying solely on point estimates is that they contain no indication of the model's confidence in its predictions. Despite this lack of information, downstream methods such as reranking, cutoff prediction, and none-of-the-above classification are still able to learn effective functions to accomplish their respective tasks. Unfortunately, these downstream methods can suffer poor performance when the initial ranking model loses confidence in its score predictions. This becomes increasingly important in high-stakes settings, such as medical searches that can influence health decision making. Recent work has resolved this lack of information by introducing Bayesian uncertainty to capture the possible distribution of a document score. This paper presents the use of this uncertainty information as an indicator of how well downstream methods will function over a ranklist. We highlight a significant bias against certain disease-related queries within the posterior distribution of a neural model, and show that this bias in a model's predictive distribution propagates to downstream methods. Finally, we introduce a multi-distribution uncertainty metric, confidence decay, as a valid way of partially identifying these failure cases in an offline setting without the need of any user feedback.|给定一个查询，神经检索模型预测每个文档的相关性点估计; 然而，仅仅依赖点估计的一个显著缺点是，它们不包含模型对其预测的置信度的指示。尽管缺乏这种信息，下游方法，如重新排序，截止预测，以及没有上述分类仍然能够学习有效的功能，以完成各自的任务。不幸的是，当初始排名模型对其分数预测失去信心时，这些下游方法的性能可能会很差。这在高风险环境中变得越来越重要，例如可以影响健康决策的医学搜索。最近的工作通过引入贝叶斯不确定性来捕获文档分数的可能分布，解决了这种信息缺乏的问题。本文介绍了使用这种不确定性信息作为一个指标，以及下游方法将如何在一个排名表的功能。我们强调，在神经模型的后验概率中，某些与疾病相关的查询存在显著的偏差，并表明模型预测分布的这种偏差会传播到下游方法。最后，我们介绍了一个多分布不确定性度量，置信度衰减，作为一个有效的方法，部分识别这些失败案例在脱机设置，而不需要任何用户反馈。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inconsistent+Ranking+Assumptions+in+Medical+Search+and+Their+Downstream+Consequences)|0|
|[Exploiting Session Information in BERT-based Session-aware Sequential Recommendation](https://doi.org/10.1145/3477495.3531910)|Jinseok Jamie Seol, Youngrok Ko, Sanggoo Lee|Seoul National University, Seoul, Republic of Korea|In recommendation systems, utilizing the user interaction history as sequential information has resulted in great performance improvement. However, in many online services, user interactions are commonly grouped by sessions that presumably share preferences, which requires a different approach from ordinary sequence representation techniques. To this end, sequence representation models with a hierarchical structure or various viewpoints have been developed but with a rather complex network structure. In this paper, we propose three methods to improve recommendation performance by exploiting session information while minimizing additional parameters in a BERT-based sequential recommendation model: using session tokens, adding session segment embeddings, and a time-aware self-attention. We demonstrate the feasibility of the proposed methods through experiments on widely used recommendation datasets.|在推荐系统中，利用用户交互历史作为序列信息，可以大大提高推荐系统的性能。然而，在许多在线服务中，用户交互通常按照可能共享首选项的会话进行分组，这需要一种不同于普通序列表示技术的方法。为此，开发了具有层次结构或不同视点的序列表示模型，但其网络结构相当复杂。在基于 BERT 的顺序推荐模型中，我们提出了利用会话信息同时最小化附加参数来提高推荐性能的三种方法: 使用会话令牌、增加会话段嵌入和有时间意识的自我注意。通过在广泛使用的推荐数据集上的实验，验证了该方法的可行性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Session+Information+in+BERT-based+Session-aware+Sequential+Recommendation)|0|
|[Towards Reproducible Machine Learning Research in Information Retrieval](https://doi.org/10.1145/3477495.3532686)|Ana Lucic, Maurits J. R. Bleeker, Maarten de Rijke, Koustuv Sinha, Sami Jullien, Robert Stojnic|McGill University, Montreal, Canada; University of Amsterdam, Amsterdam, Netherlands; Facebook AI Research, London, United Kingdom|While recent progress in the field of machine learning (ML) and information retrieval (IR) has been significant, the reproducibility of these cutting-edge results is often lacking, with many submissions failing to provide the necessary information in order to ensure subsequent reproducibility. Despite the introduction of self-check mechanisms before submission (such as the Reproducibility Checklist, criteria for evaluating reproducibility during reviewing at several major conferences, artifact review and badging framework, and dedicated reproducibility tracks and challenges at major IR conferences, the motivation for executing reproducible research is lacking in the broader information community. We propose this tutorial as a gentle introduction to help ensure reproducible research in IR, with a specific emphasis on ML aspects of IR research.|虽然机器学习(ML)和信息检索学习(IR)领域的最新进展显著，但这些尖端结果的可重复性往往缺乏，许多提交的文件未能提供必要的信息，以确保随后的可重复性。尽管在提交之前引入了自我检查机制(例如重现性检查表，在几个主要会议上评估重现性的标准，工件审查和徽章框架，以及在主要 IR 会议上专门的重现性轨道和挑战，在更广泛的信息社区中缺乏执行可重现性研究的动机。我们建议本教程作为一个温和的介绍，以帮助确保在 IR 的重复性研究，并特别强调机器学习方面的 IR 研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Reproducible+Machine+Learning+Research+in+Information+Retrieval)|0|
|[Structured and Natural Responses Co-generation for Conversational Search](https://doi.org/10.1145/3477495.3532063)|Chenchen Ye, Lizi Liao, Fuli Feng, Wei Ji, TatSeng Chua|Singapore Management University, Singapore, Singapore; University of Science and Technology of China, Heifei, China; National University of Singapore, Singapore, Singapore; Sea-NExT Joint Lab, National University of Singapore, Singapore, Singapore|Generating fluent and informative natural responses while main- taining representative internal states for search optimization is critical for conversational search systems. Existing approaches ei- ther 1) predict structured dialog acts first and then generate natural response; or 2) map conversation context to natural responses di- rectly in an end-to-end manner. Both kinds of approaches have shortcomings. The former suffers from error accumulation while the semantic associations between structured acts and natural re- sponses are confined in single direction. The latter emphasizes generating natural responses but fails to predict structured acts. Therefore, we propose a neural co-generation model that gener- ates the two concurrently. The key lies in a shared latent space shaped by two informed priors. Specifically, we design structured dialog acts and natural response auto-encoding as two auxiliary tasks in an interconnected network architecture. It allows for the concurrent generation and bidirectional semantic associations. The shared latent space also enables asynchronous reinforcement learn- ing for further joint optimization. Experiments show that our model achieves significant performance improvements.|生成流畅和信息丰富的自然反应，同时为搜索引擎优化保留有代表性的内部状态，这对会话搜索系统至关重要。现有的方法包括: 1)预测结构化对话首先发生，然后产生自然反应; 或者2)以端到端的方式将对话上下文直接映射到自然反应。这两种方法都有缺点。结构化行为和自然反应之间的语义联系是单向的，而结构化行为和自然反应之间的语义联系是单向的。后者强调产生自然反应，但无法预测结构化行为。因此，我们提出了一个神经元协同生成模型，并生成两个。关键在于一个共享的潜在空间，由两个知情的前任塑造。具体来说，我们设计了结构化对话行为和自然响应自动编码作为互联网络体系结构中的两个辅助任务。它允许并发生成和双向语义关联。共享潜在空间还支持异步强化学习，以进一步优化联合。实验结果表明，该模型取得了显著的性能改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structured+and+Natural+Responses+Co-generation+for+Conversational+Search)|0|
|[PEVAE: A Hierarchical VAE for Personalized Explainable Recommendation](https://doi.org/10.1145/3477495.3532039)|Zefeng Cai, Zerui Cai|East China Normal University, Shanghai, China|Variational autoencoders (VAEs) have been widely applied in recommendations. One reason is that their amortized inferences are beneficial for overcoming the data sparsity. However, in explainable recommendation that generates natural language explanations, they are still rarely explored. Thus, we aim to extend VAE to explainable recommendation. In this task, we find that VAE can generate acceptable explanations for users with few relevant training samples, however, it tends to generate less personalized explanations for users with relatively sufficient samples than autoencoders (AEs). We conjecture that information shared by different users in VAE disturbs the information for a specific user. To deal with this problem, we present PErsonalized VAE (PEVAE) that generates personalized natural language explanations for explainable recommendation. Moreover, we propose two novel mechanisms to aid our model in generating more personalized explanations, including 1) Self-Adaption Fusion (SAF) manipulates the latent space in a self-adaption manner for controlling the influence of shared information. In this way, our model can enjoy the advantage of overcoming the sparsity of data while generating more personalized explanations for a user with relatively sufficient training samples. 2) DEpendence Maximization (DEM) strengthens dependence between recommendations and explanations by maximizing the mutual information. It makes the explanation more specific to the input user-item pair and thus improves the personalization of the generated explanations. Extensive experiments show PEVAE can generate more personalized explanations and further analyses demonstrate the practical effect of our proposed methods.|变分自动编码器(VAE)已被广泛应用于建议。一个原因是，他们的摊销推断有利于克服数据稀疏。然而，在生成自然语言解释的可解释推荐中，它们仍然很少被探索。因此，我们的目标是将 VAE 扩展到可解释的推荐。在这个任务中，我们发现 VAE 可以在相关训练样本较少的情况下为用户生成可接受的解释，但是，与自动编码器(AE)相比，它往往在样本相对充足的情况下为用户生成较少的个性化解释。我们推测 VAE 中不同用户共享的信息会干扰特定用户的信息。为了解决这个问题，我们提出了个性化的 VAE (PEVAE) ，它可以为解释性推荐生成个性化的自然语言解释。此外，我们提出了两种新的机制来帮助我们的模型产生更多的个性化解释，包括1)自适应融合(SAF)以自适应的方式操纵潜在空间来控制共享信息的影响。通过这种方式，我们的模型可以在克服数据稀疏性的同时，通过相对充足的训练样本为用户生成更加个性化的解释。2)依赖最大化(DEM)通过最大化相互信息来增强推荐与解释之间的依赖性。它使解释更加具体到输入用户项对，从而改进了生成的解释的个性化。大量的实验表明，PEVAE 可以产生更加个性化的解释，进一步的分析表明，我们提出的方法的实际效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PEVAE:+A+Hierarchical+VAE+for+Personalized+Explainable+Recommendation)|0|
|[Counterfactual Learning To Rank for Utility-Maximizing Query Autocompletion](https://doi.org/10.1145/3477495.3531958)|Adam Block, Rahul Kidambi, Daniel N. Hill, Thorsten Joachims, Inderjit S. Dhillon|Amazon Search, Berkeley, CA, USA; Amazon Music, San Fransisco, CA, USA; University of Texas at Austin, Austin, TX, USA; Massachusetts Institute of Technology, Cambridge, MA, USA|Conventional methods for query autocompletion aim to predict which completed query a user will select from a list. A shortcoming of this approach is that users often do not know which query will provide the best retrieval performance on the current information retrieval system, meaning that any query autocompletion methods trained to mimic user behavior can lead to suboptimal query suggestions. To overcome this limitation, we propose a new approach that explicitly optimizes the query suggestions for downstream retrieval performance. We formulate this as a problem of ranking a set of rankings, where each query suggestion is represented by the downstream item ranking it produces. We then present a learning method that ranks query suggestions by the quality of their item rankings. The algorithm is based on a counterfactual learning approach that is able to leverage feedback on the items (e.g., clicks, purchases) to evaluate query suggestions through an unbiased estimator, thus avoiding the assumption that users write or select optimal queries. We establish theoretical support for the proposed approach and provide learning-theoretic guarantees. We also present empirical results on publicly available datasets, and demonstrate real-world applicability using data from an online shopping store.|查询自动完成的传统方法旨在预测用户将从列表中选择哪个已完成的查询。这种方法的一个缺点是，用户通常不知道哪个查询将在当前的信息检索系统上提供最佳的检索性能，这意味着任何经过训练的模拟用户行为的查询自动完成方法都可能导致次优的查询建议。为了克服这一限制，我们提出了一种新的方法，显式优化查询建议的下游检索性能。我们将这个问题表述为对一组排名进行排序的问题，其中每个查询建议由它产生的下游项目排名表示。然后，我们提出了一种学习方法，根据项目排名的质量对查询建议进行排序。该算法基于一种反事实学习方法，能够利用对项目(如点击、购买)的反馈，通过一个无偏估计器来评估查询建议，从而避免了用户编写或选择最佳查询的假设。我们为提出的方法建立了理论支持，并提供了学习理论保证。我们还提出了公开可用数据集的实证结果，并证明了真实世界的适用性使用数据从网上购物商店。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Learning+To+Rank+for+Utility-Maximizing+Query+Autocompletion)|0|
|[Automatic Expert Selection for Multi-Scenario and Multi-Task Search](https://doi.org/10.1145/3477495.3531942)|Xinyu Zou, Zhi Hu, Yiming Zhao, Xuchu Ding, Zhongyi Liu, Chenliang Li, Aixin Sun|Wuhan University, Wuhan, China; Nanyang Technological University, Singapore, Singapore; Ant Group, Hangzhou, China|Multi-scenario learning (MSL) enables a service provider to cater for users' fine-grained demands by separating services for different user sectors, e.g., by user's geographical region. Under each scenario there is a need to optimize multiple task-specific targets e.g., click through rate and conversion rate, known as multi-task learning (MTL). Recent solutions for MSL and MTL are mostly based on the multi-gate mixture-of-experts (MMoE) architecture. MMoE structure is typically static and its design requires domain-specific knowledge, making it less effective in handling both MSL and MTL. In this paper, we propose a novel Automatic Expert Selection framework for Multi-scenario and Multi-task search, named AESM2. AESM2 integrates both MSL and MTL into a unified framework with an automatic structure learning. Specifically, AESM2 stacks multi-task layers over multi-scenario layers. This hierarchical design enables us to flexibly establish intrinsic connections between different scenarios, and at the same time also supports high-level feature extraction for different tasks. At each multi-scenario/multi-task layer, a novel expert selection algorithm is proposed to automatically identify scenario-/task-specific and shared experts for each input. Experiments over two real-world large-scale datasets demonstrate the effectiveness of AESM2 over a battery of strong baselines. Online A/B test also shows substantial performance gain on multiple metrics. Currently, AESM2 has been deployed online for serving major traffic.|多场景学习可让服务供应商因应用户的细粒度需求，将不同用户界别的服务(例如按用户地理地区)分开。在每种情况下，都需要优化多个特定任务的目标，例如点击率和转换率，称为多任务学习(MTL)。最近的 MSL 和 MTL 解决方案大多基于多门混合专家(MMoE)体系结构。MMoE 结构通常是静态的，其设计需要特定于领域的知识，因此在处理 MSL 和 MTL 时效率较低。本文提出了一种面向多场景多任务搜索的自动专家选择框架 AESM2。AESM2将 MSL 和 MTL 集成到一个具有自动结构学习的统一框架中。具体来说，AESM2在多场景层上堆叠多任务层。这种分层设计使我们能够灵活地建立不同场景之间的内在联系，同时也支持不同任务的高级特征提取。在每个多场景/多任务层，提出了一种新的专家选择算法来自动识别每个输入的场景/任务特定的和共享的专家。通过两个真实世界的大规模数据集的实验证明了 AESM2在一组强基线上的有效性。在线 A/B 测试还显示了在多个指标上的大量性能增益。目前，AESM2已经部署在线服务主要流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Expert+Selection+for+Multi-Scenario+and+Multi-Task+Search)|0|
|[Multi-Agent RL-based Information Selection Model for Sequential Recommendation](https://doi.org/10.1145/3477495.3532022)|Kaiyuan Li, Pengfei Wang, Chenliang Li|Wuhan University, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|For sequential recommender, the coarse-grained yet sparse sequential signals mined from massive user-item interactions have become the bottleneck to further improve the recommendation performance. To alleviate the spareness problem, exploiting auxiliary semantic features (\eg textual descriptions, visual images and knowledge graph) to enrich contextual information then turns into a mainstream methodology. Though effective, we argue that these different heterogeneous features certainly include much noise which may overwhelm the valuable sequential signals, and therefore easily reach the phenomenon of negative collaboration (ie 1 + 1 > 2). How to design a flexible strategy to select proper auxiliary information and alleviate the negative collaboration towards a better recommendation is still an interesting and open question. Unfortunately, few works have addressed this challenge in sequential recommendation. In this paper, we introduce a Multi-Agent RL-based Information S election Model (named MARIS) to explore an effective collaboration between different kinds of auxiliary information and sequential signals in an automatic way. Specifically, MARIS formalizes the auxiliary feature selection as a cooperative Multi-agent Markov Decision Process. For each auxiliary feature type, MARIS resorts to using an agent to determine whether a specific kind of auxiliary feature should be imported to achieve a positive collaboration. In between, a QMIX network is utilized to cooperate their joint selection actions and produce an episode corresponding an effective combination of different auxiliary features for the whole historical sequence. Considering the lack of supervised selection signals, we further devise a novel reward-guided sampling strategy to leverage exploitation and exploration scheme for episode sampling. By preserving them in a replay buffer, MARIS learns the action-value function and the reward alternatively for optimization. Extensive experiments on four real-world datasets demonstrate that our model obtains significant performance improvement over up-to-date state-of-the-art recommendation models.|对于序列推荐系统来说，从大量用户交互中挖掘出的粗粒度稀疏序列信号已经成为进一步提高推荐性能的瓶颈。为了解决这一问题，利用辅助语义特征(如文本描述、视觉图像和知识图形)丰富上下文信息成为主流方法论。虽然有效，我们认为这些不同的异质性特征肯定包括大量的噪声，这可能压倒有价值的序列信号，因此很容易达到负协作现象(即1 + 1 > 2)。如何设计一种灵活的策略，选择合适的辅助信息，减轻负面协作，以获得更好的推荐，仍然是一个有趣而开放的问题。不幸的是，很少有作品在连续推荐中解决了这个问题。本文提出了一种基于多 Agent RL 的信息 S 选择模型(MARIS) ，用于探索不同辅助信息与序列信号之间的自动有效协作。具体来说，MARIS 将辅助特征选择形式化为一个合作的多代理马可夫决策过程。对于每一种辅助特征类型，MARIS 都使用一个代理来确定是否需要导入一种特定的辅助特征来实现积极的协作。其间，利用 QMIX 网络协同它们的联合选择行动，产生对应于整个历史序列的不同辅助特征的有效组合的情节。考虑到缺乏监督选择信号，我们进一步设计了一种新的奖励引导抽样策略，以利用开发和探索方案的情节抽样。通过将它们保存在一个重播缓冲区中，MARIS 学习动作-价值函数和优化的报酬。在四个真实世界数据集上的大量实验表明，我们的模型比最新的最先进的推荐模型获得了显著的性能改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Agent+RL-based+Information+Selection+Model+for+Sequential+Recommendation)|0|
|[Neural Statistics for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531762)|Yanhua Huang, Hangyu Wang, Yiyun Miao, Ruiwen Xu, Lei Zhang, Weinan Zhang|Xiaohongshu Inc., Shanghai, China; Shanghai Jiao Tong University, Shanghai, China|With the success of deep learning, click-through rate (CTR) predictions are transitioning from shallow approaches to deep architectures. Current deep CTR prediction usually follows the Embedding & MLP paradigm, where the model embeds categorical features into latent semantic space. This paper introduces a novel embedding technique called neural statistics that instead learns explicit semantics of categorical features by incorporating feature engineering as an innate prior into the deep architecture in an end-to-end manner. Besides, since the statistical information changes over time, we study how to adapt to the distribution shift in the MLP module efficiently. Offline experiments on two public datasets validate the effectiveness of neural statistics against state-of-the-art models. We also apply it to a large-scale recommender system via online A/B tests, where the user's satisfaction is significantly improved.|随着深度学习的成功，点进率预测(ctrl)正从浅层方法向深层架构过渡。目前的深度 CTR 预测通常遵循嵌入与 MLP 范式，该模型将范畴特征嵌入到潜在语义空间中。本文介绍了一种新的嵌入技术，称为神经统计学，通过将特征工程作为一种先天优势以端到端的方式结合到深层体系结构中，来学习范畴特征的显性语义。此外，由于统计信息随时间变化，我们研究了如何有效地适应 MLP 模块中的分布变化。在两个公共数据集上的离线实验验证了针对最先进模型的神经统计的有效性。我们还通过在线 A/B 测试将其应用于大规模的推荐系统测试，用户的满意度显著提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Statistics+for+Click-Through+Rate+Prediction)|0|
|[Towards Results-level Proportionality for Multi-objective Recommender Systems](https://doi.org/10.1145/3477495.3531787)|Ladislav Peska, Patrik Dokoupil|Charles University, Prague, Czech Rep|The main focus of our work is the problem of multiple objectives optimization (MOO) while providing a final list of recommendations to the user. Currently, system designers can tune MOO by setting importance of individual objectives, usually in some kind of weighted average setting. However, this does not have to translate into the presence of such objectives in the final results. In contrast, in our work we would like to allow system designers or end-users to directly quantify the required relative ratios of individual objectives in the resulting recommendations, e.g., the final results should have 60% relevance, 30% diversity and 10% novelty. If individual objectives are transformed to represent quality on the same scale, these result conditioning expressions may greatly contribute towards recommendations tuneability and explainability as well as user's control over recommendations. To achieve this task, we propose an iterative algorithm inspired by the mandates allocation problem in public elections. The algorithm is applicable as long as per-item marginal gains of individual objectives can be calculated. Effectiveness of the algorithm is evaluated on several settings of relevance-novelty-diversity optimization problem. Furthermore, we also outline several options to scale individual objectives to represent similar value for the user.|我们工作的主要重点是多目标优化(MOO)问题，同时向用户提供最终的建议列表。目前，系统设计者可以通过设定个人目标的重要性来调整 MOO，通常是在某种加权平均数设置中。然而，这并不意味着在最终结果中存在这样的目标。相比之下，在我们的工作中，我们希望允许系统设计者或最终用户直接量化结果建议中各个目标所需的相对比例，例如，最终结果应该有60% 的相关性，30% 的多样性和10% 的新颖性。如果将单个目标转换为在同一尺度上表示质量，那么这些结果条件表达式可能极大地有助于建议的可调整性和可解释性，以及用户对建议的控制。为了实现这一任务，我们提出了一个迭代算法的启发任务分配问题在公共选举。只要能够计算出单个目标的单项边际收益，该算法是可行的。该算法的有效性是根据相关性-新颖性-多样性最佳化问题进行评估的。此外，我们还概述了几个选项，以缩放单个目标，表示用户的类似价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Results-level+Proportionality+for+Multi-objective+Recommender+Systems)|0|
|[Transform Cold-Start Users into Warm via Fused Behaviors in Large-Scale Recommendation](https://doi.org/10.1145/3477495.3531797)|Pengyang Li, Rong Chen, Quan Liu, Jian Xu, Bo Zheng|Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China|Recommendation for cold-start users who have very limited data is a canonical challenge in recommender systems. Existing deep recommender systems utilize user content features and behaviors to produce personalized recommendations, yet often face significant performance degradation on cold-start users compared to existing ones due to the following challenges: (1) Cold-start users may have a quite different distribution of features from existing users. (2) The few behaviors of cold-start users are hard to be exploited. In this paper, we propose a recommender system called Cold-Transformer to alleviate these problems. Specifically, we design context-based Embedding Adaption to offset the differences in feature distribution. It transforms the embedding of cold-start users into a warm state that is more like existing ones to represent corresponding user preferences. Furthermore, to exploit the few behaviors of cold-start users and characterize the user context, we propose Label Encoding that models Fused Behaviors of positive and negative feedback simultaneously, which are relatively more sufficient. Last, to perform large-scale industrial recommendations, we keep the two-tower architecture that de-couples user and target item. Extensive experiments on public and industrial datasets show that Cold-Transformer significantly outperforms state-of-the-art methods, including those that are deep coupled and less scalable.|对于数据非常有限的冷启动用户的推荐在推荐系统中是一个典型的挑战。现有的深度推荐系统利用用户内容特征和行为来产生个性化的推荐，但是由于以下挑战，冷启动用户的性能往往比现有的推荐系统有显著的下降: (1)冷启动用户可能具有与现有用户完全不同的特征分布。(2)冷启动用户的少数行为很难被利用。在这篇文章中，我们提出了一个叫做冷变压器的推荐系统来缓解这些问题。具体来说，我们设计了基于上下文的嵌入适应，以抵消特征分布的差异。它将冷启动用户的嵌入转换为更像现有用户的暖状态，以表示相应的用户偏好。此外，为了充分利用冷启动用户的少数行为并刻画用户上下文特征，我们提出了标签编码方法，该方法同时对正反馈和负反馈的融合行为进行建模，相对来说比较充分。最后，为了执行大规模的工业建议，我们保留了解耦用户和目标项目的双塔架构。在公共和工业数据集上进行的大量实验表明，冷变压器的性能明显优于最先进的方法，包括那些深度耦合和可伸缩性较差的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transform+Cold-Start+Users+into+Warm+via+Fused+Behaviors+in+Large-Scale+Recommendation)|0|
|[Coarse-to-Fine Sparse Sequential Recommendation](https://doi.org/10.1145/3477495.3531732)|Jiacheng Li, Tong Zhao, Jin Li, Jim Chan, Christos Faloutsos, George Karypis, SooMin Pantel, Julian J. McAuley|Amazon, Seattle, WA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; University of California, San Diego, La Jolla, CA, USA|Sequential recommendation aims to model dynamic user behavior from historical interactions. Self-attentive methods have proven effective at capturing short-term dynamics and long-term preferences. Despite their success, these approaches still struggle to model sparse data, on which they struggle to learn high-quality item representations. We propose to model user dynamics from shopping intents and interacted items simultaneously. The learned intents are coarse-grained and work as prior knowledge for item recommendation. To this end, we present a coarse-to-fine self-attention framework, namely CaFe, which explicitly learns coarse-grained and fine-grained sequential dynamics. Specifically, CaFe first learns intents from coarse-grained sequences which are dense and hence provide high-quality user intent representations. Then, CaFe fuses intent representations into item encoder outputs to obtain improved item representations. Finally, we infer recommended items based on representations of items and corresponding intents. Experiments on sparse datasets show that CaFe outperforms state-of-the-art self-attentive recommenders by 44.03% [email protected] on average.|顺序推荐旨在从历史交互中建立动态用户行为模型。事实证明，自我关注的方法在捕捉短期动态和长期偏好方面是有效的。尽管这些方法取得了成功，但它们仍然难以建立稀疏数据的模型，难以在稀疏数据上学习高质量的项目表示。我们建议同时从购物意图和交互项目建立用户动态模型。学习意图是粗粒度的，作为项目推荐的先验知识。为此，我们提出了一个由粗到细的自我注意框架，即 CaFe，它显式地学习粗粒度和细粒度的序列动力学。具体来说，CaFe 首先从密集的粗粒度序列中学习意图，因此提供高质量的用户意图表示。然后，CaFe 将意图表示融合到项编码器输出中，以获得改进的项表示。最后，根据项目的表示和相应的意图推断推荐项目。在稀疏数据集上的实验表明，CaFe 的性能平均比最先进的自我关注推荐系统高出44.03% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Coarse-to-Fine+Sparse+Sequential+Recommendation)|0|
|[Conversational Recommendation via Hierarchical Information Modeling](https://doi.org/10.1145/3477495.3531830)|Quan Tu, Shen Gao, Yanran Li, Jianwei Cui, Bin Wang, Rui Yan|Xiaomi AI Lab, Beijing, China; Peking University, Beijing, China; Renmin University of China, Beijing, China|Conversational recommendation system aims to recommend appropriate items to user by directly asking preference on attributes or recommending item list. However, most of existing methods only employ the flat item and attribute relationship, and ignore the hierarchical relationship connected by the similar user which can provide more comprehensive information. And these methods usually use the user accepted attributes to represent the conversational history and ignore the hierarchical information of sequential transition in the historical turns. In this paper, we propose Hierarchical Information-aware Conversational Recommender (HICR) to model the two types of hierarchical information to boost the performance of CRS. Experiments conducted on four benchmark datasets verify the effectiveness of our proposed model.|会话推荐系统旨在通过直接询问用户对属性的偏好或推荐项目列表来向用户推荐合适的项目。然而，现有的方法大多只使用平面项目和属性关系，而忽略了相似用户之间的层次关系，这样可以提供更全面的信息。这些方法通常使用用户接受的属性来表示会话历史，而忽略了历史转折中顺序转换的层次信息。本文提出了基于层次信息感知的会话推荐系统(HICR) ，对两种层次信息进行建模，以提高会话推荐系统的性能。在四个基准数据集上进行的实验验证了该模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Recommendation+via+Hierarchical+Information+Modeling)|0|
|[CTnoCVR: A Novelty Auxiliary Task Making the Lower-CTR-Higher-CVR Upper](https://doi.org/10.1145/3477495.3531843)|Dandan Zhang, Haotian Wu, Guanqi Zeng, Yao Yang, Weijiang Qiu, Yujie Chen, Haoyuan Hu|Cainiao Network, Hangzhou, China; Beijing Jiaotong University, Beijing, China; China Electric Power Research Institute, Beijing, China; Zhejiang Lab, Hangzhou, China|In recent years, multi-task learning models based on deep learning in recommender systems have attracted increasing attention from researchers in industry and academia. Accurately estimating post-click conversion rate (CVR) is often considered as the primary task of multi-task learning in recommender systems. However, some advertisers may try to get higher click-through rates (CTR) by over-decorating their ads, which may result in excessive exposure to samples with lower CVR. For example, some only eye-catching clickbait have higher CTR, but actually, CVR is very low. As a result, the overall performance of the recommender system will be hurt. In this paper, we introduce a novelty auxiliary task called CTnoCVR, which aims to predict the probability of events with click but no-conversion, in various state-of-the-art multi-task models of recommender systems to promote samples with high CVR but low CTR. Plentiful Experiments on a large-scale dataset gathered from traffic logs of Taobao's recommender system demonstrate that the introduction of CTnoCVR task significantly improves the prediction effect of CVR under various multi-task frameworks. In addition, we conduct the online test and evaluate the effectiveness of our proposed method to make those samples with high CVR and low CTR rank higher.|近年来，推荐系统中基于深度学习的多任务学习模型越来越受到业界和学术界的关注。在推荐系统中，准确估计点击后转换率(CVR)常常被认为是多任务学习的首要任务。然而，一些广告商可能试图通过过度装饰他们的广告来获得更高的点击率(CTR) ，这可能导致过度暴露于低 CVR 的样品。例如，一些只有吸引眼球的点击诱饵有较高的点击率，但实际上，CVR 是非常低的。因此，推荐系统的整体表现将受到影响。本文介绍了一种新颖的辅助任务 CTnoCVR，该任务在推荐系统的多任务模型中预测点击不转换的事件发生概率，以提升高 CVR 低 CTR 的样本。大量的实验表明，在多任务框架下，引入 CTnoCVR 任务可以显著提高 CVR 的预测效果。这些实验都是从淘宝推荐系统的流量日志中收集的大规模数据集中得到的。此外，我们进行了在线测试，并评估了我们提出的方法的有效性，使高 CVR 和低 CTR 排名的样本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CTnoCVR:+A+Novelty+Auxiliary+Task+Making+the+Lower-CTR-Higher-CVR+Upper)|0|
|[Smooth-AUC: Smoothing the Path Towards Rank-based CTR Prediction](https://doi.org/10.1145/3477495.3531865)|Shuang Tang, Fangyuan Luo, Jun Wu|Beijing Jiaotong University, Beijing, China|Deep neural networks (DNNs) have been a key technique for click-through rate (CTR) estimation, yet existing DNNs-based CTR models neglect the inconsistency between their optimization objectives (e.g., Binary Cross Entropy, BCE) and CTR ranking metrics (e.g., Area Under the ROC Curve, AUC). It is noteworthy that directly optimizing AUC by gradient-descent methods is difficult due to the non-differentiable Heaviside function built-in AUC. To this end, we propose a smooth approximation of AUC, called smooth-AUC (SAUC), towards the rank-based CTR prediction. Specifically, SAUC relaxes the Heaviside function via sigmoid with a temperature coefficient (aiming at controlling the function sharpness) in order to facilitate the gradient-based optimization. Furthermore, SAUC is a plug-and-play objective that can be used in any DNNs-based CTR model. Experimental results on two real-world datasets demonstrate that SAUC consistently improves the recommendation accuracy of current DNNs-based CTR models.|深度神经网络(DNN)一直是点进率评估的关键技术，然而现有的基于 DNN 的 CTR 模型忽略了它们的优化目标(例如，二进制交叉熵，BCE)和 CTR 排名指标(例如，ROC Curve 下面积，AUC)之间的不一致性。值得注意的是，由于 AUC 内置的不可微单位阶跃函数，用梯度下降法直接优化 AUC 是困难的。为此，我们提出了一种平滑近似的 AUC，称为平滑 AUC (SAUC) ，用于基于秩的 CTR 预测。具体来说，SAUC 通过 sigmoid 放松单位阶跃函数(目的是控制函数的清晰度) ，以便于基于梯度的优化温度系数。此外，SAUC 是一个即插即用的目标，可以在任何基于 DNN 的 CTR 模型中使用。在两个实际数据集上的实验结果表明，SAUC 一致地提高了当前基于 DNN 的 CTR 模型的推荐精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Smooth-AUC:+Smoothing+the+Path+Towards+Rank-based+CTR+Prediction)|0|
|[Alignment Rationale for Query-Document Relevance](https://doi.org/10.1145/3477495.3531883)|Youngwoo Kim, Razieh Rahimi, James Allan|University of Massachusetts Amherst, Amherst, MA, USA|Deep neural networks are widely used for text pair classification tasks such as as adhoc information retrieval. These deep neural networks are not inherently interpretable and require additional efforts to get rationale behind their decisions. Existing explanation models are not yet capable of inducing alignments between the query terms and the document terms -- which part of the document rationales are responsible for which part of the query? In this paper, we study how the input perturbations can be used to infer or evaluate alignments between the query and document spans, which best explain the black-box ranker's relevance prediction. We use different perturbation strategies and accordingly propose a set of metrics to evaluate the faithfulness of alignment rationales to the model. Our experiments show that the defined metrics based on substitution-based perturbation are more successful in preferring higher-quality alignments, compared to the deletion-based metrics.|深度神经网络广泛用于文本对分类任务，如自组织信息检索。这些深层神经网络本质上是不可解释的，需要额外的努力来获得其决策背后的理由。现有的解释模型还不能在查询术语和文档术语之间引入对齐——文档基本原理的哪一部分负责查询的哪一部分？在本文中，我们研究了如何利用输入扰动来推断或评估查询和文档跨度之间的对齐，这最好地解释了黑盒排名的相关性预测。我们使用不同的摄动策略，并相应地提出了一套度量来评估对齐基本原理的忠实性模型。我们的实验表明，与基于删除的度量相比，基于替换扰动的度量更容易获得高质量的比对。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Alignment+Rationale+for+Query-Document+Relevance)|0|
|[Learning to Rank Knowledge Subgraph Nodes for Entity Retrieval](https://doi.org/10.1145/3477495.3531888)|Parastoo Jafarzadeh, Zahra Amirmahani, Faezeh Ensan|Ferdowsi University of Mashhad, Mashhad, Iran; Ryerson University, Toronto, ON, Canada|The importance of entity retrieval, the task of retrieving a ranked list of related entities from big knowledge bases given a textual query, has been widely acknowledged in the literature. In this paper, we propose a novel entity retrieval method that addresses the important challenge that revolves around the need to effectively represent and model context in which entities relate to each other. Based on our proposed method, a model is firstly trained to retrieve and prune a subgraph of a textual knowledge graph that represents contextual relationships between entities. Secondly, a deep model is introduced to reason over the textual content of nodes, edges, and the given question and score and rank entities in the subgraph. We show experimentally that our approach outperforms state-of-the-art methods on a number of benchmarks for entity retrieval.|实体检索的重要性在文献中得到了广泛的认可。在本文中，我们提出了一种新的实体检索方法，以解决围绕着需要有效地表示和模型实体相互关联的上下文的重要挑战。基于该方法，首先训练一个模型来检索和剪枝表示实体间上下文关系的文本知识图的子图。其次，引入一个深度模型来推理子图中节点、边和给定问题的文本内容以及子图中的得分和排序实体。我们的实验表明，我们的方法在实体检索的许多基准上优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Rank+Knowledge+Subgraph+Nodes+for+Entity+Retrieval)|0|
|[ELECRec: Training Sequential Recommenders as Discriminators](https://doi.org/10.1145/3477495.3531894)|Yongjun Chen, Jia Li, Caiming Xiong|Salesforce Research, Palo Alto, CA, USA|Sequential recommendation is often considered as a generative task, i.e., training a sequential encoder to generate the next item of a user's interests based on her historical interacted items. Despite their prevalence, these methods usually require training with more meaningful samples to be effective, which otherwise will lead to a poorly trained model. In this work, we propose to train the sequential recommenders as discriminators rather than generators. Instead of predicting the next item, our method trains a discriminator to distinguish if a sampled item is a 'real' target item or not. A generator, as an auxiliary model, is trained jointly with the discriminator to sample plausible alternative next items and will be thrown out after training. The trained discriminator is considered as the final SR model and denoted as \modelname. Experiments conducted on four datasets demonstrate the effectiveness and efficiency of the proposed approach.|顺序推荐通常被认为是一个生成任务，例如，训练一个顺序编码器根据用户的历史交互项目生成下一个用户感兴趣的项目。尽管这些方法普遍存在，但通常需要训练更有意义的样本才能有效，否则将导致训练不足的模型。在这项工作中，我们建议训练顺序推荐器作为鉴别器，而不是生成器。我们的方法不是预测下一个项目，而是训练一个鉴别器来区分一个采样的项目是否是“真正的”目标项目。发电机作为辅助模型，与鉴别器联合训练，以抽样合理的替代下一个项目，并将在训练后抛出。训练后的鉴别器被认为是最终的 SR 模型，并表示为模型名。在四个数据集上进行的实验表明了该方法的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELECRec:+Training+Sequential+Recommenders+as+Discriminators)|0|
|[A2A-API: A Prototype for Biomedical Information Retrieval Research and Benchmarking](https://doi.org/10.1145/3477495.3531667)|Maciej Rybinski, Liam Watts, Sarvnaz Karimi|CSIRO Data61, Sydney, NSW, Australia|Finding relevant literature is crucial for biomedical research and in the practice of evidence-based medicine, making biomedical search an important application area within the field of information retrieval. This is recognised by the broader IR community, and in particular by the organisers of Text Retrieval Conference (TREC) as early as 2003. While TREC provides crucial evaluation resources, to get started in biomedical IR one needs to tackle an important software engineering hurdle of parsing, indexing, and deploying several large document collections. Moreover, many newcomers to the field often face a steep learning curve, where theoretical concepts are tangled up with technical aspects. Finally, many of the existing baselines and systems are difficult to reproduce. We aim to alleviate all three of these bottlenecks with the launch of A2A-API. It is a RESTful API which serves as an easy-to-use and programming-language-independent interface to existing biomedical TREC collections. It builds upon A2A, our system for biomedical information retrieval benchmarking, and extends it with additional functionalities. Apart from providing programmatic access to the features of the original A2A system - focused principally on benchmarking - A2A-API supports biomedical IR researchers in development of systems featuring reranking and query reformulation components. In this demonstration, we illustrate the capabilities of A2A-API with comprehensive use cases.|寻找相关文献对于生物医学研究和循证医学的实践至关重要，这使得生物医学搜索成为信息检索领域的一个重要应用领域。早在2003年，更广泛的信息检索社区，特别是文本检索会议(TREC)的组织者就认识到了这一点。虽然 TREC 提供了关键的评估资源，但要开始学习生物医学 IR，需要解决一个重要的软件工程障碍，即解析、索引和部署几个大型文档集。此外，该领域的许多新手往往面临一个陡峭的学习曲线，其中理论概念与技术方面纠缠在一起。最后，许多现有的基线和系统很难再现。我们的目标是通过推出 A2A-API 来缓解所有这三个瓶颈。它是一个 RESTful API，作为一个易于使用和独立于编程语言的接口，用于现有的生物医学 TREC 集合。它建立在我们的生物医学信息检索基准测试系统 A2A 的基础上，并扩展了其他功能。除了提供对原始 A2A 系统特性的程序访问(主要侧重于基准测试)外，A2A-API 还支持生物医学红外研究人员开发具有重新排序和查询重新制定组件的系统。在本演示中，我们通过全面的用例说明了 A2A-API 的功能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A2A-API:+A+Prototype+for+Biomedical+Information+Retrieval+Research+and+Benchmarking)|0|
|[Learning to Rank Instant Search Results with Multiple Indices: A Case Study in Search Aggregation for Entertainment](https://doi.org/10.1145/3477495.3536334)|Scott Rome, Sardar Hamidian, Richard Walsh, Kevin Foley, Ferhan Ture|Comcast, Sunnyvale, CA, USA; Comcast, Washington, DC, USA; Comcast, Philadelphia, PA, USA|At Xfinity, an instant search system provides a variety of results for a given query from different sources. For each keystroke, new results are rendered on screen to the user, which could contain movies, television series, sporting events, music videos, news clips, person pages, and other result types. Users are also able to use the Xfinity Voice Remote to submit longer queries, some of which are more open-ended. Examples of queries include incomplete words which match multiple results through lexical matching (i.e., "ali"), topical searches ("vampire movies"), and more specific longer searches ("Movies with Adam Sandler"). Since results can be based on lexical matches, semantic matches, item-to-item similarity matches, or a variety of business logic driven sources, a key challenge is how to combine results into a single list. To accomplish this, we propose merging the lists via a Learning to Rank (LTR) neural model which takes into account the search query. This combined list can be personalized via a second LTR neural model with knowledge of the user's search history and metadata of the programs. Because instant search is under-represented in the literature, we present our learnings from research to aid other practitioners.|在 Xfinity，即时搜索系统为来自不同来源的特定查询提供多种结果。对于每次按键，新的结果都会在屏幕上呈现给用户，其中可能包含电影、电视剧、体育赛事、音乐视频、新闻剪辑、人物页面和其他结果类型。用户还可以使用 Xfinity Voice Remote 提交更长的查询，其中一些查询更为开放。查询的例子包括通过词汇匹配(例如“ ali”)匹配多个结果的不完整单词、主题搜索(“吸血鬼电影”)和更具体的长搜索(“与 Adam Sandler 的电影”)。由于结果可以基于词汇匹配、语义匹配、项目间相似性匹配或各种业务逻辑驱动源，因此一个关键的挑战是如何将结果组合成一个单独的列表。为了实现这一点，我们建议通过一个学习排序(LTR)神经模型，考虑到搜索查询合并列表。这个组合列表可以通过第二个具有用户搜索历史和程序元数据知识的 LTR 神经模型进行个性化。因为即时搜索在文献中的代表性不足，我们提出我们从研究中学到的东西来帮助其他从业者。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Rank+Instant+Search+Results+with+Multiple+Indices:+A+Case+Study+in+Search+Aggregation+for+Entertainment)|0|
|[Scalable Exploration for Neural Online Learning to Rank with Perturbed Feedback](https://doi.org/10.1145/3477495.3532057)|Yiling Jia, Hongning Wang|University of Virginia, Charlottesville, VA, USA|Deep neural networks (DNNs) demonstrates significant advantages in improving ranking performance in retrieval tasks. Driven by the recent developments in optimization and generalization of DNNs, learning a neural ranking model online from its interactions with users becomes possible. However, the required exploration for model learning has to be performed in the entire neural network parameter space, which is prohibitively expensive and limits the application of such online solutions in practice. In this work, we propose an efficient exploration strategy for online interactive neural ranker learning based on bootstrapping. Our solution is based on an ensemble of ranking models trained with perturbed user click feedback. The proposed method eliminates explicit confidence set construction and the associated computational overhead, which enables the online neural rankers training to be efficiently executed in practice with theoretical guarantees. Extensive comparisons with an array of state-of-the-art OL2R algorithms on two public learning to rank benchmark datasets demonstrate the effectiveness and computational efficiency of our proposed neural OL2R solution.|深层神经网络(DNN)在提高检索任务的排序性能方面具有显著的优势。在 DNN 优化和泛化的最新发展的驱动下，从与用户的交互中学习在线神经排序模型成为可能。然而，模型学习所需要的探索必须在整个神经网络参数空间中进行，这是非常昂贵的，并且限制了这种在线解决方案在实际中的应用。本文提出了一种基于自举的在线交互式神经排序学习的有效探索策略。我们的解决方案是基于一个排名模型的集合训练与不安的用户点击反馈。该方法消除了显式置信集结构和相关的计算开销，使在线神经排序训练能够在理论保证的情况下在实际应用中有效地执行。通过与一系列最先进的 OL2R 算法在两个公共学习基准数据集上的广泛比较，证明了我们提出的神经 OL2R 解决方案的有效性和计算效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Exploration+for+Neural+Online+Learning+to+Rank+with+Perturbed+Feedback)|0|
|[Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems](https://doi.org/10.1145/3477495.3531869)|Hojoon Lee, Dongyoon Hwang, Kyushik Min, Jaegul Choo|KAKAO Enterprise, SeongNam, Republic of Korea; KAIST, SeongNam, Republic of Korea|Interactive Recommender Systems (IRSs) have attracted a lot of attention, due to their ability to model interactive processes between users and recommender systems. Numerous approaches have adopted Reinforcement Learning (RL) algorithms, as these can directly maximize users' cumulative rewards. In IRS, researchers commonly utilize publicly available review datasets to compare and evaluate algorithms. However, user feedback provided in public datasets merely includes instant responses (e.g., a rating), with no inclusion of delayed responses (e.g., the dwell time and the lifetime value). Thus, the question remains whether these review datasets are an appropriate choice to evaluate the long-term effects in IRS. In this work, we revisited experiments on IRS with review datasets and compared RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Following extensive analysis, we can reveal three main findings: First, a simple greedy reward model consistently outperforms RL-based models in maximizing cumulative rewards. Second, applying higher weighting to long-term rewards leads to degradation of recommendation performance. Third, user feedbacks have mere long-term effects in the benchmark datasets. Based on our findings, we conclude that a dataset has to be carefully verified and that a simple greedy baseline should be included for a proper evaluation of RL-based IRS approaches. Our code and dataset are available at https://github.com/dojeon-ai/irs_validation.|交互式推荐系统(IRS)由于能够对用户和推荐系统之间的交互过程进行建模而引起了人们的广泛关注。许多方法都采用了强化学习算法，因为这些算法可以直接最大化用户的累积回报。在 IRS 中，研究人员通常利用公开的评论数据集来比较和评估算法。然而，在公共数据集中提供的用户反馈只包括即时响应(例如，评级) ，没有包括延迟响应(例如，停留时间和生命周期值)。因此，问题仍然是这些审查数据集是否是评估 IRS 长期影响的合适选择。在这项工作中，我们重新回顾了 IRS 的实验与评论数据集，并比较了基于 RL 的模型与一个简单的奖励模型，贪婪地推荐项目具有最高的一步奖励。经过广泛的分析，我们可以揭示三个主要的发现: 第一，一个简单的贪婪报酬模型在最大化累积报酬方面始终优于基于 RL 的模型。其次，对长期奖励加权会导致推荐绩效的下降。第三，用户反馈在基准数据集中只有长期效果。基于我们的研究结果，我们得出结论，一个数据集必须被仔细验证，并且一个简单的贪婪基线应该被包括在一个基于 RL 的 IRS 方法的正确评估中。我们的代码和数据集可在 https://github.com/dojeon-ai/irs_validation 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Validating+Long-Term+User+Feedbacks+in+Interactive+Recommendation+Systems)|0|
|[Structure-Aware Semantic-Aligned Network for Universal Cross-Domain Retrieval](https://doi.org/10.1145/3477495.3532061)|Jialin Tian, Xing Xu, Kai Wang, Zuo Cao, Xunliang Cai, Heng Tao Shen|Meituan, Shanghai, China; University of Electronic Science and Technology of China & Peng Cheng Laboratory, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China|The goal of cross-domain retrieval (CDR) is to search for instances of the same category in one domain by using a query from another domain. Existing CDR approaches mainly consider the standard scenario that the cross-domain data for both training and testing come from the same categories and underlying distributions. However, these methods cannot be well extended to the newly emerging task of universal cross-domain retrieval (UCDR), where the testing data belong to the domain and categories not present during training. Compared to CDR, the UCDR task is more challenging due to (1) visually diverse data from multi-source domains, (2) the domain shift between seen and unseen domains, and (3) the semantic shift across seen and unseen categories. To tackle these problems, we propose a novel model termed Structure-Aware Semantic-Aligned Network (SASA) to align the heterogeneous representations of multi-source domains without loss of generalizability for the UCDR task. Specifically, we leverage the advanced Vision Transformer (ViT) as the backbone and devise a distillation-alignment ViT (DAViT) with a novel token-based strategy, which incorporates two complementary distillation and alignment tokens into the ViT architecture. In addition, the distillation token is devised to improve the generalizability of our model by structure information preservation and the alignment token is used to improve discriminativeness with trainable categorical prototypes. Extensive experiments on three large-scale benchmarks, i.e., Sketchy, TU-Berlin, and DomainNet, demonstrate the superiority of our SASA method over the state-of-the-art UCDR and ZS-SBIR methods.|跨域检索(CDR)的目标是通过使用来自另一个域的查询在一个域中搜索相同类别的实例。现有的 CDR 方法主要考虑这样的标准场景: 用于培训和测试的跨域数据来自相同的类别和底层分布。然而，这些方法不能很好地推广到新出现的通用跨域检索(UCDR)任务，其中的测试数据属于领域和类别不存在的训练过程中。与 CDR 相比，UCDR 任务更具挑战性，因为(1)来自多源域的视觉多样化数据，(2)可见和不可见域之间的域转移，以及(3)跨可见和不可见类别的语义转移。为了解决这些问题，我们提出了一种称为结构感知语义对齐网络(SASA)的新模型，该模型可以在不损失 UCDR 任务通用性的前提下对多源域的异构表示进行对齐。具体而言，我们利用先进的视觉变压器(ViT)作为骨干，并设计了一种蒸馏对准 ViT (DAViT) ，其具有基于令牌的新策略，其将两个互补的蒸馏和对准令牌合并到 ViT 体系结构中。此外，通过结构信息的保留，设计了精馏令牌来提高模型的泛化能力，并利用对齐令牌来提高可训练范畴原型的区分能力。在 Sketchy、 TU-Berlin 和 DomainNet 这三个大型基准测试上的大量实验证明了我们的 SASA 方法优于最先进的 UCDR 和 ZS-SBIR 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structure-Aware+Semantic-Aligned+Network+for+Universal+Cross-Domain+Retrieval)|0|
|[Enhancing Top-N Item Recommendations by Peer Collaboration](https://doi.org/10.1145/3477495.3531773)|Yang Sun, Fajie Yuan, Min Yang, Alexandros Karatzoglou, Li Shen, Xiaoyan Zhao|Google Research, London, United Kingdom; Harbin Institute of Technology, Shenzhen, Shenzhen, China; JD Explore Academy, Beijing, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Westlake University, Hangzhou, China|Deep neural networks (DNN) based recommender models often require numerous parameters to achieve remarkable performance. However, this inevitably brings redundant neurons, a phenomenon referred to as over-parameterization. In this paper, we plan to exploit such redundancy phenomena for recommender systems (RS), and propose a top-N item recommendation framework called PCRec that leverages collaborative training of two recommender models of the same network structure, termed peer collaboration. We first introduce two criteria to identify the importance of parameters of a given recommender model. Then, we rejuvenate the unimportant parameters by copying parameters from its peer network. After such an operation and retraining, the original recommender model is endowed with more representation capacity by possessing more functional model parameters. To show its generality, we instantiate PCRec by using three well-known recommender models. We conduct extensive experiments on two real-world datasets, and show that PCRec yields significantly better performance than its counterpart with the same model (parameter) size.|基于深度神经网络(DNN)的推荐模型往往需要大量的参数才能达到显著的性能。然而，这不可避免地带来了多余的神经元，这种现象被称为过度参数化。在本文中，我们计划在推荐系统中利用这种冗余现象，并提出了一个名为 PCRec 的前 N 项推荐框架，该框架利用了两个相同网络结构的推荐模型的协同训练，称为对等协作。我们首先引入两个标准来确定一个给定的推荐模型参数的重要性。然后，我们通过从其对等网络中复制参数来恢复不重要的参数。经过这样的操作和再训练，原有的推荐模型具有更多的功能模型参数，从而具有更强的表示能力。为了显示其通用性，我们使用三个著名的推荐模型来实例化 PCRec。我们在两个真实世界的数据集上进行了广泛的实验，结果表明，与相同模型(参数)大小的同类数据集相比，PCRec 产生了明显更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Top-N+Item+Recommendations+by+Peer+Collaboration)|0|
|[Learning-to-Rank at the Speed of Sampling: Plackett-Luce Gradient Estimation with Minimal Computational Complexity](https://doi.org/10.1145/3477495.3531842)|Harrie Oosterhuis|Radboud University, Nijmegen, Netherlands|Plackett-Luce gradient estimation enables the optimization of stochastic ranking models within feasible time constraints through sampling techniques. Unfortunately, the computational complexity of existing methods does not scale well with the length of the rankings, i.e. the ranking cutoff, nor with the item collection size. In this paper, we introduce the novel PL-Rank-3 algorithm that performs unbiased gradient estimation with a computational complexity comparable to the best sorting algorithms. As a result, our novel learning-to-rank method is applicable in any scenario where standard sorting is feasible in reasonable time. Our experimental results indicate large gains in the time required for optimization, without any loss in performance. For the field, our contribution could potentially allow state-of-the-art learning-to-rank methods to be applied to much larger scales than previously feasible.|Plackett-Luce 梯度估计可以通过抽样技术在可行的时间约束下优化随机排序模型。遗憾的是，现有方法的计算复杂度并不能很好地与排名的长度(即排名截止值)和项目集合的大小相适应。在本文中，我们介绍了一种新的 PL-Rank-3算法，该算法执行无偏梯度估计，其计算复杂度与最佳排序算法相当。因此，我们的新学习排序方法适用于任何情况下，标准排序是可行的在合理的时间。我们的实验结果表明，优化所需的时间大大增加，性能没有任何损失。对于这个领域，我们的贡献可能使最先进的学习排名方法应用于比以前可行的更大的范围。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning-to-Rank+at+the+Speed+of+Sampling:+Plackett-Luce+Gradient+Estimation+with+Minimal+Computational+Complexity)|0|
|[Rethinking Correlation-based Item-Item Similarities for Recommender Systems](https://doi.org/10.1145/3477495.3532055)|Katsuhiko Hayashi|Hokkaido University, Sapporo, Japan|This paper studies correlation-based item-item similarity measures for recommendation systems. While current research on recommender systems is directed toward deep learning-based approaches, nearest neighbor methods have been still used extensively in commercial recommender systems due to their simplicity. A crucial step in item-based nearest neighbor methods is to compute similarities between items, which are generally estimated through correlation measures like Pearson. The purpose of this paper is to re-investigate the effectiveness of correlation-based nearest neighbor methods on several benchmark datasets that have been used for recommendation evaluation in recent years. This paper also provides a more effective estimation method for correlation measures than the classical Pearson correlation coefficient and shows that this leads to significant improvements in recommendation performance.|本文研究了基于相关性的推荐系统项目相似性度量。虽然目前对推荐系统的研究主要集中在基于深度学习的方法上，但是最近邻方法由于其简单性在商业推荐系统中仍然得到了广泛的应用。基于项目的最近邻方法的一个关键步骤是计算项目之间的相似性，这通常通过相关度量(如 Pearson)来估计。本文旨在重新研究基于相关性的最近邻方法在近年来用于推荐评价的几个基准数据集上的有效性。本文还提供了一种比经典的皮尔逊相关系数更有效的相关度量估计方法，结果表明这种方法可以显著提高推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Correlation-based+Item-Item+Similarities+for+Recommender+Systems)|0|
|[DeSCoVeR: Debiased Semantic Context Prior for Venue Recommendation](https://doi.org/10.1145/3477495.3531877)|Sailaja Rajanala, Arghya Pal, Manish Singh, Raphael C.W. Phan, KokSheik Wong|Monash University Malaysia, Bandar Sunway, Malaysia; Indian Institute of Technology Hyderabad, Hyderabad, India; Harvard Medical School, Boston, MA, USA|We present a novel semantic context prior-based venue recommendation system that uses only the title and the abstract of a paper. Based on the intuition that the text in the title and abstract have both semantic and syntactic components, we demonstrate that a joint training of a semantic feature extractor and syntactic feature extractor collaboratively leverages meaningful information that helps to provide venues for papers. The proposed methodology that we call DeSCoVeR at first elicits these semantic and syntactic features using a Neural Topic Model and text classifier respectively. The model then executes a transfer learning optimization procedure to perform a contextual transfer between the feature distributions of the Neural Topic Model and the text classifier during the training phase. DeSCoVeR also mitigates the document-level label bias using a Causal back-door path criterion and a sentence-level keyword bias removal technique. Experiments on the DBLP dataset show that DeSCoVeR outperforms the state-of-the-art methods.|我们提出了一个新的基于语义上下文先验的场地推荐系统，它只使用文章的标题和摘要。基于标题和摘要中的文本同时具有语义和句法成分的直觉，我们证明了语义特征提取器和句法特征提取器的联合训练协同利用有意义的信息，有助于为论文提供场所。我们提出的方法，我们称为 DeSCoVeR 首先引出这些语义和句法特征使用神经主题模型和文本分类器分别。然后，该模型执行一个迁移学习优化过程，在训练阶段在神经主题模型的特征分布和文本分类器之间进行上下文迁移。DeSCoVeR 还使用因果后门路径标准和句子级关键字偏差消除技术来减轻文档级标签偏差。在 DBLP 数据集上的实验表明，DeSCoVeR 方法的性能优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeSCoVeR:+Debiased+Semantic+Context+Prior+for+Venue+Recommendation)|0|
|[Revisiting Bundle Recommendation: Datasets, Tasks, Challenges and Opportunities for Intent-aware Product Bundling](https://doi.org/10.1145/3477495.3531904)|Zhu Sun, Jie Yang, Kaidong Feng, Hui Fang, Xinghua Qu, Yew Soon Ong|Delft University of Technology, Delft, Netherlands; Institute of High Performance Computing and Centre for Frontier AI Research, A*STAR, Singapore, Singapore; Yanshan University, Qinhuangdao, China; A*STAR Centre for Frontier AI Research and Nanyang Technological University, Singapore, Singapore; Shanghai University of Finance and Economics, Shanghai, China; Bytedance AI Lab, Singapore, Singapore|Product bundling is a commonly-used marketing strategy in both offline retailers and online e-commerce systems. Current research on bundle recommendation is limited by: (1) noisy datasets, where bundles are defined by heuristics, e.g., products co-purchased in the same session; and (2) specific tasks, holding unrealistic assumptions, e.g., the availability of bundles for recommendation directly. In this paper, we propose to take a step back and consider the process of bundle recommendation from a holistic user experience perspective. We first construct high-quality bundle datasets with rich meta information, particularly bundle intents, through a carefully designed crowd-sourcing task. We then define a series of tasks that together, support all key steps in a typical bundle recommendation process, from bundle detection, completion, ranking, to explanation and auto-naming. Finally, we conduct extensive experiments and in-depth analysis that demonstrate the challenges of bundle recommendation, arising from the need for capturing complex relations among users, products, and bundles, as well as the research opportunities, especially in graph-based neural methods. To sum up, our study delivers new data sources, opens up new research directions, and provides useful guidance for product bundling in real e-commerce platforms. Our datasets are available at GitHub (\urlhttps://github.com/BundleRec/bundle_recommendation ).|绑售是线下零售商和在线电子商务系统中常用的营销策略。目前对捆绑推荐的研究受到以下因素的限制: (1)有噪音的数据集，其中捆绑包是由启发式定义的，例如，在同一会话中共同购买的产品; (2)具体的任务，持有不切实际的假设，例如，捆绑包的可用性直接推荐。在本文中，我们建议退一步，从整体用户体验的角度来考虑捆绑推荐的过程。我们首先通过一个精心设计的众包任务，构建包含丰富元信息的高质量捆绑数据集，特别是捆绑意图。然后，我们定义一系列任务，这些任务一起支持典型的包推荐过程中的所有关键步骤，从包检测、完成、排名到解释和自动命名。最后，我们进行了广泛的实验和深入的分析，展示了捆绑推荐的挑战，由于需要捕获用户、产品和捆绑之间的复杂关系，以及研究机会，特别是在基于图的神经方法。总之，我们的研究提供了新的数据来源，开辟了新的研究方向，并为绑售在真正的电子商务平台上提供了有用的指导。我们的数据集可以在 GitHub 上获得(urlhttps:// GitHub.com/bundlerec/bundle_recommendation )。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Bundle+Recommendation:+Datasets,+Tasks,+Challenges+and+Opportunities+for+Intent-aware+Product+Bundling)|0|
|[Query Facet Mapping and its Applications in Streaming Services: The Netflix Case Study](https://doi.org/10.1145/3477495.3536330)|Sudeep Das, Ivan Provalov, Vickie Zhang, Weidong Zhang|Netflix Inc., Los Gatos, CA, USA|In an instant search setting such as Netflix Search where results are returned in response to every keystroke, determining how a partial query maps onto broad classes of relevant entities orfacets --- such as videos, talent, and genres --- can facilitate a better understanding of the underlying objective of that query. Such a query-to-facet mapping system has a multitude of applications. It can help improve the quality of search results, drive meaningful result organization, and can be leveraged to establish trust by being transparent with Netflix members when they search for an entity that is not available on the service. By anticipating the relevant facets with each keystroke entry, the system can also better guide the experience within a search session. When aggregated across queries, the facets can reveal interesting patterns of member interest. A key challenge for building such a system is to judiciously balance lexical similarity with behavioral relevance. In this paper, we present a high level overview of a Query Facet Mapping system that we have developed at Netflix, describe its main components, provide evaluation results with real-world data, and outline several potential applications.|在像 Netflix Search 这样的即时搜索设置中，每次按键都会返回结果，确定一个部分查询如何映射到相关实体或方面的广泛类别——比如视频、人才和类型——可以促进对该查询的潜在目标的更好理解。这种查询到面的映射系统有大量的应用程序。它可以帮助提高搜索结果的质量，推动有意义的结果组织，并且可以通过在 Netflix 成员搜索服务中不可用的实体时对其保持透明来建立信任。通过预测每个按键输入的相关方面，系统还可以更好地指导搜索会话中的体验。当跨查询聚合时，方面可以显示成员感兴趣的有趣模式。建立这样一个系统的关键挑战是明智地平衡词汇相似性和行为相关性。本文对我们在 Netflix 上开发的 Query Facet Mapping 系统进行了高层次的概述，描述了它的主要组件，提供了实际数据的评估结果，并概述了几个潜在的应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query+Facet+Mapping+and+its+Applications+in+Streaming+Services:+The+Netflix+Case+Study)|0|
|[Implicit Feedback for Dense Passage Retrieval: A Counterfactual Approach](https://doi.org/10.1145/3477495.3531994)|Shengyao Zhuang, Hang Li, Guido Zuccon|The University of Queensland, Brisbane, QLD, Australia|In this paper we study how to effectively exploit implicit feedback in Dense Retrievers (DRs). We consider the specific case in which click data from a historic click log is available as implicit feedback. We then exploit such historic implicit interactions to improve the effectiveness of a DR. A key challenge that we study is the effect that biases in the click signal, such as position bias, have on the DRs. To overcome the problems associated with the presence of such bias, we propose the Counterfactual Rocchio (CoRocchio) algorithm for exploiting implicit feedback in Dense Retrievers. We demonstrate both theoretically and empirically that dense query representations learnt with CoRocchio are unbiased with respect to position bias and lead to higher retrieval effectiveness. We make available the implementations of the proposed methods and the experimental framework, along with all results at https://github.com/ielab/Counterfactual-DR.|本文研究了密集检索器(DRs)中如何有效地利用内隐反馈。我们考虑这样一个特定的情况，在这种情况下，来自历史点击日志的点击数据可以作为隐式反馈使用。然后，我们利用这种历史性的隐性相互作用来提高 DR 的有效性。我们研究的一个关键挑战是点击信号中的偏差(如位置偏差)对 DR 的影响。为了克服与存在这种偏差相关的问题，我们提出反事实 Rocchio (CoRocchio)算法用于利用致密检索器中的隐性反馈。我们从理论和实验两方面证明了 CoRocchio 学习的密集查询表示对位置偏差是无偏的，从而提高了检索效率。我们提供了建议方法和实验框架的实施，以及所有 https://github.com/ielab/counterfactual-dr 的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Implicit+Feedback+for+Dense+Passage+Retrieval:+A+Counterfactual+Approach)|0|
|[Offline Evaluation of Ranked Lists using Parametric Estimation of Propensities](https://doi.org/10.1145/3477495.3532032)|Vishwa Vinay, Manoj Kilaru, David Arbour|Adobe Research, San Jose, CA, USA; Adobe Research, Bangalore, India; University of California, San Diego, CA, USA|Search engines and recommendation systems attempt to continually improve the quality of the experience they afford to their users. Refining the ranker that produces the lists displayed in response to user requests is an important component of this process. A common practice is for the service providers to make changes (e.g. new ranking features, different ranking models) and A/B test them on a fraction of their users to establish the value of the change. An alternative approach estimates the effectiveness of the proposed changes offline, utilising previously collected clickthrough data on the old ranker to posit what the user behaviour on ranked lists produced by the new ranker would have been. A majority of offline evaluation approaches invoke the well studied inverse propensity weighting to adjust for biases inherent in logged data. In this paper, we propose the use of parametric estimates for these propensities. Specifically, by leveraging well known learning-to-rank methods as subroutines, we show how accurate offline evaluation can be achieved when the new rankings to be evaluated differ from the logged ones.|搜索引擎和推荐系统试图不断提高它们为用户提供的体验的质量。优化生成响应用户请求的列表的排名是这个过程的一个重要组成部分。一个常见的做法是，服务提供商进行更改(例如，新的排名功能，不同的排名模型)和 A/B 测试他们的一小部分用户，以建立变化的价值。另一种方法是利用先前收集到的老排名者的点击数据，来估计新排名者生成的排名表上的用户行为的有效性。大多数离线评估方法都会调用经过充分研究的倾向性反向加权来调整测井数据中固有的偏差。在本文中，我们提出了这些倾向的参数估计的使用。具体来说，通过利用众所周知的学习排名方法作为子程序，我们展示了当评估的新排名与记录的排名不同时，如何实现准确的离线评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Evaluation+of+Ranked+Lists+using+Parametric+Estimation+of+Propensities)|0|
|[CAPTOR: A Crowd-Aware Pre-Travel Recommender System for Out-of-Town Users](https://doi.org/10.1145/3477495.3531949)|Haoran Xin, Xinjiang Lu, Nengjun Zhu, Tong Xu, Dejing Dou, Hui Xiong|Shanghai University, Shanghai, China; Baidu Research, Beijing, China; University of Science and Technology of China, Hefei, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China|Pre-travel out-of-town recommendation aims to recommend Point-of-Interests (POIs) to the users who plan to travel out of their hometown in the near future yet have not decided where to go, i.e., their destination regions and POIs both remain unknown. It is a non-trivial task since the searching space is vast, which may lead to distinct travel experiences in different out-of-town regions and eventually confuse decision-making. Besides, users' out-of-town travel behaviors are affected not only by their personalized preferences but heavily by others' travel behaviors. To this end, we propose a Crowd-Aware Pre-Travel Out-of-town Recommendation framework (CAPTOR) consisting of two major modules: spatial-affined conditional random field (SA-CRF) and crowd behavior memory network (CBMN). Specifically, SA-CRF captures the spatial affinity among POIs while preserving the inherent information of POIs. Then, CBMN is proposed to maintain the crowd travel behaviors w.r.t. each region through three affiliated blocks reading and writing the memory adaptively. We devise the elaborated metric space with a dynamic mapping mechanism, where the users and POIs are distinguishable both inherently and geographically. Extensive experiments on two real-world nationwide datasets validate the effectiveness of CAPTOR against the pre-travel out-of-town recommendation task.|旅行前出城推荐的目的是向那些计划在不久的将来离开家乡但还没有决定去哪里旅行的用户推荐他们的兴趣点，也就是说，他们的目的地和兴趣点都是未知的。由于搜索空间巨大，这是一个非常重要的任务，可能会导致在不同的城外地区有不同的旅行体验，并最终混淆决策。此外，用户的出城旅游行为不仅受到个人偏好的影响，还受到他人旅游行为的影响。为此，我们提出了一个基于人群感知的预先出城推荐框架(CAPTOR) ，该框架由两个主要模块组成: 空间仿真条件随机域(SA-CRF)和人群行为记忆网络(cBMN)。特别地，SA-CRF 捕获 POI 之间的空间亲和性，同时保留 POI 的固有信息。然后，提出了通过三个附属块自适应地读写记忆来维持每个区域的人群出行行为。我们使用动态映射机制设计了详细的度量空间，其中用户和 POI 在本质上和地理上都是可以区分的。在两个真实世界的全国性数据集上进行了大量的实验，验证了 CAPTOR 对于出城前的推荐任务的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAPTOR:+A+Crowd-Aware+Pre-Travel+Recommender+System+for+Out-of-Town+Users)|0|
|[Unify Local and Global Information for Top-N Recommendation](https://doi.org/10.1145/3477495.3532070)|Xiaoming Liu, Shaocong Wu, Zhaohan Zhang, Chao Shen||Knowledge graph (KG), integrating complex information and containing rich semantics, is widely considered as side information to enhance the recommendation systems. However, most of the existing KG-based methods concentrate on encoding the structural information in the graph, without utilizing the collaborative signals in user-item interaction data, which are important for understanding user preferences. Therefore, the representations learned by these models are insufficient for representing semantic information of users and items in the recommendation environment. The combination of both kinds of data provides a good chance to solve this problem, but it faces the following challenges: i) the inner correlations in user-item interaction data are difficult to capture from one side of the user or item; ii) capturing the knowledge associations on the whole KG would introduce noises and variously influence the recommendation results; iii) the semantic gap between both kinds of data is hard to alleviate. To tackle this research gap, we propose a novel duet representation learning framework named KADM to fuse local information (user-item interaction data) and global information (external knowledge graph) for the top-N recommendation, which is composed of two separate sub-models. One learns the local representations by discovering the inner correlations in local information with a knowledge-aware co-attention mechanism, and another learns the global representations by encoding the knowledge associations in global information with a relation-aware attention network. The two sub-models are jointly trained as part of the semantic fusion network to compute the user preferences, which discriminates the contribution of the two sub-models under the special context. We conduct experiments on two real-world datasets, and the evaluations show that KADM significantly outperforms state-of-art methods. Further ablation studies confirm that the duet architecture performs significantly better than either sub-model on the recommendation tasks.|知识图集成了复杂的信息，包含丰富的语义，被广泛认为是增强推荐系统的边信息。然而，现有的基于 KG 的方法大多集中于对图中的结构信息进行编码，而没有利用用户交互数据中的协作信号，这对于理解用户偏好非常重要。因此，这些模型所学到的表示方法不足以表示推荐环境中用户和项目的语义信息。这两种数据的结合为解决这一问题提供了很好的机会，但它面临着以下挑战: 1)用户项目交互数据的内部相关性难以从用户或项目的一侧获取; 2)捕捉整个 KG 的知识关联会引入噪声并对推荐结果产生各种影响; 3)两种数据之间的语义差异难以缓解。为了解决这一问题，本文提出了一种新的二元表示学习框架 KADM，它融合了顶层 N 推荐的局部信息(用户项目交互数据)和全局信息(外部知识图) ，该框架由两个独立的子模型组成。一种是通过知识感知共注意机制发现局部信息的内在相关性来学习局部表征，另一种是通过关系感知注意网络对全局信息中的知识关联进行编码来学习全局表征。将这两个子模型作为语义融合网络的一部分进行联合训练，以计算用户偏好，从而区分两个子模型在特定语境下的贡献。我们在两个真实世界的数据集上进行了实验，结果表明 KADM 的性能明显优于最先进的方法。进一步的消融研究证实，二重奏架构在推荐任务上的表现明显优于任何一个子模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unify+Local+and+Global+Information+for+Top-N+Recommendation)|0|
|[Deployable and Continuable Meta-learning-Based Recommender System with Fast User-Incremental Updates](https://doi.org/10.1145/3477495.3531964)|Renchu Guan, Haoyu Pang, Fausto Giunchiglia, Ximing Li, Xuefeng Yang, Xiaoyue Feng|University of Trento, Trento, Italy; Tencent, Shenzhen, China; Jilin University, Changchun, China|User cold-start is a major challenge in building personalized recommender systems. Due to the lack of sufficient interactions, it is difficult to effectively model new users. One of the main solutions is to obtain an initial model through meta-learning (mainly gradient-based methods) and adapt it to new users with a few steps of gradient descent. Although these methods have achieved remarkable performance, they are still far from being usable in real-world applications due to their high-demand data processing, heavy computational burden, and inability to perform effective user-incremental update. In this paper, we propose a d eployable and c ontinuable m eta-learning-based r ecommendation (DCMR) approach, which can achieve fast user-incremental updating with task replay and first-order gradient descent. Specifically, we introduce a dual-constrained task sampler, distillation-based loss functions, and an adaptive controller in this framework to balance the trade-off between stability and plasticity in updating. In summary, DCMR can be updated while serving new users; in other words, it learns continuously and rapidly from a sequential user stream and is able to make recommendations at any time. The extensive experiments conducted on three benchmark datasets illustrate the superiority of our model.|用户冷启动是构建个性化推荐系统的主要挑战。由于缺乏足够的交互，很难对新用户进行有效的建模。其中一个主要的解决方案是通过元学习(主要是基于梯度的方法)获得一个初始模型，并通过几个步骤使其适应新用户的梯度下降法。虽然这些方法已经取得了显著的性能，但是由于其高需求的数据处理、沉重的计算负担以及不能执行有效的用户增量更新，它们在实际应用中仍然远远不能使用。在本文中，我们提出了一种可部署和可持续的基于元学习的 r 推荐(dCMR)方法，它可以通过任务重播和一阶梯度下降法实现快速的用户增量更新。具体来说，我们引入了一个双约束任务采样器，基于蒸馏的损失函数，以及在这个框架中的一个自适应控制器，以平衡稳定性和可塑性之间的权衡在更新。总之，DCMR 可以在为新用户提供服务的同时进行更新; 换句话说，它可以从连续的用户流中不断快速地学习，并且能够在任何时候提出建议。在三个基准数据集上进行的大量实验表明了该模型的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deployable+and+Continuable+Meta-learning-Based+Recommender+System+with+Fast+User-Incremental+Updates)|0|
|[Bias Mitigation for Toxicity Detection via Sequential Decisions](https://doi.org/10.1145/3477495.3531945)|Lu Cheng, Ahmadreza Mosallanezhad, Yasin N. Silva, Deborah L. Hall, Huan Liu|Arizona State University, Glendale, AZ, USA; Arizona State University, Tempe, AZ, USA; Loyola University Chicago, Chicago, IL, USA|Increased social media use has contributed to the greater prevalence of abusive, rude, and offensive textual comments. Machine learning models have been developed to detect toxic comments online, yet these models tend to show biases against users with marginalized or minority identities (e.g., females and African Americans). Established research in debiasing toxicity classifiers often (1) takes a static or batch approach, assuming that all information is available and then making a one-time decision; and (2) uses a generic strategy to mitigate different biases (e.g., gender and racial biases) that assumes the biases are independent of one another. However, in real scenarios, the input typically arrives as a sequence of comments/words over time instead of all at once. Thus, decisions based on partial information must be made while additional input is arriving. Moreover, social bias is complex by nature. Each type of bias is defined within its unique context, which, consistent with intersectionality theory within the social sciences, might be correlated with the contexts of other forms of bias. In this work, we consider debiasing toxicity detection as a sequential decision-making process where different biases can be interdependent. In particular, we study debiasing toxicity detection with two aims: (1) to examine whether different biases tend to correlate with each other; and (2) to investigate how to jointly mitigate these correlated biases in an interactive manner to minimize the total amount of bias. At the core of our approach is a framework built upon theories of sequential Markov Decision Processes that seeks to maximize the prediction accuracy and minimize the bias measures tailored to individual biases. Evaluations on two benchmark datasets empirically validate the hypothesis that biases tend to be correlated and corroborate the effectiveness of the proposed sequential debiasing strategy.|越来越多的社交媒体使用导致了辱骂、粗鲁和冒犯性的文字评论更加普遍。机器学习模型已经被开发用来检测网上的有毒评论，然而这些模型往往显示出对边缘化或少数族裔身份的用户(例如，女性和非裔美国人)的偏见。已建立的减少毒性分类器的研究通常(1)采用静态或批量方法，假设所有信息都可用，然后做出一次性决策; (2)使用通用策略来减轻假定偏见彼此独立的不同偏见(例如性别和种族偏见)。然而，在真实的场景中，输入通常是以注释/单词序列的形式随着时间的推移而到达，而不是一次性全部到达。因此，当额外的输入到达时，必须根据部分信息做出决策。此外，社会偏见本质上是复杂的。每种类型的偏见都是在其独特的背景下定义的，这与社会科学中的交叉性理论一致，可能与其他形式的偏见的背景相关。在这项工作中，我们认为去偏毒性检测是一个连续的决策过程中，不同的偏见可以相互依赖。具体而言，我们研究去偏毒性检测有两个目的: (1)检查不同的偏倚是否倾向于相互关联; (2)研究如何以交互方式共同减轻这些相关偏倚，以最小化偏倚总量。我们的方法的核心是一个建立在序贯马尔可夫决策过程理论基础上的框架，该框架寻求最大限度地提高预测的准确性，最小化针对个别偏差的偏差测量。对两个基准数据集的评估经验验证了偏差倾向于相关的假设，并证实了所提出的序贯去偏策略的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+Mitigation+for+Toxicity+Detection+via+Sequential+Decisions)|0|
|[Regulating Group Exposure for Item Providers in Recommendation](https://doi.org/10.1145/3477495.3531760)|Mirko Marras, Ludovico Boratto, Guilherme Ramos, Gianni Fenu|University of Lisbon, Lisbon, Portugal; University of Cagliari, Cagliari, Italy|Engaging all content providers, including newcomers or minority demographic groups, is crucial for online platforms to keep growing and working. Hence, while building recommendation services, the interests of those providers should be valued. In this paper, we consider providers as grouped based on a common characteristic in settings in which certain provider groups have low representation of items in the catalog and, thus, in the user interactions. Then, we envision a scenario wherein platform owners seek to control the degree of exposure to such groups in the recommendation process. To support this scenario, we rely on disparate exposure measures that characterize the gap between the share of recommendations given to groups and the target level of exposure pursued by the platform owners. We then propose a re-ranking procedure that ensures desired levels of exposure are met. Experiments show that, while supporting certain groups of providers by rendering them with the target exposure, beyond-accuracy objectives experience significant gains with negligible impact in recommendation utility.|吸引所有内容提供商，包括新来者或少数族裔群体，对于在线平台保持增长和运作至关重要。因此，在构建推荐服务时，应该重视这些提供者的利益。在本文中，我们认为提供程序是基于一个共同特征进行分组的，在这种情况下，某些提供程序组在目录中的项表示较低，因此在用户交互中也是如此。然后，我们设想一个场景，其中平台所有者寻求控制在推荐过程中暴露于这些群体的程度。为了支持这一设想，我们依靠不同的曝光度量标准，这些标准体现了给予群体的建议份额与平台所有者追求的曝光度目标水平之间的差距。然后，我们提出了一个重新排序的程序，以确保所需的暴露水平得到满足。实验表明，虽然支持某些群体的供应商，使他们的目标暴露，超过准确性的目标经历了显着的收益，对推荐效用的影响可以忽略不计。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regulating+Group+Exposure+for+Item+Providers+in+Recommendation)|0|
|[IPR: Interaction-level Preference Ranking for Explicit feedback](https://doi.org/10.1145/3477495.3531777)|ShihYang Liu, HsienHao Chen, ChihMing Chen, MingFeng Tsai, ChuanJu Wang|National Chengchi University, Taipei, Taiwan Roc; National Chengchi University, Academia Sinica, Taipei, Taiwan Roc; Academia Sinica, Taipei, Taiwan Roc|Explicit feedback---user input regarding their interest in an item---is the most helpful information for recommendation as it comes directly from the user and shows their direct interest in the item. Most approaches either treat the recommendation given such feedback as a typical regression problem or regard such data as implicit and then directly adopt approaches for implicit feedback; both methods, however,tend to yield unsatisfactory performance in top-k recommendation. In this paper, we propose interaction-level preference ranking(IPR), a novel pairwise ranking embedding learning approach to better utilize explicit feedback for recommendation. Experiments conducted on three real-world datasets show that IPR yields the best results compared to six strong baselines.|明确的反馈——用户关于他们对某个项目感兴趣的输入——是对推荐最有帮助的信息，因为它直接来自用户，并显示了他们对该项目的直接兴趣。大多数方法要么将给出的这种反馈视为典型的回归问题，要么将这种数据视为隐式的，然后直接采用隐式反馈的方法; 然而，这两种方法在 top-k 推荐中的表现往往都不令人满意。在本文中，我们提出了交互层次偏好排序(IPR) ，这是一种新的嵌入学习的成对排序方法，以更好地利用显式反馈进行推荐。在三个实际数据集上进行的实验表明，与六个强基线相比，IPR 产生的结果最好。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IPR:+Interaction-level+Preference+Ranking+for+Explicit+feedback)|0|
|[MP2: A Momentum Contrast Approach for Recommendation with Pointwise and Pairwise Learning](https://doi.org/10.1145/3477495.3531813)|Menghan Wang, Yuchen Guo, Zhenqi Zhao, Guangzheng Hu, Yuming Shen, Mingming Gong, Philip H. S. Torr|Tencent Inc., Shanghai, China; eBay Inc., Shanghai, China; University of Oxford, London, United Kingdom; The University of Melbourne, Melbourne, VIC, Australia|Binary pointwise labels (aka implicit feedback) are heavily leveraged by deep learning based recommendation algorithms nowadays. In this paper we discuss the limited expressiveness of these labels may fail to accommodate varying degrees of user preference, and thus lead to conflicts during model training, which we call annotation bias. To solve this issue, we find the soft-labeling property of pairwise labels could be utilized to alleviate the bias of pointwise labels. To this end, we propose a momentum contrast framework (\method ) that combines pointwise and pairwise learning for recommendation. \method has a three-tower network structure: one user network and two item networks. The two item networks are used for computing pointwise and pairwise loss respectively. To alleviate the influence of the annotation bias, we perform a momentum update to ensure a consistent item representation. Extensive experiments on real-world datasets demonstrate the superiority of our method against state-of-the-art recommendation algorithms.|二进制点态标签(即隐式反馈)是当今基于深度学习的推荐算法的重要组成部分。在本文中，我们讨论了这些标签的有限表达可能无法适应不同程度的用户偏好，从而导致模型训练过程中的冲突，我们称之为注释偏差。为了解决这个问题，我们发现可以利用成对标签的软标签特性来缓解点态标签的偏差。为此，我们提出了一个动量对比框架(方法) ，结合点态和成对学习的推荐。方法具有三塔网络结构: 一个用户网络和两个项目网络。两项网络分别用于计算逐点损失和成对损失。为了减轻注释偏差的影响，我们进行动量更新以确保项目表示的一致性。在真实世界数据集上的大量实验证明了我们的方法对最先进的推荐算法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MP2:+A+Momentum+Contrast+Approach+for+Recommendation+with+Pointwise+and+Pairwise+Learning)|0|
|[Deep Page-Level Interest Network in Reinforcement Learning for Ads Allocation](https://doi.org/10.1145/3477495.3531847)|Guogang Liao, Xiaowen Shi, Ze Wang, Xiaoxu Wu, Chuheng Zhang, Yongkang Wang, Xingxing Wang, Dong Wang|Meituan, Beijing, China; Tsinghua University, Beijing, China|A mixed list of ads and organic items is usually displayed in feed and how to allocate the limited slots to maximize the overall revenue is a key problem. Meanwhile, user behavior modeling is essential in recommendation and advertising (e.g., CTR prediction and ads allocation). Most previous works only model point-level positive feedback (i.e., click), which neglect the page-level information of feedback and other types of feedback. To this end, we propose Deep Page-level Interest Network (DPIN) to model the page-level user preference and exploit multiple types of feedback. Specifically, we introduce four different types of page-level feedback, and capture user preference for item arrangement under different receptive fields through the multi-channel interaction module. Through extensive offline and online experiments on Meituan food delivery platform, we demonstrate that DPIN can effectively model the page-level user preference and increase the revenue.|一个广告和有机项目的混合列表通常显示在饲料和如何分配有限的插槽，以最大限度地提高总收入是一个关键问题。同时，用户行为建模对于推荐和广告(例如，点击率预测和广告分配)至关重要。大多数以前的作品只是模拟点级别的正反馈(例如，点击) ，而忽略了反馈和其他类型的反馈的页级信息。为此，我们提出了深层页面级兴趣网络(DPIN)来建模页面级用户偏好，并利用多种类型的反馈。具体来说，我们引入了四种不同类型的页面级反馈，并通过多通道交互模块捕捉用户对不同接收域下项目排列的偏好。通过在美团外卖平台上进行的大量线下和线上实验，我们证明了 DPIN 可以有效地模拟页面级别的用户偏好，并增加收入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Page-Level+Interest+Network+in+Reinforcement+Learning+for+Ads+Allocation)|0|
|[Improving Micro-video Recommendation via Contrastive Multiple Interests](https://doi.org/10.1145/3477495.3531861)|Beibei Li, Beihong Jin, Jiageng Song, Yisong Yu, Yiyuan Zheng, Wei Zhou|Institute of Software, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China; MX Media Co., Ltd., Singapore, Singapore|With the rapid increase of micro-video creators and viewers, how to make personalized recommendations from a large number of candidates to viewers begins to attract more and more attention. However, existing micro-video recommendation models rely on expensive multi-modal information and learn an overall interest embedding that cannot reflect the user's multiple interests in micro-videos. Recently, contrastive learning provides a new opportunity for refining the existing recommendation techniques. Therefore, in this paper, we propose to extract contrastive multi-interests and devise a micro-video recommendation model CMI. Specifically, CMI learns multiple interest embeddings for each user from his/her historical interaction sequence, in which the implicit orthogonal micro-video categories are used to decouple multiple user interests. Moreover, it establishes the contrastive multi-interest loss to improve the robustness of interest embeddings and the performance of recommendations. The results of experiments on two micro-video datasets demonstrate that CMI achieves state-of-the-art performance over existing baselines.|随着微视频制作者和观众的迅速增多，如何从大量的候选人中向观众提供个性化的推荐，开始引起越来越多的关注。然而，现有的微视频推荐模型依赖于昂贵的多模态信息，学习的总体兴趣嵌入不能反映用户在微视频中的多重兴趣。近年来，对比学习为完善现有的推荐技术提供了一个新的机会。因此，本文提出提取对比多兴趣并设计一个微视频推荐模型 CMI。具体来说，CMI 从每个用户的历史交互序列中学习多个兴趣嵌入，其中使用隐式正交微视频类别来解耦多个用户兴趣。此外，本文还建立了对比的多利益损失模型，以提高利益嵌入的鲁棒性和建议的执行效率。在两个微视频数据集上的实验结果表明，CMI 在现有的基线上取得了最好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Micro-video+Recommendation+via+Contrastive+Multiple+Interests)|0|
|[Can Users Predict Relative Query Effectiveness?](https://doi.org/10.1145/3477495.3531893)|Oleg Zendel, Melika P. Ebrahim, J. Shane Culpepper, Alistair Moffat, Falk Scholer|RMIT University, Melbourne, VIC, Australia; The University of Melbourne, Melbourne, VIC, Australia|Any given information need can be expressed via a wide range of possible queries. Recent work with such query variations has demonstrated that different queries can fetch notably divergent sets of documents, even when the queries have identical intents and superficial similarity. That is, different users might receive SERPs of quite different effectiveness for the same information need. That observation then raises an interesting question: do users have a sense of how useful any given query will be? Can they anticipate the effectiveness of alternative queries for the same retrieval need? To explore that question we designed and carried out a crowd-sourced user study in which we asked subjects to consider an information need statement expressed as a backstory, and then provide their opinions as to the relative usefulness of a set of queries ostensibly addressing that objective. We solicited opinions using two different interfaces: one that collected absolute ratings of queries, and one that required that the subjects place a set of queries into "order". We found that crowd workers are reasonably consistent in their estimates of how effective queries are likely to be, and also that their estimates correlate positively with actual system performance.|任何给定的信息需求都可以通过各种可能的查询来表示。最近对这种查询变体的研究表明，不同的查询可以获取明显不同的文档集，即使查询具有相同的意图和表面上的相似性。也就是说，对于相同的信息需求，不同的用户可能会收到效果完全不同的 SERP。这种观察提出了一个有趣的问题: 用户是否知道任何给定的查询有多大用处？他们能够预测相同检索需求的替代查询的有效性吗？为了探索这个问题，我们设计并进行了一个众包用户研究，在这个研究中，我们要求受试者考虑一个表达为背景故事的信息需求陈述，然后提供他们对一组表面上针对该目标的查询的相对有用性的意见。我们使用两种不同的界面来征求意见: 一种是收集查询的绝对评分，另一种是要求被试将一组查询按顺序排列。我们发现，人群工作者对查询可能的有效性的估计是相当一致的，而且他们的估计与实际系统性能正相关。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Users+Predict+Relative+Query+Effectiveness?)|0|
|[Is Non-IID Data a Threat in Federated Online Learning to Rank?](https://doi.org/10.1145/3477495.3531709)|Shuyi Wang, Guido Zuccon|The University of Queensland, Brisbane, QLD, Australia|In this perspective paper we study the effect of non independent and identically distributed (non-IID) data on federated online learning to rank (FOLTR) and chart directions for future work in this new and largely unexplored research area of Information Retrieval. In the FOLTR process, clients participate in a federation to jointly create an effective ranker from the implicit click signal originating in each client, without the need to share data (documents, queries, clicks). A well-known factor that affects the performance of federated learning systems, and that poses serious challenges to these approaches, is that there may be some type of bias in the way data is distributed across clients. While FOLTR systems are on their own rights a type of federated learning system, the presence and effect of non-IID data in FOLTR has not been studied. To this aim, we first enumerate possible data distribution settings that may showcase data bias across clients and thus give rise to the non-IID problem. Then, we study the impact of each setting on the performance of the current state-of-the-art FOLTR approach, the Federated Pairwise Differentiable Gradient Descent (FPDGD), and we highlight which data distributions may pose a problem for FOLTR methods. We also explore how common approaches proposed in the federated learning literature address non-IID issues in FOLTR. This allows us to unveil new research gaps that, we argue, future research in FOLTR should consider.|在这篇前瞻性的论文中，我们研究了非独立和同分布(非 IID)数据对联邦在线学习排名(FOLTR)的影响，以及未来工作的图表方向，这是一个新的、很大程度上尚未探索的信息检索研究领域。在 FOLTR 过程中，客户端参与到一个联合中，从每个客户端发出的隐式点击信号中共同创建一个有效的排名，而不需要共享数据(文档、查询、点击)。影响联邦学习系统性能的一个众所周知的因素是，数据在客户端之间的分布方式可能存在某种偏差，这对这些方法提出了严峻的挑战。虽然 FOLTR 系统本身就是一种联邦学习系统，但是对于 FOLTR 中非 IID 数据的存在和影响还没有进行研究。为此，我们首先列举可能的数据分布设置，这些设置可能显示客户端之间的数据偏差，从而引起非 IID 问题。然后，我们研究了每种设置对当前最先进的 FOLTR 方法——联邦成对可微分梯度下降法(fPDGD)——性能的影响，并强调了哪些数据分布可能会给 FOLTR 方法带来问题。我们还探讨了联合学习文献中提出的常用方法如何解决 FOLTR 中的非 IID 问题。这使我们能够揭示新的研究差距，我们认为，在 FOLTR 的未来研究应该考虑。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+Non-IID+Data+a+Threat+in+Federated+Online+Learning+to+Rank?)|0|
|[On Natural Language User Profiles for Transparent and Scrutable Recommendation](https://doi.org/10.1145/3477495.3531873)|Filip Radlinski, Krisztian Balog, Fernando Diaz, Lucas Dixon, Ben Wedin|Google, Stavanger, Norway; Google, London, United Kingdom; Google, Paris, France; Google, Montreal, Canada; Google, Cambridge, MA, USA|Natural interaction with recommendation and personalized search systems has received tremendous attention in recent years. We focus on the challenge of supporting people's understanding and control of these systems and explore a fundamentally new way of thinking about representation of knowledge in recommendation and personalization systems. Specifically, we argue that it may be both desirable and possible for algorithms that use natural language representations of users' preferences to be developed. We make the case that this could provide significantly greater transparency, as well as affordances for practical actionable interrogation of, and control over, recommendations. Moreover, we argue that such an approach, if successfully applied, may enable a major step towards systems that rely less on noisy implicit observations while increasing portability of knowledge of one's interests.|近年来，与推荐系统和个性化检索系统的自然交互受到了极大的关注。我们重点关注支持人们理解和控制这些系统的挑战，并探索一种在推荐和个性化系统中表示知识的全新思维方式。具体来说，我们认为开发使用用户偏好的自然语言表示的算法是可取的，也是可能的。我们认为，这可以提供更大的透明度，以及提供实际可行的审讯和控制，建议。此外，我们认为，这种方法，如果成功地应用，可能使一个重大的步骤，系统的依赖噪音较少的隐含观察，同时增加了一个人的兴趣知识的可移植性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Natural+Language+User+Profiles+for+Transparent+and+Scrutable+Recommendation)|0|
|[Retrieval-Enhanced Machine Learning](https://doi.org/10.1145/3477495.3531722)|Hamed Zamani, Fernando Diaz, Mostafa Dehghani, Donald Metzler, Michael Bendersky|Google Research, Mountain View, CA, USA; University of Massachusetts Amherst, Amherst, MA, USA; Google Research, Amsterdam, Netherlands; Google Research, Montréal, PQ, Canada|Although information access systems have long supportedpeople in accomplishing a wide range of tasks, we propose broadening the scope of users of information access systems to include task-driven machines, such as machine learning models. In this way, the core principles of indexing, representation, retrieval, and ranking can be applied and extended to substantially improve model generalization, scalability, robustness, and interpretability. We describe a generic retrieval-enhanced machine learning (REML) framework, which includes a number of existing models as special cases. REML challenges information retrieval conventions, presenting opportunities for novel advances in core areas, including optimization. The REML research agenda lays a foundation for a new style of information access research and paves a path towards advancing machine learning and artificial intelligence.|尽管信息访问系统长期以来一直支持人们完成各种各样的任务，但我们建议扩大信息访问系统的用户范围，以包括任务驱动的机器，如机器学习模型。通过这种方式，可以应用和扩展索引、表示、检索和排序的核心原则，从而大大提高模型泛化、可伸缩性、健壮性和可解释性。我们描述了一个通用的检索增强机器学习(REML)框架，其中包括一些现有的模型作为特殊情况。REML 挑战了信息检索惯例，为核心领域的新进展提供了机会，包括优化。REML 研究议程为新型的信息获取研究奠定了基础，为机器学习和人工智能的发展铺平了道路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Enhanced+Machine+Learning)|0|
|[Multi-CPR: A Multi Domain Chinese Dataset for Passage Retrieval](https://doi.org/10.1145/3477495.3531736)|Dingkun Long, Qiong Gao, Kuan Zou, Guangwei Xu, Pengjun Xie, Ruijie Guo, Jian Xu, Guanjun Jiang, Luxi Xing, Ping Yang|Alibaba Group, Hangzhou, China|Passage retrieval is a fundamental task in information retrieval (IR) research, which has drawn much attention recently. In the English field, the availability of large-scale annotated dataset (e.g, MS MARCO) and the emergence of deep pre-trained language models (e.g, BERT) has resulted in a substantial improvement of existing passage retrieval systems. However, in the Chinese field, especially for specific domains, passage retrieval systems are still immature due to quality-annotated dataset being limited by scale. Therefore, in this paper, we present a novel multi-domain Chinese dataset for passage retrieval (Multi-CPR). The dataset is collected from three different domains, including E-commerce, Entertainment video and Medical. Each dataset contains millions of passages and a certain amount of human annotated query-passage related pairs. We implement various representative passage retrieval methods as baselines. We find that the performance of retrieval models trained on dataset from general domain will inevitably decrease on specific domain. Nevertheless, a passage retrieval system built on in-domain annotated dataset can achieve significant improvement, which indeed demonstrates the necessity of domain labeled data for further optimization. We hope the release of the Multi-CPR dataset could benchmark Chinese passage retrieval task in specific domain and also make advances for future studies.|短文检索是信息检索研究中的一项基础性工作，近年来备受关注。在英语领域，大规模注释数据集(例如 MS MARCO)的可用性和深度预训练语言模型(例如 BERT)的出现使现有的文章检索系统得到了实质性的改进。然而，在中文领域，特别是在特定领域，由于质量注释数据集受到规模的限制，文章检索系统还不成熟。因此，本文提出了一种新的多领域中文文本检索数据集(Multi-CPR)。该数据集收集自三个不同的领域，包括电子商务，娱乐视频和医疗。每个数据集包含数百万个段落和一定数量的人工注释的查询-段落相关对。我们实现了各种具有代表性的文章检索方法作为基线。研究发现，对一般领域数据集训练的检索模型在特定领域的性能不可避免地会下降。然而，建立在域内注释数据集上的文章检索系统可以取得显著的改进，这确实说明了域标记数据进一步优化的必要性。我们希望通过多 CPR 数据集的发布，能够为特定领域的中文文章检索任务提供基准，并为今后的研究提供参考。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-CPR:+A+Multi+Domain+Chinese+Dataset+for+Passage+Retrieval)|0|
|[MIMICS-Duo: Offline & Online Evaluation of Search Clarification](https://doi.org/10.1145/3477495.3531750)|Leila Tavakoli, Johanne R. Trippas, Hamed Zamani, Falk Scholer, Mark Sanderson|University of Massachusetts Amherst, Amherst, MA, USA; RMIT University, Melbourne, VIC, Australia; University of Melbourne, Melbourne, VIC, Australia|Asking clarification questions is an active area of research; however, resources for training and evaluating search clarification methods are not sufficient. To address this issue, we describe MIMICS-Duo, a new freely available dataset of 306 search queries with multiple clarifications (a total of 1,034 query-clarification pairs). MIMICS-Duo contains fine-grained annotations on clarification questions and their candidate answers and enhances the existing MIMICS datasets by enabling multi-dimensional evaluation of search clarification methods, including online and offline evaluation. We conduct extensive analysis to demonstrate the relationship between offline and online search clarification datasets and outline several research directions enabled by MIMICS-Duo. We believe that this resource will help researchers better understand clarification in search.|提出澄清问题是一个活跃的研究领域，然而，培训和评估搜索澄清方法的资源是不够的。为了解决这个问题，我们描述了 MIMICS-Duo，这是一个新的免费数据集，包含306个具有多重澄清的搜索查询(总共1,034个查询-澄清对)。MIMICS-Duo 包含关于澄清问题及其候选答案的细粒度注释，并通过支持搜索澄清方法的多维评估(包括在线和离线评估)来增强现有的 MIMICS 数据集。我们进行了广泛的分析，以证明离线和在线搜索澄清数据集之间的关系，并概述了由 MIMICS-Duo 实现的几个研究方向。我们相信，这一资源将有助于研究人员更好地理解在搜索澄清。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MIMICS-Duo:+Offline+&+Online+Evaluation+of+Search+Clarification)|0|
|[A Common Framework for Exploring Document-at-a-Time and Score-at-a-Time Retrieval Methods](https://doi.org/10.1145/3477495.3531657)|Andrew Trotman, Joel Mackenzie, Pradeesh Parameswaran, Jimmy Lin|University of Waterloo, Waterloo, Canada; The University of Queensland, Brisbane, QLD, Australia; University of Otago, Dunedin, New Zealand|Document-at-a-time (DaaT) and score-at-a-time (SaaT) query evaluation techniques are different approaches to top-k retrieval with inverted indexes. While modern systems are dominated by DaaT, the academic literature has seen decades of debate about the merits of each. Recently, there has been renewed interest in SaaT methods for learned sparse lexical models, where studies have shown that transformers generate "wacky weights" that appear to reduce opportunities for optimizations in DaaT methods. However, researchers currently lack an easy-to-use SaaT system to support further exploration. This is the gap that our work fills. Starting with a modern SaaT system (JASS), we built Python bindings in order to integrate into the DaaT Pyserini IR toolkit (Lucene). The result is a common frontend to both a DaaT and a SaaT system. We demonstrate how recent experiments with a wide range of learned sparse lexical models can be easily reproduced. Our contribution is a framework that enables future research comparing DaaT and SaaT methods in the context of modern neural retrieval models.|一次文档(DaaT)和一次得分(SaaT)查询评估技术是两种不同的方法，用于带有倒排索引的 top-k 检索。虽然现代系统是由 DaaT 主导的，但学术文献已经对每个系统的优点进行了数十年的争论。最近，人们对学习稀疏词汇模型的 SaaT 方法重新产生了兴趣，研究表明，变压器产生的“古怪的权重”似乎减少了 DaaT 方法优化的机会。然而，研究人员目前缺乏一个易于使用的 SaaT 系统来支持进一步的探索。这是我们的工作填补的空白。从一个现代 SaaT 系统(JASS)开始，我们构建了 Python 绑定，以便集成到 DaaT Pyserini IR 工具包(Lucene)中。其结果是 DaaT 和 SaaT 系统的共同前端。我们证明了最近的实验与广泛的学习稀疏词汇模型可以很容易地再现。我们的贡献是一个框架，使未来的研究比较 DaaT 和 SaaT 方法在现代神经检索模型的背景下。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Common+Framework+for+Exploring+Document-at-a-Time+and+Score-at-a-Time+Retrieval+Methods)|0|
|[BiTe-REx: An Explainable Bilingual Text Retrieval System in the Automotive Domain](https://doi.org/10.1145/3477495.3531665)|Viju Sudhi, Sabine Wehnert, Norbert Michael Homner, Sebastian Ernst, Mark Gonter, Andreas Krug, Ernesto William De Luca|Otto von Guericke University, Magdeburg, Germany; Audi AG, Ingolstadt, Germany|To satiate the comprehensive information need of users, retrieval systems surpassing the boundaries of language are inevitable in the present digital space in the wake of an ever-rising multilingualism. This work presents the first-of-its-kind Bilingual Text Retrieval Explanations (BiTe-REx) aimed at users performing competitor or wage analysis in the automotive domain. BiTe-REx supports users to gather a more comprehensive picture of their query by retrieving results regardless of the query language and enables them to make a more informed decision by exposing how the underlying model judges the relevance of documents. With a user study, we demonstrate statistically significant results on the understandability and helpfulness of the explanations provided by the system.|为了满足用户的综合信息需求，随着多种语言的日益普及，超越语言边界的检索系统在当今数字化空间中是不可避免的。这项工作提出了第一种双语文本检索解释(BiTe-REx) ，旨在用户执行竞争对手或工资分析在汽车领域。BiTe-REx 支持用户通过检索结果(不管查询语言如何)收集更全面的查询信息，并通过揭示底层模型如何判断文档的相关性，使用户能够做出更明智的决策。通过用户研究，我们证明了系统提供的解释的可理解性和有用性的统计学显著结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BiTe-REx:+An+Explainable+Bilingual+Text+Retrieval+System+in+the+Automotive+Domain)|0|
|[Are Taylor's Posts Risky? Evaluating Cumulative Revelations in Online Personal Data: A persona-based tool for evaluating awareness of online risks and harms](https://doi.org/10.1145/3477495.3531659)|Leif Azzopardi, Jo Briggs, Melissa Duheric, Callum Nash, Emma Nicol, Wendy Moncur, Burkhard Schafer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+Taylor's+Posts+Risky?+Evaluating+Cumulative+Revelations+in+Online+Personal+Data:+A+persona-based+tool+for+evaluating+awareness+of+online+risks+and+harms)|0|
|[DDEN: A Heterogeneous Learning-to-Rank Approach with Deep Debiasing Experts Network](https://doi.org/10.1145/3477495.3536320)|Wenchao Xiu, Yiran Wang, Taofeng Xue, Kai Zhang, Qin Zhang, Zhonghuo Wu, Yifan Yang, Gong Zhang|Meituan, Shanghai, China|Learning-to-Rank(LTR) is widely used in many Information Retrieval(IR) scenarios, including web search and Location Based Services(LBS) search. However, most existing LTR techniques mainly focus on homogeneous ranking. Taking QAC in Dianping search as an example, heterogeneous documents including suggested queries (SQ) and Point-of-Interests(POI) need to be ranked and presented to enhance user experience. New challenges are faced when conducting heterogeneous ranking, including inconsistent feature space and more serious position bias caused by distinct representation spaces. Therefore, we propose Deep Debiasing Experts Network (DDEN), a novel heterogeneous LTR approach based on Mixture-of-Experts architecture and gating network, to deal with the inconsistent feature space of documents in ranking system. Furthermore, DDEN mitigates the position bias by adopting adversarial-debiasing framework embedded with heterogeneous LTR techniques. We conduct reproducible experiments on industrial datasets from Dianping, one of the largest local life platforms, and deploy DDEN in online application. Results show that DDEN substantially improves ranking performance in offline evaluation and boost the overall click-through rate in online A/B test by 2.1%.|学习到排名(learning-to-Rank，LTR)广泛应用于许多信息检索场景，包括网络搜索和基于位置的服务(Location Based Services，LBS)搜索。然而，大多数现有的 LTR 技术主要集中在同质排序。以点评搜索中的质量控制(QAC)为例，需要对包括建议查询(SQ)和兴趣点(POI)在内的异构文档进行排序和呈现，以提高用户体验。异构排序面临的新挑战包括不一致的特征空间和不同表示空间引起的更严重的位置偏差。为此，本文提出了一种基于专家混合体系结构和门网络的异构 LTR 方法——深度去偏专家网络(Deep Debioning Expert Network，DDEN) ，用于处理排序系统中文档的不一致特征空间。此外，DDEN 通过采用嵌入异构 LTR 技术的对抗性消偏框架来缓解位置偏差。我们在本地最大的生活平台之一 Dianping 的工业数据集上进行可重复的实验，并在在线应用中部署 DDEN。结果显示，DDEN 大大提高了离线评估的排名表现，并使在线 A/B 测试的整体点进率提高了2.1% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DDEN:+A+Heterogeneous+Learning-to-Rank+Approach+with+Deep+Debiasing+Experts+Network)|0|
|[An Intelligent Advertisement Short Video Production System via Multi-Modal Retrieval](https://doi.org/10.1145/3477495.3536323)|Yanheng Wei, Lianghua Huang, Yanhao Zhang, Yun Zheng, Pan Pan|Alibaba Group, Beijing, China|In its most basic form, advertising video production communicates a message about a product or service to the public. In the age of digital marketing, where the most popular way to connect with audiences is through advertising videos. However, advertising video production is a costly and complicated process from creation, material shooting, editing to the final commercial video. Therefore, producing qualified advertising videos is a capital and talent-intensive task, which poses a huge challenge for start-ups or inexperienced ad creators. paper proposes an intelligent advertising video production system driven by multi-modal retrieval, which only requires the input of descriptive copy. This system can automatically generate scripts, then extract key queries, retrieve related short video materials in the video library, and finally synthesize short advertising videos. The whole process minimizes human input, greatly reduces the threshold for advertising video production and greatly improves output and efficiency. It has a modular design to encourage the study of new multi-modal algorithms, which can be evaluated in batch mode. It can also integrate with a user interface, which allows user studies and data collection in an interactive mode, where the back end can be fully algorithmic or a wizard of oz setup. The proposed system has been fully verified and has broad prospects in the production of short videos for commodity advertisements within Alibaba.|在最基本的形式中，广告视频制作向公众传达了关于产品或服务的信息。在数字营销时代，最流行的与观众联系的方式是通过广告视频。然而，广告视频制作是一个昂贵而复杂的过程，从创作、素材拍摄、编辑到最终的商业视频。因此，制作合格的广告视频是一项资本和人才密集型的任务，这对初创企业或缺乏经验的广告创作者来说是一个巨大的挑战。提出了一种基于多模态检索的智能广告视频制作系统，该系统只需要输入描述性文本。该系统可以自动生成脚本，然后提取关键查询，检索视频库中相关的短视频资料，最后合成广告短视频。整个过程最大限度地减少了人工投入，大大降低了广告视频制作的门槛，大大提高了产量和效率。它采用模块化设计，以鼓励对新的多模态算法的研究，这些算法可以在批处理模式下进行评估。它还可以集成一个用户界面，允许用户研究和数据收集在一个交互模式，其中后端可以完全算法或绿野仙踪设置向导。建议的系统已经全面验证，在阿里巴巴制作商品广告短片方面具有广阔前景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Intelligent+Advertisement+Short+Video+Production+System+via+Multi-Modal+Retrieval)|0|
|[An Industrial Framework for Cold-Start Recommendation in Zero-Shot Scenarios](https://doi.org/10.1145/3477495.3536332)|Zhaoxin Huan, Gongduo Zhang, Xiaolu Zhang, Jun Zhou, Qintong Wu, Lihong Gu, Jinjie Gu, Yong He, Yue Zhu, Linjian Mo|Ant Group, Hangzhou, China|There exists the cold-start problem in the recommendation systems when observed user-item interactions are insufficient. To alleviate this problem, most existing works aim to learn globally shared prior knowledge across all items and be fast adapted to a new item with few interactions. However, such learning techniques are data demanding and work poorly on new items with no interactions. In this applied paper, we present an industrial framework recently deployed on Alipay to address the item cold-start problem in zero-shot scenarios. The proposed framework provides both efficient and high-quality recommendations for cold items with no log data. Specifically, we formulate the cold-start problem as a zero-shot learning problem and build a highly efficient infrastructure to accomplish online zero-shot recommendations used on large-scale platforms. Extensive offline experiments and online A/B testing demonstrate that the proposed framework has superior performance and recommends cold items to preferred users more effectively than other state-of-the-art methods.|当观察到的用户-项目交互不足时，推荐系统存在冷启动问题。为了缓解这一问题，大多数现有的工作旨在学习全球共享的所有项目的先验知识，并迅速适应一个新的项目，几乎没有互动。然而，这种学习技术对数据的要求很高，而且在没有交互的情况下对新项目的处理效果很差。在这篇应用文章中，我们提出了一个最近部署在支付宝上的产业框架，来解决零射击情景下的项目冷启动问题。拟议的框架为没有日志数据的冷藏物品提供了高效率和高质量的建议。具体来说，我们将冷启动问题描述为一个零拍学习问题，并建立一个高效的基础设施来实现在大规模平台上使用的在线零拍推荐。大量的离线实验和在线 A/B 测试表明，所提出的框架具有优越的性能，比其他最先进的方法更有效地向首选用户推荐冷项。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Industrial+Framework+for+Cold-Start+Recommendation+in+Zero-Shot+Scenarios)|0|
|[What the Actual...Examining User Behaviour in Information Retrieval](https://doi.org/10.1145/3477495.3532687)|George Buchanan, Dana McKay|RMIT University, Melbourne, VIC, Australia; University of Melbourne, Melbourne, VIC, Australia|Conducting studies involving actual users is a recurring challenge in information retrieval. In this tutorial we will address the main strategic and tactical choices for engaging with, designing and executing user studies, considering both evaluation and formative investigation. The tension between reproducibility and ensuring natural user behaviour will be a recurring focus, seeking to help individual researchers make an intentional and well-argued choice for their research. The presenters have over fifty years of combined experience working in interactive information retrieval, and information interaction in general.|进行涉及实际使用者的研究是信息检索的一个反复出现的挑战。在本教程中，我们将讨论参与、设计和执行用户研究的主要战略和战术选择，同时考虑评估和形成性调查。可重复性和确保自然使用者行为之间的紧张关系将是一个反复出现的焦点，目的是帮助个别研究人员为其研究做出有意识和有充分理由的选择。主持人在互动信息检索和一般的信息互动方面有超过五十年的工作经验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+the+Actual...Examining+User+Behaviour+in+Information+Retrieval)|0|
|[User-centered Non-factoid Answer Retrieval](https://doi.org/10.1145/3477495.3531689)|Marwah Alaofi|RMIT University, Melbourne, VIC, Australia|In this research, we aim to examine the assumptions made about users when searching for non-factoid answers using search engines. That is, the way they approach non-factoid question-answering tasks, the language they use to express their questions, the variability in their queries and their behavior towards the provided answers. The investigation will also examine the extent to which these neglected factors affect retrieval performance and potentially highlight the importance of building more realistic methodologies and test collections that capture the real nature of this task. Through our preliminary work, we have begun to explore the characteristics of non-factoid question-answering queries and investigate query variability and their impact on modern retrieval models. Our preliminary results demonstrate notable differences between non-factoid questions sampled from a large query log and those used in QA datasets. In addition, our results demonstrate a profound effect of query variability on retrieval consistency, indicating a potential impact on retrieval performance that is worth studying. We highlight the importance of understanding user behaviour while searching for non-factoid answers, specifically the way they behave in response to receiving an answer. This should advance our understanding of the support users require across different types of non-factoid questions and inform the design of interaction models that support learning and encourage exploring.|本研究旨在探讨使用搜寻引擎搜寻非事实性答案时，对使用者所作的假设。也就是说，他们处理非事实性问答任务的方式，他们用来表达他们的问题的语言，他们的查询的可变性和他们对提供的答案的行为。调查还将审查这些被忽视的因素在多大程度上影响检索性能，并可能强调建立更现实的方法和测试收集的重要性，以捕捉这一任务的真实性质。通过我们的初步工作，我们已经开始探索非事实问答查询的特点，并调查查询的可变性及其对现代检索模型的影响。我们的初步结果表明，从大型查询日志中抽样的非事实性问题与 QA 数据集中使用的问题之间存在显著差异。此外，我们的研究结果显示了查询变异性对检索一致性的深刻影响，表明了对检索性能的潜在影响，值得研究。我们强调了理解用户行为的重要性，同时寻找非事实性的答案，特别是他们的行为方式，以回应收到的答案。这将提高我们对用户在不同类型的非事实性问题中需要的支持的理解，并为支持学习和鼓励探索的交互模型的设计提供信息。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-centered+Non-factoid+Answer+Retrieval)|0|
|[Intelligent Conversational Agents for Ambient Computing](https://doi.org/10.1145/3477495.3532087)|Ruhi Sarikaya|Amazon, Seattle, WA, USA|We are in the midst of an AI revolution. Three primary disruptive changes set off this revolution: 1) increase in compute power, mobile internet, and advances in deep learning. The next decade is expected to be about the proliferation of Internet-of-Things (IoT) devices and sensors, which will generate exponentially larger amounts of data to reason over and pave the way for ambient computing. This will also give rise to new forms of interaction patterns with these systems. Users will have to interact with these systems under increasingly richer context and in real-time. Conversational AI has a critical role to play in this revolution, but only if it delivers on its promise of enabling natural, frictionless, and personalized interactions in any context the user is in, while hiding the complexity of these systems through ambient intelligence. However, current commercial conversational AI systems are trained primarily with a supervised learning paradigm, which is difficult, if not impossible, to scale by manually annotating data for increasingly complex sets of contextual conditions. Inherent ambiguity in natural language further complicates the problem. We need to devise new forms of learning paradigms and frameworks that will scale to this complexity. In this talk, we present some early steps we are taking with Alexa, Amazon's Conversational AI system, to move from supervised learning to self-learning methods, where the AI relies on customer interactions for supervision in our journey to ambient intelligence.|我们正处于人工智能革命的中期。三个主要的颠覆性变化引发了这场革命: 1)计算能力的提高，移动互联网的发展，以及深度学习的进步。下一个十年预计将是物联网设备和传感器的激增，它们将产生指数级数量的数据来进行推理，并为环境计算铺平道路。这也将产生与这些系统交互模式的新形式。用户将不得不在日益丰富的上下文环境下与这些系统进行实时交互。对话式人工智能在这场革命中扮演着关键的角色，但前提是它能够在用户所处的任何环境中实现自然、无摩擦和个性化的交互，同时通过环境智能隐藏这些系统的复杂性。然而，目前的商业会话人工智能系统主要使用监督式学习范式进行训练，这种范式很难(如果不是不可能的话)通过手动为日益复杂的上下文条件集注释数据来扩展。自然语言中固有的歧义使问题进一步复杂化。我们需要设计新的学习范式和框架，以适应这种复杂性。在本次演讲中，我们将介绍亚马逊的对话式人工智能系统 Alexa 的一些早期步骤，该系统将从监督式学习转向自学习方法，在我们的环境智能过程中，人工智能依赖客户互动进行监督。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intelligent+Conversational+Agents+for+Ambient+Computing)|0|
|[A Robust Computerized Adaptive Testing Approach in Educational Question Retrieval](https://doi.org/10.1145/3477495.3531928)|Yan Zhuang, Qi Liu, Zhenya Huang, Zhi Li, Binbin Jin, Haoyang Bi, Enhong Chen, Shijin Wang|Huawei Cloud Computing Technologies Co., Ltd, Hangzhou, China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China & Institute of Artificial Intelligence, Hefei Comprehensive National Science Center & State Key Laboratory of Cognitive Intelligence, Hefei, China; State Key Laboratory of Cognitive Intelligence & iFLYTEK AI Research (Central China), iFLYTEK Co., Ltd, Hefei, China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|Computerized Adaptive Testing (CAT) is a promising testing mode in personalized online education (e.g., GRE), which aims at measuring student's proficiency accurately and reducing test length. The "adaptive" is reflected in its selection algorithm that can retrieve best-suited questions for student based on his/her estimated proficiency at each test step. Although there are many sophisticated selection algorithms for improving CAT's effectiveness, they are restricted and perturbed by the accuracy of current proficiency estimate, thus lacking robustness. To this end, we investigate a general method to enhance the robustness of existing algorithms by leveraging student's "multi-facet" nature during tests. Specifically, we present a generic optimization criterion Robust Adaptive Testing (RAT) for proficiency estimation via fusing multiple estimates at each step, which maintains a multi-facet description of student's potential proficiency. We further provide theoretical analyses of such estimator's desirable statistical properties: asymptotic unbiasedness, efficiency, and consistency. Extensive experiments on perturbed synthetic data and three real-world datasets show that selection algorithms in our RAT framework are robust and yield substantial improvements.|计算机自适应测试(CAT)是个性化网络教育(如 GRE)中一种很有前途的测试模式，其目的是准确测量学生的水平，减少测试时间。“适应性”反映在其选择算法中，该算法可以根据学生在每个测试步骤中的估计熟练程度为学生检索最适合的问题。虽然有许多复杂的选择算法来提高 CAT 的有效性，但它们都受到当前水平估计精度的限制和干扰，因此缺乏鲁棒性。为此，我们研究了一种通用的方法，以增强现有的算法的健壮性，利用学生的“多方面”的性质在测试。具体来说，我们提出了一个通用的优化标准鲁棒自适应测试(RAT)的水平估计融合多个估计在每一个步骤，它保持了一个学生的潜在水平的多方面的描述。进一步从理论上分析了这类估计量的理想统计性质: 渐近无偏性、有效性和一致性。在扰动合成数据和三个实际数据集上的大量实验表明，我们的 RAT 框架中的选择算法是健壮的，并且产生了实质性的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Robust+Computerized+Adaptive+Testing+Approach+in+Educational+Question+Retrieval)|0|
|[Forest-based Deep Recommender](https://doi.org/10.1145/3477495.3531980)|Chao Feng, Defu Lian, Zheng Liu, Xing Xie, Le Wu, Enhong Chen|Microsoft Research Asia, Beijing, China; Hefei university of Technology, Hefei, China; University of Science and Technology of China, Hefei, China|With the development of deep learning techniques, deep recommendation models also achieve remarkable improvements in terms of recommendation accuracy. However, due to the large number of candidate items in practice and the high cost of preference computation, these methods also suffer from low efficiency of recommendation. The recently proposed tree-based deep recommendation models alleviate the problem by directly learning tree structure and representations under the guidance of recommendation objectives. However, such models have two shortcomings. First, the max-heap assumption in the hierarchical tree, in which the preference for a parent node should be the maximum between the preferences for its children, is difficult to satisfy in their binary classification objectives. Second, the learned index only includes a single tree, which is different from the widely-used multiple trees index, providing an opportunity to improve the accuracy of recommendation. To this end, we propose a Deep Forest-based Recommender (DeFoRec for short) for an efficient recommendation. In DeFoRec, all the trees generated during training process are retained to form the forest. When learning node representation of each tree, we have to satisfy the max-heap assumption as much as possible and mimic beam search behavior over the tree in the training stage. This is achieved by DeFoRec to regard the training task as multi-classification over tree nodes at the same level. However, the number of tree nodes grows exponentially with levels, making us to train the preference model by the guidance of sampled-softmax technique. The experiments are conducted on real-world datasets, validating the effectiveness of the proposed preference model learning method and tree learning method.|随着深度学习技术的发展，深度推荐模型在推荐精度方面也取得了显著的提高。然而，由于实际中候选项数量大，偏好计算成本高，这些方法也存在推荐效率低的问题。最近提出的基于树的深度推荐模型通过在推荐目标的指导下直接学习树的结构和表示来解决这个问题。然而，这种模式有两个缺点。首先，层次树中的最大堆假设(父节点的首选项应该是其子节点的首选项之间的最大值)难以满足其二进制分类目标。其次，学习索引只包括一棵树，这与广泛使用的多棵树索引不同，为提高推荐的准确性提供了机会。为此，我们提出了一个基于深度森林的推荐器(简称 DeFoRec)来实现有效的推荐。在 DeFoRec 中，所有在训练过程中生成的树被保留以形成森林。在学习每棵树的节点表示时，必须尽可能满足最大堆假设，并在训练阶段模拟树上的束搜索行为。DeFoRec 将训练任务视为同一层次上的树节点上的多分类，从而实现了这一目标。然而，树节点的数量随着层次的增加呈指数增长，这使得我们在采样-软极大技术的指导下对偏好模型进行训练。在实际数据集上进行了实验，验证了所提出的偏好模型学习方法和树学习方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forest-based+Deep+Recommender)|0|
|[Ranking Interruptus: When Truncated Rankings Are Better and How to Measure That](https://doi.org/10.1145/3477495.3532051)|Enrique Amigó, Stefano Mizzaro, Damiano Spina|UNED NLP & IR Group, Madrid, Spain; RMIT University, Melbourne, VIC, Australia; University of Udine, Udine, Italy|Most of information retrieval effectiveness evaluation metrics assume that systems appending irrelevant documents at the bottom of the ranking are as effective as (or not worse than) systems that have a stopping criteria to 'truncate' the ranking at the right position to avoid retrieving those irrelevant documents at the end. It can be argued, however, that such truncated rankings are more useful to the end user. It is thus important to understand how to measure retrieval effectiveness in this scenario. In this paper we provide both theoretical and experimental contributions. We first define formal properties to analyze how effectiveness metrics behave when evaluating truncated rankings. Our theoretical analysis shows that de-facto standard metrics do not satisfy desirable properties to evaluate truncated rankings: only Observational Information Effectiveness (OIE) -- a metric based on Shannon's information theory -- satisfies them all. We then perform experiments to compare several metrics on nine TREC datasets. According to our experimental results, the most appropriate metrics for truncated rankings are OIE and a novel extension of Rank-Biased Precision that adds a user effort factor penalizing the retrieval of irrelevant documents.|大多数信息检索有效性评估指标都假定，在排名底部附加不相关文档的系统与那些有停止标准的系统一样有效(或者不比那些有停止标准的系统差) ，后者会在正确的位置“截断”排名，以避免在最后检索到那些不相关的文档。然而，可以说，这种截断的排名对最终用户更有用。因此，了解如何在此场景中度量检索效率非常重要。在本文中，我们提供了理论和实验的贡献。我们首先定义形式属性来分析效率指标在评估截断排名时的表现。我们的理论分析表明，事实上的标准指标不能满足评估截断排名的理想属性: 只有观测信息有效性(OIE)——一个基于香农信息理论的指标——能够满足所有这些指标。然后，我们进行实验来比较九个 TREC 数据集上的几个指标。根据我们的实验结果，最适合截断排名的指标是 OIE 和一个新的扩展排名偏差精度，增加了用户的努力因素惩罚检索不相关的文档。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking+Interruptus:+When+Truncated+Rankings+Are+Better+and+How+to+Measure+That)|0|
|[Offline Retrieval Evaluation Without Evaluation Metrics](https://doi.org/10.1145/3477495.3532033)|Fernando Diaz, Andres Ferraro|Google, Montréal, PQ, Canada; Mila - Quebec Artificial Intelligence Institute, Montréal, PQ, Canada|Offline evaluation of information retrieval and recommendation has traditionally focused on distilling the quality of a ranking into a scalar metric such as average precision or normalized discounted cumulative gain. We can use this metric to compare the performance of multiple systems for the same request. Although evaluation metrics provide a convenient summary of system performance, they also collapse subtle differences across users into a single number and can carry assumptions about user behavior and utility not supported across retrieval scenarios. We propose recall-paired preference (RPP), a metric-free evaluation method based on directly computing a preference between ranked lists. RPP simulates multiple user subpopulations per query and compares systems across these pseudo-populations. Our results across multiple search and recommendation tasks demonstrate that RPP substantially improves discriminative power while correlating well with existing metrics and being equally robust to incomplete data.|对信息检索和推荐的离线评估传统上侧重于将排名的质量提炼为一个标量指标，如平均精度或标准化折现累计增益。我们可以使用这个度量来比较同一个请求的多个系统的性能。虽然评估指标提供了一个方便的系统性能总结，但是它们也将用户之间的细微差异折叠成一个数字，并且可以对不支持检索场景的用户行为和实用程序进行假设。我们提出了一种基于直接计算排名表之间偏好的无度量评价方法——召回配对偏好(RPP)。RPP 模拟每个查询的多个用户子种群，并比较这些伪种群中的系统。我们在多个搜索和推荐任务中的结果表明，RPP 大大提高了识别能力，同时与现有指标关联良好，对不完整数据具有同样的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Retrieval+Evaluation+Without+Evaluation+Metrics)|0|
|[Pareto-Optimal Fairness-Utility Amortizations in Rankings with a DBN Exposure Model](https://doi.org/10.1145/3477495.3532036)|Till Kletti, JeanMichel Renders, Patrick Loiseau|Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, Grenoble, France; Naver Labs Europe, Meylan, France|In recent years, it has become clear that rankings delivered in many areas need not only be useful to the users but also respect fairness of exposure for the item producers. We consider the problem of finding ranking policies that achieve a Pareto-optimal tradeoff between these two aspects. Several methods were proposed to solve it; for instance a popular one is to use linear programming with a Birkhoff-von Neumann decomposition. These methods, however, are based on a classical Position Based exposure Model (PBM), which assumes independence between the items (hence the exposure only depends on the rank). In many applications, this assumption is unrealistic and the community increasingly moves towards considering other models that include dependences, such as the Dynamic Bayesian Network (DBN) exposure model. For such models, computing (exact) optimal fair ranking policies remains an open question. In this paper, we answer this question by leveraging a new geometrical method based on the so-called expohedron proposed recently for the PBM (Kletti et al., WSDM'22). We lay out the structure of a new geometrical object (the DBN-expohedron), and propose for it a Carathéodory decomposition algorithm of complexity $O(n^3)$, where n is the number of documents to rank. Such an algorithm enables expressing any feasible expected exposure vector as a distribution over at most n rankings; furthermore we show that we can compute the whole set of Pareto-optimal expected exposure vectors with the same complexity $O(n^3)$. Our work constitutes the first exact algorithm able to efficiently find a Pareto-optimal distribution of rankings. It is applicable to a broad range of fairness notions, including classical notions of meritocratic and demographic fairness. We empirically evaluate our method on the TREC2020 and MSLR datasets and compare it to several baselines in terms of Pareto-optimality and speed.|近年来，很明显，在许多领域提供的排名不仅需要对用户有用，而且还要尊重项目制作者的公平曝光。我们考虑的问题，找到排序的政策，实现了帕累托最优权衡这两个方面。人们提出了几种方法来解决这个问题，例如，一种流行的方法是使用伯克霍夫-冯诺依曼分解的线性规划。然而，这些方法是基于经典的基于位置的曝光模型(PBM) ，该模型假设项目之间的独立性(因此曝光只取决于排名)。在许多应用程序中，这种假设是不现实的，社区越来越倾向于考虑包含依赖关系的其他模型，例如动态贝氏网路暴露模型。对于这样的模型，计算(精确的)最优公平排序策略仍然是一个悬而未决的问题。在本文中，我们回答这个问题，利用一个新的几何方法的基础上，所谓的外三面体最近提出的 PBM (Kletti 等，WSDM’22)。我们给出了一个新的几何对象(DBN-expohedron)的结构，并提出了一个复杂度为 $O (n ^ 3) $的 Carathéodory 分解算法，其中 n 是要排序的文档数。这种算法能够表示任何可行的期望暴露矢量作为一个分布在最多 n 个排名; 此外，我们表明，我们可以计算整个集合的帕累托最优期望暴露矢量具有相同的复杂度 $O (n ^ 3) $。我们的工作构成了第一个精确的算法，能够有效地找到排名的帕累托最优分布。它适用于广泛的公平概念，包括精英统治和人口统计公平的经典概念。我们在 TREC2020和 MSLR 数据集上经验性地评估了我们的方法，并将其与几个基线在帕累托最优性和速度方面进行了比较。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto-Optimal+Fairness-Utility+Amortizations+in+Rankings+with+a+DBN+Exposure+Model)|0|
|[Risk-Sensitive Deep Neural Learning to Rank](https://doi.org/10.1145/3477495.3532056)|Pedro Henrique Silva Rodrigues, Daniel Xavier de Sousa, Thierson Couto Rosa, Marcos André Gonçalves|Federal Institute of Goiás - IFG, Anápolis, Brazil; Federal University of Minas Gerais - UFMG, Belo Horizonte, Brazil; Federal University of Goiás - UFG, Goiânia, Brazil|Learning to Rank (L2R) is the core task of many Information Retrieval systems. Recently, a great effort has been put on exploring Deep Neural Networks (DNNs) for L2R, with significant results. However, risk-sensitiveness, an important and recent advance in the L2R arena, that reduces variability and increases trust, has not been incorporated into Deep Neural L2R yet. Risk-sensitive measures are important to assess the risk of an IR system to perform worse than a set of baseline IR systems for several queries. However, the risk-sensitive measures described in the literature have a non-smooth behavior, making them difficult, if not impossible, to be optimized by DNNs. In this work we solve this difficult problem by proposing a family of new loss functions -- \riskloss\ -- that support a smooth risk-sensitive optimization. \riskloss\ introduces two important contributions: (i) the substitution of the traditional NDCG or MAP metrics in risk-sensitive measures with smooth loss functions that evaluate the correlation between the predicted and the true relevance order of documents for a given query and (ii) the use of distinct versions of the same DNN architecture as baselines by means of a multi-dropout technique during the smooth risk-sensitive optimization, avoiding the inconvenience of assessing multiple IR systems as part of DNN training. We empirically demonstrate significant achievements of the proposed \riskloss\ functions when used with recent DNN methods in the context of well-known web-search datasets such as WEB10K, YAHOO, and MQ2007. Our solutions reach improvements of 8% in effectiveness (NDCG) while improving in around 5% the risk-sensitiveness (\grisk\ measure) when applied together with a state-of-the-art Self-Attention DNN-L2R architecture. Furthermore, \riskloss\ is capable of reducing by 28% the losses over the best evaluated baselines and significantly improving over the risk-sensitive state-of-the-art non-DNN method (by up to 13.3%) while keeping (or even increasing) overall effectiveness. All these results ultimately establish a new level for the state-of-the-art on risk-sensitiveness and DNN-L2R research.|学习排名(L2R)是许多信息检索系统的核心任务。近年来，针对 L2R 的深层神经网络(DNN)的研究取得了显著的成果。然而，风险敏感性，一个重要的和最近在 L2R 领域的进展，减少变异性和增加信任，尚未被纳入深层神经 L2R。风险敏感度量对于评估一个 IR 系统在几个查询中的性能低于一组基准 IR 系统的风险非常重要。然而，文献中描述的风险敏感性措施有一个不平滑的行为，使他们难以，如果不是不可能，被 DNN 优化。在这项工作中，我们通过提出一系列新的损失函数——风险损失——来解决这个难题，这些函数支持平稳的风险敏感优化。风险损失引入了两个重要贡献: (i)用平滑损失函数替换风险敏感度量中的传统 NDCG 或 MAP 指标，评估给定查询的文档的预测和真实相关顺序之间的相关性; (ii)通过平滑风险敏感性优化期间的多退出技术使用相同 DNN 架构的不同版本作为基线，避免了评估多个 IR 系统作为 DNN 训练的一部分的不便。当与最近的 DNN 方法在诸如 WEB10K，YAHOO 和 MQ2007等著名的网络搜索数据集的背景下使用时，我们经验性地证明了所提出的风险损失函数的显着成就。我们的解决方案在与最先进的自我注意 DNN-L2R 架构一起应用时，有效性(NDCG)提高了8% ，而风险敏感性(风险测量)提高了约5% 。此外，风险损失能够比最佳评估基线减少28% 的损失，并且比风险敏感的最先进的非 DNN 方法(高达13.3%)显着改善，同时保持(甚至增加)总体有效性。所有这些结果最终为风险敏感性和 DNN-L2R 研究的最新水平奠定了一个新的基础。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Risk-Sensitive+Deep+Neural+Learning+to+Rank)|0|
|[Adaptable Text Matching via Meta-Weight Regulator](https://doi.org/10.1145/3477495.3531932)|Bo Zhang, Chen Zhang, Fang Ma, Dawei Song|Beijing Institute of Technology, Beijing, China|Neural text matching models have been used in a range of applications such as question answering and natural language inference, and have yielded a good performance. However, these neural models are of a limited adaptability, resulting in a decline in performance when encountering test examples from a different dataset or even a different task. The adaptability is particularly important in the few-shot setting: in many cases, there is only a limited amount of labeled data available for a target dataset or task, while we may have access to a richly labeled source dataset or task. However, adapting a model trained on the abundant source data to a few-shot target dataset or task is challenging. To tackle this challenge, we propose a Meta-Weight Regulator (MWR), which is a meta-learning approach that learns to assign weights to the source examples based on their relevance to the target loss. Specifically, MWR first trains the model on the uniformly weighted source examples, and measures the efficacy of the model on the target examples via a loss function. By iteratively performing a (meta) gradient descent, high-order gradients are propagated to the source examples. These gradients are then used to update the weights of source examples, in a way that is relevant to the target performance. As MWR is model-agnostic, it can be applied to any backbone neural model. Extensive experiments are conducted with various backbone text matching models, on four widely used datasets and two tasks. The results demonstrate that our proposed approach significantly outperforms a number of existing adaptation methods and effectively improves the cross-dataset and cross-task adaptability of the neural text matching models in the few-shot setting.|神经文本匹配模型已经在问答、自然语言推理等领域得到了广泛的应用，并取得了良好的效果。然而，这些神经模型的适应性有限，当遇到来自不同数据集甚至不同任务的测试例子时，会导致性能下降。适应性在少镜头设置中尤其重要: 在许多情况下，目标数据集或任务只有有限数量的标记数据可用，而我们可以访问标记丰富的源数据集或任务。然而，将一个基于大量源数据训练的模型应用于少量目标数据集或任务是具有挑战性的。为了应对这一挑战，我们提出了一种元权重调节器(MWR) ，它是一种元学习方法，学习根据源示例与目标损失的相关性为其分配权重。具体来说，MWR 首先在均匀加权的源例子上训练模型，然后通过损失函数来度量模型对目标例子的有效性。通过迭代执行一个(元)梯度下降法，高阶梯度被传播到源示例。然后使用这些渐变来更新源示例的权重，其方式与目标性能相关。由于 MWR 是模型无关的，因此它可以应用于任何骨干神经网络模型。在四个广泛使用的数据集和两个任务上，使用各种骨干文本匹配模型进行了广泛的实验。结果表明，本文提出的方法明显优于现有的一些自适应方法，有效地提高了神经元文本匹配模型在少镜头情况下的跨数据集和跨任务适应性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptable+Text+Matching+via+Meta-Weight+Regulator)|0|
|[Re-thinking Knowledge Graph Completion Evaluation from an Information Retrieval Perspective](https://doi.org/10.1145/3477495.3532052)|Ying Zhou, Xuanang Chen, Ben He, Zheng Ye, Le Sun|Institute of Software, Chinese Academy of Sciences, Beijing, China; South-Central University for Nationalities, Wuhan, China; University of Chinese Academy of Sciences & Institute of Software, Chinese Academy of Sciences, Beijing, China|Knowledge graph completion (KGC) aims to infer missing knowledge triples based on known facts in a knowledge graph. Current KGC research mostly follows an entity ranking protocol, wherein the effectiveness is measured by the predicted rank of a masked entity in a test triple. The overall performance is then given by a micro(-average) metric over all individual answer entities. Due to the incomplete nature of the large-scale knowledge bases, such an entity ranking setting is likely affected by unlabelled top-ranked positive examples, raising questions on whether the current evaluation protocol is sufficient to guarantee a fair comparison of KGC systems. To this end, this paper presents a systematic study on whether and how the label sparsity affects the current KGC evaluation with the popular micro metrics. Specifically, inspired by the TREC paradigm for large-scale information retrieval (IR) experimentation, we create a relatively "complete" judgment set based on a sample from the popular FB15k-237 dataset following the TREC pooling method. According to our analysis, it comes as a surprise that switching from the original labels to our "complete" labels results in a drastic change of system ranking of a variety of 13 popular KGC models in terms of micro metrics. Further investigation indicates that the IR-like macro(-average) metrics are more stable and discriminative under different settings, meanwhile, less affected by label sparsity. Thus, for KGC evaluation, we recommend conducting TREC-style pooling to balance between human efforts and label completeness, and reporting also the IR-like macro metrics to reflect the ranking nature of the KGC task.|知识图完成(KGC)是基于知识图中已知事实推断出缺失的知识三元组。目前的 KGC 研究大多遵循一个实体排名协议，其中的有效性是衡量一个被掩盖的实体在一个测试三元组的预测排名。然后，通过对所有单个答案实体的微观(平均)度量给出总体表现。由于大规模知识库的不完整性，这种实体排名设置可能会受到没有标记的排名最高的积极实例的影响，从而引起目前的评价议定书是否足以保证公平比较 KGC 系统的问题。为此，本文利用当前流行的微观指标，对标签稀疏性是否以及如何影响当前 KGC 评价进行了系统的研究。具体来说，受到 TREC 大规模信息检索(IR)实验范例的启发，我们创建了一个相对“完整”的判断集，该判断集基于流行的 FB15k-237数据集的样本，采用 TREC 汇集方法。根据我们的分析，令人惊讶的是，从原始标签切换到我们的“完整”标签导致系统排名的急剧变化的各种13个流行的 KGC 模型在微观指标方面。进一步的研究表明，类 IR 宏(平均)指标在不同的设置下更加稳定和具有区分性，同时受标签稀疏性的影响较小。因此，对于 KGC 评估，我们建议进行 TREC 风格的池来平衡人工努力和标签完整性，并报告类似 IR 的宏指标来反映 KGC 任务的排名性质。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Re-thinking+Knowledge+Graph+Completion+Evaluation+from+an+Information+Retrieval+Perspective)|0|
|[CRET: Cross-Modal Retrieval Transformer for Efficient Text-Video Retrieval](https://doi.org/10.1145/3477495.3531960)|Kaixiang Ji, Jiajia Liu, Weixiang Hong, Liheng Zhong, Jian Wang, Jingdong Chen, Wei Chu|Ant Group, Hangzhou, China|Given a text query, the text-to-video retrieval task aims to find the relevant videos in the database. Recently, model-based (MDB) methods have demonstrated superior accuracy than embedding-based (EDB) methods due to their excellent capacity of modeling local video/text correspondences, especially when equipped with large-scale pre-training schemes like ClipBERT. Generally speaking, MDB methods take a text-video pair as input and harness deep models to predict the mutual similarity, while EDB methods first utilize modality-specific encoders to extract embeddings for text and video, then evaluate the distance based on the extracted embeddings. Notably, MDB methods cannot produce explicit representations for text and video, instead, they have to exhaustively pair the query with every database item to predict their mutual similarities in the inference stage, which results in significant inefficiency in practical applications. In this work, we propose a novel EDB method CRET (Cross-modal REtrieval Transformer), which not only demonstrates promising efficiency in retrieval tasks, but also achieves better accuracy than existing MDB methods. The credits are mainly attributed to our proposed Cross-modal Correspondence Modeling (CCM) module and Gaussian Estimation of Embedding Space (GEES) loss. Specifically, the CCM module is composed by transformer decoders and a set of decoder centers. With the help of the learned decoder centers, the text/video embeddings can be efficiently aligned, without suffering from pairwise model-based inference. Moreover, to balance the information loss and computational overhead when sampling frames from a given video, we present a novel GEES loss, which implicitly conducts dense sampling in the video embedding space, without suffering from heavy computational cost. Extensive experiments show that without pre-training on extra datasets, our proposed CRET outperforms the state-of-the-art MDB methods that were pre-trained on additional datasets, meanwhile still shows promising efficiency in retrieval tasks.|给定一个文本查询，文本到视频检索任务的目的是在数据库中找到相关的视频。近年来，基于模型(MDB)的方法由于其优异的局部视频/文本对应建模能力而显示出优于基于嵌入的方法的准确性，特别是当配备了大规模的预训练方案，如 ClipBERT。一般来说，MDB 方法以文本-视频对为输入，利用深度模型来预测相似度，而 EDB 方法首先利用特定于模态的编码器来提取文本和视频的嵌入，然后根据提取的嵌入来评估距离。值得注意的是，MDB 方法不能生成文本和视频的显式表示，相反，它们必须将查询与每个数据库项穷举地配对，以预测它们在推理阶段的相似性，这导致了实际应用中的显著效率低下。本文提出了一种新的多模态检索转换器(CRET)方法，该方法不仅在检索任务中表现出良好的效率，而且比现有的 MDB 方法具有更高的准确率。这主要归功于我们提出的交叉模态对应建模(CCM)模块和嵌入空间的高斯估计(GEES)损失。具体来说，CCM 模块由变压器解码器和一组解码中心组成。借助于所学习的解码中心，文本/视频嵌入可以有效地对齐，而不会受到基于成对模型的推理的影响。此外，为了平衡从给定视频帧采样时的信息损失和计算开销，我们提出了一种新的 GEES 损失算法，该算法在视频嵌入空间中隐式地进行密集采样，不需要承担大量的计算开销。大量的实验表明，在不对额外数据集进行预训练的情况下，我们提出的 CRET 方法优于对额外数据集进行预训练的最先进的 MDB 方法，同时在检索任务中仍然显示出有希望的效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CRET:+Cross-Modal+Retrieval+Transformer+for+Efficient+Text-Video+Retrieval)|0|
|[Learn from Unlabeled Videos for Near-duplicate Video Retrieval](https://doi.org/10.1145/3477495.3532010)|Xiangteng He, Yulin Pan, Mingqian Tang, Yiliang Lv, Yuxin Peng|Alibaba Group, Hangzhou, China; Peking University, Beijing, China|Near-duplicate video retrieval (NDVR) aims to find the copies or transformations of the query video from a massive video database. It plays an important role in many video related applications, including copyright protection, tracing, filtering and etc. Video representation and similarity search are crucial to any video retrieval system. To derive effective video representation, most video retrieval systems require a large amount of manually annotated data for training, making it costly inefficient. In addition, most retrieval systems are based on frame-level features for video similarity searching, making it expensive both storage wise and search wise. To address the above issues, we propose a video representation learning (VRL) approach to effectively address the above shortcomings. It first effectively learns video representation from unlabeled videos via contrastive learning to avoid the expensive cost of manual annotation. Then, it exploits transformer structure to aggregate frame-level features into clip-level to reduce both storage space and search complexity. It can learn the complementary and discriminative information from the interactions among clip frames, as well as acquire the frame permutation and missing invariant ability to support more flexible retrieval manners. Comprehensive experiments on two challenging near-duplicate video retrieval datasets, namely FIVR-200K and SVD, verify the effectiveness of our proposed VRL approach, which achieves the best performance of video retrieval on accuracy and efficiency.|近重复视频检索(NDVR)的目标是从海量视频数据库中查找查询视频的副本或变换。它在许多视频相关应用中起着重要作用，包括版权保护、跟踪、过滤等。视频表示和最近邻搜索对于任何视频检索系统都至关重要。为了获得有效的视频表示，大多数视频检索系统需要大量的人工注释数据进行训练，这使得系统效率低下。此外，大多数检索系统基于帧级特征进行视频相似性搜索，这使得存储和搜索成本都很高。针对上述问题，本文提出了一种视频表示学习(VRL)方法，有效地解决了上述问题。它首先通过对比学习有效地从未标记的视频中学习视频表示，从而避免了人工标注的昂贵成本。然后，利用变压器结构将帧级特征聚合为剪辑级特征，降低存储空间和搜索复杂度。它可以从剪辑帧之间的交互中学习互补信息和鉴别信息，获得帧排列和缺失不变量能力，支持更灵活的检索方式。通过对 FIVR-200K 和 SVD 两个具有挑战性的近重复视频检索数据集的综合实验，验证了本文提出的 VRL 方法的有效性，在准确性和效率方面达到了最佳的视频检索性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learn+from+Unlabeled+Videos+for+Near-duplicate+Video+Retrieval)|0|
|[Progressive Learning for Image Retrieval with Hybrid-Modality Queries](https://doi.org/10.1145/3477495.3532047)|Yida Zhao, Yuqing Song, Qin Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Learning+for+Image+Retrieval+with+Hybrid-Modality+Queries)|0|
|[Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking](https://doi.org/10.1145/3477495.3531997)|Qian Dong, Yiding Liu, Suqi Cheng, Shuaiqiang Wang, Zhicong Cheng, Shuzi Niu, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Explicit+Knowledge+in+Pre-trained+Language+Models+for+Passage+Re-ranking)|0|
|[Axiomatically Regularized Pre-training for Ad hoc Search](https://doi.org/10.1145/3477495.3531943)|Jia Chen, Yiqun Liu, Yan Fang, Jiaxin Mao, Hui Fang, Shenghao Yang, Xiaohui Xie, Min Zhang, Shaoping Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Axiomatically+Regularized+Pre-training+for+Ad+hoc+Search)|0|
|[On the Role of Relevance in Natural Language Processing Tasks](https://doi.org/10.1145/3477495.3532034)|Artsiom Sauchuk, James Thorne, Alon Y. Halevy, Nicola Tonellotto, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Role+of+Relevance+in+Natural+Language+Processing+Tasks)|0|
|[Adversarial Graph Perturbations for Recommendations at Scale](https://doi.org/10.1145/3477495.3531763)|Huiyuan Chen, Kaixiong Zhou, KweiHerng Lai, Xia Hu, Fei Wang, Hao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Graph+Perturbations+for+Recommendations+at+Scale)|0|
|[Relevance under the Iceberg: Reasonable Prediction for Extreme Multi-label Classification](https://doi.org/10.1145/3477495.3531767)|JyunYu Jiang, WeiCheng Chang, Jiong Zhang, ChoJui Hsieh, HsiangFu Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevance+under+the+Iceberg:+Reasonable+Prediction+for+Extreme+Multi-label+Classification)|0|
|[Gating-adapted Wavelet Multiresolution Analysis for Exposure Sequence Modeling in CTR Prediction](https://doi.org/10.1145/3477495.3531771)|Xiaoxiao Xu, Zhiwei Fang, Qian Yu, Ruoran Huang, Chaosheng Fan, Yong Li, Yang He, Changping Peng, Zhangang Lin, Jingping Shao, Non Non||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gating-adapted+Wavelet+Multiresolution+Analysis+for+Exposure+Sequence+Modeling+in+CTR+Prediction)|0|
|[Animating Images to Transfer CLIP for Video-Text Retrieval](https://doi.org/10.1145/3477495.3531776)|Yu Liu, Huai Chen, Lianghua Huang, Di Chen, Bin Wang, Pan Pan, Lisheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Animating+Images+to+Transfer+CLIP+for+Video-Text+Retrieval)|0|
|[Image-Text Retrieval via Contrastive Learning with Auxiliary Generative Features and Support-set Regularization](https://doi.org/10.1145/3477495.3531783)|Lei Zhang, Min Yang, Chengming Li, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Image-Text+Retrieval+via+Contrastive+Learning+with+Auxiliary+Generative+Features+and+Support-set+Regularization)|0|
|[Denoising Time Cycle Modeling for Recommendation](https://doi.org/10.1145/3477495.3531785)|Sicong Xie, Qunwei Li, Weidi Xu, Kaiming Shen, Shaohu Chen, Wenliang Zhong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Denoising+Time+Cycle+Modeling+for+Recommendation)|0|
|[Value Penalized Q-Learning for Recommender Systems](https://doi.org/10.1145/3477495.3531796)|Chengqian Gao, Ke Xu, Kuangqi Zhou, Lanqing Li, Xueqian Wang, Bo Yuan, Peilin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Value+Penalized+Q-Learning+for+Recommender+Systems)|0|
|[From Cluster Ranking to Document Ranking](https://doi.org/10.1145/3477495.3531819)|Egor Markovskiy, Fiana Raiber, Shoham Sabach, Oren Kurland||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Cluster+Ranking+to+Document+Ranking)|0|
|[ILMART: Interpretable Ranking with Constrained LambdaMART](https://doi.org/10.1145/3477495.3531840)|Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Alberto Veneri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ILMART:+Interpretable+Ranking+with+Constrained+LambdaMART)|0|
|[On Extractive Summarization for Profile-centric Neural Expert Search in Academia](https://doi.org/10.1145/3477495.3531713)|Rennan C. Lima, Rodrygo L. T. Santos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Extractive+Summarization+for+Profile-centric+Neural+Expert+Search+in+Academia)|0|
|[Joint Optimization of Ad Ranking and Creative Selection](https://doi.org/10.1145/3477495.3531855)|Kaiyi Lin, Xiang Zhang, Feng Li, Pengjie Wang, Qingqing Long, Hongbo Deng, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Optimization+of+Ad+Ranking+and+Creative+Selection)|0|
|[Long Document Re-ranking with Modular Re-ranker](https://doi.org/10.1145/3477495.3531860)|Luyu Gao, Jamie Callan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long+Document+Re-ranking+with+Modular+Re-ranker)|0|
|[Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning](https://doi.org/10.1145/3477495.3531746)|Xiang Chen, Lei Li, Ningyu Zhang, Chuanqi Tan, Fei Huang, Luo Si, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relation+Extraction+as+Open-book+Examination:+Retrieval-enhanced+Prompt+Tuning)|0|
|[End-to-end Distantly Supervised Information Extraction with Retrieval Augmentation](https://doi.org/10.1145/3477495.3531876)|Yue Zhang, Hongliang Fei, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-end+Distantly+Supervised+Information+Extraction+with+Retrieval+Augmentation)|0|
|[Assessing Scientific Research Papers with Knowledge Graphs](https://doi.org/10.1145/3477495.3531879)|Kexuan Sun, Zhiqiang Qiu, Abel Salinas, Yuzhong Huang, DongHo Lee, Daniel Benjamin, Fred Morstatter, Xiang Ren, Kristina Lerman, Jay Pujara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Scientific+Research+Papers+with+Knowledge+Graphs)|0|
|[A Content Recommendation Policy for Gaining Subscribers](https://doi.org/10.1145/3477495.3531885)|Konstantinos Theocharidis, Manolis Terrovitis, Spiros Skiadopoulos, Panagiotis Karras||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Content+Recommendation+Policy+for+Gaining+Subscribers)|0|
|[MM-Rec: Visiolinguistic Model Empowered Multimodal News Recommendation](https://doi.org/10.1145/3477495.3531896)|Chuhan Wu, Fangzhao Wu, Tao Qi, Chao Zhang, Yongfeng Huang, Tong Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MM-Rec:+Visiolinguistic+Model+Empowered+Multimodal+News+Recommendation)|0|
|[Towards Personalized Bundle Creative Generation with Contrastive Non-Autoregressive Decoding](https://doi.org/10.1145/3477495.3531909)|Penghui Wei, Shaoguo Liu, Xuanhua Yang, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Personalized+Bundle+Creative+Generation+with+Contrastive+Non-Autoregressive+Decoding)|0|
|[Another Look at Information Retrieval as Statistical Translation](https://doi.org/10.1145/3477495.3531717)|Yuqi Liu, Chengcheng Hu, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Another+Look+at+Information+Retrieval+as+Statistical+Translation)|0|
|[ACORDAR: A Test Collection for Ad Hoc Content-Based (RDF) Dataset Retrieval](https://doi.org/10.1145/3477495.3531729)|Tengteng Lin, Qiaosheng Chen, Gong Cheng, Ahmet Soylu, Basil Ell, Ruoqi Zhao, Qing Shi, Xiaxia Wang, Yu Gu, Evgeny Kharlamov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACORDAR:+A+Test+Collection+for+Ad+Hoc+Content-Based+(RDF)+Dataset+Retrieval)|0|
|[RELISON: A Framework for Link Recommendation in Social Networks](https://doi.org/10.1145/3477495.3531730)|Javier SanzCruzado, Pablo Castells||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RELISON:+A+Framework+for+Link+Recommendation+in+Social+Networks)|0|
|[The Istella22 Dataset: Bridging Traditional and Neural Learning to Rank Evaluation](https://doi.org/10.1145/3477495.3531740)|Domenico Dato, Sean MacAvaney, Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Istella22+Dataset:+Bridging+Traditional+and+Neural+Learning+to+Rank+Evaluation)|0|
|[Axiomatic Retrieval Experimentation with ir_axioms](https://doi.org/10.1145/3477495.3531743)|Alexander Bondarenko, Maik Fröbe, Jan Heinrich Reimer, Benno Stein, Michael Völske, Matthias Hagen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Axiomatic+Retrieval+Experimentation+with+ir_axioms)|0|
|[Knowledge Graph Question Answering Datasets and Their Generalizability: Are They Enough for Future Research?](https://doi.org/10.1145/3477495.3531751)|Longquan Jiang, Ricardo Usbeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Question+Answering+Datasets+and+Their+Generalizability:+Are+They+Enough+for+Future+Research?)|0|
|[Golden Retriever: A Real-Time Multi-Modal Text-Image Retrieval System with the Ability to Focus](https://doi.org/10.1145/3477495.3531666)|Florian Schneider, Chris Biemann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Golden+Retriever:+A+Real-Time+Multi-Modal+Text-Image+Retrieval+System+with+the+Ability+to+Focus)|0|
|[ZeroMatcher: A Cost-Off Entity Matching System](https://doi.org/10.1145/3477495.3531661)|Congcong Ge, Xiaocan Zeng, Lu Chen, Yunjun Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ZeroMatcher:+A+Cost-Off+Entity+Matching+System)|0|
|[QFinder: A Framework for Quantity-centric Ranking](https://doi.org/10.1145/3477495.3531672)|Satya Almasian, Milena Bruseva, Michael Gertz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QFinder:+A+Framework+for+Quantity-centric+Ranking)|0|
|[CHERCHE: A New Tool to Rapidly Implement Pipelines in Information Retrieval](https://doi.org/10.1145/3477495.3531695)|Raphaël Sourty, José G. Moreno, Lynda Tamine, FrançoisPaul Servant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CHERCHE:+A+New+Tool+to+Rapidly+Implement+Pipelines+in+Information+Retrieval)|0|
|[Arm: Efficient Learning of Neural Retrieval Models with Desired Accuracy by Automatic Knowledge Amalgamation](https://doi.org/10.1145/3477495.3531664)|Linzhu Yu, Dawei Jiang, Ke Chen, Lidan Shou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Arm:+Efficient+Learning+of+Neural+Retrieval+Models+with+Desired+Accuracy+by+Automatic+Knowledge+Amalgamation)|0|
|[An Auto Encoder-based Dimensionality Reduction Technique for Efficient Entity Linking in Business Phone Conversations](https://doi.org/10.1145/3477495.3536322)|Md. Tahmid Rahman Laskar, Cheng Chen, Jonathan Johnston, XueYong Fu, Shashi Bhushan TN, Simon CorstonOliver||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Auto+Encoder-based+Dimensionality+Reduction+Technique+for+Efficient+Entity+Linking+in+Business+Phone+Conversations)|0|
|[Applications and Future of Dense Retrieval in Industry](https://doi.org/10.1145/3477495.3536324)|Yubin Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Applications+and+Future+of+Dense+Retrieval+in+Industry)|0|
|[Flipping the Script: Inverse Information Seeking Dialogues for Market Research](https://doi.org/10.1145/3477495.3536326)|Josh Seltzer, Kathy Cheng, Shi Zong, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flipping+the+Script:+Inverse+Information+Seeking+Dialogues+for+Market+Research)|0|
|[Information Ecosystem Threats in Minoritized Communities: Challenges, Open Problems and Research Directions](https://doi.org/10.1145/3477495.3536327)|Shiri DoriHacohen, Scott A. Hale||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Ecosystem+Threats+in+Minoritized+Communities:+Challenges,+Open+Problems+and+Research+Directions)|0|
|[Extractive Search for Analysis of Biomedical Texts](https://doi.org/10.1145/3477495.3536328)|Daniel Clothiaux, Ravi Starzl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extractive+Search+for+Analysis+of+Biomedical+Texts)|0|
|[Recent Advances in Retrieval-Augmented Text Generation](https://doi.org/10.1145/3477495.3532682)|Deng Cai, Yan Wang, Lemao Liu, Shuming Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recent+Advances+in+Retrieval-Augmented+Text+Generation)|0|
|[Adaptive Dialogue Management for Conversational Information Elicitation](https://doi.org/10.1145/3477495.3531684)|Harshita Sahijwani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Dialogue+Management+for+Conversational+Information+Elicitation)|0|
|[Pre-Training for Mathematics-Aware Retrieval](https://doi.org/10.1145/3477495.3531680)|Anja Reusch||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-Training+for+Mathematics-Aware+Retrieval)|0|
|[Explainable Conversational Question Answering over Heterogeneous Sources](https://doi.org/10.1145/3477495.3531688)|Philipp Christmann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Conversational+Question+Answering+over+Heterogeneous+Sources)|0|
|[KA-Recsys: Patient Focused Knowledge Appropriate Health Recommender System](https://doi.org/10.1145/3477495.3531687)|Khushboo Thaker||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KA-Recsys:+Patient+Focused+Knowledge+Appropriate+Health+Recommender+System)|0|
|[Bilateral Self-unbiased Learning from Biased Implicit Feedback](https://doi.org/10.1145/3477495.3531946)|Jaewoong Lee, Seongmin Park, Joonseok Lee, Jongwuk Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bilateral+Self-unbiased+Learning+from+Biased+Implicit+Feedback)|0|
|[Why do Semantically Unrelated Categories Appear in the Same Session?: A Demand-aware Method](https://doi.org/10.1145/3477495.3531806)|Liqi Yang, Linhao Luo, Xiaofeng Zhang, Fengxin Li, Xinni Zhang, Zelin Jiang, Shuai Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+do+Semantically+Unrelated+Categories+Appear+in+the+Same+Session?:+A+Demand-aware+Method)|0|
|[Scalable User Interface Optimization Using Combinatorial Bandits](https://doi.org/10.1145/3477495.3536325)|Ioannis Kangas, Maud Schwoerer, Lucas Bernardi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+User+Interface+Optimization+Using+Combinatorial+Bandits)|0|
|[Users: Can't Work With Them, Can't Work Without Them?](https://doi.org/10.1145/3477495.3532787)|Alistair Moffat||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Users:+Can't+Work+With+Them,+Can't+Work+Without+Them?)|0|
|[Interacting with Non-Cooperative User: A New Paradigm for Proactive Dialogue Policy](https://doi.org/10.1145/3477495.3532001)|Wenqiang Lei, Yao Zhang, Feifan Song, Hongru Liang, Jiaxin Mao, Jiancheng Lv, Zhenglu Yang, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interacting+with+Non-Cooperative+User:+A+New+Paradigm+for+Proactive+Dialogue+Policy)|0|
|[ADPL: Adversarial Prompt-based Domain Adaptation for Dialogue Summarization with Knowledge Disentanglement](https://doi.org/10.1145/3477495.3531933)|Lulu Zhao, Fujia Zheng, Weihao Zeng, Keqing He, Ruotong Geng, Huixing Jiang, Wei Wu, Weiran Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ADPL:+Adversarial+Prompt-based+Domain+Adaptation+for+Dialogue+Summarization+with+Knowledge+Disentanglement)|0|
|[IR Evaluation and Learning in the Presence of Forbidden Documents](https://doi.org/10.1145/3477495.3532006)|David Carmel, Nachshon Cohen, Amir Ingber, Elad Kravi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IR+Evaluation+and+Learning+in+the+Presence+of+Forbidden+Documents)|0|
|[Human Preferences as Dueling Bandits](https://doi.org/10.1145/3477495.3531991)|Xinyi Yan, Chengxi Luo, Charles L. A. Clarke, Nick Craswell, Ellen M. Voorhees, Pablo Castells||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human+Preferences+as+Dueling+Bandits)|0|
|[IAOTP: An Interactive End-to-End Solution for Aspect-Opinion Term Pairs Extraction](https://doi.org/10.1145/3477495.3532085)|Ambreen Nazir, Yuan Rao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IAOTP:+An+Interactive+End-to-End+Solution+for+Aspect-Opinion+Term+Pairs+Extraction)|0|
|[Exploring Heterogeneous Data Lake based on Unified Canonical Graphs](https://doi.org/10.1145/3477495.3531759)|Qin Yuan, Ye Yuan, Zhenyu Wen, He Wang, Chen Chen, Guoren Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Heterogeneous+Data+Lake+based+on+Unified+Canonical+Graphs)|0|
|[Distilling Knowledge on Text Graph for Social Media Attribute Inference](https://doi.org/10.1145/3477495.3531968)|Quan Li, Xiaoting Li, Lingwei Chen, Dinghao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Knowledge+on+Text+Graph+for+Social+Media+Attribute+Inference)|0|
|[A Simple Meta-learning Paradigm for Zero-shot Intent Classification with Mixture Attention Mechanism](https://doi.org/10.1145/3477495.3531803)|Han Liu, Siyang Zhao, Xiaotong Zhang, Feng Zhang, Junjie Sun, Hong Yu, Xianchao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Simple+Meta-learning+Paradigm+for+Zero-shot+Intent+Classification+with+Mixture+Attention+Mechanism)|0|
|[Analyzing the Support Level for Tips Extracted from Product Reviews](https://doi.org/10.1145/3477495.3531805)|Miriam Farber, David Carmel, Lital Kuchy, Avihai Mejer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+the+Support+Level+for+Tips+Extracted+from+Product+Reviews)|0|
|[UserBERT: Pre-training User Model with Contrastive Self-supervision](https://doi.org/10.1145/3477495.3531810)|Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UserBERT:+Pre-training+User+Model+with+Contrastive+Self-supervision)|0|
|[Modern Baselines for SPARQL Semantic Parsing](https://doi.org/10.1145/3477495.3531841)|Debayan Banerjee, Pranav Ajit Nair, Jivat Neet Kaur, Ricardo Usbeck, Chris Biemann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modern+Baselines+for+SPARQL+Semantic+Parsing)|0|
|[Posterior Probability Matters: Doubly-Adaptive Calibration for Neural Predictions in Online Advertising](https://doi.org/10.1145/3477495.3531911)|Penghui Wei, Weimin Zhang, Ruijie Hou, Jinquan Liu, Shaoguo Liu, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Posterior+Probability+Matters:+Doubly-Adaptive+Calibration+for+Neural+Predictions+in+Online+Advertising)|0|
|[Table Enrichment System for Machine Learning](https://doi.org/10.1145/3477495.3531678)|Yuyang Dong, Masafumi Oyamada||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Table+Enrichment+System+for+Machine+Learning)|0|
|[LawNet-Viz: A Web-based System to Visually Explore Networks of Law Article References](https://doi.org/10.1145/3477495.3531668)|Lucio La Cava, Andrea Simeri, Andrea Tagarelli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LawNet-Viz:+A+Web-based+System+to+Visually+Explore+Networks+of+Law+Article+References)|0|
|[Quote Erat Demonstrandum: A Web Interface for Exploring the Quotebank Corpus](https://doi.org/10.1145/3477495.3531696)|Vuk Vukovic, Akhil Arora, HuanCheng Chang, Andreas Spitz, Robert West||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quote+Erat+Demonstrandum:+A+Web+Interface+for+Exploring+the+Quotebank+Corpus)|0|
|[Unsupervised Product Offering Title Quality Scores](https://doi.org/10.1145/3477495.3536333)|Henry S. Vieira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Product+Offering+Title+Quality+Scores)|0|
|[Few-shot Information Extraction is Here: Pre-train, Prompt and Entail](https://doi.org/10.1145/3477495.3532786)|Eneko Agirre||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+Information+Extraction+is+Here:+Pre-train,+Prompt+and+Entail)|0|
|[Improving Implicit Alternating Least Squares with Ring-based Regularization](https://doi.org/10.1145/3477495.3531995)|Rui Fan, Jin Chen, Jin Zhang, Defu Lian, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Implicit+Alternating+Least+Squares+with+Ring-based+Regularization)|0|
|[Target-aware Abstractive Related Work Generation with Contrastive Learning](https://doi.org/10.1145/3477495.3532065)|Xiuying Chen, Hind Alamro, Mingzhe Li, Shen Gao, Rui Yan, Xin Gao, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Target-aware+Abstractive+Related+Work+Generation+with+Contrastive+Learning)|0|
|[Information Need Awareness: An EEG Study](https://doi.org/10.1145/3477495.3531999)|Dominika Michalkova, Mario ParraRodriguez, Yashar Moshfeghi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Need+Awareness:+An+EEG+Study)|0|
|[Unifying Cross-lingual Summarization and Machine Translation with Compression Rate](https://doi.org/10.1145/3477495.3532071)|Yu Bai, Heyan Huang, Kai Fan, Yang Gao, Yiming Zhu, Jiaao Zhan, Zewen Chi, Boxing Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+Cross-lingual+Summarization+and+Machine+Translation+with+Compression+Rate)|0|
|[What Makes the Story Forward?: Inferring Commonsense Explanations as Prompts for Future Event Generation](https://doi.org/10.1145/3477495.3532080)|Li Lin, Yixin Cao, Lifu Huang, Shuang Li, Xuming Hu, Lijie Wen, Jianmin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+Makes+the+Story+Forward?:+Inferring+Commonsense+Explanations+as+Prompts+for+Future+Event+Generation)|0|
|[A Dual-Expert Framework for Event Argument Extraction](https://doi.org/10.1145/3477495.3531923)|Rui Li, Wenlin Zhao, Cheng Yang, Sen Su||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dual-Expert+Framework+for+Event+Argument+Extraction)|0|
|[CorED: Incorporating Type-level and Instance-level Correlations for Fine-grained Event Detection](https://doi.org/10.1145/3477495.3531956)|Jiawei Sheng, Rui Sun, Shu Guo, Shiyao Cui, Jiangxia Cao, Lihong Wang, Tingwen Liu, Hongbo Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CorED:+Incorporating+Type-level+and+Instance-level+Correlations+for+Fine-grained+Event+Detection)|0|
|[QUASER: Question Answering with Scalable Extractive Rationalization](https://doi.org/10.1145/3477495.3532049)|Asish Ghoshal, Srinivasan Iyer, Bhargavi Paranjape, Kushal Lakhotia, Scott Wentau Yih, Yashar Mehdad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QUASER:+Question+Answering+with+Scalable+Extractive+Rationalization)|0|
|[PTAU: Prompt Tuning for Attributing Unanswerable Questions](https://doi.org/10.1145/3477495.3532048)|Jinzhi Liao, Xiang Zhao, Jianming Zheng, Xinyi Li, Fei Cai, Jiuyang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PTAU:+Prompt+Tuning+for+Attributing+Unanswerable+Questions)|0|
|[DGQAN: Dual Graph Question-Answer Attention Networks for Answer Selection](https://doi.org/10.1145/3477495.3532084)|Haitian Yang, Xuan Zhao, Yan Wang, Min Li, Wei Chen, Weiqing Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DGQAN:+Dual+Graph+Question-Answer+Attention+Networks+for+Answer+Selection)|0|
|[Towards Event-level Causal Relation Identification](https://doi.org/10.1145/3477495.3531758)|Chuang Fan, Daoxing Liu, Libo Qin, Yue Zhang, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Event-level+Causal+Relation+Identification)|0|
|[Hierarchical Task-aware Multi-Head Attention Network](https://doi.org/10.1145/3477495.3531781)|Jing Du, Lina Yao, Xianzhi Wang, Bin Guo, Zhiwen Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Task-aware+Multi-Head+Attention+Network)|0|
|[Enhancing Event-Level Sentiment Analysis with Structured Arguments](https://doi.org/10.1145/3477495.3531784)|Qi Zhang, Jie Zhou, Qin Chen, Qingchun Bai, Liang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Event-Level+Sentiment+Analysis+with+Structured+Arguments)|0|
|[Translation-Based Implicit Annotation Projection for Zero-Shot Cross-Lingual Event Argument Extraction](https://doi.org/10.1145/3477495.3531808)|Chenwei Lou, Jun Gao, Changlong Yu, Wei Wang, Huan Zhao, Weiwei Tu, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Translation-Based+Implicit+Annotation+Projection+for+Zero-Shot+Cross-Lingual+Event+Argument+Extraction)|0|
|[Understanding Long Programming Languages with Structure-Aware Sparse Attention](https://doi.org/10.1145/3477495.3531811)|Tingting Liu, Chengyu Wang, Cen Chen, Ming Gao, Aoying Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+Long+Programming+Languages+with+Structure-Aware+Sparse+Attention)|0|
|[Dialogue Topic Segmentation via Parallel Extraction Network with Neighbor Smoothing](https://doi.org/10.1145/3477495.3531817)|Jinxiong Xia, Cao Liu, Jiansong Chen, Yuchen Li, Fan Yang, Xunliang Cai, Guanglu Wan, Houfeng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dialogue+Topic+Segmentation+via+Parallel+Extraction+Network+with+Neighbor+Smoothing)|0|
|[Expression Syntax Information Bottleneck for Math Word Problems](https://doi.org/10.1145/3477495.3531824)|Jing Xiong, Chengming Li, Min Yang, Xiping Hu, Bin Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expression+Syntax+Information+Bottleneck+for+Math+Word+Problems)|0|
|[Masking and Generation: An Unsupervised Method for Sarcasm Detection](https://doi.org/10.1145/3477495.3531825)|Rui Wang, Qianlong Wang, Bin Liang, Yi Chen, Zhiyuan Wen, Bing Qin, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Masking+and+Generation:+An+Unsupervised+Method+for+Sarcasm+Detection)|0|
|[Learned Token Pruning in Contextualized Late Interaction over BERT (ColBERT)](https://doi.org/10.1145/3477495.3531835)|Carlos Lassance, Maroua Maachou, Joohee Park, Stéphane Clinchant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learned+Token+Pruning+in+Contextualized+Late+Interaction+over+BERT+(ColBERT))|0|
|[GraFN: Semi-Supervised Node Classification on Graph with Few Labels via Non-Parametric Distribution Assignment](https://doi.org/10.1145/3477495.3531838)|Junseok Lee, Yunhak Oh, Yeonjun In, Namkyeong Lee, Dongmin Hyun, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraFN:+Semi-Supervised+Node+Classification+on+Graph+with+Few+Labels+via+Non-Parametric+Distribution+Assignment)|0|
|[Which Discriminator for Cooperative Text Generation?](https://doi.org/10.1145/3477495.3531858)|Antoine Chaffin, Thomas Scialom, Sylvain Lamprier, Jacopo Staiano, Benjamin Piwowarski, Ewa Kijak, Vincent Claveau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Which+Discriminator+for+Cooperative+Text+Generation?)|0|
|[Topological Analysis of Contradictions in Text](https://doi.org/10.1145/3477495.3531881)|Xiangcheng Wu, Xi Niu, Ruhani Rahman||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topological+Analysis+of+Contradictions+in+Text)|0|
|[Dual Pseudo Supervision for Semi-Supervised Text Classification with a Reliable Teacher](https://doi.org/10.1145/3477495.3531887)|Shujie Li, Min Yang, Chengming Li, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Pseudo+Supervision+for+Semi-Supervised+Text+Classification+with+a+Reliable+Teacher)|0|
|[An Efficient Fusion Mechanism for Multimodal Low-resource Setting](https://doi.org/10.1145/3477495.3531900)|Dushyant Singh Chauhan, Asif Ekbal, Pushpak Bhattacharyya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Fusion+Mechanism+for+Multimodal+Low-resource+Setting)|0|
|[PST: Measuring Skill Proficiency in Programming Exercise Process via Programming Skill Tracing](https://doi.org/10.1145/3477495.3531903)|Ruixin Li, Yu Yin, Le Dai, Shuanghong Shen, Xin Lin, Yu Su, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PST:+Measuring+Skill+Proficiency+in+Programming+Exercise+Process+via+Programming+Skill+Tracing)|0|
|[MuchSUM: Multi-channel Graph Neural Network for Extractive Summarization](https://doi.org/10.1145/3477495.3531906)|Qianren Mao, Hongdong Zhu, Junnan Liu, Cheng Ji, Hao Peng, Jianxin Li, Lihong Wang, Zheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MuchSUM:+Multi-channel+Graph+Neural+Network+for+Extractive+Summarization)|0|
|[Multi-label Masked Language Modeling on Zero-shot Code-switched Sentiment Analysis](https://doi.org/10.1145/3477495.3531914)|Zhi Li, Xing Gao, Ji Zhang, Yin Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-label+Masked+Language+Modeling+on+Zero-shot+Code-switched+Sentiment+Analysis)|0|
|[Extractive Elementary Discourse Units for Improving Abstractive Summarization](https://doi.org/10.1145/3477495.3531916)|Ye Xiong, Teeradaj Racharak, Minh Le Nguyen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extractive+Elementary+Discourse+Units+for+Improving+Abstractive+Summarization)|0|
|[LightSGCN: Powering Signed Graph Convolution Network for Link Sign Prediction with Simplified Architecture Design](https://doi.org/10.1145/3477495.3531917)|Haoxin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LightSGCN:+Powering+Signed+Graph+Convolution+Network+for+Link+Sign+Prediction+with+Simplified+Architecture+Design)|0|
|[ir_metadata: An Extensible Metadata Schema for IR Experiments](https://doi.org/10.1145/3477495.3531738)|Timo Breuer, Jüri Keller, Philipp Schaer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ir_metadata:+An+Extensible+Metadata+Schema+for+IR+Experiments)|0|
|[CODEC: Complex Document and Entity Collection](https://doi.org/10.1145/3477495.3531712)|Iain Mackie, Paul Owoicho, Carlos Gemmell, Sophie Fischer, Sean MacAvaney, Jeffrey Dalton||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CODEC:+Complex+Document+and+Entity+Collection)|0|
|[Would You Ask it that Way?: Measuring and Improving Question Naturalness for Knowledge Graph Question Answering](https://doi.org/10.1145/3477495.3531739)|Trond Linjordet, Krisztian Balog||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Would+You+Ask+it+that+Way?:+Measuring+and+Improving+Question+Naturalness+for+Knowledge+Graph+Question+Answering)|0|
|[Biographical Semi-Supervised Relation Extraction Dataset](https://doi.org/10.1145/3477495.3531742)|Alistair Plum, Tharindu Ranasinghe, Spencer Jones, Constantin Orasan, Ruslan Mitkov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Biographical+Semi-Supervised+Relation+Extraction+Dataset)|0|
|[CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines](https://doi.org/10.1145/3477495.3531745)|Soham Poddar, Azlaan Mustafa Samad, Rajdeep Mukherjee, Niloy Ganguly, Saptarshi Ghosh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAVES:+A+Dataset+to+facilitate+Explainable+Classification+and+Summarization+of+Concerns+towards+COVID+Vaccines)|0|
|[SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated Counterfactuals](https://doi.org/10.1145/3477495.3531677)|Zijian Zhang, Vinay Setty, Avishek Anand||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SparCAssist:+A+Model+Risk+Assessment+Assistant+Based+on+Sparse+Generated+Counterfactuals)|0|
|[TARexp: A Python Framework for Technology-Assisted Review Experiments](https://doi.org/10.1145/3477495.3531663)|Eugene Yang, David D. Lewis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TARexp:+A+Python+Framework+for+Technology-Assisted+Review+Experiments)|0|
|[SpaceQA: Answering Questions about the Design of Space Missions and Space Craft Concepts](https://doi.org/10.1145/3477495.3531697)|Andrés GarcíaSilva, Cristian Berrio, José Manuél GómezPérez, José Antonio Martínez Heras, Alessandro Donati, Ilaria Roma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SpaceQA:+Answering+Questions+about+the+Design+of+Space+Missions+and+Space+Craft+Concepts)|0|
|[A Python Interface to PISA!](https://doi.org/10.1145/3477495.3531656)|Sean MacAvaney, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Python+Interface+to+PISA!)|0|
|[Organizing Portuguese Legal Documents through Topic Discovery](https://doi.org/10.1145/3477495.3536329)|Daniela Vianna, Edleno Silva de Moura||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Organizing+Portuguese+Legal+Documents+through+Topic+Discovery)|0|
|[A Low-Cost, Controllable and Interpretable Task-Oriented Chatbot: With Real-World After-Sale Services as Example](https://doi.org/10.1145/3477495.3536331)|Xiangyu Xi, Chenxu Lv, Yuncheng Hua, Wei Ye, Chaobo Sun, Shuaipeng Liu, Fan Yang, Guanglu Wan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Low-Cost,+Controllable+and+Interpretable+Task-Oriented+Chatbot:+With+Real-World+After-Sale+Services+as+Example)|0|
|[Beyond Opinion Mining: Summarizing Opinions of Customer Reviews](https://doi.org/10.1145/3477495.3532676)|Reinald Kim Amplayo, Arthur Brazinskas, Yoshi Suhara, Xiaolan Wang, Bing Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Opinion+Mining:+Summarizing+Opinions+of+Customer+Reviews)|0|
|[Fairness-Aware Question Answering for Intelligent Assistants](https://doi.org/10.1145/3477495.3531682)|Sachin Pathiyan Cherumanal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness-Aware+Question+Answering+for+Intelligent+Assistants)|0|
|[Continuous Result Delta Evaluation of IR Systems](https://doi.org/10.1145/3477495.3531686)|Gabriela González Sáez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continuous+Result+Delta+Evaluation+of+IR+Systems)|0|
