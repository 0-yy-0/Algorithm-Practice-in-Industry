# SIGIR2022 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Hypergraph Contrastive Collaborative Filtering](https://doi.org/10.1145/3477495.3532058)|Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, Jimmy X. Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hypergraph+Contrastive+Collaborative+Filtering)|22|
|[Are Graph Augmentations Necessary?: Simple Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3477495.3531937)|Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, Quoc Viet Hung Nguyen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+Graph+Augmentations+Necessary?:+Simple+Graph+Contrastive+Learning+for+Recommendation)|20|
|[From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective](https://doi.org/10.1145/3477495.3531857)|Thibault Formal, Carlos Lassance, Benjamin Piwowarski, Stéphane Clinchant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Distillation+to+Hard+Negative+Sampling:+Making+Sparse+Neural+IR+Models+More+Effective)|10|
|[Multi-level Cross-view Contrastive Learning for Knowledge-aware Recommender System](https://doi.org/10.1145/3477495.3532025)|Ding Zou, Wei Wei, XianLing Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, Xin Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-level+Cross-view+Contrastive+Learning+for+Knowledge-aware+Recommender+System)|10|
|[Knowledge Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3477495.3532009)|Yuhao Yang, Chao Huang, Lianghao Xia, Chenliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Contrastive+Learning+for+Recommendation)|10|
|[Meta-Knowledge Transfer for Inductive Knowledge Graph Embedding](https://doi.org/10.1145/3477495.3531757)|Mingyang Chen, Wen Zhang, Yushan Zhu, Hongting Zhou, Zonggang Yuan, Changliang Xu, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Knowledge+Transfer+for+Inductive+Knowledge+Graph+Embedding)|8|
|[CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems](https://doi.org/10.1145/3477495.3531959)|Mohammadmehdi Naghiaei, Hossein A. Rahmani, Yashar Deldjoo|University of Southern California, California, CA, USA; Polytechnic University of Bari, Bari, Italy; University College London, London, United Kingdom|Recently, there has been a rising awareness that when machine learning (ML) algorithms are used to automate choices, they may treat/affect individuals unfairly, with legal, ethical, or economic consequences. Recommender systems are prominent examples of such ML systems that assist users in making high-stakes judgments. A common trend in the previous literature research on fairness in recommender systems is that the majority of works treat user and item fairness concerns separately, ignoring the fact that recommender systems operate in a two-sided marketplace. In this work, we present an optimization-based re-ranking approach that seamlessly integrates fairness constraints from both the consumer and producer-side in a joint objective framework. We demonstrate through large-scale experiments on 8 datasets that our proposed method is capable of improving both consumer and producer fairness without reducing overall recommendation quality, demonstrating the role algorithms may play in minimizing data biases.|最近，人们越来越意识到，当机器学习(ML)算法被用于自动选择时，它们可能会不公平地对待/影响个人，产生法律、道德或经济后果。推荐系统是这种机器学习系统的突出例子，它可以帮助用户做出高风险的判断。在以往关于推荐系统公平性的文献研究中，一个普遍的趋势是，大多数研究将用户和项目的公平性问题分开处理，忽略了推荐系统在双边市场中运行的事实。在这项工作中，我们提出了一个基于优化的重新排序方法，在一个联合目标框架中无缝地整合来自消费者和生产者方面的公平约束。我们通过在8个数据集上的大规模实验证明了我们提出的方法能够在不降低整体推荐质量的情况下提高消费者和生产者的公平性，并且证明了算法在最小化数据偏差方面可能发挥的作用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CPFair:+Personalized+Consumer+and+Producer+Fairness+Re-ranking+for+Recommender+Systems)|7|
|[Curriculum Learning for Dense Retrieval Distillation](https://doi.org/10.1145/3477495.3531791)|Hansi Zeng, Hamed Zamani, Vishwa Vinay||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curriculum+Learning+for+Dense+Retrieval+Distillation)|7|
|[Constructing Better Evaluation Metrics by Incorporating the Anchoring Effect into the User Model](https://doi.org/10.1145/3477495.3531953)|Nuo Chen, Fan Zhang, Tetsuya Sakai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constructing+Better+Evaluation+Metrics+by+Incorporating+the+Anchoring+Effect+into+the+User+Model)|7|
|[Graph Trend Filtering Networks for Recommendation](https://doi.org/10.1145/3477495.3531985)|Wenqi Fan, Xiaorui Liu, Wei Jin, Xiangyu Zhao, Jiliang Tang, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Trend+Filtering+Networks+for+Recommendation)|6|
|[An Efficiency Study for SPLADE Models](https://doi.org/10.1145/3477495.3531833)|Carlos Lassance, Stéphane Clinchant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficiency+Study+for+SPLADE+Models)|6|
|[Improving Conversational Recommender Systems via Transformer-based Sequential Modelling](https://doi.org/10.1145/3477495.3531852)|Jie Zou, Evangelos Kanoulas, Pengjie Ren, Zhaochun Ren, Aixin Sun, Cheng Long|Shandong University, Qingdao, China; University of Amsterdam, Amsterdam, Netherlands; [email protected]|In Conversational Recommender Systems (CRSs), conversations usually involve a set of related items and entities e.g., attributes of items. These items and entities are mentioned in order following the development of a dialogue. In other words, potential sequential dependencies exist in conversations. However, most of the existing CRSs neglect these potential sequential dependencies. In this paper, we propose a Transformer-based sequential conversational recommendation method, named TSCR, which models the sequential dependencies in the conversations to improve CRS. We represent conversations by items and entities, and construct user sequences to discover user preferences by considering both mentioned items and entities. Based on the constructed sequences, we deploy a Cloze task to predict the recommended items along a sequence. Experimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines.|在会话推荐系统(CRS)中，会话通常涉及一组相关的项目和实体，例如，项目的属性。这些项目和实体将在对话发展之后按顺序提及。换句话说，潜在的顺序依赖性存在于会话中。然而，大多数现有的 CRS 忽略了这些潜在的顺序依赖关系。本文提出了一种基于变压器的顺序会话推荐方法 TSCR，该方法通过建立会话中的顺序依赖关系来改进 CRS。我们通过条目和实体表示会话，并通过考虑上述条目和实体构造用户序列来发现用户偏好。基于构造的序列，我们部署完形填空任务来预测一个序列中推荐的项目。实验结果表明，我们的 TSCR 模型明显优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Conversational+Recommender+Systems+via+Transformer-based+Sequential+Modelling)|5|
|[BERT-ER: Query-specific BERT Entity Representations for Entity Ranking](https://doi.org/10.1145/3477495.3531944)|Shubham Chatterjee, Laura Dietz|University of New Hampshire, Durham, NH, USA|Entity-oriented search systems often learn vector representations of entities via the introductory paragraph from the Wikipedia page of the entity. As such representations are the same for every query, our hypothesis is that the representations are not ideal for IR tasks. In this work, we present BERT Entity Representations (BERT-ER) which are query-specific vector representations of entities obtained from text that describes how an entity is relevant for a query. Using BERT-ER in a downstream entity ranking system, we achieve a performance improvement of 13-42% (Mean Average Precision) over a system that uses the BERT embedding of the introductory paragraph from Wikipedia on two large-scale test collections. Our approach also outperforms entity ranking systems using entity embeddings from Wikipedia2Vec, ERNIE, and E-BERT. We show that our entity ranking system using BERT-ER can increase precision at the top of the ranking by promoting relevant entities to the top. With this work, we release our BERT models and query-specific entity embeddings fine-tuned for the entity ranking task.|面向实体的搜索系统通常通过实体的 Wikipedia 页面中的介绍性段落学习实体的向量表示。由于这种表示对于每个查询都是相同的，我们的假设是，这种表示对于 IR 任务来说并不理想。在这项工作中，我们提出了 BERT 实体表示(BERT-ER) ，它是从文本中获得的实体的特定于查询的向量表示，描述了一个实体如何与一个查询相关。在下游实体排名系统中使用 BERT-ER，我们比在两个大规模测试集合中使用 BERT 嵌入的介绍性段落的系统获得了13-42% 的性能提高(均值平均精度)。我们的方法也优于使用 Wikipedia2Vec、 ERNIE 和 E-BERT 的实体嵌入的实体排序系统。结果表明，使用 BERT-ER 的实体排名系统可以通过将相关实体提升到顶端来提高排名的精度。通过这项工作，我们发布了我们的 BERT 模型和针对实体排序任务的查询特定实体嵌入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BERT-ER:+Query-specific+BERT+Entity+Representations+for+Entity+Ranking)|5|
|[Reduce, Reuse, Recycle: Green Information Retrieval Research](https://doi.org/10.1145/3477495.3531766)|Harrisen Scells, Shengyao Zhuang, Guido Zuccon|The University of Queensland, Brisbane, QLD, Australia|Recent advances in Information Retrieval utilise energy-intensive hardware to produce state-of-the-art results. In areas of research highly related to Information Retrieval, such as Natural Language Processing and Machine Learning, there have been efforts to quantify and reduce the power and emissions produced by methods that depend on such hardware. Research that is conscious of the environmental impacts of its experimentation and takes steps to mitigate some of these impacts is considered 'Green'. Given the continuous demand for more data and power-hungry techniques, Green research is likely to become more important within the broader research community. Therefore, within the Information Retrieval community, the consequences of non-Green (in other words, Red) research should at least be considered and acknowledged. As such, the aims of this perspective paper are fourfold: (1) to review the Green literature not only for Information Retrieval but also for related domains in order to identify transferable Green techniques; (2) to provide measures for quantifying the power usage and emissions of Information Retrieval research; (3) to report the power usage and emission impacts for various current IR methods; and (4) to provide a framework to guide Green Information Retrieval research, taking inspiration from 'reduce, reuse, recycle' waste management campaigns, including salient examples from the literature that implement these concepts.|最近在信息检索方面的进展利用能源密集型硬件来产生最先进的结果。在与信息检索高度相关的研究领域，如自然语言处理和机器学习，一直在努力量化和减少依赖这些硬件的方法所产生的功率和排放。意识到实验对环境的影响并采取措施减轻其中一些影响的研究被认为是“绿色”的。鉴于对更多数据和耗电技术的持续需求，绿色研究可能在更广泛的研究领域变得更加重要。因此，在信息检索社区内，非绿色(换句话说，红色)研究的后果至少应该被考虑和承认。因此，本文件的目的有四个: (1)不仅为信息检索而且为相关领域查阅绿色文献，以便确定可转用的绿色技术; (2)提供量化信息检索研究的用电量和排放量的措施; (3)报告各种现行红外线方法的用电量和排放影响; (4)提供一个框架，以指导绿色信息检索研究，从“减少、再使用、回收”废物管理运动中获得启发，包括实施这些概念的文献中的突出例子。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reduce,+Reuse,+Recycle:+Green+Information+Retrieval+Research)|5|
|[On-Device Next-Item Recommendation with Self-Supervised Knowledge Distillation](https://doi.org/10.1145/3477495.3531775)|Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Guandong Xu, Quoc Viet Hung Nguyen|Griffith University, Gold Coast, Australia; The University of Queensland, Brisbane, QLD, Australia; Baidu Inc., Beijing, China; University of Technology Sydney, Sydney, NSW, Australia|Session-based recommender systems (SBR) are becoming increasingly popular because they can predict user interests without relying on long-term user profile and support login-free recommendation. Modern recommender systems operate in a fully server-based fashion. To cater to millions of users, the frequent model maintaining and the high-speed processing for concurrent user requests are required, which comes at the cost of a huge carbon footprint. Meanwhile, users need to upload their behavior data even including the immediate environmental context to the server, raising the public concern about privacy. On-device recommender systems circumvent these two issues with cost-conscious settings and local inference. However, due to the limited memory and computing resources, on-device recommender systems are confronted with two fundamental challenges: (1) how to reduce the size of regular models to fit edge devices? (2) how to retain the original capacity? Previous research mostly adopts tensor decomposition techniques to compress regular recommendation models with low compression rates so as to avoid drastic performance degradation. In this paper, we explore ultra-compact models for next-item recommendation, by loosing the constraint of dimensionality consistency in tensor decomposition. To compensate for the capacity loss caused by compression, we develop a self-supervised knowledge distillation framework which enables the compressed model (student) to distill the essential information lying in the raw data, and improves the long-tail item recommendation through an embedding-recombination strategy with the original model (teacher). The extensive experiments on two benchmarks demonstrate that, with 30x size reduction, the compressed model almost comes with no accuracy loss, and even outperforms its uncompressed counterpart. The code is released at https://github.com/xiaxin1998/OD-Rec.|基于会话的推荐系统正变得越来越流行，因为它们可以预测用户的兴趣而不依赖于长期的用户配置文件和支持免登录的推荐。现代推荐系统以完全基于服务器的方式运行。为了满足数百万用户的需求，需要频繁的模型维护和对并发用户请求的高速处理，这需要付出巨大的碳足印。与此同时，用户需要上传他们的行为数据，甚至包括即时的环境背景到服务器，引起公众对隐私的关注。设备上的推荐系统通过成本意识设置和本地推断来规避这两个问题。然而，由于有限的内存和计算资源，设备上的推荐系统面临着两个基本的挑战: (1)如何减少常规模型的大小，以适应边缘设备？(2)如何保留原有能力？以往的研究大多采用张量分解技术对低压缩率的常规推荐模型进行压缩，以避免性能的急剧下降。本文通过放松张量分解中维度一致性的约束，探索了下一项推荐的超紧模型。为了弥补压缩带来的容量损失，提出了一种自监督知识提取框架，使压缩模型(学生)能够提取原始数据中的关键信息，并通过与原始模型(教师)的嵌入-重组策略改进长尾项目推荐。在两个基准上的大量实验表明，在缩小了30倍尺寸的情况下，压缩模型几乎没有精度损失，甚至优于未压缩模型。密码在 https://github.com/xiaxin1998/od-rec 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On-Device+Next-Item+Recommendation+with+Self-Supervised+Knowledge+Distillation)|5|
|[DisenCDR: Learning Disentangled Representations for Cross-Domain Recommendation](https://doi.org/10.1145/3477495.3531967)|Jiangxia Cao, Xixun Lin, Xin Cong, Jing Ya, Tingwen Liu, Bin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DisenCDR:+Learning+Disentangled+Representations+for+Cross-Domain+Recommendation)|5|
|[Personalized Fashion Compatibility Modeling via Metapath-guided Heterogeneous Graph Learning](https://doi.org/10.1145/3477495.3532038)|Weili Guan, Fangkai Jiao, Xuemeng Song, Haokun Wen, ChungHsing Yeh, Xiaojun Chang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Fashion+Compatibility+Modeling+via+Metapath-guided+Heterogeneous+Graph+Learning)|5|
|[Explainable Fairness in Recommendation](https://doi.org/10.1145/3477495.3531973)|Yingqiang Ge, Juntao Tan, Yan Zhu, Yinglong Xia, Jiebo Luo, Shuchang Liu, Zuohui Fu, Shijie Geng, Zelong Li, Yongfeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Fairness+in+Recommendation)|5|
|[Measuring Fairness in Ranked Results: An Analytical and Empirical Comparison](https://doi.org/10.1145/3477495.3532018)|Amifa Raj, Michael D. Ekstrand||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Fairness+in+Ranked+Results:+An+Analytical+and+Empirical+Comparison)|5|
|[Webformer: Pre-training with Web Pages for Information Retrieval](https://doi.org/10.1145/3477495.3532086)|Yu Guo, Zhengyi Ma, Jiaxin Mao, Hongjin Qian, Xinyu Zhang, Hao Jiang, Zhao Cao, Zhicheng Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Webformer:+Pre-training+with+Web+Pages+for+Information+Retrieval)|5|
|[BARS: Towards Open Benchmarking for Recommender Systems](https://doi.org/10.1145/3477495.3531723)|Jieming Zhu, Quanyu Dai, Liangcai Su, Rong Ma, Jinyang Liu, Guohao Cai, Xi Xiao, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BARS:+Towards+Open+Benchmarking+for+Recommender+Systems)|5|
|[V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation](https://doi.org/10.1145/3477495.3532076)|Xuemeng Song, Liqiang Jing, Dengtian Lin, Zhongzhou Zhao, Haiqing Chen, Liqiang Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=V2P:+Vision-to-Prompt+based+Multi-Modal+Product+Summary+Generation)|5|
|[A Weakly Supervised Propagation Model for Rumor Verification and Stance Detection with Multiple Instance Learning](https://doi.org/10.1145/3477495.3531930)|Ruichao Yang, Jing Ma, Hongzhan Lin, Wei Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Weakly+Supervised+Propagation+Model+for+Rumor+Verification+and+Stance+Detection+with+Multiple+Instance+Learning)|5|
|[Positive, Negative and Neutral: Modeling Implicit Feedback in Session-based News Recommendation](https://doi.org/10.1145/3477495.3532040)|Shansan Gong, Kenny Q. Zhu|Shanghai Jiao Tong University, Shanghai, China|News recommendation for anonymous readers is a useful but challenging task for many news portals, where interactions between readers and articles are limited within a temporary login session. Previous works tend to formulate session-based recommendation as a next item prediction task, while they neglect the implicit feedback from user behaviors, which indicates what users really like or dislike. Hence, we propose a comprehensive framework to model user behaviors through positive feedback (i.e., the articles they spend more time on) and negative feedback (i.e., the articles they choose to skip without clicking in). Moreover, the framework implicitly models the user using their session start time, and the article using its initial publishing time, in what we call neutral feedback. Empirical evaluation on three real-world news datasets shows the framework's promising performance of more accurate, diverse and even unexpectedness recommendations than other state-of-the-art session-based recommendation approaches.|对于许多新闻门户网站来说，为匿名读者推荐新闻是一项有用但具有挑战性的任务，因为在临时登录会话中，读者和文章之间的交互受到限制。以往的研究倾向于将基于会话的推荐作为下一个项目的预测任务，而忽略了来自用户行为的隐性反馈，这表明用户真正喜欢或不喜欢什么。因此，我们提出了一个全面的框架，通过积极反馈(即，他们花费更多时间的文章)和消极反馈(即，他们选择不点击跳过的文章)来模拟用户行为。此外，框架使用用户的会话开始时间隐式地对用户进行建模，并使用文章的初始发布时间隐式地对文章进行建模，我们称之为中性反馈。对三个真实世界新闻数据集的实证评估表明，与其他基于会话的最新推荐方法相比，该框架具有更准确、更多样、甚至更出人意料的推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Positive,+Negative+and+Neutral:+Modeling+Implicit+Feedback+in+Session-based+News+Recommendation)|4|
|[Multi-Behavior Sequential Transformer Recommender](https://doi.org/10.1145/3477495.3532023)|Enming Yuan, Wei Guo, Zhicheng He, Huifeng Guo, Chengkai Liu, Ruiming Tang|Noah's Ark Lab, Huawei, Shenzhen, China; Tsinghua University, Beijing, China; Shanghai Jiao Tong University, Shanghai, China|In most real-world recommender systems, users interact with items in a sequential and multi-behavioral manner. Exploring the fine-grained relationship of items behind the users' multi-behavior interactions is critical in improving the performance of recommender systems. Despite the great successes, existing methods seem to have limitations on modelling heterogeneous item-level multi-behavior dependencies, capturing diverse multi-behavior sequential dynamics, or alleviating data sparsity problems. In this paper, we show it is possible to derive a framework to address all the above three limitations. The proposed framework MB-STR, a Multi-Behavior Sequential Transformer Recommender, is equipped with the multi-behavior transformer layer (MB-Trans), the multi-behavior sequential pattern generator (MB-SPG) and the behavior-aware prediction module (BA-Pred). Compared with a typical transformer, we design MB-Trans to capture multi-behavior heterogeneous dependencies as well as behavior-specific semantics, propose MB-SPG to encode the diverse sequential patterns among multiple behaviors, and incorporate BA-Pred to better leverage multi-behavior supervision. Comprehensive experiments on three real-world datasets show the effectiveness of MB-STR by significantly boosting the recommendation performance compared with various competitive baselines. Further ablation studies demonstrate the superiority of different modules of MB-STR.|在大多数现实世界的推荐系统中，用户以一种顺序和多行为的方式与项目交互。探索用户多行为交互背后的细粒度关系对于提高推荐系统的性能至关重要。尽管取得了巨大的成功，但现有的方法似乎在建模异构项目级多行为依赖、捕获多种多行为顺序动态或缓解数据稀疏问题方面存在局限性。在本文中，我们展示了推导一个框架来解决上述三个限制是可能的。提出的多行为顺序变压器推荐系统框架 MB-STR 具有多行为顺序变压器层(MB-Trans)、多行为顺序模式发生器(MB-SPG)和行为感知预测模块(BA-Pred)。与典型的变压器相比，我们设计 MB-Trans 来捕获多行为异构依赖和行为特定的语义，提出 MB-SPG 来编码多行为之间的不同序列模式，并结合 BA-Pred 来更好地利用多行为监督。在三个实际数据集上的综合实验表明，与不同的竞争基线相比，MB-STR 能够显著提高推荐性能。进一步的消融研究证明了 MB-STR 不同模块的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavior+Sequential+Transformer+Recommender)|4|
|[News Recommendation with Candidate-aware User Modeling](https://doi.org/10.1145/3477495.3531778)|Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang|Microsoft Research Asia, Beijing, China; Tsinghua University, Beijing, China|News recommendation aims to match news with personalized user interest. Existing methods for news recommendation usually model user interest from historical clicked news without the consideration of candidate news. However, each user usually has multiple interests, and it is difficult for these methods to accurately match a candidate news with a specific user interest. In this paper, we present a candidate-aware user modeling method for personalized news recommendation, which can incorporate candidate news into user modeling for better matching between candidate news and user interest. We propose a candidate-aware self-attention network that uses candidate news as clue to model candidate-aware global user interest. In addition, we propose a candidate-aware CNN network to incorporate candidate news into local behavior context modeling and learn candidate-aware short-term user interest. Besides, we use a candidate-aware attention network to aggregate previously clicked news weighted by their relevance with candidate news to build candidate-aware user representation. Experiments on real-world datasets show the effectiveness of our method in improving news recommendation performance.|新闻推荐旨在使新闻与个性化的用户兴趣相匹配。现有的新闻推荐方法通常根据历史点击新闻建立用户兴趣模型，而不考虑候选新闻。然而，每个用户通常有多个兴趣，这些方法很难准确地匹配一个候选新闻和一个特定的用户兴趣。提出了一种基于候选者感知的个性化新闻推荐用户建模方法，该方法将候选新闻融入到用户建模中，以更好地匹配候选新闻和用户兴趣。我们提出了一个以候选新闻为线索的候选感知自我注意网络，该网络对全球候选感知用户兴趣进行建模。此外，我们提出了一个候选人感知的 CNN 网络，将候选人新闻纳入本地行为上下文建模，并学习候选人感知的短期用户兴趣。此外，我们利用一个候选人感知的注意网络来聚合先前点击过的新闻，并根据它们与候选人新闻的相关性来加权，从而建立一个候选人感知的用户表示。在实际数据集上的实验结果表明了该方法在提高新闻推荐性能方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=News+Recommendation+with+Candidate-aware+User+Modeling)|4|
|[Price DOES Matter!: Modeling Price and Interest Preferences in Session-based Recommendation](https://doi.org/10.1145/3477495.3532043)|Xiaokun Zhang, Bo Xu, Liang Yang, Chenliang Li, Fenglong Ma, Haifeng Liu, Hongfei Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Price+DOES+Matter!:+Modeling+Price+and+Interest+Preferences+in+Session-based+Recommendation)|4|
|[CORE: Simple and Effective Session-based Recommendation within Consistent Representation Space](https://doi.org/10.1145/3477495.3531955)|Yupeng Hou, Binbin Hu, Zhiqiang Zhang, Wayne Xin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CORE:+Simple+and+Effective+Session-based+Recommendation+within+Consistent+Representation+Space)|4|
|[Unlearning Protected User Attributes in Recommendations with Adversarial Training](https://doi.org/10.1145/3477495.3531820)|Christian Ganhör, David Penz, Navid Rekabsaz, Oleg Lesota, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlearning+Protected+User+Attributes+in+Recommendations+with+Adversarial+Training)|4|
|[Deep Multi-Representational Item Network for CTR Prediction](https://doi.org/10.1145/3477495.3531845)|Jihai Zhang, Fangquan Lin, Cheng Yang, Wei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Multi-Representational+Item+Network+for+CTR+Prediction)|4|
|[GETNext: Trajectory Flow Map Enhanced Transformer for Next POI Recommendation](https://doi.org/10.1145/3477495.3531983)|Song Yang, Jiamou Liu, Kaiqi Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GETNext:+Trajectory+Flow+Map+Enhanced+Transformer+for+Next+POI+Recommendation)|4|
|[ReCANet: A Repeat Consumption-Aware Neural Network for Next Basket Recommendation in Grocery Shopping](https://doi.org/10.1145/3477495.3531708)|Mozhdeh Ariannezhad, Sami Jullien, Ming Li, Min Fang, Sebastian Schelter, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReCANet:+A+Repeat+Consumption-Aware+Neural+Network+for+Next+Basket+Recommendation+in+Grocery+Shopping)|4|
|[A Review-aware Graph Contrastive Learning Framework for Recommendation](https://doi.org/10.1145/3477495.3531927)|Jie Shuai, Kun Zhang, Le Wu, Peijie Sun, Richang Hong, Meng Wang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Review-aware+Graph+Contrastive+Learning+Framework+for+Recommendation)|4|
|[H-ERNIE: A Multi-Granularity Pre-Trained Language Model for Web Search](https://doi.org/10.1145/3477495.3531986)|Xiaokai Chu, Jiashu Zhao, Lixin Zou, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=H-ERNIE:+A+Multi-Granularity+Pre-Trained+Language+Model+for+Web+Search)|4|
|[GERE: Generative Evidence Retrieval for Fact Verification](https://doi.org/10.1145/3477495.3531827)|Jiangui Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GERE:+Generative+Evidence+Retrieval+for+Fact+Verification)|4|
|[Towards Feature Selection for Ranking and Classification Exploiting Quantum Annealers](https://doi.org/10.1145/3477495.3531755)|Maurizio Ferrari Dacrema, Fabio Moroni, Riccardo Nembrini, Nicola Ferro, Guglielmo Faggioli, Paolo Cremonesi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Feature+Selection+for+Ranking+and+Classification+Exploiting+Quantum+Annealers)|4|
|[Continual Learning Dialogue Systems - Learning during Conversation](https://doi.org/10.1145/3477495.3532677)|Sahisnu Mazumder, Bing Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Learning+Dialogue+Systems+-+Learning+during+Conversation)|4|
|[Conversational Information Seeking: Theory and Application](https://doi.org/10.1145/3477495.3532678)|Jeffrey Dalton, Sophie Fischer, Paul Owoicho, Filip Radlinski, Federico Rossetto, Johanne R. Trippas, Hamed Zamani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Information+Seeking:+Theory+and+Application)|4|
|[MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset](https://doi.org/10.1145/3477495.3531744)|Dan Saattrup Nielsen, Ryan McConville||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MuMiN:+A+Large-Scale+Multilingual+Multimodal+Fact-Checked+Misinformation+Social+Network+Dataset)|4|
|[A Non-Factoid Question-Answering Taxonomy](https://doi.org/10.1145/3477495.3531926)|Valeria Bolotova, Vladislav Blinov, Falk Scholer, W. Bruce Croft, Mark Sanderson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Non-Factoid+Question-Answering+Taxonomy)|4|
|[A Multitask Framework for Sentiment, Emotion and Sarcasm aware Cyberbullying Detection from Multi-modal Code-Mixed Memes](https://doi.org/10.1145/3477495.3531925)|Krishanu Maity, Prince Jha, Sriparna Saha, Pushpak Bhattacharyya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multitask+Framework+for+Sentiment,+Emotion+and+Sarcasm+aware+Cyberbullying+Detection+from+Multi-modal+Code-Mixed+Memes)|4|
|[MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale Recommendation Scenarios](https://doi.org/10.1145/3477495.3531733)|Xiaofeng Pan, Ming Li, Jing Zhang, Keren Yu, Hong Wen, Luping Wang, Chengjun Mao, Bo Cao|The University of Sydney, Sydney, NSW, China; Alibaba Group, Hangzhou, China|Different from large-scale platforms such as Taobao and Amazon, CVR modeling in small-scale recommendation scenarios is more challenging due to the severe Data Distribution Fluctuation (DDF) issue. DDF prevents existing CVR models from being effective since 1) several months of data are needed to train CVR models sufficiently in small scenarios, leading to considerable distribution discrepancy between training and online serving; and 2) e-commerce promotions have significant impacts on small scenarios, leading to distribution uncertainty of the upcoming time period. In this work, we propose a novel CVR method named MetaCVR from a perspective of meta learning to address the DDF issue. Firstly, a base CVR model which consists of a Feature Representation Network (FRN) and output layers is designed and trained sufficiently with samples across months. Then we treat time periods with different data distributions as different occasions and obtain positive and negative prototypes for each occasion using the corresponding samples and the pre-trained FRN. Subsequently, a Distance Metric Network (DMN) is devised to calculate the distance metrics between each sample and all prototypes to facilitate mitigating the distribution uncertainty. At last, we develop an Ensemble Prediction Network (EPN) which incorporates the output of FRN and DMN to make the final CVR prediction. In this stage, we freeze the FRN and train the DMN and EPN with samples from recent time period, therefore effectively easing the distribution discrepancy. To the best of our knowledge, this is the first study of CVR prediction targeting the DDF issue in small-scale recommendation scenarios. Experimental results on real-world datasets validate the superiority of our MetaCVR and online A/B test also shows our model achieves impressive gains of 11.92% on PCVR and 8.64% on GMV.|与淘宝和亚马逊等大型平台不同，由于数据分布波动(DDF)问题严重，小规模推荐场景下的 CVR 建模更具挑战性。DDF 阻止了现有的 CVR 模型的有效性，因为1)需要几个月的数据来充分训练 CVR 模型在小场景中，导致训练和在线服务之间的相当大的分布差异; 2)电子商务促销对小场景有重大影响，导致即将到来的时间段的分布不确定性。本文从元学习的角度出发，提出了一种新的 CVR 方法 MetaCVR 来解决 DDF 问题。首先，设计了一个由特征表示网络(FRN)和输出层组成的基本 CVR 模型，并对该模型进行了数月的样本训练。然后将不同时间段的数据分布视为不同的场合，利用相应的样本和预先训练好的 FRN，得到每个场合的正负原型。随后，设计了一个距离度量网络(DMN)来计算每个样本和所有原型之间的距离度量，以减少分布的不确定性。最后，我们开发了一个集成预测网络(EPN) ，将 FRN 和 DMN 的输出结合起来进行 CVR 的最终预测。在这一阶段，我们冻结 FRN，并用最近时间段的样本训练 DMN 和 EPN，从而有效地缓解了分布差异。据我们所知，这是第一个针对小规模推荐场景中 DDF 问题的 CVR 预测研究。在实际数据集上的实验结果验证了我们的 MetaCVR 模型的优越性，在线 A/B 测试也表明我们的模型在 PCVR 和 GMV 上分别取得了令人印象深刻的11.92% 和8.64% 的增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaCVR:+Conversion+Rate+Prediction+via+Meta+Learning+in+Small-Scale+Recommendation+Scenarios)|3|
|[Can Clicks Be Both Labels and Features?: Unbiased Behavior Feature Collection and Uncertainty-aware Learning to Rank](https://doi.org/10.1145/3477495.3531948)|Tao Yang, Chen Luo, Hanqing Lu, Parth Gupta, Bing Yin, Qingyao Ai|University of Utah, Salt Lake City, UT, USA; Amazon Search, Palo Alto, CA, USA|Using implicit feedback collected from user clicks as training labels for learning-to-rank algorithms is a well-developed paradigm that has been extensively studied and used in modern IR systems. Using user clicks as ranking features, on the other hand, has not been fully explored in existing literature. Despite its potential in improving short-term system performance, whether the incorporation of user clicks as ranking features is beneficial for learning-to-rank systems in the long term is still questionable. Two of the most important problems are (1) the explicit bias introduced by noisy user behavior, and (2) the implicit bias, which we refer to as the exploitation bias, introduced by the dynamic training and serving of learning-to-rank systems with behavior features. In this paper, we explore the possibility of incorporating user clicks as both training labels and ranking features for learning to rank. We formally investigate the problems in feature collection and model training, and propose a counterfactual feature projection function and a novel uncertainty-aware learning to rank framework. Experiments on public datasets show that ranking models learned with the proposed framework can significantly outperform models built with raw click features and algorithms that rank items without considering model uncertainty.|使用从用户点击收集的隐式反馈作为学习到排序算法的训练标签是一个发展良好的范例，已经在现代 IR 系统中得到了广泛的研究和应用。使用用户点击作为排名功能，另一方面，还没有充分探讨现有的文献。尽管它在提高短期系统性能方面具有潜力，但是从长远来看，将用户点击作为排名功能的结合是否有利于学习排名系统仍然值得怀疑。其中最重要的两个问题是: (1)噪声用户行为引入的显性偏差和(2)具有行为特征的学习排序系统的动态训练和服务引入的隐性偏差，我们称之为剥削偏差。在这篇文章中，我们探讨了将用户点击作为训练标签和排名特征来学习排名的可能性。我们正式研究了特征收集和模型训练中的问题，提出了一种反事实特征投影函数和一种新的不确定性学习排序框架。对公共数据集的实验表明，使用所提出的框架学习的排序模型可以显著优于使用原始点击特征和算法建立的模型，这些模型不考虑模型的不确定性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Clicks+Be+Both+Labels+and+Features?:+Unbiased+Behavior+Feature+Collection+and+Uncertainty-aware+Learning+to+Rank)|3|
|[User-Centric Conversational Recommendation with Multi-Aspect User Modeling](https://doi.org/10.1145/3477495.3532074)|Shuokai Li, Ruobing Xie, Yongchun Zhu, Xiang Ao, Fuzhen Zhuang, Qing He|WeChat Search Application Department, Tencent, Beijing, China; Institute of Artificial Intelligence, Beihang University, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Conversational recommender systems (CRS) aim to provide highquality recommendations in conversations. However, most conventional CRS models mainly focus on the dialogue understanding of the current session, ignoring other rich multi-aspect information of the central subjects (i.e., users) in recommendation. In this work, we highlight that the user's historical dialogue sessions and look-alike users are essential sources of user preferences besides the current dialogue session in CRS. To systematically model the multi-aspect information, we propose a User-Centric Conversational Recommendation (UCCR) model, which returns to the essence of user preference learning in CRS tasks. Specifically, we propose a historical session learner to capture users' multi-view preferences from knowledge, semantic, and consuming views as supplements to the current preference signals. A multi-view preference mapper is conducted to learn the intrinsic correlations among different views in current and historical sessions via self-supervised objectives. We also design a temporal look-alike user selector to understand users via their similar users. The learned multi-aspect multi-view user preferences are then used for the recommendation and dialogue generation. In experiments, we conduct comprehensive evaluations on both Chinese and English CRS datasets. The significant improvements over competitive models in both recommendation and dialogue generation verify the superiority of UCCR.|会话推荐系统(CRS)旨在提供高质量的会话推荐。然而，大多数传统的 CRS 模型主要侧重于对当前会话的对话理解，而忽略了推荐中心主体(即用户)的其他丰富的多方面信息。在这项工作中，我们强调用户的历史对话会话和外观相似的用户是用户偏好的重要来源，除了当前的对话会话在 CRS。为了系统地建立多方面信息的模型，本文提出了一种以用户为中心的会话推荐(UCCR)模型，该模型回归了 CRS 任务中用户偏好学习的本质。具体来说，我们提出了一个历史会话学习者来捕捉用户的多视图偏好，从知识，语义和消费观点作为补充的当前偏好信号。通过自监督目标，提出了一种多视点偏好映射算法，用于研究当前会议和历史会议中不同视点之间的内在相关性。我们还设计了一个时间外观相似的用户选择器，通过相似的用户来理解用户。然后利用所学习的多方面多视图用户偏好进行推荐和对话生成。在实验中，我们对中英文 CRS 数据集进行了综合评价。在推荐和对话生成方面对竞争模式的重大改进证明了 UCCR 的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-Centric+Conversational+Recommendation+with+Multi-Aspect+User+Modeling)|3|
|[When Multi-Level Meets Multi-Interest: A Multi-Grained Neural Model for Sequential Recommendation](https://doi.org/10.1145/3477495.3532081)|Yu Tian, Jianxin Chang, Yanan Niu, Yang Song, Chenliang Li|Kuaishou.com, Beijing, China; Wuhan University, Wuhan, China|Sequential recommendation aims at identifying the next item that is preferred by a user based on their behavioral history. Compared to conventional sequential models that leverage attention mechanisms and RNNs, recent efforts mainly follow two directions for improvement: multi-interest learning and graph convolutional aggregation. Specifically, multi-interest methods such as ComiRec and MIMN, focus on extracting different interests for a user by performing historical item clustering, while graph convolution methods including TGSRec and SURGE elect to refine user preferences based on multilevel correlations between historical items. Unfortunately, neither of them realizes that these two types of solutions can mutually complement each other, by aggregating multi-level user preference to achieve more precise multi-interest extraction for a better recommendation. To this end, in this paper, we propose a unified multi-grained neural model (named MGNM) via a combination of multi-interest learning and graph convolutional aggregation. Concretely, MGNM first learns the graph structure and information aggregation paths of the historical items for a user. It then performs graph convolution to derive item representations in an iterative fashion, in which the complex preferences at different levels can be well captured. Afterwards, a novel sequential capsule network is proposed to inject the sequential patterns into the multi-interest extraction process, leading to a more precise interest learning in a multi-grained manner. Experiments on three real-world datasets from different scenarios demonstrate the superiority of MGNM against several state-of-the-art baselines. The performance gain over the best baseline is up to 27.10% and 25.17% in terms of [email protected] and [email protected] respectively, which is one of the largest gains in recent development of sequential recommendation. Further analysis also demonstrates that MGNM is robust and effective at user preference understanding at multi-grained levels.|顺序推荐的目的是根据用户的行为历史来确定他们喜欢的下一个项目。与利用注意机制和 RNN 的传统序列模型相比，最近的努力主要遵循两个改进方向: 多兴趣学习和图卷积聚合。具体来说，ComiRec 和 MIMN 等多兴趣方法侧重于通过对历史项目进行聚类来为用户提取不同的兴趣，而 TGSRec 和 SurGE 等图形卷积方法则选择基于历史项目之间的多级相关性来改进用户偏好。不幸的是，他们都没有意识到这两种解决方案可以相互补充，通过聚合多级用户偏好来实现更精确的多兴趣提取以获得更好的推荐。为此，本文将多兴趣学习和图卷积聚合相结合，提出了一种统一的多粒度神经网络模型(MGNM)。具体来说，MGNM 首先为用户学习历史项的图形结构和信息聚合路径。然后，它执行图形卷积，以迭代的方式派生项表示，在这种方式中，可以很好地捕获不同级别的复杂首选项。然后，提出了一种新的序列胶囊网络，将序列模式引入到多兴趣提取过程中，从而实现多粒度的兴趣学习。通过对来自不同场景的三个真实世界数据集的实验，证明了 MGNM 算法对几个最新基线的优越性。就[ email protected ]和[ email protected ]而言，超过最佳基线的性能提升分别高达27.10% 和25.17% ，这是最近顺序推荐发展中最大的提升之一。进一步的分析还表明，MGNM 在多粒度级别上对用户偏好的理解是健壮的和有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Multi-Level+Meets+Multi-Interest:+A+Multi-Grained+Neural+Model+for+Sequential+Recommendation)|3|
|[AutoGSR: Neural Architecture Search for Graph-based Session Recommendation](https://doi.org/10.1145/3477495.3531940)|Jingfan Chen, Guanghui Zhu, Haojun Hou, Chunfeng Yuan, Yihua Huang|Nanjing University, Nanjing, China|Session-based recommendation aims to predict next click action (e.g., item) of anonymous users based on a fixed number of previous actions. Recently, Graph Neural Networks (GNNs) have shown superior performance in various applications. Inspired by the success of GNNs, tremendous endeavors have been devoted to introduce GNNs into session-based recommendation and have achieved significant results. Nevertheless, due to the highly diverse types of potential information in sessions, existing GNNs-based methods perform differently on different session datasets, leading to the need for efficient design of neural networks adapted to various session recommendation scenarios. To address this problem, we propose Automated neural architecture search for Graph-based Session Recommendation, namely AutoGSR, a framework that provides a practical and general solution to automatically find the optimal GNNs-based session recommendation model. In AutoGSR, we propose two novel GNN operations to build an expressive and compact search space. Building upon the search space, we employ a differentiable search algorithm to search for the optimal graph neural architecture. Furthermore, to consider all types of session information together, we propose to learn the item meta knowledge, which acts as a priori knowledge for guiding the optimization of final session representations. Comprehensive experiments on three real-world datasets demonstrate that AutoGSR is able to find effective neural architectures and achieve state-of-the-art results. To the best of our knowledge, we are the first to study the neural architecture search for the session-based recommendation.|基于会话的推荐旨在预测匿名用户的下一次点击操作(例如，条目) ，该推荐基于一个固定数量的以前的操作。近年来，图形神经网络(GNN)在各种应用中表现出了优越的性能。在 GNN 取得成功的启发下，为将 GNN 引入会议建议作出了巨大努力，并取得了重大成果。然而，由于会议中潜在信息的类型多种多样，现有的基于全球导航系统的方法在不同的会议数据集上表现不同，因此需要有效设计适应各种会议推荐情景的神经网络。为了解决这个问题，我们提出了基于图的会话推荐的自动神经网络体系结构搜索，即 AutoGSR，这个框架提供了一个实用的和通用的解决方案来自动找到最佳的基于 GNN 的会话推荐模型。在 AutoGSR 中，我们提出了两种新的 GNN 操作来构建一个表达式的、紧凑的搜索空间。在搜索空间的基础上，采用可微搜索算法来搜索最优的图神经网络结构。此外，为了一起考虑所有类型的会话信息，我们建议学习项目元知识，它作为指导最终会话表示优化的先验知识。对三个实际数据集的综合实验表明，AutoGSR 能够找到有效的神经结构，并取得最先进的结果。据我们所知，我们是第一个研究神经结构搜索的会话为基础的建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoGSR:+Neural+Architecture+Search+for+Graph-based+Session+Recommendation)|3|
|[How Does Feedback Signal Quality Impact Effectiveness of Pseudo Relevance Feedback for Passage Retrieval](https://doi.org/10.1145/3477495.3531822)|Hang Li, Ahmed Mourad, Bevan Koopman, Guido Zuccon|CSIRO, Brisbane, QLD, Australia; The University of Queensland, Brisbane, QLD, Australia|Pseudo-Relevance Feedback (PRF) assumes that the top results retrieved by a first-stage ranker are relevant to the original query and uses them to improve the query representation for a second round of retrieval. This assumption however is often not correct: some or even all of the feedback documents may be irrelevant. Indeed, the effectiveness of PRF methods may well depend on the quality of the feedback signal and thus on the effectiveness of the first-stage ranker. This aspect however has received little attention before. In this paper we control the quality of the feedback signal and measure its impact on a range of PRF methods, including traditional bag-of-words methods (Rocchio), and dense vector-based methods (learnt and not learnt). Our results show the important role the quality of the feedback signal plays on the effectiveness of PRF methods. Importantly, and surprisingly, our analysis reveals that not all PRF methods are the same when dealing with feedback signals of varying quality. These findings are critical to gain a better understanding of the PRF methods and of which and when they should be used, depending on the feedback signal quality, and set the basis for future research in this area.|伪相关反馈(PRF)假设第一阶段排序器检索到的最高结果与原始查询相关，并利用这些结果改善查询表示以进行第二轮检索。然而，这种假设往往是不正确的: 一些甚至所有的反馈文档可能是不相关的。事实上，PRF 方法的有效性很大程度上取决于反馈信号的质量，因此也取决于第一阶段排序器的有效性。然而，这方面以前很少受到关注。在本文中，我们控制反馈信号的质量，并测量其对一系列 PRF 方法的影响，包括传统的词袋方法(Rocchio)和基于密集向量的方法(学习和不学习)。结果表明，反馈信号的质量对 PRF 方法的有效性起着重要作用。重要的是，令人惊讶的是，我们的分析表明，并非所有的 PRF 方法是相同的，当处理不同质量的反馈信号。这些发现对于更好地理解 PRF 方法以及根据反馈信号的质量，什么时候应该使用这些方法是至关重要的，并且为这一领域的未来研究奠定了基础。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Does+Feedback+Signal+Quality+Impact+Effectiveness+of+Pseudo+Relevance+Feedback+for+Passage+Retrieval)|3|
|[Revisiting Two-tower Models for Unbiased Learning to Rank](https://doi.org/10.1145/3477495.3531837)|Le Yan, Zhen Qin, Honglei Zhuang, Xuanhui Wang, Michael Bendersky, Marc Najork|Google, Mountain View, CA, USA|Two-tower architecture is commonly used in real-world systems for Unbiased Learning to Rank (ULTR), where a Deep Neural Network (DNN) tower models unbiased relevance predictions, while another tower models observation biases inherent in the training data like user clicks. This two-tower architecture introduces inductive biases to allow more efficient use of limited observational logs and better generalization during deployment than single-tower architecture that may learn spurious correlations between relevance predictions and biases. However, despite their popularity, it is largely neglected in the literature that existing two-tower models assume that the joint distribution of relevance prediction and observation probabilities are completely factorizable. In this work, we revisit two-tower models for ULTR. We rigorously show that the factorization assumption can be too strong for real-world user behaviors, and existing methods may easily fail under slightly milder assumptions. We then propose several novel ideas that consider a wider spectrum of user behaviors while still under the two-tower framework to maintain simplicity and generalizability. Our concerns of existing two-tower models and the effectiveness of our proposed methods are validated on both controlled synthetic and large-scale real-world datasets.|双塔架构通常用于现实世界的无偏学习排名(ULTR)系统，其中一个深度神经网络(DNN)塔模型无偏相关性预测，而另一个塔模型观察偏差固有的训练数据，如用户点击。与单塔架构相比，这种双塔架构引入了归纳偏差，以便更有效地使用有限的观测日志，并在部署期间更好地进行概括，而单塔架构可以学习相关性预测和偏差之间的伪相关性。然而，尽管现有的双塔模型很流行，但它们大多被忽视了，现有的双塔模型假定相关预测和观测概率的联合分布是完全可分解的。在这项工作中，我们重新讨论了 ULTR 的双塔模型。我们严格地证明了因子分解假设对于真实世界的用户行为来说可能过于强烈，并且在稍微温和的假设下，现有的方法可能很容易失败。然后，我们提出了几个新的想法，考虑更广泛的用户行为，同时仍然在双塔框架下，以保持简单性和普遍性。我们对现有的双塔模型的关注和我们提出的方法的有效性是在受控的合成和大规模的真实世界数据集上得到验证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Two-tower+Models+for+Unbiased+Learning+to+Rank)|3|
|[Mitigating Bias in Search Results Through Contextual Document Reranking and Neutrality Regularization](https://doi.org/10.1145/3477495.3531891)|George Zerveas, Navid Rekabsaz, Daniel Cohen, Carsten Eickhoff|Brown University, Providence, RI, USA; Johannes Kepler University Linz & Linz Institute of Technology, Linz, Austria|Societal biases can influence Information Retrieval system results, and conversely, search results can potentially reinforce existing societal biases. Recent research has therefore focused on developing methods for quantifying and mitigating bias in search results and applied them to contemporary retrieval systems that leverage transformer-based language models. In the present work, we expand this direction of research by considering bias mitigation within a framework for contextual document embedding reranking. In this framework, the transformer-based query encoder is optimized for relevance ranking through a list-wise objective, by jointly scoring for the same query a large set of candidate document embeddings in the context of one another, instead of in isolation. At the same time, we impose a regularization loss which penalizes highly scoring documents that deviate from neutrality with respect to a protected attribute (e.g., gender). Our approach for bias mitigation is end-to-end differentiable and efficient. Compared to the existing alternatives for deep neural retrieval architectures, which are based on adversarial training, we demonstrate that it can attain much stronger bias mitigation/fairness. At the same time, for the same amount of bias mitigation, it offers significantly better relevance performance (utility). Crucially, our method allows for a more finely controllable and predictable intensity of bias mitigation, which is essential for practical deployment in production systems.|社会偏见可以影响信息检索系统的结果，相反，搜索结果可能会加强现有的社会偏见。因此，最近的研究侧重于开发用于量化和减轻搜索结果偏差的方法，并将其应用于利用基于转换器的语言模型的当代检索系统。在本文的工作中，我们扩展了这个研究方向，在上下文文档嵌入重排序的框架内考虑了偏差缓解。在这个框架中，基于转换器的查询编码器通过列表目标优化相关性排序，为同一个查询联合评分一大组候选文档嵌入在另一个上下文中，而不是孤立。与此同时，我们强制规范化的损失，惩罚高得分的文件偏离中立方面的保护属性(例如，性别)。我们的减少偏差的方法是端到端可微和有效的。与已有的基于对抗训练的深度神经检索结构相比，我们证明了该结构可以获得更强的偏差缓解/公平性。同时，对于相同数量的偏差缓解，它提供了明显更好的相关性能(效用)。至关重要的是，我们的方法允许更精细地控制和可预测的偏差缓解强度，这对于生产系统中的实际部署是必不可少的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Bias+in+Search+Results+Through+Contextual+Document+Reranking+and+Neutrality+Regularization)|3|
|[Curriculum Contrastive Context Denoising for Few-shot Conversational Dense Retrieval](https://doi.org/10.1145/3477495.3531961)|Kelong Mao, Zhicheng Dou, Hongjin Qian|Renmin University of China, Beijing, China; Renmin University of China & Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China|Conversational search is a crucial and promising branch in information retrieval. In this paper, we reveal that not all historical conversational turns are necessary for understanding the intent of the current query. The redundant noisy turns in the context largely hinder the improvement of search performance. However, enhancing the context denoising ability for conversational search is quite challenging due to data scarcity and the steep difficulty for simultaneously learning conversational query encoding and context denoising. To address these issues, in this paper, we present a novel Curriculum cOntrastive conTExt Denoising framework, COTED, towards few-shot conversational dense retrieval. Under a curriculum training order, we progressively endow the model with the capability of context denoising via contrastive learning between noised samples and denoised samples generated by a new conversation data augmentation strategy. Three curriculums tailored to conversational search are exploited in our framework. Extensive experiments on two few-shot conversational search datasets, i.e., CAsT-19 and CAsT-20, validate the effectiveness and superiority of our method compared with the state-of-the-art baselines.|会话搜索是信息检索中一个重要而有前途的分支。本文揭示了并非所有的历史会话转折都是理解当前查询意图的必要条件。上下文中的冗余噪声转折很大程度上阻碍了搜索性能的提高。然而，由于数据的稀缺性和同时学习会话查询编码和上下文去噪的困难性，提高会话搜索的上下文去噪能力是一个相当具有挑战性的问题。为了解决这些问题，本文提出了一种新的课程对比语境去噪框架 COTED，该框架旨在实现少镜头的会话密集检索。在课程训练顺序下，我们逐步赋予该模型通过对比学习去除噪声样本和通过一种新的会话数据增强策略产生的去噪样本的上下文去噪能力。在我们的框架中开发了三个适合会话搜索的课程。在两个少量会话搜索数据集，即 CAsT-19和 CAsT-20上的广泛实验验证了我们的方法与最先进的基线相比的有效性和优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curriculum+Contrastive+Context+Denoising+for+Few-shot+Conversational+Dense+Retrieval)|3|
|[Decoupled Side Information Fusion for Sequential Recommendation](https://doi.org/10.1145/3477495.3531963)|Yueqi Xie, Peilin Zhou, Sunghun Kim|Upstage, Hong Kong, Hong Kong; HKUST, Hong Kong, Hong Kong|Side information fusion for sequential recommendation (SR) aims to effectively leverage various side information to enhance the performance of next-item prediction. Most state-of-the-art methods build on self-attention networks and focus on exploring various solutions to integrate the item embedding and side information embeddings before the attention layer. However, our analysis shows that the early integration of various types of embeddings limits the expressiveness of attention matrices due to a rank bottleneck and constrains the flexibility of gradients. Also, it involves mixed correlations among the different heterogeneous information resources, which brings extra disturbance to attention calculation. Motivated by this, we propose Decoupled Side Information Fusion for Sequential Recommendation (DIF-SR), which moves the side information from the input to the attention layer and decouples the attention calculation of various side information and item representation. We theoretically and empirically show that the proposed solution allows higher-rank attention matrices and flexible gradients to enhance the modeling capacity of side information fusion. Also, auxiliary attribute predictors are proposed to further activate the beneficial interaction between side information and item representation learning. Extensive experiments on four real-world datasets demonstrate that our proposed solution stably outperforms state-of-the-art SR models. Further studies show that our proposed solution can be readily incorporated into current attention-based SR models and significantly boost performance. Our source code is available at https://github.com/AIM-SE/DIF-SR.|序贯推荐侧信息融合是为了有效地利用各种侧信息来提高下一个项目的预测性能。大多数最新的方法都是建立在自我注意网络的基础上，着重于探索各种解决方案，以整合注意层之前的项目嵌入和侧信息嵌入。然而，我们的分析表明，由于等级瓶颈的存在，各种嵌入类型的早期集成限制了注意矩阵的表达能力，同时也限制了梯度的灵活性。此外，它还涉及到不同异质信息资源之间的混合相关，给注意计算带来额外的干扰。在此基础上，提出了基于解耦的序贯推荐侧信息融合方法(DIF-SR) ，该方法将侧信息从输入层移动到注意层，并对各侧信息的注意计算和项目表示进行解耦。理论和实验结果表明，该方法允许高阶注意矩阵和灵活的梯度，提高了侧向信息融合的建模能力。同时，提出了辅助属性预测器，以进一步激活侧信息与项目表征学习之间的有益交互作用。在四个真实世界数据集上的大量实验表明，我们提出的解决方案稳定地优于最先进的 SR 模型。进一步的研究表明，我们提出的解决方案可以很容易地纳入目前的注意为基础的 SR 模型，并显着提高性能。我们的源代码可以在 https://github.com/aim-se/dif-sr 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Side+Information+Fusion+for+Sequential+Recommendation)|3|
|[Is News Recommendation a Sequential Recommendation Task?](https://doi.org/10.1145/3477495.3531862)|Chuhan Wu, Fangzhao Wu, Tao Qi, Chenliang Li, Yongfeng Huang|York University, Toronto, Canada; Renmin University of China, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|For sequential recommendation, it is essential to capture and predict future or long-term user preference for generating accurate recommendation over time. To improve the predictive capacity, we adopt reinforcement learning (RL) for developing effective sequential recommenders. However, user-item interaction data is likely to be sparse, complicated and time-varying. It is not easy to directly apply RL techniques to improve the performance of sequential recommendation.

Inspired by the availability of knowledge graph (KG), we propose a novel Knowledge-guidEd Reinforcement Learning model (KERL for short) for fusing KG information into a RL framework for sequential recommendation. Specifically, we formalize the sequential recommendation task as a Markov Decision Process (MDP), and make three major technical extensions in this framework, including state representation, reward function and learning algorithm. First, we propose to enhance the state representations with KG information considering both exploitation and exploration. Second, we carefully design a composite reward function that is able to compute both sequence- and knowledge-level rewards. Third, we propose a new algorithm for more effectively learning the proposed model. To our knowledge, it is the first time that knowledge information has been explicitly discussed and utilized in RL-based sequential recommenders, especially for the exploration process. Extensive experiment results on both next-item and next-session recommendation tasks show that our model can significantly outperform the baselines on four real-world datasets.|对于连续推荐，必须捕获和预测未来或长期的用户偏好，以便随着时间的推移产生准确的推荐。为了提高预测能力，我们采用强化学习(RL)来开发有效的顺序推荐系统。然而，用户项交互数据可能是稀疏的、复杂的和时变的。直接应用 RL 技术来提高顺序推荐的性能并不容易。受到知识图表(kG)的启发，我们提出了一种新的知识引导强化学习模型(简称 KERL) ，用于将 kG 信息融合到一个 RL 框架中，用于连续推荐。具体来说，我们将顺序推荐任务形式化为一个马可夫决策过程(mDP) ，并在这个框架中进行了三个主要的技术扩展，包括状态表示、奖励函数和学习算法。首先，我们提出了利用 KG 信息同时考虑开发和探索的方法来增强状态表示。其次，我们仔细设计了一个复合奖励函数，它能够计算序列和知识水平的奖励。第三，我们提出了一个新的算法，以更有效地学习所提出的模型。据我们所知，知识信息首次被明确地讨论和利用在基于 RL 的顺序推荐系统中，特别是在探索过程中。对下一个项目和下一个会话推荐任务的大量实验结果表明，我们的模型可以显著优于四个真实世界数据集的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+News+Recommendation+a+Sequential+Recommendation+Task?)|3|
|[Dual Contrastive Network for Sequential Recommendation](https://doi.org/10.1145/3477495.3531918)|Guanyu Lin, Chen Gao, Yinfeng Li, Yu Zheng, Zhiheng Li, Depeng Jin, Yong Li|Tsinghua University, Beijing, China|Widely applied in today's recommender systems, sequential recommendation predicts the next interacted item for a given user via his/her historical item sequence. However, sequential recommendation suffers data sparsity issue like most recommenders. To extract auxiliary signals from the data, some recent works exploit self-supervised learning to generate augmented data via dropout strategy, which, however, leads to sparser sequential data and obscure signals. In this paper, we propose D ual C ontrastive N etwork (DCN) to boost sequential recommendation, from a new perspective of integrating auxiliary user-sequence for items. Specifically, we propose two kinds of contrastive learning. The first one is the dual representation contrastive learning that minimizes the distances between embeddings and sequence-representations of users/items. The second one is the dual interest contrastive learning which aims to self-supervise the static interest with the dynamic interest of next item prediction via auxiliary training. We also incorporate the auxiliary task of predicting next user for a given item's historical user sequence, which can capture the trends of items preferred by certain types of users. Experiments on benchmark datasets verify the effectiveness of our proposed method. Further ablation study also illustrates the boosting effect of the proposed components upon different sequential models.|顺序推荐在当今的推荐系统中被广泛应用，它通过用户的历史项目顺序来预测给定用户的下一个交互项目。然而，与大多数推荐程序一样，顺序推荐也存在数据稀疏的问题。为了从数据中提取辅助信号，最近的一些工作利用自监督学习通过丢失策略生成增强数据，但是这样会导致序列数据更稀疏，信号更模糊。本文从集成项目辅助用户序列的新角度出发，提出了 D-C 对比 N 网络(DCN)来增强序列推荐。具体来说，我们提出了两种对比学习。第一种是双重表示对比学习，它最小化了嵌入和用户/项目序列表示之间的距离。第二种是双兴趣对比学习，目的是通过辅助训练对静态兴趣和下一项预测的动态兴趣进行自我监督。我们还结合了辅助任务，即预测给定项目的历史用户序列的下一个用户，这可以捕获某些类型的用户喜欢的项目的趋势。在基准数据集上的实验验证了该方法的有效性。进一步的消融研究也说明了所提出的组件对不同序列模型的增强效应。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Contrastive+Network+for+Sequential+Recommendation)|3|
|[PKG: A Personal Knowledge Graph for Recommendation](https://doi.org/10.1145/3477495.3531671)|Yu Yang, Jiangxu Lin, Xiaolian Zhang, Meng Wang|Southeast University, Nanjing, China; Huawei Technologies Co. Ltd., Shenzhen, China|Mobile internet users generate personal data on the devices all the time in this era. In this paper, we demonstrate a novel system for integrating the data of a user from different sources into a Personal Knowledge Graph, i.e., PKG. We show how a user's intention can be detected and how the personal data can be aligned and connected by the user behaviors. The constructed PKG allows the system makes reasonable and accurate recommendations for users by a "neural + symbolic'' approach across different services. Our system is shown in https://youtu.be/hWuo8KCDrto.|在这个时代，移动互联网用户一直在设备上生成个人数据。在本文中，我们展示了一个新的系统来整合来自不同来源的用户的数据到一个个人知识图，即 PKG。我们展示了如何检测用户的意图，以及如何通过用户行为来校准和连接个人数据。构建的 PKG 允许系统通过“神经 + 符号”的方法跨越不同的服务为用户提供合理和准确的建议。我们的系统以 https://youtu.be/hwuo8kcdrto 显示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PKG:+A+Personal+Knowledge+Graph+for+Recommendation)|3|
|[Co-training Disentangled Domain Adaptation Network for Leveraging Popularity Bias in Recommenders](https://doi.org/10.1145/3477495.3531952)|Zhihong Chen, Jiawei Wu, Chenliang Li, Jingxu Chen, Rong Xiao, Binqiang Zhao|Wuhan University, Wuhan, China; Alibaba Group, Hangzhou, China|Recommender system usually faces popularity bias. From the popularity distribution shift perspective, the normal paradigm trained on exposed items (most are hot items) identifies that recommending popular items more frequently can achieve lower loss, thus injecting popularity information into item property embedding, e.g., id embedding. From the long-tail distribution shift perspective, the sparse interactions of long-tail items lead to insufficient learning of them. The resultant distribution discrepancy between hot and long-tail items would not only inherit the bias, but also amplify the bias. Existing work addresses this issue with inverse propensity scoring (IPS) or causal embeddings. However, we argue that not all popularity biases mean bad effects, i.e., some items show higher popularity due to better quality or conform to current trends, which deserve more recommendations. Blindly seeking unbiased learning may inhibit high-quality or fashionable items. To make better use of the popularity bias, we propose a co-training disentangled domain adaptation network (CD$^2$AN), which can co-train both biased and unbiased models. Specifically, for popularity distribution shift, CD$^2$AN disentangles item property representation and popularity representation from item property embedding. For long-tail distribution shift, we introduce additional unexposed items (most are long-tail items) to align the distribution of hot and long-tail item property representations. Further, from the instances perspective, we carefully design the item similarity regularization to learn comprehensive item representation, which encourages item pairs with more effective co-occurrences patterns to have more similar item property representations. Based on offline evaluations and online A/B tests, we show that CD$^2$AN outperforms the existing debiased solutions. Currently, CD$^2$AN has been successfully deployed at Mobile Taobao App and handling major online traffic.|推荐系统通常面临受欢迎程度的偏见。从受欢迎度分布转移的角度来看，通常对曝光项目(大多数是热门项目)进行训练的范式认为，更频繁地推荐受欢迎项目可以获得更低的损失，从而将受欢迎信息注入项目属性嵌入，例如，ID 嵌入。从长尾分布偏移的角度来看，长尾项目之间稀疏的交互作用导致对它们的学习不足。由此产生的热点项目与长尾项目之间的分布差异不仅会继承偏差，而且会放大偏差。现有的工作解决这个问题的逆倾向评分(IPS)或因果嵌入。然而，我们认为并非所有的流行偏见都意味着负面影响，例如，一些项目由于质量更好或符合当前趋势而显示出更高的流行度，这值得更多的推荐。盲目追求无偏见的学习可能会抑制高质量或时尚的项目。为了更好地利用流行度偏差，我们提出了一种协同训练的去纠缠域自适应网络(CD $^ 2 $AN) ，它可以同时训练有偏和无偏模型。具体地说，对于流行度分布转移，CD $^ 2 $AN 将项目属性表示和流行度表示从项目属性嵌入中分离出来。对于长尾分布转移，我们引入了额外的未公开项(大多数是长尾项)来对齐热点和长尾项属性表示的分布。此外，从实例的角度，我们仔细设计了项目相似性正则化，以学习综合项目表示，鼓励具有更有效的共现模式的项目对具有更多相似的项目属性表示。基于离线评估和在线 A/B 测试，我们表明 CD $^ 2 $AN 优于现有的去偏解决方案。目前，CD $^ 2 $AN 已经成功部署在移动淘宝应用程序上，并处理主要的在线流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-training+Disentangled+Domain+Adaptation+Network+for+Leveraging+Popularity+Bias+in+Recommenders)|3|
|[Multi-Level Interaction Reranking with User Behavior History](https://doi.org/10.1145/3477495.3532026)|Yunjia Xi, Weiwen Liu, Jieming Zhu, Xilong Zhao, Xinyi Dai, Ruiming Tang, Weinan Zhang, Rui Zhang, Yong Yu|Huawei Noah's Ark Lab, Shenzhen, China; ruizhang.info, Shenzhen, China; Shanghai Jiao Tong University, Shanghai, China|As the final stage of the multi-stage recommender system (MRS), reranking directly affects users' experience and satisfaction, thus playing a critical role in MRS. Despite the improvement achieved in the existing work, three issues are yet to be solved. First, users' historical behaviors contain rich preference information, such as users' long and short-term interests, but are not fully exploited in reranking. Previous work typically treats items in history equally important, neglecting the dynamic interaction between the history and candidate items. Second, existing reranking models focus on learning interactions at the item level while ignoring the fine-grained feature-level interactions. Lastly, estimating the reranking score on the ordered initial list before reranking may lead to the early scoring problem, thereby yielding suboptimal reranking performance. To address the above issues, we propose a framework named Multi-level Interaction Reranking (MIR). MIR combines low-level cross-item interaction and high-level set-to-list interaction, where we view the candidate items to be reranked as a set and the users' behavior history in chronological order as a list. We design a novel SLAttention structure for modeling the set-to-list interactions with personalized long-short term interests. Moreover, feature-level interactions are incorporated to capture the fine-grained influence among items. We design MIR in such a way that any permutation of the input items would not change the output ranking, and we theoretically prove it. Extensive experiments on three public and proprietary datasets show that MIR significantly outperforms the state-of-the-art models using various ranking and utility metrics.|作为多阶段推荐系统(MRS)的最后阶段，重新排名直接影响用户的体验和满意度，因此在 MRS 中发挥着关键作用。尽管现有工作已有所改善，但仍有三个问题有待解决。首先，用户的历史行为包含了丰富的偏好信息，如用户的长期和短期兴趣，但在重新排序时没有得到充分的利用。以往的研究通常认为历史条目同等重要，而忽视了历史条目与候选条目之间的动态互动。其次，现有的重新排序模型侧重于项目层面的学习交互，而忽略了细粒度的特征层面的交互。最后，在重新排序之前估计排序初始列表上的重新排序得分可能会导致早期得分问题，从而产生次优的重新排序性能。为了解决上述问题，我们提出了一个名为多级交互重排(MIR)的框架。MIR 结合了低层次的跨项目交互和高层次的集合-列表交互，我们将待重新排序的候选项作为一个集合，将用户的行为历史按照时间顺序作为一个列表。我们设计了一个新颖的空间注意结构，用于建模具有个性化长期短期兴趣的集合列表交互。此外，特征层次的交互作用被合并来捕获项目之间的细粒度影响。我们设计 MIR 的方法使得输入项的任何排列都不会改变输出的排名，并且我们从理论上证明了这一点。对三个公共和专有数据集的大量实验表明，使用各种排名和效用指标，MIR 显著优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Level+Interaction+Reranking+with+User+Behavior+History)|3|
|[RankFlow: Joint Optimization of Multi-Stage Cascade Ranking Systems as Flows](https://doi.org/10.1145/3477495.3532050)|Jiarui Qin, Jiachen Zhu, Bo Chen, Zhirong Liu, Weiwen Liu, Ruiming Tang, Rui Zhang, Yong Yu, Weinan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RankFlow:+Joint+Optimization+of+Multi-Stage+Cascade+Ranking+Systems+as+Flows)|3|
|[Towards Suicide Ideation Detection Through Online Conversational Context](https://doi.org/10.1145/3477495.3532068)|Ramit Sawhney, Shivam Agarwal, Atula Tejaswi Neerkaje, Nikolaos Aletras, Preslav Nakov, Lucie Flek||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Suicide+Ideation+Detection+Through+Online+Conversational+Context)|3|
|[Socially-aware Dual Contrastive Learning for Cold-Start Recommendation](https://doi.org/10.1145/3477495.3531780)|Jing Du, Zesheng Ye, Lina Yao, Bin Guo, Zhiwen Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Socially-aware+Dual+Contrastive+Learning+for+Cold-Start+Recommendation)|3|
|[A Multi-Task Based Neural Model to Simulate Users in Goal Oriented Dialogue Systems](https://doi.org/10.1145/3477495.3531814)|To Eun Kim, Aldo Lipani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Task+Based+Neural+Model+to+Simulate+Users+in+Goal+Oriented+Dialogue+Systems)|3|
|[Investigating Accuracy-Novelty Performance for Graph-based Collaborative Filtering](https://doi.org/10.1145/3477495.3532005)|Minghao Zhao, Le Wu, Yile Liang, Lei Chen, Jian Zhang, Qilin Deng, Kai Wang, Xudong Shen, Tangjie Lv, Runze Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Accuracy-Novelty+Performance+for+Graph-based+Collaborative+Filtering)|3|
|[Learning to Denoise Unreliable Interactions for Graph Collaborative Filtering](https://doi.org/10.1145/3477495.3531889)|Changxin Tian, Yuexiang Xie, Yaliang Li, Nan Yang, Wayne Xin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Denoise+Unreliable+Interactions+for+Graph+Collaborative+Filtering)|3|
|[DAWAR: Diversity-aware Web APIs Recommendation for Mashup Creation based on Correlation Graph](https://doi.org/10.1145/3477495.3531962)|Wenwen Gong, Xuyun Zhang, Yifei Chen, Qiang He, Amin Beheshti, Xiaolong Xu, Chao Yan, Lianyong Qi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAWAR:+Diversity-aware+Web+APIs+Recommendation+for+Mashup+Creation+based+on+Correlation+Graph)|3|
|[Post Processing Recommender Systems with Knowledge Graphs for Recency, Popularity, and Diversity of Explanations](https://doi.org/10.1145/3477495.3532041)|Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Mirko Marras||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post+Processing+Recommender+Systems+with+Knowledge+Graphs+for+Recency,+Popularity,+and+Diversity+of+Explanations)|3|
|[Learning Graph-based Disentangled Representations for Next POI Recommendation](https://doi.org/10.1145/3477495.3532012)|Zhaobo Wang, Yanmin Zhu, Haobing Liu, Chunyang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Graph-based+Disentangled+Representations+for+Next+POI+Recommendation)|3|
|[AutoLossGen: Automatic Loss Function Generation for Recommender Systems](https://doi.org/10.1145/3477495.3531941)|Zelong Li, Jianchao Ji, Yingqiang Ge, Yongfeng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoLossGen:+Automatic+Loss+Function+Generation+for+Recommender+Systems)|3|
|[MGPolicy: Meta Graph Enhanced Off-policy Learning for Recommendations](https://doi.org/10.1145/3477495.3532021)|Xiangmeng Wang, Qian Li, Dianer Yu, Zhichao Wang, Hongxu Chen, Guandong Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MGPolicy:+Meta+Graph+Enhanced+Off-policy+Learning+for+Recommendations)|3|
|[Privacy-Preserving Synthetic Data Generation for Recommendation Systems](https://doi.org/10.1145/3477495.3532044)|Fan Liu, Zhiyong Cheng, Huilin Chen, Yinwei Wei, Liqiang Nie, Mohan S. Kankanhalli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Synthetic+Data+Generation+for+Recommendation+Systems)|3|
|[Self-Guided Learning to Denoise for Robust Recommendation](https://doi.org/10.1145/3477495.3532059)|Yunjun Gao, Yuntao Du, Yujia Hu, Lu Chen, Xinjun Zhu, Ziquan Fang, Baihua Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Guided+Learning+to+Denoise+for+Robust+Recommendation)|3|
|[Faster Learned Sparse Retrieval with Guided Traversal](https://doi.org/10.1145/3477495.3531774)|Antonio Mallia, Joel Mackenzie, Torsten Suel, Nicola Tonellotto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Faster+Learned+Sparse+Retrieval+with+Guided+Traversal)|3|
|[Analysing the Robustness of Dual Encoders for Dense Retrieval Against Misspellings](https://doi.org/10.1145/3477495.3531818)|Georgios Sidiropoulos, Evangelos Kanoulas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analysing+the+Robustness+of+Dual+Encoders+for+Dense+Retrieval+Against+Misspellings)|3|
|[Cross-Probe BERT for Fast Cross-Modal Search](https://doi.org/10.1145/3477495.3531826)|Tan Yu, Hongliang Fei, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Probe+BERT+for+Fast+Cross-Modal+Search)|3|
|[DH-HGCN: Dual Homogeneity Hypergraph Convolutional Network for Multiple Social Recommendations](https://doi.org/10.1145/3477495.3531828)|Jiadi Han, Qian Tao, Yufei Tang, Yuhan Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DH-HGCN:+Dual+Homogeneity+Hypergraph+Convolutional+Network+for+Multiple+Social+Recommendations)|3|
|[To Interpolate or not to Interpolate: PRF, Dense and Sparse Retrievers](https://doi.org/10.1145/3477495.3531884)|Hang Li, Shuai Wang, Shengyao Zhuang, Ahmed Mourad, Xueguang Ma, Jimmy Lin, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=To+Interpolate+or+not+to+Interpolate:+PRF,+Dense+and+Sparse+Retrievers)|3|
|[Selective Fairness in Recommendation via Prompts](https://doi.org/10.1145/3477495.3531913)|Yiqing Wu, Ruobing Xie, Yongchun Zhu, Fuzhen Zhuang, Xiang Ao, Xu Zhang, Leyu Lin, Qing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Selective+Fairness+in+Recommendation+via+Prompts)|3|
|[ReLoop: A Self-Correction Continual Learning Loop for Recommender Systems](https://doi.org/10.1145/3477495.3531922)|Guohao Cai, Jieming Zhu, Quanyu Dai, Zhenhua Dong, Xiuqiang He, Ruiming Tang, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReLoop:+A+Self-Correction+Continual+Learning+Loop+for+Recommender+Systems)|3|
|[SoChainDB: A Database for Storing and Retrieving Blockchain-Powered Social Network Data](https://doi.org/10.1145/3477495.3531735)|Hoang H. Nguyen, Dmytro Bozhkov, Zahra Ahmadi, NhatMinh Nguyen, ThanhNam Doan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SoChainDB:+A+Database+for+Storing+and+Retrieving+Blockchain-Powered+Social+Network+Data)|3|
|[From Little Things Big Things Grow: A Collection with Seed Studies for Medical Systematic Review Literature Search](https://doi.org/10.1145/3477495.3531748)|Shuai Wang, Harrisen Scells, Justin Clark, Bevan Koopman, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Little+Things+Big+Things+Grow:+A+Collection+with+Seed+Studies+for+Medical+Systematic+Review+Literature+Search)|3|
|[Assessing Student's Dynamic Knowledge State by Exploring the Question Difficulty Effect](https://doi.org/10.1145/3477495.3531939)|Shuanghong Shen, Zhenya Huang, Qi Liu, Yu Su, Shijin Wang, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Student's+Dynamic+Knowledge+State+by+Exploring+the+Question+Difficulty+Effect)|3|
|[MetaCare++: Meta-Learning with Hierarchical Subtyping for Cold-Start Diagnosis Prediction in Healthcare Data](https://doi.org/10.1145/3477495.3532020)|Yanchao Tan, Carl Yang, Xiangyu Wei, Chaochao Chen, Weiming Liu, Longfei Li, Jun Zhou, Xiaolin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaCare++:+Meta-Learning+with+Hierarchical+Subtyping+for+Cold-Start+Diagnosis+Prediction+in+Healthcare+Data)|3|
|[Generalizing to the Future: Mitigating Entity Bias in Fake News Detection](https://doi.org/10.1145/3477495.3531816)|Yongchun Zhu, Qiang Sheng, Juan Cao, Shuokai Li, Danding Wang, Fuzhen Zhuang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalizing+to+the+Future:+Mitigating+Entity+Bias+in+Fake+News+Detection)|3|
|[ORCAS-I: Queries Annotated with Intent using Weak Supervision](https://doi.org/10.1145/3477495.3531737)|Daria Alexander, Wojciech Kusa, Arjen P. de Vries||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ORCAS-I:+Queries+Annotated+with+Intent+using+Weak+Supervision)|3|
|[Unified Dialog Model Pre-training for Task-Oriented Dialog Understanding and Generation](https://doi.org/10.1145/3477495.3532069)|Wanwei He, Yinpei Dai, Min Yang, Jian Sun, Fei Huang, Luo Si, Yongbin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Dialog+Model+Pre-training+for+Task-Oriented+Dialog+Understanding+and+Generation)|3|
|[Introducing Problem Schema with Hierarchical Exercise Graph for Knowledge Tracing](https://doi.org/10.1145/3477495.3532004)|Hanshuang Tong, Zhen Wang, Yun Zhou, Shiwei Tong, Wenyuan Han, Qi Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Introducing+Problem+Schema+with+Hierarchical+Exercise+Graph+for+Knowledge+Tracing)|3|
|[A Flexible Framework for Offline Effectiveness Metrics](https://doi.org/10.1145/3477495.3531924)|Alistair Moffat, Joel Mackenzie, Paul Thomas, Leif Azzopardi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Flexible+Framework+for+Offline+Effectiveness+Metrics)|3|
|[Incorporating Context Graph with Logical Reasoning for Inductive Relation Prediction](https://doi.org/10.1145/3477495.3531996)|Qika Lin, Jun Liu, Fangzhi Xu, Yudai Pan, Yifan Zhu, Lingling Zhang, Tianzhe Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Context+Graph+with+Logical+Reasoning+for+Inductive+Relation+Prediction)|3|
|[Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion](https://doi.org/10.1145/3477495.3531992)|Xiang Chen, Ningyu Zhang, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, Fei Huang, Luo Si, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hybrid+Transformer+with+Multi-level+Fusion+for+Multimodal+Knowledge+Graph+Completion)|3|
|[HTKG: Deep Keyphrase Generation with Neural Hierarchical Topic Guidance](https://doi.org/10.1145/3477495.3531990)|Yuxiang Zhang, Tao Jiang, Tianyu Yang, Xiaoli Li, Suge Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HTKG:+Deep+Keyphrase+Generation+with+Neural+Hierarchical+Topic+Guidance)|3|
|[Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning](https://doi.org/10.1145/3477495.3532016)|Fangzhi Xu, Jun Liu, Qika Lin, Yudai Pan, Lingling Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logiformer:+A+Two-Branch+Graph+Transformer+Network+for+Interpretable+Logical+Reasoning)|3|
|[Constrained Sequence-to-Tree Generation for Hierarchical Text Classification](https://doi.org/10.1145/3477495.3531765)|Chao Yu, Yi Shen, Yue Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constrained+Sequence-to-Tree+Generation+for+Hierarchical+Text+Classification)|3|
|[Answering Count Queries with Explanatory Evidence](https://doi.org/10.1145/3477495.3531870)|Shrestha Ghosh, Simon Razniewski, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Answering+Count+Queries+with+Explanatory+Evidence)|3|
|[Space4HGNN: A Novel, Modularized and Reproducible Platform to Evaluate Heterogeneous Graph Neural Network](https://doi.org/10.1145/3477495.3531720)|Tianyu Zhao, Cheng Yang, Yibo Li, Quan Gan, Zhenyi Wang, Fengqi Liang, Huan Zhao, Yingxia Shao, Xiao Wang, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Space4HGNN:+A+Novel,+Modularized+and+Reproducible+Platform+to+Evaluate+Heterogeneous+Graph+Neural+Network)|3|
|[NeuralKG: An Open Source Library for Diverse Representation Learning of Knowledge Graphs](https://doi.org/10.1145/3477495.3531669)|Wen Zhang, Xiangnan Chen, Zhen Yao, Mingyang Chen, Yushan Zhu, Hongtao Yu, Yufeng Huang, Yajing Xu, Ningyu Zhang, Zezhong Xu, Zonggang Yuan, Feiyu Xiong, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeuralKG:+An+Open+Source+Library+for+Diverse+Representation+Learning+of+Knowledge+Graphs)|3|
|[Deep Knowledge Graph Representation Learning for Completion, Alignment, and Question Answering](https://doi.org/10.1145/3477495.3532679)|Soumen Chakrabarti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Knowledge+Graph+Representation+Learning+for+Completion,+Alignment,+and+Question+Answering)|3|
|[HIEN: Hierarchical Intention Embedding Network for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531988)|Zuowu Zheng, Changwang Zhang, Xiaofeng Gao, Guihai Chen|Tencent Inc., Shenzhen, China; Shanghai Jiao Tong University, Shanghai, China|Click-through rate (CTR) prediction plays an important role in online advertising and recommendation systems, which aims at estimating the probability of a user clicking on a specific item. Feature interaction modeling and user interest modeling methods are two popular domains in CTR prediction, and they have been studied extensively in recent years. However, these methods still suffer from two limitations. First, traditional methods regard item attributes as ID features, while neglecting structure information and relation dependencies among attributes. Second, when mining user interests from user-item interactions, current models ignore user intents and item intents for different attributes, which lacks interpretability. Based on this observation, in this paper, we propose a novel approach Hierarchical Intention Embedding Network (HIEN), which considers dependencies of attributes based on bottom-up tree aggregation in the constructed attribute graph. HIEN also captures user intents for different item attributes as well as item intents based on our proposed hierarchical attention mechanism. Extensive experiments on both public and production datasets show that the proposed model significantly outperforms the state-of-the-art methods. In addition, HIEN can be applied as an input module to state-of-the-art CTR prediction methods, bringing further performance lift for these existing models that might already be intensively used in real systems.|在在线广告和推荐系统中，点进率预测(ctrl)扮演着重要的角色，其目的是估计用户点击特定项目的概率。特征交互建模和用户兴趣建模是 CTR 预测的两个热门领域，近年来得到了广泛的研究。然而，这些方法仍然存在两个局限性。首先，传统的方法把项目属性看作 ID 特征，而忽略了结构信息和属性之间的关系依赖。其次，当从用户-项目交互中挖掘用户兴趣时，目前的模型忽略了不同属性的用户意图和项目意图，缺乏可解释性。在此基础上，本文提出了一种新的层次意图嵌入网络(HIEN)方法，该方法在构造的属性图中考虑基于自底向上树聚集的属性依赖关系。HIEN 还根据我们提出的分层注意机制捕获不同项目属性的用户意图以及项目意图。在公共数据集和生产数据集上的大量实验表明，所提出的模型明显优于最先进的方法。此外，HIEN 还可以作为最先进的 CTR 预测方法的输入模块，为这些可能已经在实际系统中广泛使用的现有模型带来进一步的性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HIEN:+Hierarchical+Intention+Embedding+Network+for+Click-Through+Rate+Prediction)|2|
|[Neural Query Synthesis and Domain-Specific Ranking Templates for Multi-Stage Clinical Trial Matching](https://doi.org/10.1145/3477495.3531853)|Ronak Pradeep, Yilin Li, Yuetong Wang, Jimmy Lin|University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, ON, Canada|In this work, we propose an effective multi-stage neural ranking system for the clinical trial matching problem. First, we introduce NQS, a neural query synthesis method that leverages a zero-shot document expansion model to generate multiple sentence-long queries from lengthy patient descriptions. These queries are independently issued to a search engine and the results are fused. We find that on the TREC 2021 Clinical Trials Track, this method outperforms strong traditional baselines like BM25 and BM25 + RM3 by about 12 points in [email protected] , a relative improvement of 34%. This simple method is so effective that even a state-of-the-art neural relevance ranking method trained on the medical subset of MS MARCO passage, when reranking the results of NQS, fails to improve on the ranked list. Second, we introduce a two-stage neural reranking pipeline trained on clinical trial matching data using tailored ranking templates. In this setting, we can train a pointwise reranker using just 1.1k positive examples and obtain effectiveness improvements over NQS by 24 points. This end-to-end multi-stage system demonstrates a 20% relative effectiveness gain compared to the second-best submission at TREC 2021, making it an important step towards better automated clinical trial matching.|在这项工作中，我们提出了一个有效的多阶段神经排序系统的临床试验匹配问题。首先，我们介绍了 NQS，这是一种神经查询合成方法，它利用一个零拍文档扩展模型，从冗长的患者描述中生成多个句子长的查询。这些查询被独立地发送给搜索引擎，并且结果被融合。我们发现，在 TREC 2021临床试验跟踪中，这种方法比强大的传统基线如 BM25和 BM25 + RM3在[ email protected ]中高出约12分，相对提高了34% 。这种简单的方法是如此有效，以至于即使是在 MS MARCO 通道的医学子集上训练的最先进的神经相关性排序方法，在对 NQS 的结果重新排序时，也不能改进排序列表。其次，我们介绍了一个两阶段的神经重新排序管道训练临床试验匹配数据使用定制的排序模板。在这种情况下，我们可以训练一个点态的重新排序使用只有1.1 k 正的例子，并获得24点的有效性改进超过 NQS。这种端到端的多阶段系统与 TREC 2021年第二好的提交相比，显示出20% 的相对有效性增益，这使得它朝着更好的自动化临床试验匹配迈出了重要的一步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Query+Synthesis+and+Domain-Specific+Ranking+Templates+for+Multi-Stage+Clinical+Trial+Matching)|2|
|[Improving Contrastive Learning of Sentence Embeddings with Case-Augmented Positives and Retrieved Negatives](https://doi.org/10.1145/3477495.3531823)|Wei Wang, Liangzhu Ge, Jingqiao Zhang, Cheng Yang|Alibaba Group, Hangzhou, China|Following SimCSE, contrastive learning based methods have achieved the state-of-the-art (SOTA) performance in learning sentence embeddings. However, the unsupervised contrastive learning methods still lag far behind the supervised counterparts. We attribute this to the quality of positive and negative samples, and aim to improve both. Specifically, for positive samples, we propose switch-case augmentation to flip the case of the first letter of randomly selected words in a sentence. This is to counteract the intrinsic bias of pre-trained token embeddings to frequency, word cases and subwords. For negative samples, we sample hard negatives from the whole dataset based on a pre-trained language model. Combining the above two methods with SimCSE, our proposed Contrastive learning with Augmented and Retrieved Data for Sentence embedding (CARDS) method significantly surpasses the current SOTA on STS benchmarks in the unsupervised setting.|继 SimCSE 之后，基于对比学习的方法在学习句子嵌入方面取得了先进的性能。然而，无监督对比学习方法仍然远远落后于有监督对比学习方法。我们将此归因于阳性和阴性样本的质量，并致力于改善这两种情况。特别地，对于正样本，我们提出开关格增强来翻转句子中随机选择的单词的第一个字母的情况。这是为了抵消预先训练的标记嵌入对频率、词例和子词的内在偏差。对于阴性样本，我们基于预训练语言模型从整个数据集中抽取硬阴性样本。将上述两种方法与 SimCSE 相结合，我们提出的对比学习与增强和检索数据的句子嵌入(CARDS)方法显着超过目前的 SOTA 的 STS 基准在无监督的设置。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Contrastive+Learning+of+Sentence+Embeddings+with+Case-Augmented+Positives+and+Retrieved+Negatives)|2|
|[Diversity Vs Relevance: A Practical Multi-objective Study in Luxury Fashion Recommendations](https://doi.org/10.1145/3477495.3531866)|João Sá, Vanessa Queiroz Marinho, Ana Rita Magalhães, Tiago Lacerda, Diogo Gonçalves|Farfetch, London, United Kingdom|Personalized algorithms focusing uniquely on accuracy might provide highly relevant recommendations, but the recommended items could be too similar to current users' preferences. Therefore, recommenders might prevent users from exploring new products and brands (filter bubbles). This is especially critical for luxury fashion recommendations because luxury shoppers expect to discover exclusive and rare items. Thus, recommender systems for fashion need to consider diversity and elevate the shopping experience by recommending new brands and products from the catalog. In this work, we explored a handful of diversification strategies to rerank the output of a relevance-focused recommender system. Subsequently, we conducted a multi-objective offline experiment optimizing for relevance and diversity simultaneously. We measured diversity with commonly used metrics such as coverage, serendipity, and neighborhood distance, whereas, for relevance, we selected ranking metrics such as recall. The best diversification strategy offline improved user engagement by 2% in click-through rate and presented an uplift of 46% in distinct brands recommended when AB tested against real users. These results reinforced the importance of considering accuracy and diversity metrics when developing a recommender system.|专注于准确性的个性化算法可能会提供高度相关的推荐，但推荐的项目可能与当前用户的偏好过于相似。因此，推荐者可能会阻止用户探索新的产品和品牌(过滤气泡)。这对于奢侈品时尚推荐来说尤其重要，因为奢侈品消费者希望发现独一无二的稀有物品。因此，时尚推荐系统需要考虑多样性，并通过推荐目录中的新品牌和产品来提升购物体验。在这项工作中，我们探索了一些多样化策略，以重新排列以相关性为中心的推荐系统的产出。随后，我们进行了多目标离线实验，同时对相关性和多样性进行了优化。我们使用常用的指标(如覆盖率、意外发现和邻近距离)来衡量多样性，而对于相关性，我们选择了排名指标(如回忆)。线下最佳多样化策略提高了2% 的用户参与点进率，当 AB 公司对真实用户进行测试时，推荐的不同品牌的用户参与度提高了46% 。这些结果强调了在开发推荐系统时考虑准确性和多样性指标的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diversity+Vs+Relevance:+A+Practical+Multi-objective+Study+in+Luxury+Fashion+Recommendations)|2|
|[Exploiting Variational Domain-Invariant User Embedding for Partially Overlapped Cross Domain Recommendation](https://doi.org/10.1145/3477495.3531975)|Weiming Liu, Xiaolin Zheng, Jiajie Su, Mengling Hu, Yanchao Tan, Chaochao Chen|Zhejiang University, Hangzhou, China|Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge to solve the cold-start problem in recommender systems. Most of the existing CDR models assume that both the source and target domains share the same overlapped user set for knowledge transfer. However, only few proportion of users simultaneously activate on both the source and target domains in practical CDR tasks. In this paper, we focus on the Partially Overlapped Cross-Domain Recommendation (POCDR) problem, that is, how to leverage the information of both the overlapped and non-overlapped users to improve recommendation performance. Existing approaches cannot fully utilize the useful knowledge behind the non-overlapped users across domains, which limits the model performance when the majority of users turn out to be non-overlapped. To address this issue, we propose an end-to-end Dual-autoencoder with Variational Domain-invariant Embedding Alignment (VDEA) model, a cross-domain recommendation framework for the POCDR problem, which utilizes dual variational autoencoders with both local and global embedding alignment for exploiting domain-invariant user embedding. VDEA first adopts variational inference to capture collaborative user preferences, and then utilizes Gromov-Wasserstein distribution co-clustering optimal transport to cluster the users with similar rating interaction behaviors. Our empirical studies on Douban and Amazon datasets demonstrate that VDEA significantly outperforms the state-of-the-art models, especially under the POCDR setting.|跨域推荐(CDR)是一种利用不同领域知识解决推荐系统冷启动问题的方法。现有的 CDR 模型大多假设源域和目标域共享相同的重叠用户集进行知识转移。然而，在实际的 CDR 任务中，只有少数用户在源域和目标域同时激活。本文主要研究部分重叠跨域推荐(POCDR)问题，即如何利用重叠用户和非重叠用户的信息来提高推荐性能。现有的方法不能充分利用跨领域非重叠用户背后的有用知识，这限制了大多数用户不重叠时的模型性能。针对这一问题，本文提出了一种基于变分域不变嵌入对齐(VDEA)模型的端到端双变分自动编码器，该模型利用具有局部和全局嵌入对齐的双变分自动编码器进行域不变用户嵌入。VDEA 首先采用变分推理获取协同用户偏好，然后利用 Gromov-Wasserstein 分布协聚类最优传输对具有相似评分交互行为的用户进行聚类。我们对 Douban 和亚马逊数据集的实证研究表明，VDEA 显著优于最先进的模型，特别是在 POCDR 设置下。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Variational+Domain-Invariant+User+Embedding+for+Partially+Overlapped+Cross+Domain+Recommendation)|2|
|[Variational Reasoning about User Preferences for Conversational Recommendation](https://doi.org/10.1145/3477495.3532077)|Zhaochun Ren, Zhi Tian, Dongdong Li, Pengjie Ren, Liu Yang, Xin Xin, Huasheng Liang, Maarten de Rijke, Zhumin Chen|Shandong University, Qingdao, China; WeChat, Tencent, Shenzhen, China; University of Amsterdam, Amsterdam, Netherlands|Conversational recommender systems (CRSs) provide recommendations through interactive conversations. CRSs typically provide recommendations through relatively straightforward interactions, where the system continuously inquires about a user's explicit attribute-aware preferences and then decides which items to recommend. In addition, topic tracking is often used to provide naturally sounding responses. However, merely tracking topics is not enough to recognize a user's real preferences in a dialogue. In this paper, we address the problem of accurately recognizing and maintaining user preferences in CRSs. Three challenges come with this problem: (1) An ongoing dialogue only provides the user's short-term feedback; (2) Annotations of user preferences are not available; and (3) There may be complex semantic correlations among items that feature in a dialogue. We tackle these challenges by proposing an end-to-end variational reasoning approach to the task of conversational recommendation. We model both long-term preferences and short-term preferences as latent variables with topical priors for explicit long-term and short-term preference exploration, respectively. We use an efficient stochastic gradient variational Bayesian (SGVB) estimator for optimizing the derived evidence lower bound. A policy network is then used to predict topics for a clarification utterance or items for a recommendation response. The use of explicit sequences of preferences with multi-hop reasoning in a heterogeneous knowledge graph helps to provide more accurate conversational recommendation results. Extensive experiments conducted on two benchmark datasets show that our proposed method outperforms state-of-the-art baselines in terms of both objective and subjective evaluation metric|会话推荐系统(CRS)通过交互式对话提供推荐。CRS 通常通过相对简单的交互提供推荐，系统不断地查询用户的明确的属性感知偏好，然后决定推荐哪些项目。此外，主题跟踪通常用于提供听起来很自然的回答。但是，仅仅跟踪主题不足以识别用户在对话中的真实偏好。在本文中，我们解决了准确识别和维护用户偏好的问题。这个问题带来了三个挑战: (1)持续的对话只提供用户的短期反馈; (2)用户偏好的注释不可用; (3)对话中的项目之间可能存在复杂的语义关联。我们通过提出一种端到端的变分推理方法来解决这些挑战。我们将长期偏好和短期偏好分别建模为具有主题先验的潜在变量，用于显性长期和短期偏好探索。我们使用一个有效的随机梯度变分贝叶斯(SGVB)估计器来优化导出的证据下界。然后使用策略网络来预测澄清话语的主题或推荐响应的项目。在异构知识图中使用多跳推理的显式偏好序列有助于提供更准确的会话推荐结果。在两个基准数据集上进行的大量实验表明，我们提出的方法在客观和主观评价指标方面都优于最先进的基准|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Variational+Reasoning+about+User+Preferences+for+Conversational+Recommendation)|2|
|[Analyzing and Simulating User Utterance Reformulation in Conversational Recommender Systems](https://doi.org/10.1145/3477495.3531936)|Shuo Zhang, MuChun Wang, Krisztian Balog|Bloomberg, London, United Kingdom; University of Stavanger, Stavanger, Norway; University of Science and Technology of China, Hefei, China|User simulation has been a cost-effective technique for evaluating conversational recommender systems. However, building a human-like simulator is still an open challenge. In this work, we focus on how users reformulate their utterances when a conversational agent fails to understand them. First, we perform a user study, involving five conversational agents across different domains, to identify common reformulation types and their transition relationships. A common pattern that emerges is that persistent users would first try to rephrase, then simplify, before giving up. Next, to incorporate the observed reformulation behavior in a user simulator, we introduce the task of reformulation sequence generation: to generate a sequence of reformulated utterances with a given intent (rephrase or simplify). We develop methods by extending transformer models guided by the reformulation type and perform further filtering based on estimated reading difficulty. We demonstrate the effectiveness of our approach using both automatic and human evaluation.|用户仿真已经成为评估会话推荐系统的一种经济有效的技术。然而，建立一个类似人的模拟器仍然是一个公开的挑战。在这项工作中，我们的重点是如何用户重新组织他们的话语时，一个会话代理无法理解他们。首先，我们进行了一个用户研究，涉及五个不同领域的会话代理，以确定常见的重构类型及其转换关系。出现的一种常见模式是，持久用户在放弃之前会首先尝试重新措辞，然后进行简化。接下来，为了在用户模拟器中整合观察到的重新表述行为，我们引入了重新表述序列生成的任务: 生成具有给定意图(重新表述或简化)的重新表述话语序列。我们发展的方法，扩展变压器模型指导下的重新公式类型和进一步滤波的基础上估计读取困难。我们使用自动评估和人工评估证明了我们的方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+and+Simulating+User+Utterance+Reformulation+in+Conversational+Recommender+Systems)|2|
|[Learning to Infer User Implicit Preference in Conversational Recommendation](https://doi.org/10.1145/3477495.3531844)|Chenhao Hu, Shuhua Huang, Yansen Zhang, Yubao Liu|Sun Yat-Sen University & Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China|Conversational recommender systems (CRS) enable traditional recommender systems to interact with users by asking questions about attributes and recommending items. The attribute-level and item-level feedback of users can be utilized to estimate users' preferences. However, existing works do not fully exploit the advantage of explicit item feedback --- they only use the item feedback in rather implicit ways such as updating the latent user and item representation. Since CRS has multiple chances to interact with users, leveraging the context in the conversation may help infer users' implicit feedback (e.g., some specific attributes) when recommendations get rejected. To address the limitations of existing methods, we propose a new CRS framework called Conversational Recommender with Implicit Feedback (CRIF). CRIF formulates the conversational recommendation scheme as a four-phase process consisting of offline representation learning, tracking, decision, and inference. In the inference module, by fully utilizing the relation between users' attribute-level and item-level feedback, our method can explicitly deduce users' implicit preferences. Therefore, CRIF is able to achieve more accurate user preference estimation. Besides, in the decision module, to better utilize the attribute-level and item-level feedback, we adopt inverse reinforcement learning to learn a flexible decision strategy that selects the suitable action at each conversation turn. Through extensive experiments on four benchmark CRS datasets, we validate the effectiveness of our approach, which significantly outperforms the state-of-the-art CRS methods.|会话推荐系统(CRS)使得传统的推荐系统能够通过询问关于属性的问题和推荐项目与用户进行交互。用户的属性级反馈和项目级反馈可以用来估计用户的偏好。然而，现有的作品并没有充分利用显式项目反馈的优势——他们只是以相当隐式的方式使用项目反馈，比如更新潜在用户和项目表示。由于 CRS 有多个与用户交互的机会，当推荐被拒绝时，利用会话中的上下文可能有助于推断用户的隐式反馈(例如，一些特定的属性)。为了解决现有方法的局限性，我们提出了一个新的 CRS 框架，称为隐式反馈会话推荐(CRIF)。CRIF 将会话推荐方案设计为离线表征学习、跟踪、决策和推理四个阶段。在推理模块中，通过充分利用用户属性级反馈和项目级反馈之间的关系，可以明确推断出用户的隐性偏好。因此，CRIF 能够实现更准确的用户偏好估计。此外，在决策模块中，为了更好地利用属性级别和项目级别的反馈，我们采用逆向强化学习学习灵活的决策策略，在每次谈话转折点选择合适的行动。通过对四个基准 CRS 数据集的大量实验，我们验证了该方法的有效性，其性能明显优于目前最先进的 CRS 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Infer+User+Implicit+Preference+in+Conversational+Recommendation)|2|
|[Recognizing Medical Search Query Intent by Few-shot Learning](https://doi.org/10.1145/3477495.3531789)|Yaqing Wang, Song Wang, Yanyan Li, Dejing Dou|Baidu Inc. & University of Virginia, Beijing, China; Baidu Inc., Beijing, China|Online healthcare services can provide unlimited and in-time medical information to users, which promotes social goods and breaks the barriers of locations. However, understanding the user intents behind the medical related queries is a challenging problem. Medical search queries are usually short and noisy, lack strict syntactic structure, and also require professional background to understand the medical terms. The medical intents are fine-grained, making them hard to recognize. In addition, many intents only have a few labeled data. To handle these problems, we propose a few-shot learning method for medical search query intent recognition called MEDIC. We extract co-click queries from user search logs as weak supervision to compensate for the lack of labeled data. We also design a new query encoder which learns to represent queries as a combination of semantic knowledge recorded in an external medical knowledge graph, syntactic knowledge which marks the grammatical role of each word in the query, and generic knowledge which is captured by language models pretrained from large-scale text corpus. Experimental results on a real medical search query intent recognition dataset validate the effectiveness of MEDIC.|在线医疗服务可以向用户提供无限制和及时的医疗信息，促进社会商品，打破地理位置的障碍。然而，理解医疗相关查询背后的用户意图是一个具有挑战性的问题。医学检索查询通常短小而嘈杂，缺乏严格的句法结构，而且需要专业背景才能理解医学术语。医学意图是细粒度的，很难识别。此外，许多意图只有少量带标签的数据。针对这些问题，本文提出了一种基于少镜头学习的医学搜索查询意图识别方法 MEDIC。我们从用户搜索日志中提取共同点击查询作为薄弱的监督，以弥补标记数据的缺乏。我们还设计了一种新的查询编码器，该编码器学习将外部医学知识图中记录的语义知识、标记查询中每个词语法角色的句法知识以及从大规模文本语料库中预先训练的语言模型获取的通用知识组合起来来表示查询。在一个真实的医学搜索查询意图识别数据集上的实验结果验证了 MEDIC 算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recognizing+Medical+Search+Query+Intent+by+Few-shot+Learning)|2|
|[PERD: Personalized Emoji Recommendation with Dynamic User Preference](https://doi.org/10.1145/3477495.3531779)|Xuanzhi Zheng, Guoshuai Zhao, Li Zhu, Xueming Qian|Xi'an Jiaotong University, Xi'an, China|Emoji recommendation is an important task to help users find appropriate emojis from thousands of candidates based on a short tweet text. Traditional emoji recommendation methods lack personalized recommendation and ignore user historical information in selecting emojis. In this paper, we propose a personalized emoji recommendation with dynamic user preference (PERD) which contains a text encoder and a personalized attention mechanism. In text encoder, a BERT model is contained to learn dense and low-dimensional representations of tweets. In personalized attention, user dynamic preferences are learned according to semantic and sentimental similarity between historical tweets and the tweet which is waiting for emoji recommendation. Informative historical tweets are selected and highlighted. Experiments are carried out on two real-world datasets from Sina Weibo and Twitter. Experimental results validate the superiority of our approach on personalized emoji recommendation.|表情符号推荐是一项重要的任务，它可以帮助用户根据一条短短的推文从数千名候选人中找到合适的表情符号。传统的表情符号推荐方法缺乏个性化推荐，在选择表情符号时忽略了用户的历史信息。本文提出了一种基于动态用户偏好的个性化表情推荐(PERD) ，它包含一个文本编码器和一个个性化的注意机制。在文本编码器中，BERT 模型用于学习 tweet 的稠密和低维表示。在个性化关注中，根据历史推文和等待表情推荐的推文之间的语义和情感相似性来学习用户的动态偏好。选择并突出显示信息丰富的历史 tweet。实验是在来自新浪微博和推特的两个真实世界的数据集上进行的。实验结果验证了该方法在个性化表情符号推荐中的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PERD:+Personalized+Emoji+Recommendation+with+Dynamic+User+Preference)|2|
|[Sequential/Session-based Recommendations: Challenges, Approaches, Applications and Opportunities](https://doi.org/10.1145/3477495.3532685)|Shoujin Wang, Qi Zhang, Liang Hu, Xiuzhen Zhang, Yan Wang, Charu Aggarwal|RMIT University & Macquarie University, Melbourne , Australia; RMIT University, Melbourne, Australia; Macquarie University, Sydney , Australia; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; Tongji University, Shanghai , China; DeepBlue Academy of Sciences, Shanghai, China|In recent years, sequential recommender systems (SRSs) and session-based recommender systems (SBRSs) have emerged as a new paradigm of RSs to capture users' short-term but dynamic preferences for enabling more timely and accurate recommendations. Although SRSs and SBRSs have been extensively studied, there are many inconsistencies in this area caused by the diverse descriptions, settings, assumptions and application domains. There is no work to provide a unified framework and problem statement to remove the commonly existing and various inconsistencies in the area of SR/SBR. There is a lack of work to provide a comprehensive and systematic demonstration of the data characteristics, key challenges, most representative and state-of-the-art approaches, typical real- world applications and important future research directions in the area. This work aims to fill in these gaps so as to facilitate further research in this exciting and vibrant area.|近年来，顺序推荐系统(SRS)和基于会话的推荐系统(SBRS)已经成为一种新的 RSS 模式，它们可以捕获用户短期的动态偏好，从而实现更及时、更准确的推荐。尽管 SRS 和 SBRS 已经得到了广泛的研究，但是由于描述、设置、假设和应用领域的不同，在这个领域还存在着许多不一致之处。目前还没有提供一个统一的框架和问题说明来消除 SR/SBR 领域中普遍存在的各种不一致之处。目前缺乏对数据特征、主要挑战、最具代表性和最先进的方法、典型的现实世界应用和该领域未来重要研究方向进行全面和系统的论证的工作。这项工作旨在填补这些空白，以促进在这个令人兴奋和充满活力的领域的进一步研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential/Session-based+Recommendations:+Challenges,+Approaches,+Applications+and+Opportunities)|2|
|[Probabilistic Permutation Graph Search: Black-Box Optimization for Fairness in Ranking](https://doi.org/10.1145/3477495.3532045)|Ali Vardasbi, Fatemeh Sarvi, Maarten de Rijke|University of Amsterdam, Amsterdam, Netherlands|There are several measures for fairness in ranking, based on different underlying assumptions and perspectives. \acPL optimization with the REINFORCE algorithm can be used for optimizing black-box objective functions over permutations. In particular, it can be used for optimizing fairness measures. However, though effective for queries with a moderate number of repeating sessions, \acPL optimization has room for improvement for queries with a small number of repeating sessions. In this paper, we present a novel way of representing permutation distributions, based on the notion of permutation graphs. Similar to~\acPL, our distribution representation, called~\acPPG, can be used for black-box optimization of fairness. Different from~\acPL, where pointwise logits are used as the distribution parameters, in~\acPPG pairwise inversion probabilities together with a reference permutation construct the distribution. As such, the reference permutation can be set to the best sampled permutation regarding the objective function, making~\acPPG suitable for both deterministic and stochastic rankings. Our experiments show that~\acPPG, while comparable to~\acPL for larger session repetitions (i.e., stochastic ranking), improves over~\acPL for optimizing fairness metrics for queries with one session (i.e., deterministic ranking). Additionally, when accurate utility estimations are available, e.g., in tabular models, the performance of \acPPG in fairness optimization is significantly boosted compared to lower quality utility estimations from a learning to rank model, leading to a large performance gap with PL. Finally, the pairwise probabilities make it possible to impose pairwise constraints such as "item $d_1$ should always be ranked higher than item $d_2$.'' Such constraints can be used to simultaneously optimize the fairness metric and control another objective such as ranking performance.|根据不同的基本假设和观点，有几种衡量排名公平性的方法。使用 REINFORCE 算法的 acPL 优化可以用于优化黑盒目标函数。特别是可以用来优化公平性措施。然而，尽管对于具有中等数量重复会话的查询有效，但是对于具有少量重复会话的查询，acPL 优化还有改进的空间。本文基于置换图的概念，提出了一种表示置换分布的新方法。与 ~ acPL 类似，我们的分布表示(称为 ~ acPPG)可以用于公平性的黑盒优化。与以逐点对数作为分布参数的 ~ acPPG 不同，在 ~ acPPG 中成对反演概率与参考置换构成分布。因此，对于目标函数，可以将参考排序设置为最佳采样排序，使 ~ acPPG 既适用于确定性排序，也适用于随机排序。我们的实验表明 ~ acPPG 在较大的会话重复(即随机排名)方面与 ~ acPL 相当，但在优化一个会话查询(即确定性排名)的公平性指标方面优于 ~ acPL。此外，当准确的效用估计可用时，例如在表格模型中，acPPG 在公平优化中的表现显着提高，与来自学习到等级模型的较低质量效用估计相比，导致与 PL 的巨大性能差距。最后，成对概率使得可以施加成对约束，例如“项 $d _ 1 $应该总是排在项 $d _ 2 $之前”这种约束可以用来同时优化公平性度量和控制另一个目标，如排名性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Probabilistic+Permutation+Graph+Search:+Black-Box+Optimization+for+Fairness+in+Ranking)|2|
|[Less is More: Reweighting Important Spectral Graph Features for Recommendation](https://doi.org/10.1145/3477495.3532014)|Shaowen Peng, Kazunari Sugiyama, Tsunenori Mine|Kyoto University, Kyoto, Japan; Kyushu University, Fukuoka, Japan|As much as Graph Convolutional Networks (GCNs) have shown tremendous success in recommender systems and collaborative filtering (CF), the mechanism of how they, especially the core components (\textiti.e., neighborhood aggregation) contribute to recommendation has not been well studied. To unveil the effectiveness of GCNs for recommendation, we first analyze them in a spectral perspective and discover two important findings: (1) only a small portion of spectral graph features that emphasize the neighborhood smoothness and difference contribute to the recommendation accuracy, whereas most graph information can be considered as noise that even reduces the performance, and (2) repetition of the neighborhood aggregation emphasizes smoothed features and filters out noise information in an ineffective way. Based on the two findings above, we propose a new GCN learning scheme for recommendation by replacing neihgborhood aggregation with a simple yet effective Graph Denoising Encoder (GDE), which acts as a band pass filter to capture important graph features. We show that our proposed method alleviates the over-smoothing and is comparable to an indefinite-layer GCN that can take any-hop neighborhood into consideration. Finally, we dynamically adjust the gradients over the negative samples to expedite model training without introducing additional complexity. Extensive experiments on five real-world datasets show that our proposed method not only outperforms state-of-the-arts but also achieves 12x speedup over LightGCN.|尽管图形卷积网络在推荐系统和协同过滤(CF)方面取得了巨大的成功，但其核心组件(textititi.e. 邻域聚合)对推荐的贡献机制还没有得到很好的研究。为了揭示 GCNs 在推荐中的有效性，我们首先从谱的角度分析它们，发现两个重要的结果: (1)只有一小部分强调邻域平滑和差异的谱图特征有助于推荐精度，而大多数图形信息可以被视为噪声，甚至降低性能; (2)重复的邻域聚合强调平滑的特征，并以无效的方式过滤掉噪声信息。基于以上两个发现，我们提出了一种新的 GCN 推荐学习方案，用一种简单而有效的图形去噪编码器(GDE)代替邻域聚合，GDE 作为带通滤波器来捕捉重要的图形特征。结果表明，我们提出的方法减轻了过度平滑，并可比拟一个不确定层 GCN，可以考虑任何跳邻居。最后，我们动态调整负样本上的梯度，以加快模型训练而不引入额外的复杂性。在五个真实世界数据集上的大量实验表明，我们提出的方法不仅优于最新技术，而且比 LightGCN 提高了12倍的速度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Less+is+More:+Reweighting+Important+Spectral+Graph+Features+for+Recommendation)|2|
|[Interpolative Distillation for Unifying Biased and Debiased Recommendation](https://doi.org/10.1145/3477495.3532002)|Sihao Ding, Fuli Feng, Xiangnan He, Jinqiu Jin, Wenjie Wang, Yong Liao, Yongdong Zhang|University of Science and Technology of China & CCCD Key Lab of MCT, Hefei, China; National University of Singapore, Singapore, China; University of Science and Technology of China, Hefei, China|Most recommender systems evaluate model performance offline through either: 1) normal biased test on factual interactions; or 2) debiased test with records from the randomized controlled trial. In fact, both tests only reflect part of the whole picture: factual interactions are collected from the recommendation policy, fitting them better implies benefiting the platform with higher click or conversion rate; in contrast, debiased test eliminates system-induced biases and thus is more reflective of user true preference. Nevertheless, we find that existing models exhibit trade-off on the two tests, and there lacks methods that perform well on both tests. In this work, we aim to develop a win-win recommendation method that is strong on both tests. It is non-trivial, since it requires to learn a model that can make accurate prediction in both factual environment (ie normal biased test) and counterfactual environment (ie debiased test). Towards the goal, we perform environment-aware recommendation modeling by considering both environments. In particular, we propose an Interpolative Distillation (InterD) framework, which interpolates the biased and debiased models at user-item pair level by distilling a student model. We conduct experiments on three real-world datasets with both tests. Empirical results justify the rationality and effectiveness of InterD, which stands out on both tests especially demonstrates remarkable gains on less popular items.|大多数推荐系统通过以下两种方式评估模型的离线性能: 1)对实际交互进行正常偏向测试; 或者2)利用随机对照试验记录进行偏向测试。事实上，这两个测试只反映了整体情况的一部分: 实际的交互是从推荐策略中收集的，更好地适应它们意味着更高的点击率或转化率有利于平台; 相反，去偏向测试消除了系统引起的偏见，因此更能反映用户的真实偏好。尽管如此，我们发现现有的模型在两个测试中表现出了折衷，并且缺乏在两个测试中都表现良好的方法。在这项工作中，我们的目标是开发一个双赢的推荐方法，在两个测试中都很强。它是非平凡的，因为它需要学习一个模型，可以作出准确的预测既在事实环境(即正常偏向测试)和反事实环境(即去偏向测试)。为了实现这个目标，我们通过考虑两种环境来执行环境感知的推荐建模。特别地，我们提出了一个插值蒸馏(InterD)框架，它通过提取学生模型在用户项目对水平上插值有偏和无偏模型。我们用这两个测试在三个真实世界的数据集上进行实验。实证结果证明了 InterD 的合理性和有效性，它在两个测试中都表现突出，尤其是在不太受欢迎的项目上表现出显著的收益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpolative+Distillation+for+Unifying+Biased+and+Debiased+Recommendation)|2|
|[Enhancing Hypergraph Neural Networks with Intent Disentanglement for Session-based Recommendation](https://doi.org/10.1145/3477495.3531794)|Yinfeng Li, Chen Gao, Hengliang Luo, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Hypergraph+Neural+Networks+with+Intent+Disentanglement+for+Session-based+Recommendation)|2|
|[Generative Adversarial Framework for Cold-Start Item Recommendation](https://doi.org/10.1145/3477495.3531897)|Hao Chen, Zefan Wang, Feiran Huang, Xiao Huang, Yue Xu, Yishi Lin, Peng He, Zhoujun Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Adversarial+Framework+for+Cold-Start+Item+Recommendation)|2|
|[Dynamics-Aware Adaptation for Reinforcement Learning Based Cross-Domain Interactive Recommendation](https://doi.org/10.1145/3477495.3531969)|Junda Wu, Zhihui Xie, Tong Yu, Handong Zhao, Ruiyi Zhang, Shuai Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamics-Aware+Adaptation+for+Reinforcement+Learning+Based+Cross-Domain+Interactive+Recommendation)|2|
|[A Study of Cross-Session Cross-Device Search Within an Academic Digital Library](https://doi.org/10.1145/3477495.3531929)|Sebastian Gomes, Miriam Boon, Orland Hoeber||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Study+of+Cross-Session+Cross-Device+Search+Within+an+Academic+Digital+Library)|2|
|[Locality-Sensitive State-Guided Experience Replay Optimization for Sparse Rewards in Online Recommendation](https://doi.org/10.1145/3477495.3532015)|Xiaocong Chen, Lina Yao, Julian J. McAuley, Weili Guan, Xiaojun Chang, Xianzhi Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Locality-Sensitive+State-Guided+Experience+Replay+Optimization+for+Sparse+Rewards+in+Online+Recommendation)|2|
|[An Attribute-Driven Mirror Graph Network for Session-based Recommendation](https://doi.org/10.1145/3477495.3531935)|Siqi Lai, Erli Meng, Fan Zhang, Chenliang Li, Bin Wang, Aixin Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Attribute-Driven+Mirror+Graph+Network+for+Session-based+Recommendation)|2|
|[FUM: Fine-grained and Fast User Modeling for News Recommendation](https://doi.org/10.1145/3477495.3531790)|Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FUM:+Fine-grained+and+Fast+User+Modeling+for+News+Recommendation)|2|
|[Experiments on Generalizability of User-Oriented Fairness in Recommender Systems](https://doi.org/10.1145/3477495.3531718)|Hossein A. Rahmani, Mohammadmehdi Naghiaei, Mahdi Dehghan, Mohammad Aliannejadi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Experiments+on+Generalizability+of+User-Oriented+Fairness+in+Recommender+Systems)|2|
|[Geometric Disentangled Collaborative Filtering](https://doi.org/10.1145/3477495.3531982)|Yiding Zhang, Chaozhuo Li, Xing Xie, Xiao Wang, Chuan Shi, Yuming Liu, Hao Sun, Liangjie Zhang, Weiwei Deng, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+Disentangled+Collaborative+Filtering)|2|
|[Generating Clarifying Questions with Web Search Results](https://doi.org/10.1145/3477495.3531981)|Ziliang Zhao, Zhicheng Dou, Jiaxin Mao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Clarifying+Questions+with+Web+Search+Results)|2|
|[Enhancing CTR Prediction with Context-Aware Feature Representation Learning](https://doi.org/10.1145/3477495.3531970)|Fangye Wang, Yingxu Wang, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, Ning Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+CTR+Prediction+with+Context-Aware+Feature+Representation+Learning)|2|
|[Joint Multisided Exposure Fairness for Recommendation](https://doi.org/10.1145/3477495.3532007)|Haolun Wu, Bhaskar Mitra, Chen Ma, Fernando Diaz, Xue Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Multisided+Exposure+Fairness+for+Recommendation)|2|
|[Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction](https://doi.org/10.1145/3477495.3531772)|Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-train+a+Discriminative+Text+Encoder+for+Dense+Retrieval+via+Contrastive+Span+Prediction)|2|
|[CenterCLIP: Token Clustering for Efficient Text-Video Retrieval](https://doi.org/10.1145/3477495.3531950)|Shuai Zhao, Linchao Zhu, Xiaohan Wang, Yi Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CenterCLIP:+Token+Clustering+for+Efficient+Text-Video+Retrieval)|2|
|[ProFairRec: Provider Fairness-aware News Recommendation](https://doi.org/10.1145/3477495.3532046)|Tao Qi, Fangzhao Wu, Chuhan Wu, Peijie Sun, Le Wu, Xiting Wang, Yongfeng Huang, Xing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ProFairRec:+Provider+Fairness-aware+News+Recommendation)|2|
|[Rethinking Reinforcement Learning for Recommendation: A Prompt Perspective](https://doi.org/10.1145/3477495.3531714)|Xin Xin, Tiago Pimentel, Alexandros Karatzoglou, Pengjie Ren, Konstantina Christakopoulou, Zhaochun Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Reinforcement+Learning+for+Recommendation:+A+Prompt+Perspective)|2|
|[Alleviating Spurious Correlations in Knowledge-aware Recommendations through Counterfactual Generator](https://doi.org/10.1145/3477495.3531934)|Shanlei Mu, Yaliang Li, Wayne Xin Zhao, Jingyuan Wang, Bolin Ding, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Alleviating+Spurious+Correlations+in+Knowledge-aware+Recommendations+through+Counterfactual+Generator)|2|
|[HAKG: Hierarchy-Aware Knowledge Gated Network for Recommendation](https://doi.org/10.1145/3477495.3531987)|Yuntao Du, Xinjun Zhu, Lu Chen, Baihua Zheng, Yunjun Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HAKG:+Hierarchy-Aware+Knowledge+Gated+Network+for+Recommendation)|2|
|[Entity-aware Transformers for Entity Search](https://doi.org/10.1145/3477495.3531971)|Emma J. Gerritse, Faegheh Hasibi, Arjen P. de Vries||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity-aware+Transformers+for+Entity+Search)|2|
|[CharacterBERT and Self-Teaching for Improving the Robustness of Dense Retrievers on Queries with Typos](https://doi.org/10.1145/3477495.3531951)|Shengyao Zhuang, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CharacterBERT+and+Self-Teaching+for+Improving+the+Robustness+of+Dense+Retrievers+on+Queries+with+Typos)|2|
|[Thinking inside The Box: Learning Hypercube Representations for Group Recommendation](https://doi.org/10.1145/3477495.3532066)|Tong Chen, Hongzhi Yin, Jing Long, Quoc Viet Hung Nguyen, Yang Wang, Meng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Thinking+inside+The+Box:+Learning+Hypercube+Representations+for+Group+Recommendation)|2|
|[Multi-modal Graph Contrastive Learning for Micro-video Recommendation](https://doi.org/10.1145/3477495.3532027)|Zixuan Yi, Xi Wang, Iadh Ounis, Craig MacDonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Graph+Contrastive+Learning+for+Micro-video+Recommendation)|2|
|[InPars: Unsupervised Dataset Generation for Information Retrieval](https://doi.org/10.1145/3477495.3531863)|Luiz Henrique Bonifacio, Hugo Abonizio, Marzieh Fadaee, Rodrigo Frassetto Nogueira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InPars:+Unsupervised+Dataset+Generation+for+Information+Retrieval)|2|
|[Addressing Gender-related Performance Disparities in Neural Rankers](https://doi.org/10.1145/3477495.3531882)|Shirin Seyedsalehi, Amin Bigdeli, Negar Arabzadeh, Morteza Zihayat, Ebrahim Bagheri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Gender-related+Performance+Disparities+in+Neural+Rankers)|2|
|[State Encoders in Reinforcement Learning for Recommendation: A Reproducibility Study](https://doi.org/10.1145/3477495.3531716)|Jin Huang, Harrie Oosterhuis, Bunyamin Cetinkaya, Thijs Rood, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=State+Encoders+in+Reinforcement+Learning+for+Recommendation:+A+Reproducibility+Study)|2|
|[Wikimarks: Harvesting Relevance Benchmarks from Wikipedia](https://doi.org/10.1145/3477495.3531731)|Laura Dietz, Shubham Chatterjee, Connor Lennox, Sumanta Kashyapi, Pooja Oza, Ben Gamari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wikimarks:+Harvesting+Relevance+Benchmarks+from+Wikipedia)|2|
|[Gender Fairness in Information Retrieval Systems](https://doi.org/10.1145/3477495.3532680)|Amin Bigdeli, Negar Arabzadeh, Shirin Seyedsalehi, Morteza Zihayat, Ebrahim Bagheri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gender+Fairness+in+Information+Retrieval+Systems)|2|
|[Fairness of Exposure in Light of Incomplete Exposure Estimation](https://doi.org/10.1145/3477495.3531977)|Maria Heuss, Fatemeh Sarvi, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+of+Exposure+in+Light+of+Incomplete+Exposure+Estimation)|2|
|[Few-Shot Stance Detection via Target-Aware Prompt Distillation](https://doi.org/10.1145/3477495.3531979)|Yan Jiang, Jinhua Gao, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-Shot+Stance+Detection+via+Target-Aware+Prompt+Distillation)|2|
|[Unsupervised Belief Representation Learning with Information-Theoretic Variational Graph Auto-Encoders](https://doi.org/10.1145/3477495.3532072)|Jinning Li, Huajie Shao, Dachun Sun, Ruijie Wang, Yuchen Yan, Jinyang Li, Shengzhong Liu, Hanghang Tong, Tarek F. Abdelzaher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Belief+Representation+Learning+with+Information-Theoretic+Variational+Graph+Auto-Encoders)|2|
|[Towards Motivational and Empathetic Response Generation in Online Mental Health Support](https://doi.org/10.1145/3477495.3531912)|Tulika Saha, Vaibhav Gakhreja, Anindya Sundar Das, Souhitya Chakraborty, Sriparna Saha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Motivational+and+Empathetic+Response+Generation+in+Online+Mental+Health+Support)|2|
|[Multimodal Entity Linking with Gated Hierarchical Fusion and Contrastive Training](https://doi.org/10.1145/3477495.3531867)|Peng Wang, Jiangheng Wu, Xiaohang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Entity+Linking+with+Gated+Hierarchical+Fusion+and+Contrastive+Training)|2|
|[Tag-assisted Multimodal Sentiment Analysis under Uncertain Missing Modalities](https://doi.org/10.1145/3477495.3532064)|Jiandian Zeng, Tianyi Liu, Jiantao Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tag-assisted+Multimodal+Sentiment+Analysis+under+Uncertain+Missing+Modalities)|2|
|[Enhancing Zero-Shot Stance Detection via Targeted Background Knowledge](https://doi.org/10.1145/3477495.3531807)|Qinglin Zhu, Bin Liang, Jingyi Sun, Jiachen Du, Lanjun Zhou, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Zero-Shot+Stance+Detection+via+Targeted+Background+Knowledge)|2|
|[Relation-Guided Few-Shot Relational Triple Extraction](https://doi.org/10.1145/3477495.3531831)|Xin Cong, Jiawei Sheng, Shiyao Cui, Bowen Yu, Tingwen Liu, Bin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relation-Guided+Few-Shot+Relational+Triple+Extraction)|2|
|[Summarizing Legal Regulatory Documents using Transformers](https://doi.org/10.1145/3477495.3531872)|Svea Klaus, Ria Van Hecke, Kaweh Djafari Naini, Ismail Sengor Altingovde, Juan BernabéMoreno, Enrique HerreraViedma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Summarizing+Legal+Regulatory+Documents+using+Transformers)|2|
|[An Inspection of the Reproducibility and Replicability of TCT-ColBERT](https://doi.org/10.1145/3477495.3531721)|Xiao Wang, Sean MacAvaney, Craig Macdonald, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Inspection+of+the+Reproducibility+and+Replicability+of+TCT-ColBERT)|2|
|[MET-Meme: A Multimodal Meme Dataset Rich in Metaphors](https://doi.org/10.1145/3477495.3532019)|Bo Xu, Tingting Li, Junzhe Zheng, Mehdi Naseriparsa, Zhehuan Zhao, Hongfei Lin, Feng Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MET-Meme:+A+Multimodal+Meme+Dataset+Rich+in+Metaphors)|2|
|[Fostering Coopetition While Plugging Leaks: The Design and Implementation of the MS MARCO Leaderboards](https://doi.org/10.1145/3477495.3531725)|Jimmy Lin, Daniel Campos, Nick Craswell, Bhaskar Mitra, Emine Yilmaz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fostering+Coopetition+While+Plugging+Leaks:+The+Design+and+Implementation+of+the+MS+MARCO+Leaderboards)|2|
|[Too Many Relevants: Whither Cranfield Test Collections?](https://doi.org/10.1145/3477495.3531728)|Ellen M. Voorhees, Nick Craswell, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Too+Many+Relevants:+Whither+Cranfield+Test+Collections?)|2|
|[Document Expansion Baselines and Learned Sparse Lexical Representations for MS MARCO V1 and V2](https://doi.org/10.1145/3477495.3531749)|Xueguang Ma, Ronak Pradeep, Rodrigo Frassetto Nogueira, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Document+Expansion+Baselines+and+Learned+Sparse+Lexical+Representations+for+MS+MARCO+V1+and+V2)|2|
|[ClueWeb22: 10 Billion Web Documents with Rich Information](https://doi.org/10.1145/3477495.3536321)|Arnold Overwijk, Chenyan Xiong, Jamie Callan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ClueWeb22:+10+Billion+Web+Documents+with+Rich+Information)|2|
|[User-Aware Multi-Interest Learning for Candidate Matching in Recommenders](https://doi.org/10.1145/3477495.3532073)|Zheng Chai, Zhihong Chen, Chenliang Li, Rong Xiao, Houyi Li, Jiawei Wu, Jingxu Chen, Haihong Tang|Zhejiang University, Hangzhou, China; Wuhan University, Wuhan, China; Alibaba Group, Hangzhou, China|Recommender systems have become a fundamental service in most E-Commerce platforms, in which the matching stage aims to retrieve potentially relevant candidate items to users for further ranking. Recently, some efforts on extracting multi-interests from user's historical behaviors have demonstrated superior performance. However, the historical behaviors are not noise-free due to the possible misclicks or disturbances. Existing works mainly overlook the fact that the interests of a user are not only reflected by the historical behaviors, but also inherently regulated by the profile information. Hence, we are interested in exploiting the benefit of user profile in multi-interest learning to enhance candidate matching performance. To this end, a user-aware multi-interest learning framework (named UMI) is proposed in this paper to exploit both user profile and behavior information for candidate matching. Specifically, UMI consists of two main components: dual-attention routing and interest refinement. In the dual-attention routing, we firstly introduce a user-guided attention network to identify the important historical items with respect to the user profile. Then, the resultant importance weights are leveraged via the dual-attentive capsule network to extract the user's multi-interests. Afterwards, the extracted interests are utilized to highlight the corresponding user profile features for interest refinement, such that different user profiles can be incorporated into interest learning for diverse user preference understanding. Besides, to improve the model's discriminative capacity, we further devise a harder-negatives strategy to support model optimization. Extensive experiments show that UMI significantly outperforms state-of-the-art multi-interest modeling alternatives. Currently, UMI has been successfully deployed at Taobao App in Alibaba, serving hundreds of millions of users.|推荐系统已经成为大多数电子商务平台的基本服务，其中匹配阶段的目的是检索潜在的相关候选项目，以便用户进一步排名。最近，一些从用户历史行为中提取多重利益的尝试已经显示出了卓越的性能。然而，由于可能的错误或干扰，历史行为并不是无噪声的。现有的研究工作主要忽视了用户的利益不仅反映在历史行为上，而且内在地受到个人资料信息的调节。因此，我们有兴趣在多兴趣学习中利用用户资料的好处来提高候选人匹配性能。为此，本文提出了一种基于用户感知的多兴趣学习框架(UMI) ，该框架利用用户信息和行为信息进行候选人匹配。具体来说，UMI 包括两个主要组成部分: 双注意路由和兴趣细化。在双注意路由中，我们首先引入一个用户引导的注意网络来识别与用户资料相关的重要历史项目。然后，通过双注意胶囊网络利用得到的重要性权重来提取用户的多重兴趣。然后利用提取出的兴趣特征突出相应的用户兴趣特征进行兴趣细化，从而将不同的用户兴趣特征融入到兴趣学习中以获得不同的用户偏好理解。此外，为了提高模型的判别能力，我们进一步设计了一个较难否定的策略来支持模型优化。大量的实验表明，UMI 明显优于最先进的多重兴趣建模方案。目前，用户界面已经在阿里巴巴的淘宝应用上成功部署，为数亿用户提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-Aware+Multi-Interest+Learning+for+Candidate+Matching+in+Recommenders)|1|
|[ESCM2: Entire Space Counterfactual Multi-Task Model for Post-Click Conversion Rate Estimation](https://doi.org/10.1145/3477495.3531972)|Hao Wang, TaiWei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu, Ruopeng Li, Wei Chu|Ant Group, Hangzhou, China|Accurate estimation of post-click conversion rate is critical for building recommender systems, which has long been confronted with sample selection bias and data sparsity issues. Methods in the Entire Space Multi-task Model (ESMM) family leverage the sequential pattern of user actions, \ie $impression\rightarrow click \rightarrow conversion$ to address data sparsity issue. However, they still fail to ensure the unbiasedness of CVR estimates. In this paper, we theoretically demonstrate that ESMM suffers from the following two problems: (1) Inherent Estimation Bias (IEB) for CVR estimation, where the CVR estimate is inherently higher than the ground truth; (2) Potential Independence Priority (PIP) for CTCVR estimation, where ESMM might overlook the causality from click to conversion. To this end, we devise a principled approach named Entire Space Counterfactual Multi-task Modelling (ESCM$^2$), which employs a counterfactual risk miminizer as a regularizer in ESMM to address both IEB and PIP issues simultaneously. Extensive experiments on offline datasets and online environments demonstrate that our proposed ESCM$^2$ can largely mitigate the inherent IEB and PIP issues and achieve better performance than baseline models.|准确估计点击后的转换率是建立推荐系统的关键，长期以来推荐系统一直面临样本选择偏差和数据稀疏问题。整个空间多任务模型(ESMM)家族中的方法利用了用户操作的顺序模式，例如: $pressionright-tarrow 单击 right-tarrow 转换 $来解决数据稀疏问题。然而，他们仍然不能确保 CVR 估计的公正性。在本文中，我们从理论上证明了 ESMM 存在以下两个问题: (1) CVR 估计的内在估计偏差(IEB) ，其中 CVR 估计固有地高于地面真值; (2) CTCVR 估计的潜在独立优先级(PIP) ，其中 ESMM 可能忽略从点击到转换的因果关系。为此，我们设计了一种名为“整个空间反事实多任务建模”(ESCM $^ 2 $)的原则性方法，该方法使用反事实风险模拟器作为 ESMM 中的规则化器，同时解决 IEB 和 PIP 问题。在离线数据集和在线环境上的大量实验表明，我们提出的 ESCM $^ 2 $可以在很大程度上缓解内在的 IEB 和 PIP 问题，并取得比基线模型更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ESCM2:+Entire+Space+Counterfactual+Multi-Task+Model+for+Post-Click+Conversion+Rate+Estimation)|1|
|[Single-shot Embedding Dimension Search in Recommender System](https://doi.org/10.1145/3477495.3532060)|Liang Qu, Yonghong Ye, Ningzhi Tang, Lixin Zhang, Yuhui Shi, Hongzhi Yin|WeChat, Tencent, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; The University of Queensland, Brisbane, QLD, Australia|As a crucial component of most modern deep recommender systems, feature embedding maps high-dimensional sparse user/item features into low-dimensional dense embeddings. However, these embeddings are usually assigned a unified dimension, which suffers from the following issues: (1) high memory usage and computation cost. (2) sub-optimal performance due to inferior dimension assignments. In order to alleviate the above issues, some works focus on automated embedding dimension search by formulating it as hyper-parameter optimization or embedding pruning problems. However, they either require well-designed search space for hyperparameters or need time-consuming optimization procedures. In this paper, we propose a Single-Shot Embedding Dimension Search method, called SSEDS, which can efficiently assign dimensions for each feature field via a single-shot embedding pruning operation while maintaining the recommendation accuracy of the model. Specifically, it introduces a criterion for identifying the importance of each embedding dimension for each feature field. As a result, SSEDS could automatically obtain mixed-dimensional embeddings by explicitly reducing redundant embedding dimensions based on the corresponding dimension importance ranking and the predefined parameter budget. Furthermore, the proposed SSEDS is model-agnostic, meaning that it could be integrated into different base recommendation models. The extensive offline experiments are conducted on two widely used public datasets for CTR (Click Through Rate) prediction task, and the results demonstrate that SSEDS can still achieve strong recommendation performance even if it has reduced 90% parameters. Moreover, SSEDS has also been deployed on the WeChat Subscription platform for practical recommendation services. The 7-day online A/B test results show that SSEDS can significantly improve the performance of the online recommendation model while reducing resource consumption.|作为现代深度推荐系统的重要组成部分，特征嵌入将高维稀疏用户/项目特征映射为低维密集嵌入。然而，这些嵌入通常被分配一个统一的维度，这受到以下问题: (1)高内存使用和计算成本。(2)由于尺寸分配不合理而导致性能次优。为了解决上述问题，一些工作将嵌入维搜索问题转化为超参数优化问题或嵌入剪枝问题。然而，它们要么需要设计良好的超参数搜索空间，要么需要耗时的优化过程。本文提出了一种单镜头嵌入维度搜索方法 SSEDS，该方法通过单镜头嵌入剪枝操作，可以有效地为每个特征域分配维度，同时保持模型的推荐精度。具体地说，它引入了一个标准来识别每个特征字段的每个嵌入维的重要性。因此，SSEDS 可以根据相应的维重要性排序和预定义的参数预算，通过显式地减少冗余嵌入维数来自动获得混合维嵌入。此外，提出的 SSEDS 是模型无关的，这意味着它可以集成到不同的基本推荐模型中。在两个广泛使用的公共数据集上进行了广泛的离线实验，结果表明，即使 SSEDS 减少了90% 的参数，仍然可以获得很好的推荐性能。此外，SSEDS 还被部署在微信订阅平台上，提供实用的推荐服务。为期7天的在线 A/B 测试结果表明，SSEDS 在降低资源消耗的同时，可以显著提高在线推荐模型的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Single-shot+Embedding+Dimension+Search+in+Recommender+System)|1|
|[Zero-shot Query Contextualization for Conversational Search](https://doi.org/10.1145/3477495.3531769)|Antonios Minas Krasakis, Andrew Yates, Evangelos Kanoulas|University of Amsterdam, Amsterdam, Netherlands|Current conversational passage retrieval systems cast conversational search into ad-hoc search by using an intermediate query resolution step that places the user's question in context of the conversation. While the proposed methods have proven effective, they still assume the availability of large-scale question resolution and conversational search datasets. To waive the dependency on the availability of such data, we adapt a pre-trained token-level dense retriever on ad-hoc search data to perform conversational search with no additional fine-tuning. The proposed method allows to contextualize the user question within the conversation history, but restrict the matching only between question and potential answer. Our experiments demonstrate the effectiveness of the proposed approach. We also perform an analysis that provides insights of how contextualization works in the latent space, in essence introducing a bias towards salient terms from the conversation.|当前的会话文本检索系统通过使用一个中间查询解析步骤，将用户的问题置于会话上下文中，从而将会话搜索转换为特定搜索。虽然提出的方法已被证明是有效的，但它们仍然假设大规模的问题解决和会话搜索数据集的可用性。为了摆脱对这些数据可用性的依赖，我们在自组织搜索数据上采用了一个预先训练的令牌级密集检索器来执行会话搜索，而不需要进行额外的微调。该方法允许在会话历史中上下文化用户问题，但只限制问题和潜在答案之间的匹配。实验证明了该方法的有效性。我们还进行了一个分析，提供了如何在潜在空间的情境化工作的见解，在本质上引入了一个从会话突出术语的偏见。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Query+Contextualization+for+Conversational+Search)|1|
|[DisenCTR: Dynamic Graph-based Disentangled Representation for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531851)|Yifan Wang, Yifang Qin, Fang Sun, Bo Zhang, Xuyang Hou, Ke Hu, Jia Cheng, Jun Lei, Ming Zhang|Peking University, Beijing, China; Meituan, Beijing, China|Click-through rate (CTR) prediction plays a critical role in recommender systems and other applications. Recently, modeling user behavior sequences attracts much attention and brings great improvements in the CTR field. Many existing works utilize attention mechanism or recurrent neural networks to exploit user interest from the sequence, but fail to recognize the simple truth that a user's real-time interests are inherently diverse and fluid. In this paper, we propose DisenCTR, a novel dynamic graph-based disentangled representation framework for CTR prediction. The key novelty of our method compared with existing approaches is to model evolving diverse interests of users. Specifically, we construct a time-evolving user-item interaction graph induced by historical interactions. And based on the rich dynamics supplied by the graph, we propose a disentangled graph representation module to extract diverse user interests. We further exploit the fluidity of user interests and model the temporal effect of historical behaviors using Mixture of Hawkes Process. Extensive experiments on three real-world datasets demonstrate the superior performance of our method comparing to state-of-the-art approaches.|在推荐系统和其他应用程序中，点进率(ctrl)预测起着至关重要的作用。近年来，用户行为序列建模引起了人们的广泛关注，并在 CTR 领域得到了很大的发展。现有的许多作品利用注意机制或反复神经网络从序列中挖掘用户兴趣，但未能认识到用户的实时兴趣具有内在的多样性和流动性这一简单事实。本文提出了一种新的基于动态图的分离表示框架 DisenCTR，用于 CTR 预测。与现有方法相比，我们的方法的关键新颖之处在于对用户的不同兴趣进行建模。具体来说，我们构造了一个由历史交互作用引起的时间演化的用户-项目交互图。基于图所提供的丰富的动态性，我们提出了一个分离的图表示模块来提取不同的用户兴趣。进一步利用用户兴趣的流动性，利用霍克斯过程混合模型对历史行为的时间效应进行建模。在三个真实世界数据集上的大量实验表明，与最先进的方法相比，我们的方法具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DisenCTR:+Dynamic+Graph-based+Disentangled+Representation+for+Click-Through+Rate+Prediction)|1|
|[BERT-based Dense Intra-ranking and Contextualized Late Interaction via Multi-task Learning for Long Document Retrieval](https://doi.org/10.1145/3477495.3531856)|Minghan Li, Éric Gaussier|Univ. Grenoble Alpes, CNRS, LIG, Grenoble, France|Combining query tokens and document tokens and inputting them to pre-trained transformer models like BERT, an approach known as interaction-based, has shown state-of-the-art effectiveness for information retrieval. However, the computational complexity of this approach is high due to the online self-attention computation. In contrast, dense retrieval methods in representation-based approaches are known to be efficient, however less effective. A tradeoff between the two is reached with late interaction methods like ColBERT, which attempt to benefit from both approaches: contextualized token embeddings can be pre-calculated over BERT for fine-grained effective interaction while preserving efficiency. However, despite its success in passage retrieval, it's not straightforward to use this approach for long document retrieval. In this paper, we propose a cascaded late interaction approach using a single model for long document retrieval. Fast intra-ranking by dot product is used to select relevant passages, then fine-grained interaction of pre-stored token embeddings is used to generate passage scores which are aggregated to the final document score. Multi-task learning is used to train a BERT model to optimize both a dot product and a fine-grained interaction loss functions. Our experiments reveal that the proposed approach obtains near state-of-the-art level effectiveness while being efficient on such collections as TREC 2019.|将查询令牌和文档令牌结合起来，并将它们输入到像 BERT 这样的经过预先训练的转换器模型中，这种方法被称为基于交互的方法，已经显示出对于信息检索的最先进的有效性。然而，由于在线自注意计算，这种方法的计算复杂度很高。相比之下，基于表示的方法中的密集检索方法已知是有效的，但是效率较低。这两种方法之间的折衷是通过 ColBERT 这样的后期交互方法实现的，它们试图从两种方法中受益: 上下文化的令牌嵌入可以在 BERT 上预先计算出细粒度的有效交互，同时保持效率。然而，尽管这种方法在文章检索方面取得了成功，但是要长时间地使用这种方法并不是一件简单的文献检索。在这篇文章中，我们提出了一个级联的晚期交互方法，使用单一模型的长期文献检索。首先利用点乘快速内排序来选择相关段落，然后利用预存储令牌嵌入的细粒度交互来生成段落分数，并将这些分数聚合为最终的文档分数。多任务学习用于训练 BERT 模型，以优化网点积和细粒度交互损失函数。我们的实验表明，所提出的方法获得接近最先进水平的效率，同时对 TREC 2019这样的集合是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BERT-based+Dense+Intra-ranking+and+Contextualized+Late+Interaction+via+Multi-task+Learning+for+Long+Document+Retrieval)|1|
|[RESETBERT4Rec: A Pre-training Model Integrating Time And User Historical Behavior for Sequential Recommendation](https://doi.org/10.1145/3477495.3532054)|Qihang Zhao|University of Science and Technology of China & JD AI Research, Hefei & Shanghai, China|Sequential recommendation methods are very important in modern recommender systems because they can well capture users' dynamic interests from their interaction history, and make accurate recommendations for users, thereby helping enterprises succeed in business. However, despite the great success of existing sequential recommendation-based methods, they focus too much on item-level modeling of users' click history and lack information about the user's entire click history (such as click order, click time, etc.). To tackle this problem, inspired by recent advances in pre-training techniques in the field of natural language processing, we build a new pre-training task based on the original BERT pre-training framework and incorporate temporal information. Specifically, we propose a new model called the RE arrange S equence prE -training and T ime embedding model via BERT for sequential R ecommendation (RESETBERT4Rec ) \footnoteThis work was completed during JD internship., it further captures the information of the user's whole click history by adding a rearrange sequence prediction task to the original BERT pre-training framework, while it integrates different views of time information. Comprehensive experiments on two public datasets as well as one e-commerce dataset demonstrate that RESETBERT4Rec achieves state-of-the-art performance over existing baselines.|序贯推荐方法在现代推荐系统中具有重要意义，因为它能够很好地从用户的交互历史中捕捉用户的动态兴趣，为用户提供准确的推荐，从而帮助企业获得成功。然而，尽管现有的基于顺序推荐的方法取得了巨大的成功，但它们过于关注用户点击历史的项目级建模，缺乏关于用户整个点击历史的信息(如点击顺序、点击时间等)。为了解决这一问题，受自然语言处理领域预训练技术的最新进展的启发，我们在原有的 BERT 预训练框架的基础上，结合时间信息构建了一个新的预训练任务。具体来说，我们提出了一个新的模型，称为 RE 安排 S 序列预训练和 T 时间嵌入模型，通过 BERT 进行顺序 R 推荐(RESETBERT4Rec)注释这项工作是在 JD 实习期间完成的，它通过在原有的 BERT 预训练框架中增加一个重排序列预测任务，进一步获取用户的整个点击历史信息，同时整合不同的时间信息视图。对两个公共数据集和一个电子商务数据集的综合实验表明，RESETBERT4Rec 在现有的基线上取得了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RESETBERT4Rec:+A+Pre-training+Model+Integrating+Time+And+User+Historical+Behavior+for+Sequential+Recommendation)|1|
|[Clustering based Behavior Sampling with Long Sequential Data for CTR Prediction](https://doi.org/10.1145/3477495.3531829)|Yuren Zhang, Enhong Chen, Binbin Jin, Hao Wang, Min Hou, Wei Huang, Runlong Yu|University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, Anhui, China; Huawei Cloud Computing Technologies Co., Ltd., Hangzhou, Zhejiang, China|Click-through rate (CTR) prediction is fundamental in many industrial applications, such as online advertising and recommender systems. With the development of the online platforms, the sequential user behaviors grow rapidly, bringing us great opportunity to better understand user preferences.However, it is extremely challenging for existing sequential models to effectively utilize the entire behavior history of each user. First, there is a lot of noise in such long histories, which can seriously hurt the prediction performance. Second, feeding the long behavior sequence directly results in infeasible inference time and storage cost. In order to tackle these challenges, in this paper we propose a novel framework, which we name as User Behavior Clustering Sampling (UBCS). In UBCS, short sub-sequences will be obtained from the whole user history sequence with two cascaded modules: (i) Behavior Sampling module samples short sequences related to candidate items using a novel sampling method which takes relevance and temporal information into consideration; (ii) Item Clustering module clusters items into a small number of cluster centroids, mitigating the impact of noise and improving efficiency. Then, the sampled short sub-sequences will be fed into the CTR prediction module for efficient prediction. Moreover, we conduct a self-supervised consistency pre-training task to extract user persona preference and optimize the sampling module effectively. Experiments on real-world datasets demonstrate the superiority and efficiency of our proposed framework.|在许多工业应用中，如在线广告和推荐系统中，点进率(ctrl)预测是基础。随着在线平台的发展，连续用户行为迅速增长，为我们更好地理解用户偏好带来了巨大的机遇。然而，对于现有的顺序模型来说，有效地利用每个用户的整个行为历史是极具挑战性的。首先，在如此长的历史中存在大量的噪声，这会严重影响预测性能。其次，长行为序列直接导致不可行的推理时间和存储成本。为了应对这些挑战，本文提出了一个新的框架，我们称之为用户行为聚类抽样(UBCS)。在 UBCS 中，通过两个级联模块从整个用户历史序列中获取短子序列: (1)行为采样模块采用一种新的考虑相关性和时间信息的采样方法对与候选项相关的短子序列进行采样; (2)项目聚类模块将项目聚类为少量的聚类质心，减少噪声的影响，提高效率。然后，将采样的短子序列输入 CTR 预测模块进行有效预测。此外，我们进行了自我监督的一致性预训练任务，以提取用户的人物偏好，并有效地优化抽样模块。在实际数据集上的实验表明了该框架的优越性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clustering+based+Behavior+Sampling+with+Long+Sequential+Data+for+CTR+Prediction)|1|
|[Matching Search Result Diversity with User Diversity Acceptance in Web Search Sessions](https://doi.org/10.1145/3477495.3531880)|Jiqun Liu, Fangyuan Han|The University of Oklahoma, Norman, OK, USA; Xiamen University, Xiamen, China|Promoting diversity in ranking while maintaining the relevance of ranked results is critical for enhancing human-centered search systems. While existing ranking algorithm and diversity IR metrics provide a solid basis for evaluating and improving search result diversification in offline experiments, it misses out possible divergences and temporal changes of users' levels of Diversity Acceptance, which in this work refers to the extent to which users actually prefer to interact with topically diversified search results. To address this gap between offline evaluations and users' expectations, we proposed an intuitive diversity acceptance measure and ran experiments for diversity acceptance prediction and diversity-aware re-ranking based on datasets from both controlled lab and naturalistic settings. Our results demonstrate that: 1) user diversity acceptance change across different query segments and session contexts, and can be predicted from search interaction signals; 2) our diversity-aware re-ranking algorithm utilizing predicted diversity acceptance and estimated relevance labels can effectively minimize the gap between diversity acceptance and result diversity, while maintaining SERP relevance levels. Our research presents an initial attempt on balancing user needs, result diversity, and SERP relevance in sessions and highlights the importance of studying diversity acceptance in promoting effective result diversification.|促进排名的多样性，同时保持排名结果的相关性，对于加强以人为中心的搜索系统至关重要。虽然现有的排名算法和多样性 IR 指标为评估和改善离线实验中的搜索结果多样性提供了坚实的基础，但它忽略了用户多样性接受水平的可能的分歧和时间变化，这在本文中指的是用户实际上更喜欢与主题多样化的搜索结果交互的程度。为了解决离线评估和用户期望之间的差距，我们提出了一个直观的多样性接受度量，并进行了基于受控实验室和自然环境数据集的多样性接受预测和多样性感知重新排序的实验。研究结果表明: 1)用户多样性接受度在不同查询段和会话上下文之间的变化，可以通过搜索交互信号进行预测; 2)我们的多样性感知重排算法利用预测的多样性接受度和估计的相关标签，可以有效地最小化多样性接受度和结果多样性之间的差距，同时保持 SERP 相关水平。我们的研究提出了在会议中平衡用户需求、结果多样性和 SERP 相关性的初步尝试，并强调了研究多样性接受在促进有效结果多样化中的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Matching+Search+Result+Diversity+with+User+Diversity+Acceptance+in+Web+Search+Sessions)|1|
|[Distill-VQ: Learning Retrieval Oriented Vector Quantization By Distilling Knowledge from Dense Embeddings](https://doi.org/10.1145/3477495.3531799)|Shitao Xiao, Zheng Liu, Weihao Han, Jianjin Zhang, Defu Lian, Yeyun Gong, Qi Chen, Fan Yang, Hao Sun, Yingxia Shao, Xing Xie||Vector quantization (VQ) based ANN indexes, such as Inverted File System (IVF) and Product Quantization (PQ), have been widely applied to embedding based document retrieval thanks to the competitive time and memory efficiency. Originally, VQ is learned to minimize the reconstruction loss, i.e., the distortions between the original dense embeddings and the reconstructed embeddings after quantization. Unfortunately, such an objective is inconsistent with the goal of selecting ground-truth documents for the input query, which may cause severe loss of retrieval quality. Recent works identify such a defect, and propose to minimize the retrieval loss through contrastive learning. However, these methods intensively rely on queries with ground-truth documents, whose performance is limited by the insufficiency of labeled data. In this paper, we propose Distill-VQ, which unifies the learning of IVF and PQ within a knowledge distillation framework. In Distill-VQ, the dense embeddings are leveraged as "teachers'', which predict the query's relevance to the sampled documents. The VQ modules are treated as the "students'', which are learned to reproduce the predicted relevance, such that the reconstructed embeddings may fully preserve the retrieval result of the dense embeddings. By doing so, Distill-VQ is able to derive substantial training signals from the massive unlabeled data, which significantly contributes to the retrieval quality. We perform comprehensive explorations for the optimal conduct of knowledge distillation, which may provide useful insights for the learning of VQ based ANN index. We also experimentally show that the labeled data is no longer a necessity for high-quality vector quantization, which indicates Distill-VQ's strong applicability in practice. The evaluations are performed on MS MARCO and Natural Questions benchmarks, where Distill-VQ notably outperforms the SOTA VQ methods in Recall and MRR. Our code is avaliable at https://github.com/staoxiao/LibVQ.|基于向量量化(vQ)的人工神经网络索引，例如倒置文件系统(IVF)和产品量化(PQ) ，由于具有竞争性的时间和存储效率，已被广泛应用于基于嵌入的文献检索。最初，学习 VQ 来最小化重构损失，即原始密集嵌入和量化后重构嵌入之间的失真。遗憾的是，这样的目标不符合为输入查询选择地面真实文档的目标，这可能导致检索质量的严重损失。最近的工作发现了这一缺陷，并提出通过对比学习来最小化检索损失。然而，这些方法主要依赖于对地面真相文档的查询，其性能受到标记数据不足的限制。在本文中，我们提出了提取 VQ，它在一个知识提取框架内将 IVF 和 PQ 的学习结合起来。在蒸馏 VQ 中，密集嵌入被用作“教师”，用于预测查询与采样文档的相关性。将 VQ 模块视为“学生”，学习再现预测的相关性，使得重构嵌入能够完全保留密集嵌入的检索结果。通过这种方法，DistilVQ 能够从海量的未标记数据中提取出大量的训练信号，从而大大提高了检索质量。本文对知识提取的最优化进行了全面的探索，为基于矢量量化的神经网络指标的学习提供了有益的启示。我们还通过实验表明，标记数据不再是高质量向量量化的必要条件，这表明蒸馏 VQ 在实践中的强大适用性。评估是在微软 MARCO 和自然问题基准上进行的，其中蒸馏 VQ 明显优于召回和 MRR 中的 SOTA VQ 方法。我们的代码 https://github.com/staoxiao/libvq 可用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distill-VQ:+Learning+Retrieval+Oriented+Vector+Quantization+By+Distilling+Knowledge+from+Dense+Embeddings)|1|
|[Neural Pseudo-Relevance Feedback Models for Sparse and Dense Retrieval](https://doi.org/10.1145/3477495.3531685)|Xiao Wang|University of Glasgow, Glasgow, Scotland, United Kingdom|Pseudo-relevance feedback mechanisms have long served as an effective technique to improve the retrieval effectiveness in information retrieval. Recently, large pre-trained language models, such as T5 and BERT, have shown a strong capacity to capture the latent traits of texts. Given the success of these models, we seek to study the capacity of these models for query reformulation. In addition, the BERT models have demonstrated further promise for dense retrieval, where the query and documents are encoded into the contextualised embeddings and relevant documents are retrieved by conducting the semantic matching operation. Although the success of pseudo-relevance feedback for sparse retrieval is well documented, effective pseudo-relevance feedback approaches for dense retrieval paradigm are still in their infancy. Thus, we are concerned with excavating the potential of the pseudo-relevance feedback information combined with the large pre-trained models to conduct effective query reformulation operating on both sparse retrieval and dense retrieval.|长期以来，伪相关反馈机制一直是提高信息检索检索效率的有效方法。近年来，大型的预训练语言模型，如 T5和 BERT，已经显示出很强的捕捉文本潜在特征的能力。鉴于这些模型的成功，我们寻求研究这些模型的查询重构能力。此外，BERT 模型还进一步展示了密集检索的前景，其中查询和文档被编码到上下文嵌入中，相关文档通过进行语义匹配操作进行检索。虽然伪相关反馈在稀疏检索方面的成功已有文献记载，但有效的伪相关反馈方法在密集检索范式中仍处于起步阶段。因此，我们致力于挖掘伪相关反馈信息与大型预训练模型相结合的潜力，对稀疏检索和密集检索进行有效的查询重构。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Pseudo-Relevance+Feedback+Models+for+Sparse+and+Dense+Retrieval)|1|
|[Neighbour Interaction based Click-Through Rate Prediction via Graph-masked Transformer](https://doi.org/10.1145/3477495.3532031)|Erxue Min, Yu Rong, Tingyang Xu, Yatao Bian, Da Luo, Kangyi Lin, Junzhou Huang, Sophia Ananiadou, Peilin Zhao|Weixin Open Platform, Tencent, Guangzhou, UNK, China; The University of Manchester, Manchester, UNK, United Kingdom; University of Texas at Arlington, Arlington, UNK, USA; University of Manchester, Manchester, UNK, United Kingdom; Tencent AI Lab, Shenzhen, UNK, China; Tencent AI lab, Shenzhen, UNK, China|Click-Through Rate (CTR) prediction, which aims to estimate the probability that a user will click an item, is an essential component of online advertising. Existing methods mainly attempt to mine user interests from users' historical behaviours, which contain users' directly interacted items. Although these methods have made great progress, they are often limited by the recommender system's direct exposure and inactive interactions, and thus fail to mine all potential user interests. To tackle these problems, we propose Neighbor-Interaction based CTR prediction (NI-CTR), which considers this task under a Heterogeneous Information Network (HIN) setting. In short, Neighbor-Interaction based CTR prediction involves the local neighborhood of the target user-item pair in the HIN to predict their linkage. In order to guide the representation learning of the local neighbourhood, we further consider different kinds of interactions among the local neighborhood nodes from both explicit and implicit perspective, and propose a novel Graph-Masked Transformer (GMT) to effectively incorporates these kinds of interactions to produce highly representative embeddings for the target user-item pair. Moreover, in order to improve model robustness against neighbour sampling, we enforce a consistency regularization loss over the neighbourhood embedding. We conduct extensive experiments on two real-world datasets with millions of instances and the experimental results show that our proposed method outperforms state-of-the-art CTR models significantly. Meanwhile, the comprehensive ablation studies verify the effectiveness of every component of our model. Furthermore, we have deployed this framework on the WeChat Official Account Platform with billions of users. The online A/B tests demonstrate an average CTR improvement of 21.9% against all online baselines.|点进率预测是在线广告的一个重要组成部分，其目的是估计用户点击某个项目的概率。现有的方法主要是从用户的历史行为中挖掘用户兴趣，这些历史行为包含了用户直接交互的项目。尽管这些方法已经取得了很大的进步，但它们往往受到推荐系统直接暴露和非活动交互的限制，因此无法挖掘所有潜在的用户兴趣。为了解决这些问题，我们提出了基于邻居交互的点击率预测(NI-CTR) ，它考虑了异构信息网络(HIN)环境下的任务。简而言之，基于邻域交互的 CTR 预测涉及到 HIN 中目标用户-项目对的局部邻域来预测它们之间的联系。为了指导局部邻域的表示学习，我们进一步从显式和隐式两个角度考虑局部邻域节点之间的不同交互，并提出了一种新的图掩盖变换器(GMT) ，以有效地整合这些交互，为目标用户项对产生高度代表性的嵌入。此外，为了提高模型对邻域采样的鲁棒性，我们对邻域嵌入增加了一个一致性正则化损失。我们在两个实际数据集上进行了大量的实验，实验结果表明，我们提出的方法明显优于最先进的 CTR 模型。同时，综合烧蚀研究验证了模型各组成部分的有效性。此外，我们已经在微信官方账号平台上部署了这个框架，拥有数十亿用户。在线 A/B 测试显示，与所有在线基线相比，点击率平均提高了21.9% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighbour+Interaction+based+Click-Through+Rate+Prediction+via+Graph-masked+Transformer)|1|
|[Why Don't You Click: Understanding Non-Click Results in Web Search with Brain Signals](https://doi.org/10.1145/3477495.3532082)|Ziyi Ye, Xiaohui Xie, Yiqun Liu, Zhihong Wang, Xuancheng Li, Jiaji Li, Xuesong Chen, Min Zhang, Shaoping Ma|The Chinese University of Hong Kong, Shenzhen, Shenzhen, China; Tsinghua University, Beijing, China|Web search heavily relies on click-through behavior as an essential feedback signal for performance evaluation and improvement. Traditionally, click is usually treated as a positive implicit feedback signal of relevance or usefulness, while non-click is regarded as a signal of irrelevance or uselessness. However, there are many cases where users satisfy their information need with the contents shown on the Search Engine Result Page (SERP). This raises the problem of measuring the usefulness of non-click results and modeling user satisfaction in such circumstances. For a long period, understanding non-click results is challenging owing to the lack of user interactions. In recent years, the rapid development of neuroimaging technologies constitutes a paradigm shift in various industries, e.g., search, entertainment, and education. Therefore, we benefit from these technologies and apply them to bridge the gap between the human mind and the external search system in non-click situations. To this end, we analyze the differences in brain signals between the examination of non-click search results in different usefulness levels. Inspired by these findings, we conduct supervised learning tasks to estimate the usefulness of non-click results with brain signals and conventional information (i.e., content and context factors). Furthermore, we devise two re-ranking methods, i.e., a Personalized Method (PM) and a Generalized Intent modeling Method (GIM), for search result re-ranking with the estimated usefulness. Results show that it is feasible to utilize brain signals to improve usefulness estimation performance and enhance human-computer interactions by search result re-ranking.|网络搜索在很大程度上依赖于点击行为作为性能评估和改进的重要反馈信号。传统上，点击通常被视为相关性或有用性的积极隐性反馈信号，而非点击则被视为无关性或无用性的信号。但是，在许多情况下，用户使用搜索引擎结果页(SERP)上显示的内容来满足他们的信息需求。这就提出了测量非点击结果的有用性以及在这种情况下建立用户满意度模型的问题。长期以来，由于缺乏用户交互，理解非点击结果是一项挑战。近年来，神经影像技术的快速发展构成了搜索、娱乐和教育等多个行业的范式转变。因此，我们从这些技术中受益，并应用它们在非点击情况下架起人类思维和外部搜索系统之间的桥梁。为此，我们分析了不同有用性水平的非点击检索结果在大脑信号方面的差异。受这些发现的启发，我们进行了一些监督式学习的任务，用大脑信号和传统信息(即内容和上下文因素)来评估非点击结果的有用性。此外，我们设计了两个重新排序的方法，即个性化方法(PM)和广义意图建模方法(GIM) ，用于搜索结果的重新排序与估计的有用性。实验结果表明，利用大脑信号进行搜索结果重排可以提高有用性估计性能，增强人机交互。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+Don't+You+Click:+Understanding+Non-Click+Results+in+Web+Search+with+Brain+Signals)|1|
|[Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation](https://doi.org/10.1145/3477495.3531989)|Nicholas Lim, Bryan Hooi, SeeKiong Ng, Yong Liang Goh, Renrong Weng, Rui Tan|National University of Singapore, Singapore, Singapore; GrabTaxi Holdings, Singapore, Singapore|Learning which Point-of-Interest (POI) a user will visit next is a challenging task for personalized recommender systems due to the large search space of possible POIs in the region. A recurring problem among existing works that makes it difficult to learn and perform well is the sparsity of the User-POI matrix. In this paper, we propose our Hierarchical Multi-Task Graph Recurrent Network (HMT-GRN) approach, which alleviates the data sparsity problem by learning different User-Region matrices of lower sparsities in a multi-task setting. We then perform a Hierarchical Beam Search (HBS) on the different region and POI distributions to hierarchically reduce the search space with increasing spatial granularity and predict the next POI. Our HBS provides efficiency gains by reducing the search space, resulting in speedups of 5 to 7 times over an exhaustive approach. In addition, we also propose a novel selectivity layer to predict if the next POI has been visited before by the user to balance between personalization and exploration. Experimental results on two real-world Location-Based Social Network (LBSN) datasets show that our model significantly outperforms baseline and the state-of-the-art methods.|由于该地区可能存在的 POI 搜索空间很大，因此了解用户下一步将访问哪个 POI 对于个性化推荐系统来说是一项具有挑战性的任务。现有作品中反复出现的一个难以学习和执行的问题是 User-POI 矩阵的稀疏性。本文提出了一种分层多任务图回归网络(HMT-GRN)方法，通过在多任务环境下学习不同稀疏度较低的用户区域矩阵来解决数据稀疏问题。然后对不同区域和 POI 分布进行分层束搜索(HBS) ，随着空间粒度的增加逐步减少搜索空间，并预测下一个 POI。我们的 HBS 通过减少搜索空间提供了效率增益，在一个详尽的方法中导致5到7倍的加速。此外，我们还提出了一个新的选择层来预测下一个 POI 是否已经被用户访问过，以便在个性化和探索之间取得平衡。在两个实际的基于位置的社会网络(LBSN)数据集上的实验结果表明，我们的模型明显优于基线和最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Multi-Task+Graph+Recurrent+Network+for+Next+POI+Recommendation)|1|
|[Progressive Self-Attention Network with Unsymmetrical Positional Encoding for Sequential Recommendation](https://doi.org/10.1145/3477495.3531800)|Yuehua Zhu, Bo Huang, Shaohua Jiang, Muli Yang, Yanhua Yang, Wenliang Zhong|AntGroup, Hangzhou, China; Xidian University, Xian, China|In real-world recommendation systems, the preferences of users are often affected by long-term constant interests and short-term temporal needs. The recently proposed Transformer-based models have proved superior in the sequential recommendation, modeling temporal dynamics globally via the remarkable self-attention mechanism. However, all equivalent item-item interactions in original self-attention are cumbersome, failing to capture the drifting of users' local preferences, which contain abundant short-term patterns. In this paper, we propose a novel interpretable convolutional self-attention, which efficiently captures both short- and long-term patterns with a progressive attention distribution. Specifically, a down-sampling convolution module is proposed to segment the overall long behavior sequence into a series of local subsequences. Accordingly, the segments are interacted with each item in the self-attention layer to produce locality-aware contextual representations, during which the quadratic complexity in original self-attention is reduced to nearly linear complexity. Moreover, to further enhance the robust feature learning in the context of Transformers, an unsymmetrical positional encoding strategy is carefully designed. Extensive experiments are carried out on real-world datasets, \eg ML-1M, Amazon Books, and Yelp, indicating that the proposed method outperforms the state-of-the-art methods w.r.t. both effectiveness and efficiency.|在实际的推荐系统中，用户的偏好往往受到长期不变的利益和短期的时间需求的影响。最近提出的变压器为基础的模型已被证明优越的顺序推荐，建模全球时间动态通过显着的自我注意机制。然而，原始自我注意中的所有等效项目-项目交互都是繁琐的，未能捕捉到用户本地偏好的漂移，其中包含了丰富的短期模式。在本文中，我们提出了一种新的可解释的卷积自我注意，有效地捕捉短期和长期的模式与逐步注意分布。特别地，提出了一种下采样卷积模块，将整个长行为序列分割成一系列局部子序列。相应地，这些片段与自我注意层中的每个项目相互作用，产生具有局部感知的上下文表征，在此过程中，原始自我注意的二次复杂度降低到接近线性复杂度。此外，为了进一步提高变压器环境下的鲁棒性特征学习，设计了一种非对称的位置编码策略。在现实世界的数据集上进行了大量的实验，例如 ML-1M，Amazon Books 和 Yelp，表明所提出的方法在效率和效果上都优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Self-Attention+Network+with+Unsymmetrical+Positional+Encoding+for+Sequential+Recommendation)|1|
|[A New Sequential Prediction Framework with Spatial-temporal Embedding](https://doi.org/10.1145/3477495.3531846)|Jihai Zhang, Fangquan Lin, Cheng Yang, Wei Jiang|Alibaba Group, Hangzhou, China|Sequential prediction is one of the key components in recommendation. In online e-commerce recommendation system, user behavior consists of the sequential visiting logs and item behavior contains the interacted user list in order. Most of the existing state-of-the-art sequential prediction methods only consider the user behavior while ignoring the item behavior. In addition, we find that user behavior varies greatly at different time, and most existing models fail to characterize the rich temporal information. To address the above problems, we propose a transformer-based spatial-temporal recommendation framework (STEM). In the STEM framework, we first utilize attention mechanisms to model user behavior and item behavior, and then exploit spatial and temporal information through a transformer-based model. The STEM framework, as a plug-in, is able to be incorporated into many neural network-based sequential recommendation methods to improve performance. We conduct extensive experiments on three real-world Amazon datasets. The results demonstrate the effectiveness of our proposed framework.|序贯预测是推荐系统的关键组成部分之一。在在线电子商务推荐系统中，用户行为由顺序访问日志组成，项目行为按顺序包含交互式用户列表。现有的大多数最先进的顺序预测方法只考虑用户行为，而忽略项目行为。此外，我们发现用户行为在不同的时间变化很大，现有的模型不能刻画丰富的时间信息。为了解决上述问题，我们提出了一个基于变压器的时空推荐框架(STEM)。在 STEM 框架中，我们首先利用注意机制对用户行为和项目行为进行建模，然后通过一个基于转换器的模型来利用空间和时间信息。STEM 框架作为一个插件，能够被整合到许多基于神经网络的顺序推荐方法中，以提高性能。我们在三个真实的亚马逊数据集上进行了广泛的实验。仿真结果表明了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Sequential+Prediction+Framework+with+Spatial-temporal+Embedding)|1|
|[Mitigating the Filter Bubble While Maintaining Relevance: Targeted Diversification with VAE-based Recommender Systems](https://doi.org/10.1145/3477495.3531890)|Zhaolin Gao, Tianshu Shen, Zheda Mai, Mohamed Reda Bouadjenek, Isaac Waller, Ashton Anderson, Ron Bodkin, Scott Sanner|Deakin University, Geelong, Australia; Vector Institute for Artificial Intelligence, Toronto, ON, Canada; Optimy AI, Toronto, ON, Canada; University of Toronto, Toronto, ON, Canada|Online recommendation systems are prone to create filter bubbles, whereby users are only recommended content narrowly aligned with their historical interests. In the case of media recommendation, this can reinforce political polarization by recommending topical content (e.g., on the economy) at one extreme end of the political spectrum even though this topic has broad coverage from multiple political viewpoints that would provide a more balanced and informed perspective for the user. Historically, Maximal Marginal Relevance (MMR) has been used to diversify result lists and even mitigate filter bubbles, but suffers from three key drawbacks: (1)~MMR directly sacrifices relevance for diversity, (2)~MMR typically diversifies across all content and not just targeted dimensions (e.g., political polarization), and (3)~MMR is inefficient in practice due to the need to compute pairwise similarities between recommended items. To simultaneously address these limitations, we propose a novel methodology that trains Concept Activation Vectors (CAVs) for targeted topical dimensions (e.g., political polarization). We then modulate the latent embeddings of user preferences in a state-of-the-art VAE-based recommender system to diversify along the targeted dimension while preserving topical relevance across orthogonal dimensions. Our experiments show that our Targeted Diversification VAE-based Collaborative Filtering (TD-VAE-CF) methodology better preserves relevance of content to user preferences across a range of diversification levels in comparison to both untargeted and targeted variations of Maximum Marginal Relevance (MMR); TD-VAE-CF is also much more computationally efficient than the post-hoc re-ranking approach of MMR.|在线推荐系统容易产生过滤气泡，用户只能被推荐与他们的历史兴趣狭窄地一致的内容。就媒体推荐而言，这可能会加剧政治两极分化，推荐政治光谱一端的主题内容(例如经济) ，尽管这个主题有多种政治观点的广泛覆盖，可以为用户提供一个更加平衡和知情的视角。从历史上看，最大边际相关(MMR)一直被用来使结果列表多样化，甚至减轻过滤器泡沫，但遭受三个关键的缺点: (1) ~ MMR 直接牺牲相关性的多样性，(2) ~ MMR 通常多样化跨所有内容，而不仅仅是有针对性的维度(例如，政治极化) ，和(3) ~ MMR 在实践中是低效的，因为需要计算推荐项目之间的成对相似性。为了同时解决这些局限性，我们提出了一种新的方法，训练概念激活向量(CAV)的目标主题维度(例如，政治极化)。然后，我们调整潜在的嵌入用户偏好在一个国家的最先进的 VAE 为基础的推荐系统，以多样化沿着目标的维度，同时保持跨正交维度的主题相关性。我们的实验表明，我们的基于目标多样化 VAE 的协同过滤(TD-VAE-CF)方法更好地保留了多样化水平范围内的用户偏好的内容相关性，与非目标和有针对性的最大边际相关性(MMR)变化相比，TD-VAE-CF 也比 MMR 的事后重新排序方法计算效率高得多。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+the+Filter+Bubble+While+Maintaining+Relevance:+Targeted+Diversification+with+VAE-based+Recommender+Systems)|1|
|[Modality-Balanced Embedding for Video Retrieval](https://doi.org/10.1145/3477495.3531899)|Xun Wang, Bingqing Ke, Xuanping Li, Fangyu Liu, Mingyu Zhang, Xiao Liang, Qiushi Xiao||Video search has become the main routine for users to discover videos relevant to a text query on large short-video sharing platforms. During training a query-video bi-encoder model using online search logs,\textit we identify a modality bias phenomenon that the video encoder almost entirely relies on text matching, neglecting other modalities of the videos such as vision, audio, \etc This modality imbalance results from a) modality gap: the relevance between a query and a video text is much easier to learn as the query is also a piece of text, with the same modality as the video text; b) data bias: most training samples can be solved solely by text matching. Here we share our practices to improve the first retrieval stage including our solution for the modality imbalance issue. We propose \modelname (short for Modality Balanced Video Retrieval) with two key components: manually generated modality-shuffled (MS) samples and a dynamic margin (DM) based on visual relevance. They can encourage the video encoder to pay balanced attentions to each modality. Through extensive experiments on a real world dataset, we show empirically that our method is both effective and efficient in solving modality bias problem. We have also deployed our ~\modelname~ in a large video platform and observed statistically significant boost over a highly optimized baseline in an A/B test and manual GSB evaluations.|视频搜索已成为用户在大型短视频分享平台上发现与文本查询相关的视频的主要程序。在使用在线搜索日志(texttit)对查询-视频双编码器模型进行训练时，我们发现了一种模态偏差现象，即视频编码器几乎完全依赖于文本匹配，而忽略了视频的其他模态，如视觉、音频等。这种模态偏差源于: a)模态差异: 查询和视频文本之间的相关性更容易学习，因为查询也是一段文本，具有与视频文本相同的模态; b)数据偏差: 大多数训练样本可以单独通过文本匹配来解决。在这里，我们分享我们的做法，以改善第一个检索阶段，包括我们的解决方案的形式不平衡的问题。提出了一种基于视觉相关性的动态边界检索模型，该模型由两个关键部分组成: 手动生成的模态混合样本(MS)和动态边界(DM)。它们可以鼓励视频编码器对每种模式给予均衡的关注。通过对实际数据集的大量实验，证明了该方法在解决模态偏差问题上的有效性。我们还在一个大型视频平台上部署了我们的“模型名”，并在 A/B 测试和手动 GSB 评估中观察到统计学上显著提高了高度优化的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modality-Balanced+Embedding+for+Video+Retrieval)|1|
|[Expanded Lattice Embeddings for Spoken Document Retrieval on Informal Meetings](https://doi.org/10.1145/3477495.3531921)|Esaú VillatoroTello, Srikanth R. Madikeri, Petr Motlícek, Aravind Ganapathiraju, Alexei V. Ivanov|Idiap Research Institute, Martigny, Switzerland; Uniphore Software Systems Inc., Palo Alto, CA, USA|In this paper, we evaluate different alternatives to process richer forms of Automatic Speech Recognition (ASR) output based on lattice expansion algorithms for Spoken Document Retrieval (SDR). Typically, SDR systems employ ASR transcripts to index and retrieve relevant documents. However, ASR errors negatively affect the retrieval performance. Multiple alternative hypotheses can also be used to augment the input to document retrieval to compensate for the erroneous one-best hypothesis. In Weighted Finite State Transducer-based ASR systems, using the n-best output (i.e. the top "n'' scoring hypotheses) for the retrieval task is common, since they can easily be fed to a traditional Information Retrieval (IR) pipeline. However, the n-best hypotheses are terribly redundant, and do not sufficiently encapsulate the richness of the ASR output, which is represented as an acyclic directed graph called the lattice. In particular, we utilize the lattice's constrained minimum path cover to generate a minimum set of hypotheses that serve as input to the reranking phase of IR. The novelty of our proposed approach is the incorporation of the lattice as an input for neural reranking by considering a set of hypotheses that represents every arc in the lattice. The obtained hypotheses are encoded through sentence embeddings using BERT-based models, namely SBERT and RoBERTa, and the final ranking of the retrieved segments is obtained with a max-pooling operation over the computed scores among the input query and the hypotheses set. We present our evaluation on the publicly available AMI meeting corpus. Our results indicate that the proposed use of hypotheses from the expanded lattice improves the SDR performance significantly over the n-best ASR output.|在这篇文章中，我们评估了处理更丰富形式的自动语音识别(ASR)输出的不同方案，这些方案是基于文献检索的格展开算法。通常，SDR 系统使用 ASR 记录来索引和检索相关文档。但是，ASR 错误会对检索性能产生负面影响。多重替代假设也可以用来增加对文献检索的输入，以弥补错误的最佳假设。在基于加权有限状态转换器的 ASR 系统中，对于检索任务使用 n 个最佳输出(即顶部的“ n”评分假设)是很常见的，因为它们可以很容易地提供给传统的信息检索(IR)流水线。然而，n 个最佳假设是非常多余的，并且没有充分封装 ASR 输出的丰富性，ASR 输出被表示为一个称为格的非循环有向图。特别地，我们利用格子的约束最小路覆盖生成一组最小假设，作为 IR 重新排序阶段的输入。我们提出的方法的新颖之处在于，通过考虑一组代表格子中每个弧的假设，将格子作为神经重新排序的输入。所得到的假设通过使用基于 BERT 的模型(即 SBERT 和 RoBERTa)的句子嵌入进行编码，并且通过对输入查询和假设集之间计算得分的最大池操作获得检索段的最终排序。我们提出了我们的评价公开可用的 AMI 会议语料库。我们的结果表明，提出的假设使用从扩展格提高软件无线电性能显着超过 n 最佳的 ASR 输出。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expanded+Lattice+Embeddings+for+Spoken+Document+Retrieval+on+Informal+Meetings)|1|
|[Improving Item Cold-start Recommendation via Model-agnostic Conditional Variational Autoencoder](https://doi.org/10.1145/3477495.3531902)|Xu Zhao, Yi Ren, Ying Du, Shenzheng Zhang, Nian Wang|Tencent News, Beijing, China|Embedding & MLP has become a paradigm for modern large-scale recommendation system. However, this paradigm suffers from the cold-start problem which will seriously compromise the ecological health of recommendation systems. This paper attempts to tackle the item cold-start problem by generating enhanced warmed-up ID embeddings for cold items with historical data and limited interaction records. From the aspect of industrial practice, we mainly focus on the following three points of item cold-start: 1) How to conduct cold-start without additional data requirements and make strategy easy to be deployed in online recommendation scenarios. 2) How to leverage both historical records and constantly emerging interaction data of new items. 3) How to model the relationship between item ID and side information stably from interaction data. To address these problems, we propose a model-agnostic Conditional Variational Autoencoder based Recommendation(CVAR) framework with some advantages including compatibility on various backbones, no extra requirements for data, utilization of both historical data and recent emerging interactions. CVAR uses latent variables to learn a distribution over item side information and generates desirable item ID embeddings using a conditional decoder. The proposed method is evaluated by extensive offline experiments on public datasets and online A/B tests on Tencent News recommendation platform, which further illustrate the advantages and robustness of CVAR.|嵌入式 MLP 已经成为现代大规模推荐系统的典范。然而，这种模式受到冷启动问题的影响，这将严重损害推荐系统的生态健康。本文试图利用历史数据和有限的交互记录为冷藏物品生成增强的预热 ID 嵌入，从而解决物品冷启动问题。从工业实践的角度出发，重点研究了项目冷启动的三个方面: 1)如何在不增加额外数据需求的情况下进行冷启动，使策略易于在在线推荐场景中部署。2)如何利用历史记录和新项目不断涌现的交互数据。3)如何从交互数据中稳定地建立项目 ID 与侧信息之间的关系模型。为了解决这些问题，我们提出了一个基于模型无关的条件变分自动编码器推荐(CVAR)框架，该框架具有一些优点，包括在不同骨干上的兼容性，对数据没有额外的要求，利用历史数据和最近出现的交互。CVAR 使用潜变量学习项目边信息的分布，并使用条件解码器生成所需的项目 ID 嵌入。该方法通过在公共数据集上的大量离线实验和在腾讯新闻推荐平台上的在线 A/B 测试进行了评估，进一步说明了 CVAR 的优势和稳健性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Item+Cold-start+Recommendation+via+Model-agnostic+Conditional+Variational+Autoencoder)|1|
|[Multi-Faceted Global Item Relation Learning for Session-Based Recommendation](https://doi.org/10.1145/3477495.3532024)|Qilong Han, Chi Zhang, Rui Chen, Riwei Lai, Hongtao Song, Li Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Faceted+Global+Item+Relation+Learning+for+Session-Based+Recommendation)|1|
|[Item Similarity Mining for Multi-Market Recommendation](https://doi.org/10.1145/3477495.3531839)|Jiangxia Cao, Xin Cong, Tingwen Liu, Bin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item+Similarity+Mining+for+Multi-Market+Recommendation)|1|
|[Interpreting Patient Descriptions using Distantly Supervised Similar Case Retrieval](https://doi.org/10.1145/3477495.3532003)|Israa Alghanmi, Luis Espinosa Anke, Steven Schockaert||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpreting+Patient+Descriptions+using+Distantly+Supervised+Similar+Case+Retrieval)|1|
|[Towards Explainable Search Results: A Listwise Explanation Generator](https://doi.org/10.1145/3477495.3532067)|Puxuan Yu, Razieh Rahimi, James Allan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Explainable+Search+Results:+A+Listwise+Explanation+Generator)|1|
|[Bit-aware Semantic Transformer Hashing for Multi-modal Retrieval](https://doi.org/10.1145/3477495.3531947)|Wentao Tan, Lei Zhu, Weili Guan, Jingjing Li, Zhiyong Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bit-aware+Semantic+Transformer+Hashing+for+Multi-modal+Retrieval)|1|
|[Multimodal Disentanglement Variational AutoEncoders for Zero-Shot Cross-Modal Retrieval](https://doi.org/10.1145/3477495.3532028)|Jialin Tian, Kai Wang, Xing Xu, Zuo Cao, Fumin Shen, Heng Tao Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Disentanglement+Variational+AutoEncoders+for+Zero-Shot+Cross-Modal+Retrieval)|1|
|[User-controllable Recommendation Against Filter Bubbles](https://doi.org/10.1145/3477495.3532075)|Wenjie Wang, Fuli Feng, Liqiang Nie, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-controllable+Recommendation+Against+Filter+Bubbles)|1|
|[Evaluation of Herd Behavior Caused by Population-scale Concept Drift in Collaborative Filtering](https://doi.org/10.1145/3477495.3531792)|Chenglong Ma, Yongli Ren, Pablo Castells, Mark Sanderson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluation+of+Herd+Behavior+Caused+by+Population-scale+Concept+Drift+in+Collaborative+Filtering)|1|
|[A 'Pointwise-Query, Listwise-Document' based Query Performance Prediction Approach](https://doi.org/10.1145/3477495.3531821)|Suchana Datta, Sean MacAvaney, Debasis Ganguly, Derek Greene||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+'Pointwise-Query,+Listwise-Document'+based+Query+Performance+Prediction+Approach)|1|
|[AHP: Learning to Negative Sample for Hyperedge Prediction](https://doi.org/10.1145/3477495.3531836)|Hyunjin Hwang, Seungwoo Lee, Chanyoung Park, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AHP:+Learning+to+Negative+Sample+for+Hyperedge+Prediction)|1|
|[Interactive Query Clarification and Refinement via User Simulation](https://doi.org/10.1145/3477495.3531871)|Pierre Erbacher, Ludovic Denoyer, Laure Soulier||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interactive+Query+Clarification+and+Refinement+via+User+Simulation)|1|
|[Explainable Session-based Recommendation with Meta-path Guided Instances and Self-Attention Mechanism](https://doi.org/10.1145/3477495.3531895)|Jiayin Zheng, Juanyun Mai, Yanlong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Session-based+Recommendation+with+Meta-path+Guided+Instances+and+Self-Attention+Mechanism)|1|
|[QSG Transformer: Transformer with Query-Attentive Semantic Graph for Query-Focused Summarization](https://doi.org/10.1145/3477495.3531901)|Choongwon Park, Youngjoong Ko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QSG+Transformer:+Transformer+with+Query-Attentive+Semantic+Graph+for+Query-Focused+Summarization)|1|
|[Next Point-of-Interest Recommendation with Auto-Correlation Enhanced Multi-Modal Transformer Network](https://doi.org/10.1145/3477495.3531905)|Yanjun Qin, Yuchen Fang, Haiyong Luo, Fang Zhao, Chenxing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Next+Point-of-Interest+Recommendation+with+Auto-Correlation+Enhanced+Multi-Modal+Transformer+Network)|1|
|[Neutralizing Popularity Bias in Recommendation Models](https://doi.org/10.1145/3477495.3531907)|Guipeng Xv, Chen Lin, Hui Li, Jinsong Su, Weiyao Ye, Yewang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neutralizing+Popularity+Bias+in+Recommendation+Models)|1|
|[ROGUE: A System for Exploratory Search of GANs](https://doi.org/10.1145/3477495.3531675)|Yang Liu, Alan Medlar, Dorota Glowacka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ROGUE:+A+System+for+Exploratory+Search+of+GANs)|1|
|[Searching for a New and Better Future of Work](https://doi.org/10.1145/3477495.3532088)|Jaime Teevan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Searching+for+a+New+and+Better+Future+of+Work)|1|
|[INMO: A Model-Agnostic and Scalable Module for Inductive Collaborative Filtering](https://doi.org/10.1145/3477495.3532000)|Yunfan Wu, Qi Cao, Huawei Shen, Shuchang Tao, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=INMO:+A+Model-Agnostic+and+Scalable+Module+for+Inductive+Collaborative+Filtering)|1|
|[Conversational Question Answering on Heterogeneous Sources](https://doi.org/10.1145/3477495.3531815)|Philipp Christmann, Rishiraj Saha Roy, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Question+Answering+on+Heterogeneous+Sources)|1|
|[COSPLAY: Concept Set Guided Personalized Dialogue Generation Across Both Party Personas](https://doi.org/10.1145/3477495.3531957)|Chen Xu, Piji Li, Wei Wang, Haoran Yang, Siyun Wang, Chuangbai Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COSPLAY:+Concept+Set+Guided+Personalized+Dialogue+Generation+Across+Both+Party+Personas)|1|
|[KETCH: Knowledge Graph Enhanced Thread Recommendation in Healthcare Forums](https://doi.org/10.1145/3477495.3532008)|Limeng Cui, Dongwon Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KETCH:+Knowledge+Graph+Enhanced+Thread+Recommendation+in+Healthcare+Forums)|1|
|[Explainable Legal Case Matching via Inverse Optimal Transport-based Rationale Extraction](https://doi.org/10.1145/3477495.3531974)|Weijie Yu, Zhongxiang Sun, Jun Xu, Zhenhua Dong, Xu Chen, Hongteng Xu, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Legal+Case+Matching+via+Inverse+Optimal+Transport-based+Rationale+Extraction)|1|
|[Optimizing Generalized Gini Indices for Fairness in Rankings](https://doi.org/10.1145/3477495.3532035)|Virginie Do, Nicolas Usunier||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Generalized+Gini+Indices+for+Fairness+in+Rankings)|1|
|[Video Moment Retrieval from Text Queries via Single Frame Annotation](https://doi.org/10.1145/3477495.3532078)|Ran Cui, Tianwen Qian, Pai Peng, Elena Daskalaki, Jingjing Chen, Xiaowei Guo, Huyang Sun, YuGang Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Video+Moment+Retrieval+from+Text+Queries+via+Single+Frame+Annotation)|1|
|[You Need to Read Again: Multi-granularity Perception Network for Moment Retrieval in Videos](https://doi.org/10.1145/3477495.3532083)|Xin Sun, Xuan Wang, Jialin Gao, Qiong Liu, Xi Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Need+to+Read+Again:+Multi-granularity+Perception+Network+for+Moment+Retrieval+in+Videos)|1|
|[Personalized Abstractive Opinion Tagging](https://doi.org/10.1145/3477495.3532037)|Mengxue Zhao, Yang Yang, Miao Li, Jingang Wang, Wei Wu, Pengjie Ren, Maarten de Rijke, Zhaochun Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Abstractive+Opinion+Tagging)|1|
|[Contrastive Learning with Hard Negative Entities for Entity Set Expansion](https://doi.org/10.1145/3477495.3531954)|Yinghui Li, Yangning Li, Yuxin He, Tianyu Yu, Ying Shen, HaiTao Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+with+Hard+Negative+Entities+for+Entity+Set+Expansion)|1|
|[EFLEC: Efficient Feature-LEakage Correction in GNN based Recommendation Systems](https://doi.org/10.1145/3477495.3531770)|Ishaan Kumar, Yaochen Hu, Yingxue Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFLEC:+Efficient+Feature-LEakage+Correction+in+GNN+based+Recommendation+Systems)|1|
|[P3 Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning](https://doi.org/10.1145/3477495.3531786)|Xiaomeng Hu, Shi Yu, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu, Ge Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=P3+Ranker:+Mitigating+the+Gaps+between+Pre-training+and+Ranking+Fine-tuning+with+Prompt-based+Learning+and+Pre-finetuning)|1|
|[Empowering Next POI Recommendation with Multi-Relational Modeling](https://doi.org/10.1145/3477495.3531801)|Zheng Huang, Jing Ma, Yushun Dong, Natasha Zhang Foutz, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Next+POI+Recommendation+with+Multi-Relational+Modeling)|1|
|[Learning Trustworthy Web Sources to Derive Correct Answers and Reduce Health Misinformation in Search](https://doi.org/10.1145/3477495.3531812)|Dake Zhang, Amir Vakili Tahami, Mustafa Abualsaud, Mark D. Smucker||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Trustworthy+Web+Sources+to+Derive+Correct+Answers+and+Reduce+Health+Misinformation+in+Search)|1|
|[On Optimizing Top-K Metrics for Neural Ranking Models](https://doi.org/10.1145/3477495.3531849)|Rolf Jagerman, Zhen Qin, Xuanhui Wang, Michael Bendersky, Marc Najork||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Optimizing+Top-K+Metrics+for+Neural+Ranking+Models)|1|
|[Identifying Argumentative Questions in Web Search Logs](https://doi.org/10.1145/3477495.3531864)|Yamen Ajjour, Pavel Braslavski, Alexander Bondarenko, Benno Stein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Argumentative+Questions+in+Web+Search+Logs)|1|
|[An MLP-based Algorithm for Efficient Contrastive Graph Recommendations](https://doi.org/10.1145/3477495.3531874)|Siwei Liu, Iadh Ounis, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+MLP-based+Algorithm+for+Efficient+Contrastive+Graph+Recommendations)|1|
|[Entity-Conditioned Question Generation for Robust Attention Distribution in Neural Information Retrieval](https://doi.org/10.1145/3477495.3531878)|Revanth Gangi Reddy, Md. Arafat Sultan, Martin Franz, Avirup Sil, Heng Ji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity-Conditioned+Question+Generation+for+Robust+Attention+Distribution+in+Neural+Information+Retrieval)|1|
|[C3: Continued Pretraining with Contrastive Weak Supervision for Cross Language Ad-Hoc Retrieval](https://doi.org/10.1145/3477495.3531886)|Eugene Yang, Suraj Nair, Ramraj Chandradevan, Rebecca IglesiasFlores, Douglas W. Oard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=C3:+Continued+Pretraining+with+Contrastive+Weak+Supervision+for+Cross+Language+Ad-Hoc+Retrieval)|1|
|[A Meta-learning Approach to Fair Ranking](https://doi.org/10.1145/3477495.3531892)|Yuan Wang, Zhiqiang Tao, Yi Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Meta-learning+Approach+to+Fair+Ranking)|1|
|[Where Does the Performance Improvement Come From?: - A Reproducibility Concern about Image-Text Retrieval](https://doi.org/10.1145/3477495.3531715)|Jun Rao, Fei Wang, Liang Ding, Shuhan Qi, Yibing Zhan, Weifeng Liu, Dacheng Tao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Where+Does+the+Performance+Improvement+Come+From?:+-+A+Reproducibility+Concern+about+Image-Text+Retrieval)|1|
|[Competitive Search](https://doi.org/10.1145/3477495.3532771)|Oren Kurland, Moshe Tennenholtz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Competitive+Search)|1|
|[A Dataset for Sentence Retrieval for Open-Ended Dialogues](https://doi.org/10.1145/3477495.3531727)|Itay Harel, Hagai Taitelbaum, Idan Szpektor, Oren Kurland||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dataset+for+Sentence+Retrieval+for+Open-Ended+Dialogues)|1|
|[iRec: An Interactive Recommendation Framework](https://doi.org/10.1145/3477495.3531754)|Thiago Silva, Nícollas Silva, Heitor Werneck, Carlos Mito, Adriano C. M. Pereira, Leonardo Rocha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iRec:+An+Interactive+Recommendation+Framework)|1|
|[RecDelta: An Interactive Dashboard on Top-k Recommendation for Cross-model Evaluation](https://doi.org/10.1145/3477495.3531674)|YiShyuan Chiang, YuZe Liu, ChenFeng Tsai, JingKai Lou, MingFeng Tsai, ChuanJu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecDelta:+An+Interactive+Dashboard+on+Top-k+Recommendation+for+Cross-model+Evaluation)|1|
|[Asyncval: A Toolkit for Asynchronously Validating Dense Retriever Checkpoints During Training](https://doi.org/10.1145/3477495.3531658)|Shengyao Zhuang, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Asyncval:+A+Toolkit+for+Asynchronously+Validating+Dense+Retriever+Checkpoints+During+Training)|1|
|[TaskMAD: A Platform for Multimodal Task-Centric Knowledge-Grounded Conversational Experimentation](https://doi.org/10.1145/3477495.3531679)|Alessandro Speggiorin, Jeffrey Dalton, Anton Leuski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TaskMAD:+A+Platform+for+Multimodal+Task-Centric+Knowledge-Grounded+Conversational+Experimentation)|1|
|[IRVILAB: Gamified Searching on Multilingual Wikipedia](https://doi.org/10.1145/3477495.3531662)|Paavo Arvola, Tuulikki Alamettälä||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IRVILAB:+Gamified+Searching+on+Multilingual+Wikipedia)|1|
|[Improving Efficiency and Robustness of Transformer-based Information Retrieval Systems](https://doi.org/10.1145/3477495.3532681)|Edmon Begoli, Sudarshan Srinivasan, Maria Mahbub||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Efficiency+and+Robustness+of+Transformer-based+Information+Retrieval+Systems)|1|
|[Self-Supervised Learning for Recommender System](https://doi.org/10.1145/3477495.3532684)|Chao Huang, Xiang Wang, Xiangnan He, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Learning+for+Recommender+System)|1|
|[ReNeuIR: Reaching Efficiency in Neural Information Retrieval](https://doi.org/10.1145/3477495.3531704)|Sebastian Bruch, Claudio Lucchese, Franco Maria Nardini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReNeuIR:+Reaching+Efficiency+in+Neural+Information+Retrieval)|1|
|[Generating Knowledge-based Explanation for Recommendation from Review](https://doi.org/10.1145/3477495.3531683)|Zuoxi Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Knowledge-based+Explanation+for+Recommendation+from+Review)|1|
|[Improving Fairness and Transparency for Artists in Music Recommender Systems](https://doi.org/10.1145/3477495.3531681)|Karlijn Dinnissen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Fairness+and+Transparency+for+Artists+in+Music+Recommender+Systems)|1|
|[Exploring Modular Task Decomposition in Cross-domain Named Entity Recognition](https://doi.org/10.1145/3477495.3531976)|Xinghua Zhang, Bowen Yu, Yubin Wang, Tingwen Liu, Taoyu Su, Hongbo Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Modular+Task+Decomposition+in+Cross-domain+Named+Entity+Recognition)|1|
|[Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification](https://doi.org/10.1145/3477495.3531984)|Kai Zhang, Qi Liu, Zhenya Huang, Mingyue Cheng, Kun Zhang, Mengdi Zhang, Wei Wu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Adaptive+Semantic+Transfer+for+Cross-domain+Sentiment+Classification)|1|
|[Hybrid CNN Based Attention with Category Prior for User Image Behavior Modeling](https://doi.org/10.1145/3477495.3531854)|Xin Chen, Qingtao Tang, Ke Hu, Yue Xu, Shihang Qiu, Jia Cheng, Jun Lei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hybrid+CNN+Based+Attention+with+Category+Prior+for+User+Image+Behavior+Modeling)|1|
|[When Online Meets Offline: Exploring Periodicity for Travel Destination Prediction](https://doi.org/10.1145/3477495.3531859)|Wanjie Tao, Liangyue Li, Chen Chen, Zulong Chen, Hong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Online+Meets+Offline:+Exploring+Periodicity+for+Travel+Destination+Prediction)|1|
|[Modeling User Behavior With Interaction Networks for Spam Detection](https://doi.org/10.1145/3477495.3531875)|Prabhat Agarwal, Manisha Srivastava, Vishwakarma Singh, Charles Rosenberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+User+Behavior+With+Interaction+Networks+for+Spam+Detection)|1|
|[ArchivalQA: A Large-scale Benchmark Dataset for Open-Domain Question Answering over Historical News Collections](https://doi.org/10.1145/3477495.3531734)|Jiexin Wang, Adam Jatowt, Masatoshi Yoshikawa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ArchivalQA:+A+Large-scale+Benchmark+Dataset+for+Open-Domain+Question+Answering+over+Historical+News+Collections)|1|
|[Structure and Semantics Preserving Document Representations](https://doi.org/10.1145/3477495.3532062)|Natraj Raman, Sameena Shah, Manuela Veloso||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structure+and+Semantics+Preserving+Document+Representations)|1|
|[Aspect Feature Distillation and Enhancement Network for Aspect-based Sentiment Analysis](https://doi.org/10.1145/3477495.3531938)|Rui Liu, Jiahao Cao, Nannan Sun, Lei Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aspect+Feature+Distillation+and+Enhancement+Network+for+Aspect-based+Sentiment+Analysis)|1|
|[Detecting Frozen Phrases in Open-Domain Question Answering](https://doi.org/10.1145/3477495.3531793)|Mostafa Yadegari, Ehsan Kamalloo, Davood Rafiei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Frozen+Phrases+in+Open-Domain+Question+Answering)|1|
|[Understanding User Satisfaction with Task-oriented Dialogue Systems](https://doi.org/10.1145/3477495.3531798)|Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+User+Satisfaction+with+Task-oriented+Dialogue+Systems)|1|
|[On Survivorship Bias in MS MARCO](https://doi.org/10.1145/3477495.3531832)|Prashansa Gupta, Sean MacAvaney||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Survivorship+Bias+in+MS+MARCO)|1|
|[Bias Mitigation for Evidence-aware Fake News Detection by Causal Intervention](https://doi.org/10.1145/3477495.3531850)|Junfei Wu, Qiang Liu, Weizhi Xu, Shu Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+Mitigation+for+Evidence-aware+Fake+News+Detection+by+Causal+Intervention)|1|
|[Preference Enhanced Social Influence Modeling for Network-Aware Cascade Prediction](https://doi.org/10.1145/3477495.3532042)|Likang Wu, Hao Wang, Enhong Chen, Zhi Li, Hongke Zhao, Jianhui Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preference+Enhanced+Social+Influence+Modeling+for+Network-Aware+Cascade+Prediction)|1|
|[Users and Contemporary SERPs: A (Re-)Investigation](https://doi.org/10.1145/3477495.3531719)|Nirmal Roy, David Maxwell, Claudia Hauff||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Users+and+Contemporary+SERPs:+A+(Re-)Investigation)|1|
|[ReMeDi: Resources for Multi-domain, Multi-service, Medical Dialogues](https://doi.org/10.1145/3477495.3531809)|Guojun Yan, Jiahuan Pei, Pengjie Ren, Zhaochun Ren, Xin Xin, Huasheng Liang, Maarten de Rijke, Zhumin Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReMeDi:+Resources+for+Multi-domain,+Multi-service,+Medical+Dialogues)|1|
|[Online DATEing: A Web Interface for Temporal Annotations](https://doi.org/10.1145/3477495.3531670)|Dennis Aumiller, Satya Almasian, David Pohl, Michael Gertz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+DATEing:+A+Web+Interface+for+Temporal+Annotations)|1|
|[Few-shot Node Classification on Attributed Networks with Graph Meta-learning](https://doi.org/10.1145/3477495.3531978)|Yonghao Liu, Mengyu Li, Ximing Li, Fausto Giunchiglia, Xiaoyue Feng, Renchu Guan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+Node+Classification+on+Attributed+Networks+with+Graph+Meta-learning)|1|
|[Co-clustering Interactions via Attentive Hypergraph Neural Network](https://doi.org/10.1145/3477495.3531868)|Tianchi Yang, Cheng Yang, Luhao Zhang, Chuan Shi, Maodi Hu, Huaijun Liu, Tao Li, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-clustering+Interactions+via+Attentive+Hypergraph+Neural+Network)|1|
|[Mutual Disentanglement Learning for Joint Fine-Grained Sentiment Classification and Controllable Text Generation](https://doi.org/10.1145/3477495.3532029)|Hao Fei, Chenliang Li, Donghong Ji, Fei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mutual+Disentanglement+Learning+for+Joint+Fine-Grained+Sentiment+Classification+and+Controllable+Text+Generation)|1|
|[Learning Disentangled Representations for Counterfactual Regression via Mutual Information Minimization](https://doi.org/10.1145/3477495.3532011)|Mingyuan Cheng, Xinru Liao, Quan Liu, Bin Ma, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Disentangled+Representations+for+Counterfactual+Regression+via+Mutual+Information+Minimization)|1|
|[L3E-HD: A Framework Enabling Efficient Ensemble in High-Dimensional Space for Language Tasks](https://doi.org/10.1145/3477495.3531761)|Fangxin Liu, Haomin Li, Xiaokang Yang, Li Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=L3E-HD:+A+Framework+Enabling+Efficient+Ensemble+in+High-Dimensional+Space+for+Language+Tasks)|1|
|[Graph Capsule Network with a Dual Adaptive Mechanism](https://doi.org/10.1145/3477495.3531764)|Xiangping Zheng, Xun Liang, Bo Wu, Yuhui Guo, Xuan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Capsule+Network+with+a+Dual+Adaptive+Mechanism)|1|
|[Training Entire-Space Models for Target-oriented Opinion Words Extraction](https://doi.org/10.1145/3477495.3531768)|Yuncong Li, Fang Wang, ShengHua Zhong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Training+Entire-Space+Models+for+Target-oriented+Opinion+Words+Extraction)|1|
|[Point Prompt Tuning for Temporally Language Grounding](https://doi.org/10.1145/3477495.3531795)|Yawen Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Point+Prompt+Tuning+for+Temporally+Language+Grounding)|1|
|[What Makes a Good Podcast Summary?](https://doi.org/10.1145/3477495.3531802)|Rezvaneh Rezapour, Sravana Reddy, Rosie Jones, Ian Soboroff||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+Makes+a+Good+Podcast+Summary?)|1|
|[BSAL: A Framework of Bi-component Structure and Attribute Learning for Link Prediction](https://doi.org/10.1145/3477495.3531804)|Bisheng Li, Min Zhou, Shengzhong Zhang, Menglin Yang, Defu Lian, Zengfeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BSAL:+A+Framework+of+Bi-component+Structure+and+Attribute+Learning+for+Link+Prediction)|1|
|[Tensor-based Graph Modularity for Text Data Clustering](https://doi.org/10.1145/3477495.3531834)|Rafika Boutalbi, Mira Ait Saada, Anastasiia Iurshina, Steffen Staab, Mohamed Nadif||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tensor-based+Graph+Modularity+for+Text+Data+Clustering)|1|
|[GraphAD: A Graph Neural Network for Entity-Wise Multivariate Time-Series Anomaly Detection](https://doi.org/10.1145/3477495.3531848)|Xu Chen, Qiu Qiu, Changshan Li, Kunqing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphAD:+A+Graph+Neural+Network+for+Entity-Wise+Multivariate+Time-Series+Anomaly+Detection)|1|
|[Lightweight Meta-Learning for Low-Resource Abstractive Summarization](https://doi.org/10.1145/3477495.3531908)|Taehun Huh, Youngjoong Ko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lightweight+Meta-Learning+for+Low-Resource+Abstractive+Summarization)|1|
|[Task-Oriented Dialogue System as Natural Language Generation](https://doi.org/10.1145/3477495.3531920)|Weizhi Wang, Zhirui Zhang, Junliang Guo, Yinpei Dai, Boxing Chen, Weihua Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Oriented+Dialogue+System+as+Natural+Language+Generation)|1|
|[Where Do Queries Come From?](https://doi.org/10.1145/3477495.3531711)|Marwah Alaofi, Luke Gallagher, Dana McKay, Lauren L. Saling, Mark Sanderson, Falk Scholer, Damiano Spina, Ryen W. White||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Where+Do+Queries+Come+From?)|1|
|[OVQA: A Clinically Generated Visual Question Answering Dataset](https://doi.org/10.1145/3477495.3531724)|Yefan Huang, Xiaoli Wang, Feiyan Liu, Guofeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OVQA:+A+Clinically+Generated+Visual+Question+Answering+Dataset)|1|
|[Monant Medical Misinformation Dataset: Mapping Articles to Fact-Checked Claims](https://doi.org/10.1145/3477495.3531726)|Ivan Srba, Branislav Pecher, Matús Tomlein, Róbert Móro, Elena Stefancova, Jakub Simko, Mária Bieliková||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Monant+Medical+Misinformation+Dataset:+Mapping+Articles+to+Fact-Checked+Claims)|1|
|[ViQuAE, a Dataset for Knowledge-based Visual Question Answering about Named Entities](https://doi.org/10.1145/3477495.3531753)|Paul Lerner, Olivier Ferret, Camille Guinaudeau, Hervé Le Borgne, Romaric Besançon, José G. Moreno, Jesús LovónMelgarejo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ViQuAE,+a+Dataset+for+Knowledge-based+Visual+Question+Answering+about+Named+Entities)|1|
|[DIANES: A DEI Audit Toolkit for News Sources](https://doi.org/10.1145/3477495.3531660)|Xiaoxiao Shang, Zhiyuan Peng, Qiming Yuan, Sabiq Khan, Lauren Xie, Yi Fang, Subramaniam Vincent||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIANES:+A+DEI+Audit+Toolkit+for+News+Sources)|1|
|[NAS-CTR: Efficient Neural Architecture Search for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3532030)|Guanghui Zhu, Feng Cheng, Defu Lian, Chunfeng Yuan, Yihua Huang|University of Science and Technology of China, Hefei, China; Nanjing University, Nanjing, China|Click-Through Rate (CTR) prediction has been widely used in many machine learning tasks such as online advertising and personalization recommendation. Unfortunately, given a domain-specific dataset, searching effective feature interaction operations and combinations from a huge candidate space requires significant expert experience and computational costs. Recently, Neural Architecture Search (NAS) has achieved great success in discovering high-quality network architectures automatically. However, due to the diversity of feature interaction operations and combinations, the existing NAS-based work that treats the architecture search as a black-box optimization problem over a discrete search space suffers from low efficiency. Therefore, it is essential to explore a more efficient architecture search method. To achieve this goal, we propose NAS-CTR, a differentiable neural architecture search approach for CTR prediction. First, we design a novel and expressive architecture search space and a continuous relaxation scheme to make the search space differentiable. Second, we formulate the architecture search for CTR prediction as a joint optimization problem with discrete constraints on architectures and leverage proximal iteration to solve the constrained optimization problem. Additionally, a straightforward yet effective method is proposed to eliminate the aggregation of skip connections. Extensive experimental results reveal that NAS-CTR can outperform the SOTA human-crafted architectures and other NAS-based methods in both test accuracy and search efficiency.|点进率预测已经广泛应用于许多机器学习任务，例如在线广告和个性化推荐。不幸的是，给定一个特定领域的数据集，从一个巨大的候选空间中搜索有效的特征交互操作和组合需要大量的专家经验和计算成本。近年来，神经网络体系结构搜索(NAS)在自动发现高质量的网络体系结构方面取得了巨大的成功。然而，由于功能交互操作和组合的多样性，现有的基于 NAS 的工作将体系结构搜索视为离散搜索空间上的黑盒子最佳化问题，效率低下。因此，有必要探索一种更有效的体系结构搜索方法。为了实现这一目标，我们提出了 NAS-CTR，一种用于 CTR 预测的可微分神经结构搜索方法。首先，我们设计了一个新颖的、具有表现力的体系结构搜索空间和一个连续松弛方案，使搜索空间具有可微性。其次，我们将 CTR 预测的体系结构搜索描述为一个联合最佳化问题，对体系结构进行离散约束，并利用近端迭代来解决约束最佳化问题。此外，提出了一种简单而有效的方法来消除跳跃连接的聚集。大量的实验结果表明，NAS-CTR 在测试精度和搜索效率方面都优于 SOTA 人工架构和其他基于 NAS 的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NAS-CTR:+Efficient+Neural+Architecture+Search+for+Click-Through+Rate+Prediction)|0|
|[Learning to Enrich Query Representation with Pseudo-Relevance Feedback for Cross-lingual Retrieval](https://doi.org/10.1145/3477495.3532013)|Ramraj Chandradevan, Eugene Yang, Mahsa Yarmohammadi, Eugene Agichtein|Johns Hopkins University, Baltimore, MD, USA; Emory University, Atlanta, GA, USA|Cross-lingual information retrieval (CLIR) aims to provide access to information across languages. Recent pre-trained multilingual language models brought large improvements to the natural language tasks, including cross-lingual adhoc retrieval. However, pseudo-relevance feedback (PRF), a family of techniques for improving ranking using the contents of top initially retrieved items, has not been explored with neural CLIR retrieval models. Two of the challenges are incorporating feedback from long documents, and cross-language knowledge transfer. To address these challenges, we propose a novel neural CLIR architecture, NCLPRF, capable of incorporating PRF feedback from multiple potentially long documents, which enables improvements to query representation in the shared semantic space between query and document languages. The additional information that the feedback documents provide in a target language, can enrich the query representation, bringing it closer to relevant documents in the embedding space. The proposed model performance across three CLIR test collections in Chinese, Russian, and Persian languages, exhibits significant improvements over traditional and SOTA neural CLIR baselines across all three collections.|跨语言信息检索(CLIR)旨在提供跨语言的信息获取途径。最近预先训练的多语言模型给自然语言任务带来了很大的改进，包括跨语言的即席检索。然而，伪相关反馈(PRF)作为一种利用最初检索项目的内容来提高排名的技术，尚未在神经元 CLIR 检索模型中得到应用。其中两个挑战是整合来自长文档的反馈，以及跨语言的知识转移。为了应对这些挑战，我们提出了一个新的神经 CLIR 架构，NCLPRF，能够合并来自多个潜在的长文档的 PRF 反馈，这使得查询语言和文档语言之间的共享语义空间中的查询表示得到改进。反馈文档以目标语言提供的附加信息可以丰富查询表示，使其更接近嵌入空间中的相关文档。在中文，俄文和波斯语的三个 CLIR 测试集合中，所提出的模型性能比所有三个集合中的传统和 SOTA 神经 CLIR 基线都有显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Enrich+Query+Representation+with+Pseudo-Relevance+Feedback+for+Cross-lingual+Retrieval)|0|
|[Incorporating Retrieval Information into the Truncation of Ranking Lists for Better Legal Search](https://doi.org/10.1145/3477495.3531998)|Yixiao Ma, Qingyao Ai, Yueyue Wu, Yunqiu Shao, Yiqun Liu, Min Zhang, Shaoping Ma|Tsinghua University, Beijing, China; University of Utah, Salt Lake City, UT, USA|The truncation of ranking lists predicted by retrieval models is vital to ensure users' search experience. Particularly, in specific vertical domains where documents are usually complicated and extensive (e.g., legal cases), the cost of browsing results is much higher than traditional IR tasks (e.g., Web search) and setting a reasonable cut-off position is quite necessary. While it is straightforward to apply existing result list truncation approaches to legal case retrieval, the effectiveness of these methods is limited because they only focus on simple document statistics and usually fail to capture the context information of documents in the ranking list. These existing efforts also treat result list truncation as an isolated task instead of a component in the entire ranking process, limiting the usage of truncation in practical systems. To tackle these limitations, we propose LeCut, a ranking list truncation model for legal case retrieval. LeCut utilizes contextual features of the retrieval task to capture the semantic-level similarity between documents and decides the best cut-off position with attention mechanisms. We further propose a Joint Optimization of Truncation and Reranking (JOTR) framework based on LeCut to improve the performance of truncation and retrieval tasks simultaneously. Comparison against competitive baselines on public benchmark datasets demonstrates the effectiveness of LeCut and JOTR. A case study is conducted to visualize the cut-off positions of LeCut and the process of how JOTR improves both retrieval and truncation tasks.|检索模型预测的排名列表的截断对于保证用户的搜索体验至关重要。特别是，在特定的垂直领域，文档通常是复杂和广泛的(例如，法律案件) ，浏览结果的成本远远高于传统的 IR 任务(例如，网络搜索) ，设置一个合理的截止位置是非常必要的。虽然将现有的结果清单截断方法应用于法律案件检索很简单，但这些方法的有效性有限，因为它们只侧重于简单的文件统计，通常无法捕捉排名清单中文件的上下文信息。这些现有的工作还将结果列表截断视为一个孤立的任务，而不是整个排序过程中的一个组件，从而限制了截断在实际系统中的使用。为了解决这些局限性，我们提出了 LeCut，一种用于法律案例检索的排序列表截断模型。LeCut 利用检索任务的上下文特征来捕获文档之间的语义级相似性，并通过注意机制确定最佳截止位置。进一步提出了一种基于 LeCut 的联合优化截断与重排(JOTR)框架，以同时提高截断与检索任务的性能。与公共基准数据集的竞争基线进行比较，可以证明 LeCut 和 JOTR 的有效性。通过案例研究，可视化 LeCut 的截止位置以及 JOTR 如何改进检索和截断任务的过程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Retrieval+Information+into+the+Truncation+of+Ranking+Lists+for+Better+Legal+Search)|0|
|[Ada-Ranker: A Data Distribution Adaptive Ranking Paradigm for Sequential Recommendation](https://doi.org/10.1145/3477495.3531931)|Xinyan Fan, Jianxun Lian, Wayne Xin Zhao, Zheng Liu, Chaozhuo Li, Xing Xie|Microsoft Research Asia, Beijing, China; Renmin University of China, Beijing, China|A large-scale recommender system usually consists of recall and ranking modules. The goal of ranking modules (aka rankers) is to elaborately discriminate users' preference on item candidates proposed by recall modules. With the success of deep learning techniques in various domains, we have witnessed the mainstream rankers evolve from traditional models to deep neural models. However, the way that we design and use rankers remains unchanged: offline training the model, freezing the parameters, and deploying it for online serving. Actually, the candidate items are determined by specific user requests, in which underlying distributions (e.g., the proportion of items for different categories, the proportion of popular or new items) are highly different from one another in a production environment. The classical parameter-frozen inference manner cannot adapt to dynamic serving circumstances, making rankers' performance compromised. In this paper, we propose a new training and inference paradigm, termed as Ada-Ranker, to address the challenges of dynamic online serving. Instead of using parameter-frozen models for universal serving, Ada-Ranker can adaptively modulate parameters of a ranker according to the data distribution of the current group of item candidates. We first extract distribution patterns from the item candidates. Then, we modulate the ranker by the patterns to make the ranker adapt to the current data distribution. Finally, we use the revised ranker to score the candidate list. In this way, we empower the ranker with the capacity of adapting from a global model to a local model which better handles the current task. As a first study, we examine our Ada-Ranker paradigm in the sequential recommendation scenario. Experiments on three datasets demonstrate that Ada-Ranker can effectively enhance various base sequential models and also outperform a comprehensive set of competitive baselines.|一个大规模的推荐系统通常包括召回和排名模块。排序模块(又称排序器)的目标是精心区分用户对召回模块提出的候选项的偏好。随着深度学习技术在各个领域的成功，我们目睹了主流的排名从传统模型演变为深度神经模型。然而，我们设计和使用排名的方式保持不变: 离线训练模型，冻结参数，并部署它在线服务。实际上，候选项是由特定的用户请求决定的，在这种情况下，底层分布(例如，不同类别的项目比例，流行项目或新项目的比例)在生产环境中彼此之间差异很大。传统的参数冻结推理方式不能适应动态服务环境，使得排序器的性能受到影响。在本文中，我们提出了一个新的训练和推理范式，称为 Ada-Ranker，以解决动态在线服务的挑战。Ada-Ranker 可以根据当前项目候选者组的数据分布自适应地调整排序器的参数，而不必使用通用服务的参数冻结模型。我们首先从候选项中提取分布模式。然后，根据模式对排序器进行调整，使排序器适应当前的数据分布。最后，我们使用修改后的排名对候选人列表进行评分。通过这种方式，我们赋予排名者从全球模型到更好地处理当前任务的局部模型的适应能力。作为第一个研究，我们在顺序推荐场景中检查我们的 Ada-Ranker 范式。在三个数据集上的实验表明，Ada-Ranker 能够有效地增强各种基本序列模型，并且表现优于一组综合的竞争基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ada-Ranker:+A+Data+Distribution+Adaptive+Ranking+Paradigm+for+Sequential+Recommendation)|0|
|[Retrieval and Recommendation Systems at the Crossroads of Artificial Intelligence, Ethics, and Regulation](https://doi.org/10.1145/3477495.3532683)|Markus Schedl, Emilia Gómez, Elisabeth Lex|Johannes Kepler University Linz & Linz Institue of Technology, Linz, Austria; Graz University of Technology, Graz, Austria; European Commission, Joint Research Centre and Universitat Pompeu Fabra, Seville/Barcelona, Spain|This tutorial aims at providing its audience an interdisciplinary overview about the topics of fairness and non-discrimination, diversity, and transparency of AI systems, tailored to the research fields of information retrieval and recommender systems. By means of this tutorial, we would like to equip the mostly technical audience of SIGIR with the necessary understanding of the ethical implications of their research and development on the one hand, and of recent political and legal regulations that address the aforementioned challenges on the other hand.|本教程旨在为读者提供一个关于人工智能系统的公平性和非歧视性、多样性和透明度等主题的跨学科概述，适用于信息检索和推荐系统的研究领域。通过本教程，我们希望让 SIGIR 的大多数技术读者一方面了解他们的研究和发展的道德影响，另一方面了解解决上述挑战的最新政治和法律法规。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval+and+Recommendation+Systems+at+the+Crossroads+of+Artificial+Intelligence,+Ethics,+and+Regulation)|0|
|[Adversarial Filtering Modeling on Long-term User Behavior Sequences for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531788)|Xiaochen Li, Jian Liang, Xialong Liu, Yu Zhang|Lazada Group, Beijing, China; Alibaba Group, Beijing, China|Rich user behavior information is of great importance for capturing and understanding user interest in click-through rate (CTR) prediction. To improve the richness, collecting long-term behaviors becomes a typical approach in academy and industry but at the cost of increasing online storage and latency. Recently, researchers have proposed several approaches to shorten long-term behavior sequence and then model user interests. These approaches reduce online cost efficiently but do not well handle the noisy information in long-term user behavior, which may deteriorate the performance of CTR prediction significantly. To obtain better cost/performance trade-off, we propose a novel Adversarial Filtering Model (ADFM) to model long-term user behavior. ADFM uses a hierarchical aggregation representation to compress raw behavior sequence and then learns to remove useless behavior information with an adversarial filtering mechanism. The selected user behaviors are fed into interest extraction module for CTR prediction. Experimental results on public datasets and industrial dataset demonstrate that our method achieves significant improvements over state-of-the-art models.|丰富的用户行为信息对于捕捉和理解用户对点进率预测的兴趣非常重要。为了提高丰富性，收集长期行为成为学术界和工业界的一种典型方法，但代价是增加在线存储和延迟。最近，研究人员提出了几种方法来缩短长期行为序列，然后模型用户的兴趣。这些方法有效地降低了在线成本，但不能很好地处理长期用户行为中的噪声信息，这可能会严重影响 CTR 预测的性能。为了获得更好的性价比，我们提出了一种新的对抗过滤模型(ADFM)来模拟长期用户行为。ADFM 使用分层聚合表示来压缩原始行为序列，然后学习使用对抗性过滤机制去除无用的行为信息。将选定的用户行为反馈到兴趣提取模块中进行点击率预测。在公共数据集和工业数据集上的实验结果表明，该方法比现有的模型有明显的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Filtering+Modeling+on+Long-term+User+Behavior+Sequences+for+Click-Through+Rate+Prediction)|0|
|[LoL: A Comparative Regularization Loss over Query Reformulation Losses for Pseudo-Relevance Feedback](https://doi.org/10.1145/3477495.3532017)|Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, Xueqi Cheng|Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China; Data Intelligence System Research Center, Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China; Tsinghua University, Beijing, China; Data Intelligence System Research Center, Institute of Computing Technology, CAS, Beijing, China|Pseudo-relevance feedback (PRF) has proven to be an effective query reformulation technique to improve retrieval accuracy. It aims to alleviate the mismatch of linguistic expressions between a query and its potential relevant documents. Existing PRF methods independently treat revised queries originating from the same query but using different numbers of feedback documents, resulting in severe query drift. Without comparing the effects of two different revisions from the same query, a PRF model may incorrectly focus on the additional irrelevant information increased in the more feedback, and thus reformulate a query that is less effective than the revision using the less feedback. Ideally, if a PRF model can distinguish between irrelevant and relevant information in the feedback, the more feedback documents there are, the better the revised query will be. To bridge this gap, we propose the Loss-over-Loss (LoL) framework to compare the reformulation losses between different revisions of the same query during training. Concretely, we revise an original query multiple times in parallel using different amounts of feedback and compute their reformulation losses. Then, we introduce an additional regularization loss on these reformulation losses to penalize revisions that use more feedback but gain larger losses. With such comparative regularization, the PRF model is expected to learn to suppress the extra increased irrelevant information by comparing the effects of different revised queries. Further, we present a differentiable query reformulation method to implement this framework. This method revises queries in the vector space and directly optimizes the retrieval performance of query vectors, applicable for both sparse and dense retrieval models. Empirical evaluation demonstrates the effectiveness and robustness of our method for two typical sparse and dense retrieval models.|伪相关反馈(PRF)已被证明是一种有效的查询重构技术，以提高检索的准确性。它旨在缓解查询与潜在相关文档之间的语言表达不匹配问题。现有的 PRF 方法独立处理来自同一查询但使用不同数量的反馈文档的修改查询，导致严重的查询漂移。如果不比较来自同一查询的两个不同修订的效果，PRF 模型可能会错误地关注更多反馈中增加的附加不相关信息，从而使用更少的反馈重新表述比修订更低效的查询。理想情况下，如果 PRF 模型能够区分反馈中的不相关信息和相关信息，那么反馈文档越多，修改后的查询就越好。为了弥补这一差距，我们提出了损失超过损失(LoL)框架来比较同一查询在培训期间不同修订版本之间的重构损失。具体来说，我们使用不同数量的反馈并行多次修改原始查询，并计算它们的重新表述损失。然后，我们引入一个额外的正则化损失对这些重制损失，以惩罚修订使用更多的反馈，但获得更大的损失。通过这种比较正则化，PRF 模型可以通过比较不同修订查询的效果来抑制额外增加的不相关信息。进一步，我们提出了一个可微查询重构方法来实现这个框架。该方法对向量空间中的查询进行修正，直接优化查询向量的检索性能，适用于稀疏和密集检索模型。实验结果表明，该方法对两种典型的稀疏和密集检索模型具有较好的鲁棒性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LoL:+A+Comparative+Regularization+Loss+over+Query+Reformulation+Losses+for+Pseudo-Relevance+Feedback)|0|
|[Determinantal Point Process Likelihoods for Sequential Recommendation](https://doi.org/10.1145/3477495.3531965)|Yuli Liu, Christian J. Walder, Lexing Xie|Data61, CSIRO & Australian National University, Canberra, Australia; Australian National University & Data61, CSIRO, Canberra, Australia|Sequential recommendation is a popular task in academic research and close to real-world application scenarios, where the goal is to predict the next action(s) of the user based on his/her previous sequence of actions. In the training process of recommender systems, the loss function plays an essential role in guiding the optimization of recommendation models to generate accurate suggestions for users. However, most existing sequential recommendation tech- niques focus on designing algorithms or neural network architectures, and few efforts have been made to tailor loss functions that fit naturally into the practical application scenario of sequential recommender systems. Ranking-based losses, such as cross-entropy and Bayesian Personalized Ranking (BPR) are widely used in the sequential recommendation area. We argue that such objective functions suffer from two inherent drawbacks: i) the dependencies among elements of a sequence are overlooked in these loss formulations; ii) instead of balancing accuracy (quality) and diversity, only generating accurate results has been over emphasized. We therefore propose two new loss functions based on the Determinantal Point Process (DPP) likelihood, that can be adaptively applied to estimate the subsequent item or items. The DPP-distributed item set captures natural dependencies among temporal actions, and a quality vs. diversity decomposition of the DPP kernel pushes us to go beyond accuracy-oriented loss functions. Experimental results using the proposed loss functions on three real-world datasets show marked improvements over state-of-the-art sequential recommendation methods in both quality and diversity metrics.|顺序推荐是学术研究中的一个热门任务，它接近于真实的应用场景，其目标是根据用户以前的操作顺序预测他/她的下一个操作。在推荐系统的培训过程中，损失函数对于指导推荐模型的优化，为用户提供准确的建议起着至关重要的作用。然而，现有的顺序推荐技术大多侧重于设计算法或神经网络体系结构，很少有人努力去调整自然适合顺序推荐系统实际应用场景的损失函数。基于排序的损失，如交叉熵和贝叶斯个性化排序(BPR)被广泛应用于序列推荐领域。我们认为这样的目标函数有两个固有的缺点: i)在这些损失公式中忽略了序列元素之间的依赖关系; ii)没有平衡准确性(质量)和多样性，只有产生准确的结果被过分强调。因此，我们提出两个新的基于行列式点过程(DPP)可能性的损失函数，可以自适应地应用于估计随后的项目。DPP 分布式项目集捕获时间操作之间的自然依赖关系，DPP 内核的质量与多样性分解促使我们超越面向准确性的损失函数。在三个实际数据集上使用提出的损失函数的实验结果显示，在质量和多样性度量方面，该方法比最先进的顺序推荐方法有明显的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Determinantal+Point+Process+Likelihoods+for+Sequential+Recommendation)|0|
|[Re-weighting Negative Samples for Model-Agnostic Matching](https://doi.org/10.1145/3477495.3532053)|Jiazhen Lou, Hong Wen, Fuyu Lv, Jing Zhang, Tengfei Yuan, Zhao Li|Zhejiang University, Hangzhou, China; The University of Sydney, Darlington, NSW, Australia; Alibaba Group, Hangzhou, China|Recommender Systems (RS), as an efficient tool to discover users' interested items from a very large corpus, has attracted more and more attention from academia and industry. As the initial stage of RS, large-scale matching is fundamental yet challenging. A typical recipe is to learn user and item representations with a two-tower architecture and then calculate the similarity score between both representation vectors, which however still struggles in how to properly deal with negative samples. In this paper, we find that the common practice that randomly sampling negative samples from the entire space and treating them equally is not an optimal choice, since the negative samples from different sub-spaces at different stages have different importance to a matching model. To address this issue, we propose a novel method named Unbiased Model-Agnostic Matching Approach (UMA2). It consists of two basic modules including 1) General Matching Model (GMM), which is model-agnostic and can be implemented as any embedding-based two-tower models; and 2) Negative Samples Debias Network (NSDN), which discriminates negative samples by borrowing the idea of Inverse Propensity Weighting (IPW) and re-weighs the loss in GMM. UMA$^2$ seamlessly integrates these two modules in an end-to-end multi-task learning framework. Extensive experiments on both real-world offline dataset and online A/B test demonstrate its superiority over state-of-the-art methods.|推荐系统(RS)作为一种从庞大的语料库中发现用户感兴趣的项目的有效工具，越来越受到学术界和业界的关注。作为遥感的初始阶段，大规模匹配是一个基础性的挑战。一个典型的方法是使用双塔体系结构学习用户和项目表示，然后计算两个表示向量之间的相似度得分，但是如何正确处理负样本仍然是一个难题。在本文中，我们发现从整个空间中随机抽取负样本并平等对待它们的常见做法并不是最优选择，因为不同阶段不同子空间中的负样本对匹配模型的重要性不同。为了解决这一问题，我们提出了一种新的方法——无偏模型-不可知匹配方法(UMA2)。它包括两个基本模块: 1)通用匹配模型(GMM) ，该模型与模型无关，可以作为任何嵌入式双塔模型实现; 2)负样本偏差网络(NSDN) ，该网络借助逆倾向加权(IPW)的思想对负样本进行判别，并在 GMM 中重新权衡损失。UMA $^ 2 $在端到端多任务学习框架中无缝地集成了这两个模块。通过对现实世界离线数据集和在线 A/B 测试的大量实验，证明了该方法优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Re-weighting+Negative+Samples+for+Model-Agnostic+Matching)|0|
|[Item-Provider Co-learning for Sequential Recommendation](https://doi.org/10.1145/3477495.3531756)|Lei Chen, Jingtao Ding, Min Yang, Chengming Li, Chonggang Song, Lingling Yi|Sun Yat-sen University, Shenzhen, China; Tencent Inc., Shenzhen, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China|Sequential recommender systems (SRSs) have become a research hotspot recently due to its powerful ability in capturing users' dynamic preferences. The key idea behind SRSs is to model the sequential dependencies over the user-item interactions. However, we argue that users' preferences are not only determined by their view or purchase items but also affected by the item-providers with which users have interacted. For instance, in a short-video scenario, a user may click on a video because he/she is attracted to either the video content or simply the video-providers as the vloggers are his/her idols. Motivated by the above observations, in this paper, we propose IPSRec, a novel Item-Provider co-learning framework for Sequential Recommendation. Specifically, we propose two representation learning methods (single-steam and cross-stream) to learn comprehensive item and user representations based on the user's historical item sequence and provider sequence. Then, contrastive learning is employed to further enhance the user embeddings in a self-supervised manner, which treats the representations of a specific user learned from the item side as well as the item-provider side as the positive pair and treats the representations of different users in the batch as the negative samples. Extensive experiments on three real-world SRS datasets demonstrate that IPSRec achieves substantially better results than the strong competitors. For reproducibility, our code and data are available at https://github.com/siat-nlp/IPSRec.|顺序推荐系统(SRS)由于具有捕获用户动态偏好的强大功能，近年来成为研究的热点。SRS 背后的关键思想是在用户-项目交互之间建立顺序依赖关系模型。然而，我们认为用户的偏好不仅取决于他们的观点或购买项目，而且还受到项目供应商的用户已经互动。例如，在一个短视频场景中，用户可能会点击一个视频，因为他/她要么被视频内容吸引，要么被视频提供商吸引，因为视频博客是他/她的偶像。基于上述观察，本文提出了一种新的项目提供者协同学习的序贯推荐框架 IPSRec。具体来说，我们提出了两种表示学习方法(单蒸汽和跨流)来学习综合项目和用户表示基于用户的历史项目序列和提供者序列。然后，采用对比学习的方法，以自监督的方式进一步增强用户嵌入，将从项目侧和项目提供者侧学习到的特定用户的表征视为正对，将批处理中不同用户的表征视为负样本。对三个实际 SRS 数据集的大量实验表明，IPSRec 比强大的竞争对手获得了更好的结果。为确保重复性，我们的代码和数据可在 https://github.com/siat-nlp/ipsrec 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item-Provider+Co-learning+for+Sequential+Recommendation)|0|
|[Inconsistent Ranking Assumptions in Medical Search and Their Downstream Consequences](https://doi.org/10.1145/3477495.3531898)|Daniel Cohen, Kevin Du, Bhaskar Mitra, Laura Mercurio, Navid Rekabsaz, Carsten Eickhoff|Microsoft, Montreal, PQ, Canada; Johannes Kepler Univ Linz, Linz, Austria; Brown Univ, Providence, RI 02912 USA; Brown Univ, Alpert Med Sch, Providence, RI 02912 USA|Given a query, neural retrieval models predict point estimates of relevance for each document; however, a significant drawback of relying solely on point estimates is that they contain no indication of the model's confidence in its predictions. Despite this lack of information, downstream methods such as reranking, cutoff prediction, and none-of-the-above classification are still able to learn effective functions to accomplish their respective tasks. Unfortunately, these downstream methods can suffer poor performance when the initial ranking model loses confidence in its score predictions. This becomes increasingly important in high-stakes settings, such as medical searches that can influence health decision making. Recent work has resolved this lack of information by introducing Bayesian uncertainty to capture the possible distribution of a document score. This paper presents the use of this uncertainty information as an indicator of how well downstream methods will function over a ranklist. We highlight a significant bias against certain disease-related queries within the posterior distribution of a neural model, and show that this bias in a model's predictive distribution propagates to downstream methods. Finally, we introduce a multi-distribution uncertainty metric, confidence decay, as a valid way of partially identifying these failure cases in an offline setting without the need of any user feedback.|给定一个查询，神经检索模型预测每个文档的相关性点估计; 然而，仅仅依赖点估计的一个显著缺点是，它们不包含模型对其预测的置信度的指示。尽管缺乏这种信息，下游方法，如重新排序，截止预测，以及没有上述分类仍然能够学习有效的功能，以完成各自的任务。不幸的是，当初始排名模型对其分数预测失去信心时，这些下游方法的性能可能会很差。这在高风险环境中变得越来越重要，例如可以影响健康决策的医学搜索。最近的工作通过引入贝叶斯不确定性来捕获文档分数的可能分布，解决了这种信息缺乏的问题。本文介绍了使用这种不确定性信息作为一个指标，以及下游方法将如何在一个排名表的功能。我们强调，在神经模型的后验概率中，某些与疾病相关的查询存在显著的偏差，并表明模型预测分布的这种偏差会传播到下游方法。最后，我们介绍了一个多分布不确定性度量，置信度衰减，作为一个有效的方法，部分识别这些失败案例在脱机设置，而不需要任何用户反馈。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inconsistent+Ranking+Assumptions+in+Medical+Search+and+Their+Downstream+Consequences)|0|
|[Exploiting Session Information in BERT-based Session-aware Sequential Recommendation](https://doi.org/10.1145/3477495.3531910)|Jinseok Jamie Seol, Youngrok Ko, Sanggoo Lee|Seoul National University, Seoul, Republic of Korea|In recommendation systems, utilizing the user interaction history as sequential information has resulted in great performance improvement. However, in many online services, user interactions are commonly grouped by sessions that presumably share preferences, which requires a different approach from ordinary sequence representation techniques. To this end, sequence representation models with a hierarchical structure or various viewpoints have been developed but with a rather complex network structure. In this paper, we propose three methods to improve recommendation performance by exploiting session information while minimizing additional parameters in a BERT-based sequential recommendation model: using session tokens, adding session segment embeddings, and a time-aware self-attention. We demonstrate the feasibility of the proposed methods through experiments on widely used recommendation datasets.|在推荐系统中，利用用户交互历史作为序列信息，可以大大提高推荐系统的性能。然而，在许多在线服务中，用户交互通常按照可能共享首选项的会话进行分组，这需要一种不同于普通序列表示技术的方法。为此，开发了具有层次结构或不同视点的序列表示模型，但其网络结构相当复杂。在基于 BERT 的顺序推荐模型中，我们提出了利用会话信息同时最小化附加参数来提高推荐性能的三种方法: 使用会话令牌、增加会话段嵌入和有时间意识的自我注意。通过在广泛使用的推荐数据集上的实验，验证了该方法的可行性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Session+Information+in+BERT-based+Session-aware+Sequential+Recommendation)|0|
|[Towards Reproducible Machine Learning Research in Information Retrieval](https://doi.org/10.1145/3477495.3532686)|Ana Lucic, Maurits J. R. Bleeker, Maarten de Rijke, Koustuv Sinha, Sami Jullien, Robert Stojnic|Facebook AI Research, London, United Kingdom; McGill University, Montreal, Canada; University of Amsterdam, Amsterdam, Netherlands|While recent progress in the field of machine learning (ML) and information retrieval (IR) has been significant, the reproducibility of these cutting-edge results is often lacking, with many submissions failing to provide the necessary information in order to ensure subsequent reproducibility. Despite the introduction of self-check mechanisms before submission (such as the Reproducibility Checklist, criteria for evaluating reproducibility during reviewing at several major conferences, artifact review and badging framework, and dedicated reproducibility tracks and challenges at major IR conferences, the motivation for executing reproducible research is lacking in the broader information community. We propose this tutorial as a gentle introduction to help ensure reproducible research in IR, with a specific emphasis on ML aspects of IR research.|虽然机器学习(ML)和信息检索学习(IR)领域的最新进展显著，但这些尖端结果的可重复性往往缺乏，许多提交的文件未能提供必要的信息，以确保随后的可重复性。尽管在提交之前引入了自我检查机制(例如重现性检查表，在几个主要会议上评估重现性的标准，工件审查和徽章框架，以及在主要 IR 会议上专门的重现性轨道和挑战，在更广泛的信息社区中缺乏执行可重现性研究的动机。我们建议本教程作为一个温和的介绍，以帮助确保在 IR 的重复性研究，并特别强调机器学习方面的 IR 研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Reproducible+Machine+Learning+Research+in+Information+Retrieval)|0|
|[Structured and Natural Responses Co-generation for Conversational Search](https://doi.org/10.1145/3477495.3532063)|Chenchen Ye, Lizi Liao, Fuli Feng, Wei Ji, TatSeng Chua|Singapore Management University, Singapore, Singapore; National University of Singapore, Singapore, Singapore; Sea-NExT Joint Lab, National University of Singapore, Singapore, Singapore; University of Science and Technology of China, Heifei, China|Generating fluent and informative natural responses while main- taining representative internal states for search optimization is critical for conversational search systems. Existing approaches ei- ther 1) predict structured dialog acts first and then generate natural response; or 2) map conversation context to natural responses di- rectly in an end-to-end manner. Both kinds of approaches have shortcomings. The former suffers from error accumulation while the semantic associations between structured acts and natural re- sponses are confined in single direction. The latter emphasizes generating natural responses but fails to predict structured acts. Therefore, we propose a neural co-generation model that gener- ates the two concurrently. The key lies in a shared latent space shaped by two informed priors. Specifically, we design structured dialog acts and natural response auto-encoding as two auxiliary tasks in an interconnected network architecture. It allows for the concurrent generation and bidirectional semantic associations. The shared latent space also enables asynchronous reinforcement learn- ing for further joint optimization. Experiments show that our model achieves significant performance improvements.|生成流畅和信息丰富的自然反应，同时为搜索引擎优化保留有代表性的内部状态，这对会话搜索系统至关重要。现有的方法包括: 1)预测结构化对话首先发生，然后产生自然反应; 或者2)以端到端的方式将对话上下文直接映射到自然反应。这两种方法都有缺点。结构化行为和自然反应之间的语义联系是单向的，而结构化行为和自然反应之间的语义联系是单向的。后者强调产生自然反应，但无法预测结构化行为。因此，我们提出了一个神经元协同生成模型，并生成两个。关键在于一个共享的潜在空间，由两个知情的前任塑造。具体来说，我们设计了结构化对话行为和自然响应自动编码作为互联网络体系结构中的两个辅助任务。它允许并发生成和双向语义关联。共享潜在空间还支持异步强化学习，以进一步优化联合。实验结果表明，该模型取得了显著的性能改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structured+and+Natural+Responses+Co-generation+for+Conversational+Search)|0|
|[PEVAE: A Hierarchical VAE for Personalized Explainable Recommendation](https://doi.org/10.1145/3477495.3532039)|Zefeng Cai, Zerui Cai|East China Normal University, Shanghai, China|Variational autoencoders (VAEs) have been widely applied in recommendations. One reason is that their amortized inferences are beneficial for overcoming the data sparsity. However, in explainable recommendation that generates natural language explanations, they are still rarely explored. Thus, we aim to extend VAE to explainable recommendation. In this task, we find that VAE can generate acceptable explanations for users with few relevant training samples, however, it tends to generate less personalized explanations for users with relatively sufficient samples than autoencoders (AEs). We conjecture that information shared by different users in VAE disturbs the information for a specific user. To deal with this problem, we present PErsonalized VAE (PEVAE) that generates personalized natural language explanations for explainable recommendation. Moreover, we propose two novel mechanisms to aid our model in generating more personalized explanations, including 1) Self-Adaption Fusion (SAF) manipulates the latent space in a self-adaption manner for controlling the influence of shared information. In this way, our model can enjoy the advantage of overcoming the sparsity of data while generating more personalized explanations for a user with relatively sufficient training samples. 2) DEpendence Maximization (DEM) strengthens dependence between recommendations and explanations by maximizing the mutual information. It makes the explanation more specific to the input user-item pair and thus improves the personalization of the generated explanations. Extensive experiments show PEVAE can generate more personalized explanations and further analyses demonstrate the practical effect of our proposed methods.|变分自动编码器(VAE)已被广泛应用于建议。一个原因是，他们的摊销推断有利于克服数据稀疏。然而，在生成自然语言解释的可解释推荐中，它们仍然很少被探索。因此，我们的目标是将 VAE 扩展到可解释的推荐。在这个任务中，我们发现 VAE 可以在相关训练样本较少的情况下为用户生成可接受的解释，但是，与自动编码器(AE)相比，它往往在样本相对充足的情况下为用户生成较少的个性化解释。我们推测 VAE 中不同用户共享的信息会干扰特定用户的信息。为了解决这个问题，我们提出了个性化的 VAE (PEVAE) ，它可以为解释性推荐生成个性化的自然语言解释。此外，我们提出了两种新的机制来帮助我们的模型产生更多的个性化解释，包括1)自适应融合(SAF)以自适应的方式操纵潜在空间来控制共享信息的影响。通过这种方式，我们的模型可以在克服数据稀疏性的同时，通过相对充足的训练样本为用户生成更加个性化的解释。2)依赖最大化(DEM)通过最大化相互信息来增强推荐与解释之间的依赖性。它使解释更加具体到输入用户项对，从而改进了生成的解释的个性化。大量的实验表明，PEVAE 可以产生更加个性化的解释，进一步的分析表明，我们提出的方法的实际效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PEVAE:+A+Hierarchical+VAE+for+Personalized+Explainable+Recommendation)|0|
|[Counterfactual Learning To Rank for Utility-Maximizing Query Autocompletion](https://doi.org/10.1145/3477495.3531958)|Adam Block, Rahul Kidambi, Daniel N. Hill, Thorsten Joachims, Inderjit S. Dhillon|Massachusetts Institute of Technology, Cambridge, MA, USA; University of Texas at Austin, Austin, TX, USA; Amazon Search, Berkeley, CA, USA; Amazon Music, San Fransisco, CA, USA|Conventional methods for query autocompletion aim to predict which completed query a user will select from a list. A shortcoming of this approach is that users often do not know which query will provide the best retrieval performance on the current information retrieval system, meaning that any query autocompletion methods trained to mimic user behavior can lead to suboptimal query suggestions. To overcome this limitation, we propose a new approach that explicitly optimizes the query suggestions for downstream retrieval performance. We formulate this as a problem of ranking a set of rankings, where each query suggestion is represented by the downstream item ranking it produces. We then present a learning method that ranks query suggestions by the quality of their item rankings. The algorithm is based on a counterfactual learning approach that is able to leverage feedback on the items (e.g., clicks, purchases) to evaluate query suggestions through an unbiased estimator, thus avoiding the assumption that users write or select optimal queries. We establish theoretical support for the proposed approach and provide learning-theoretic guarantees. We also present empirical results on publicly available datasets, and demonstrate real-world applicability using data from an online shopping store.|查询自动完成的传统方法旨在预测用户将从列表中选择哪个已完成的查询。这种方法的一个缺点是，用户通常不知道哪个查询将在当前的信息检索系统上提供最佳的检索性能，这意味着任何经过训练的模拟用户行为的查询自动完成方法都可能导致次优的查询建议。为了克服这一限制，我们提出了一种新的方法，显式优化查询建议的下游检索性能。我们将这个问题表述为对一组排名进行排序的问题，其中每个查询建议由它产生的下游项目排名表示。然后，我们提出了一种学习方法，根据项目排名的质量对查询建议进行排序。该算法基于一种反事实学习方法，能够利用对项目(如点击、购买)的反馈，通过一个无偏估计器来评估查询建议，从而避免了用户编写或选择最佳查询的假设。我们为提出的方法建立了理论支持，并提供了学习理论保证。我们还提出了公开可用数据集的实证结果，并证明了真实世界的适用性使用数据从网上购物商店。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Learning+To+Rank+for+Utility-Maximizing+Query+Autocompletion)|0|
|[Automatic Expert Selection for Multi-Scenario and Multi-Task Search](https://doi.org/10.1145/3477495.3531942)|Xinyu Zou, Zhi Hu, Yiming Zhao, Xuchu Ding, Zhongyi Liu, Chenliang Li, Aixin Sun|Nanyang Technological University, Singapore, Singapore; Wuhan University, Wuhan, China; Ant Group, Hangzhou, China|Multi-scenario learning (MSL) enables a service provider to cater for users' fine-grained demands by separating services for different user sectors, e.g., by user's geographical region. Under each scenario there is a need to optimize multiple task-specific targets e.g., click through rate and conversion rate, known as multi-task learning (MTL). Recent solutions for MSL and MTL are mostly based on the multi-gate mixture-of-experts (MMoE) architecture. MMoE structure is typically static and its design requires domain-specific knowledge, making it less effective in handling both MSL and MTL. In this paper, we propose a novel Automatic Expert Selection framework for Multi-scenario and Multi-task search, named AESM2. AESM2 integrates both MSL and MTL into a unified framework with an automatic structure learning. Specifically, AESM2 stacks multi-task layers over multi-scenario layers. This hierarchical design enables us to flexibly establish intrinsic connections between different scenarios, and at the same time also supports high-level feature extraction for different tasks. At each multi-scenario/multi-task layer, a novel expert selection algorithm is proposed to automatically identify scenario-/task-specific and shared experts for each input. Experiments over two real-world large-scale datasets demonstrate the effectiveness of AESM2 over a battery of strong baselines. Online A/B test also shows substantial performance gain on multiple metrics. Currently, AESM2 has been deployed online for serving major traffic.|多场景学习可让服务供应商因应用户的细粒度需求，将不同用户界别的服务(例如按用户地理地区)分开。在每种情况下，都需要优化多个特定任务的目标，例如点击率和转换率，称为多任务学习(MTL)。最近的 MSL 和 MTL 解决方案大多基于多门混合专家(MMoE)体系结构。MMoE 结构通常是静态的，其设计需要特定于领域的知识，因此在处理 MSL 和 MTL 时效率较低。本文提出了一种面向多场景多任务搜索的自动专家选择框架 AESM2。AESM2将 MSL 和 MTL 集成到一个具有自动结构学习的统一框架中。具体来说，AESM2在多场景层上堆叠多任务层。这种分层设计使我们能够灵活地建立不同场景之间的内在联系，同时也支持不同任务的高级特征提取。在每个多场景/多任务层，提出了一种新的专家选择算法来自动识别每个输入的场景/任务特定的和共享的专家。通过两个真实世界的大规模数据集的实验证明了 AESM2在一组强基线上的有效性。在线 A/B 测试还显示了在多个指标上的大量性能增益。目前，AESM2已经部署在线服务主要流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Expert+Selection+for+Multi-Scenario+and+Multi-Task+Search)|0|
|[Multi-Agent RL-based Information Selection Model for Sequential Recommendation](https://doi.org/10.1145/3477495.3532022)|Kaiyuan Li, Pengfei Wang, Chenliang Li|Wuhan University, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China|For sequential recommender, the coarse-grained yet sparse sequential signals mined from massive user-item interactions have become the bottleneck to further improve the recommendation performance. To alleviate the spareness problem, exploiting auxiliary semantic features (\eg textual descriptions, visual images and knowledge graph) to enrich contextual information then turns into a mainstream methodology. Though effective, we argue that these different heterogeneous features certainly include much noise which may overwhelm the valuable sequential signals, and therefore easily reach the phenomenon of negative collaboration (ie 1 + 1 > 2). How to design a flexible strategy to select proper auxiliary information and alleviate the negative collaboration towards a better recommendation is still an interesting and open question. Unfortunately, few works have addressed this challenge in sequential recommendation. In this paper, we introduce a Multi-Agent RL-based Information S election Model (named MARIS) to explore an effective collaboration between different kinds of auxiliary information and sequential signals in an automatic way. Specifically, MARIS formalizes the auxiliary feature selection as a cooperative Multi-agent Markov Decision Process. For each auxiliary feature type, MARIS resorts to using an agent to determine whether a specific kind of auxiliary feature should be imported to achieve a positive collaboration. In between, a QMIX network is utilized to cooperate their joint selection actions and produce an episode corresponding an effective combination of different auxiliary features for the whole historical sequence. Considering the lack of supervised selection signals, we further devise a novel reward-guided sampling strategy to leverage exploitation and exploration scheme for episode sampling. By preserving them in a replay buffer, MARIS learns the action-value function and the reward alternatively for optimization. Extensive experiments on four real-world datasets demonstrate that our model obtains significant performance improvement over up-to-date state-of-the-art recommendation models.|对于序列推荐系统来说，从大量用户交互中挖掘出的粗粒度稀疏序列信号已经成为进一步提高推荐性能的瓶颈。为了解决这一问题，利用辅助语义特征(如文本描述、视觉图像和知识图形)丰富上下文信息成为主流方法论。虽然有效，我们认为这些不同的异质性特征肯定包括大量的噪声，这可能压倒有价值的序列信号，因此很容易达到负协作现象(即1 + 1 > 2)。如何设计一种灵活的策略，选择合适的辅助信息，减轻负面协作，以获得更好的推荐，仍然是一个有趣而开放的问题。不幸的是，很少有作品在连续推荐中解决了这个问题。本文提出了一种基于多 Agent RL 的信息 S 选择模型(MARIS) ，用于探索不同辅助信息与序列信号之间的自动有效协作。具体来说，MARIS 将辅助特征选择形式化为一个合作的多代理马可夫决策过程。对于每一种辅助特征类型，MARIS 都使用一个代理来确定是否需要导入一种特定的辅助特征来实现积极的协作。其间，利用 QMIX 网络协同它们的联合选择行动，产生对应于整个历史序列的不同辅助特征的有效组合的情节。考虑到缺乏监督选择信号，我们进一步设计了一种新的奖励引导抽样策略，以利用开发和探索方案的情节抽样。通过将它们保存在一个重播缓冲区中，MARIS 学习动作-价值函数和优化的报酬。在四个真实世界数据集上的大量实验表明，我们的模型比最新的最先进的推荐模型获得了显著的性能改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Agent+RL-based+Information+Selection+Model+for+Sequential+Recommendation)|0|
|[Neural Statistics for Click-Through Rate Prediction](https://doi.org/10.1145/3477495.3531762)|Yanhua Huang, Hangyu Wang, Yiyun Miao, Ruiwen Xu, Lei Zhang, Weinan Zhang|Xiaohongshu Inc., Shanghai, China; Shanghai Jiao Tong University, Shanghai, China|With the success of deep learning, click-through rate (CTR) predictions are transitioning from shallow approaches to deep architectures. Current deep CTR prediction usually follows the Embedding & MLP paradigm, where the model embeds categorical features into latent semantic space. This paper introduces a novel embedding technique called neural statistics that instead learns explicit semantics of categorical features by incorporating feature engineering as an innate prior into the deep architecture in an end-to-end manner. Besides, since the statistical information changes over time, we study how to adapt to the distribution shift in the MLP module efficiently. Offline experiments on two public datasets validate the effectiveness of neural statistics against state-of-the-art models. We also apply it to a large-scale recommender system via online A/B tests, where the user's satisfaction is significantly improved.|随着深度学习的成功，点进率预测(ctrl)正从浅层方法向深层架构过渡。目前的深度 CTR 预测通常遵循嵌入与 MLP 范式，该模型将范畴特征嵌入到潜在语义空间中。本文介绍了一种新的嵌入技术，称为神经统计学，通过将特征工程作为一种先天优势以端到端的方式结合到深层体系结构中，来学习范畴特征的显性语义。此外，由于统计信息随时间变化，我们研究了如何有效地适应 MLP 模块中的分布变化。在两个公共数据集上的离线实验验证了针对最先进模型的神经统计的有效性。我们还通过在线 A/B 测试将其应用于大规模的推荐系统测试，用户的满意度显著提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Statistics+for+Click-Through+Rate+Prediction)|0|
|[Towards Results-level Proportionality for Multi-objective Recommender Systems](https://doi.org/10.1145/3477495.3531787)|Ladislav Peska, Patrik Dokoupil|Charles University, Prague, Czech Rep|The main focus of our work is the problem of multiple objectives optimization (MOO) while providing a final list of recommendations to the user. Currently, system designers can tune MOO by setting importance of individual objectives, usually in some kind of weighted average setting. However, this does not have to translate into the presence of such objectives in the final results. In contrast, in our work we would like to allow system designers or end-users to directly quantify the required relative ratios of individual objectives in the resulting recommendations, e.g., the final results should have 60% relevance, 30% diversity and 10% novelty. If individual objectives are transformed to represent quality on the same scale, these result conditioning expressions may greatly contribute towards recommendations tuneability and explainability as well as user's control over recommendations. To achieve this task, we propose an iterative algorithm inspired by the mandates allocation problem in public elections. The algorithm is applicable as long as per-item marginal gains of individual objectives can be calculated. Effectiveness of the algorithm is evaluated on several settings of relevance-novelty-diversity optimization problem. Furthermore, we also outline several options to scale individual objectives to represent similar value for the user.|我们工作的主要重点是多目标优化(MOO)问题，同时向用户提供最终的建议列表。目前，系统设计者可以通过设定个人目标的重要性来调整 MOO，通常是在某种加权平均数设置中。然而，这并不意味着在最终结果中存在这样的目标。相比之下，在我们的工作中，我们希望允许系统设计者或最终用户直接量化结果建议中各个目标所需的相对比例，例如，最终结果应该有60% 的相关性，30% 的多样性和10% 的新颖性。如果将单个目标转换为在同一尺度上表示质量，那么这些结果条件表达式可能极大地有助于建议的可调整性和可解释性，以及用户对建议的控制。为了实现这一任务，我们提出了一个迭代算法的启发任务分配问题在公共选举。只要能够计算出单个目标的单项边际收益，该算法是可行的。该算法的有效性是根据相关性-新颖性-多样性最佳化问题进行评估的。此外，我们还概述了几个选项，以缩放单个目标，表示用户的类似价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Results-level+Proportionality+for+Multi-objective+Recommender+Systems)|0|
|[Transform Cold-Start Users into Warm via Fused Behaviors in Large-Scale Recommendation](https://doi.org/10.1145/3477495.3531797)|Pengyang Li, Rong Chen, Quan Liu, Jian Xu, Bo Zheng|Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China|Recommendation for cold-start users who have very limited data is a canonical challenge in recommender systems. Existing deep recommender systems utilize user content features and behaviors to produce personalized recommendations, yet often face significant performance degradation on cold-start users compared to existing ones due to the following challenges: (1) Cold-start users may have a quite different distribution of features from existing users. (2) The few behaviors of cold-start users are hard to be exploited. In this paper, we propose a recommender system called Cold-Transformer to alleviate these problems. Specifically, we design context-based Embedding Adaption to offset the differences in feature distribution. It transforms the embedding of cold-start users into a warm state that is more like existing ones to represent corresponding user preferences. Furthermore, to exploit the few behaviors of cold-start users and characterize the user context, we propose Label Encoding that models Fused Behaviors of positive and negative feedback simultaneously, which are relatively more sufficient. Last, to perform large-scale industrial recommendations, we keep the two-tower architecture that de-couples user and target item. Extensive experiments on public and industrial datasets show that Cold-Transformer significantly outperforms state-of-the-art methods, including those that are deep coupled and less scalable.|对于数据非常有限的冷启动用户的推荐在推荐系统中是一个典型的挑战。现有的深度推荐系统利用用户内容特征和行为来产生个性化的推荐，但是由于以下挑战，冷启动用户的性能往往比现有的推荐系统有显著的下降: (1)冷启动用户可能具有与现有用户完全不同的特征分布。(2)冷启动用户的少数行为很难被利用。在这篇文章中，我们提出了一个叫做冷变压器的推荐系统来缓解这些问题。具体来说，我们设计了基于上下文的嵌入适应，以抵消特征分布的差异。它将冷启动用户的嵌入转换为更像现有用户的暖状态，以表示相应的用户偏好。此外，为了充分利用冷启动用户的少数行为并刻画用户上下文特征，我们提出了标签编码方法，该方法同时对正反馈和负反馈的融合行为进行建模，相对来说比较充分。最后，为了执行大规模的工业建议，我们保留了解耦用户和目标项目的双塔架构。在公共和工业数据集上进行的大量实验表明，冷变压器的性能明显优于最先进的方法，包括那些深度耦合和可伸缩性较差的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transform+Cold-Start+Users+into+Warm+via+Fused+Behaviors+in+Large-Scale+Recommendation)|0|
|[Coarse-to-Fine Sparse Sequential Recommendation](https://doi.org/10.1145/3477495.3531732)|Jiacheng Li, Tong Zhao, Jin Li, Jim Chan, Christos Faloutsos, George Karypis, SooMin Pantel, Julian J. McAuley|Carnegie Mellon University, Pittsburgh, PA, USA; University of California, San Diego, La Jolla, CA, USA; Amazon, Seattle, WA, USA|Sequential recommendation aims to model dynamic user behavior from historical interactions. Self-attentive methods have proven effective at capturing short-term dynamics and long-term preferences. Despite their success, these approaches still struggle to model sparse data, on which they struggle to learn high-quality item representations. We propose to model user dynamics from shopping intents and interacted items simultaneously. The learned intents are coarse-grained and work as prior knowledge for item recommendation. To this end, we present a coarse-to-fine self-attention framework, namely CaFe, which explicitly learns coarse-grained and fine-grained sequential dynamics. Specifically, CaFe first learns intents from coarse-grained sequences which are dense and hence provide high-quality user intent representations. Then, CaFe fuses intent representations into item encoder outputs to obtain improved item representations. Finally, we infer recommended items based on representations of items and corresponding intents. Experiments on sparse datasets show that CaFe outperforms state-of-the-art self-attentive recommenders by 44.03% [email protected] on average.|顺序推荐旨在从历史交互中建立动态用户行为模型。事实证明，自我关注的方法在捕捉短期动态和长期偏好方面是有效的。尽管这些方法取得了成功，但它们仍然难以建立稀疏数据的模型，难以在稀疏数据上学习高质量的项目表示。我们建议同时从购物意图和交互项目建立用户动态模型。学习意图是粗粒度的，作为项目推荐的先验知识。为此，我们提出了一个由粗到细的自我注意框架，即 CaFe，它显式地学习粗粒度和细粒度的序列动力学。具体来说，CaFe 首先从密集的粗粒度序列中学习意图，因此提供高质量的用户意图表示。然后，CaFe 将意图表示融合到项编码器输出中，以获得改进的项表示。最后，根据项目的表示和相应的意图推断推荐项目。在稀疏数据集上的实验表明，CaFe 的性能平均比最先进的自我关注推荐系统高出44.03% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Coarse-to-Fine+Sparse+Sequential+Recommendation)|0|
|[Conversational Recommendation via Hierarchical Information Modeling](https://doi.org/10.1145/3477495.3531830)|Quan Tu, Shen Gao, Yanran Li, Jianwei Cui, Bin Wang, Rui Yan|Xiaomi AI Lab, Beijing, China; Renmin University of China, Beijing, China; Peking University, Beijing, China|Conversational recommendation system aims to recommend appropriate items to user by directly asking preference on attributes or recommending item list. However, most of existing methods only employ the flat item and attribute relationship, and ignore the hierarchical relationship connected by the similar user which can provide more comprehensive information. And these methods usually use the user accepted attributes to represent the conversational history and ignore the hierarchical information of sequential transition in the historical turns. In this paper, we propose Hierarchical Information-aware Conversational Recommender (HICR) to model the two types of hierarchical information to boost the performance of CRS. Experiments conducted on four benchmark datasets verify the effectiveness of our proposed model.|会话推荐系统旨在通过直接询问用户对属性的偏好或推荐项目列表来向用户推荐合适的项目。然而，现有的方法大多只使用平面项目和属性关系，而忽略了相似用户之间的层次关系，这样可以提供更全面的信息。这些方法通常使用用户接受的属性来表示会话历史，而忽略了历史转折中顺序转换的层次信息。本文提出了基于层次信息感知的会话推荐系统(HICR) ，对两种层次信息进行建模，以提高会话推荐系统的性能。在四个基准数据集上进行的实验验证了该模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Recommendation+via+Hierarchical+Information+Modeling)|0|
|[CTnoCVR: A Novelty Auxiliary Task Making the Lower-CTR-Higher-CVR Upper](https://doi.org/10.1145/3477495.3531843)|Dandan Zhang, Haotian Wu, Guanqi Zeng, Yao Yang, Weijiang Qiu, Yujie Chen, Haoyuan Hu|Cainiao Network, Hangzhou, China; Zhejiang Lab, Hangzhou, China; China Electric Power Research Institute, Beijing, China; Beijing Jiaotong University, Beijing, China|In recent years, multi-task learning models based on deep learning in recommender systems have attracted increasing attention from researchers in industry and academia. Accurately estimating post-click conversion rate (CVR) is often considered as the primary task of multi-task learning in recommender systems. However, some advertisers may try to get higher click-through rates (CTR) by over-decorating their ads, which may result in excessive exposure to samples with lower CVR. For example, some only eye-catching clickbait have higher CTR, but actually, CVR is very low. As a result, the overall performance of the recommender system will be hurt. In this paper, we introduce a novelty auxiliary task called CTnoCVR, which aims to predict the probability of events with click but no-conversion, in various state-of-the-art multi-task models of recommender systems to promote samples with high CVR but low CTR. Plentiful Experiments on a large-scale dataset gathered from traffic logs of Taobao's recommender system demonstrate that the introduction of CTnoCVR task significantly improves the prediction effect of CVR under various multi-task frameworks. In addition, we conduct the online test and evaluate the effectiveness of our proposed method to make those samples with high CVR and low CTR rank higher.|近年来，推荐系统中基于深度学习的多任务学习模型越来越受到业界和学术界的关注。在推荐系统中，准确估计点击后转换率(CVR)常常被认为是多任务学习的首要任务。然而，一些广告商可能试图通过过度装饰他们的广告来获得更高的点击率(CTR) ，这可能导致过度暴露于低 CVR 的样品。例如，一些只有吸引眼球的点击诱饵有较高的点击率，但实际上，CVR 是非常低的。因此，推荐系统的整体表现将受到影响。本文介绍了一种新颖的辅助任务 CTnoCVR，该任务在推荐系统的多任务模型中预测点击不转换的事件发生概率，以提升高 CVR 低 CTR 的样本。大量的实验表明，在多任务框架下，引入 CTnoCVR 任务可以显著提高 CVR 的预测效果。这些实验都是从淘宝推荐系统的流量日志中收集的大规模数据集中得到的。此外，我们进行了在线测试，并评估了我们提出的方法的有效性，使高 CVR 和低 CTR 排名的样本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CTnoCVR:+A+Novelty+Auxiliary+Task+Making+the+Lower-CTR-Higher-CVR+Upper)|0|
|[Smooth-AUC: Smoothing the Path Towards Rank-based CTR Prediction](https://doi.org/10.1145/3477495.3531865)|Shuang Tang, Fangyuan Luo, Jun Wu|Beijing Jiaotong University, Beijing, China|Deep neural networks (DNNs) have been a key technique for click-through rate (CTR) estimation, yet existing DNNs-based CTR models neglect the inconsistency between their optimization objectives (e.g., Binary Cross Entropy, BCE) and CTR ranking metrics (e.g., Area Under the ROC Curve, AUC). It is noteworthy that directly optimizing AUC by gradient-descent methods is difficult due to the non-differentiable Heaviside function built-in AUC. To this end, we propose a smooth approximation of AUC, called smooth-AUC (SAUC), towards the rank-based CTR prediction. Specifically, SAUC relaxes the Heaviside function via sigmoid with a temperature coefficient (aiming at controlling the function sharpness) in order to facilitate the gradient-based optimization. Furthermore, SAUC is a plug-and-play objective that can be used in any DNNs-based CTR model. Experimental results on two real-world datasets demonstrate that SAUC consistently improves the recommendation accuracy of current DNNs-based CTR models.|深度神经网络(DNN)一直是点进率评估的关键技术，然而现有的基于 DNN 的 CTR 模型忽略了它们的优化目标(例如，二进制交叉熵，BCE)和 CTR 排名指标(例如，ROC Curve 下面积，AUC)之间的不一致性。值得注意的是，由于 AUC 内置的不可微单位阶跃函数，用梯度下降法直接优化 AUC 是困难的。为此，我们提出了一种平滑近似的 AUC，称为平滑 AUC (SAUC) ，用于基于秩的 CTR 预测。具体来说，SAUC 通过 sigmoid 放松单位阶跃函数(目的是控制函数的清晰度) ，以便于基于梯度的优化温度系数。此外，SAUC 是一个即插即用的目标，可以在任何基于 DNN 的 CTR 模型中使用。在两个实际数据集上的实验结果表明，SAUC 一致地提高了当前基于 DNN 的 CTR 模型的推荐精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Smooth-AUC:+Smoothing+the+Path+Towards+Rank-based+CTR+Prediction)|0|
|[Alignment Rationale for Query-Document Relevance](https://doi.org/10.1145/3477495.3531883)|Youngwoo Kim, Razieh Rahimi, James Allan|University of Massachusetts Amherst, Amherst, MA, USA|Deep neural networks are widely used for text pair classification tasks such as as adhoc information retrieval. These deep neural networks are not inherently interpretable and require additional efforts to get rationale behind their decisions. Existing explanation models are not yet capable of inducing alignments between the query terms and the document terms -- which part of the document rationales are responsible for which part of the query? In this paper, we study how the input perturbations can be used to infer or evaluate alignments between the query and document spans, which best explain the black-box ranker's relevance prediction. We use different perturbation strategies and accordingly propose a set of metrics to evaluate the faithfulness of alignment rationales to the model. Our experiments show that the defined metrics based on substitution-based perturbation are more successful in preferring higher-quality alignments, compared to the deletion-based metrics.|深度神经网络广泛用于文本对分类任务，如自组织信息检索。这些深层神经网络本质上是不可解释的，需要额外的努力来获得其决策背后的理由。现有的解释模型还不能在查询术语和文档术语之间引入对齐——文档基本原理的哪一部分负责查询的哪一部分？在本文中，我们研究了如何利用输入扰动来推断或评估查询和文档跨度之间的对齐，这最好地解释了黑盒排名的相关性预测。我们使用不同的摄动策略，并相应地提出了一套度量来评估对齐基本原理的忠实性模型。我们的实验表明，与基于删除的度量相比，基于替换扰动的度量更容易获得高质量的比对。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Alignment+Rationale+for+Query-Document+Relevance)|0|
|[Learning to Rank Knowledge Subgraph Nodes for Entity Retrieval](https://doi.org/10.1145/3477495.3531888)|Parastoo Jafarzadeh, Zahra Amirmahani, Faezeh Ensan|Ferdowsi University of Mashhad, Mashhad, Iran; Ryerson University, Toronto, ON, Canada|The importance of entity retrieval, the task of retrieving a ranked list of related entities from big knowledge bases given a textual query, has been widely acknowledged in the literature. In this paper, we propose a novel entity retrieval method that addresses the important challenge that revolves around the need to effectively represent and model context in which entities relate to each other. Based on our proposed method, a model is firstly trained to retrieve and prune a subgraph of a textual knowledge graph that represents contextual relationships between entities. Secondly, a deep model is introduced to reason over the textual content of nodes, edges, and the given question and score and rank entities in the subgraph. We show experimentally that our approach outperforms state-of-the-art methods on a number of benchmarks for entity retrieval.|实体检索的重要性在文献中得到了广泛的认可。在本文中，我们提出了一种新的实体检索方法，以解决围绕着需要有效地表示和模型实体相互关联的上下文的重要挑战。基于该方法，首先训练一个模型来检索和剪枝表示实体间上下文关系的文本知识图的子图。其次，引入一个深度模型来推理子图中节点、边和给定问题的文本内容以及子图中的得分和排序实体。我们的实验表明，我们的方法在实体检索的许多基准上优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Rank+Knowledge+Subgraph+Nodes+for+Entity+Retrieval)|0|
|[ELECRec: Training Sequential Recommenders as Discriminators](https://doi.org/10.1145/3477495.3531894)|Yongjun Chen, Jia Li, Caiming Xiong|Salesforce Research, Palo Alto, CA, USA|Sequential recommendation is often considered as a generative task, i.e., training a sequential encoder to generate the next item of a user's interests based on her historical interacted items. Despite their prevalence, these methods usually require training with more meaningful samples to be effective, which otherwise will lead to a poorly trained model. In this work, we propose to train the sequential recommenders as discriminators rather than generators. Instead of predicting the next item, our method trains a discriminator to distinguish if a sampled item is a 'real' target item or not. A generator, as an auxiliary model, is trained jointly with the discriminator to sample plausible alternative next items and will be thrown out after training. The trained discriminator is considered as the final SR model and denoted as \modelname. Experiments conducted on four datasets demonstrate the effectiveness and efficiency of the proposed approach.|顺序推荐通常被认为是一个生成任务，例如，训练一个顺序编码器根据用户的历史交互项目生成下一个用户感兴趣的项目。尽管这些方法普遍存在，但通常需要训练更有意义的样本才能有效，否则将导致训练不足的模型。在这项工作中，我们建议训练顺序推荐器作为鉴别器，而不是生成器。我们的方法不是预测下一个项目，而是训练一个鉴别器来区分一个采样的项目是否是“真正的”目标项目。发电机作为辅助模型，与鉴别器联合训练，以抽样合理的替代下一个项目，并将在训练后抛出。训练后的鉴别器被认为是最终的 SR 模型，并表示为模型名。在四个数据集上进行的实验表明了该方法的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELECRec:+Training+Sequential+Recommenders+as+Discriminators)|0|
|[A2A-API: A Prototype for Biomedical Information Retrieval Research and Benchmarking](https://doi.org/10.1145/3477495.3531667)|Maciej Rybinski, Liam Watts, Sarvnaz Karimi|CSIRO Data61, Sydney, NSW, Australia|Finding relevant literature is crucial for biomedical research and in the practice of evidence-based medicine, making biomedical search an important application area within the field of information retrieval. This is recognised by the broader IR community, and in particular by the organisers of Text Retrieval Conference (TREC) as early as 2003. While TREC provides crucial evaluation resources, to get started in biomedical IR one needs to tackle an important software engineering hurdle of parsing, indexing, and deploying several large document collections. Moreover, many newcomers to the field often face a steep learning curve, where theoretical concepts are tangled up with technical aspects. Finally, many of the existing baselines and systems are difficult to reproduce. We aim to alleviate all three of these bottlenecks with the launch of A2A-API. It is a RESTful API which serves as an easy-to-use and programming-language-independent interface to existing biomedical TREC collections. It builds upon A2A, our system for biomedical information retrieval benchmarking, and extends it with additional functionalities. Apart from providing programmatic access to the features of the original A2A system - focused principally on benchmarking - A2A-API supports biomedical IR researchers in development of systems featuring reranking and query reformulation components. In this demonstration, we illustrate the capabilities of A2A-API with comprehensive use cases.|寻找相关文献对于生物医学研究和循证医学的实践至关重要，这使得生物医学搜索成为信息检索领域的一个重要应用领域。早在2003年，更广泛的信息检索社区，特别是文本检索会议(TREC)的组织者就认识到了这一点。虽然 TREC 提供了关键的评估资源，但要开始学习生物医学 IR，需要解决一个重要的软件工程障碍，即解析、索引和部署几个大型文档集。此外，该领域的许多新手往往面临一个陡峭的学习曲线，其中理论概念与技术方面纠缠在一起。最后，许多现有的基线和系统很难再现。我们的目标是通过推出 A2A-API 来缓解所有这三个瓶颈。它是一个 RESTful API，作为一个易于使用和独立于编程语言的接口，用于现有的生物医学 TREC 集合。它建立在我们的生物医学信息检索基准测试系统 A2A 的基础上，并扩展了其他功能。除了提供对原始 A2A 系统特性的程序访问(主要侧重于基准测试)外，A2A-API 还支持生物医学红外研究人员开发具有重新排序和查询重新制定组件的系统。在本演示中，我们通过全面的用例说明了 A2A-API 的功能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A2A-API:+A+Prototype+for+Biomedical+Information+Retrieval+Research+and+Benchmarking)|0|
|[Learning to Rank Instant Search Results with Multiple Indices: A Case Study in Search Aggregation for Entertainment](https://doi.org/10.1145/3477495.3536334)|Scott Rome, Sardar Hamidian, Richard Walsh, Kevin Foley, Ferhan Ture|Comcast, Philadelphia, PA, USA; Comcast, Washington, DC, USA; Comcast, Sunnyvale, CA, USA|At Xfinity, an instant search system provides a variety of results for a given query from different sources. For each keystroke, new results are rendered on screen to the user, which could contain movies, television series, sporting events, music videos, news clips, person pages, and other result types. Users are also able to use the Xfinity Voice Remote to submit longer queries, some of which are more open-ended. Examples of queries include incomplete words which match multiple results through lexical matching (i.e., "ali"), topical searches ("vampire movies"), and more specific longer searches ("Movies with Adam Sandler"). Since results can be based on lexical matches, semantic matches, item-to-item similarity matches, or a variety of business logic driven sources, a key challenge is how to combine results into a single list. To accomplish this, we propose merging the lists via a Learning to Rank (LTR) neural model which takes into account the search query. This combined list can be personalized via a second LTR neural model with knowledge of the user's search history and metadata of the programs. Because instant search is under-represented in the literature, we present our learnings from research to aid other practitioners.|在 Xfinity，即时搜索系统为来自不同来源的特定查询提供多种结果。对于每次按键，新的结果都会在屏幕上呈现给用户，其中可能包含电影、电视剧、体育赛事、音乐视频、新闻剪辑、人物页面和其他结果类型。用户还可以使用 Xfinity Voice Remote 提交更长的查询，其中一些查询更为开放。查询的例子包括通过词汇匹配(例如“ ali”)匹配多个结果的不完整单词、主题搜索(“吸血鬼电影”)和更具体的长搜索(“与 Adam Sandler 的电影”)。由于结果可以基于词汇匹配、语义匹配、项目间相似性匹配或各种业务逻辑驱动源，因此一个关键的挑战是如何将结果组合成一个单独的列表。为了实现这一点，我们建议通过一个学习排序(LTR)神经模型，考虑到搜索查询合并列表。这个组合列表可以通过第二个具有用户搜索历史和程序元数据知识的 LTR 神经模型进行个性化。因为即时搜索在文献中的代表性不足，我们提出我们从研究中学到的东西来帮助其他从业者。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Rank+Instant+Search+Results+with+Multiple+Indices:+A+Case+Study+in+Search+Aggregation+for+Entertainment)|0|
|[Scalable Exploration for Neural Online Learning to Rank with Perturbed Feedback](https://doi.org/10.1145/3477495.3532057)|Yiling Jia, Hongning Wang|University of Virginia, Charlottesville, VA, USA|Deep neural networks (DNNs) demonstrates significant advantages in improving ranking performance in retrieval tasks. Driven by the recent developments in optimization and generalization of DNNs, learning a neural ranking model online from its interactions with users becomes possible. However, the required exploration for model learning has to be performed in the entire neural network parameter space, which is prohibitively expensive and limits the application of such online solutions in practice. In this work, we propose an efficient exploration strategy for online interactive neural ranker learning based on bootstrapping. Our solution is based on an ensemble of ranking models trained with perturbed user click feedback. The proposed method eliminates explicit confidence set construction and the associated computational overhead, which enables the online neural rankers training to be efficiently executed in practice with theoretical guarantees. Extensive comparisons with an array of state-of-the-art OL2R algorithms on two public learning to rank benchmark datasets demonstrate the effectiveness and computational efficiency of our proposed neural OL2R solution.|深层神经网络(DNN)在提高检索任务的排序性能方面具有显著的优势。在 DNN 优化和泛化的最新发展的驱动下，从与用户的交互中学习在线神经排序模型成为可能。然而，模型学习所需要的探索必须在整个神经网络参数空间中进行，这是非常昂贵的，并且限制了这种在线解决方案在实际中的应用。本文提出了一种基于自举的在线交互式神经排序学习的有效探索策略。我们的解决方案是基于一个排名模型的集合训练与不安的用户点击反馈。该方法消除了显式置信集结构和相关的计算开销，使在线神经排序训练能够在理论保证的情况下在实际应用中有效地执行。通过与一系列最先进的 OL2R 算法在两个公共学习基准数据集上的广泛比较，证明了我们提出的神经 OL2R 解决方案的有效性和计算效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Exploration+for+Neural+Online+Learning+to+Rank+with+Perturbed+Feedback)|0|
|[Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems](https://doi.org/10.1145/3477495.3531869)|Hojoon Lee, Dongyoon Hwang, Kyushik Min, Jaegul Choo|KAIST, SeongNam, Republic of Korea; KAKAO Enterprise, SeongNam, Republic of Korea|Interactive Recommender Systems (IRSs) have attracted a lot of attention, due to their ability to model interactive processes between users and recommender systems. Numerous approaches have adopted Reinforcement Learning (RL) algorithms, as these can directly maximize users' cumulative rewards. In IRS, researchers commonly utilize publicly available review datasets to compare and evaluate algorithms. However, user feedback provided in public datasets merely includes instant responses (e.g., a rating), with no inclusion of delayed responses (e.g., the dwell time and the lifetime value). Thus, the question remains whether these review datasets are an appropriate choice to evaluate the long-term effects in IRS. In this work, we revisited experiments on IRS with review datasets and compared RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Following extensive analysis, we can reveal three main findings: First, a simple greedy reward model consistently outperforms RL-based models in maximizing cumulative rewards. Second, applying higher weighting to long-term rewards leads to degradation of recommendation performance. Third, user feedbacks have mere long-term effects in the benchmark datasets. Based on our findings, we conclude that a dataset has to be carefully verified and that a simple greedy baseline should be included for a proper evaluation of RL-based IRS approaches. Our code and dataset are available at https://github.com/dojeon-ai/irs_validation.|交互式推荐系统(IRS)由于能够对用户和推荐系统之间的交互过程进行建模而引起了人们的广泛关注。许多方法都采用了强化学习算法，因为这些算法可以直接最大化用户的累积回报。在 IRS 中，研究人员通常利用公开的评论数据集来比较和评估算法。然而，在公共数据集中提供的用户反馈只包括即时响应(例如，评级) ，没有包括延迟响应(例如，停留时间和生命周期值)。因此，问题仍然是这些审查数据集是否是评估 IRS 长期影响的合适选择。在这项工作中，我们重新回顾了 IRS 的实验与评论数据集，并比较了基于 RL 的模型与一个简单的奖励模型，贪婪地推荐项目具有最高的一步奖励。经过广泛的分析，我们可以揭示三个主要的发现: 第一，一个简单的贪婪报酬模型在最大化累积报酬方面始终优于基于 RL 的模型。其次，对长期奖励加权会导致推荐绩效的下降。第三，用户反馈在基准数据集中只有长期效果。基于我们的研究结果，我们得出结论，一个数据集必须被仔细验证，并且一个简单的贪婪基线应该被包括在一个基于 RL 的 IRS 方法的正确评估中。我们的代码和数据集可在 https://github.com/dojeon-ai/irs_validation 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Validating+Long-Term+User+Feedbacks+in+Interactive+Recommendation+Systems)|0|
|[Structure-Aware Semantic-Aligned Network for Universal Cross-Domain Retrieval](https://doi.org/10.1145/3477495.3532061)|Jialin Tian, Xing Xu, Kai Wang, Zuo Cao, Xunliang Cai, Heng Tao Shen|University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China & Peng Cheng Laboratory, Chengdu, China; Meituan, Shanghai, China|The goal of cross-domain retrieval (CDR) is to search for instances of the same category in one domain by using a query from another domain. Existing CDR approaches mainly consider the standard scenario that the cross-domain data for both training and testing come from the same categories and underlying distributions. However, these methods cannot be well extended to the newly emerging task of universal cross-domain retrieval (UCDR), where the testing data belong to the domain and categories not present during training. Compared to CDR, the UCDR task is more challenging due to (1) visually diverse data from multi-source domains, (2) the domain shift between seen and unseen domains, and (3) the semantic shift across seen and unseen categories. To tackle these problems, we propose a novel model termed Structure-Aware Semantic-Aligned Network (SASA) to align the heterogeneous representations of multi-source domains without loss of generalizability for the UCDR task. Specifically, we leverage the advanced Vision Transformer (ViT) as the backbone and devise a distillation-alignment ViT (DAViT) with a novel token-based strategy, which incorporates two complementary distillation and alignment tokens into the ViT architecture. In addition, the distillation token is devised to improve the generalizability of our model by structure information preservation and the alignment token is used to improve discriminativeness with trainable categorical prototypes. Extensive experiments on three large-scale benchmarks, i.e., Sketchy, TU-Berlin, and DomainNet, demonstrate the superiority of our SASA method over the state-of-the-art UCDR and ZS-SBIR methods.|跨域检索(CDR)的目标是通过使用来自另一个域的查询在一个域中搜索相同类别的实例。现有的 CDR 方法主要考虑这样的标准场景: 用于培训和测试的跨域数据来自相同的类别和底层分布。然而，这些方法不能很好地推广到新出现的通用跨域检索(UCDR)任务，其中的测试数据属于领域和类别不存在的训练过程中。与 CDR 相比，UCDR 任务更具挑战性，因为(1)来自多源域的视觉多样化数据，(2)可见和不可见域之间的域转移，以及(3)跨可见和不可见类别的语义转移。为了解决这些问题，我们提出了一种称为结构感知语义对齐网络(SASA)的新模型，该模型可以在不损失 UCDR 任务通用性的前提下对多源域的异构表示进行对齐。具体而言，我们利用先进的视觉变压器(ViT)作为骨干，并设计了一种蒸馏对准 ViT (DAViT) ，其具有基于令牌的新策略，其将两个互补的蒸馏和对准令牌合并到 ViT 体系结构中。此外，通过结构信息的保留，设计了精馏令牌来提高模型的泛化能力，并利用对齐令牌来提高可训练范畴原型的区分能力。在 Sketchy、 TU-Berlin 和 DomainNet 这三个大型基准测试上的大量实验证明了我们的 SASA 方法优于最先进的 UCDR 和 ZS-SBIR 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structure-Aware+Semantic-Aligned+Network+for+Universal+Cross-Domain+Retrieval)|0|
|[Enhancing Top-N Item Recommendations by Peer Collaboration](https://doi.org/10.1145/3477495.3531773)|Yang Sun, Fajie Yuan, Min Yang, Alexandros Karatzoglou, Li Shen, Xiaoyan Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Top-N+Item+Recommendations+by+Peer+Collaboration)|0|
|[Learning-to-Rank at the Speed of Sampling: Plackett-Luce Gradient Estimation with Minimal Computational Complexity](https://doi.org/10.1145/3477495.3531842)|Harrie Oosterhuis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning-to-Rank+at+the+Speed+of+Sampling:+Plackett-Luce+Gradient+Estimation+with+Minimal+Computational+Complexity)|0|
|[Rethinking Correlation-based Item-Item Similarities for Recommender Systems](https://doi.org/10.1145/3477495.3532055)|Katsuhiko Hayashi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Correlation-based+Item-Item+Similarities+for+Recommender+Systems)|0|
|[DeSCoVeR: Debiased Semantic Context Prior for Venue Recommendation](https://doi.org/10.1145/3477495.3531877)|Sailaja Rajanala, Arghya Pal, Manish Singh, Raphael C.W. Phan, KokSheik Wong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeSCoVeR:+Debiased+Semantic+Context+Prior+for+Venue+Recommendation)|0|
|[Revisiting Bundle Recommendation: Datasets, Tasks, Challenges and Opportunities for Intent-aware Product Bundling](https://doi.org/10.1145/3477495.3531904)|Zhu Sun, Jie Yang, Kaidong Feng, Hui Fang, Xinghua Qu, Yew Soon Ong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Bundle+Recommendation:+Datasets,+Tasks,+Challenges+and+Opportunities+for+Intent-aware+Product+Bundling)|0|
|[Query Facet Mapping and its Applications in Streaming Services: The Netflix Case Study](https://doi.org/10.1145/3477495.3536330)|Sudeep Das, Ivan Provalov, Vickie Zhang, Weidong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query+Facet+Mapping+and+its+Applications+in+Streaming+Services:+The+Netflix+Case+Study)|0|
|[Implicit Feedback for Dense Passage Retrieval: A Counterfactual Approach](https://doi.org/10.1145/3477495.3531994)|Shengyao Zhuang, Hang Li, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Implicit+Feedback+for+Dense+Passage+Retrieval:+A+Counterfactual+Approach)|0|
|[Offline Evaluation of Ranked Lists using Parametric Estimation of Propensities](https://doi.org/10.1145/3477495.3532032)|Vishwa Vinay, Manoj Kilaru, David Arbour||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Evaluation+of+Ranked+Lists+using+Parametric+Estimation+of+Propensities)|0|
|[CAPTOR: A Crowd-Aware Pre-Travel Recommender System for Out-of-Town Users](https://doi.org/10.1145/3477495.3531949)|Haoran Xin, Xinjiang Lu, Nengjun Zhu, Tong Xu, Dejing Dou, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAPTOR:+A+Crowd-Aware+Pre-Travel+Recommender+System+for+Out-of-Town+Users)|0|
|[Unify Local and Global Information for Top-N Recommendation](https://doi.org/10.1145/3477495.3532070)|Xiaoming Liu, Shaocong Wu, Zhaohan Zhang, Chao Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unify+Local+and+Global+Information+for+Top-N+Recommendation)|0|
|[Deployable and Continuable Meta-learning-Based Recommender System with Fast User-Incremental Updates](https://doi.org/10.1145/3477495.3531964)|Renchu Guan, Haoyu Pang, Fausto Giunchiglia, Ximing Li, Xuefeng Yang, Xiaoyue Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deployable+and+Continuable+Meta-learning-Based+Recommender+System+with+Fast+User-Incremental+Updates)|0|
|[Bias Mitigation for Toxicity Detection via Sequential Decisions](https://doi.org/10.1145/3477495.3531945)|Lu Cheng, Ahmadreza Mosallanezhad, Yasin N. Silva, Deborah L. Hall, Huan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+Mitigation+for+Toxicity+Detection+via+Sequential+Decisions)|0|
|[Regulating Group Exposure for Item Providers in Recommendation](https://doi.org/10.1145/3477495.3531760)|Mirko Marras, Ludovico Boratto, Guilherme Ramos, Gianni Fenu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regulating+Group+Exposure+for+Item+Providers+in+Recommendation)|0|
|[IPR: Interaction-level Preference Ranking for Explicit feedback](https://doi.org/10.1145/3477495.3531777)|ShihYang Liu, HsienHao Chen, ChihMing Chen, MingFeng Tsai, ChuanJu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IPR:+Interaction-level+Preference+Ranking+for+Explicit+feedback)|0|
|[MP2: A Momentum Contrast Approach for Recommendation with Pointwise and Pairwise Learning](https://doi.org/10.1145/3477495.3531813)|Menghan Wang, Yuchen Guo, Zhenqi Zhao, Guangzheng Hu, Yuming Shen, Mingming Gong, Philip H. S. Torr||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MP2:+A+Momentum+Contrast+Approach+for+Recommendation+with+Pointwise+and+Pairwise+Learning)|0|
|[Deep Page-Level Interest Network in Reinforcement Learning for Ads Allocation](https://doi.org/10.1145/3477495.3531847)|Guogang Liao, Xiaowen Shi, Ze Wang, Xiaoxu Wu, Chuheng Zhang, Yongkang Wang, Xingxing Wang, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Page-Level+Interest+Network+in+Reinforcement+Learning+for+Ads+Allocation)|0|
|[Improving Micro-video Recommendation via Contrastive Multiple Interests](https://doi.org/10.1145/3477495.3531861)|Beibei Li, Beihong Jin, Jiageng Song, Yisong Yu, Yiyuan Zheng, Wei Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Micro-video+Recommendation+via+Contrastive+Multiple+Interests)|0|
|[Can Users Predict Relative Query Effectiveness?](https://doi.org/10.1145/3477495.3531893)|Oleg Zendel, Melika P. Ebrahim, J. Shane Culpepper, Alistair Moffat, Falk Scholer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Users+Predict+Relative+Query+Effectiveness?)|0|
|[Is Non-IID Data a Threat in Federated Online Learning to Rank?](https://doi.org/10.1145/3477495.3531709)|Shuyi Wang, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+Non-IID+Data+a+Threat+in+Federated+Online+Learning+to+Rank?)|0|
|[On Natural Language User Profiles for Transparent and Scrutable Recommendation](https://doi.org/10.1145/3477495.3531873)|Filip Radlinski, Krisztian Balog, Fernando Diaz, Lucas Dixon, Ben Wedin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Natural+Language+User+Profiles+for+Transparent+and+Scrutable+Recommendation)|0|
|[Retrieval-Enhanced Machine Learning](https://doi.org/10.1145/3477495.3531722)|Hamed Zamani, Fernando Diaz, Mostafa Dehghani, Donald Metzler, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Enhanced+Machine+Learning)|0|
|[Multi-CPR: A Multi Domain Chinese Dataset for Passage Retrieval](https://doi.org/10.1145/3477495.3531736)|Dingkun Long, Qiong Gao, Kuan Zou, Guangwei Xu, Pengjun Xie, Ruijie Guo, Jian Xu, Guanjun Jiang, Luxi Xing, Ping Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-CPR:+A+Multi+Domain+Chinese+Dataset+for+Passage+Retrieval)|0|
|[MIMICS-Duo: Offline & Online Evaluation of Search Clarification](https://doi.org/10.1145/3477495.3531750)|Leila Tavakoli, Johanne R. Trippas, Hamed Zamani, Falk Scholer, Mark Sanderson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MIMICS-Duo:+Offline+&+Online+Evaluation+of+Search+Clarification)|0|
|[A Common Framework for Exploring Document-at-a-Time and Score-at-a-Time Retrieval Methods](https://doi.org/10.1145/3477495.3531657)|Andrew Trotman, Joel Mackenzie, Pradeesh Parameswaran, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Common+Framework+for+Exploring+Document-at-a-Time+and+Score-at-a-Time+Retrieval+Methods)|0|
|[BiTe-REx: An Explainable Bilingual Text Retrieval System in the Automotive Domain](https://doi.org/10.1145/3477495.3531665)|Viju Sudhi, Sabine Wehnert, Norbert Michael Homner, Sebastian Ernst, Mark Gonter, Andreas Krug, Ernesto William De Luca||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BiTe-REx:+An+Explainable+Bilingual+Text+Retrieval+System+in+the+Automotive+Domain)|0|
|[Are Taylor's Posts Risky? Evaluating Cumulative Revelations in Online Personal Data: A persona-based tool for evaluating awareness of online risks and harms](https://doi.org/10.1145/3477495.3531659)|Leif Azzopardi, Jo Briggs, Melissa Duheric, Callum Nash, Emma Nicol, Wendy Moncur, Burkhard Schafer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+Taylor's+Posts+Risky?+Evaluating+Cumulative+Revelations+in+Online+Personal+Data:+A+persona-based+tool+for+evaluating+awareness+of+online+risks+and+harms)|0|
|[DDEN: A Heterogeneous Learning-to-Rank Approach with Deep Debiasing Experts Network](https://doi.org/10.1145/3477495.3536320)|Wenchao Xiu, Yiran Wang, Taofeng Xue, Kai Zhang, Qin Zhang, Zhonghuo Wu, Yifan Yang, Gong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DDEN:+A+Heterogeneous+Learning-to-Rank+Approach+with+Deep+Debiasing+Experts+Network)|0|
|[An Intelligent Advertisement Short Video Production System via Multi-Modal Retrieval](https://doi.org/10.1145/3477495.3536323)|Yanheng Wei, Lianghua Huang, Yanhao Zhang, Yun Zheng, Pan Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Intelligent+Advertisement+Short+Video+Production+System+via+Multi-Modal+Retrieval)|0|
|[An Industrial Framework for Cold-Start Recommendation in Zero-Shot Scenarios](https://doi.org/10.1145/3477495.3536332)|Zhaoxin Huan, Gongduo Zhang, Xiaolu Zhang, Jun Zhou, Qintong Wu, Lihong Gu, Jinjie Gu, Yong He, Yue Zhu, Linjian Mo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Industrial+Framework+for+Cold-Start+Recommendation+in+Zero-Shot+Scenarios)|0|
|[What the Actual...Examining User Behaviour in Information Retrieval](https://doi.org/10.1145/3477495.3532687)|George Buchanan, Dana McKay||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+the+Actual...Examining+User+Behaviour+in+Information+Retrieval)|0|
|[User-centered Non-factoid Answer Retrieval](https://doi.org/10.1145/3477495.3531689)|Marwah Alaofi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-centered+Non-factoid+Answer+Retrieval)|0|
|[Intelligent Conversational Agents for Ambient Computing](https://doi.org/10.1145/3477495.3532087)|Ruhi Sarikaya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intelligent+Conversational+Agents+for+Ambient+Computing)|0|
|[A Robust Computerized Adaptive Testing Approach in Educational Question Retrieval](https://doi.org/10.1145/3477495.3531928)|Yan Zhuang, Qi Liu, Zhenya Huang, Zhi Li, Binbin Jin, Haoyang Bi, Enhong Chen, Shijin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Robust+Computerized+Adaptive+Testing+Approach+in+Educational+Question+Retrieval)|0|
|[Forest-based Deep Recommender](https://doi.org/10.1145/3477495.3531980)|Chao Feng, Defu Lian, Zheng Liu, Xing Xie, Le Wu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forest-based+Deep+Recommender)|0|
|[Ranking Interruptus: When Truncated Rankings Are Better and How to Measure That](https://doi.org/10.1145/3477495.3532051)|Enrique Amigó, Stefano Mizzaro, Damiano Spina||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking+Interruptus:+When+Truncated+Rankings+Are+Better+and+How+to+Measure+That)|0|
|[Offline Retrieval Evaluation Without Evaluation Metrics](https://doi.org/10.1145/3477495.3532033)|Fernando Diaz, Andres Ferraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Retrieval+Evaluation+Without+Evaluation+Metrics)|0|
|[Pareto-Optimal Fairness-Utility Amortizations in Rankings with a DBN Exposure Model](https://doi.org/10.1145/3477495.3532036)|Till Kletti, JeanMichel Renders, Patrick Loiseau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto-Optimal+Fairness-Utility+Amortizations+in+Rankings+with+a+DBN+Exposure+Model)|0|
|[Risk-Sensitive Deep Neural Learning to Rank](https://doi.org/10.1145/3477495.3532056)|Pedro Henrique Silva Rodrigues, Daniel Xavier de Sousa, Thierson Couto Rosa, Marcos André Gonçalves||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Risk-Sensitive+Deep+Neural+Learning+to+Rank)|0|
|[Adaptable Text Matching via Meta-Weight Regulator](https://doi.org/10.1145/3477495.3531932)|Bo Zhang, Chen Zhang, Fang Ma, Dawei Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptable+Text+Matching+via+Meta-Weight+Regulator)|0|
|[Re-thinking Knowledge Graph Completion Evaluation from an Information Retrieval Perspective](https://doi.org/10.1145/3477495.3532052)|Ying Zhou, Xuanang Chen, Ben He, Zheng Ye, Le Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Re-thinking+Knowledge+Graph+Completion+Evaluation+from+an+Information+Retrieval+Perspective)|0|
|[CRET: Cross-Modal Retrieval Transformer for Efficient Text-Video Retrieval](https://doi.org/10.1145/3477495.3531960)|Kaixiang Ji, Jiajia Liu, Weixiang Hong, Liheng Zhong, Jian Wang, Jingdong Chen, Wei Chu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CRET:+Cross-Modal+Retrieval+Transformer+for+Efficient+Text-Video+Retrieval)|0|
|[Learn from Unlabeled Videos for Near-duplicate Video Retrieval](https://doi.org/10.1145/3477495.3532010)|Xiangteng He, Yulin Pan, Mingqian Tang, Yiliang Lv, Yuxin Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learn+from+Unlabeled+Videos+for+Near-duplicate+Video+Retrieval)|0|
|[Progressive Learning for Image Retrieval with Hybrid-Modality Queries](https://doi.org/10.1145/3477495.3532047)|Yida Zhao, Yuqing Song, Qin Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Learning+for+Image+Retrieval+with+Hybrid-Modality+Queries)|0|
|[Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking](https://doi.org/10.1145/3477495.3531997)|Qian Dong, Yiding Liu, Suqi Cheng, Shuaiqiang Wang, Zhicong Cheng, Shuzi Niu, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Explicit+Knowledge+in+Pre-trained+Language+Models+for+Passage+Re-ranking)|0|
|[Axiomatically Regularized Pre-training for Ad hoc Search](https://doi.org/10.1145/3477495.3531943)|Jia Chen, Yiqun Liu, Yan Fang, Jiaxin Mao, Hui Fang, Shenghao Yang, Xiaohui Xie, Min Zhang, Shaoping Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Axiomatically+Regularized+Pre-training+for+Ad+hoc+Search)|0|
|[On the Role of Relevance in Natural Language Processing Tasks](https://doi.org/10.1145/3477495.3532034)|Artsiom Sauchuk, James Thorne, Alon Y. Halevy, Nicola Tonellotto, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Role+of+Relevance+in+Natural+Language+Processing+Tasks)|0|
|[Adversarial Graph Perturbations for Recommendations at Scale](https://doi.org/10.1145/3477495.3531763)|Huiyuan Chen, Kaixiong Zhou, KweiHerng Lai, Xia Hu, Fei Wang, Hao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Graph+Perturbations+for+Recommendations+at+Scale)|0|
|[Relevance under the Iceberg: Reasonable Prediction for Extreme Multi-label Classification](https://doi.org/10.1145/3477495.3531767)|JyunYu Jiang, WeiCheng Chang, Jiong Zhang, ChoJui Hsieh, HsiangFu Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevance+under+the+Iceberg:+Reasonable+Prediction+for+Extreme+Multi-label+Classification)|0|
|[Gating-adapted Wavelet Multiresolution Analysis for Exposure Sequence Modeling in CTR Prediction](https://doi.org/10.1145/3477495.3531771)|Xiaoxiao Xu, Zhiwei Fang, Qian Yu, Ruoran Huang, Chaosheng Fan, Yong Li, Yang He, Changping Peng, Zhangang Lin, Jingping Shao, Non Non||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gating-adapted+Wavelet+Multiresolution+Analysis+for+Exposure+Sequence+Modeling+in+CTR+Prediction)|0|
|[Animating Images to Transfer CLIP for Video-Text Retrieval](https://doi.org/10.1145/3477495.3531776)|Yu Liu, Huai Chen, Lianghua Huang, Di Chen, Bin Wang, Pan Pan, Lisheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Animating+Images+to+Transfer+CLIP+for+Video-Text+Retrieval)|0|
|[Image-Text Retrieval via Contrastive Learning with Auxiliary Generative Features and Support-set Regularization](https://doi.org/10.1145/3477495.3531783)|Lei Zhang, Min Yang, Chengming Li, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Image-Text+Retrieval+via+Contrastive+Learning+with+Auxiliary+Generative+Features+and+Support-set+Regularization)|0|
|[Denoising Time Cycle Modeling for Recommendation](https://doi.org/10.1145/3477495.3531785)|Sicong Xie, Qunwei Li, Weidi Xu, Kaiming Shen, Shaohu Chen, Wenliang Zhong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Denoising+Time+Cycle+Modeling+for+Recommendation)|0|
|[Value Penalized Q-Learning for Recommender Systems](https://doi.org/10.1145/3477495.3531796)|Chengqian Gao, Ke Xu, Kuangqi Zhou, Lanqing Li, Xueqian Wang, Bo Yuan, Peilin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Value+Penalized+Q-Learning+for+Recommender+Systems)|0|
|[From Cluster Ranking to Document Ranking](https://doi.org/10.1145/3477495.3531819)|Egor Markovskiy, Fiana Raiber, Shoham Sabach, Oren Kurland||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Cluster+Ranking+to+Document+Ranking)|0|
|[ILMART: Interpretable Ranking with Constrained LambdaMART](https://doi.org/10.1145/3477495.3531840)|Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Alberto Veneri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ILMART:+Interpretable+Ranking+with+Constrained+LambdaMART)|0|
|[On Extractive Summarization for Profile-centric Neural Expert Search in Academia](https://doi.org/10.1145/3477495.3531713)|Rennan C. Lima, Rodrygo L. T. Santos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Extractive+Summarization+for+Profile-centric+Neural+Expert+Search+in+Academia)|0|
|[Joint Optimization of Ad Ranking and Creative Selection](https://doi.org/10.1145/3477495.3531855)|Kaiyi Lin, Xiang Zhang, Feng Li, Pengjie Wang, Qingqing Long, Hongbo Deng, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Optimization+of+Ad+Ranking+and+Creative+Selection)|0|
|[Long Document Re-ranking with Modular Re-ranker](https://doi.org/10.1145/3477495.3531860)|Luyu Gao, Jamie Callan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long+Document+Re-ranking+with+Modular+Re-ranker)|0|
|[Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning](https://doi.org/10.1145/3477495.3531746)|Xiang Chen, Lei Li, Ningyu Zhang, Chuanqi Tan, Fei Huang, Luo Si, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relation+Extraction+as+Open-book+Examination:+Retrieval-enhanced+Prompt+Tuning)|0|
|[End-to-end Distantly Supervised Information Extraction with Retrieval Augmentation](https://doi.org/10.1145/3477495.3531876)|Yue Zhang, Hongliang Fei, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-end+Distantly+Supervised+Information+Extraction+with+Retrieval+Augmentation)|0|
|[Assessing Scientific Research Papers with Knowledge Graphs](https://doi.org/10.1145/3477495.3531879)|Kexuan Sun, Zhiqiang Qiu, Abel Salinas, Yuzhong Huang, DongHo Lee, Daniel Benjamin, Fred Morstatter, Xiang Ren, Kristina Lerman, Jay Pujara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Scientific+Research+Papers+with+Knowledge+Graphs)|0|
|[A Content Recommendation Policy for Gaining Subscribers](https://doi.org/10.1145/3477495.3531885)|Konstantinos Theocharidis, Manolis Terrovitis, Spiros Skiadopoulos, Panagiotis Karras||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Content+Recommendation+Policy+for+Gaining+Subscribers)|0|
|[MM-Rec: Visiolinguistic Model Empowered Multimodal News Recommendation](https://doi.org/10.1145/3477495.3531896)|Chuhan Wu, Fangzhao Wu, Tao Qi, Chao Zhang, Yongfeng Huang, Tong Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MM-Rec:+Visiolinguistic+Model+Empowered+Multimodal+News+Recommendation)|0|
|[Towards Personalized Bundle Creative Generation with Contrastive Non-Autoregressive Decoding](https://doi.org/10.1145/3477495.3531909)|Penghui Wei, Shaoguo Liu, Xuanhua Yang, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Personalized+Bundle+Creative+Generation+with+Contrastive+Non-Autoregressive+Decoding)|0|
|[Another Look at Information Retrieval as Statistical Translation](https://doi.org/10.1145/3477495.3531717)|Yuqi Liu, Chengcheng Hu, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Another+Look+at+Information+Retrieval+as+Statistical+Translation)|0|
|[ACORDAR: A Test Collection for Ad Hoc Content-Based (RDF) Dataset Retrieval](https://doi.org/10.1145/3477495.3531729)|Tengteng Lin, Qiaosheng Chen, Gong Cheng, Ahmet Soylu, Basil Ell, Ruoqi Zhao, Qing Shi, Xiaxia Wang, Yu Gu, Evgeny Kharlamov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACORDAR:+A+Test+Collection+for+Ad+Hoc+Content-Based+(RDF)+Dataset+Retrieval)|0|
|[RELISON: A Framework for Link Recommendation in Social Networks](https://doi.org/10.1145/3477495.3531730)|Javier SanzCruzado, Pablo Castells||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RELISON:+A+Framework+for+Link+Recommendation+in+Social+Networks)|0|
|[The Istella22 Dataset: Bridging Traditional and Neural Learning to Rank Evaluation](https://doi.org/10.1145/3477495.3531740)|Domenico Dato, Sean MacAvaney, Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Istella22+Dataset:+Bridging+Traditional+and+Neural+Learning+to+Rank+Evaluation)|0|
|[Axiomatic Retrieval Experimentation with ir_axioms](https://doi.org/10.1145/3477495.3531743)|Alexander Bondarenko, Maik Fröbe, Jan Heinrich Reimer, Benno Stein, Michael Völske, Matthias Hagen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Axiomatic+Retrieval+Experimentation+with+ir_axioms)|0|
|[Knowledge Graph Question Answering Datasets and Their Generalizability: Are They Enough for Future Research?](https://doi.org/10.1145/3477495.3531751)|Longquan Jiang, Ricardo Usbeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Question+Answering+Datasets+and+Their+Generalizability:+Are+They+Enough+for+Future+Research?)|0|
|[Golden Retriever: A Real-Time Multi-Modal Text-Image Retrieval System with the Ability to Focus](https://doi.org/10.1145/3477495.3531666)|Florian Schneider, Chris Biemann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Golden+Retriever:+A+Real-Time+Multi-Modal+Text-Image+Retrieval+System+with+the+Ability+to+Focus)|0|
|[ZeroMatcher: A Cost-Off Entity Matching System](https://doi.org/10.1145/3477495.3531661)|Congcong Ge, Xiaocan Zeng, Lu Chen, Yunjun Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ZeroMatcher:+A+Cost-Off+Entity+Matching+System)|0|
|[QFinder: A Framework for Quantity-centric Ranking](https://doi.org/10.1145/3477495.3531672)|Satya Almasian, Milena Bruseva, Michael Gertz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QFinder:+A+Framework+for+Quantity-centric+Ranking)|0|
|[CHERCHE: A New Tool to Rapidly Implement Pipelines in Information Retrieval](https://doi.org/10.1145/3477495.3531695)|Raphaël Sourty, José G. Moreno, Lynda Tamine, FrançoisPaul Servant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CHERCHE:+A+New+Tool+to+Rapidly+Implement+Pipelines+in+Information+Retrieval)|0|
|[Arm: Efficient Learning of Neural Retrieval Models with Desired Accuracy by Automatic Knowledge Amalgamation](https://doi.org/10.1145/3477495.3531664)|Linzhu Yu, Dawei Jiang, Ke Chen, Lidan Shou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Arm:+Efficient+Learning+of+Neural+Retrieval+Models+with+Desired+Accuracy+by+Automatic+Knowledge+Amalgamation)|0|
|[An Auto Encoder-based Dimensionality Reduction Technique for Efficient Entity Linking in Business Phone Conversations](https://doi.org/10.1145/3477495.3536322)|Md. Tahmid Rahman Laskar, Cheng Chen, Jonathan Johnston, XueYong Fu, Shashi Bhushan TN, Simon CorstonOliver||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Auto+Encoder-based+Dimensionality+Reduction+Technique+for+Efficient+Entity+Linking+in+Business+Phone+Conversations)|0|
|[Applications and Future of Dense Retrieval in Industry](https://doi.org/10.1145/3477495.3536324)|Yubin Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Applications+and+Future+of+Dense+Retrieval+in+Industry)|0|
|[Flipping the Script: Inverse Information Seeking Dialogues for Market Research](https://doi.org/10.1145/3477495.3536326)|Josh Seltzer, Kathy Cheng, Shi Zong, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flipping+the+Script:+Inverse+Information+Seeking+Dialogues+for+Market+Research)|0|
|[Information Ecosystem Threats in Minoritized Communities: Challenges, Open Problems and Research Directions](https://doi.org/10.1145/3477495.3536327)|Shiri DoriHacohen, Scott A. Hale||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Ecosystem+Threats+in+Minoritized+Communities:+Challenges,+Open+Problems+and+Research+Directions)|0|
|[Extractive Search for Analysis of Biomedical Texts](https://doi.org/10.1145/3477495.3536328)|Daniel Clothiaux, Ravi Starzl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extractive+Search+for+Analysis+of+Biomedical+Texts)|0|
|[Recent Advances in Retrieval-Augmented Text Generation](https://doi.org/10.1145/3477495.3532682)|Deng Cai, Yan Wang, Lemao Liu, Shuming Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recent+Advances+in+Retrieval-Augmented+Text+Generation)|0|
|[Adaptive Dialogue Management for Conversational Information Elicitation](https://doi.org/10.1145/3477495.3531684)|Harshita Sahijwani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Dialogue+Management+for+Conversational+Information+Elicitation)|0|
|[Pre-Training for Mathematics-Aware Retrieval](https://doi.org/10.1145/3477495.3531680)|Anja Reusch||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-Training+for+Mathematics-Aware+Retrieval)|0|
|[Explainable Conversational Question Answering over Heterogeneous Sources](https://doi.org/10.1145/3477495.3531688)|Philipp Christmann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Conversational+Question+Answering+over+Heterogeneous+Sources)|0|
|[KA-Recsys: Patient Focused Knowledge Appropriate Health Recommender System](https://doi.org/10.1145/3477495.3531687)|Khushboo Thaker||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KA-Recsys:+Patient+Focused+Knowledge+Appropriate+Health+Recommender+System)|0|
|[Bilateral Self-unbiased Learning from Biased Implicit Feedback](https://doi.org/10.1145/3477495.3531946)|Jaewoong Lee, Seongmin Park, Joonseok Lee, Jongwuk Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bilateral+Self-unbiased+Learning+from+Biased+Implicit+Feedback)|0|
|[Why do Semantically Unrelated Categories Appear in the Same Session?: A Demand-aware Method](https://doi.org/10.1145/3477495.3531806)|Liqi Yang, Linhao Luo, Xiaofeng Zhang, Fengxin Li, Xinni Zhang, Zelin Jiang, Shuai Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+do+Semantically+Unrelated+Categories+Appear+in+the+Same+Session?:+A+Demand-aware+Method)|0|
|[Scalable User Interface Optimization Using Combinatorial Bandits](https://doi.org/10.1145/3477495.3536325)|Ioannis Kangas, Maud Schwoerer, Lucas Bernardi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+User+Interface+Optimization+Using+Combinatorial+Bandits)|0|
|[Users: Can't Work With Them, Can't Work Without Them?](https://doi.org/10.1145/3477495.3532787)|Alistair Moffat||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Users:+Can't+Work+With+Them,+Can't+Work+Without+Them?)|0|
|[Interacting with Non-Cooperative User: A New Paradigm for Proactive Dialogue Policy](https://doi.org/10.1145/3477495.3532001)|Wenqiang Lei, Yao Zhang, Feifan Song, Hongru Liang, Jiaxin Mao, Jiancheng Lv, Zhenglu Yang, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interacting+with+Non-Cooperative+User:+A+New+Paradigm+for+Proactive+Dialogue+Policy)|0|
|[ADPL: Adversarial Prompt-based Domain Adaptation for Dialogue Summarization with Knowledge Disentanglement](https://doi.org/10.1145/3477495.3531933)|Lulu Zhao, Fujia Zheng, Weihao Zeng, Keqing He, Ruotong Geng, Huixing Jiang, Wei Wu, Weiran Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ADPL:+Adversarial+Prompt-based+Domain+Adaptation+for+Dialogue+Summarization+with+Knowledge+Disentanglement)|0|
|[IR Evaluation and Learning in the Presence of Forbidden Documents](https://doi.org/10.1145/3477495.3532006)|David Carmel, Nachshon Cohen, Amir Ingber, Elad Kravi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IR+Evaluation+and+Learning+in+the+Presence+of+Forbidden+Documents)|0|
|[Human Preferences as Dueling Bandits](https://doi.org/10.1145/3477495.3531991)|Xinyi Yan, Chengxi Luo, Charles L. A. Clarke, Nick Craswell, Ellen M. Voorhees, Pablo Castells||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human+Preferences+as+Dueling+Bandits)|0|
|[IAOTP: An Interactive End-to-End Solution for Aspect-Opinion Term Pairs Extraction](https://doi.org/10.1145/3477495.3532085)|Ambreen Nazir, Yuan Rao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IAOTP:+An+Interactive+End-to-End+Solution+for+Aspect-Opinion+Term+Pairs+Extraction)|0|
|[Exploring Heterogeneous Data Lake based on Unified Canonical Graphs](https://doi.org/10.1145/3477495.3531759)|Qin Yuan, Ye Yuan, Zhenyu Wen, He Wang, Chen Chen, Guoren Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Heterogeneous+Data+Lake+based+on+Unified+Canonical+Graphs)|0|
|[Distilling Knowledge on Text Graph for Social Media Attribute Inference](https://doi.org/10.1145/3477495.3531968)|Quan Li, Xiaoting Li, Lingwei Chen, Dinghao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Knowledge+on+Text+Graph+for+Social+Media+Attribute+Inference)|0|
|[A Simple Meta-learning Paradigm for Zero-shot Intent Classification with Mixture Attention Mechanism](https://doi.org/10.1145/3477495.3531803)|Han Liu, Siyang Zhao, Xiaotong Zhang, Feng Zhang, Junjie Sun, Hong Yu, Xianchao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Simple+Meta-learning+Paradigm+for+Zero-shot+Intent+Classification+with+Mixture+Attention+Mechanism)|0|
|[Analyzing the Support Level for Tips Extracted from Product Reviews](https://doi.org/10.1145/3477495.3531805)|Miriam Farber, David Carmel, Lital Kuchy, Avihai Mejer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+the+Support+Level+for+Tips+Extracted+from+Product+Reviews)|0|
|[UserBERT: Pre-training User Model with Contrastive Self-supervision](https://doi.org/10.1145/3477495.3531810)|Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UserBERT:+Pre-training+User+Model+with+Contrastive+Self-supervision)|0|
|[Modern Baselines for SPARQL Semantic Parsing](https://doi.org/10.1145/3477495.3531841)|Debayan Banerjee, Pranav Ajit Nair, Jivat Neet Kaur, Ricardo Usbeck, Chris Biemann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modern+Baselines+for+SPARQL+Semantic+Parsing)|0|
|[Posterior Probability Matters: Doubly-Adaptive Calibration for Neural Predictions in Online Advertising](https://doi.org/10.1145/3477495.3531911)|Penghui Wei, Weimin Zhang, Ruijie Hou, Jinquan Liu, Shaoguo Liu, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Posterior+Probability+Matters:+Doubly-Adaptive+Calibration+for+Neural+Predictions+in+Online+Advertising)|0|
|[Table Enrichment System for Machine Learning](https://doi.org/10.1145/3477495.3531678)|Yuyang Dong, Masafumi Oyamada||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Table+Enrichment+System+for+Machine+Learning)|0|
|[LawNet-Viz: A Web-based System to Visually Explore Networks of Law Article References](https://doi.org/10.1145/3477495.3531668)|Lucio La Cava, Andrea Simeri, Andrea Tagarelli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LawNet-Viz:+A+Web-based+System+to+Visually+Explore+Networks+of+Law+Article+References)|0|
|[Quote Erat Demonstrandum: A Web Interface for Exploring the Quotebank Corpus](https://doi.org/10.1145/3477495.3531696)|Vuk Vukovic, Akhil Arora, HuanCheng Chang, Andreas Spitz, Robert West||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quote+Erat+Demonstrandum:+A+Web+Interface+for+Exploring+the+Quotebank+Corpus)|0|
|[Unsupervised Product Offering Title Quality Scores](https://doi.org/10.1145/3477495.3536333)|Henry S. Vieira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Product+Offering+Title+Quality+Scores)|0|
|[Few-shot Information Extraction is Here: Pre-train, Prompt and Entail](https://doi.org/10.1145/3477495.3532786)|Eneko Agirre||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+Information+Extraction+is+Here:+Pre-train,+Prompt+and+Entail)|0|
|[Improving Implicit Alternating Least Squares with Ring-based Regularization](https://doi.org/10.1145/3477495.3531995)|Rui Fan, Jin Chen, Jin Zhang, Defu Lian, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Implicit+Alternating+Least+Squares+with+Ring-based+Regularization)|0|
|[Target-aware Abstractive Related Work Generation with Contrastive Learning](https://doi.org/10.1145/3477495.3532065)|Xiuying Chen, Hind Alamro, Mingzhe Li, Shen Gao, Rui Yan, Xin Gao, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Target-aware+Abstractive+Related+Work+Generation+with+Contrastive+Learning)|0|
|[Information Need Awareness: An EEG Study](https://doi.org/10.1145/3477495.3531999)|Dominika Michalkova, Mario ParraRodriguez, Yashar Moshfeghi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Need+Awareness:+An+EEG+Study)|0|
|[Unifying Cross-lingual Summarization and Machine Translation with Compression Rate](https://doi.org/10.1145/3477495.3532071)|Yu Bai, Heyan Huang, Kai Fan, Yang Gao, Yiming Zhu, Jiaao Zhan, Zewen Chi, Boxing Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+Cross-lingual+Summarization+and+Machine+Translation+with+Compression+Rate)|0|
|[What Makes the Story Forward?: Inferring Commonsense Explanations as Prompts for Future Event Generation](https://doi.org/10.1145/3477495.3532080)|Li Lin, Yixin Cao, Lifu Huang, Shuang Li, Xuming Hu, Lijie Wen, Jianmin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+Makes+the+Story+Forward?:+Inferring+Commonsense+Explanations+as+Prompts+for+Future+Event+Generation)|0|
|[A Dual-Expert Framework for Event Argument Extraction](https://doi.org/10.1145/3477495.3531923)|Rui Li, Wenlin Zhao, Cheng Yang, Sen Su||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dual-Expert+Framework+for+Event+Argument+Extraction)|0|
|[CorED: Incorporating Type-level and Instance-level Correlations for Fine-grained Event Detection](https://doi.org/10.1145/3477495.3531956)|Jiawei Sheng, Rui Sun, Shu Guo, Shiyao Cui, Jiangxia Cao, Lihong Wang, Tingwen Liu, Hongbo Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CorED:+Incorporating+Type-level+and+Instance-level+Correlations+for+Fine-grained+Event+Detection)|0|
|[QUASER: Question Answering with Scalable Extractive Rationalization](https://doi.org/10.1145/3477495.3532049)|Asish Ghoshal, Srinivasan Iyer, Bhargavi Paranjape, Kushal Lakhotia, Scott Wentau Yih, Yashar Mehdad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QUASER:+Question+Answering+with+Scalable+Extractive+Rationalization)|0|
|[PTAU: Prompt Tuning for Attributing Unanswerable Questions](https://doi.org/10.1145/3477495.3532048)|Jinzhi Liao, Xiang Zhao, Jianming Zheng, Xinyi Li, Fei Cai, Jiuyang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PTAU:+Prompt+Tuning+for+Attributing+Unanswerable+Questions)|0|
|[DGQAN: Dual Graph Question-Answer Attention Networks for Answer Selection](https://doi.org/10.1145/3477495.3532084)|Haitian Yang, Xuan Zhao, Yan Wang, Min Li, Wei Chen, Weiqing Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DGQAN:+Dual+Graph+Question-Answer+Attention+Networks+for+Answer+Selection)|0|
|[Towards Event-level Causal Relation Identification](https://doi.org/10.1145/3477495.3531758)|Chuang Fan, Daoxing Liu, Libo Qin, Yue Zhang, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Event-level+Causal+Relation+Identification)|0|
|[Hierarchical Task-aware Multi-Head Attention Network](https://doi.org/10.1145/3477495.3531781)|Jing Du, Lina Yao, Xianzhi Wang, Bin Guo, Zhiwen Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Task-aware+Multi-Head+Attention+Network)|0|
|[Enhancing Event-Level Sentiment Analysis with Structured Arguments](https://doi.org/10.1145/3477495.3531784)|Qi Zhang, Jie Zhou, Qin Chen, Qingchun Bai, Liang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Event-Level+Sentiment+Analysis+with+Structured+Arguments)|0|
|[Translation-Based Implicit Annotation Projection for Zero-Shot Cross-Lingual Event Argument Extraction](https://doi.org/10.1145/3477495.3531808)|Chenwei Lou, Jun Gao, Changlong Yu, Wei Wang, Huan Zhao, Weiwei Tu, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Translation-Based+Implicit+Annotation+Projection+for+Zero-Shot+Cross-Lingual+Event+Argument+Extraction)|0|
|[Understanding Long Programming Languages with Structure-Aware Sparse Attention](https://doi.org/10.1145/3477495.3531811)|Tingting Liu, Chengyu Wang, Cen Chen, Ming Gao, Aoying Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+Long+Programming+Languages+with+Structure-Aware+Sparse+Attention)|0|
|[Dialogue Topic Segmentation via Parallel Extraction Network with Neighbor Smoothing](https://doi.org/10.1145/3477495.3531817)|Jinxiong Xia, Cao Liu, Jiansong Chen, Yuchen Li, Fan Yang, Xunliang Cai, Guanglu Wan, Houfeng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dialogue+Topic+Segmentation+via+Parallel+Extraction+Network+with+Neighbor+Smoothing)|0|
|[Expression Syntax Information Bottleneck for Math Word Problems](https://doi.org/10.1145/3477495.3531824)|Jing Xiong, Chengming Li, Min Yang, Xiping Hu, Bin Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expression+Syntax+Information+Bottleneck+for+Math+Word+Problems)|0|
|[Masking and Generation: An Unsupervised Method for Sarcasm Detection](https://doi.org/10.1145/3477495.3531825)|Rui Wang, Qianlong Wang, Bin Liang, Yi Chen, Zhiyuan Wen, Bing Qin, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Masking+and+Generation:+An+Unsupervised+Method+for+Sarcasm+Detection)|0|
|[Learned Token Pruning in Contextualized Late Interaction over BERT (ColBERT)](https://doi.org/10.1145/3477495.3531835)|Carlos Lassance, Maroua Maachou, Joohee Park, Stéphane Clinchant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learned+Token+Pruning+in+Contextualized+Late+Interaction+over+BERT+(ColBERT))|0|
|[GraFN: Semi-Supervised Node Classification on Graph with Few Labels via Non-Parametric Distribution Assignment](https://doi.org/10.1145/3477495.3531838)|Junseok Lee, Yunhak Oh, Yeonjun In, Namkyeong Lee, Dongmin Hyun, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraFN:+Semi-Supervised+Node+Classification+on+Graph+with+Few+Labels+via+Non-Parametric+Distribution+Assignment)|0|
|[Which Discriminator for Cooperative Text Generation?](https://doi.org/10.1145/3477495.3531858)|Antoine Chaffin, Thomas Scialom, Sylvain Lamprier, Jacopo Staiano, Benjamin Piwowarski, Ewa Kijak, Vincent Claveau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Which+Discriminator+for+Cooperative+Text+Generation?)|0|
|[Topological Analysis of Contradictions in Text](https://doi.org/10.1145/3477495.3531881)|Xiangcheng Wu, Xi Niu, Ruhani Rahman||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topological+Analysis+of+Contradictions+in+Text)|0|
|[Dual Pseudo Supervision for Semi-Supervised Text Classification with a Reliable Teacher](https://doi.org/10.1145/3477495.3531887)|Shujie Li, Min Yang, Chengming Li, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Pseudo+Supervision+for+Semi-Supervised+Text+Classification+with+a+Reliable+Teacher)|0|
|[An Efficient Fusion Mechanism for Multimodal Low-resource Setting](https://doi.org/10.1145/3477495.3531900)|Dushyant Singh Chauhan, Asif Ekbal, Pushpak Bhattacharyya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Fusion+Mechanism+for+Multimodal+Low-resource+Setting)|0|
|[PST: Measuring Skill Proficiency in Programming Exercise Process via Programming Skill Tracing](https://doi.org/10.1145/3477495.3531903)|Ruixin Li, Yu Yin, Le Dai, Shuanghong Shen, Xin Lin, Yu Su, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PST:+Measuring+Skill+Proficiency+in+Programming+Exercise+Process+via+Programming+Skill+Tracing)|0|
|[MuchSUM: Multi-channel Graph Neural Network for Extractive Summarization](https://doi.org/10.1145/3477495.3531906)|Qianren Mao, Hongdong Zhu, Junnan Liu, Cheng Ji, Hao Peng, Jianxin Li, Lihong Wang, Zheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MuchSUM:+Multi-channel+Graph+Neural+Network+for+Extractive+Summarization)|0|
|[Multi-label Masked Language Modeling on Zero-shot Code-switched Sentiment Analysis](https://doi.org/10.1145/3477495.3531914)|Zhi Li, Xing Gao, Ji Zhang, Yin Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-label+Masked+Language+Modeling+on+Zero-shot+Code-switched+Sentiment+Analysis)|0|
|[Extractive Elementary Discourse Units for Improving Abstractive Summarization](https://doi.org/10.1145/3477495.3531916)|Ye Xiong, Teeradaj Racharak, Minh Le Nguyen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extractive+Elementary+Discourse+Units+for+Improving+Abstractive+Summarization)|0|
|[LightSGCN: Powering Signed Graph Convolution Network for Link Sign Prediction with Simplified Architecture Design](https://doi.org/10.1145/3477495.3531917)|Haoxin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LightSGCN:+Powering+Signed+Graph+Convolution+Network+for+Link+Sign+Prediction+with+Simplified+Architecture+Design)|0|
|[ir_metadata: An Extensible Metadata Schema for IR Experiments](https://doi.org/10.1145/3477495.3531738)|Timo Breuer, Jüri Keller, Philipp Schaer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ir_metadata:+An+Extensible+Metadata+Schema+for+IR+Experiments)|0|
|[CODEC: Complex Document and Entity Collection](https://doi.org/10.1145/3477495.3531712)|Iain Mackie, Paul Owoicho, Carlos Gemmell, Sophie Fischer, Sean MacAvaney, Jeffrey Dalton||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CODEC:+Complex+Document+and+Entity+Collection)|0|
|[Would You Ask it that Way?: Measuring and Improving Question Naturalness for Knowledge Graph Question Answering](https://doi.org/10.1145/3477495.3531739)|Trond Linjordet, Krisztian Balog||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Would+You+Ask+it+that+Way?:+Measuring+and+Improving+Question+Naturalness+for+Knowledge+Graph+Question+Answering)|0|
|[Biographical Semi-Supervised Relation Extraction Dataset](https://doi.org/10.1145/3477495.3531742)|Alistair Plum, Tharindu Ranasinghe, Spencer Jones, Constantin Orasan, Ruslan Mitkov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Biographical+Semi-Supervised+Relation+Extraction+Dataset)|0|
|[CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines](https://doi.org/10.1145/3477495.3531745)|Soham Poddar, Azlaan Mustafa Samad, Rajdeep Mukherjee, Niloy Ganguly, Saptarshi Ghosh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAVES:+A+Dataset+to+facilitate+Explainable+Classification+and+Summarization+of+Concerns+towards+COVID+Vaccines)|0|
|[SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated Counterfactuals](https://doi.org/10.1145/3477495.3531677)|Zijian Zhang, Vinay Setty, Avishek Anand||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SparCAssist:+A+Model+Risk+Assessment+Assistant+Based+on+Sparse+Generated+Counterfactuals)|0|
|[TARexp: A Python Framework for Technology-Assisted Review Experiments](https://doi.org/10.1145/3477495.3531663)|Eugene Yang, David D. Lewis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TARexp:+A+Python+Framework+for+Technology-Assisted+Review+Experiments)|0|
|[SpaceQA: Answering Questions about the Design of Space Missions and Space Craft Concepts](https://doi.org/10.1145/3477495.3531697)|Andrés GarcíaSilva, Cristian Berrio, José Manuél GómezPérez, José Antonio Martínez Heras, Alessandro Donati, Ilaria Roma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SpaceQA:+Answering+Questions+about+the+Design+of+Space+Missions+and+Space+Craft+Concepts)|0|
|[A Python Interface to PISA!](https://doi.org/10.1145/3477495.3531656)|Sean MacAvaney, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Python+Interface+to+PISA!)|0|
|[Organizing Portuguese Legal Documents through Topic Discovery](https://doi.org/10.1145/3477495.3536329)|Daniela Vianna, Edleno Silva de Moura||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Organizing+Portuguese+Legal+Documents+through+Topic+Discovery)|0|
|[A Low-Cost, Controllable and Interpretable Task-Oriented Chatbot: With Real-World After-Sale Services as Example](https://doi.org/10.1145/3477495.3536331)|Xiangyu Xi, Chenxu Lv, Yuncheng Hua, Wei Ye, Chaobo Sun, Shuaipeng Liu, Fan Yang, Guanglu Wan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Low-Cost,+Controllable+and+Interpretable+Task-Oriented+Chatbot:+With+Real-World+After-Sale+Services+as+Example)|0|
|[Beyond Opinion Mining: Summarizing Opinions of Customer Reviews](https://doi.org/10.1145/3477495.3532676)|Reinald Kim Amplayo, Arthur Brazinskas, Yoshi Suhara, Xiaolan Wang, Bing Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Opinion+Mining:+Summarizing+Opinions+of+Customer+Reviews)|0|
|[Fairness-Aware Question Answering for Intelligent Assistants](https://doi.org/10.1145/3477495.3531682)|Sachin Pathiyan Cherumanal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness-Aware+Question+Answering+for+Intelligent+Assistants)|0|
|[Continuous Result Delta Evaluation of IR Systems](https://doi.org/10.1145/3477495.3531686)|Gabriela González Sáez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continuous+Result+Delta+Evaluation+of+IR+Systems)|0|
