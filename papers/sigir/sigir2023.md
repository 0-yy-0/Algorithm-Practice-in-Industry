# SIGIR2023 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[A Symmetric Dual Encoding Dense Retrieval Framework for Knowledge-Intensive Visual Question Answering](https://doi.org/10.1145/3539618.3591629)|Alireza Salemi, Juan Altmayer Pizzorno, Hamed Zamani||Knowledge-Intensive Visual Question Answering (KI-VQA) refers to answering a question about an image whose answer does not lie in the image. This paper presents a new pipeline for KI-VQA tasks, consisting of a retriever and a reader. First, we introduce DEDR, a symmetric dual encoding dense retrieval framework in which documents and queries are encoded into a shared embedding space using uni-modal (textual) and multi-modal encoders. We introduce an iterative knowledge distillation approach that bridges the gap between the representation spaces in these two encoders. Extensive evaluation on two well-established KI-VQA datasets, i.e., OK-VQA and FVQA, suggests that DEDR outperforms state-of-the-art baselines by 11.6% and 30.9% on OK-VQA and FVQA, respectively. Utilizing the passages retrieved by DEDR, we further introduce MM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, for generating a textual answer for KI-VQA tasks. MM-FiD encodes the question, the image, and each retrieved passage separately and uses all passages jointly in its decoder. Compared to competitive baselines in the literature, this approach leads to 5.5% and 8.5% improvements in terms of question answering accuracy on OK-VQA and FVQA, respectively.|知识密集型视觉问题回答(KI-VQA)是指回答一个关于图像的问题，而这个问题的答案并不在图像中。本文提出了一种新的 KI-VQA 任务流水线，它由一个检索器和一个读取器组成。首先，我们介绍了 DEDR，一个对称的双重编码密集检索框架，其中文档和查询被编码到一个共享的嵌入空间使用单模态(文本)和多模态编码器。我们介绍了一种迭代的知识提取方法，它弥补了这两个编码器中表示空间之间的差距。对两个行之有效的 KI-VQA 数据集(即 OK-VQA 和 FVQA)的广泛评估表明，在 OK-VQA 和 FVQA 上，DEDR 的表现分别比最先进的基线水平高出11.6% 和30.9% 。利用 DEDR 检索到的段落，我们进一步介绍了 MM-FiD，一种编码器-解码器多模态融合-解码器模型，用于生成 KI-VQA 任务的文本答案。MM-FiD 分别对问题、图像和每个检索到的段落进行编码，并在其解码器中联合使用所有段落。与文献中的竞争性基线相比，这种方法在 OK-VQA 和 FVQA 上的问答准确率分别提高了5.5% 和8.5% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Symmetric+Dual+Encoding+Dense+Retrieval+Framework+for+Knowledge-Intensive+Visual+Question+Answering)|2|
|[Frequency Enhanced Hybrid Attention Network for Sequential Recommendation](https://doi.org/10.1145/3539618.3591689)|Xinyu Du, Huanhuan Yuan, Pengpeng Zhao, Jianfeng Qu, Fuzhen Zhuang, Guanfeng Liu, Yanchi Liu, Victor S. Sheng||The self-attention mechanism, which equips with a strong capability of modeling long-range dependencies, is one of the extensively used techniques in the sequential recommendation field. However, many recent studies represent that current self-attention based models are low-pass filters and are inadequate to capture high-frequency information. Furthermore, since the items in the user behaviors are intertwined with each other, these models are incomplete to distinguish the inherent periodicity obscured in the time domain. In this work, we shift the perspective to the frequency domain, and propose a novel Frequency Enhanced Hybrid Attention Network for Sequential Recommendation, namely FEARec. In this model, we firstly improve the original time domain self-attention in the frequency domain with a ramp structure to make both low-frequency and high-frequency information could be explicitly learned in our approach. Moreover, we additionally design a similar attention mechanism via auto-correlation in the frequency domain to capture the periodic characteristics and fuse the time and frequency level attention in a union model. Finally, both contrastive learning and frequency regularization are utilized to ensure that multiple views are aligned in both the time domain and frequency domain. Extensive experiments conducted on four widely used benchmark datasets demonstrate that the proposed model performs significantly better than the state-of-the-art approaches.|自注意机制具有很强的远程依赖建模能力，是顺序推荐领域中广泛应用的技术之一。然而，许多最近的研究表明，目前基于自我注意的模型是低通滤波器，不足以捕获高频信息。此外，由于用户行为中的项目相互交织在一起，这些模型不能完全区分隐藏在时域中的固有周期性。在这项工作中，我们将视角转移到频域，并提出了一种新的频率增强的混合注意网络的顺序推荐，即 FEARec。在这个模型中，我们首先在频率域改进了原有的时域自注意，使得低频和高频信息都可以在我们的方法中显式地学习。此外，我们还设计了一个类似的注意机制，通过在频域中的自相关来捕捉周期特性，并将时间和频率水平的注意融合到一个联合模型中。最后，利用对比学习和频率正则化技术保证了多视图在时域和频域的对齐。在四个广泛使用的基准数据集上进行的大量实验表明，所提出的模型的性能明显优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Frequency+Enhanced+Hybrid+Attention+Network+for+Sequential+Recommendation)|1|
|[Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation](https://doi.org/10.1145/3539618.3591755)|Yang Zhang, Tianhao Shi, Fuli Feng, Wenjie Wang, Dingxian Wang, Xiangnan He, Yongdong Zhang||Click-Through Rate (CTR) prediction plays a core role in recommender systems, serving as the final-stage filter to rank items for a user. The key to addressing the CTR task is learning feature interactions that are useful for prediction, which is typically achieved by fitting historical click data with the Empirical Risk Minimization (ERM) paradigm. Representative methods include Factorization Machines and Deep Interest Network, which have achieved wide success in industrial applications. However, such a manner inevitably learns unstable feature interactions, i.e., the ones that exhibit strong correlations in historical data but generalize poorly for future serving. In this work, we reformulate the CTR task -- instead of pursuing ERM on historical data, we split the historical data chronologically into several periods (a.k.a, environments), aiming to learn feature interactions that are stable across periods. Such feature interactions are supposed to generalize better to predict future behavior data. Nevertheless, a technical challenge is that existing invariant learning solutions like Invariant Risk Minimization are not applicable, since the click data entangles both environment-invariant and environment-specific correlations. To address this dilemma, we propose Disentangled Invariant Learning (DIL) which disentangles feature embeddings to capture the two types of correlations separately. To improve the modeling efficiency, we further design LightDIL which performs the disentanglement at the higher level of the feature field. Extensive experiments demonstrate the effectiveness of DIL in learning stable feature interactions for CTR. We release the code at https://github.com/zyang1580/DIL.|点进率(ctrl)预测在推荐系统中扮演着核心角色，充当为用户排序项目的最终过滤器。解决 CTR 任务的关键是学习对预测有用的特征交互，这通常是通过将历史点击数据与经验风险最小化(ERM)范式相匹配来实现的。代表性的方法包括因子分解机和深度兴趣网络，它们在工业应用中取得了广泛的成功。然而，这种方式不可避免地会学习到不稳定的特征交互，即在历史数据中表现出强相关性的特征交互，但对于未来服务的推广很差。在这项工作中，我们重新规划了 CTR 任务——而不是追求历史数据的 ERM，我们按时间顺序将历史数据分成几个时期(也就是环境) ，目的是学习跨时期稳定的特性交互。这样的特征交互被认为可以更好地推广以预测未来的行为数据。然而，一个技术挑战是，现有的不变学习解决方案，如不变风险最小化是不适用的，因为点击数据纠缠环境不变和环境特定的相关性。为了解决这一难题，我们提出了解除特征嵌入的不变学习(DIL)算法，分别捕获两种类型的相关性。为了提高建模效率，我们进一步设计了 LightDIL，它在特征字段的更高层次上执行分离。大量的实验证明了 DIL 在 CTR 中学习稳定特征交互的有效性。我们在 https://github.com/zyang1580/dil 公布密码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reformulating+CTR+Prediction:+Learning+Invariant+Feature+Interactions+for+Recommendation)|1|
|[How Well do Offline Metrics Predict Online Performance of Product Ranking Models?](https://doi.org/10.1145/3539618.3591865)|Xiaojie Wang, Ruoyuan Gao, Anoop Jain, Graham Edge, Sachin Ahuja||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Well+do+Offline+Metrics+Predict+Online+Performance+of+Product+Ranking+Models?)|1|
|[pybool_ir: A Toolkit for Domain-Specific Search Experiments](https://doi.org/10.1145/3539618.3591819)|Harrisen Scells, Martin Potthast||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=pybool_ir:+A+Toolkit+for+Domain-Specific+Search+Experiments)|1|
|[Lexically-Accelerated Dense Retrieval](https://doi.org/10.1145/3539618.3591715)|Hrishikesh Kulkarni, Sean MacAvaney, Nazli Goharian, Ophir Frieder||Retrieval approaches that score documents based on learned dense vectors (i.e., dense retrieval) rather than lexical signals (i.e., conventional retrieval) are increasingly popular. Their ability to identify related documents that do not necessarily contain the same terms as those appearing in the user's query (thereby improving recall) is one of their key advantages. However, to actually achieve these gains, dense retrieval approaches typically require an exhaustive search over the document collection, making them considerably more expensive at query-time than conventional lexical approaches. Several techniques aim to reduce this computational overhead by approximating the results of a full dense retriever. Although these approaches reasonably approximate the top results, they suffer in terms of recall -- one of the key advantages of dense retrieval. We introduce 'LADR' (Lexically-Accelerated Dense Retrieval), a simple-yet-effective approach that improves the efficiency of existing dense retrieval models without compromising on retrieval effectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval exploration that uses a document proximity graph. We explore two variants of LADR: a proactive approach that expands the search space to the neighbors of all seed documents, and an adaptive approach that selectively searches the documents with the highest estimated relevance in an iterative fashion. Through extensive experiments across a variety of dense retrieval models, we find that LADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier among approximate k nearest neighbor techniques. Further, we find that when tuned to take around 8ms per query in retrieval latency on our hardware, LADR consistently achieves both precision and recall that are on par with an exhaustive search on standard benchmarks.|基于学习密集向量(即密集检索)而非词汇信号(即常规检索)对文档进行评分的检索方法越来越流行。它们能够识别出与用户查询中出现的不一定包含相同术语的相关文档(从而提高召回率) ，这是它们的主要优势之一。然而，为了实际获得这些收益，密集检索方法通常需要对文档集进行彻底搜索，这使得它们在查询时比传统的词法方法昂贵得多。一些技术旨在通过近似一个完全密集的检索器的结果来减少这种计算开销。尽管这些方法可以合理地接近最高的结果，但它们在回忆方面受到影响——这是密集检索的关键优势之一。我们介绍了“ LADR”(词汇加速密集检索) ，一个简单而有效的方法，提高了现有的密集检索模型的效率，而不影响检索的有效性。LADR 使用词汇检索技术来引导使用文档接近图的密集检索探索。我们探索了 LADR 的两种变体: 一种积极主动的方法，将搜索空间扩展到所有种子文档的邻居，以及一种自适应的方法，以迭代的方式选择性地搜索具有最高估计相关性的文档。通过对各种密集检索模型的大量实验，我们发现 LADR 在近似 k 最近邻技术中建立了一种新的密集检索有效性——帕累托前沿。此外，我们发现，当硬件上的检索延迟调整到每个查询大约需要8毫秒时，LADR 始终如一地实现了这两个准确率召回率，与标准基准的详尽搜索相当。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lexically-Accelerated+Dense+Retrieval)|1|
|[Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization](https://doi.org/10.1145/3539618.3591760)|Shashank Gupta, Harrie Oosterhuis, Maarten de Rijke||Counterfactual learning to rank (CLTR) relies on exposure-based inverse propensity scoring (IPS), a LTR-specific adaptation of IPS to correct for position bias. While IPS can provide unbiased and consistent estimates, it often suffers from high variance. Especially when little click data is available, this variance can cause CLTR to learn sub-optimal ranking behavior. Consequently, existing CLTR methods bring significant risks with them, as naively deploying their models can result in very negative user experiences. We introduce a novel risk-aware CLTR method with theoretical guarantees for safe deployment. We apply a novel exposure-based concept of risk regularization to IPS estimation for LTR. Our risk regularization penalizes the mismatch between the ranking behavior of a learned model and a given safe model. Thereby, it ensures that learned ranking models stay close to a trusted model, when there is high uncertainty in IPS estimation, which greatly reduces the risks during deployment. Our experimental results demonstrate the efficacy of our proposed method, which is effective at avoiding initial periods of bad performance when little data is available, while also maintaining high performance at convergence. For the CLTR field, our novel exposure-based risk minimization method enables practitioners to adopt CLTR methods in a safer manner that mitigates many of the risks attached to previous methods.|反事实学习排名(CLTR)依赖于基于暴露的逆倾向评分(IPS) ，IPS 的一种 LTR 特异性适应，以纠正位置偏差。虽然 IPS 可以提供无偏和一致的估计，但它经常受到高方差的影响。特别是当很少的点击数据可用时，这种方差会导致 CLTR 学习次优排序行为。因此，现有的 CLTR 方法带来了巨大的风险，因为天真地部署它们的模型可能会导致非常负面的用户体验。我们介绍了一种新的风险意识的 CLTR 方法与安全部署的理论保证。我们将一种新的基于暴露的风险正则化概念应用于长期寿命周期的 IPS 估计。我们的风险正则化惩罚了学习模型的排序行为和给定的安全模型之间的不匹配。因此，当 IPS 估计存在较高的不确定性时，学习的排序模型能够保持接近可信模型，从而大大降低了部署过程中的风险。实验结果证明了该方法的有效性，该方法在保证收敛性能的同时，能有效地避免初始阶段性能不佳的情况。对于 CLTR 领域，我们新颖的基于暴露的风险最小化方法使从业者能够以更安全的方式采用 CLTR 方法，从而减轻了许多与以前的方法相关的风险。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Safe+Deployment+for+Counterfactual+Learning+to+Rank+with+Exposure-Based+Risk+Minimization)|1|
|[Disentangled Contrastive Collaborative Filtering](https://doi.org/10.1145/3539618.3591665)|Xubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, Chao Huang||Recent studies show that graph neural networks (GNNs) are prevalent to model high-order relationships for collaborative filtering (CF). Towards this research line, graph contrastive learning (GCL) has exhibited powerful performance in addressing the supervision label shortage issue by learning augmented user and item representations. While many of them show their effectiveness, two key questions still remain unexplored: i) Most existing GCL-based CF models are still limited by ignoring the fact that user-item interaction behaviors are often driven by diverse latent intent factors (e.g., shopping for family party, preferred color or brand of products); ii) Their introduced non-adaptive augmentation techniques are vulnerable to noisy information, which raises concerns about the model's robustness and the risk of incorporating misleading self-supervised signals. In light of these limitations, we propose a Disentangled Contrastive Collaborative Filtering framework (DCCF) to realize intent disentanglement with self-supervised augmentation in an adaptive fashion. With the learned disentangled representations with global context, our DCCF is able to not only distill finer-grained latent factors from the entangled self-supervision signals but also alleviate the augmentation-induced noise. Finally, the cross-view contrastive learning task is introduced to enable adaptive augmentation with our parameterized interaction mask generator. Experiments on various public datasets demonstrate the superiority of our method compared to existing solutions. Our model implementation is released at the link https://github.com/HKUDS/DCCF.|最近的研究表明，图形神经网络(GNN)普遍用于模拟协同过滤(CF)的高阶关系。针对这一研究方向，图形对比学习(GCL)通过学习增强用户和项目表示，在解决监督标签短缺问题方面表现出强大的性能。虽然其中许多显示了它们的有效性，但有两个关键问题仍然没有得到探索: i)大多数现有的基于 GCL 的 CF 模型仍然受到限制，因为忽略了用户项目交互行为通常由不同的潜在意图因素驱动(例如，为家庭聚会，首选颜色或产品品牌) ; ii)它们引入的非自适应增强技术易受噪声信息的影响，这引起了对模型的稳健性和纳入误导性自我监督信号的风险的担忧。鉴于这些局限性，我们提出了一个自适应增强的协同过滤对比度分离框架(dCCF)来实现意图分离。利用学习的全局解纠缠表示，我们的 DCCF 不仅能够从纠缠的自我监督信号中提取出更细粒度的潜在因子，而且能够减轻增强引起的噪声。最后，引入横向视图对比学习任务，利用参数化交互掩模生成器实现自适应增强。在各种公共数据集上的实验表明了该方法相对于现有解的优越性。我们的模型实现在链接 https://github.com/hkuds/dccf 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Contrastive+Collaborative+Filtering)|1|
|[A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning](https://doi.org/10.1145/3539618.3591631)|Jiangui Chen, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yiqun Liu, Yixing Fan, Xueqi Cheng||Knowledge-intensive language tasks (KILTs) benefit from retrieving high-quality relevant contexts from large external knowledge corpora. Learning task-specific retrievers that return relevant contexts at an appropriate level of semantic granularity, such as a document retriever, passage retriever, sentence retriever, and entity retriever, may help to achieve better performance on the end-to-end task. But a task-specific retriever usually has poor generalization ability to new domains and tasks, and it may be costly to deploy a variety of specialised retrievers in practice. We propose a unified generative retriever (UGR) that combines task-specific effectiveness with robust performance over different retrieval tasks in KILTs. To achieve this goal, we make two major contributions: (i) To unify different retrieval tasks into a single generative form, we introduce an n-gram-based identifier for relevant contexts at different levels of granularity in KILTs. And (ii) to address different retrieval tasks with a single model, we employ a prompt learning strategy and investigate three methods to design prompt tokens for each task. In this way, the proposed UGR model can not only share common knowledge across tasks for better generalization, but also perform different retrieval tasks effectively by distinguishing task-specific characteristics. We train UGR on a heterogeneous set of retrieval corpora with well-designed prompts in a supervised and multi-task fashion. Experimental results on the KILT benchmark demonstrate the effectiveness of UGR on in-domain datasets, out-of-domain datasets, and unseen tasks.|知识密集型语言任务(KILT)受益于从大型外部知识库中检索高质量的相关上下文。学习以适当的语义粒度返回相关上下文的特定任务检索器，如文档检索器、文章检索器、句子检索器和实体检索器，可能有助于在端到端任务中获得更好的性能。但是特定于任务的检索器通常对新领域和任务的泛化能力较差，而且在实践中部署各种专门的检索器可能成本较高。我们提出了一个统一的生成检索器(UGR) ，它结合了任务特定的有效性和鲁棒性能对不同的检索任务在 KILT。为了实现这一目标，我们做出了两个主要贡献: (i)为了将不同的检索任务统一到一个单一的生成形式，我们在 KILT 中引入了一个基于 n-gram 的标识符来标识不同粒度级别的相关上下文。为了解决不同的检索任务，我们采用了快速学习策略，并研究了三种方法为每个任务设计快速令牌。这样，该模型不仅可以实现任务之间的共同知识共享以便更好地泛化，而且可以通过区分任务特定的特征来有效地执行不同的检索任务。我们在一个异构的检索语料集上训练 UGR，这些检索语料集以监督和多任务的方式使用精心设计的提示。在 KILT 基准上的实验结果证明了 UGR 在域内数据集、域外数据集和未知任务上的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Unified+Generative+Retriever+for+Knowledge-Intensive+Language+Tasks+via+Prompt+Learning)|1|
|[ADL: Adaptive Distribution Learning Framework for Multi-Scenario CTR Prediction](https://doi.org/10.1145/3539618.3591944)|Jinyun Li, Huiwen Zheng, Yuanlin Liu, Minfang Lu, Lixia Wu, Haoyuan Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ADL:+Adaptive+Distribution+Learning+Framework+for+Multi-Scenario+CTR+Prediction)|1|
|[FINAL: Factorized Interaction Layer for CTR Prediction](https://doi.org/10.1145/3539618.3591988)|Jieming Zhu, Qinglin Jia, Guohao Cai, Quanyu Dai, Jingjie Li, Zhenhua Dong, Ruiming Tang, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FINAL:+Factorized+Interaction+Layer+for+CTR+Prediction)|1|
|[The Dark Side of Explanations: Poisoning Recommender Systems with Counterfactual Examples](https://doi.org/10.1145/3539618.3592070)|Ziheng Chen, Fabrizio Silvestri, Jia Wang, Yongfeng Zhang, Gabriele Tolomei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Dark+Side+of+Explanations:+Poisoning+Recommender+Systems+with+Counterfactual+Examples)|1|
|[Weakly-Supervised Scientific Document Classification via Retrieval-Augmented Multi-Stage Training](https://doi.org/10.1145/3539618.3592085)|Ran Xu, Yue Yu, Joyce C. Ho, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weakly-Supervised+Scientific+Document+Classification+via+Retrieval-Augmented+Multi-Stage+Training)|1|
|[Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce](https://doi.org/10.1145/3539618.3591963)|Yibo Wang, Yanbing Xue, Bo Liu, Musen Wen, Wenting Zhao, Stephen Guo, Philip S. Yu||Position bias, the phenomenon whereby users tend to focus on higher-ranked items of the search result list regardless of the actual relevance to queries, is prevailing in many ranking systems. Position bias in training data biases the ranking model, leading to increasingly unfair item rankings, click-through-rate (CTR), and conversion rate (CVR) predictions. To jointly mitigate position bias in both item CTR and CVR prediction, we propose two position-bias-free CTR and CVR prediction models: Position-Aware Click-Conversion (PACC) and PACC via Position Embedding (PACC-PE). PACC is built upon probability decomposition and models position information as a probability. PACC-PE utilizes neural networks to model product-specific position information as embedding. Experiments on the E-commerce sponsored product search dataset show that our proposed models have better ranking effectiveness and can greatly alleviate position bias in both CTR and CVR prediction.|排名偏差是指用户倾向于关注搜索结果列表中排名较高的项目，而不考虑与查询的实际相关性，这种现象在许多排名系统中普遍存在。训练数据中的位置偏差使排名模型产生偏差，导致项目排名、点击率(CTR)和转换率(CVR)预测日益不公平。为了共同减轻项目 CTR 和 CVR 预测中的位置偏差，我们提出了两种无位置偏差的 CTR 和 CVR 预测模型: 位置感知点击转换(PACC)和通过位置嵌入(PACC-PE)的 PACC。PACC 是建立在概率分解和模型位置信息作为一个概率。PACC-PE 利用神经网络将特定产品的位置信息作为嵌入信息进行建模。对电子商务赞助商产品搜索数据集的实验结果表明，该模型具有较好的排序效果，可以大大减轻 CTR 和 CVR 预测中的位置偏差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Click-Conversion+Multi-Task+Model+with+Position+Bias+Mitigation+for+Sponsored+Search+in+eCommerce)|0|
|[Beyond Two-Tower Matching: Learning Sparse Retrievable Cross-Interactions for Recommendation](https://doi.org/10.1145/3539618.3591643)|Liangcai Su, Fan Yan, Jieming Zhu, Xi Xiao, Haoyi Duan, Zhou Zhao, Zhenhua Dong, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Two-Tower+Matching:+Learning+Sparse+Retrievable+Cross-Interactions+for+Recommendation)|0|
|[News Popularity Beyond the Click-Through-Rate for Personalized Recommendations](https://doi.org/10.1145/3539618.3591741)|Ashutosh Nayak, Mayur Garg, Rajasekhara Reddy Duvvuru Muni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=News+Popularity+Beyond+the+Click-Through-Rate+for+Personalized+Recommendations)|0|
|[Learning Query-aware Embedding Index for Improving E-commerce Dense Retrieval](https://doi.org/10.1145/3539618.3591834)|Mingming Li, Chunyuan Yuan, Binbin Wang, Jingwei Zhuo, Songlin Wang, Lin Liu, Sulong Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Query-aware+Embedding+Index+for+Improving+E-commerce+Dense+Retrieval)|0|
|[Exploiting Simulated User Feedback for Conversational Search: Ranking, Rewriting, and Beyond](https://doi.org/10.1145/3539618.3591683)|Paul Owoicho, Ivan Sekulic, Mohammad Aliannejadi, Jeffrey Dalton, Fabio Crestani||This research aims to explore various methods for assessing user feedback in mixed-initiative conversational search (CS) systems. While CS systems enjoy profuse advancements across multiple aspects, recent research fails to successfully incorporate feedback from the users. One of the main reasons for that is the lack of system-user conversational interaction data. To this end, we propose a user simulator-based framework for multi-turn interactions with a variety of mixed-initiative CS systems. Specifically, we develop a user simulator, dubbed ConvSim, that, once initialized with an information need description, is capable of providing feedback to a system's responses, as well as answering potential clarifying questions. Our experiments on a wide variety of state-of-the-art passage retrieval and neural re-ranking models show that effective utilization of user feedback can lead to 16% retrieval performance increase in terms of nDCG@3. Moreover, we observe consistent improvements as the number of feedback rounds increases (35% relative improvement in terms of nDCG@3 after three rounds). This points to a research gap in the development of specific feedback processing modules and opens a potential for significant advancements in CS. To support further research in the topic, we release over 30,000 transcripts of system-simulator interactions based on well-established CS datasets.|本研究旨在探讨混合主动式会话搜寻系统中评估使用者反馈的各种方法。虽然 CS 系统在多个方面取得了长足的进步，但最近的研究未能成功地整合来自用户的反馈。其中一个主要原因是缺乏系统-用户交互数据。为此，我们提出了一个基于用户模拟器的框架，用于多个混合主动 CS 系统的多回合交互。具体来说，我们开发了一个用户模拟器，称为 ConvSim，一旦用信息需求描述初始化，就能够为系统的响应提供反馈，并回答潜在的澄清问题。我们在各种最先进的文章检索和神经元重排序模型上的实验表明，有效利用用户反馈可以提高16% 的检索性能。此外，我们观察到随着反馈回合数量的增加，一致的改善(三个回合后 nDCG@3的相对改善率为35%)。这指出了在开发特定的反馈处理模块方面的研究差距，并为 CS 的重大进展开辟了潜力。为了支持本课题的进一步研究，我们发布了超过30,000份基于已建立的 CS 数据集的系统-模拟器交互的文本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Simulated+User+Feedback+for+Conversational+Search:+Ranking,+Rewriting,+and+Beyond)|0|
|[Modeling Orders of User Behaviors via Differentiable Sorting: A Multi-task Framework to Predicting User Post-click Conversion](https://doi.org/10.1145/3539618.3592023)|Menghan Wang, Jinming Yang, Yuchen Guo, Yuming Shen, Mengying Zhu, Yanlin Wang||User post-click conversion prediction is of high interest to researchers and developers. Recent studies employ multi-task learning to tackle the selection bias and data sparsity problem, two severe challenges in post-click behavior prediction, by incorporating click data. However, prior works mainly focused on pointwise learning and the orders of labels (i.e., click and post-click) are not well explored, which naturally poses a listwise learning problem. Inspired by recent advances on differentiable sorting, in this paper, we propose a novel multi-task framework that leverages orders of user behaviors to predict user post-click conversion in an end-to-end approach. Specifically, we define an aggregation operator to combine predicted outputs of different tasks to a unified score, then we use the computed scores to model the label relations via differentiable sorting. Extensive experiments on public and industrial datasets show the superiority of our proposed model against competitive baselines.|用户点击后的转换预测是研究人员和开发人员非常感兴趣的。最近的研究采用多任务学习来解决选择偏差和数据稀疏问题，这两个严峻的挑战后点击行为预测，通过整合点击数据。然而，以前的作品主要集中在点式学习和标签的顺序(即，点击和后点击)没有很好的探索，这自然造成了一个列表式学习问题。受可微分排序技术最新进展的启发，本文提出了一种新的多任务框架，该框架利用用户行为的顺序来预测端到端的用户点击后转换。具体来说，我们定义了一个聚合算子，将不同任务的预测输出结合成一个统一的得分，然后使用计算出的得分通过可微排序来建模标签关系。在公共和工业数据集上的大量实验表明了我们提出的模型对竞争基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Orders+of+User+Behaviors+via+Differentiable+Sorting:+A+Multi-task+Framework+to+Predicting+User+Post-click+Conversion)|0|
|[Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce Search](https://doi.org/10.1145/3539618.3591863)|Zhigong Zhou, Ning Ding, Xiaochuan Fan, Yue Shang, Yiming Qiu, Jingwei Zhuo, Zhiwei Ge, Songlin Wang, Lin Liu, Sulong Xu, Han Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic-enhanced+Modality-asymmetric+Retrieval+for+Online+E-commerce+Search)|0|
|[Intent-aware Ranking Ensemble for Personalized Recommendation](https://doi.org/10.1145/3539618.3591702)|Jiayu Li, Peijie Sun, Zhefan Wang, Weizhi Ma, Yangkun Li, Min Zhang, Zhoutian Feng, Daiyue Xue||Ranking ensemble is a critical component in real recommender systems. When a user visits a platform, the system will prepare several item lists, each of which is generally from a single behavior objective recommendation model. As multiple behavior intents, e.g., both clicking and buying some specific item category, are commonly concurrent in a user visit, it is necessary to integrate multiple single-objective ranking lists into one. However, previous work on rank aggregation mainly focused on fusing homogeneous item lists with the same objective while ignoring ensemble of heterogeneous lists ranked with different objectives with various user intents.   In this paper, we treat a user's possible behaviors and the potential interacting item categories as the user's intent. And we aim to study how to fuse candidate item lists generated from different objectives aware of user intents. To address such a task, we propose an Intent-aware ranking Ensemble Learning~(IntEL) model to fuse multiple single-objective item lists with various user intents, in which item-level personalized weights are learned. Furthermore, we theoretically prove the effectiveness of IntEL with point-wise, pair-wise, and list-wise loss functions via error-ambiguity decomposition. Experiments on two large-scale real-world datasets also show significant improvements of IntEL on multiple behavior objectives simultaneously compared to previous ranking ensemble models.|等级集成是实际推荐系统中的一个重要组成部分。当用户访问一个平台时，系统将准备几个项目列表，每个项目列表通常来自一个行为客观推荐模型。由于多种行为意图，例如点击和购买某个特定的商品类别，在用户访问中通常是并发的，因此有必要将多个单目标排名列表集成到一个列表中。然而，以往的排名聚合研究主要集中在同一目标下的同类项目列表的融合，而忽略了不同目标下不同用户意图的异类项目列表的集合。在本文中，我们将用户的可能行为和潜在的交互项目类别视为用户的意图。研究了如何根据用户意图对不同目标生成的候选项目表进行融合。为了解决这个问题，我们提出了一个意图感知排名集成学习模型(IntEL) ，该模型将多个单目标项目列表与不同的用户意图相融合，其中项目级别的个性化权重被学习。此外，我们还通过误差模糊度分解从理论上证明了对点损耗、对损耗和列表损耗函数的有效性。在两个大规模真实世界数据集上的实验也表明，与以前的排序集合模型相比，IntEL 在同时处理多个行为目标上也有显著的改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intent-aware+Ranking+Ensemble+for+Personalized+Recommendation)|0|
|[A Model-Agnostic Popularity Debias Training Framework for Click-Through Rate Prediction in Recommender System](https://doi.org/10.1145/3539618.3591939)|Fan Zhang, Qijie Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Model-Agnostic+Popularity+Debias+Training+Framework+for+Click-Through+Rate+Prediction+in+Recommender+System)|0|
|[U-NEED: A Fine-grained Dataset for User Needs-Centric E-commerce Conversational Recommendation](https://doi.org/10.1145/3539618.3591878)|Yuanxing Liu, Weinan Zhang, Baohua Dong, Yan Fan, Hang Wang, Fan Feng, Yifan Chen, Ziyu Zhuang, Hengbin Cui, Yongbin Li, Wanxiang Che||Conversational recommender systems (CRSs) aim to understand the information needs and preferences expressed in a dialogue to recommend suitable items to the user. Most of the existing conversational recommendation datasets are synthesized or simulated with crowdsourcing, which has a large gap with real-world scenarios. To bridge the gap, previous work contributes a dataset E-ConvRec, based on pre-sales dialogues between users and customer service staff in E-commerce scenarios. However, E-ConvRec only supplies coarse-grained annotations and general tasks for making recommendations in pre-sales dialogues. Different from that, we use real user needs as a clue to explore the E-commerce conversational recommendation in complex pre-sales dialogues, namely user needs-centric E-commerce conversational recommendation (UNECR).   In this paper, we construct a user needs-centric E-commerce conversational recommendation dataset (U-NEED) from real-world E-commerce scenarios. U-NEED consists of 3 types of resources: (i) 7,698 fine-grained annotated pre-sales dialogues in 5 top categories (ii) 333,879 user behaviors and (iii) 332,148 product knowledge tuples. To facilitate the research of UNECR, we propose 5 critical tasks: (i) pre-sales dialogue understanding (ii) user needs elicitation (iii) user needs-based recommendation (iv) pre-sales dialogue generation and (v) pre-sales dialogue evaluation. We establish baseline methods and evaluation metrics for each task. We report experimental results of 5 tasks on U-NEED. We also report results in 3 typical categories. Experimental results indicate that the challenges of UNECR in various categories are different.|会话推荐系统(CRS)旨在理解对话中表达的信息需求和偏好，从而向用户推荐合适的项目。现有的会话推荐数据集大多是通过众包合成或模拟的，与现实情景有很大的差距。为了弥补这一差距，以前的工作提供了一个数据集 E-ConvRec，该数据集基于电子商务场景中用户和客户服务人员之间的售前对话。然而，E-ConvRec 只提供粗粒度的注释和一般性任务，用于在售前对话中提出建议。与此不同的是，我们以用户真实需求为线索，探索复杂的售前对话中的电子商务会话推荐，即以用户需求为中心的电子商务会话推荐。本文从现实电子商务场景出发，构建了一个以用户需求为中心的电子商务会话推荐数据集(U-Need)。U-Need 由3种类型的资源组成: (i)在5个顶级类别中的7,698个细粒度注释的售前对话(ii)333,879个用户行为和(iii)332,148个产品知识元组。为了促进 UNECR 的研究，我们提出了5个关键任务: (i)售前对话理解(ii)用户需求启发(iii)基于用户需求的推荐(iv)售前对话生成和(v)售前对话评估。我们为每个任务建立基线方法和评估指标。我们报告了5个任务的实验结果。我们还报告了3个典型类别的结果。实验结果表明，联合国难民事务高级专员办事处在不同类别中面临的挑战是不同的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=U-NEED:+A+Fine-grained+Dataset+for+User+Needs-Centric+E-commerce+Conversational+Recommendation)|0|
|[Continuous Input Embedding Size Search For Recommender Systems](https://doi.org/10.1145/3539618.3591653)|Yunke Qu, Tong Chen, Xiangyu Zhao, Lizhen Cui, Kai Zheng, Hongzhi Yin||Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a given memory budget. In this paper, we propose continuous input embedding size search (CIESS), a novel RL-based method that operates on a continuous search space with arbitrary embedding sizes to choose from. In CIESS, we further present an innovative random walk-based exploration strategy to allow the RL policy to efficiently explore more candidate embedding sizes and converge to a better decision. CIESS is also model-agnostic and hence generalizable to a variety of latent factor RSs, whilst experiments on two real-world datasets have shown state-of-the-art performance of CIESS under different memory budgets when paired with three popular recommendation models.|潜在因素模型是当今推荐系统最受欢迎的骨干，因为它们具有突出的性能。潜在因素模型将用户和项目表示为实值嵌入向量进行两两相似性计算，所有的嵌入传统上都限制在一个相对较大的统一大小(例如，256维)。随着当代电子商务中用户数量和商品目录的指数级增长，这种设计无可否认地变得内存效率低下。为了方便轻量级推荐，强化学习(RL)最近为不同用户/项目提供了识别不同嵌入大小的机会。然而，由于受到搜索效率和学习最优 RL 策略的挑战，现有的基于 RL 的方法仅限于高度离散的、预定义的嵌入大小选择。这导致在给定的内存预算下，为了获得更好的推荐效果，在嵌入大小中引入更细粒度的可能性被很大程度上忽略了。本文提出了连续输入嵌入大小搜索(CIESS) ，这是一种新的基于 RL 的方法，可以在任意嵌入大小的连续搜索空间上进行选择。在 CIESS，我们进一步提出了一个创新的基于随机漫步的探索策略，使 RL 策略能够有效地探索更多的候选嵌入规模，并收敛到一个更好的决策。CIESS 也是模型无关的，因此可以推广到各种潜在因素 RS，而在两个真实世界数据集上的实验显示，当与三种流行的推荐模型配对时，CIESS 在不同内存预算下的最先进性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continuous+Input+Embedding+Size+Search+For+Recommender+Systems)|0|
|[A Geometric Framework for Query Performance Prediction in Conversational Search](https://doi.org/10.1145/3539618.3591625)|Guglielmo Faggioli, Nicola Ferro, Cristina Ioana Muntean, Raffaele Perego, Nicola Tonellotto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Geometric+Framework+for+Query+Performance+Prediction+in+Conversational+Search)|0|
|[Neighborhood-based Hard Negative Mining for Sequential Recommendation](https://doi.org/10.1145/3539618.3591995)|Lu Fan, Jiashu Pu, Rongsheng Zhang, XiaoMing Wu||Negative sampling plays a crucial role in training successful sequential recommendation models. Instead of merely employing random negative sample selection, numerous strategies have been proposed to mine informative negative samples to enhance training and performance. However, few of these approaches utilize structural information. In this work, we observe that as training progresses, the distributions of node-pair similarities in different groups with varying degrees of neighborhood overlap change significantly, suggesting that item pairs in distinct groups may possess different negative relationships. Motivated by this observation, we propose a Graph-based Negative sampling approach based on Neighborhood Overlap (GNNO) to exploit structural information hidden in user behaviors for negative mining. GNNO first constructs a global weighted item transition graph using training sequences. Subsequently, it mines hard negative samples based on the degree of overlap with the target item on the graph. Furthermore, GNNO employs curriculum learning to control the hardness of negative samples, progressing from easy to difficult. Extensive experiments on three Amazon benchmarks demonstrate GNNO's effectiveness in consistently enhancing the performance of various state-of-the-art models and surpassing existing negative sampling strategies. The code will be released at \url{https://github.com/floatSDSDS/GNNO}.|负抽样对顺序推荐模型的建立起着至关重要的作用。为了提高训练效果，人们提出了许多挖掘负样本信息的策略，而不仅仅是采用随机的负样本选择。然而，这些方法很少利用结构信息。本研究发现，随着训练的进行，邻域重叠程度不同的不同群体中节点对相似性的分布发生了显著的变化，提示不同群体中的项目对可能具有不同的负相关关系。在此基础上，本文提出了一种基于邻域重叠(GNNO)的负向采样方法，利用用户行为中隐藏的结构信息进行负向挖掘。GNNO 首先使用训练序列构造一个全局加权项目转移图。然后，根据图上目标项的重叠程度挖掘硬负样本。此外，GNNO 使用课程学习来控制负面样本的硬度，从容易进展到难。在三个 Amazon 基准上的大量实验证明了 GNNO 在持续提高各种最先进模型的性能和超越现有的负采样策略方面的有效性。代码将在 url { https://github.com/floatsdsds/gnno }发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighborhood-based+Hard+Negative+Mining+for+Sequential+Recommendation)|0|
|[Query Performance Prediction: From Ad-hoc to Conversational Search](https://doi.org/10.1145/3539618.3591919)|Chuan Meng, Negar Arabzadeh, Mohammad Aliannejadi, Maarten de Rijke||Query performance prediction (QPP) is a core task in information retrieval. The QPP task is to predict the retrieval quality of a search system for a query without relevance judgments. Research has shown the effectiveness and usefulness of QPP for ad-hoc search. Recent years have witnessed considerable progress in conversational search (CS). Effective QPP could help a CS system to decide an appropriate action to be taken at the next turn. Despite its potential, QPP for CS has been little studied. We address this research gap by reproducing and studying the effectiveness of existing QPP methods in the context of CS. While the task of passage retrieval remains the same in the two settings, a user query in CS depends on the conversational history, introducing novel QPP challenges. In particular, we seek to explore to what extent findings from QPP methods for ad-hoc search generalize to three CS settings: (i) estimating the retrieval quality of different query rewriting-based retrieval methods, (ii) estimating the retrieval quality of a conversational dense retrieval method, and (iii) estimating the retrieval quality for top ranks vs. deeper-ranked lists. Our findings can be summarized as follows: (i) supervised QPP methods distinctly outperform unsupervised counterparts only when a large-scale training set is available; (ii) point-wise supervised QPP methods outperform their list-wise counterparts in most cases; and (iii) retrieval score-based unsupervised QPP methods show high effectiveness in assessing the conversational dense retrieval method, ConvDR.|查询性能预测是信息检索的核心任务。QPP 任务是在没有相关性判断的情况下预测查询搜索系统的检索质量。研究表明 QPP 在自组织搜索中的有效性和实用性。近年来，会话搜索取得了长足的进步。有效的质量保证计划可以帮助 CS 系统决定下一轮要采取的适当行动。尽管 QPP 具有很大的潜力，但是对它的研究还很少。我们通过再现和研究现有的 QPP 方法在 CS 背景下的有效性来弥补这一研究差距。虽然在这两种情况下，文章检索的任务是相同的，但用户在 CS 中的查询依赖于会话历史，引入了新的 QPP 挑战。特别是，我们试图探索用于特别搜索的 QPP 方法的结果在多大程度上概括为三种 CS 设置: (i)估计不同基于查询重写的检索方法的检索质量，(ii)估计会话密集检索方法的检索质量，以及(iii)估计顶级与更深级列表的检索质量。我们的研究结果可以总结如下: (i)监督 QPP 方法只有在大规模训练集可用时才明显优于无监督的对应方法; (ii)点式监督 QPP 方法在大多数情况下优于其列表式对应方法; 和(iii)基于检索评分的无监督 QPP 方法在评估会话密集检索方法，ConvDR 方面显示出高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query+Performance+Prediction:+From+Ad-hoc+to+Conversational+Search)|0|
|[Integrity and Junkiness Failure Handling for Embedding-based Retrieval: A Case Study in Social Network Search](https://doi.org/10.1145/3539618.3591831)|Wenping Wang, Yunxi Guo, Chiyao Shen, Shuai Ding, Guangdeng Liao, Hao Fu, Pramodh Karanth Prabhakar||Embedding based retrieval has seen its usage in a variety of search applications like e-commerce, social networking search etc. While the approach has demonstrated its efficacy in tasks like semantic matching and contextual search, it is plagued by the problem of uncontrollable relevance. In this paper, we conduct an analysis of embedding-based retrieval launched in early 2021 on our social network search engine, and define two main categories of failures introduced by it, integrity and junkiness. The former refers to issues such as hate speech and offensive content that can severely harm user experience, while the latter includes irrelevant results like fuzzy text matching or language mismatches. Efficient methods during model inference are further proposed to resolve the issue, including indexing treatments and targeted user cohort treatments, etc. Though being simple, we show the methods have good offline NDCG and online A/B tests metrics gain in practice. We analyze the reasons for the improvements, pointing out that our methods are only preliminary attempts to this important but challenging problem. We put forward potential future directions to explore.|嵌入式检索在电子商务、社交网络搜索等多种搜索应用中得到了广泛的应用。虽然该方法在语义匹配和上下文搜索等任务中表现出了很好的效果，但是相关性不可控的问题仍然困扰着该方法。本文对2021年初在我国社交网络搜索引擎上推出的嵌入式检索进行了分析，并定义了嵌入式检索引入的两类主要失败: 完整性和垃圾性。前者指的是可能严重损害用户体验的仇恨言论和冒犯性内容等问题，而后者包括模糊文本匹配或语言不匹配等不相关的结果。进一步提出了有效的模型推理方法，包括索引处理和目标用户队列处理等。实践表明，该方法简单易行，具有良好的离线 NDCG 和在线 A/B 测试指标收益。我们分析了改进的原因，指出我们的方法只是对这个重要但具有挑战性的问题的初步尝试。我们提出了潜在的未来发展方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrity+and+Junkiness+Failure+Handling+for+Embedding-based+Retrieval:+A+Case+Study+in+Social+Network+Search)|0|
|[Embedding Based Retrieval in Friend Recommendation](https://doi.org/10.1145/3539618.3591848)|Jiahui Shi, Vivek Chaurasiya, Yozen Liu, Shubham Vij, Yan Wu, Satya Kanduri, Neil Shah, Peicheng Yu, Nik Srivastava, Lei Shi, Ganesh Venkataraman, Jun Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+Based+Retrieval+in+Friend+Recommendation)|0|
|[Exploring User and Item Representation, Justification Generation, and Data Augmentation for Conversational Recommender Systems](https://doi.org/10.1145/3539618.3591795)|Sergey Volokhin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+User+and+Item+Representation,+Justification+Generation,+and+Data+Augmentation+for+Conversational+Recommender+Systems)|0|
|[MELT: Mutual Enhancement of Long-Tailed User and Item for Sequential Recommendation](https://doi.org/10.1145/3539618.3591725)|Kibum Kim, Dongmin Hyun, Sukwon Yun, Chanyoung Park||The long-tailed problem is a long-standing challenge in Sequential Recommender Systems (SRS) in which the problem exists in terms of both users and items. While many existing studies address the long-tailed problem in SRS, they only focus on either the user or item perspective. However, we discover that the long-tailed user and item problems exist at the same time, and considering only either one of them leads to sub-optimal performance of the other one. In this paper, we propose a novel framework for SRS, called Mutual Enhancement of Long-Tailed user and item (MELT), that jointly alleviates the long-tailed problem in the perspectives of both users and items. MELT consists of bilateral branches each of which is responsible for long-tailed users and items, respectively, and the branches are trained to mutually enhance each other, which is trained effectively by a curriculum learning-based training. MELT is model-agnostic in that it can be seamlessly integrated with existing SRS models. Extensive experiments on eight datasets demonstrate the benefit of alleviating the long-tailed problems in terms of both users and items even without sacrificing the performance of head users and items, which has not been achieved by existing methods. To the best of our knowledge, MELT is the first work that jointly alleviates the long-tailed user and item problems in SRS.|长尾问题是顺序推荐系统(SRS)中长期存在的一个挑战，其中问题既存在于用户中，也存在于项目中。虽然许多现有的研究解决了 SRS 中的长尾问题，但他们只关注用户或项目的角度。然而，我们发现长尾用户问题和条目问题同时存在，只考虑其中一个会导致另一个的性能次优。本文提出了一种新的 SRS 框架，称为长尾用户和项目的相互增强(MELT) ，它从用户和项目的角度共同解决了长尾问题。MELT 包括两个分支机构，每个分支机构分别负责长尾用户和项目，各分支机构接受培训以相互促进，通过基于课程学习的培训进行有效培训。MELT 是模型无关的，因为它可以与现有的 SRS 模型无缝集成。在8个数据集上的大量实验表明，在不牺牲首用户和项目性能的前提下，可以缓解用户和项目的长尾问题，这是现有方法所不能达到的。据我们所知，MELT 是第一个共同解决 SRS 中长尾用户和项目问题的工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MELT:+Mutual+Enhancement+of+Long-Tailed+User+and+Item+for+Sequential+Recommendation)|0|
|[DMBIN: A Dual Multi-behavior Interest Network for Click-Through Rate Prediction via Contrastive Learning](https://doi.org/10.1145/3539618.3591669)|Tianqi He, Kaiyuan Li, Shan Chen, Haitao Wang, Qiang Liu, Xingxing Wang, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DMBIN:+A+Dual+Multi-behavior+Interest+Network+for+Click-Through+Rate+Prediction+via+Contrastive+Learning)|0|
|[Ensemble Modeling with Contrastive Knowledge Distillation for Sequential Recommendation](https://doi.org/10.1145/3539618.3591679)|Hanwen Du, Huanhuan Yuan, Pengpeng Zhao, Fuzhen Zhuang, Guanfeng Liu, Lei Zhao, Yanchi Liu, Victor S. Sheng||Sequential recommendation aims to capture users' dynamic interest and predicts the next item of users' preference. Most sequential recommendation methods use a deep neural network as sequence encoder to generate user and item representations. Existing works mainly center upon designing a stronger sequence encoder. However, few attempts have been made with training an ensemble of networks as sequence encoders, which is more powerful than a single network because an ensemble of parallel networks can yield diverse prediction results and hence better accuracy. In this paper, we present Ensemble Modeling with contrastive Knowledge Distillation for sequential recommendation (EMKD). Our framework adopts multiple parallel networks as an ensemble of sequence encoders and recommends items based on the output distributions of all these networks. To facilitate knowledge transfer between parallel networks, we propose a novel contrastive knowledge distillation approach, which performs knowledge transfer from the representation level via Intra-network Contrastive Learning (ICL) and Cross-network Contrastive Learning (CCL), as well as Knowledge Distillation (KD) from the logits level via minimizing the Kullback-Leibler divergence between the output distributions of the teacher network and the student network. To leverage contextual information, we train the primary masked item prediction task alongside the auxiliary attribute prediction task as a multi-task learning scheme. Extensive experiments on public benchmark datasets show that EMKD achieves a significant improvement compared with the state-of-the-art methods. Besides, we demonstrate that our ensemble method is a generalized approach that can also improve the performance of other sequential recommenders. Our code is available at this link: https://github.com/hw-du/EMKD.|序贯推荐旨在捕捉用户的动态兴趣，预测用户的下一项偏好。大多数顺序推荐方法使用深层神经网络作为序列编码器来生成用户和项目表示。现有的工作主要集中在设计一个更强的序列编码器。然而，很少有人尝试将一个网络集合训练成序列编码器，它比单个网络更强大，因为一个并行网络集合可以产生不同的预测结果，从而提高准确性。本文提出了一种基于对比知识提取的序贯推荐系统集成建模方法。我们的框架采用多个并行网络作为序列编码器的集成，并根据这些网络的输出分布推荐项目。为了促进并行网络之间的知识转移，提出了一种新的对比知识提取方法，该方法通过网络内对比学习(ICL)和跨网络对比学习(CCL)从表示层进行知识转移，通过最小化教师网络和学生网络输出分布之间的 Kullback-Leibler 差异，从 logits 层进行知识提取。为了充分利用上下文信息，我们将主要隐藏项目预测任务与辅助属性预测任务一起训练为一个多任务学习方案。在公共基准数据集上进行的大量实验表明，EMKD 方法与最新的方法相比，取得了显著的改进。此外，我们证明了我们的集成方法是一种通用的方法，也可以改善其他顺序推荐器的性能。我们的代码可在以下连结找到:  https://github.com/hw-du/emkd。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ensemble+Modeling+with+Contrastive+Knowledge+Distillation+for+Sequential+Recommendation)|0|
|[HDNR: A Hyperbolic-Based Debiased Approach for Personalized News Recommendation](https://doi.org/10.1145/3539618.3591693)|Shicheng Wang, Shu Guo, Lihong Wang, Tingwen Liu, Hongbo Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HDNR:+A+Hyperbolic-Based+Debiased+Approach+for+Personalized+News+Recommendation)|0|
|[LinRec: Linear Attention Mechanism for Long-term Sequential Recommender Systems](https://doi.org/10.1145/3539618.3591717)|Langming Liu, Liu Cai, Chi Zhang, Xiangyu Zhao, Jingtong Gao, Wanyu Wang, Yifu Lv, Wenqi Fan, Yiqi Wang, Ming He, Zitao Liu, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LinRec:+Linear+Attention+Mechanism+for+Long-term+Sequential+Recommender+Systems)|0|
|[Personalized Retrieval over Millions of Items](https://doi.org/10.1145/3539618.3591749)|Hemanth Vemuri, Sheshansh Agrawal, Shivam Mittal, Deepak Saini, Akshay Soni, Abhinav V. Sambasivan, Wenhao Lu, Yajun Wang, Mehul Parsana, Purushottam Kar, Manik Varma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Retrieval+over+Millions+of+Items)|0|
|[BKD: A Bridge-based Knowledge Distillation Method for Click-Through Rate Prediction](https://doi.org/10.1145/3539618.3591958)|Yin Deng, Yingxin Chen, Xin Dong, Lingchao Pan, Hai Li, Lei Cheng, Linjian Mo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BKD:+A+Bridge-based+Knowledge+Distillation+Method+for+Click-Through+Rate+Prediction)|0|
|[Hierarchical Type Enhanced Negative Sampling for Knowledge Graph Embedding](https://doi.org/10.1145/3539618.3591996)|Zhenzhou Lin, Zishuo Zhao, Jingyou Xie, Ying Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Type+Enhanced+Negative+Sampling+for+Knowledge+Graph+Embedding)|0|
|[LOVF: Layered Organic View Fusion for Click-through Rate Prediction in Online Advertising](https://doi.org/10.1145/3539618.3592014)|Lingwei Kong, Lu Wang, Xiwei Zhao, Junsheng Jin, Zhangang Lin, Jinghe Hu, Jingping Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LOVF:+Layered+Organic+View+Fusion+for+Click-through+Rate+Prediction+in+Online+Advertising)|0|
|[Optimizing Reciprocal Rank with Bayesian Average for improved Next Item Recommendation](https://doi.org/10.1145/3539618.3592033)|Xiangkui Lu, Jun Wu, Jianbo Yuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Reciprocal+Rank+with+Bayesian+Average+for+improved+Next+Item+Recommendation)|0|
|[uCTRL: Unbiased Contrastive Representation Learning via Alignment and Uniformity for Collaborative Filtering](https://doi.org/10.1145/3539618.3592076)|Jaewoong Lee, Seongmin Park, Mincheol Yoon, Jongwuk Lee||Because implicit user feedback for the collaborative filtering (CF) models is biased toward popular items, CF models tend to yield recommendation lists with popularity bias. Previous studies have utilized inverse propensity weighting (IPW) or causal inference to mitigate this problem. However, they solely employ pointwise or pairwise loss functions and neglect to adopt a contrastive loss function for learning meaningful user and item representations. In this paper, we propose Unbiased ConTrastive Representation Learning (uCTRL), optimizing alignment and uniformity functions derived from the InfoNCE loss function for CF models. Specifically, we formulate an unbiased alignment function used in uCTRL. We also devise a novel IPW estimation method that removes the bias of both users and items. Despite its simplicity, uCTRL equipped with existing CF models consistently outperforms state-of-the-art unbiased recommender models, up to 12.22% for Recall@20 and 16.33% for NDCG@20 gains, on four benchmark datasets.|由于协同过滤(CF)模型的隐式用户反馈偏向于流行项目，CF 模型倾向于产生带有流行偏见的推荐列表。以往的研究采用逆倾向加权(IPW)或因果推断来缓解这一问题。然而，他们仅仅使用逐点损失函数或成对损失函数，而忽略了采用对比损失函数来学习有意义的用户和项目表示。本文针对 CF 模型，提出了无偏对比表示学习(uCTRL)、优化对齐和由 InfoNCE 损失函数导出的均匀性函数。具体来说，我们制定了一个无偏对齐函数在 uCTRL 中使用。我们还设计了一种新的 IPW 估计方法，消除了用户和项目的偏差。尽管简单，配备现有 CF 模型的 uCTRL 始终优于最先进的无偏差推荐模型，在四个基准数据集上，Recall@20最高为12.22% ，NDCG@20最高为16.33% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=uCTRL:+Unbiased+Contrastive+Representation+Learning+via+Alignment+and+Uniformity+for+Collaborative+Filtering)|0|
|[Unsupervised Query Performance Prediction for Neural Models with Pairwise Rank Preferences](https://doi.org/10.1145/3539618.3592082)|Ashutosh Singh, Debasis Ganguly, Suchana Datta, Craig MacDonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Query+Performance+Prediction+for+Neural+Models+with+Pairwise+Rank+Preferences)|0|
|[Repetition and Exploration in Sequential Recommendation](https://doi.org/10.1145/3539618.3591914)|Ming Li, Ali Vardasbi, Andrew Yates, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Repetition+and+Exploration+in+Sequential+Recommendation)|0|
|[JDsearch: A Personalized Product Search Dataset with Real Queries and Full Interactions](https://doi.org/10.1145/3539618.3591900)|Jiongnan Liu, Zhicheng Dou, Guoyu Tang, Sulong Xu||Recently, personalized product search attracts great attention and many models have been proposed. To evaluate the effectiveness of these models, previous studies mainly utilize the simulated Amazon recommendation dataset, which contains automatically generated queries and excludes cold users and tail products. We argue that evaluating with such a dataset may yield unreliable results and conclusions, and deviate from real user satisfaction. To overcome these problems, in this paper, we release a personalized product search dataset comprised of real user queries and diverse user-product interaction types (clicking, adding to cart, following, and purchasing) collected from JD.com, a popular Chinese online shopping platform. More specifically, we sample about 170,000 active users on a specific date, then record all their interacted products and issued queries in one year, without removing any tail users and products. This finally results in roughly 12,000,000 products, 9,400,000 real searches, and 26,000,000 user-product interactions. We study the characteristics of this dataset from various perspectives and evaluate representative personalization models to verify its feasibility. The dataset can be publicly accessed at Github: https://github.com/rucliujn/JDsearch.|近年来，个性化产品搜索引起了人们的广泛关注，提出了许多个性化产品搜索模型。为了评估这些模型的有效性，以往的研究主要利用模拟亚马逊推荐数据集，其中包含自动生成的查询，并排除了冷用户和尾部产品。我们认为，使用这样的数据集进行评估可能产生不可靠的结果和结论，并偏离真正的用户满意度。为了克服这些问题，本文发布了一个个性化产品搜索数据集，该数据集由真实用户查询和不同的用户-产品交互类型(点击、添加到购物车、跟随和购买)组成，收集自中国流行的在线购物平台京东(JD.com)。更具体地说，我们在一个特定的日期抽样约170,000个活跃用户，然后记录他们所有的交互产品，并在一年内发布查询，而不删除任何尾用户和产品。这最终产生了大约12,000,000个产品，9,400,000个实际搜索，以及26,000,000个用户-产品交互。我们从不同的角度研究了这个数据集的特点，并评价了具有代表性的个性化模型，以验证其可行性。该数据集可以在 Github:  https://Github.com/rucliujn/jdsearch 上公开访问。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=JDsearch:+A+Personalized+Product+Search+Dataset+with+Real+Queries+and+Full+Interactions)|0|
|[FedAds: A Benchmark for Privacy-Preserving CVR Estimation with Vertical Federated Learning](https://doi.org/10.1145/3539618.3591909)|Penghui Wei, Hongjian Dou, Shaoguo Liu, Rongjun Tang, Li Liu, Liang Wang, Bo Zheng||Conversion rate (CVR) estimation aims to predict the probability of conversion event after a user has clicked an ad. Typically, online publisher has user browsing interests and click feedbacks, while demand-side advertising platform collects users' post-click behaviors such as dwell time and conversion decisions. To estimate CVR accurately and protect data privacy better, vertical federated learning (vFL) is a natural solution to combine two sides' advantages for training models, without exchanging raw data. Both CVR estimation and applied vFL algorithms have attracted increasing research attentions. However, standardized and systematical evaluations are missing: due to the lack of standardized datasets, existing studies adopt public datasets to simulate a vFL setting via hand-crafted feature partition, which brings challenges to fair comparison. We introduce FedAds, the first benchmark for CVR estimation with vFL, to facilitate standardized and systematical evaluations for vFL algorithms. It contains a large-scale real world dataset collected from Alibaba's advertising platform, as well as systematical evaluations for both effectiveness and privacy aspects of various vFL algorithms. Besides, we also explore to incorporate unaligned data in vFL to improve effectiveness, and develop perturbation operations to protect privacy well. We hope that future research work in vFL and CVR estimation benefits from the FedAds benchmark.|转换率(CVR)估计的目的是预测用户点击广告后发生转换事件的概率。通常，在线出版商有用户浏览兴趣和点击反馈，而需求侧广告平台收集用户的点击后行为，如停留时间和转换决定。为了更准确地估计 CVR，更好地保护数据隐私，垂直联邦学习(vFL)是一种自然而然的解决方案，它结合了双方在训练模型方面的优势，不需要交换原始数据。CVR 估计和应用的 vFL 算法都受到了越来越多的研究关注。然而，由于缺乏标准化的数据集，现有的研究采用公共数据集通过手工特征划分来模拟 vFL 设置，这给公平比较带来了挑战。我们引入 FedAds，第一个用 vFL 进行 CVR 估计的基准，以促进 vFL 算法的标准化和系统化评估。它包含从阿里巴巴广告平台收集的大规模真实世界数据集，以及对各种 vfL 算法的有效性和隐私方面的系统评估。此外，我们还探讨了在 vFL 中加入未对齐数据以提高效率，并开发扰动操作以更好地保护隐私。我们希望未来在 vFL 和 CVR 估计方面的研究工作能够从 FedAds 基准中受益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedAds:+A+Benchmark+for+Privacy-Preserving+CVR+Estimation+with+Vertical+Federated+Learning)|0|
|[TMML: Text-Guided MuliModal Product Location For Alleviating Retrieval Inconsistency in E-Commerce](https://doi.org/10.1145/3539618.3591836)|Youhua Tang, Xiong Xiong, Siyang Sun, Baoliang Cui, Yun Zheng, Haihong Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TMML:+Text-Guided+MuliModal+Product+Location+For+Alleviating+Retrieval+Inconsistency+in+E-Commerce)|0|
|[Alleviating Matching Bias in Marketing Recommendations](https://doi.org/10.1145/3539618.3591854)|Junpeng Fang, Qing Cui, Gongduo Zhang, Caizhi Tang, Lihong Gu, Longfei Li, Jinjie Gu, Jun Zhou, Fei Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Alleviating+Matching+Bias+in+Marketing+Recommendations)|0|
|[Implicit Query Parsing at Amazon Product Search](https://doi.org/10.1145/3539618.3591858)|Chen Luo, Rahul Goutam, Haiyang Zhang, Chao Zhang, Yangqiu Song, Bing Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Implicit+Query+Parsing+at+Amazon+Product+Search)|0|
|[Delving into E-Commerce Product Retrieval with Vision-Language Pre-training](https://doi.org/10.1145/3539618.3591859)|Xiaoyang Zheng, Fuyu Lv, Zilong Wang, Qingwen Liu, Xiaoyi Zeng||E-commerce search engines comprise a retrieval phase and a ranking phase, where the first one returns a candidate product set given user queries. Recently, vision-language pre-training, combining textual information with visual clues, has been popular in the application of retrieval tasks. In this paper, we propose a novel V+L pre-training method to solve the retrieval problem in Taobao Search. We design a visual pre-training task based on contrastive learning, outperforming common regression-based visual pre-training tasks. In addition, we adopt two negative sampling schemes, tailored for the large-scale retrieval task. Besides, we introduce the details of the online deployment of our proposed method in real-world situations. Extensive offline/online experiments demonstrate the superior performance of our method on the retrieval task. Our proposed method is employed as one retrieval channel of Taobao Search and serves hundreds of millions of users in real time.|电子商务搜索引擎包括检索阶段和排名阶段，其中第一个搜索引擎返回给定用户查询的候选产品集。近年来，将文本信息与视觉线索相结合的视觉语言预训练方法在检索任务中的应用越来越普遍。本文针对淘宝搜索中的检索问题，提出了一种新的 V + L 预训练方法。我们设计了一个基于对比学习的视觉预训练任务，其表现优于一般的基于回归的视觉预训练任务。此外，我们还采用了两种负抽样方案，以适应大规模的检索任务。此外，我们还详细介绍了我们提出的方法在现实环境中的在线部署。大量的离线/在线实验证明了该方法在检索任务中的优越性能。我们提出的方法被用作淘宝搜索的一个检索通道，为数亿用户提供实时服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Delving+into+E-Commerce+Product+Retrieval+with+Vision-Language+Pre-training)|0|
|[Contrastive Box Embedding for Collaborative Reasoning](https://doi.org/10.1145/3539618.3591654)|Tingting Liang, Yuanqing Zhang, Qianhui Di, Congying Xia, Youhuizi Li, Yuyu Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Box+Embedding+for+Collaborative+Reasoning)|0|
|[Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation](https://doi.org/10.1145/3539618.3591672)|Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Contrastive+Transformer+for+Hierarchical+Preference+Modeling+in+Sequential+Recommendation)|0|
|[Meta-optimized Contrastive Learning for Sequential Recommendation](https://doi.org/10.1145/3539618.3591727)|Xiuyuan Qin, Huanhuan Yuan, Pengpeng Zhao, Junhua Fang, Fuzhen Zhuang, Guanfeng Liu, Yanchi Liu, Victor S. Sheng||Contrastive Learning (CL) performances as a rising approach to address the challenge of sparse and noisy recommendation data. Although having achieved promising results, most existing CL methods only perform either hand-crafted data or model augmentation for generating contrastive pairs to find a proper augmentation operation for different datasets, which makes the model hard to generalize. Additionally, since insufficient input data may lead the encoder to learn collapsed embeddings, these CL methods expect a relatively large number of training data (e.g., large batch size or memory bank) to contrast. However, not all contrastive pairs are always informative and discriminative enough for the training processing. Therefore, a more general CL-based recommendation model called Meta-optimized Contrastive Learning for sequential Recommendation (MCLRec) is proposed in this work. By applying both data augmentation and learnable model augmentation operations, this work innovates the standard CL framework by contrasting data and model augmented views for adaptively capturing the informative features hidden in stochastic data augmentation. Moreover, MCLRec utilizes a meta-learning manner to guide the updating of the model augmenters, which helps to improve the quality of contrastive pairs without enlarging the amount of input data. Finally, a contrastive regularization term is considered to encourage the augmentation model to generate more informative augmented views and avoid too similar contrastive pairs within the meta updating. The experimental results on commonly used datasets validate the effectiveness of MCLRec.|对比学习(CL)作为一种新兴的方法来解决稀疏和噪声推荐数据的挑战。虽然已经取得了很好的效果，但是现有的 CL 方法只能通过手工数据或者模型增强来生成对比对，以便为不同的数据集找到合适的增强操作，这使得模型很难推广。此外，由于输入数据不足可能导致编码器学习折叠嵌入，这些 CL 方法期望相对大量的训练数据(例如，大批量或内存库)进行对比。然而，并非所有的对比对都具有足够的信息量和判别力来进行训练处理。因此，本文提出了一种更为通用的基于 CL 的推荐模型，称为序贯推荐元优化对比学习(MCLRec)。通过应用数据增强和可学习模型增强操作，对比数据和模型增强视图，创新标准 CL 框架，自适应地捕捉随机数据增强中隐藏的信息特征。此外，MCLRec 利用元学习方式来指导模型增强器的更新，这有助于提高对比对的质量，而不需要扩大输入数据的数量。最后，考虑了一个对比正则化项，以鼓励增强模型生成更多的信息增强视图，避免元更新中出现过于相似的对比对。在常用数据集上的实验结果验证了 MCLRec 算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-optimized+Contrastive+Learning+for+Sequential+Recommendation)|0|
|[A Personalized Dense Retrieval Framework for Unified Information Access](https://doi.org/10.1145/3539618.3591626)|Hansi Zeng, Surya Kallumadi, Zaid Alibadi, Rodrigo Frassetto Nogueira, Hamed Zamani||Developing a universal model that can efficiently and effectively respond to a wide range of information access requests -- from retrieval to recommendation to question answering -- has been a long-lasting goal in the information retrieval community. This paper argues that the flexibility, efficiency, and effectiveness brought by the recent development in dense retrieval and approximate nearest neighbor search have smoothed the path towards achieving this goal. We develop a generic and extensible dense retrieval framework, called \framework, that can handle a wide range of (personalized) information access requests, such as keyword search, query by example, and complementary item recommendation. Our proposed approach extends the capabilities of dense retrieval models for ad-hoc retrieval tasks by incorporating user-specific preferences through the development of a personalized attentive network. This allows for a more tailored and accurate personalized information access experience. Our experiments on real-world e-commerce data suggest the feasibility of developing universal information access models by demonstrating significant improvements even compared to competitive baselines specifically developed for each of these individual information access tasks. This work opens up a number of fundamental research directions for future exploration.|开发一个通用的模型，可以有效率和有效地响应广泛的信息访问请求——从检索到推荐到问答——一直是信息检索社区的长期目标。本文认为，最近在密集检索和近似最近邻搜索方面的发展所带来的灵活性、效率和有效性为实现这一目标铺平了道路。我们开发了一个通用的和可扩展的密集检索框架，称为框架，可以处理广泛的(个性化的)信息访问请求，如关键字搜索，按例查询，补充项目推荐。我们提出的方法扩展了密集检索模型的能力，通过合并用户特定的偏好，通过开发一个个性化的注意网络的特定检索任务。这样可以提供更加量身定制和准确的个性化信息访问体验。我们对现实世界电子商务数据的实验表明，即使与为这些个人信息获取任务中的每一项专门制定的竞争性基线相比，通用信息获取模型的开发也是可行的。这项工作为今后的探索开辟了一些基础性的研究方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Personalized+Dense+Retrieval+Framework+for+Unified+Information+Access)|0|
|[One Blade for One Purpose: Advancing Math Information Retrieval using Hybrid Search](https://doi.org/10.1145/3539618.3591746)|Wei Zhong, ShengChieh Lin, JhengHong Yang, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One+Blade+for+One+Purpose:+Advancing+Math+Information+Retrieval+using+Hybrid+Search)|0|
|[Poisoning Self-supervised Learning Based Sequential Recommendations](https://doi.org/10.1145/3539618.3591751)|Yanling Wang, Yuchen Liu, Qian Wang, Cong Wang, Chenliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Poisoning+Self-supervised+Learning+Based+Sequential+Recommendations)|0|
|[Graph Masked Autoencoder for Sequential Recommendation](https://doi.org/10.1145/3539618.3591692)|Yaowen Ye, Lianghao Xia, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Masked+Autoencoder+for+Sequential+Recommendation)|0|
|[A Generic Learning Framework for Sequential Recommendation with Distribution Shifts](https://doi.org/10.1145/3539618.3591624)|Zhengyi Yang, Xiangnan He, Jizhi Zhang, Jiancan Wu, Xin Xin, Jiawei Chen, Xiang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Generic+Learning+Framework+for+Sequential+Recommendation+with+Distribution+Shifts)|0|
|[Single-shot Feature Selection for Multi-task Recommendations](https://doi.org/10.1145/3539618.3591767)|Yejing Wang, Zhaocheng Du, Xiangyu Zhao, Bo Chen, Huifeng Guo, Ruiming Tang, Zhenhua Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Single-shot+Feature+Selection+for+Multi-task+Recommendations)|0|
|[Fine-Grained Preference-Aware Personalized Federated POI Recommendation with Data Sparsity](https://doi.org/10.1145/3539618.3591688)|Xiao Zhang, Ziming Ye, Jianfeng Lu, Fuzhen Zhuang, Yanwei Zheng, Dongxiao Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fine-Grained+Preference-Aware+Personalized+Federated+POI+Recommendation+with+Data+Sparsity)|0|
|[Model-Agnostic Decentralized Collaborative Learning for On-Device POI Recommendation](https://doi.org/10.1145/3539618.3591733)|Jing Long, Tong Chen, Quoc Viet Hung Nguyen, Guandong Xu, Kai Zheng, Hongzhi Yin||As an indispensable personalized service in Location-based Social Networks (LBSNs), the next Point-of-Interest (POI) recommendation aims to help people discover attractive and interesting places. Currently, most POI recommenders are based on the conventional centralized paradigm that heavily relies on the cloud to train the recommendation models with large volumes of collected users' sensitive check-in data. Although a few recent works have explored on-device frameworks for resilient and privacy-preserving POI recommendations, they invariably hold the assumption of model homogeneity for parameters/gradients aggregation and collaboration. However, users' mobile devices in the real world have various hardware configurations (e.g., compute resources), leading to heterogeneous on-device models with different architectures and sizes. In light of this, We propose a novel on-device POI recommendation framework, namely Model-Agnostic Collaborative learning for on-device POI recommendation (MAC), allowing users to customize their own model structures (e.g., dimension \& number of hidden layers). To counteract the sparsity of on-device user data, we propose to pre-select neighbors for collaboration based on physical distances, category-level preferences, and social networks. To assimilate knowledge from the above-selected neighbors in an efficient and secure way, we adopt the knowledge distillation framework with mutual information maximization. Instead of sharing sensitive models/gradients, clients in MAC only share their soft decisions on a preloaded reference dataset. To filter out low-quality neighbors, we propose two sampling strategies, performance-triggered sampling and similarity-based sampling, to speed up the training process and obtain optimal recommenders. In addition, we design two novel approaches to generate more effective reference datasets while protecting users' privacy.|作为基于位置的社交网络(LBSNs)中不可或缺的个性化服务，下一个兴趣点(POI)推荐旨在帮助人们发现有吸引力和有趣的地方。目前，大多数 POI 推荐系统都是基于传统的集中式模式，这种模式严重依赖于云来训练推荐模型，并收集了大量用户的敏感签入数据。虽然最近的一些工作已经探索了弹性和保护隐私的 POI 建议在设备上的框架，他们总是持有参数/梯度聚合和协作的模型同质性的假设。然而，在现实世界中，用户的移动设备有各种各样的硬件配置(例如，计算资源) ，导致了具有不同体系结构和大小的异构设备上模型。鉴于此，我们提出了一个新的设备上 POI 推荐框架，即设备上 POI 推荐的模型不可知合作学习(model-Agnotic) ，允许用户定制自己的模型结构(例如，尺寸和隐藏层数)。为了弥补设备上用户数据的稀缺性，我们建议根据物理距离、类别级别偏好和社交网络预先选择合作的邻居。为了有效、安全地吸收上述邻居的知识，我们采用了具有互信息最大化的知识提取框架。MAC 中的客户端不共享敏感的模型/梯度，而只在预加载的参考数据集上共享他们的软决策。为了过滤掉低质量的邻居，我们提出了两种抽样策略: 性能触发抽样和基于相似度的抽样，以加快训练过程，并获得最优的推荐。此外，我们设计了两种新的方法来生成更有效的参考数据集，同时保护用户的隐私。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Model-Agnostic+Decentralized+Collaborative+Learning+for+On-Device+POI+Recommendation)|0|
|[Multi-view Hypergraph Contrastive Policy Learning for Conversational Recommendation](https://doi.org/10.1145/3539618.3591737)|Sen Zhao, Wei Wei, XianLing Mao, Shuai Zhu, Minghui Yang, Zujie Wen, Dangyang Chen, Feida Zhu||Conversational recommendation systems (CRS) aim to interactively acquire user preferences and accordingly recommend items to users. Accurately learning the dynamic user preferences is of crucial importance for CRS. Previous works learn the user preferences with pairwise relations from the interactive conversation and item knowledge, while largely ignoring the fact that factors for a relationship in CRS are multiplex. Specifically, the user likes/dislikes the items that satisfy some attributes (Like/Dislike view). Moreover social influence is another important factor that affects user preference towards the item (Social view), while is largely ignored by previous works in CRS. The user preferences from these three views are inherently different but also correlated as a whole. The user preferences from the same views should be more similar than that from different views. The user preferences from Like View should be similar to Social View while different from Dislike View. To this end, we propose a novel model, namely Multi-view Hypergraph Contrastive Policy Learning (MHCPL). Specifically, MHCPL timely chooses useful social information according to the interactive history and builds a dynamic hypergraph with three types of multiplex relations from different views. The multiplex relations in each view are successively connected according to their generation order.|会话推荐系统(CRS)旨在交互式地获取用户偏好，从而向用户推荐项目。准确地了解动态用户偏好对 CRS 至关重要。以往的研究主要是从交互式会话和项目知识中了解成对关系的用户偏好，而忽略了 CRS 中影响关系的因素是多重的这一事实。具体来说，用户喜欢/不喜欢满足某些属性的项(Like/Dislike 视图)。此外，社会影响力是影响用户对商品偏好的另一个重要因素(社会视图) ，而以往的研究大多忽略了社会影响力。来自这三个视图的用户首选项在本质上是不同的，但作为一个整体也是相关的。来自相同视图的用户首选项应该比来自不同视图的用户首选项更加相似。来自 Like View 的用户首选项应该类似于 Social View，而不同于 Dislike View。为此，我们提出了一个新的模型，即多视图超图对比策略学习(MHCPL)。具体来说，MHCPL 根据交互历史及时选择有用的社会信息，从不同角度构建了三类多元关系的动态超图。每个视图中的多路复用关系根据它们的生成顺序依次连接。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-view+Hypergraph+Contrastive+Policy+Learning+for+Conversational+Recommendation)|0|
|[Learnable Pillar-based Re-ranking for Image-Text Retrieval](https://doi.org/10.1145/3539618.3591712)|Leigang Qu, Meng Liu, Wenjie Wang, Zhedong Zheng, Liqiang Nie, TatSeng Chua||Image-text retrieval aims to bridge the modality gap and retrieve cross-modal content based on semantic similarities. Prior work usually focuses on the pairwise relations (i.e., whether a data sample matches another) but ignores the higher-order neighbor relations (i.e., a matching structure among multiple data samples). Re-ranking, a popular post-processing practice, has revealed the superiority of capturing neighbor relations in single-modality retrieval tasks. However, it is ineffective to directly extend existing re-ranking algorithms to image-text retrieval. In this paper, we analyze the reason from four perspectives, i.e., generalization, flexibility, sparsity, and asymmetry, and propose a novel learnable pillar-based re-ranking paradigm. Concretely, we first select top-ranked intra- and inter-modal neighbors as pillars, and then reconstruct data samples with the neighbor relations between them and the pillars. In this way, each sample can be mapped into a multimodal pillar space only using similarities, ensuring generalization. After that, we design a neighbor-aware graph reasoning module to flexibly exploit the relations and excavate the sparse positive items within a neighborhood. We also present a structure alignment constraint to promote cross-modal collaboration and align the asymmetric modalities. On top of various base backbones, we carry out extensive experiments on two benchmark datasets, i.e., Flickr30K and MS-COCO, demonstrating the effectiveness, superiority, generalization, and transferability of our proposed re-ranking paradigm.|图像-文本检索旨在弥合情态差异，基于语义相似性检索跨情态内容。先前的工作通常侧重于成对关系(例如，一个数据样本是否匹配另一个) ，但忽略了高阶邻居关系(例如，多个数据样本之间的匹配结构)。重排序是一种流行的后处理实践，它揭示了在单模态检索任务中捕获邻居关系的优越性。然而，将现有的重新排序算法直接推广到图像文本检索是无效的。本文从概括性、灵活性、稀疏性和不对称性四个方面分析了排序问题产生的原因，并提出了一种新的可学习的基于支柱的排序范式。具体来说，我们首先选择排名最高的模态内邻居和模态间邻居作为支柱，然后利用它们与支柱之间的邻居关系重构数据样本。通过这种方式，每个样本只需使用相似性即可映射到多模态支柱空间，从而确保泛化。然后设计邻域感知图推理模块，灵活地利用邻域间的关系，挖掘邻域内的稀疏正项。我们还提出了一个结构调整约束，以促进跨模式协作和调整不对称的模式。在各种基础骨干之上，我们对 Flickr30K 和 MS-COCO 这两个基准数据集进行了广泛的实验，证明了我们提出的重新排序范式的有效性、优越性、通用性和可转移性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learnable+Pillar-based+Re-ranking+for+Image-Text+Retrieval)|0|
|[When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation](https://doi.org/10.1145/3539618.3591786)|Zihua Si, Zhongxiang Sun, Xiao Zhang, Jun Xu, Xiaoxue Zang, Yang Song, Kun Gai, JiRong Wen||Modern online service providers such as online shopping platforms often provide both search and recommendation (S&R) services to meet different user needs. Rarely has there been any effective means of incorporating user behavior data from both S&R services. Most existing approaches either simply treat S&R behaviors separately, or jointly optimize them by aggregating data from both services, ignoring the fact that user intents in S&R can be distinctively different. In our paper, we propose a Search-Enhanced framework for the Sequential Recommendation (SESRec) that leverages users' search interests for recommendation, by disentangling similar and dissimilar representations within S&R behaviors. Specifically, SESRec first aligns query and item embeddings based on users' query-item interactions for the computations of their similarities. Two transformer encoders are used to learn the contextual representations of S&R behaviors independently. Then a contrastive learning task is designed to supervise the disentanglement of similar and dissimilar representations from behavior sequences of S&R. Finally, we extract user interests by the attention mechanism from three perspectives, i.e., the contextual representations, the two separated behaviors containing similar and dissimilar interests. Extensive experiments on both industrial and public datasets demonstrate that SESRec consistently outperforms state-of-the-art models. Empirical studies further validate that SESRec successfully disentangle similar and dissimilar user interests from their S&R behaviors.|现代在线服务提供商，如在线购物平台，经常同时提供搜索和推荐(S & R)服务，以满足不同的用户需求。很少有任何有效的方法来整合来自 S & R 服务的用户行为数据。大多数现有的方法要么单独处理 S & R 行为，要么通过聚合来自两个服务的数据共同优化它们，忽略了 S & R 中的用户意图可能截然不同的事实。在我们的论文中，我们提出了一个搜索增强的序列推荐框架(SESRec) ，它利用用户的搜索兴趣进行推荐，通过在 S & R 行为中分离相似和不相似的表示。具体来说，SESRec 首先根据用户的查询-项交互对查询和项嵌入进行对齐，以计算它们的相似性。使用两个变压器编码器分别学习 S & R 行为的上下文表示。然后设计了一个对比学习任务来监督 S & R 行为序列中相似和不相似表征的分离。最后，通过注意机制从三个方面提取用户的兴趣，即语境表征，两个分离的具有相似兴趣和不同兴趣的行为。在工业和公共数据集上的大量实验表明，SESRec 始终优于最先进的模型。实证研究进一步验证了 SESRec 成功地将相似和不同的用户兴趣从他们的 S & R 行为中分离出来。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Search+Meets+Recommendation:+Learning+Disentangled+Search+Representation+for+Recommendation)|0|
|[Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?](https://doi.org/10.1145/3539618.3591703)|Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon||Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable.|系统评价是对一个高度关注的研究问题的文献的综合评价。这些评论往往被视为循证医学中最高形式的证据，是回答医学领域研究问题的关键策略。为了创建一个高质量的系统综述，复杂的布尔查询通常被构建来检索复习主题的研究。然而，对于系统综述研究人员来说，构建一个高质量的系统综述布尔查询通常需要很长的时间，而且往往得到的结果远远不够有效。差的查询可能导致有偏见或无效的评论，因为他们错过了检索关键证据，或广泛增加审查成本，因为他们检索了太多不相关的研究。最近在变压器为基础的生成模型显示了巨大的潜力，有效地遵循指令从用户和生成答案的基础上，正在作出的指令。在本文中，我们研究了最新的这类模型 ChatGPT 在为系统综述文献检索生成有效的布尔查询方面的有效性。通过对任务的标准测试集进行大量的实验，我们发现 ChatGPT 能够生成导致高搜索精度的查询，尽管在这方面取舍于召回。总的来说，我们的研究展示了 chatgPT 在为系统综述文献检索生成有效的布尔查询方面的潜力。ChatGPT 能够遵循复杂的指令并以高精度生成查询，这使得它成为研究人员进行系统评价的有价值的工具，特别是对于时间受到限制的快速评价，往往以较高的精度换取较低的回忆是可以接受的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+ChatGPT+Write+a+Good+Boolean+Query+for+Systematic+Review+Literature+Search?)|0|
|[Candidate-aware Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3539618.3591647)|Wei He, Guohao Sun, Jinhu Lu, Xiu Susie Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Candidate-aware+Graph+Contrastive+Learning+for+Recommendation)|0|
|[Attention Mixtures for Time-Aware Sequential Recommendation](https://doi.org/10.1145/3539618.3591951)|VietAnh Tran, Guillaume SalhaGalvan, Bruno Sguerra, Romain Hennequin||Transformers emerged as powerful methods for sequential recommendation. However, existing architectures often overlook the complex dependencies between user preferences and the temporal context. In this short paper, we introduce MOJITO, an improved Transformer sequential recommender system that addresses this limitation. MOJITO leverages Gaussian mixtures of attention-based temporal context and item embedding representations for sequential modeling. Such an approach permits to accurately predict which items should be recommended next to users depending on past actions and the temporal context. We demonstrate the relevance of our approach, by empirically outperforming existing Transformers for sequential recommendation on several real-world datasets.|变压器作为强大的顺序推荐方法出现了。然而，现有的体系结构往往忽略了用户首选项和时态上下文之间的复杂依赖关系。在这篇简短的文章中，我们介绍了 MOJITO，一个改进的 formers顺序推荐系统，它解决了这个问题。MOJITO 利用基于注意的时间上下文和项目嵌入表示的高斯混合序列建模。这种方法允许根据过去的行为和时间上下文准确地预测哪些项目应该被推荐给用户。我们证明了我们的方法的相关性，通过经验优于现有的变形金刚顺序推荐几个真实世界的数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attention+Mixtures+for+Time-Aware+Sequential+Recommendation)|0|
|[Augmenting Passage Representations with Query Generation for Enhanced Cross-Lingual Dense Retrieval](https://doi.org/10.1145/3539618.3591952)|Shengyao Zhuang, Linjun Shou, Guido Zuccon||Effective cross-lingual dense retrieval methods that rely on multilingual pre-trained language models (PLMs) need to be trained to encompass both the relevance matching task and the cross-language alignment task. However, cross-lingual data for training is often scarcely available. In this paper, rather than using more cross-lingual data for training, we propose to use cross-lingual query generation to augment passage representations with queries in languages other than the original passage language. These augmented representations are used at inference time so that the representation can encode more information across the different target languages. Training of a cross-lingual query generator does not require additional training data to that used for the dense retriever. The query generator training is also effective because the pre-training task for the generator (T5 text-to-text training) is very similar to the fine-tuning task (generation of a query). The use of the generator does not increase query latency at inference and can be combined with any cross-lingual dense retrieval method. Results from experiments on a benchmark cross-lingual information retrieval dataset show that our approach can improve the effectiveness of existing cross-lingual dense retrieval methods. Implementation of our methods, along with all generated query files are made publicly available at https://github.com/ielab/xQG4xDR.|有效的跨语言密集检索方法依赖于多语言预训练语言模型(PLM)需要培训，以涵盖相关性匹配任务和跨语言对齐任务。然而，用于培训的跨语言数据往往很少。在本文中，我们不使用更多的跨语言数据进行训练，而是提出使用跨语言查询生成来增强非原始语言中的查询的段落表示。这些增强表示在推理时使用，以便表示可以跨不同的目标语言编码更多的信息。跨语言查询生成器的训练不需要比密集检索器所使用的训练数据更多的训练数据。查询生成器训练也很有效，因为生成器的预训练任务(T5文本到文本训练)与微调任务(生成查询)非常相似。该生成器的使用不会增加推断时的查询延迟，并且可以与任何跨语言密集检索方法结合使用。对基准跨语言信息检索数据集的实验结果表明，我们的方法可以提高现有跨语言密集检索方法的有效性。我们方法的实现，以及所有生成的查询文件都可以在 https://github.com/ielab/xqg4xdr 上公开获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Augmenting+Passage+Representations+with+Query+Generation+for+Enhanced+Cross-Lingual+Dense+Retrieval)|0|
|[CEC: Towards Learning Global Optimized Recommendation through Causality Enhanced Conversion Model](https://doi.org/10.1145/3539618.3591962)|Ran Le, Guoqing Jiang, Xiufeng Shu, Ruidong Han, Qianzhong Li, Yacheng Li, Xiang Li, Wei Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CEC:+Towards+Learning+Global+Optimized+Recommendation+through+Causality+Enhanced+Conversion+Model)|0|
|[ConQueR: Contextualized Query Reduction using Search Logs](https://doi.org/10.1145/3539618.3591966)|Hyeyoung Kim, Minjin Choi, Sunkyung Lee, Eunseong Choi, YoungIn Song, Jongwuk Lee||Query reformulation is a key mechanism to alleviate the linguistic chasm of query in ad-hoc retrieval. Among various solutions, query reduction effectively removes extraneous terms and specifies concise user intent from long queries. However, it is challenging to capture hidden and diverse user intent. This paper proposes Contextualized Query Reduction (ConQueR) using a pre-trained language model (PLM). Specifically, it reduces verbose queries with two different views: core term extraction and sub-query selection. One extracts core terms from an original query at the term level, and the other determines whether a sub-query is a suitable reduction for the original query at the sequence level. Since they operate at different levels of granularity and complement each other, they are finally aggregated in an ensemble manner. We evaluate the reduction quality of ConQueR on real-world search logs collected from a commercial web search engine. It achieves up to 8.45% gains in exact match scores over the best competing model.|查询重构是自组织检索中缓解查询语言鸿沟的关键机制。在各种解决方案中，查询缩减有效地去除了多余的术语，并从长查询中指定了简洁的用户意图。然而，捕捉隐藏的和多样化的用户意图是一个挑战。提出了一种基于预训练语言模型(PLM)的上下文查询约简(ConQueR)算法。具体来说，它使用两种不同的视图来减少冗长查询: 核心术语提取和子查询选择。一个在术语级别从原始查询中提取核心术语，另一个在序列级别确定子查询对于原始查询是否是合适的简化。由于它们在不同的粒度级别上运行并相互补充，因此最终以集成的方式进行聚合。我们对从商业网络搜索引擎收集的真实世界搜索日志中的 ConQueR 的还原质量进行评估。与最佳竞争模型相比，它在精确匹配得分上获得了高达8.45% 的增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ConQueR:+Contextualized+Query+Reduction+using+Search+Logs)|0|
|[Explain Like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation](https://doi.org/10.1145/3539618.3591982)|Michael Llordes, Debasis Ganguly, Sumit Bhatia, Chirag Agarwal||Neural retrieval models (NRMs) have been shown to outperform their statistical counterparts owing to their ability to capture semantic meaning via dense document representations. These models, however, suffer from poor interpretability as they do not rely on explicit term matching. As a form of local per-query explanations, we introduce the notion of equivalent queries that are generated by maximizing the similarity between the NRM's results and the result set of a sparse retrieval system with the equivalent query. We then compare this approach with existing methods such as RM3-based query expansion and contrast differences in retrieval effectiveness and in the terms generated by each approach.|神经检索模型(NRM)由于能够通过密集的文档表示来捕获语义信息，因此其性能优于统计检索模型。然而，这些模型的可解释性很差，因为它们不依赖于明确的术语匹配。作为局部查询解释的一种形式，我们引入了等价查询的概念，这些等价查询是通过最大化 NRM 的结果与具有等价查询的稀疏检索系统的结果集之间的相似性而生成的。然后，我们比较了这种方法与现有的方法，如基于 RM3的查询扩展和对比差异的检索效果和术语生成的每种方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explain+Like+I+am+BM25:+Interpreting+a+Dense+Model's+Ranked-List+with+a+Sparse+Approximation)|0|
|[Graph Collaborative Signals Denoising and Augmentation for Recommendation](https://doi.org/10.1145/3539618.3591994)|Ziwei Fan, Ke Xu, Zhang Dong, Hao Peng, Jiawei Zhang, Philip S. Yu||Graph collaborative filtering (GCF) is a popular technique for capturing high-order collaborative signals in recommendation systems. However, GCF's bipartite adjacency matrix, which defines the neighbors being aggregated based on user-item interactions, can be noisy for users/items with abundant interactions and insufficient for users/items with scarce interactions. Additionally, the adjacency matrix ignores user-user and item-item correlations, which can limit the scope of beneficial neighbors being aggregated.   In this work, we propose a new graph adjacency matrix that incorporates user-user and item-item correlations, as well as a properly designed user-item interaction matrix that balances the number of interactions across all users. To achieve this, we pre-train a graph-based recommendation method to obtain users/items embeddings, and then enhance the user-item interaction matrix via top-K sampling. We also augment the symmetric user-user and item-item correlation components to the adjacency matrix. Our experiments demonstrate that the enhanced user-item interaction matrix with improved neighbors and lower density leads to significant benefits in graph-based recommendation. Moreover, we show that the inclusion of user-user and item-item correlations can improve recommendations for users with both abundant and insufficient interactions. The code is in \url{https://github.com/zfan20/GraphDA}.|图形协同过滤(gCF)是在推荐系统中捕获高阶协作信号的一种流行技术。然而，绿色气候基金的二分邻接矩阵定义了基于用户-项目交互聚合的邻居，这对于交互丰富的用户/项目来说可能是嘈杂的，对于交互稀少的用户/项目来说则是不足的。此外，邻接矩阵忽略了用户-用户和项目-项目之间的相关性，这可能会限制有益邻居被聚合的范围。在这项工作中，我们提出了一个新的图形邻接矩阵，包括用户-用户和项目-项目的相关性，以及一个适当设计的用户-项目交互矩阵，平衡所有用户之间的交互数量。为了实现这一目标，我们预先训练了一种基于图的推荐方法来获得用户/项目的嵌入，然后通过 top-K 抽样来增强用户-项目的交互矩阵。我们还增加了对称的用户-用户和项目-项目相关组件的邻接矩阵。我们的实验表明，增强的用户项目交互矩阵与改进的邻居和较低的密度导致显着的好处，在图的推荐。此外，我们表明，包含用户-用户和项目-项目的相关性可以改善对交互丰富和不充分的用户的推荐。代码在 url { https://github.com/zfan20/graphda }中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Collaborative+Signals+Denoising+and+Augmentation+for+Recommendation)|0|
|[Improving Conversational Passage Re-ranking with View Ensemble](https://doi.org/10.1145/3539618.3592002)|JiaHuei Ju, ShengChieh Lin, MingFeng Tsai, ChuanJu Wang||This paper presents ConvRerank, a conversational passage re-ranker that employs a newly developed pseudo-labeling approach. Our proposed view-ensemble method enhances the quality of pseudo-labeled data, thus improving the fine-tuning of ConvRerank. Our experimental evaluation on benchmark datasets shows that combining ConvRerank with a conversational dense retriever in a cascaded manner achieves a good balance between effectiveness and efficiency. Compared to baseline methods, our cascaded pipeline demonstrates lower latency and higher top-ranking effectiveness. Furthermore, the in-depth analysis confirms the potential of our approach to improving the effectiveness of conversational search.|本文提出了一种会话文章重新排序算法，该算法采用了一种新的伪标记方法。我们提出的视图集成方法提高了伪标记数据的质量，从而改善了逆重排的微调。我们对基准数据集的实验评估表明，使用级联的方式将 ConverRank 与会话密集检索器相结合，实现了有效性和效率之间的良好平衡。与基线方法相比，我们的级联流水线显示出更低的延迟和更高的排名有效性。此外，深入的分析证实了我们的方法在提高会话搜索的有效性方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Conversational+Passage+Re-ranking+with+View+Ensemble)|0|
|[Inference at Scale: Significance Testing for Large Search and Recommendation Experiments](https://doi.org/10.1145/3539618.3592004)|Ngozi Ihemelandu, Michael D. Ekstrand||A number of information retrieval studies have been done to assess which statistical techniques are appropriate for comparing systems. However, these studies are focused on TREC-style experiments, which typically have fewer than 100 topics. There is no similar line of work for large search and recommendation experiments; such studies typically have thousands of topics or users and much sparser relevance judgements, so it is not clear if recommendations for analyzing traditional TREC experiments apply to these settings. In this paper, we empirically study the behavior of significance tests with large search and recommendation evaluation data. Our results show that the Wilcoxon and Sign tests show significantly higher Type-1 error rates for large sample sizes than the bootstrap, randomization and t-tests, which were more consistent with the expected error rate. While the statistical tests displayed differences in their power for smaller sample sizes, they showed no difference in their power for large sample sizes. We recommend the sign and Wilcoxon tests should not be used to analyze large scale evaluation results. Our result demonstrate that with Top-N recommendation and large search evaluation data, most tests would have a 100% chance of finding statistically significant results. Therefore, the effect size should be used to determine practical or scientific significance.|已经进行了大量的信息检索研究，以评估哪些统计技术适合于比较系统。然而，这些研究主要集中在 TREC 风格的实验上，这些实验通常只有不到100个主题。大型搜索和推荐实验没有类似的工作; 这类研究通常有成千上万的主题或用户，相关性判断更少，因此不清楚分析传统 TREC 实验的推荐是否适用于这些设置。本文利用大量的搜索和推荐评价数据，对显著性检验的行为进行了实证研究。我们的研究结果表明，Wilcoxon 和 Sign 检验显示，对于大样本量，显著高于自举、随机和 t 检验的1型错误率，这与预期错误率更为一致。虽然统计检验显示，在较小的样本规模的权力差异，他们没有显示出他们的权力在大样本规模。我们建议不要使用符号和 Wilcoxon 试验来分析大规模的评估结果。我们的结果表明，有了 Top-N 推荐和大量的搜索评估数据，大多数测试将有100% 的机会找到统计学上显著的结果。因此，应该用效应大小来确定实际意义或科学意义。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inference+at+Scale:+Significance+Testing+for+Large+Search+and+Recommendation+Experiments)|0|
|[Improving News Recommendation via Bottlenecked Multi-task Pre-training](https://doi.org/10.1145/3539618.3592003)|Xiongfeng Xiao, Qing Li, Songlin Liu, Kun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+News+Recommendation+via+Bottlenecked+Multi-task+Pre-training)|0|
|[LADER: Log-Augmented DEnse Retrieval for Biomedical Literature Search](https://doi.org/10.1145/3539618.3592005)|Qiao Jin, Andrew Shin, Zhiyong Lu||Queries with similar information needs tend to have similar document clicks, especially in biomedical literature search engines where queries are generally short and top documents account for most of the total clicks. Motivated by this, we present a novel architecture for biomedical literature search, namely Log-Augmented DEnse Retrieval (LADER), which is a simple plug-in module that augments a dense retriever with the click logs retrieved from similar training queries. Specifically, LADER finds both similar documents and queries to the given query by a dense retriever. Then, LADER scores relevant (clicked) documents of similar queries weighted by their similarity to the input query. The final document scores by LADER are the average of (1) the document similarity scores from the dense retriever and (2) the aggregated document scores from the click logs of similar queries. Despite its simplicity, LADER achieves new state-of-the-art (SOTA) performance on TripClick, a recently released benchmark for biomedical literature retrieval. On the frequent (HEAD) queries, LADER largely outperforms the best retrieval model by 39% relative NDCG@10 (0.338 v.s. 0.243). LADER also achieves better performance on the less frequent (TORSO) queries with 11% relative NDCG@10 improvement over the previous SOTA (0.303 v.s. 0.272). On the rare (TAIL) queries where similar queries are scarce, LADER still compares favorably to the previous SOTA method (NDCG@10: 0.310 v.s. 0.295). On all queries, LADER can improve the performance of a dense retriever by 24%-37% relative NDCG@10 while not requiring additional training, and further performance improvement is expected from more logs. Our regression analysis has shown that queries that are more frequent, have higher entropy of query similarity and lower entropy of document similarity, tend to benefit more from log augmentation.|具有相似信息需求的查询往往具有相似的文档点击率，特别是在生物医学文献搜索引擎中，查询通常较短，顶级文档占总点击率的大部分。受此启发，我们提出了一种用于生物医学文献检索的新型架构，即 Log-AugmentedDEnse Retrieval (LADER) ，它是一个简单的插件模块，通过从类似的训练查询中检索到的点击日志来增强稠密检索器。具体来说，LADER 通过密集检索器找到与给定查询相似的文档和查询。然后，LADER 根据相似查询与输入查询的相似性对相关(单击)文档进行加权。LADER 的最终文档得分是(1)密集检索器的文档相似性得分和(2)相似查询的点击日志的聚合文档得分的平均值。尽管其简单，LADER 在 TripClick 上实现了新的最先进的(SOTA)性能，TripClick 是最近发布的生物医学文献检索基准。在频繁查询(HEAD)中，LADER 的性能比最佳检索模型高出39% ，相对于 NDCG@10(0.338 vs。0.243)。LADER 在不太频繁的(TORSO)查询上也取得了更好的性能，相对于之前的 SOTA (0.303对0.272) ，相对于 NDCG@10有11% 的改进。在相似查询稀少的罕见(TAIL)查询中，LADER 仍然优于以前的 SOTA 方法(NDCG@10:0.310 vs. 0.295)。在所有查询中，相对于 NDCG@10，LADER 可以将稠密检索器的性能提高24% -37% ，同时不需要额外的训练，并且预计通过更多的日志可以进一步提高性能。我们的回归分析表明，更频繁的查询、更高的查询相似度熵和更低的文档相似度熵往往更有利于日志增强。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LADER:+Log-Augmented+DEnse+Retrieval+for+Biomedical+Literature+Search)|0|
|[Measuring Service-Level Learning Effects in Search Via Query-Randomized Experiments](https://doi.org/10.1145/3539618.3592020)|Paul Musgrave, Cuize Han, Parth Gupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Service-Level+Learning+Effects+in+Search+Via+Query-Randomized+Experiments)|0|
|[Personalized Dynamic Recommender System for Investors](https://doi.org/10.1145/3539618.3592035)|Takehiro Takayanagi, ChungChi Chen, Kiyoshi Izumi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Dynamic+Recommender+System+for+Investors)|0|
|[Personalized Showcases: Generating Multi-Modal Explanations for Recommendations](https://doi.org/10.1145/3539618.3592036)|An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian John McAuley||Existing explanation models generate only text for recommendations but still struggle to produce diverse contents. In this paper, to further enrich explanations, we propose a new task named personalized showcases, in which we provide both textual and visual information to explain our recommendations. Specifically, we first select a personalized image set that is the most relevant to a user's interest toward a recommended item. Then, natural language explanations are generated accordingly given our selected images. For this new task, we collect a large-scale dataset from Google Local (i.e.,~maps) and construct a high-quality subset for generating multi-modal explanations. We propose a personalized multi-modal framework which can generate diverse and visually-aligned explanations via contrastive learning. Experiments show that our framework benefits from different modalities as inputs, and is able to produce more diverse and expressive explanations compared to previous methods on a variety of evaluation metrics.|现有的解释模型只生成建议的文本，但仍然难以产生不同的内容。在本文中，为了进一步丰富解释，我们提出了一个新的任务称为个性化展示，其中我们提供文本和视觉信息来解释我们的建议。具体来说，我们首先选择与用户对推荐项目的兴趣最相关的个性化图像集。然后，根据所选图像生成自然语言解释。对于这个新任务，我们从 Google Local (即 ~ map)收集了一个大规模的数据集，并构建了一个高质量的子集来生成多模态解释。我们提出了一个个性化的多模态框架，它可以通过对比学习产生多样化和视觉一致的解释。实验表明，我们的框架受益于不同的模式作为输入，并能够产生更多的多样性和表达的解释比以前的方法在各种评价指标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Showcases:+Generating+Multi-Modal+Explanations+for+Recommendations)|0|
|[PersonalTM: Transformer Memory for Personalized Retrieval](https://doi.org/10.1145/3539618.3592037)|Ruixue Lian, Sixing Lu, Clint Solomon, Gustavo Aguilar, Pragaash Ponnusamy, Jialong Han, Chengyuan Ma, Chenlei Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PersonalTM:+Transformer+Memory+for+Personalized+Retrieval)|0|
|[Prediction then Correction: An Abductive Prediction Correction Method for Sequential Recommendation](https://doi.org/10.1145/3539618.3592040)|Yulong Huang, Yang Zhang, Qifan Wang, Chenxu Wang, Fuli Feng||Sequential recommender models typically generate predictions in a single step during testing, without considering additional prediction correction to enhance performance as humans would. To improve the accuracy of these models, some researchers have attempted to simulate human analogical reasoning to correct predictions for testing data by drawing analogies with the prediction errors of similar training data. However, there are inherent gaps between testing and training data, which can make this approach unreliable. To address this issue, we propose an \textit{Abductive Prediction Correction} (APC) framework for sequential recommendation. Our approach simulates abductive reasoning to correct predictions. Specifically, we design an abductive reasoning task that infers the most probable historical interactions from the future interactions predicted by a recommender, and minimizes the discrepancy between the inferred and true historical interactions to adjust the predictions.We perform the abductive inference and adjustment using a reversed sequential model in the forward and backward propagation manner of neural networks. Our APC framework is applicable to various differentiable sequential recommender models. We implement it on three backbone models and demonstrate its effectiveness. We release the code at https://github.com/zyang1580/APC.|顺序推荐模型通常在测试期间在单一步骤中生成预测，而不像人类那样考虑额外的预测修正以提高性能。为了提高这些模型的准确性，一些研究人员尝试模拟人类的类比推理，通过与类似训练数据的预测错误进行类比来修正测试数据的预测。然而，测试和训练数据之间存在固有的差距，这使得这种方法不可靠。为了解决这个问题，我们提出了一个文本{溯因预测修正}(APC)框架的顺序推荐。我们的方法模拟溯因推理来修正预测。具体来说，我们设计了一个溯因推理任务，从推荐者预测的未来相互作用中推断出最可能的历史相互作用，并最小化推断的和真实的历史相互作用之间的差异来调整预测。我们使用逆序模型在神经网络的前向和后向传播方式中执行溯因推理和调整。我们的 APC 框架适用于各种可微顺序推荐模型。我们在三个骨干模型上实现了它，并验证了它的有效性。我们在 https://github.com/zyang1580/apc 公布密码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prediction+then+Correction:+An+Abductive+Prediction+Correction+Method+for+Sequential+Recommendation)|0|
|[Priming and Actions: An Analysis in Conversational Search Systems](https://doi.org/10.1145/3539618.3592041)|Xiao Fu, Aldo Lipani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Priming+and+Actions:+An+Analysis+in+Conversational+Search+Systems)|0|
|[Quantifying Ranker Coverage of Different Query Subspaces](https://doi.org/10.1145/3539618.3592045)|Negar Arabzadeh, Amin Bigdeli, Radin Hamidi Rad, Ebrahim Bagheri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+Ranker+Coverage+of+Different+Query+Subspaces)|0|
|[Sinkhorn Transformations for Single-Query Postprocessing in Text-Video Retrieval](https://doi.org/10.1145/3539618.3592064)|Konstantin Yakovlev, Gregory Polyakov, Ilseyar Alimova, Alexander Podolskiy, Andrey Bout, Sergey Nikolenko, Irina Piontkovskaya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sinkhorn+Transformations+for+Single-Query+Postprocessing+in+Text-Video+Retrieval)|0|
|[SparseEmbed: Learning Sparse Lexical Representations with Contextual Embeddings for Retrieval](https://doi.org/10.1145/3539618.3592065)|Weize Kong, Jeffrey M. Dudek, Cheng Li, Mingyang Zhang, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SparseEmbed:+Learning+Sparse+Lexical+Representations+with+Contextual+Embeddings+for+Retrieval)|0|
|[The Role of Relevance in Fair Ranking](https://doi.org/10.1145/3539618.3591933)|Aparna Balagopalan, Abigail Z. Jacobs, Asia J. Biega||Online platforms mediate access to opportunity: relevance-based rankings create and constrain options by allocating exposure to job openings and job candidates in hiring platforms, or sellers in a marketplace. In order to do so responsibly, these socially consequential systems employ various fairness measures and interventions, many of which seek to allocate exposure based on worthiness. Because these constructs are typically not directly observable, platforms must instead resort to using proxy scores such as relevance and infer them from behavioral signals such as searcher clicks. Yet, it remains an open question whether relevance fulfills its role as such a worthiness score in high-stakes fair rankings.   In this paper, we combine perspectives and tools from the social sciences, information retrieval, and fairness in machine learning to derive a set of desired criteria that relevance scores should satisfy in order to meaningfully guide fairness interventions. We then empirically show that not all of these criteria are met in a case study of relevance inferred from biased user click data. We assess the impact of these violations on the estimated system fairness and analyze whether existing fairness interventions may mitigate the identified issues. Our analyses and results surface the pressing need for new approaches to relevance collection and generation that are suitable for use in fair ranking.|在线平台调节获得机会的途径: 基于相关性的排名通过分配招聘平台中的职位空缺和求职者，或市场中的卖家的曝光度来创造和限制选择。为了负责任地做到这一点，这些社会后果系统采用了各种公平措施和干预措施，其中许多措施试图根据价值分配曝光率。由于这些结构通常不能直接观察到，因此平台必须转而使用相关性等代理评分，并从搜索者点击等行为信号中推断出这些评分。然而，相关性是否能够在高风险的公平排名中发挥其价值得分的作用，仍然是一个悬而未决的问题。在这篇论文中，我们结合了社会科学、信息检索和机器学习中的公平性的观点和工具，得出了一组期望的标准，相关性得分应该满足这些标准，以便有意义地指导公平性干预。然后，我们经验性地表明，并非所有这些标准都符合从有偏见的用户点击数据推断出的相关性的案例研究。我们评估这些违规行为对估计的系统公平性的影响，并分析现有的公平性干预措施是否可以减轻已确定的问题。我们的分析和结果表明，迫切需要新的相关性收集和生成方法，适合在公平排名中使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Role+of+Relevance+in+Fair+Ranking)|0|
|[Towards Building Voice-based Conversational Recommender Systems: Datasets, Potential Solutions and Prospects](https://doi.org/10.1145/3539618.3591876)|Xinghua Qu, Hongyang Liu, Zhu Sun, Xiang Yin, Yew Soon Ong, Lu Lu, Zejun Ma||Conversational recommender systems (CRSs) have become crucial emerging research topics in the field of RSs, thanks to their natural advantages of explicitly acquiring user preferences via interactive conversations and revealing the reasons behind recommendations. However, the majority of current CRSs are text-based, which is less user-friendly and may pose challenges for certain users, such as those with visual impairments or limited writing and reading abilities. Therefore, for the first time, this paper investigates the potential of voice-based CRS (VCRSs) to revolutionize the way users interact with RSs in a natural, intuitive, convenient, and accessible fashion. To support such studies, we create two VCRSs benchmark datasets in the e-commerce and movie domains, after realizing the lack of such datasets through an exhaustive literature review. Specifically, we first empirically verify the benefits and necessity of creating such datasets. Thereafter, we convert the user-item interactions to text-based conversations through the ChatGPT-driven prompts for generating diverse and natural templates, and then synthesize the corresponding audios via the text-to-speech model. Meanwhile, a number of strategies are delicately designed to ensure the naturalness and high quality of voice conversations. On this basis, we further explore the potential solutions and point out possible directions to build end-to-end VCRSs by seamlessly extracting and integrating voice-based inputs, thus delivering performance-enhanced, self-explainable, and user-friendly VCRSs. Our study aims to establish the foundation and motivate further pioneering research in the emerging field of VCRSs. This aligns with the principles of explainable AI and AI for social good, viz., utilizing technology's potential to create a fair, sustainable, and just world.|会话推荐系统(CRS)由于其通过交互式对话获取用户偏好并揭示推荐背后的原因的天然优势，已经成为 RSS 领域新兴的重要研究课题。然而，目前大多数 CRS 是基于文本的，不太方便用户，可能对某些用户构成挑战，例如那些有视力障碍或写作和阅读能力有限的用户。因此，本文首次研究了基于语音的 CRS (VCRS)的潜力，它可以彻底改变用户以一种自然、直观、方便和可访问的方式与 RSS 交互的方式。为了支持这样的研究，我们通过详尽的文献回顾，在电子商务和电影领域创建了两个 VCRS 基准数据集。具体来说，我们首先通过经验验证创建这样的数据集的好处和必要性。之后，我们通过 ChatGPT-driven 提示将用户项目的交互转换为基于文本的对话，生成多样化的自然模板，然后通过文本到语音模型合成相应的音频。同时，为了保证语音对话的自然性和高质量，我们精心设计了一系列的语音对话策略。在此基础上，我们进一步探索了潜在的解决方案，并指出了通过无缝提取和整合基于语音的输入来构建端到端录像机的可能方向，从而提供性能增强、自我解释和用户友好的录像机。我们的研究旨在为 VCRS 这一新兴领域的进一步开拓性研究奠定基础。这符合可解释的人工智能和人工智能的社会公益原则，也就是说，利用技术的潜力来创造一个公平、可持续和公正的世界。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Building+Voice-based+Conversational+Recommender+Systems:+Datasets,+Potential+Solutions+and+Prospects)|0|
|[Towards Explainable Conversational Recommender Systems](https://doi.org/10.1145/3539618.3591884)|Shuyu Guo, Shuo Zhang, Weiwei Sun, Pengjie Ren, Zhumin Chen, Zhaochun Ren||Explanations in conventional recommender systems have demonstrated benefits in helping the user understand the rationality of the recommendations and improving the system's efficiency, transparency, and trustworthiness. In the conversational environment, multiple contextualized explanations need to be generated, which poses further challenges for explanations. To better measure explainability in conversational recommender systems (CRS), we propose ten evaluation perspectives based on concepts from conventional recommender systems together with the characteristics of CRS. We assess five existing CRS benchmark datasets using these metrics and observe the necessity of improving the explanation quality of CRS. To achieve this, we conduct manual and automatic approaches to extend these dialogues and construct a new CRS dataset, namely Explainable Recommendation Dialogues (E-ReDial). It includes 756 dialogues with over 2,000 high-quality rewritten explanations. We compare two baseline approaches to perform explanation generation based on E-ReDial. Experimental results suggest that models trained on E-ReDial can significantly improve explainability while introducing knowledge into the models can further improve the performance. GPT-3 in the in-context learning setting can generate more realistic and diverse movie descriptions. In contrast, T5 training on E-ReDial can better generate clear reasons for recommendations based on user preferences. E-ReDial is available at https://github.com/Superbooming/E-ReDial.|传统推荐系统中的解释已经证明了在帮助用户理解推荐的合理性和提高系统的效率、透明度和可信度方面的好处。在会话环境中，需要产生多种语境化的解释，这对解释提出了进一步的挑战。为了更好地衡量会话推荐系统(CRS)的可解释性，结合 CRS 的特点，从传统推荐系统的概念出发，提出了10种评价视角。我们使用这些指标评估了5个现有的 CRS 基准数据集，并观察了提高 CRS 解释质量的必要性。为了实现这一目标，我们采用手动和自动的方法来扩展这些对话，并构建一个新的 CRS 数据集，即可解释的建议对话(E-ReDial)。它包括756个对话，超过2000个高质量的改写解释。我们比较了两种基线方法来执行基于 E-ReDial 的解释生成。实验结果表明，在 E-ReDial 上训练的模型可以显著提高模型的可解释性，而在模型中引入知识可以进一步提高模型的性能。GPT-3在上下文学习环境中可以产生更加真实和多样化的电影描述。相比之下，关于 E-ReDial 的 T5培训可以更好地根据用户偏好为推荐产生明确的理由。电子重拨可在 https://github.com/superbooming/E-ReDial 使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Explainable+Conversational+Recommender+Systems)|0|
|[MG-ShopDial: A Multi-Goal Conversational Dataset for e-Commerce](https://doi.org/10.1145/3539618.3591883)|Nolwenn Bernard, Krisztian Balog||Conversational systems can be particularly effective in supporting complex information seeking scenarios with evolving information needs. Finding the right products on an e-commerce platform is one such scenario, where a conversational agent would need to be able to provide search capabilities over the item catalog, understand and make recommendations based on the user's preferences, and answer a range of questions related to items and their usage. Yet, existing conversational datasets do not fully support the idea of mixing different conversational goals (i.e., search, recommendation, and question answering) and instead focus on a single goal. To address this, we introduce MG-ShopDial: a dataset of conversations mixing different goals in the domain of e-commerce. Specifically, we make the following contributions. First, we develop a coached human-human data collection protocol where each dialogue participant is given a set of instructions, instead of a specific script or answers to choose from. Second, we implement a data collection tool to facilitate the collection of multi-goal conversations via a web chat interface, using the above protocol. Third, we create the MG-ShopDial collection, which contains 64 high-quality dialogues with a total of 2,196 utterances for e-commerce scenarios of varying complexity. The dataset is additionally annotated with both intents and goals on the utterance level. Finally, we present an analysis of this dataset and identify multi-goal conversational patterns.|对话系统可以特别有效地支持不断变化的信息需求的复杂信息搜索情景。在电子商务平台上寻找合适的产品就是这样一种情况，会话代理需要能够在商品目录上提供搜索功能，理解并根据用户的偏好提出建议，并回答一系列与商品及其使用相关的问题。然而，现有的会话数据集并不完全支持混合不同会话目标(即搜索、推荐和问答)的想法，而是集中在一个单一的目标上。为了解决这个问题，我们介绍了 MG-ShopDial: 一个混合了电子商务领域不同目标的会话数据集。具体来说，我们做出了以下贡献。首先，我们开发一个训练有素的人类-人类数据收集协议，其中每个对话参与者被给予一组指令，而不是一个特定的脚本或答案选择。其次，利用上述协议实现了一个数据收集工具，通过网络聊天接口实现了多目标会话的收集。第三，我们创建 MG-ShopDial 集合，其中包含64个高质量对话，总共有2,196个用于不同复杂度的电子商务场景的语句。此外，数据集还在语句级别上用意图和目标进行了注释。最后，我们对该数据集进行了分析，并识别了多目标会话模式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MG-ShopDial:+A+Multi-Goal+Conversational+Dataset+for+e-Commerce)|0|
|[The Archive Query Log: Mining Millions of Search Result Pages of Hundreds of Search Engines from 25 Years of Web Archives](https://doi.org/10.1145/3539618.3591890)|Jan Heinrich Reimer, Sebastian Schmidt, Maik Fröbe, Lukas Gienapp, Harrisen Scells, Benno Stein, Matthias Hagen, Martin Potthast||The Archive Query Log (AQL) is a previously unused, comprehensive query log collected at the Internet Archive over the last 25 years. Its first version includes 356 million queries, 166 million search result pages, and 1.7 billion search results across 550 search providers. Although many query logs have been studied in the literature, the search providers that own them generally do not publish their logs to protect user privacy and vital business data. Of the few query logs publicly available, none combines size, scope, and diversity. The AQL is the first to do so, enabling research on new retrieval models and (diachronic) search engine analyses. Provided in a privacy-preserving manner, it promotes open research as well as more transparency and accountability in the search industry.|存档查询日志(Archive Query Log，AQL)是过去25年中在互联网档案馆收集的一个以前没有使用过的综合查询日志。它的第一个版本包括3.56亿个查询，1.66亿个搜索结果页面，以及来自550个搜索提供商的17亿个搜索结果。尽管文献中研究了许多查询日志，但拥有这些日志的搜索提供商通常不会发布日志，以保护用户隐私和重要业务数据。在少数几个公开可用的查询日志中，没有一个包含大小、范围和多样性。AQL 是第一个这样做的机构，它能够研究新的检索模型和(历时的)搜索引擎分析。以一种保护隐私的方式提供，它促进了开放的研究，以及在搜索行业中更多的透明度和问责制。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Archive+Query+Log:+Mining+Millions+of+Search+Result+Pages+of+Hundreds+of+Search+Engines+from+25+Years+of+Web+Archives)|0|
|[DECAF: A Modular and Extensible Conversational Search Framework](https://doi.org/10.1145/3539618.3591913)|Marco Alessio, Guglielmo Faggioli, Nicola Ferro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DECAF:+A+Modular+and+Extensible+Conversational+Search+Framework)|0|
|[LongEval-Retrieval: French-English Dynamic Test Collection for Continuous Web Search Evaluation](https://doi.org/10.1145/3539618.3591921)|Petra Galuscáková, Romain Deveaud, Gabriela González Sáez, Philippe Mulhem, Lorraine Goeuriot, Florina Piroi, Martin Popel||LongEval-Retrieval is a Web document retrieval benchmark that focuses on continuous retrieval evaluation. This test collection is intended to be used to study the temporal persistence of Information Retrieval systems and will be used as the test collection in the Longitudinal Evaluation of Model Performance Track (LongEval) at CLEF 2023. This benchmark simulates an evolving information system environment - such as the one a Web search engine operates in - where the document collection, the query distribution, and relevance all move continuously, while following the Cranfield paradigm for offline evaluation. To do that, we introduce the concept of a dynamic test collection that is composed of successive sub-collections each representing the state of an information system at a given time step. In LongEval-Retrieval, each sub-collection contains a set of queries, documents, and soft relevance assessments built from click models. The data comes from Qwant, a privacy-preserving Web search engine that primarily focuses on the French market. LongEval-Retrieval also provides a 'mirror' collection: it is initially constructed in the French language to benefit from the majority of Qwant's traffic, before being translated to English. This paper presents the creation process of LongEval-Retrieval and provides baseline runs and analysis.|LongEval-Retrieval 是一个关注于持续检索评估的 Web 文献检索基准。这个测试集旨在用于研究信息检索系统的时间持续性，并将作为 CLEF 2023年模型性能跟踪纵向评估(LongEval)的测试集。这个基准测试模拟了一个不断发展的信息系统环境——比如 Web 搜索引擎运行的环境——其中文档收集、查询分发和相关性都在不断变化，同时遵循 Cranfield 离线评估范例。为此，我们引入了动态测试集合的概念，该集合由连续的子集合组成，每个子集合表示给定时间步骤中信息系统的状态。在 LongEval-Retrieval，每个子集包含一组查询、文档和基于点击模型的软相关性评估。这些数据来自 Qwant，一个主要关注法国市场的保护隐私的网络搜索引擎。LongEval-Retrieval 还提供了一个“镜像”集合: 它最初是用法语构建的，以便从 Qwant 的大部分流量中受益，然后才被翻译成英语。本文介绍了 LongEval-Retrieval 的创建过程，并提供了基线运行和分析。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LongEval-Retrieval:+French-English+Dynamic+Test+Collection+for+Continuous+Web+Search+Evaluation)|0|
|[OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit](https://doi.org/10.1145/3539618.3591813)|Shi Yu, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OpenMatch-v2:+An+All-in-one+Multi-Modality+PLM-based+Information+Retrieval+Toolkit)|0|
|[Bootstrapping Query Suggestions in Spotify's Instant Search System](https://doi.org/10.1145/3539618.3591827)|Alva Liu, Humberto Jesús Corona Pampin, Enrico Palumbo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bootstrapping+Query+Suggestions+in+Spotify's+Instant+Search+System)|0|
|[Long-Form Information Retrieval for Enterprise Matchmaking](https://doi.org/10.1145/3539618.3591833)|Pengyuan Li, GuangJie Ren, Anna Lisa Gentile, Chad DeLuca, Daniel Tan, Sandeep Gopisetty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long-Form+Information+Retrieval+for+Enterprise+Matchmaking)|0|
|[Facebook Content Search: Efficient and Effective Adapting Search on A Large Scale](https://doi.org/10.1145/3539618.3591840)|Xiangyu Niu, YuWei Wu, Xiao Lu, Gautam Nagpal, Philip Pronin, Kecheng Hao, Zhen Liao, Guangdeng Liao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Facebook+Content+Search:+Efficient+and+Effective+Adapting+Search+on+A+Large+Scale)|0|
|[Personalized Stock Recommendation with Investors' Attention and Contextual Information](https://doi.org/10.1145/3539618.3591850)|Takehiro Takayanagi, Kiyoshi Izumi, Atsuo Kato, Naoyuki Tsunedomi, Yukina Abe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Stock+Recommendation+with+Investors'+Attention+and+Contextual+Information)|0|
|[GreenSeq: Automatic Design of Green Networks for Sequential Recommendation Systems](https://doi.org/10.1145/3539618.3591855)|Yankun Ren, Xinxing Yang, Xingyu Lu, Longfei Li, Jun Zhou, Jinjie Gu, Guannan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GreenSeq:+Automatic+Design+of+Green+Networks+for+Sequential+Recommendation+Systems)|0|
|[Conversational Bibliographic Search](https://doi.org/10.1145/3539618.3591789)|Markus Nilles||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversational+Bibliographic+Search)|0|
|[Aligning Distillation For Cold-start Item Recommendation](https://doi.org/10.1145/3539618.3591732)|Feiran Huang, Zefan Wang, Xiao Huang, Yufeng Qian, Zhetao Li, Hao Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Distillation+For+Cold-start+Item+Recommendation)|0|
|[M2EU: Meta Learning for Cold-start Recommendation via Enhancing User Preference Estimation](https://doi.org/10.1145/3539618.3591719)|Zhenchao Wu, Xiao Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M2EU:+Meta+Learning+for+Cold-start+Recommendation+via+Enhancing+User+Preference+Estimation)|0|
|[Exploration of Unranked Items in Safe Online Learning to Re-Rank](https://doi.org/10.1145/3539618.3591985)|Hiroaki Shiino, Kaito Ariu, Kenshi Abe, Riku Togashi||Bandit algorithms for online learning to rank (OLTR) problems often aim to maximize long-term revenue by utilizing user feedback. From a practical point of view, however, such algorithms have a high risk of hurting user experience due to their aggressive exploration. Thus, there has been a rising demand for safe exploration in recent years. One approach to safe exploration is to gradually enhance the quality of an original ranking that is already guaranteed acceptable quality. In this paper, we propose a safe OLTR algorithm that efficiently exchanges one of the items in the current ranking with an item outside the ranking (i.e., an unranked item) to perform exploration. We select an unranked item optimistically to explore based on Kullback-Leibler upper confidence bounds (KL-UCB) and safely re-rank the items including the selected one. Through experiments, we demonstrate that the proposed algorithm improves long-term regret from baselines without any safety violation.|用于在线学习排序(OLTR)问题的盗贼算法通常旨在利用用户反馈使长期收益最大化。然而，从实际的角度来看，这样的算法由于其积极的探索而有很高的风险损害用户体验。因此，近年来对安全勘探的需求不断增长。安全勘探的一种方法是逐步提高已经保证可接受质量的原始排名的质量。本文提出了一种安全的 OLTR 算法，该算法可以有效地将当前排名中的一个项目与排名之外的一个项目(即未排名的项目)进行交换，从而进行探索。我们选择一个未排序的项目乐观地探索基于 Kullback-Leibler 上置信界(KL-UCB)和安全重新排序的项目，包括选定的一个。实验结果表明，该算法在不违反安全约束的情况下，提高了基线长期后悔率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploration+of+Unranked+Items+in+Safe+Online+Learning+to+Re-Rank)|0|
|[Mining Interest Trends and Adaptively Assigning Sample Weight for Session-based Recommendation](https://doi.org/10.1145/3539618.3592021)|Kai Ouyang, Xianghong Xu, Miaoxin Chen, Zuotong Xie, HaiTao Zheng, Shuangyong Song, Yu Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Interest+Trends+and+Adaptively+Assigning+Sample+Weight+for+Session-based+Recommendation)|0|
|[Unbiased Pairwise Learning from Implicit Feedback for Recommender Systems without Biased Variance Control](https://doi.org/10.1145/3539618.3592077)|Yi Ren, Hongyan Tang, Jiangpeng Rong, Siwen Zhu||Generally speaking, the model training for recommender systems can be based on two types of data, namely explicit feedback and implicit feedback. Moreover, because of its general availability, we see wide adoption of implicit feedback data, such as click signal. There are mainly two challenges for the application of implicit feedback. First, implicit data just includes positive feedback. Therefore, we are not sure whether the non-interacted items are really negative or positive but not displayed to the corresponding user. Moreover, the relevance of rare items is usually underestimated since much fewer positive feedback of rare items is collected compared with popular ones. To tackle such difficulties, both pointwise and pairwise solutions are proposed before for unbiased relevance learning. As pairwise learning suits well for the ranking tasks, the previously proposed unbiased pairwise learning algorithm already achieves state-of-the-art performance. Nonetheless, the existing unbiased pairwise learning method suffers from high variance. To get satisfactory performance, non-negative estimator is utilized for practical variance control but introduces additional bias. In this work, we propose an unbiased pairwise learning method, named UPL, with much lower variance to learn a truly unbiased recommender model. Extensive offline experiments on real world datasets and online A/B testing demonstrate the superior performance of our proposed method.|一般来说，推荐系统的模型训练可以基于两种类型的数据，即显式反馈和隐式反馈。此外，由于它的普遍可用性，我们看到了隐式反馈数据的广泛采用，如点击信号。内隐反馈的应用主要面临两个挑战。首先，隐式数据只包括正反馈。因此，我们不能确定未交互的项目是否真的是负面的还是正面的，但是没有显示给对应的用户。此外，稀有物品的相关性通常被低估，因为与流行物品相比，收集到的稀有物品的正面反馈要少得多。为了克服这些困难，本文提出了点对式和成对式的无偏相关学习解决方案。由于成对学习很适合排序任务，因此提出的无偏成对学习算法已经取得了很好的性能。然而，现有的无偏成对学习方法存在较大的方差。为了获得令人满意的性能，在实际方差控制中采用了非负估计，但引入了附加偏差。在这项工作中，我们提出了一个无偏的成对学习方法，称为 UPL，与更低的方差学习一个真正无偏的推荐模型。在现实世界数据集上的大量离线实验和在线 A/B 测试证明了我们提出的方法的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unbiased+Pairwise+Learning+from+Implicit+Feedback+for+Recommender+Systems+without+Biased+Variance+Control)|0|
|[Using Entropy for Group Sampling in Pairwise Ranking from implicit feedback](https://doi.org/10.1145/3539618.3592084)|Yujie Chen, Runlong Yu, Qi Liu, Enhong Chen, Zhenya Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+Entropy+for+Group+Sampling+in+Pairwise+Ranking+from+implicit+feedback)|0|
|[Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset](https://doi.org/10.1145/3539618.3591881)|Arun Tejasvi Chaganty, Megan Leszczynski, Shu Zhang, Ravi Ganti, Krisztian Balog, Filip Radlinski||Users in consumption domains, like music, are often able to more efficiently provide preferences over a set of items (e.g. a playlist or radio) than over single items (e.g. songs). Unfortunately, this is an underexplored area of research, with most existing recommendation systems limited to understanding preferences over single items. Curating an item set exponentiates the search space that recommender systems must consider (all subsets of items!): this motivates conversational approaches-where users explicitly state or refine their preferences and systems elicit preferences in natural language-as an efficient way to understand user needs. We call this task conversational item set curation and present a novel data collection methodology that efficiently collects realistic preferences about item sets in a conversational setting by observing both item-level and set-level feedback. We apply this methodology to music recommendation to build the Conversational Playlist Curation Dataset (CPCD), where we show that it leads raters to express preferences that would not be otherwise expressed. Finally, we propose a wide range of conversational retrieval models as baselines for this task and evaluate them on the dataset.|消费领域的用户，比如音乐，往往能够更有效地提供对一组项目(如播放列表或收音机)的偏好，而不是对单个项目(如歌曲)的偏好。不幸的是，这是一个探索不足的研究领域，大多数现有的推荐系统仅限于理解对单个项目的偏好。管理一个项目集可以指数化推荐系统必须考虑的搜索空间(项目的所有子集!): 这激发了会话方法——用户明确地陈述或改进他们的偏好，系统用自然语言引出偏好——作为理解用户需求的有效方法。我们把这个任务称为会话项目集管理，并提出了一种新的数据收集方法，该方法通过观察项目级和集合级反馈，有效地收集了会话环境中关于项目集的现实偏好。我们将这种方法应用于音乐推荐，以建立对话播放列表策划数据集(CPCD) ，在这里我们表明，它导致评分者表达不会以其他方式表达的偏好。最后，我们提出了广泛的会话检索模型作为这项任务的基线，并在数据集上对它们进行评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Single+Items:+Exploring+User+Preferences+in+Item+Sets+with+the+Conversational+Playlist+Curation+Dataset)|0|
|[On the Impact of Outlier Bias on User Clicks](https://doi.org/10.1145/3539618.3591745)|Fatemeh Sarvi, Ali Vardasbi, Mohammad Aliannejadi, Sebastian Schelter, Maarten de Rijke||User interaction data is an important source of supervision in counterfactual learning to rank (CLTR). Such data suffers from presentation bias. Much work in unbiased learning to rank (ULTR) focuses on position bias, i.e., items at higher ranks are more likely to be examined and clicked. Inter-item dependencies also influence examination probabilities, with outlier items in a ranking as an important example. Outliers are defined as items that observably deviate from the rest and therefore stand out in the ranking. In this paper, we identify and introduce the bias brought about by outlier items: users tend to click more on outlier items and their close neighbors. To this end, we first conduct a controlled experiment to study the effect of outliers on user clicks. Next, to examine whether the findings from our controlled experiment generalize to naturalistic situations, we explore real-world click logs from an e-commerce platform. We show that, in both scenarios, users tend to click significantly more on outlier items than on non-outlier items in the same rankings. We show that this tendency holds for all positions, i.e., for any specific position, an item receives more interactions when presented as an outlier as opposed to a non-outlier item. We conclude from our analysis that the effect of outliers on clicks is a type of bias that should be addressed in ULTR. We therefore propose an outlier-aware click model that accounts for both outlier and position bias, called outlier-aware position-based model ( OPBM). We estimate click propensities based on OPBM ; through extensive experiments performed on both real-world e-commerce data and semi-synthetic data, we verify the effectiveness of our outlier-aware click model. Our results show the superiority of OPBM against baselines in terms of ranking performance and true relevance estimation.|用户交互数据是反事实学习排序(CLTR)的重要监督来源。这些数据存在表达偏差。无偏学习排名(ULTR)的许多工作都集中在位置偏差上，也就是说，排名较高的项目更容易被检查和点击。项目间的依赖性也会影响考试的概率，排名中的异常项目就是一个重要的例子。异常值被定义为与其他项目明显不同的项目，因此在排名中脱颖而出。在本文中，我们识别并介绍了离群项目带来的偏差: 用户往往点击更多的离群项目和他们的近邻。为此，我们首先进行了一个对照实验来研究离群值对用户点击的影响。接下来，为了检验我们对照实验的结果是否概括为自然情境，我们从一个电子商务平台探索了现实世界的点击日志。我们发现，在这两种情况下，用户在同一排名中点击离群数据项的次数明显多于非离群数据项。我们表明，这种趋势适用于所有的位置，也就是说，对于任何特定的位置，一个项目接受更多的交互作用时，表现为一个异常点，而不是一个非异常点的项目。我们从我们的分析得出结论，异常值对点击的影响是一种类型的偏见，应该在 ULTR 中解决。因此，我们提出了一种异常点击模型，这种模型同时考虑了异常点和位置偏差，称为异常点位置模型(OPBM)。我们基于 OPBM 估计点击倾向; 通过在现实电子商务数据和半合成数据上进行的大量实验，我们验证了我们的离群点击模型的有效性。我们的研究结果显示了 OPBM 在排序性能和真实相关性估计方面相对于基线的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Impact+of+Outlier+Bias+on+User+Clicks)|0|
|[Distilling Semantic Concept Embeddings from Contrastively Fine-Tuned Language Models](https://doi.org/10.1145/3539618.3591667)|Na Li, Hanane Kteich, Zied Bouraoui, Steven Schockaert||Learning vectors that capture the meaning of concepts remains a fundamental challenge. Somewhat surprisingly, perhaps, pre-trained language models have thus far only enabled modest improvements to the quality of such concept embeddings. Current strategies for using language models typically represent a concept by averaging the contextualised representations of its mentions in some corpus. This is potentially sub-optimal for at least two reasons. First, contextualised word vectors have an unusual geometry, which hampers downstream tasks. Second, concept embeddings should capture the semantic properties of concepts, whereas contextualised word vectors are also affected by other factors. To address these issues, we propose two contrastive learning strategies, based on the view that whenever two sentences reveal similar properties, the corresponding contextualised vectors should also be similar. One strategy is fully unsupervised, estimating the properties which are expressed in a sentence from the neighbourhood structure of the contextualised word embeddings. The second strategy instead relies on a distant supervision signal from ConceptNet. Our experimental results show that the resulting vectors substantially outperform existing concept embeddings in predicting the semantic properties of concepts, with the ConceptNet-based strategy achieving the best results. These findings are furthermore confirmed in a clustering task and in the downstream task of ontology completion.|捕捉概念含义的学习向量仍然是一个基本的挑战。也许有些令人惊讶的是，事先训练好的语言模型到目前为止只能适度地提高这种概念嵌入的质量。目前使用语言模型的策略通常是通过平均语料库中提及的语境化表示来表示一个概念。这可能是次优的，至少有两个原因。首先，上下文相关的词向量有一个不寻常的几何形状，这阻碍了下游任务。其次，概念嵌入应该捕捉概念的语义属性，而语境化的词向量也受到其他因素的影响。为了解决这些问题，我们提出了两种对比学习策略，基于这样的观点: 当两个句子显示出相似的属性时，相应的上下文化向量也应该是相似的。一种策略是完全无监督的，根据上下文化词嵌入的邻域结构估计句子中表达的属性。第二种策略则依赖于概念网络发出的远程监控信号。我们的实验结果表明，所得到的向量在预测概念的语义属性方面大大优于现有的概念嵌入，基于概念网的策略取得了最好的效果。这些发现在本体完成的聚类任务和下游任务中得到了进一步的证实。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Semantic+Concept+Embeddings+from+Contrastively+Fine-Tuned+Language+Models)|0|
|[Learning Fine-grained User Interests for Micro-video Recommendation](https://doi.org/10.1145/3539618.3591713)|Yu Shang, Chen Gao, Jiansheng Chen, Depeng Jin, Meng Wang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Fine-grained+User+Interests+for+Micro-video+Recommendation)|0|
|[Improving Implicit Feedback-Based Recommendation through Multi-Behavior Alignment](https://doi.org/10.1145/3539618.3591697)|Xin Xin, Xiangyuan Liu, Hanbing Wang, Pengjie Ren, Zhumin Chen, Jiahuan Lei, Xinlei Shi, Hengliang Luo, Joemon M. Jose, Maarten de Rijke, Zhaochun Ren||Recommender systems that learn from implicit feedback often use large volumes of a single type of implicit user feedback, such as clicks, to enhance the prediction of sparse target behavior such as purchases. Using multiple types of implicit user feedback for such target behavior prediction purposes is still an open question. Existing studies that attempted to learn from multiple types of user behavior often fail to: (i) learn universal and accurate user preferences from different behavioral data distributions, and (ii) overcome the noise and bias in observed implicit user feedback. To address the above problems, we propose multi-behavior alignment (MBA), a novel recommendation framework that learns from implicit feedback by using multiple types of behavioral data. We conjecture that multiple types of behavior from the same user (e.g., clicks and purchases) should reflect similar preferences of that user. To this end, we regard the underlying universal user preferences as a latent variable. The variable is inferred by maximizing the likelihood of multiple observed behavioral data distributions and, at the same time, minimizing the Kullback-Leibler divergence (KL-divergence) between user models learned from auxiliary behavior (such as clicks or views) and the target behavior separately. MBA infers universal user preferences from multi-behavior data and performs data denoising to enable effective knowledge transfer. We conduct experiments on three datasets, including a dataset collected from an operational e-commerce platform. Empirical results demonstrate the effectiveness of our proposed method in utilizing multiple types of behavioral data to enhance the prediction of the target behavior.|从隐式反馈中学习的推荐系统经常使用大量的单一类型的隐式用户反馈，如点击，以增强对稀疏目标行为(如购买)的预测。使用多种类型的隐式用户反馈来预测目标行为仍然是一个悬而未决的问题。现有的试图从多种类型的用户行为中学习的研究往往失败: (i)从不同的行为数据分布中学习普遍和准确的用户偏好，(ii)克服观察到的隐性用户反馈中的噪音和偏见。为了解决上述问题，我们提出了多行为协调(MBA) ，一个新的推荐框架，学习的内隐反馈使用多种类型的行为数据。我们推测来自同一用户的多种类型的行为(例如点击和购买)应该反映该用户的相似偏好。为此，我们认为潜在的通用用户偏好是一个潜在的变量。通过最大化多个观察到的行为数据分布的可能性来推断变量，同时最小化从辅助行为(如点击或视图)学习的用户模型与目标行为之间的 Kullback-Leibler 散度(KL- 散度)。MBA 从多行为数据中推断出普遍的用户偏好，并对数据进行去噪以实现有效的知识转移。我们在三个数据集上进行实验，包括从一个操作性电子商务平台收集的数据集。实证结果表明，该方法能够有效地利用多种类型的行为数据来提高对目标行为的预测能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Implicit+Feedback-Based+Recommendation+through+Multi-Behavior+Alignment)|0|
|[Not Just Skipping: Understanding the Effect of Sponsored Content on Users' Decision-Making in Online Health Search](https://doi.org/10.1145/3539618.3591744)|Anat Hashavit, Hongning Wang, Tamar Stern, Sarit Kraus||Advertisements (ads) are an innate part of search engine business models. Advertisers are willing to pay search engines to promote their content to a prominent position in the search result page (SERP). This raises concerns about the search engine manipulation effect (SEME): the opinions of users can be influenced by the way search results are presented. In this work, we investigate the connection between SEME and sponsored content in the health domain. We conduct a series of user studies in which participants need to evaluate the effectiveness of different non-prescription natural remedies for various medical conditions. We present participants SERPs with different intentionally created biases towards certain viewpoints, with or without sponsored content, and ask them to evaluate the effectiveness of the treatment only based on the information presented to them. We investigate two types of sponsored content: 1. Direct marketing ads that directly market the product without expressing an opinion about its effectiveness, and 2. Indirect marketing ads that explicitly advocate the product's effectiveness on the condition in the query. Our results reveal a significant difference between the influence on users from these two ad types. Though direct marketing ads are mostly skipped by users, they can tilt users decision making towards more positive viewpoints. Indirect marketing ads affect both the users' examination behaviour and their perception of the treatment's effectiveness. We further discover that the contrast between the indirect marketing ads and the viewpoint presented in the organic search results plays an important role in users' decision-making. When the contrast is high, users exhibit a strong preference towards a negative viewpoint, and when the contrast is low or none, users exhibit preference towards a more positive viewpoint.|广告是搜索引擎商业模式固有的一部分。广告商愿意支付搜索引擎，以促进其内容在搜索结果页面(SERP)的突出位置。这引起了人们对搜索引擎操作效果(SEME)的关注: 用户的意见可能会受到搜索结果呈现方式的影响。在这项工作中，我们调查了健康领域中 SEME 和赞助内容之间的关系。我们进行了一系列的用户研究，其中参与者需要评估不同的非处方自然疗法对各种医疗条件的有效性。我们向参与者展示了不同的有意制造的偏向于某些观点的 SERP，有或没有赞助内容，并要求他们仅仅根据提供给他们的信息来评估治疗的有效性。我们调查了两种类型的赞助内容: 1。直接营销广告，直接营销的产品，而不表达对其有效性的意见，和2。间接营销广告，明确提倡在查询条件下产品的有效性。我们的研究结果揭示了这两种广告类型对用户的影响存在显著差异。虽然直接营销广告大多被用户跳过，但它们可以使用户的决策倾向于更积极的观点。间接营销广告既影响用户的考试行为，也影响他们对治疗效果的感知。我们进一步发现，间接营销广告与有机搜索结果中的观点之间的对比在用户的决策中起着重要作用。当对比度较高时，用户表现出对负面观点的强烈偏好，当对比度较低或没有对比度时，用户表现出对更积极的观点的偏好。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+Just+Skipping:+Understanding+the+Effect+of+Sponsored+Content+on+Users'+Decision-Making+in+Online+Health+Search)|0|
|[A Preference Learning Decoupling Framework for User Cold-Start Recommendation](https://doi.org/10.1145/3539618.3591627)|Chunyang Wang, Yanmin Zhu, Aixin Sun, Zhaobo Wang, Ke Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Preference+Learning+Decoupling+Framework+for+User+Cold-Start+Recommendation)|0|
|[Online Conversion Rate Prediction via Neural Satellite Networks in Delayed Feedback Advertising](https://doi.org/10.1145/3539618.3591747)|Qiming Liu, Haoming Li, Xiang Ao, Yuyao Guo, Zhihong Dong, Ruobing Zhang, Qiong Chen, Jianfeng Tong, Qing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Conversion+Rate+Prediction+via+Neural+Satellite+Networks+in+Delayed+Feedback+Advertising)|0|
|[M2GNN: Metapath and Multi-interest Aggregated Graph Neural Network for Tag-based Cross-domain Recommendation](https://doi.org/10.1145/3539618.3591720)|Zepeng Huai, Yuji Yang, Mengdi Zhang, Zhongyi Zhang, Yichun Li, Wei Wu||Cross-domain recommendation (CDR) is an effective way to alleviate the data sparsity problem. Content-based CDR is one of the most promising branches since most kinds of products can be described by a piece of text, especially when cold-start users or items have few interactions. However, two vital issues are still under-explored: (1) From the content modeling perspective, sufficient long-text descriptions are usually scarce in a real recommender system, more often the light-weight textual features, such as a few keywords or tags, are more accessible, which is improperly modeled by existing methods. (2) From the CDR perspective, not all inter-domain interests are helpful to infer intra-domain interests. Caused by domain-specific features, there are part of signals benefiting for recommendation in the source domain but harmful for that in the target domain. Therefore, how to distill useful interests is crucial. To tackle the above two problems, we propose a metapath and multi-interest aggregated graph neural network (M2GNN). Specifically, to model the tag-based contents, we construct a heterogeneous information network to hold the semantic relatedness between users, items, and tags in all domains. The metapath schema is predefined according to domain-specific knowledge, with one metapath for one domain. User representations are learned by GNN with a hierarchical aggregation framework, where the intra-metapath aggregation firstly filters out trivial tags and the inter-metapath aggregation further filters out useless interests. Offline experiments and online A/B tests demonstrate that M2GNN achieves significant improvements over the state-of-the-art methods and current industrial recommender system in Dianping, respectively. Further analysis shows that M2GNN offers an interpretable recommendation.|跨域推荐(CDR)是解决数据稀疏问题的有效方法。基于内容的 CDR 是最有前途的分支之一，因为大多数类型的产品都可以用文本描述，特别是当冷启动用户或项目几乎没有交互时。然而，有两个重要的问题仍然没有得到充分的探索: (1)从内容建模的角度来看，在真实的推荐系统中，充足的长文本描述通常是稀缺的，更常见的是轻量级的文本特征，如一些关键字或标签，是更容易获得的，这是不适当的建模现有方法。(2)从 CDR 的角度来看，并非所有域间利益都有助于推断域内利益。由于特定于领域的特性，有一部分信号在源域中有利于推荐，但在目标域中有害于推荐。因此，如何提取有用的利益至关重要。为了解决上述两个问题，我们提出了一种元路径和多兴趣聚合图神经网络(M2GNN)。具体来说，为了对基于标签的内容进行建模，我们构建了一个异构的信息网络来保持所有领域中用户、项目和标签之间的语义关系。元路径模式是根据特定于领域的知识预定义的，对于一个领域只有一个元路径。GNN 利用层次聚合框架学习用户表示，其中元路径内聚合首先过滤掉平凡的标签，元路径间聚合进一步过滤掉无用的兴趣。离线实验和在线 A/B 测试表明，M2GNN 在最先进的方法和 Dianping 目前的工业推荐系统上分别取得了显著的改进。进一步的分析表明，M2GNN 提供了一个可解释的建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M2GNN:+Metapath+and+Multi-interest+Aggregated+Graph+Neural+Network+for+Tag-based+Cross-domain+Recommendation)|0|
|[Beyond the Overlapping Users: Cross-Domain Recommendation via Adaptive Anchor Link Learning](https://doi.org/10.1145/3539618.3591642)|Yi Zhao, Chaozhuo Li, Jiquan Peng, Xiaohan Fang, Feiran Huang, Senzhang Wang, Xing Xie, Jibing Gong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+the+Overlapping+Users:+Cross-Domain+Recommendation+via+Adaptive+Anchor+Link+Learning)|0|
|[Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures](https://doi.org/10.1145/3539618.3591722)|Wei Yuan, Quoc Viet Hung Nguyen, Tieke He, Liang Chen, Hongzhi Yin||Federated Recommender Systems (FedRecs) are considered privacy-preserving techniques to collaboratively learn a recommendation model without sharing user data. Since all participants can directly influence the systems by uploading gradients, FedRecs are vulnerable to poisoning attacks of malicious clients. However, most existing poisoning attacks on FedRecs are either based on some prior knowledge or with less effectiveness. To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-$K$ recommendation without relying on any prior knowledge. Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products. We conduct extensive experiments with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on two real-world recommendation datasets. The experimental results show that our attack can significantly improve the exposure rate of unpopular target items with extremely fewer malicious users and fewer global epochs than state-of-the-art attacks. In addition to disclosing the security hole, we design a novel countermeasure for poisoning attacks on FedRecs. Specifically, we propose a hierarchical gradient clipping with sparsified updating to defend against existing poisoning attacks. The empirical results demonstrate that the proposed defending mechanism improves the robustness of FedRecs.|联邦推荐系统(FedRecs)被认为是一种保护隐私的技术，可以在不共享用户数据的情况下协同学习推荐模型。由于所有参与者都可以通过上传梯度直接影响系统，因此 FedRecs 很容易受到恶意客户端的中毒攻击。然而，大多数现有的对联邦卫生委员会的中毒攻击要么是基于一些先前的知识，要么效果较差。为了揭示 FedRecs 的真实脆弱性，本文提出了一种新的中毒攻击方法，在不依赖任何先验知识的情况下，有效地操纵目标项目的等级和暴露率。具体来说，我们的攻击通过一组合成的恶意用户操纵目标项目的暴露率，这些用户上传有毒梯度，并考虑目标项目的替代产品。我们使用两个广泛使用的 FedRecs (Fed-NCF 和 Fed-LightGCN)在两个真实世界的推荐数据集上进行了广泛的实验。实验结果表明，我们的攻击可以显著提高暴露率的不受欢迎的目标项目与极少的恶意用户和更少的全球纪元比最先进的攻击。除了揭示安全漏洞，我们还设计了一种新的对策来防止对 FedRecs 的中毒攻击。具体来说，我们提出了一个分层梯度剪裁与稀疏更新，以防御现有的中毒攻击。实验结果表明，该防御机制提高了 FedRecs 的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Manipulating+Federated+Recommender+Systems:+Poisoning+with+Synthetic+Users+and+Its+Countermeasures)|0|
|[Behavior Modeling for Point of Interest Search](https://doi.org/10.1145/3539618.3591955)|Haitian Chen, Qingyao Ai, Zhijing Wu, Zhihong Wang, Yiqun Liu, Min Zhang, Shaoping Ma, Juan Hu, Naiqiang Tan, Hua Chai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Behavior+Modeling+for+Point+of+Interest+Search)|0|
|[Disentangling User Conversations with Voice Assistants for Online Shopping](https://doi.org/10.1145/3539618.3591974)|Nikhita Vedula, Marcus D. Collins, Oleg Rokhlenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangling+User+Conversations+with+Voice+Assistants+for+Online+Shopping)|0|
|[MaxSimE: Explaining Transformer-based Semantic Similarity via Contextualized Best Matching Token Pairs](https://doi.org/10.1145/3539618.3592017)|Eduardo Brito, Henri Iser||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MaxSimE:+Explaining+Transformer-based+Semantic+Similarity+via+Contextualized+Best+Matching+Token+Pairs)|0|
|[Searching for Products in Virtual Reality: Understanding the Impact of Context and Result Presentation on User Experience](https://doi.org/10.1145/3539618.3592057)|Austin R. Ward, Sandeep Avula, Hao Fei Cheng, Sheikh Muhammad Sarwar, Vanessa Murdock, Eugene Agichtein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Searching+for+Products+in+Virtual+Reality:+Understanding+the+Impact+of+Context+and+Result+Presentation+on+User+Experience)|0|
|[Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation](https://doi.org/10.1145/3539618.3592078)|Taichi Liu, Chen Gao, Zhenyu Wang, Dong Li, Jianye Hao, Depeng Jin, Yong Li||Graph Neural Network (GNN)-based models have become the mainstream approach for recommender systems. Despite the effectiveness, they are still suffering from the cold-start problem, i.e., recommend for few-interaction items. Existing GNN-based recommendation models to address the cold-start problem mainly focus on utilizing auxiliary features of users and items, leaving the user-item interactions under-utilized. However, embeddings distributions of cold and warm items are still largely different, since cold items' embeddings are learned from lower-popularity interactions, while warm items' embeddings are from higher-popularity interactions. Thus, there is a seesaw phenomenon, where the recommendation performance for the cold and warm items cannot be improved simultaneously. To this end, we proposed a Uncertainty-aware Consistency learning framework for Cold-start item recommendation (shorten as UCC) solely based on user-item interactions. Under this framework, we train the teacher model (generator) and student model (recommender) with consistency learning, to ensure the cold items with additionally generated low-uncertainty interactions can have similar distribution with the warm items. Therefore, the proposed framework improves the recommendation of cold and warm items at the same time, without hurting any one of them. Extensive experiments on benchmark datasets demonstrate that our proposed method significantly outperforms state-of-the-art methods on both warm and cold items, with an average performance improvement of 27.6%.|基于图形神经网络(GNN)的模型已经成为推荐系统的主流方法。尽管有效，他们仍然受到冷启动问题的困扰，也就是说，推荐几个互动项目。现有的基于 GNN 的推荐模型主要是利用用户和项目的辅助特性来解决冷启动问题，使用户-项目交互得不到充分利用。但是，冷暖项目的嵌入分布仍然存在很大差异，因为冷暖项目的嵌入是从低人气互动中学习的，而暖项目的嵌入是从高人气互动中学习的。因此，存在一种跷跷板现象，即冷和暖项目的推荐性能不能同时得到改善。为此，我们提出了一个完全基于用户-项目交互的冷启动项目推荐(简称 UCC)的不确定性一致性学习框架。在此框架下，我们训练具有一致性学习的教师模型(生成器)和学生模型(推荐器) ，以确保具有额外生成的低不确定性交互的冷项目能够与热项目有相似的分布。因此，本文提出的框架在不损害任何一个项目的情况下，同时改进了对冷和暖项目的推荐。在基准数据集上进行的大量实验表明，我们提出的方法在热项和冷项上都明显优于最先进的方法，平均性能提高了27.6% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty-aware+Consistency+Learning+for+Cold-Start+Item+Recommendation)|0|
|[User-Dependent Learning to Debias for Recommendation](https://doi.org/10.1145/3539618.3592083)|Fangyuan Luo, Jun Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-Dependent+Learning+to+Debias+for+Recommendation)|0|
|[MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering](https://doi.org/10.1145/3539618.3591907)|Yang Bai, Anthony Colas, Daisy Zhe Wang||Check-worthy claim detection aims at providing plausible misinformation to downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover, we collect relevant tweets for each distinct answer, then classify them into three categories: "Supporting", "Refuting", and "Neutral". In total, we annotated 5.3K tweets. Contradictory evidence is collected for all answers in the dataset. Finally, we present a baseline system for MythQA and evaluate existing NLP models for each system component using the TweetMythQA dataset. We provide initial benchmarks and identify key challenges for future models to improve upon. Code and data are available at: https://github.com/TonyBY/Myth-QA|值得核查的索赔检测旨在向下游事实核查系统或人类专家提供似是而非的错误信息以供核查。这是加快事实核查过程的关键一步。如何从一小部分预先收集的索赔中识别有价值的索赔已经做了很多努力，但是如何直接从大规模的信息来源(如 Twitter)中有效地识别有价值的索赔仍然没有得到充分的探索。为了填补这一空白，我们引入了 MythQA，这是一个新的多答案开放域问题回答(QA)任务，它涉及到基于查询的矛盾立场挖掘，用于大规模的值得检查的索赔检测。这背后的想法是，相互矛盾的说法是错误信息的有力指标，值得有关当局进行审查。为了研究这项任务，我们构建了一个评估数据集 TweetMythQA，其中包含522个基于有争议话题的事实性多答案问题。每个问题都有多个答案。此外，我们收集每个不同答案的相关推文，然后将它们分为三类: “支持”，“反驳”和“中立”。总的来说，我们注释了5.3千条 tweet。为数据集中的所有答案收集相互矛盾的证据。最后，我们提出一个 MythQA 的基线系统，并使用 TweetMythQA 数据集评估每个系统组件的现有 NLP 模型。我们提供了初步的基准，并确定了未来模型需要改进的关键挑战。代码和数据可在以下 https://github.com/tonyby/myth-qa 查阅:|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MythQA:+Query-Based+Large-Scale+Check-Worthy+Claim+Detection+through+Multi-Answer+Open-Domain+Question+Answering)|0|
|[Podify: A Podcast Streaming Platform with Automatic Logging of User Behaviour for Academic Research](https://doi.org/10.1145/3539618.3591824)|Francesco Meggetto, Yashar Moshfeghi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Podify:+A+Podcast+Streaming+Platform+with+Automatic+Logging+of+User+Behaviour+for+Academic+Research)|0|
|[Multi-lingual Semantic Search for Domain-specific Applications: Adobe Photoshop and Illustrator Help Search](https://doi.org/10.1145/3539618.3591826)|Jayant Kumar, Ashok Gupta, Zhaoyu Lu, Andrei Stefan, Tracy Holloway King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-lingual+Semantic+Search+for+Domain-specific+Applications:+Adobe+Photoshop+and+Illustrator+Help+Search)|0|
|[AttriBERT - Session-based Product Attribute Recommendation with BERT](https://doi.org/10.1145/3539618.3594714)|Akshay Jagatap, Nikki Gupta, Sachin Farfade, Prakash Mandayam Comar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AttriBERT+-+Session-based+Product+Attribute+Recommendation+with+BERT)|0|
|[Adaptive Popularity Debiasing Aggregator for Graph Collaborative Filtering](https://doi.org/10.1145/3539618.3591635)|Huachi Zhou, Hao Chen, Junnan Dong, Daochen Zha, Chuang Zhou, Xiao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Popularity+Debiasing+Aggregator+for+Graph+Collaborative+Filtering)|0|
|[Rectifying Unfairness in Recommendation Feedback Loop](https://doi.org/10.1145/3539618.3591754)|Mengyue Yang, Jun Wang, JeanFrancois Ton||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rectifying+Unfairness+in+Recommendation+Feedback+Loop)|0|
|[Measuring Item Global Residual Value for Fair Recommendation](https://doi.org/10.1145/3539618.3591724)|Jiayin Wang, Weizhi Ma, Chumeng Jiang, Min Zhang, Yuan Zhang, Biao Li, Peng Jiang||In the era of information explosion, numerous items emerge every day, especially in feed scenarios. Due to the limited system display slots and user browsing attention, various recommendation systems are designed not only to satisfy users' personalized information needs but also to allocate items' exposure. However, recent recommendation studies mainly focus on modeling user preferences to present satisfying results and maximize user interactions, while paying little attention to developing item-side fair exposure mechanisms for rational information delivery. This may lead to serious resource allocation problems on the item side, such as the Snowball Effect. Furthermore, unfair exposure mechanisms may hurt recommendation performance. In this paper, we call for a shift of attention from modeling user preferences to developing fair exposure mechanisms for items. We first conduct empirical analyses of feed scenarios to explore exposure problems between items with distinct uploaded times. This points out that unfair exposure caused by the time factor may be the major cause of the Snowball Effect. Then, we propose to explicitly model item-level customized timeliness distribution, Global Residual Value (GRV), for fair resource allocation. This GRV module is introduced into recommendations with the designed Timeliness-aware Fair Recommendation Framework (TaFR). Extensive experiments on two datasets demonstrate that TaFR achieves consistent improvements with various backbone recommendation models. By modeling item-side customized Global Residual Value, we achieve a fairer distribution of resources and, at the same time, improve recommendation performance.|在信息爆炸的时代，每天都会出现大量的条目，特别是在提要场景中。由于系统显示时隙和用户浏览注意力的限制，各种推荐系统不仅要满足用户的个性化信息需求，还要分配项目的曝光量。然而，最近的推荐研究主要集中在建立用户偏好模型，以呈现令人满意的结果和最大化用户交互，而很少注意开发项目侧公平曝光机制，以合理的信息传递。这可能会在项目方面导致严重的资源分配问题，比如雪球效应。此外，不公平的曝光机制可能会损害推荐性能。在本文中，我们呼吁将注意力从建模用户偏好转移到开发项目的公平曝光机制。我们首先进行饲料情景的实证分析，以探讨不同上传时间的项目之间的暴露问题。由此指出，时间因素造成的不公平曝光可能是雪球效应的主要原因。然后，为了实现资源的公平分配，我们提出了项目级定制时间分配的显式模型——全局剩余价值(GRV)。这个 GRV 模块被引入到建议中，并设计了时间感知的公平推荐框架(TaFR)。在两个数据集上的大量实验表明，TaFR 与各种骨干推荐模型实现了一致的改进。通过对项目端定制的全局剩余价值建模，我们实现了更公平的资源分配，同时提高了推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Item+Global+Residual+Value+for+Fair+Recommendation)|0|
|[Knowledge-enhanced Multi-View Graph Neural Networks for Session-based Recommendation](https://doi.org/10.1145/3539618.3591706)|Qian Chen, Zhiqiang Guo, Jianjun Li, Guohui Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-enhanced+Multi-View+Graph+Neural+Networks+for+Session-based+Recommendation)|0|
|[Multi-behavior Self-supervised Learning for Recommendation](https://doi.org/10.1145/3539618.3591734)|Jingcao Xu, Chaokun Wang, Cheng Wu, Yang Song, Kai Zheng, Xiaowei Wang, Changping Wang, Guorui Zhou, Kun Gai||Modern recommender systems often deal with a variety of user interactions, e.g., click, forward, purchase, etc., which requires the underlying recommender engines to fully understand and leverage multi-behavior data from users. Despite recent efforts towards making use of heterogeneous data, multi-behavior recommendation still faces great challenges. Firstly, sparse target signals and noisy auxiliary interactions remain an issue. Secondly, existing methods utilizing self-supervised learning (SSL) to tackle the data sparsity neglect the serious optimization imbalance between the SSL task and the target task. Hence, we propose a Multi-Behavior Self-Supervised Learning (MBSSL) framework together with an adaptive optimization method. Specifically, we devise a behavior-aware graph neural network incorporating the self-attention mechanism to capture behavior multiplicity and dependencies. To increase the robustness to data sparsity under the target behavior and noisy interactions from auxiliary behaviors, we propose a novel self-supervised learning paradigm to conduct node self-discrimination at both inter-behavior and intra-behavior levels. In addition, we develop a customized optimization strategy through hybrid manipulation on gradients to adaptively balance the self-supervised learning task and the main supervised recommendation task. Extensive experiments on five real-world datasets demonstrate the consistent improvements obtained by MBSSL over ten state-of-the art (SOTA) baselines. We release our model implementation at: https://github.com/Scofield666/MBSSL.git.|现代推荐系统经常处理各种用户交互，例如点击、转发、购买等，这需要底层推荐引擎完全理解和利用来自用户的多行为数据。尽管最近努力利用异构数据，多行为推荐仍然面临巨大的挑战。首先，稀疏目标信号和噪声辅助交互作用仍然是一个问题。其次，现有的利用自监督学习(SSL)解决数据稀疏问题的方法忽略了 SSL 任务与目标任务之间存在严重的优化不平衡。因此，我们提出了一个多行为自我监督学习(MBSSL)框架和自适应优化方法。具体来说，我们设计了一个行为感知图形神经网络结合自我注意机制，以捕捉行为的多样性和依赖性。为了提高目标行为和辅助行为引起的噪声干扰下对数据稀疏性的鲁棒性，提出了一种新的自监督学习范式，在行为间和行为内两个层次上进行节点自辨识。此外，通过对梯度的混合操作，我们开发了一个定制的优化策略，以自适应地平衡自监督学习任务和主要的监督推荐任务。在五个真实世界数据集上的大量实验证明了 MBSSL 在超过十个最先进的(SOTA)基线上获得的一致性改进。我们在以下 https://github.com/scofield666/mbssl.git 发布我们的模型实现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-behavior+Self-supervised+Learning+for+Recommendation)|0|
|[LOAM: Improving Long-tail Session-based Recommendation via Niche Walk Augmentation and Tail Session Mixup](https://doi.org/10.1145/3539618.3591718)|Heeyoon Yang, YunSeok Choi, Gahyung Kim, JeeHyong Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LOAM:+Improving+Long-tail+Session-based+Recommendation+via+Niche+Walk+Augmentation+and+Tail+Session+Mixup)|0|
|[An Offline Metric for the Debiasedness of Click Models](https://doi.org/10.1145/3539618.3591639)|Romain Deffayet, Philipp Hager, JeanMichel Renders, Maarten de Rijke||A well-known problem when learning from user clicks are inherent biases prevalent in the data, such as position or trust bias. Click models are a common method for extracting information from user clicks, such as document relevance in web search, or to estimate click biases for downstream applications such as counterfactual learning-to-rank, ad placement, or fair ranking. Recent work shows that the current evaluation practices in the community fail to guarantee that a well-performing click model generalizes well to downstream tasks in which the ranking distribution differs from the training distribution, i.e., under covariate shift. In this work, we propose an evaluation metric based on conditional independence testing to detect a lack of robustness to covariate shift in click models. We introduce the concept of debiasedness and a metric for measuring it. We prove that debiasedness is a necessary condition for recovering unbiased and consistent relevance scores and for the invariance of click prediction under covariate shift. In extensive semi-synthetic experiments, we show that our proposed metric helps to predict the downstream performance of click models under covariate shift and is useful in an off-policy model selection setting.|当从用户点击中学习时，一个众所周知的问题是数据中普遍存在的固有偏差，如位置偏差或信任偏差。点击模型是一种从用户点击中提取信息的常用方法，比如网络搜索中的文档相关性，或者评估下游应用的点击偏差，比如反事实学习排名、广告位置或公平排名。最近的研究表明，目前社区中的评估实践不能保证一个良好的点击模型很好地推广到下游任务，其中排名分布不同于训练分布，即在协变量转移。在这项工作中，我们提出了一个基于条件独立测试的评估指标来检测点击模型中缺乏协变量转移的稳健性。我们介绍了偏差的概念和一个衡量它的度量。我们证明了偏差是恢复无偏和一致相关分数的必要条件，以及点击预测在协变量移动下的不变性。在广泛的半综合实验中，我们表明，我们提出的度量有助于预测下游性能的点击模型下的协变量移动，是有用的非策略模型选择设置。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Offline+Metric+for+the+Debiasedness+of+Click+Models)|0|
|[InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification](https://doi.org/10.1145/3539618.3591699)|Siddhant Kharbanda, Atmadeep Banerjee, Devaansh Gupta, Akash Palrecha, Rohit Babbar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InceptionXML:+A+Lightweight+Framework+with+Synchronized+Negative+Sampling+for+Short+Text+Extreme+Classification)|0|
|[Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding](https://doi.org/10.1145/3539618.3591782)|Susik Yoon, Dongha Lee, Yunyi Zhang, Jiawei Han||Unsupervised discovery of stories with correlated news articles in real-time helps people digest massive news streams without expensive human annotations. A common approach of the existing studies for unsupervised online story discovery is to represent news articles with symbolic- or graph-based embedding and incrementally cluster them into stories. Recent large language models are expected to improve the embedding further, but a straightforward adoption of the models by indiscriminately encoding all information in articles is ineffective to deal with text-rich and evolving news streams. In this work, we propose a novel thematic embedding with an off-the-shelf pretrained sentence encoder to dynamically represent articles and stories by considering their shared temporal themes. To realize the idea for unsupervised online story discovery, a scalable framework USTORY is introduced with two main techniques, theme- and time-aware dynamic embedding and novelty-aware adaptive clustering, fueled by lightweight story summaries. A thorough evaluation with real news data sets demonstrates that USTORY achieves higher story discovery performances than baselines while being robust and scalable to various streaming settings.|不受监督地实时发现与相关新闻文章相关的故事，可以帮助人们消化大量的新闻流，而不需要昂贵的人工注释。现有的无监督在线故事发现研究的一种常用方法是使用基于符号或图形的嵌入方法来表示新闻文章，并逐步地将它们聚类到故事中。最近的大型语言模型预计将进一步改善嵌入，但直接采用模型，不加区分地编码文章中的所有信息，对处理文本丰富和不断变化的新闻流是无效的。在这项工作中，我们提出了一个新的主题嵌入与现成的预先训练的句子编码器，以动态表示文章和故事，考虑其共享的时间主题。为了实现无监督在线故事发现的思想，引入了一个可扩展框架 USTORY，该框架采用了两种主要技术: 主题和时间感知的动态嵌入和新颖感知的自适应聚类，并以轻量级故事摘要为基础。使用真实新闻数据集进行的全面评估表明，USTORY 实现了比基线更高的故事发现性能，同时对各种流设置具有鲁棒性和可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Story+Discovery+from+Continuous+News+Streams+via+Scalable+Thematic+Embedding)|0|
|[When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback?](https://doi.org/10.1145/3539618.3591785)|Yushun Dong, Jundong Li, Tobias Schnabel||In recent years, neural models have been repeatedly touted to exhibit state-of-the-art performance in recommendation. Nevertheless, multiple recent studies have revealed that the reported state-of-the-art results of many neural recommendation models cannot be reliably replicated. A primary reason is that existing evaluations are performed under various inconsistent protocols. Correspondingly, these replicability issues make it difficult to understand how much benefit we can actually gain from these neural models. It then becomes clear that a fair and comprehensive performance comparison between traditional and neural models is needed.   Motivated by these issues, we perform a large-scale, systematic study to compare recent neural recommendation models against traditional ones in top-n recommendation from implicit data. We propose a set of evaluation strategies for measuring memorization performance, generalization performance, and subgroup-specific performance of recommendation models. We conduct extensive experiments with 13 popular recommendation models (including two neural models and 11 traditional ones as baselines) on nine commonly used datasets. Our experiments demonstrate that even with extensive hyper-parameter searches, neural models do not dominate traditional models in all aspects, e.g., they fare worse in terms of average HitRate. We further find that there are areas where neural models seem to outperform non-neural models, for example, in recommendation diversity and robustness between different subgroups of users and items. Our work illuminates the relative advantages and disadvantages of neural models in recommendation and is therefore an important step towards building better recommender systems.|近年来，神经模型一再被吹捧为具有最先进性能的推荐模型。然而，最近的多项研究表明，许多神经推荐模型的报告的最新结果不能可靠地复制。一个主要原因是现有的评估是在各种不一致的协议下执行的。相应地，这些可复制性问题使我们很难理解我们实际上能从这些神经模型中获得多少好处。因此，很明显，需要在传统模型和神经模型之间进行公平和全面的性能比较。在这些问题的激励下，我们进行了一项大规模的系统研究，以比较最近的神经推荐模型和传统的顶部 n 推荐模型的隐含数据。我们提出了一套评估策略，用于测量记忆性能、概括性能和推荐模型的子组特定性能。我们在9个常用的数据集上对13个流行的推荐模型(包括2个神经模型和11个传统模型作为基线)进行了广泛的实验。我们的实验表明，即使有广泛的超参数搜索，神经模型也不能在所有方面支配传统模型，例如，它们在平均 HitRate 方面的表现更差。我们进一步发现，在一些领域，神经模型似乎比非神经模型表现得更好，例如，在不同的用户和项目子群之间的推荐多样性和鲁棒性。我们的工作阐明了神经模型在推荐中的相对优缺点，因此是建立更好的推荐系统的重要一步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Newer+is+Not+Better:+Does+Deep+Learning+Really+Benefit+Recommendation+From+Implicit+Feedback?)|0|
|[Session Search with Pre-trained Graph Classification Model](https://doi.org/10.1145/3539618.3591766)|Shengjie Ma, Chong Chen, Jiaxin Mao, Qi Tian, Xuhui Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Session+Search+with+Pre-trained+Graph+Classification+Model)|0|
|[Leveraging Transferable Knowledge Concept Graph Embedding for Cold-Start Cognitive Diagnosis](https://doi.org/10.1145/3539618.3591774)|Weibo Gao, Hao Wang, Qi Liu, Fei Wang, Xin Lin, Linan Yue, Zheng Zhang, Rui Lv, Shijin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Transferable+Knowledge+Concept+Graph+Embedding+for+Cold-Start+Cognitive+Diagnosis)|0|
|[Editable User Profiles for Controllable Text Recommendations](https://doi.org/10.1145/3539618.3591677)|Sheshera Mysore, Mahmood Jasim, Andrew McCallum, Hamed Zamani||Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the controllability of LACE under simulated user interactions. Finally, we implement LACE in an interactive controllable recommender system and conduct a user study to demonstrate that users are able to improve the quality of recommendations they receive through interactions with an editable user profile.|提出高质量建议的方法通常依赖于从交互数据中学习潜在的表示。这些方法虽然具有良好的性能，但是并没有为用户提供现成的机制来控制他们收到的推荐。我们的工作解决了这个问题，提出了 LACE，一个新的概念价值瓶颈模型的可控文本推荐。通过检索给定的用户交互文档，LACE 用一组简洁的人类可读的概念表示每个用户，并学习基于用户文档的概念的个性化表示。然后利用这个基于概念的用户配置文件来提出建议。我们的模型的设计通过与透明用户配置文件的直观交互提供了对推荐的控制。我们首先建立从 LACE 获得的建议的质量，在一个离线评估中，对三个建议任务进行评估，这三个任务跨越六个数据集，分别是暖启动、冷启动和零启动设置。接下来，我们验证了 LACE 在模拟用户交互下的可控性。最后，我们以交互式可控推荐系统实施 LACE，并进行用户研究，以证明用户能够通过与可编辑的用户资料进行交互，提高他们收到的建议的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Editable+User+Profiles+for+Controllable+Text+Recommendations)|0|
|[Keyword-Based Diverse Image Retrieval by Semantics-aware Contrastive Learning and Transformer](https://doi.org/10.1145/3539618.3591705)|Minyi Zhao, Jinpeng Wang, Dongliang Liao, Yiru Wang, Huanzhong Duan, Shuigeng Zhou||In addition to relevance, diversity is an important yet less studied performance metric of cross-modal image retrieval systems, which is critical to user experience. Existing solutions for diversity-aware image retrieval either explicitly post-process the raw retrieval results from standard retrieval systems or try to learn multi-vector representations of images to represent their diverse semantics. However, neither of them is good enough to balance relevance and diversity. On the one hand, standard retrieval systems are usually biased to common semantics and seldom exploit diversity-aware regularization in training, which makes it difficult to promote diversity by post-processing. On the other hand, multi-vector representation methods are not guaranteed to learn robust multiple projections. As a result, irrelevant images and images of rare or unique semantics may be projected inappropriately, which degrades the relevance and diversity of the results generated by some typical algorithms like top-k. To cope with these problems, this paper presents a new method called CoLT that tries to generate much more representative and robust representations for accurately classifying images. Specifically, CoLT first extracts semantics-aware image features by enhancing the preliminary representations of an existing one-to-one cross-modal system with semantics-aware contrastive learning. Then, a transformer-based token classifier is developed to subsume all the features into their corresponding categories. Finally, a post-processing algorithm is designed to retrieve images from each category to form the final retrieval result. Extensive experiments on two real-world datasets Div400 and Div150Cred show that CoLT can effectively boost diversity, and outperforms the existing methods as a whole (with a higher F1 score).|除了相关性之外，多样性是跨模态图像检索系统中一个重要但研究较少的性能指标，它对用户体验至关重要。现有的基于多样性的图像检索解决方案要么对标准检索系统的原始检索结果进行显式的后处理，要么尝试学习图像的多向量表示来表示图像的多样性语义。然而，它们都不足以平衡相关性和多样性。一方面，标准检索系统往往偏向于通用语义，在训练中很少采用多样性感知的正则化方法，这使得后处理难以提高多样性。另一方面，多向量表示方法不能保证学习鲁棒的多重投影。因此，不相关的图像和罕见或唯一语义的图像可能会被不适当地投影，从而降低了由 top-k 等典型算法产生的结果的相关性和多样性。为了解决这些问题，本文提出了一种称为 CoLT 的新方法，该方法试图生成更具代表性和鲁棒性的图像表示，从而实现图像的准确分类。具体来说，CoLT 首先提取语义感知的图像特征，通过增强现有的具有语义感知对比学习的一对一交叉模式系统的初步表示。然后，开发了一个基于转换器的令牌分类器，将所有特征归入相应的类别。最后，设计了一个后处理算法来检索每个类别的图像，形成最终的检索结果。在 Div400和 Div150Cred 两个实际数据集上的大量实验表明，CoLT 能够有效地提高多样性，并且整体上优于现有的方法(具有更高的 F1分数)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Keyword-Based+Diverse+Image+Retrieval+by+Semantics-aware+Contrastive+Learning+and+Transformer)|0|
|[Next Basket Recommendation with Intent-aware Hypergraph Adversarial Network](https://doi.org/10.1145/3539618.3591742)|Ran Li, Liang Zhang, Guannan Liu, Junjie Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Next+Basket+Recommendation+with+Intent-aware+Hypergraph+Adversarial+Network)|0|
|[AutoTransfer: Instance Transfer for Cross-Domain Recommendations](https://doi.org/10.1145/3539618.3591701)|Jingtong Gao, Xiangyu Zhao, Bo Chen, Fan Yan, Huifeng Guo, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoTransfer:+Instance+Transfer+for+Cross-Domain+Recommendations)|0|
|[Distillation-Enhanced Graph Masked Autoencoders for Bundle Recommendation](https://doi.org/10.1145/3539618.3591666)|Yuyang Ren, Haonan Zhang, Luoyi Fu, Xinbing Wang, Chenghu Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distillation-Enhanced+Graph+Masked+Autoencoders+for+Bundle+Recommendation)|0|
|[Popularity Debiasing from Exposure to Interaction in Collaborative Filtering](https://doi.org/10.1145/3539618.3591947)|Yuanhao Liu, Qi Cao, Huawei Shen, Yunfan Wu, Shuchang Tao, Xueqi Cheng||Recommender systems often suffer from popularity bias, where popular items are overly recommended while sacrificing unpopular items. Existing researches generally focus on ensuring the number of recommendations exposure of each item is equal or proportional, using inverse propensity weighting, causal intervention, or adversarial training. However, increasing the exposure of unpopular items may not bring more clicks or interactions, resulting in skewed benefits and failing in achieving real reasonable popularity debiasing. In this paper, we propose a new criterion for popularity debiasing, i.e., in an unbiased recommender system, both popular and unpopular items should receive Interactions Proportional to the number of users who Like it, namely IPL criterion. Under the guidance of the criterion, we then propose a debiasing framework with IPL regularization term which is theoretically shown to achieve a win-win situation of both popularity debiasing and recommendation performance. Experiments conducted on four public datasets demonstrate that when equipping two representative collaborative filtering models with our framework, the popularity bias is effectively alleviated while maintaining the recommendation performance.|推荐系统经常受到受欢迎程度偏差的影响，受欢迎的项目被过度推荐，而牺牲了不受欢迎的项目。现有的研究通常集中在确保每个项目的建议暴露数量相等或成比例，使用反倾向权重，因果干预，或对抗性训练。然而，增加不受欢迎的项目的曝光可能不会带来更多的点击或互动，导致扭曲的利益和未能实现真正合理的流行去偏见。在这篇文章中，我们提出了一个新的减低受欢迎程度的准则，即在一个不偏不倚的推荐系统下，受欢迎和不受欢迎的项目都应该接受与喜欢它的用户数成比例的互动，即 IPL 准则。在该准则的指导下，我们提出了一个带有 IPL 正则项的去偏框架，理论上证明了该框架可以实现人气去偏和推荐性能的双赢。在四个公共数据集上进行的实验表明，当在我们的框架中安装两个具有代表性的协同过滤模型时，在保持推荐性能的同时有效地减少了流行偏差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Popularity+Debiasing+from+Exposure+to+Interaction+in+Collaborative+Filtering)|0|
|[AutoDPQ: Automated Differentiable Product Quantization for Embedding Compression](https://doi.org/10.1145/3539618.3591953)|Xin Gan, Yuhao Wang, Xiangyu Zhao, Wanyu Wang, Yiqi Wang, Zitao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoDPQ:+Automated+Differentiable+Product+Quantization+for+Embedding+Compression)|0|
|[Can Generative LLMs Create Query Variants for Test Collections? An Exploratory Study](https://doi.org/10.1145/3539618.3591960)|Marwah Alaofi, Luke Gallagher, Mark Sanderson, Falk Scholer, Paul Thomas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Generative+LLMs+Create+Query+Variants+for+Test+Collections?+An+Exploratory+Study)|0|
|[Causal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation](https://doi.org/10.1145/3539618.3591961)|Siyu Wang, Xiaocong Chen, Quan Z. Sheng, Yihong Zhang, Lina Yao||Recommendation models are typically trained on observational user interaction data, but the interactions between latent factors in users' decision-making processes lead to complex and entangled data. Disentangling these latent factors to uncover their underlying representation can improve the robustness, interpretability, and controllability of recommendation models. This paper introduces the Causal Disentangled Variational Auto-Encoder (CaD-VAE), a novel approach for learning causal disentangled representations from interaction data in recommender systems. The CaD-VAE method considers the causal relationships between semantically related factors in real-world recommendation scenarios, rather than enforcing independence as in existing disentanglement methods. The approach utilizes structural causal models to generate causal representations that describe the causal relationship between latent factors. The results demonstrate that CaD-VAE outperforms existing methods, offering a promising solution for disentangling complex user behavior data in recommendation systems.|推荐模型通常基于观测用户交互数据进行训练，但用户决策过程中潜在因素之间的相互作用会导致复杂和纠缠的数据。分离这些潜在因素，揭示它们的基底形式，可以提高推荐模型的稳健性、可解释性和可控性。介绍了一种从推荐系统中的交互数据中学习因果解缠表示的新方法——因果解缠变分自动编码器(CaD-VAE)。在现实推荐场景中，CaD-VAE 方法考虑了语义相关因素之间的因果关系，而不是像现有的分离方法那样强制独立性。该方法利用结构性因果模型来产生描述潜在因素之间因果关系的因果表示。结果表明，CaD-VAE 方法的性能优于现有方法，为推荐系统中复杂用户行为数据的分离提供了一种有前途的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Disentangled+Variational+Auto-Encoder+for+Preference+Understanding+in+Recommendation)|0|
|[Connecting Unseen Domains: Cross-Domain Invariant Learning in Recommendation](https://doi.org/10.1145/3539618.3591965)|Yang Zhang, Yue Shen, Dong Wang, Jinjie Gu, Guannan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Connecting+Unseen+Domains:+Cross-Domain+Invariant+Learning+in+Recommendation)|0|
|[Event-Aware Adaptive Clustering Uplift Network for Insurance Creative Ranking](https://doi.org/10.1145/3539618.3591980)|Wanjie Tao, Huihui Liu, Xuqi Li, Qun Dai, Hong Wen, Zulong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Event-Aware+Adaptive+Clustering+Uplift+Network+for+Insurance+Creative+Ranking)|0|
|[Exploiting Cluster-Skipping Inverted Index for Semantic Place Retrieval](https://doi.org/10.1145/3539618.3591983)|Enes Recep Cinar, Ismail Sengor Altingovde||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Cluster-Skipping+Inverted+Index+for+Semantic+Place+Retrieval)|0|
|[Friend Ranking in Online Games via Pre-training Edge Transformers](https://doi.org/10.1145/3539618.3591990)|Liang Yao, Jiazhen Peng, Shenggong Ji, Qiang Liu, Hongyun Cai, Feng He, Xu Cheng||Friend recall is an important way to improve Daily Active Users (DAU) in online games. The problem is to generate a proper lost friend ranking list essentially. Traditional friend recall methods focus on rules like friend intimacy or training a classifier for predicting lost players' return probability, but ignore feature information of (active) players and historical friend recall events. In this work, we treat friend recall as a link prediction problem and explore several link prediction methods which can use features of both active and lost players, as well as historical events. Furthermore, we propose a novel Edge Transformer model and pre-train the model via masked auto-encoders. Our method achieves state-of-the-art results in the offline experiments and online A/B Tests of three Tencent games.|朋友回忆是提高网络游戏日常活跃用户(DAU)水平的重要途径。问题是生成一个适当的失去朋友排名名单本质上。传统的朋友回忆方法侧重于朋友间的亲密关系或训练一个分类器来预测失去的玩家的返回概率等规则，而忽略了(活跃的)玩家的特征信息和历史的朋友回忆事件。本文将好友回忆视为一个链接预测问题，探索了几种既能利用主动玩家特征又能利用丢失玩家特征以及历史事件特征的链接预测方法。此外，我们提出了一个新的边缘变压器模型和预训练的掩码自动编码器的模型。我们的方法在三个腾讯游戏的离线实验和在线 A/B 测试中取得了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Friend+Ranking+in+Online+Games+via+Pre-training+Edge+Transformers)|0|
|[Generative Relevance Feedback with Large Language Models](https://doi.org/10.1145/3539618.3591992)|Iain Mackie, Shubham Chatterjee, Jeffrey Dalton||Current query expansion models use pseudo-relevance feedback to improve first-pass retrieval effectiveness; however, this fails when the initial results are not relevant. Instead of building a language model from retrieved results, we propose Generative Relevance Feedback (GRF) that builds probabilistic feedback models from long-form text generated from Large Language Models. We study the effective methods for generating text by varying the zero-shot generation subtasks: queries, entities, facts, news articles, documents, and essays. We evaluate GRF on document retrieval benchmarks covering a diverse set of queries and document collections, and the results show that GRF methods significantly outperform previous PRF methods. Specifically, we improve MAP between 5-19% and NDCG@10 17-24% compared to RM3 expansion, and achieve the best R@1k effectiveness on all datasets compared to state-of-the-art sparse, dense, and expansion models.|当前的查询扩展模型使用伪相关反馈来提高首次检索的有效性，但是，当初始结果不相关时，这种方法就会失败。我们建议使用生成关联反馈(Generative) ，从大型语言模型生成的长形文本中建立概率反馈模型，而不是根据检索到的结果建立语言模型。我们研究了通过改变零镜头生成子任务(查询、实体、事实、新闻文章、文档和随笔)来生成文本的有效方法。我们根据涵盖不同查询和文档集合的文献检索基准对 GRF 进行评估，结果显示 GRF 方法明显优于以前的 PRF 方法。具体而言，与 RM3扩展相比，我们改善了5-19% 和 NDCG@1017-24% 之间的 MAP，并且与最先进的稀疏、密集和扩展模型相比，在所有数据集上实现了最佳的 R@1k 效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Relevance+Feedback+with+Large+Language+Models)|0|
|[Improved Vector Quantization For Dense Retrieval with Contrastive Distillation](https://doi.org/10.1145/3539618.3592001)|James O'Neill, Sourav Dutta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improved+Vector+Quantization+For+Dense+Retrieval+with+Contrastive+Distillation)|0|
|[LogicRec: Recommendation with Users' Logical Requirements](https://doi.org/10.1145/3539618.3592012)|Zhenwei Tang, Griffin Floto, Armin Toroghi, Shichao Pei, Xiangliang Zhang, Scott Sanner||Users may demand recommendations with highly personalized requirements involving logical operations, e.g., the intersection of two requirements, where such requirements naturally form structured logical queries on knowledge graphs (KGs). To date, existing recommender systems lack the capability to tackle users' complex logical requirements. In this work, we formulate the problem of recommendation with users' logical requirements (LogicRec) and construct benchmark datasets for LogicRec. Furthermore, we propose an initial solution for LogicRec based on logical requirement retrieval and user preference retrieval, where we face two challenges. First, KGs are incomplete in nature. Therefore, there are always missing true facts, which entails that the answers to logical requirements can not be completely found in KGs. In this case, item selection based on the answers to logical queries is not applicable. We thus resort to logical query embedding (LQE) to jointly infer missing facts and retrieve items based on logical requirements. Second, answer sets are under-exploited. Existing LQE methods can only deal with query-answer pairs, where queries in our case are the intersected user preferences and logical requirements. However, the logical requirements and user preferences have different answer sets, offering us richer knowledge about the requirements and preferences by providing requirement-item and preference-item pairs. Thus, we design a multi-task knowledge-sharing mechanism to exploit these answer sets collectively. Extensive experimental results demonstrate the significance of the LogicRec task and the effectiveness of our proposed method.|用户可能需要具有高度个性化需求的推荐，这些需求涉及逻辑操作，例如，两个需求的交叉点，这些需求自然而然地在知识图(KG)上形成结构化的逻辑查询。迄今为止，现有的推荐系统缺乏处理用户复杂逻辑需求的能力。在这项工作中，我们提出了与用户的逻辑需求(LogicRec)的推荐问题，并构造了基准数据集的 LogicRec。在此基础上，提出了基于逻辑需求检索和用户偏好检索的 LogicRec 初步解决方案。首先，幼稚园本质上是不完整的。因此，总是缺少真正的事实，这就意味着逻辑要求的答案不能完全在幼稚园中找到。在这种情况下，基于逻辑查询答案的项选择是不适用的。因此，我们使用逻辑查询嵌入(LQE)来联合推断丢失的事实并根据逻辑需求检索项。其次，答案集未得到充分利用。现有的 LQE 方法只能处理查询-答案对，在我们的例子中，查询是交叉的用户首选项和逻辑需求。然而，逻辑需求和用户偏好有不同的答案集，通过提供需求项和偏好项对，为我们提供了关于需求和偏好的更丰富的知识。因此，我们设计了一个多任务知识共享机制来共同利用这些答案集。大量的实验结果表明了 LogicRec 任务的重要性和提出的方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LogicRec:+Recommendation+with+Users'+Logical+Requirements)|0|
|[Matching Point of Interests and Travel Blog with Multi-view Information Fusion](https://doi.org/10.1145/3539618.3592016)|Shuokai Li, Jingbo Zhou, Jizhou Huang, Hao Chen, Fuzhen Zhuang, Qing He, Dejing Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Matching+Point+of+Interests+and+Travel+Blog+with+Multi-view+Information+Fusion)|0|
|[One-Shot Labeling for Automatic Relevance Estimation](https://doi.org/10.1145/3539618.3592032)|Sean MacAvaney, Luca Soldaini||Dealing with unjudged documents ("holes") in relevance assessments is a perennial problem when evaluating search systems with offline experiments. Holes can reduce the apparent effectiveness of retrieval systems during evaluation and introduce biases in models trained with incomplete data. In this work, we explore whether large language models can help us fill such holes to improve offline evaluations. We examine an extreme, albeit common, evaluation setting wherein only a single known relevant document per query is available for evaluation. We then explore various approaches for predicting the relevance of unjudged documents with respect to a query and the known relevant document, including nearest neighbor, supervised, and prompting techniques. We find that although the predictions of these One-Shot Labelers (1SLs) frequently disagree with human assessments, the labels they produce yield a far more reliable ranking of systems than the single labels do alone. Specifically, the strongest approaches can consistently reach system ranking correlations of over 0.85 with the full rankings over a variety of measures. Meanwhile, the approach substantially reduces the false positive rate of t-tests due to holes in relevance assessments (from 15-30% down to under 5%), giving researchers more confidence in results they find to be significant.|在用离线实验评估搜索系统时，处理相关性评估中未经判断的文档(“漏洞”)是一个长期存在的问题。漏洞会降低检索系统在评价过程中的表观有效性，并在不完全数据训练的模型中引入偏差。在这项工作中，我们探讨是否大型语言模型可以帮助我们填补这些漏洞，以改善离线评估。我们检查一个极端的，尽管是常见的，评估设置，其中每个查询只有一个已知的相关文档可用于评估。然后，我们探讨了预测未判断文档与查询和已知相关文档相关性的各种方法，包括最近邻、监督和提示技术。我们发现，尽管这些一次性标签(1SLs)的预测经常与人类的评估不一致，但是他们生产的标签产生的系统排名比单独的标签产生的系统排名可靠得多。具体来说，最强的方法可以始终达到系统排名相关性超过0.85与完整的排名在各种措施。同时，这种方法大大降低了由于相关性评估漏洞(从15-30% 下降到5% 以下)而导致的 t 检验的假阳性率，使研究人员对他们发现的重要结果更有信心。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-Shot+Labeling+for+Automatic+Relevance+Estimation)|0|
|[Quantifying and Leveraging User Fatigue for Interventions in Recommender Systems](https://doi.org/10.1145/3539618.3592044)|Hitesh Sagtani, Madan Gopal Jhawar, Akshat Gupta, Rishabh Mehrotra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+and+Leveraging+User+Fatigue+for+Interventions+in+Recommender+Systems)|0|
|[Rating Prediction in Conversational Task Assistants with Behavioral and Conversational-Flow Features](https://doi.org/10.1145/3539618.3592048)|Rafael Ferreira, David Semedo, João Magalhães||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rating+Prediction+in+Conversational+Task+Assistants+with+Behavioral+and+Conversational-Flow+Features)|0|
|[Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion](https://doi.org/10.1145/3539618.3592052)|Donghan Yu, Yiming Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Enhanced+Generative+Model+for+Large-Scale+Knowledge+Graph+Completion)|0|
|[Review-based Multi-intention Contrastive Learning for Recommendation](https://doi.org/10.1145/3539618.3592053)|Wei Yang, Tengfei Huo, Zhiqiang Liu, Chi Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Review-based+Multi-intention+Contrastive+Learning+for+Recommendation)|0|
|[Rows or Columns? Minimizing Presentation Bias When Comparing Multiple Recommender Systems](https://doi.org/10.1145/3539618.3592056)|Patrik Dokoupil, Ladislav Peska, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rows+or+Columns?+Minimizing+Presentation+Bias+When+Comparing+Multiple+Recommender+Systems)|0|
|[Simpler is Much Faster: Fair and Independent Inner Product Search](https://doi.org/10.1145/3539618.3592061)|Kazuyoshi Aoyama, Daichi Amagata, Sumio Fujita, Takahiro Hara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simpler+is+Much+Faster:+Fair+and+Independent+Inner+Product+Search)|0|
|[Simplifying Content-Based Neural News Recommendation: On User Modeling and Training Objectives](https://doi.org/10.1145/3539618.3592062)|Andreea Iana, Goran Glavas, Heiko Paulheim||The advent of personalized news recommendation has given rise to increasingly complex recommender architectures. Most neural news recommenders rely on user click behavior and typically introduce dedicated user encoders that aggregate the content of clicked news into user embeddings (early fusion). These models are predominantly trained with standard point-wise classification objectives. The existing body of work exhibits two main shortcomings: (1) despite general design homogeneity, direct comparisons between models are hindered by varying evaluation datasets and protocols; (2) it leaves alternative model designs and training objectives vastly unexplored. In this work, we present a unified framework for news recommendation, allowing for a systematic and fair comparison of news recommenders across several crucial design dimensions: (i) candidate-awareness in user modeling, (ii) click behavior fusion, and (iii) training objectives. Our findings challenge the status quo in neural news recommendation. We show that replacing sizable user encoders with parameter-efficient dot products between candidate and clicked news embeddings (late fusion) often yields substantial performance gains. Moreover, our results render contrastive training a viable alternative to point-wise classification objectives.|个性化新闻推荐的出现引发了日益复杂的推荐体系结构。大多数神经新闻推荐器依赖于用户的点击行为，通常引入专用的用户编码器，将点击新闻的内容聚合到用户嵌入(早期融合)中。这些模型主要用标准的逐点分类目标进行训练。现有的工作主体表现出两个主要缺点: (1)尽管总体设计同质化，但不同的评估数据集和协议阻碍了模型之间的直接比较; (2)留下了大量未被探索的替代模型设计和培训目标。在这项工作中，我们提出了一个新闻推荐的统一框架，允许在几个关键的设计维度上对新闻推荐进行系统和公平的比较: (i)用户建模中的候选人意识，(ii)点击行为融合，以及(iii)培训目标。我们的发现挑战了神经新闻推荐的现状。我们表明，在候选和点击新闻嵌入(后期融合)之间用参数有效的点积替换大型用户编码器通常会产生显著的性能提高。此外，我们的结果使对比训练成为一个可行的替代点分类目标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simplifying+Content-Based+Neural+News+Recommendation:+On+User+Modeling+and+Training+Objectives)|0|
|[SimTDE: Simple Transformer Distillation for Sentence Embeddings](https://doi.org/10.1145/3539618.3592063)|Jian Xie, Xin He, Jiyang Wang, Zimeng Qiu, Ali Kebarighotbi, Farhad Ghassemi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SimTDE:+Simple+Transformer+Distillation+for+Sentence+Embeddings)|0|
|[TAML: Time-Aware Meta Learning for Cold-Start Problem in News Recommendation](https://doi.org/10.1145/3539618.3592068)|Jingyuan Li, Yue Zhang, Xuan Lin, Xinxing Yang, Ge Zhou, Longfei Li, Hong Chen, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TAML:+Time-Aware+Meta+Learning+for+Cold-Start+Problem+in+News+Recommendation)|0|
|[Uncertainty-based Heterogeneous Privileged Knowledge Distillation for Recommendation System](https://doi.org/10.1145/3539618.3592079)|Ang Li, Jian Hu, Ke Ding, Xiaolu Zhang, Jun Zhou, Yong He, Xu Min||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty-based+Heterogeneous+Privileged+Knowledge+Distillation+for+Recommendation+System)|0|
|[WSFE: Wasserstein Sub-graph Feature Encoder for Effective User Segmentation in Collaborative Filtering](https://doi.org/10.1145/3539618.3592089)|Yankai Chen, Yifei Zhang, Menglin Yang, Zixing Song, Chen Ma, Irwin King||Maximizing the user-item engagement based on vectorized embeddings is a standard procedure of recent recommender models. Despite the superior performance for item recommendations, these methods however implicitly deprioritize the modeling of user-wise similarity in the embedding space; consequently, identifying similar users is underperforming, and additional processing schemes are usually required otherwise. To avoid thorough model re-training, we propose WSFE, a model-agnostic and training-free representation encoder, to be flexibly employed on the fly for effective user segmentation. Underpinned by the optimal transport theory, the encoded representations from WSFE present a matched user-wise similarity/distance measurement between the realistic and embedding space. We incorporate WSFE into six state-of-the-art recommender models and conduct extensive experiments on six real-world datasets. The empirical analyses well demonstrate the superiority and generality of WSFE to fuel multiple downstream tasks with diverse underlying targets in recommendation.|最大化基于向量化嵌入的用户项目参与是最近推荐模型的一个标准过程。尽管项目推荐的性能优越，但是这些方法隐含地剥夺了嵌入空间中用户相似性的建模优先级; 因此，识别相似的用户表现不佳，并且通常需要额外的处理方案。为了避免彻底的模型再训练，我们提出了 WSFE，一种模型不可知和无训练的表示编码器，可以灵活地应用于有效的用户分割。在最优传输理论的支持下，来自 WSFE 的编码表示提供了现实空间和嵌入空间之间匹配的用户相似度/距离度量。我们将 WSFE 整合到六个最先进的推荐模型中，并在六个真实世界的数据集上进行广泛的实验。实证分析很好地证明了 WSFE 在推荐目标不同的多下游任务方面的优越性和普遍性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WSFE:+Wasserstein+Sub-graph+Feature+Encoder+for+Effective+User+Segmentation+in+Collaborative+Filtering)|0|
|[Balanced Topic Aware Sampling for Effective Dense Retriever: A Reproducibility Study](https://doi.org/10.1145/3539618.3591915)|Shuai Wang, Guido Zuccon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balanced+Topic+Aware+Sampling+for+Effective+Dense+Retriever:+A+Reproducibility+Study)|0|
|[T2Ranking: A Large-scale Chinese Benchmark for Passage Ranking](https://doi.org/10.1145/3539618.3591874)|Xiaohui Xie, Qian Dong, Bingning Wang, Feiyang Lv, Ting Yao, Weinan Gan, Zhijing Wu, Xiangsheng Li, Haitao Li, Yiqun Liu, Jin Ma||Passage ranking involves two stages: passage retrieval and passage re-ranking, which are important and challenging topics for both academics and industries in the area of Information Retrieval (IR). However, the commonly-used datasets for passage ranking usually focus on the English language. For non-English scenarios, such as Chinese, the existing datasets are limited in terms of data scale, fine-grained relevance annotation and false negative issues. To address this problem, we introduce T2Ranking, a large-scale Chinese benchmark for passage ranking. T2Ranking comprises more than 300K queries and over 2M unique passages from real-world search engines. Expert annotators are recruited to provide 4-level graded relevance scores (fine-grained) for query-passage pairs instead of binary relevance judgments (coarse-grained). To ease the false negative issues, more passages with higher diversities are considered when performing relevance annotations, especially in the test set, to ensure a more accurate evaluation. Apart from the textual query and passage data, other auxiliary resources are also provided, such as query types and XML files of documents which passages are generated from, to facilitate further studies. To evaluate the dataset, commonly used ranking models are implemented and tested on T2Ranking as baselines. The experimental results show that T2Ranking is challenging and there is still scope for improvement. The full data and all codes are available at https://github.com/THUIR/T2Ranking/|短文排序包括短文检索和短文重排两个阶段，这两个阶段对于信息检索领域的学术界和工业界来说都是非常重要和具有挑战性的课题。然而，常用于文章排名的数据集通常集中在英语语言上。对于非英语情景，如中文，现有的数据集在数据规模、细粒度相关性标注和虚假否定问题等方面存在局限性。为了解决这个问题，我们引入了 T2Ranking，一个大规模的中文通过排名基准。T2Rank 包含超过30万个查询和超过200万个来自现实世界搜索引擎的独特段落。招募专家注释者为查询-通过对提供4级分级相关分数(细粒度) ，而不是二进制相关判断(粗粒度)。为了减少错误的否定性问题，在进行相关注释时，特别是在测试集中，需要考虑更多多样性较高的段落，以确保更准确的评价。除了文字查询和段落资料外，还提供其他辅助资源，例如查询类型和产生段落的文件的 XML 档案，以方便进一步研究。为了评估数据集，常用的排名模型被实现，并在 T2Ranking 上作为基线进行测试。实验结果表明，T2Ranking 是具有挑战性的，仍然有改进的空间。完整的数据和所有的代码都可以在 https://github.com/thuir/t2ranking/找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=T2Ranking:+A+Large-scale+Chinese+Benchmark+for+Passage+Ranking)|0|
|[Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems](https://doi.org/10.1145/3539618.3591889)|Lanling Xu, Zhen Tian, Gaowei Zhang, Junjie Zhang, Lei Wang, Bowen Zheng, Yifan Li, Jiakai Tang, Zeyu Zhang, Yupeng Hou, Xingyu Pan, Wayne Xin Zhao, Xu Chen, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+More+User-Friendly+and+Easy-to-Use+Benchmark+Library+for+Recommender+Systems)|0|
|[RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams](https://doi.org/10.1145/3539618.3591908)|Gabriel IturraBocaz, Felipe BravoMarquez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RiverText:+A+Python+Library+for+Training+and+Evaluating+Incremental+Word+Embeddings+from+Text+Data+Streams)|0|
|[HeteroCS: A Heterogeneous Community Search System With Semantic Explanation](https://doi.org/10.1145/3539618.3591812)|Weibin Cai, Fanwei Zhu, Zemin Liu, Minghui Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HeteroCS:+A+Heterogeneous+Community+Search+System+With+Semantic+Explanation)|0|
|[ranxhub: An Online Repository for Information Retrieval Runs](https://doi.org/10.1145/3539618.3591823)|Elias Bassani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ranxhub:+An+Online+Repository+for+Information+Retrieval+Runs)|0|
|[Exploratory Visualization Tool for the Continuous Evaluation of Information Retrieval Systems](https://doi.org/10.1145/3539618.3591825)|Gabriela González Sáez, Petra Galuscáková, Romain Deveaud, Lorraine Goeuriot, Philippe Mulhem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploratory+Visualization+Tool+for+the+Continuous+Evaluation+of+Information+Retrieval+Systems)|0|
|[COUPA: An Industrial Recommender System for Online to Offline Service Platforms](https://doi.org/10.1145/3539618.3591828)|Sicong Xie, Binbin Hu, Fengze Li, Ziqi Liu, Zhiqiang Zhang, Wenliang Zhong, Jun Zhou||Aiming at helping users locally discovery retail services (e.g., entertainment and dinning), Online to Offline (O2O) service platforms have become popular in recent years, which greatly challenge current recommender systems. With the real data in Alipay, a feeds-like scenario for O2O services, we find that recurrence based temporal patterns and position biases commonly exist in our scenarios, which seriously threaten the recommendation effectiveness. To this end, we propose COUPA, an industrial system targeting for characterizing user preference with following two considerations: (1) Time aware preference: we employ the continuous time aware point process equipped with an attention mechanism to fully capture temporal patterns for recommendation. (2) Position aware preference: a position selector component equipped with a position personalization module is elaborately designed to mitigate position bias in a personalized manner. Finally, we carefully implement and deploy COUPA on Alipay with a cooperation of edge, streaming and batch computing, as well as a two-stage online serving mode, to support several popular recommendation scenarios. We conduct extensive experiments to demonstrate that COUPA consistently achieves superior performance and has potential to provide intuitive evidences for recommendation|为了帮助用户在本地发现零售服务(如娱乐和餐饮) ，Online To Offline线上到线下服务平台近年来越来越流行，这极大地挑战了现有的推荐系统。利用支付宝中的实际数据，我们发现在 O2O 服务中，基于循环的时间模式和位置偏差在我们的场景中普遍存在，这严重威胁了推荐的有效性。为此，我们提出了 COUPA，这是一个针对用户偏好特征的工业系统，具有以下两个考虑因素: (1)时间感知偏好: 我们采用连续的时间感知点过程，配备注意机制，以充分捕获推荐的时间模式。(2)位置感知偏好: 精心设计的配有位置个性化模块的位置选择元件，以个性化的方式减轻位置偏差。最后，我们在支付宝上小心地实现和部署了 COUPA，并结合了边缘计算、流计算和批处理计算，以及两阶段的在线服务模式，以支持多种流行的推荐场景。我们进行了广泛的实验，以证明 COUPA 始终如一地实现卓越的性能，并有潜力为推荐提供直观的证据|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COUPA:+An+Industrial+Recommender+System+for+Online+to+Offline+Service+Platforms)|0|
|[A Practical Online Allocation Framework at Industry-scale in Constrained Recommendation](https://doi.org/10.1145/3539618.3591835)|Daohong Jian, Yang Bao, Jun Zhou, Hua Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Practical+Online+Allocation+Framework+at+Industry-scale+in+Constrained+Recommendation)|0|
|[A Transformer-Based Substitute Recommendation Model Incorporating Weakly Supervised Customer Behavior Data](https://doi.org/10.1145/3539618.3591847)|Wenting Ye, Hongfei Yang, Shuai Zhao, Haoyang Fang, Xingjian Shi, Naveen Neppalli||The substitute-based recommendation is widely used in E-commerce to provide better alternatives to customers. However, existing research typically uses the customer behavior signals like co-view and view-but-purchase-another to capture the substitute relationship. Despite its intuitive soundness, we find that such an approach might ignore the functionality and characteristics of products. In this paper, we adapt substitute recommendation into language matching problem by taking product title description as model input to consider product functionality. We design a new transformation method to de-noise the signals derived from production data. In addition, we consider multilingual support from the engineering point of view. Our proposed end-to-end transformer-based model achieves both successes from offline and online experiments. The proposed model has been deployed in a large-scale E-commerce website for 11 marketplaces in 6 languages. Our proposed model is demonstrated to increase revenue by 19% based on an online A/B experiment.|基于替代品的推荐广泛应用于电子商务中，为客户提供更好的替代品。然而，现有的研究通常使用顾客行为信号，如共同查看和查看-但购买-另一个来捕捉替代关系。尽管这种方法直观可靠，但我们发现它可能会忽略产品的功能和特性。本文以产品名称描述作为模型输入，考虑产品功能，将替代推荐应用到语言匹配问题中。我们设计了一种新的变换方法来去除从生产数据中得到的信号的噪声。此外，我们从工程的角度考虑多语言支持。我们提出的基于端到端变压器的模型在离线和在线实验中都取得了成功。拟议的模式已经在一个大型电子商务网站上用6种语言为11个市场部署。基于在线 A/B 实验，我们提出的模型被证明可以增加19% 的收入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Transformer-Based+Substitute+Recommendation+Model+Incorporating+Weakly+Supervised+Customer+Behavior+Data)|0|
|[DCBT: A Simple But Effective Way for Unified Warm and Cold Recommendation](https://doi.org/10.1145/3539618.3591856)|Jieyu Yang, Liang Zhang, Yong He, Ke Ding, Zhaoxin Huan, Xiaolu Zhang, Linjian Mo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DCBT:+A+Simple+But+Effective+Way+for+Unified+Warm+and+Cold+Recommendation)|0|
|[OFAR: A Multimodal Evidence Retrieval Framework for Illegal Live-streaming Identification](https://doi.org/10.1145/3539618.3591864)|Dengtian Lin, Yang Ma, Yuhong Li, Xuemeng Song, Jianlong Wu, Liqiang Nie||Illegal live-streaming identification, which aims to help live-streaming platforms immediately recognize the illegal behaviors in the live-streaming, such as selling precious and endangered animals, plays a crucial role in purifying the network environment. Traditionally, the live-streaming platform needs to employ some professionals to manually identify the potential illegal live-streaming. Specifically, the professional needs to search for related evidence from a large-scale knowledge database for evaluating whether a given live-streaming clip contains illegal behavior, which is time-consuming and laborious. To address this issue, in this work, we propose a multimodal evidence retrieval system, named OFAR, to facilitate the illegal live-streaming identification. OFAR consists of three modules: Query Encoder, Document Encoder, and MaxSim-based Contrastive Late Intersection. Both query encoder and document encoder are implemented with the advanced OFA encoder, which is pretrained on a large-scale multimodal dataset. In the last module, we introduce contrastive learning on the basis of the MaxiSim-based late intersection, to enhance the model's ability of query-document matching. The proposed framework achieves significant improvement on our industrial dataset TaoLive, demonstrating the advances of our scheme.|非法流媒体识别是帮助流媒体平台及时识别流媒体中的非法行为，如出售珍稀濒危动物等，对净化网络环境起着至关重要的作用。传统上，直播平台需要雇佣一些专业人员来手动识别潜在的非法直播。具体来说，专业人员需要从大规模的知识库中搜索相关证据，以评估给定的直播剪辑是否包含违法行为，这是一项既费时又费力的工作。为了解决这个问题，本文提出了一个多模态证据检索系统 OFAR，以方便非法流媒体证据的识别。OFAR 由三个模块组成: 查询编码器、文档编码器和基于 MaxSim 的对比晚交。查询编码器和文档编码器都是用先进的 OFA 编码器实现的，该编码器是在大规模多模态数据集上预先训练好的。在最后一个模块中，我们引入了基于 MaxiSim 的后期交集对比学习，以提高模型的查询-文档匹配能力。所提出的框架对我们的工业数据集 TaoLive 进行了重大改进，展示了我们方案的进步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OFAR:+A+Multimodal+Evidence+Retrieval+Framework+for+Illegal+Live-streaming+Identification)|0|
|[Complex Item Set Recommendation](https://doi.org/10.1145/3539618.3594248)|Mozhdeh Ariannezhad, Ming Li, Sami Jullien, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Complex+Item+Set+Recommendation)|0|
|[Recent Advances in the Foundations and Applications of Unbiased Learning to Rank](https://doi.org/10.1145/3539618.3594247)|Shashank Gupta, Philipp Hager, Jin Huang, Ali Vardasbi, Harrie Oosterhuis||Since its inception, the field of unbiased learning to rank (ULTR) has remained very active and has seen several impactful advancements in recent years. This tutorial provides both an introduction to the core concepts of the field and an overview of recent advancements in its foundations along with several applications of its methods. The tutorial is divided into four parts: Firstly, we give an overview of the different forms of bias that can be addressed with ULTR methods. Secondly, we present a comprehensive discussion of the latest estimation techniques in the ULTR field. Thirdly, we survey published results of ULTR in real-world applications. Fourthly, we discuss the connection between ULTR and fairness in ranking. We end by briefly reflecting on the future of ULTR research and its applications. This tutorial is intended to benefit both researchers and industry practitioners who are interested in developing new ULTR solutions or utilizing them in real-world applications.|自成立以来，无偏学习排名(ULTR)领域一直非常活跃，近年来取得了一些有影响力的进展。本教程介绍了该领域的核心概念，概述了该领域基础方面的最新进展及其方法的若干应用。本教程分为四个部分: 首先，我们概述了不同形式的偏倚，可以用 ULTR 方法处理。其次，我们对 ULTR 领域中的最新估计技术进行了全面的讨论。第三，我们调查了已发表的 ULTR 在实际应用中的结果。第四，我们讨论了 ULTR 与排名公平性之间的关系。最后，我们简要地回顾了 ULTR 研究及其应用的未来。本教程旨在使那些对开发新的 ULTR 解决方案或在实际应用中使用它们感兴趣的研究人员和行业从业人员受益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recent+Advances+in+the+Foundations+and+Applications+of+Unbiased+Learning+to+Rank)|0|
|[Large-Scale Data Processing for Information Retrieval Applications](https://doi.org/10.1145/3539618.3591797)|Pooya Khandel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large-Scale+Data+Processing+for+Information+Retrieval+Applications)|0|
|[Generative Information Retrieval](https://doi.org/10.1145/3539618.3591871)|Marc Najork|Walmart Labs, Sunnyvale, CA, USA; Instacart, San Francisco, CA, USA|ABSTRACTIn the relatively short history of machine learning, the subtle balance between engineering and theoretical progress has been proved critical at various stages. The most recent wave of AI has brought to the IR community powerful techniques, particularly for pattern recognition. While many benefits from the burst of ideas as numerous tasks become algorithmically feasible, the balance is tilting toward the application side. The existing theoretical tools in IR can no longer explain, guide, and justify the newly-established methodologies. With no choices, we have to bet our design on black-box mechanisms that we only empirically understand. The consequences can be suffering: in stark contrast to how the IR industry has envisioned modern AI making life easier, many are experiencing increased confusion and costs in data manipulation, model selection, monitoring, censoring, and decision making. This reality is not surprising: without handy theoretical tools, we often lack principled knowledge of the pattern recognition model's expressivity, optimization property, generalization guarantee, and our decision-making process has to rely on over-simplified assumptions and human judgments from time to time. Facing all the challenges, we started researching advanced theoretical tools emerging from various domains that can potentially resolve modern IR problems. We encountered many impactful ideas and made several independent publications emphasizing different pieces. Time is now to bring the community a systematic tutorial on how we successfully adapt those tools and make significant progress in understanding, designing, and eventually productionize impactful IR systems. We emphasize systematicity because IR is a comprehensive discipline that touches upon particular aspects of learning, causal inference analysis, interactive (online) decision-making, etc. It thus requires systematic calibrations to render the actual usefulness of the imported theoretical tools to serve IR problems, as they usually exhibit unique structures and definitions. Therefore, we plan this tutorial to systematically demonstrate our learning and successful experience of using advanced theoretical tools for understanding and designing IR systems.|在机器学习相对较短的历史中，工程与理论进步之间的微妙平衡在不同的阶段被证明是至关重要的。最近的人工智能浪潮给红外社区带来了强大的技术，特别是模式识别。虽然随着大量任务在算法上变得可行，思想的迸发带来了许多好处，但是平衡正在向应用程序方面倾斜。现有的 IR 理论工具已经不能解释、指导和证明新建立的方法论。由于别无选择，我们不得不把我们的设计押在我们只能凭经验理解的黑盒机制上。其结果可能是痛苦的: 与红外行业设想的现代人工智能如何使生活变得更容易形成鲜明对比的是，许多人在数据操作、模型选择、监控、审查和决策方面正经历着越来越多的混乱和成本。这一现实并不令人惊讶: 没有方便的理论工具，我们往往缺乏模式识别模型的表达能力、优化特性、泛化保证的原则性知识，我们的决策过程不得不依赖于过于简化的假设和人为判断。面对这些挑战，我们开始研究来自不同领域的先进理论工具，这些工具可以解决现代国际关系问题。我们遇到了许多有影响力的想法，并作出了几个独立的出版物，强调不同的作品。现在是时候给社区带来一个系统的教程，告诉他们我们如何成功地调整这些工具，并在理解、设计和最终生产有影响力的 IR 系统方面取得重大进展。我们强调系统性，因为国际关系是一个综合性的学科，涉及到学习的特定方面，因果推理分析，互动(在线)决策，等等。因此，需要进行系统的校准，以提供进口的理论工具的实际用途，以服务红外问题，因为他们通常表现出独特的结构和定义。因此，我们计划本教程系统地展示我们使用先进的理论工具来理解和设计 IR 系统的学习和成功经验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Information+Retrieval)|0|
|[Tasks, Copilots, and the Future of Search](https://doi.org/10.1145/3539618.3593069)|Ryen W. White||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tasks,+Copilots,+and+the+Future+of+Search)|0|
|[Learning to Re-rank with Constrained Meta-Optimal Transport](https://doi.org/10.1145/3539618.3591714)|Andrés Hoyos Idrobo||Many re-ranking strategies in search systems rely on stochastic ranking policies, encoded as Doubly-Stochastic (DS) matrices, that satisfy desired ranking constraints in expectation, e.g., Fairness of Exposure (FOE). These strategies are generally two-stage pipelines: \emph{i)} an offline re-ranking policy construction step and \emph{ii)} an online sampling of rankings step. Building a re-ranking policy requires repeatedly solving a constrained optimization problem, one for each issued query. Thus, it is necessary to recompute the optimization procedure for any new/unseen query. Regarding sampling, the Birkhoff-von-Neumann decomposition (BvND) is the favored approach to draw rankings from any DS-based policy. However, the BvND is too costly to compute online. Hence, the BvND as a sampling solution is memory-consuming as it can grow as $\gO(N\, n^2)$ for $N$ queries and $n$ documents.   This paper offers a novel, fast, lightweight way to predict fair stochastic re-ranking policies: Constrained Meta-Optimal Transport (CoMOT). This method fits a neural network shared across queries like a learning-to-rank system. We also introduce Gumbel-Matching Sampling (GumMS), an online sampling approach from DS-based policies. Our proposed pipeline, CoMOT + GumMS, only needs to store the parameters of a single model, and it generalizes to unseen queries. We empirically evaluated our pipeline on the TREC 2019 and 2020 datasets under FOE constraints. Our experiments show that CoMOT rapidly predicts fair re-ranking policies on held-out data, with a speed-up proportional to the average number of documents per query. It also displays fairness and ranking performance similar to the original optimization-based policy. Furthermore, we empirically validate the effectiveness of GumMS to approximate DS-based policies in expectation.|搜索系统中的许多重排序策略都依赖于随机排序策略，这些策略被编码为双随机(DS)矩阵，满足期望的排序约束，例如，公平曝光(FOE)。这些策略通常是两个阶段的管道: emph { i }离线重新排序策略构建步骤和 emph { ii }在线排序步骤抽样。构建一个重新排序策略需要重复解决一个受限制的最佳化问题，每个发出的查询一个。因此，有必要重新计算任何新的/未见查询的优化过程。关于抽样，Birkhoff-von-Neumann 分解(BvND)是从任何基于 DS 的政策中提取排名的最受欢迎的方法。然而，在线计算 BvND 的成本太高。因此，作为抽样解决方案的 BvND 占用内存，因为对于 $N $查询和 $n $document，它可以增长为 $gO (N，n ^ 2) $。本文提出了一种新颖、快速、轻量级的预测公平随机重排策略的方法: 约束元最优运输(CoMOT)。该方法适用于跨查询共享的神经网络，如学习排序系统。我们还介绍了 Gumbel 匹配抽样(GumMS) ，一种基于 DS 策略的在线抽样方法。我们提出的流水线 CoMOT + GumMS 只需要存储单个模型的参数，并且它可以推广到不可见的查询。我们在 FOE 约束下对 TREC 2019和2020数据集的管道进行了实证评估。我们的实验表明，CoMOT 能够快速地预测对被拒绝的数据进行公平的重新排序的策略，其速度与每个查询的平均文档数成正比。它还显示公平性和排名性能类似于原来的优化为基础的政策。此外，我们还实验验证了 GumMS 在预期情况下逼近基于 DS 策略的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Re-rank+with+Constrained+Meta-Optimal+Transport)|0|
|[Constructing Tree-based Index for Efficient and Effective Dense Retrieval](https://doi.org/10.1145/3539618.3591651)|Haitao Li, Qingyao Ai, Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Zheng Liu, Zhao Cao||Recent studies have shown that Dense Retrieval (DR) techniques can significantly improve the performance of first-stage retrieval in IR systems. Despite its empirical effectiveness, the application of DR is still limited. In contrast to statistic retrieval models that rely on highly efficient inverted index solutions, DR models build dense embeddings that are difficult to be pre-processed with most existing search indexing systems. To avoid the expensive cost of brute-force search, the Approximate Nearest Neighbor (ANN) algorithm and corresponding indexes are widely applied to speed up the inference process of DR models. Unfortunately, while ANN can improve the efficiency of DR models, it usually comes with a significant price on retrieval performance.   To solve this issue, we propose JTR, which stands for Joint optimization of TRee-based index and query encoding. Specifically, we design a new unified contrastive learning loss to train tree-based index and query encoder in an end-to-end manner. The tree-based negative sampling strategy is applied to make the tree have the maximum heap property, which supports the effectiveness of beam search well. Moreover, we treat the cluster assignment as an optimization problem to update the tree-based index that allows overlapped clustering. We evaluate JTR on numerous popular retrieval benchmarks. Experimental results show that JTR achieves better retrieval performance while retaining high system efficiency compared with widely-adopted baselines. It provides a potential solution to balance efficiency and effectiveness in neural retrieval system designs.|近年来的研究表明，密集检索(DR)技术可以显著提高红外系统第一阶段检索的性能。尽管 DR 在实证研究中取得了一定的成效，但其应用仍然有限。与依赖于高效率倒排索引解决方案的统计检索模型相比，DR 模型构建了密集的嵌入，这些嵌入很难在大多数现有的搜索索引系统中进行预处理。为了避免昂贵的暴力搜索法成本，近似最近邻(ANN)算法和相应的索引被广泛应用于加快 DR 模型的推理过程。遗憾的是，尽管人工神经网络可以提高 DR 模型的效率，但它通常会给检索性能带来巨大的代价。为了解决这个问题，我们提出了 JTR，它代表了基于树的索引和查询编码的联合优化。具体来说，我们设计了一种新的统一对比学习丢失算法，用于以端到端的方式训练基于树的索引和查询编码器。采用基于树的负采样策略，使树具有最大的堆性质，很好地支持了波束搜索的有效性。此外，我们把集群分配当作一个最佳化问题，以更新允许重叠集群的基于树的索引。我们在许多流行的检索基准上评估 JTR。实验结果表明，与广泛采用的基线相比，JTR 在保持较高系统效率的同时，获得了较好的检索性能。它提供了一个潜在的解决方案，以平衡效率和有效的神经检索系统设计。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constructing+Tree-based+Index+for+Efficient+and+Effective+Dense+Retrieval)|0|
|[Multivariate Representation Learning for Information Retrieval](https://doi.org/10.1145/3539618.3591740)|Hamed Zamani, Michael Bendersky||Dense retrieval models use bi-encoder network architectures for learning query and document representations. These representations are often in the form of a vector representation and their similarities are often computed using the dot product function. In this paper, we propose a new representation learning framework for dense retrieval. Instead of learning a vector for each query and document, our framework learns a multivariate distribution and uses negative multivariate KL divergence to compute the similarity between distributions. For simplicity and efficiency reasons, we assume that the distributions are multivariate normals and then train large language models to produce mean and variance vectors for these distributions. We provide a theoretical foundation for the proposed framework and show that it can be seamlessly integrated into the existing approximate nearest neighbor algorithms to perform retrieval efficiently. We conduct an extensive suite of experiments on a wide range of datasets, and demonstrate significant improvements compared to competitive dense retrieval models.|密集检索模型使用双编码器网络结构来学习查询和文档表示。这些表示通常采用向量表示的形式，它们的相似性通常使用点乘函数计算。本文提出了一种新的密集检索表示学习框架。我们的框架不是为每个查询和文档学习一个向量，而是学习一个联合分布，并使用负的多元 KL 散度来计算分布之间的相似性。出于简单和有效的原因，我们假设这些分布是多元正态分布，然后训练大型语言模型来产生这些分布的均值和方差向量。我们为该框架提供了理论基础，并表明该框架可以无缝集成到现有的近似最近邻算法中，从而有效地进行检索。我们在广泛的数据集上进行了大量的实验，并证明了与竞争性的密集检索模型相比有显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multivariate+Representation+Learning+for+Information+Retrieval)|0|
|[Prompt Learning for News Recommendation](https://doi.org/10.1145/3539618.3591752)|Zizhuo Zhang, Bang Wang||Some recent \textit{news recommendation} (NR) methods introduce a Pre-trained Language Model (PLM) to encode news representation by following the vanilla pre-train and fine-tune paradigm with carefully-designed recommendation-specific neural networks and objective functions. Due to the inconsistent task objective with that of PLM, we argue that their modeling paradigm has not well exploited the abundant semantic information and linguistic knowledge embedded in the pre-training process. Recently, the pre-train, prompt, and predict paradigm, called \textit{prompt learning}, has achieved many successes in natural language processing domain. In this paper, we make the first trial of this new paradigm to develop a \textit{Prompt Learning for News Recommendation} (Prompt4NR) framework, which transforms the task of predicting whether a user would click a candidate news as a cloze-style mask-prediction task. Specifically, we design a series of prompt templates, including discrete, continuous, and hybrid templates, and construct their corresponding answer spaces to examine the proposed Prompt4NR framework. Furthermore, we use the prompt ensembling to integrate predictions from multiple prompt templates. Extensive experiments on the MIND dataset validate the effectiveness of our Prompt4NR with a set of new benchmark results.|最近的一些文本{新闻推荐}(NR)方法引入了一个预训练语言模型(Pre-training Language Model，PLM) ，通过使用精心设计的特定于推荐的神经网络和目标函数，遵循普通的预训练和微调范式，对新闻表示进行编码。由于 PLM 的任务目标不一致，我们认为他们的建模范式没有很好地利用预培训过程中包含的丰富的语义信息和语言知识。近年来，自然语言处理领域的预训练、提示和预测范式(文本{提示学习})取得了许多成功。本文首次尝试开发了一个文本提示学习新闻推荐(Prompt4NR)框架，该框架将预测用户是否点击候选新闻的任务转化为完形填空式的面具预测任务。具体来说，我们设计了一系列的提示模板，包括离散的、连续的和混合的模板，并构造它们相应的答案空间来检查提出的 Prompt4NR 框架。此外，我们使用提示合并来集成来自多个提示模板的预测。MIND 数据集上的大量实验验证了 Prompt4NR 的有效性，并提供了一组新的基准测试结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Learning+for+News+Recommendation)|0|
|[Alleviating Matthew Effect of Offline Reinforcement Learning in Interactive Recommendation](https://doi.org/10.1145/3539618.3591636)|Chongming Gao, Kexin Huang, Jiawei Chen, Yuan Zhang, Biao Li, Peng Jiang, Shiqi Wang, Zhong Zhang, Xiangnan He||Offline reinforcement learning (RL), a technology that offline learns a policy from logged data without the need to interact with online environments, has become a favorable choice in decision-making processes like interactive recommendation. Offline RL faces the value overestimation problem. To address it, existing methods employ conservatism, e.g., by constraining the learned policy to be close to behavior policies or punishing the rarely visited state-action pairs. However, when applying such offline RL to recommendation, it will cause a severe Matthew effect, i.e., the rich get richer and the poor get poorer, by promoting popular items or categories while suppressing the less popular ones. It is a notorious issue that needs to be addressed in practical recommender systems.   In this paper, we aim to alleviate the Matthew effect in offline RL-based recommendation. Through theoretical analyses, we find that the conservatism of existing methods fails in pursuing users' long-term satisfaction. It inspires us to add a penalty term to relax the pessimism on states with high entropy of the logging policy and indirectly penalizes actions leading to less diverse states. This leads to the main technical contribution of the work: Debiased model-based Offline RL (DORL) method. Experiments show that DORL not only captures user interests well but also alleviates the Matthew effect. The implementation is available via https://github.com/chongminggao/DORL-codes.|离线强化学习(off-line)是一种无需与在线环境交互就可以从已记录的数据中学习策略的技术，已经成为诸如交互式推荐等决策过程中的一个有利选择。脱机 RL 面临价值高估问题。为了解决这个问题，现有的方法采用了保守主义，例如，通过限制学习政策接近行为政策或惩罚很少访问的国家行动对。然而，当把这种线下 RL 应用于推荐时，它会产生一种严重的马太效应，也就是说，富人变得更富，穷人变得更穷，通过推销受欢迎的项目或类别，同时压制不太受欢迎的项目或类别。这是一个臭名昭著的问题，需要解决的实际推荐系统。本文旨在减轻基于 RL 的离线推荐中的马太效应。通过理论分析，我们发现现有方法的保守性不足以追求用户的长期满意度。它启发我们增加一个惩罚项，以放松对伐木政策的高熵状态的悲观情绪，并间接惩罚导致较少多样性状态的行动。这导致了这项工作的主要技术贡献: 基于消偏模型的离线 RL (DORL)方法。实验表明，DORL 不仅能够很好地捕获用户兴趣，而且能够减轻马太效应。有关实施方案可透过 https://github.com/chongminggao/dorl-codes 提供。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Alleviating+Matthew+Effect+of+Offline+Reinforcement+Learning+in+Interactive+Recommendation)|0|
|[Distributionally Robust Sequential Recommnedation](https://doi.org/10.1145/3539618.3591668)|Rui Zhou, Xian Wu, Zhaopeng Qiu, Yefeng Zheng, Xu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributionally+Robust+Sequential+Recommnedation)|0|
|[Knowledge-refined Denoising Network for Robust Recommendation](https://doi.org/10.1145/3539618.3591707)|Xinjun Zhu, Yuntao Du, Yuren Mao, Lu Chen, Yujia Hu, Yunjun Gao||Knowledge graph (KG), which contains rich side information, becomes an essential part to boost the recommendation performance and improve its explainability. However, existing knowledge-aware recommendation methods directly perform information propagation on KG and user-item bipartite graph, ignoring the impacts of \textit{task-irrelevant knowledge propagation} and \textit{vulnerability to interaction noise}, which limits their performance. To solve these issues, we propose a robust knowledge-aware recommendation framework, called \textit{Knowledge-refined Denoising Network} (KRDN), to prune the task-irrelevant knowledge associations and noisy implicit feedback simultaneously. KRDN consists of an adaptive knowledge refining strategy and a contrastive denoising mechanism, which are able to automatically distill high-quality KG triplets for aggregation and prune noisy implicit feedback respectively. Besides, we also design the self-adapted loss function and the gradient estimator for model optimization. The experimental results on three benchmark datasets demonstrate the effectiveness and robustness of KRDN over the state-of-the-art knowledge-aware methods like KGIN, MCCLK, and KGCL, and also outperform robust recommendation models like SGL and SimGCL.|知识图(KG)包含了丰富的边信息，是提高推荐性能、增强推荐可解释性的重要组成部分。然而，现有的知识感知推荐方法直接在 KG 和用户项二分图上进行信息传播，忽略了文本{任务无关知识传播}和文本{交互噪声脆弱性}的影响，从而限制了它们的性能。为了解决这些问题，我们提出了一个鲁棒的知识感知推荐框架，称为 texttit { Knowledge-finedDenoisingNetwork }(KRDN) ，它可以同时修剪与任务无关的知识关联和有噪隐式反馈。KRDN 由自适应知识精炼策略和对比去噪机制两部分组成，它们分别能够自动提取高质量的 KG 三元组用于聚集和删除含噪隐式反馈。此外，我们还设计了自适应损失函数和模型优化的梯度估计器。在三个基准数据集上的实验结果显示了 KRDN 相对于最先进的知识感知方法(如 KGIN、 MCCLK 和 KGCL)的有效性和稳健性，也优于稳健的推荐模型(如 SGL 和 SimGCL)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-refined+Denoising+Network+for+Robust+Recommendation)|0|
|[Mixed-Curvature Manifolds Interaction Learning for Knowledge Graph-aware Recommendation](https://doi.org/10.1145/3539618.3591730)|Jihu Wang, Yuliang Shi, Han Yu, Xinjun Wang, Zhongmin Yan, Fanyu Kong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mixed-Curvature+Manifolds+Interaction+Learning+for+Knowledge+Graph-aware+Recommendation)|0|
|[EEDN: Enhanced Encoder-Decoder Network with Local and Global Context Learning for POI Recommendation](https://doi.org/10.1145/3539618.3591678)|Xinfeng Wang, Fumiyo Fukumoto, Jin Cui, Yoshimi Suzuki, Jiyi Li, Dongjin Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EEDN:+Enhanced+Encoder-Decoder+Network+with+Local+and+Global+Context+Learning+for+POI+Recommendation)|0|
|[Adaptive Graph Representation Learning for Next POI Recommendation](https://doi.org/10.1145/3539618.3591634)|Zhaobo Wang, Yanmin Zhu, Chunyang Wang, Wenze Ma, Bo Li, Jiadi Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Graph+Representation+Learning+for+Next+POI+Recommendation)|0|
|[Spatio-Temporal Hypergraph Learning for Next POI Recommendation](https://doi.org/10.1145/3539618.3591770)|Xiaodong Yan, Tengwei Song, Yifeng Jiao, Jianshan He, Jiaotuan Wang, Ruopeng Li, Wei Chu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Hypergraph+Learning+for+Next+POI+Recommendation)|0|
|[Mining Stable Preferences: Adaptive Modality Decorrelation for Multimedia Recommendation](https://doi.org/10.1145/3539618.3591729)|Jinghao Zhang, Qiang Liu, Shu Wu, Liang Wang||Multimedia content is of predominance in the modern Web era. In real scenarios, multiple modalities reveal different aspects of item attributes and usually possess different importance to user purchase decisions. However, it is difficult for models to figure out users' true preference towards different modalities since there exists strong statistical correlation between modalities. Even worse, the strong statistical correlation might mislead models to learn the spurious preference towards inconsequential modalities. As a result, when data (modal features) distribution shifts, the learned spurious preference might not guarantee to be as effective on the inference set as on the training set. We propose a novel MOdality DEcorrelating STable learning framework, MODEST for brevity, to learn users' stable preference. Inspired by sample re-weighting techniques, the proposed method aims to estimate a weight for each item, such that the features from different modalities in the weighted distribution are decorrelated. We adopt Hilbert Schmidt Independence Criterion (HSIC) as independence testing measure which is a kernel-based method capable of evaluating the correlation degree between two multi-dimensional and non-linear variables. Our method could be served as a play-and-plug module for existing multimedia recommendation backbones. Extensive experiments on four public datasets and four state-of-the-art multimedia recommendation backbones unequivocally show that our proposed method can improve the performances by a large margin.|在现代网络时代，多媒体内容占有主导地位。在实际场景中，多种模式揭示了商品属性的不同方面，对用户的购买决策具有不同的重要性。然而，由于模式之间存在很强的统计相关性，模型很难计算出用户对不同模式的真实偏好。更糟糕的是，这种强烈的统计相关性可能会误导模型，使其学会对无关紧要的模式的虚假偏好。因此，当数据(模态特征)分布发生变化时，学习到的虚假偏好可能不能保证在推理集上和在训练集上同样有效。我们提出了一个新的模态解相关稳定学习框架，MODEST 为简洁，学习用户的稳定偏好。该方法受样本重新加权技术的启发，旨在估计每个项目的权重，使不同方式的特征在加权分布中不相关。我们采用 Hilbert Schmidt 独立准则(HSIC)作为独立性测度，这是一种基于核的方法，能够评估两个多维和非线性变量之间的相关程度。我们的方法可以作为现有多媒体推荐主干的播放和即插即用模块。对四个公共数据集和四个最先进的多媒体推荐骨干网的大量实验表明，我们提出的方法可以大幅度提高性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Stable+Preferences:+Adaptive+Modality+Decorrelation+for+Multimedia+Recommendation)|0|
|[MEME: Multi-Encoder Multi-Expert Framework with Data Augmentation for Video Retrieval](https://doi.org/10.1145/3539618.3591726)|SeongMin Kang, YoonSik Cho||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MEME:+Multi-Encoder+Multi-Expert+Framework+with+Data+Augmentation+for+Video+Retrieval)|0|
|[Multi-Scenario Ranking with Adaptive Feature Learning](https://doi.org/10.1145/3539618.3591736)|Yu Tian, Bofang Li, Si Chen, Xubin Li, Hongbo Deng, Jian Xu, Bo Zheng, Qian Wang, Chenliang Li||Recently, Multi-Scenario Learning (MSL) is widely used in recommendation and retrieval systems in the industry because it facilitates transfer learning from different scenarios, mitigating data sparsity and reducing maintenance cost. These efforts produce different MSL paradigms by searching more optimal network structure, such as Auxiliary Network, Expert Network, and Multi-Tower Network. It is intuitive that different scenarios could hold their specific characteristics, activating the user's intents quite differently. In other words, different kinds of auxiliary features would bear varying importance under different scenarios. With more discriminative feature representations refined in a scenario-aware manner, better ranking performance could be easily obtained without expensive search for the optimal network structure. Unfortunately, this simple idea is mainly overlooked but much desired in real-world systems.Further analysis also validates the rationality of adaptive feature learning under a multi-scenario scheme. Moreover, our A/B test results on the Alibaba search advertising platform also demonstrate that Maria is superior in production environments.|近年来，多场景学习(Multi-Scenario Learning，MSL)技术被广泛应用于业界的推荐和检索系统中，因为它可以方便地从不同场景中进行转移学习，减少数据稀疏性，降低维护成本。这些努力通过寻找更多的最优网络结构，如辅助网络，专家网络和多塔网络，产生不同的 MSL 范例。直观地说，不同的场景可以保持其特定的特征，激活用户的意图完全不同。换句话说，不同的辅助特征在不同的场景下具有不同的重要性。随着更多的区分性特征表示在场景感知方式精化，可以很容易地获得更好的排序性能，而不需要对最优网络结构进行昂贵的搜索。不幸的是，这个简单的想法在现实系统中基本上被忽视了，但是却是非常需要的。进一步的分析也验证了多场景方案下自适应特征学习的合理性。此外，我们在阿里巴巴搜索广告平台的 A/B 测试结果也表明，玛丽亚在生产环境方面更胜一筹。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Scenario+Ranking+with+Adaptive+Feature+Learning)|0|
|[Curse of "Low" Dimensionality in Recommender Systems](https://doi.org/10.1145/3539618.3591659)|Naoto Ohsaka, Riku Togashi||Beyond accuracy, there are a variety of aspects to the quality of recommender systems, such as diversity, fairness, and robustness. We argue that many of the prevalent problems in recommender systems are partly due to low-dimensionality of user and item embeddings, particularly when dot-product models, such as matrix factorization, are used.   In this study, we showcase empirical evidence suggesting the necessity of sufficient dimensionality for user/item embeddings to achieve diverse, fair, and robust recommendation. We then present theoretical analyses of the expressive power of dot-product models. Our theoretical results demonstrate that the number of possible rankings expressible under dot-product models is exponentially bounded by the dimension of item factors. We empirically found that the low-dimensionality contributes to a popularity bias, widening the gap between the rank positions of popular and long-tail items; we also give a theoretical justification for this phenomenon.|除了准确性之外，推荐系统的质量还有很多方面，比如多样性、公平性和鲁棒性。我们认为，推荐系统中许多普遍存在的问题，部分是由于用户和项目嵌入的维度较低，特别是当使用像矩阵分解这样的点产品模型时。在这项研究中，我们展示了一些经验证明，它们表明了用户/项目嵌入需要足够的维度来实现多样化、公平和强大的推荐。然后，我们提出了理论分析的表达能力的点积模式。我们的理论结果表明，在点乘模型下可表达的排名的数量是指数约束的项目因素的维度。实证研究发现，低维度导致了流行偏差，扩大了流行项目和长尾项目的排名差距，并对这一现象进行了理论解释。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curse+of+"Low"+Dimensionality+in+Recommender+Systems)|0|
|[Subgraph Search over Neural-Symbolic Graphs](https://doi.org/10.1145/3539618.3591773)|Ye Yuan, Delong Ma, Anbiao Wu, Jianbin Qin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Subgraph+Search+over+Neural-Symbolic+Graphs)|0|
|[Explainable Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks](https://doi.org/10.1145/3539618.3591682)|Philipp Christmann, Rishiraj Saha Roy, Gerhard Weikum||In conversational question answering, users express their information needs through a series of utterances with incomplete context. Typical ConvQA methods rely on a single source (a knowledge base (KB), or a text corpus, or a set of tables), thus being unable to benefit from increased answer coverage and redundancy of multiple sources. Our method EXPLAIGNN overcomes these limitations by integrating information from a mixture of sources with user-comprehensible explanations for answers. It constructs a heterogeneous graph from entities and evidence snippets retrieved from a KB, a text corpus, web tables, and infoboxes. This large graph is then iteratively reduced via graph neural networks that incorporate question-level attention, until the best answers and their explanations are distilled. Experiments show that EXPLAIGNN improves performance over state-of-the-art baselines. A user study demonstrates that derived answers are understandable by end users.|在会话问答中，用户通过一系列语境不完整的话语来表达自己的信息需求。典型的 ConvQA 方法依赖于单个源(知识库(KB)、文本语料库或一组表) ，因此无法从增加的答案覆盖率和多个源的冗余中获益。我们的方法 EXPLAIGNN 克服了这些限制，整合了来自各种来源的信息和用户可理解的答案解释。它通过从知识库、文本语料库、 Web 表格和信息框中检索到的实体和证据片段构造一个异构图。然后通过包含问题级注意力的图形神经网络迭代地缩减这个大图，直到最佳答案及其解释被提炼出来。实验表明，EXPLAIGNN 提高了性能超过最先进的基线。用户研究表明，最终用户可以理解派生的答案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Conversational+Question+Answering+over+Heterogeneous+Sources+via+Iterative+Graph+Neural+Networks)|0|
|[Data-Aware Proxy Hashing for Cross-modal Retrieval](https://doi.org/10.1145/3539618.3591660)|RongCheng Tu, XianLing Mao, Wenjin Ji, Wei Wei, Heyan Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data-Aware+Proxy+Hashing+for+Cross-modal+Retrieval)|0|
|[Hear Me Out: A Study on the Use of the Voice Modality for Crowdsourced Relevance Assessments](https://doi.org/10.1145/3539618.3591694)|Nirmal Roy, Agathe Balayn, David Maxwell, Claudia Hauff||The creation of relevance assessments by human assessors (often nowadays crowdworkers) is a vital step when building IR test collections. Prior works have investigated assessor quality & behaviour, though into the impact of a document's presentation modality on assessor efficiency and effectiveness. Given the rise of voice-based interfaces, we investigate whether it is feasible for assessors to judge the relevance of text documents via a voice-based interface. We ran a user study (n = 49) on a crowdsourcing platform where participants judged the relevance of short and long documents sampled from the TREC Deep Learning corpus-presented to them either in the text or voice modality. We found that: (i) participants are equally accurate in their judgements across both the text and voice modality; (ii) with increased document length it takes participants significantly longer (for documents of length > 120 words it takes almost twice as much time) to make relevance judgements in the voice condition; and (iii) the ability of assessors to ignore stimuli that are not relevant (i.e., inhibition) impacts the assessment quality in the voice modality-assessors with higher inhibition are significantly more accurate than those with lower inhibition. Our results indicate that we can reliably leverage the voice modality as a means to effectively collect relevance labels from crowdworkers.|由人工评估员(通常是现在的众包工作者)创建相关性评估是构建 IR 测试集的关键步骤。以前的工作已经调查了评估员的质量和行为，尽管文件的呈现方式对评估员的效率和有效性的影响。鉴于基于语音的接口的兴起，我们研究了评估者通过基于语音的接口来判断文本文档的相关性是否可行。我们在一个众包平台上运行了一个用户研究(n = 49) ，参与者判断从 TREC 深度学习语料库中取样的短文档和长文档的相关性——以文本或语音形式呈现给他们。我们发现: (i)参与者在文本和语音模式中的判断同样准确; (ii)随着文件长度的增加，参与者在语音条件下做出相关判断的时间显著延长(对于长度 > 120个单词的文件，需要几乎两倍的时间) ; 以及(iii)评估者忽略不相关刺激(即抑制)的能力影响语音模式中的评估质量-抑制程度较高的评估者比抑制程度较低的评估者明显更准确。我们的研究结果表明，我们可以可靠地利用语音模式作为一种手段，有效地收集相关标签从众工作者。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hear+Me+Out:+A+Study+on+the+Use+of+the+Voice+Modality+for+Crowdsourced+Relevance+Assessments)|0|
|[Asymmetric Hashing for Fast Ranking via Neural Network Measures](https://doi.org/10.1145/3539618.3591640)|Khoa D. Doan, Shulong Tan, Weijie Zhao, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Asymmetric+Hashing+for+Fast+Ranking+via+Neural+Network+Measures)|0|
|[Wisdom of Crowds and Fine-Grained Learning for Serendipity Recommendations](https://doi.org/10.1145/3539618.3591787)|Zhe Fu, Xi Niu, Li Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wisdom+of+Crowds+and+Fine-Grained+Learning+for+Serendipity+Recommendations)|0|
|[An Effective Framework for Enhancing Query Answering in a Heterogeneous Data Lake](https://doi.org/10.1145/3539618.3591637)|Qin Yuan, Ye Yuan, Zhenyu Wen, He Wang, Shiyuan Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Effective+Framework+for+Enhancing+Query+Answering+in+a+Heterogeneous+Data+Lake)|0|
|[BeamQA: Multi-hop Knowledge Graph Question Answering with Sequence-to-Sequence Prediction and Beam Search](https://doi.org/10.1145/3539618.3591698)|Farah Atif, Ola El Khatib, Djellel Eddine Difallah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BeamQA:+Multi-hop+Knowledge+Graph+Question+Answering+with+Sequence-to-Sequence+Prediction+and+Beam+Search)|0|
|[Time-interval Aware Share Recommendation via Bi-directional Continuous Time Dynamic Graphs](https://doi.org/10.1145/3539618.3591775)|Ziwei Zhao, Xi Zhu, Tong Xu, Aakas Lizhiyu, Yu Yu, Xueying Li, Zikai Yin, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-interval+Aware+Share+Recommendation+via+Bi-directional+Continuous+Time+Dynamic+Graphs)|0|
|[Diffusion Recommender Model](https://doi.org/10.1145/3539618.3591663)|Wenjie Wang, Yiyan Xu, Fuli Feng, Xinyu Lin, Xiangnan He, TatSeng Chua||Generative models such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) are widely utilized to model the generative process of user interactions. However, these generative models suffer from intrinsic limitations such as the instability of GANs and the restricted representation ability of VAEs. Such limitations hinder the accurate modeling of the complex user interaction generation procedure, such as noisy interactions caused by various interference factors. In light of the impressive advantages of Diffusion Models (DMs) over traditional generative models in image synthesis, we propose a novel Diffusion Recommender Model (named DiffRec) to learn the generative process in a denoising manner. To retain personalized information in user interactions, DiffRec reduces the added noises and avoids corrupting users' interactions into pure noises like in image synthesis. In addition, we extend traditional DMs to tackle the unique challenges in practical recommender systems: high resource costs for large-scale item prediction and temporal shifts of user preference. To this end, we propose two extensions of DiffRec: L-DiffRec clusters items for dimension compression and conducts the diffusion processes in the latent space; and T-DiffRec reweights user interactions based on the interaction timestamps to encode temporal information. We conduct extensive experiments on three datasets under multiple settings (e.g. clean training, noisy training, and temporal training). The empirical results and in-depth analysis validate the superiority of DiffRec with two extensions over competitive baselines.|生成模型如生成对抗网络(GANs)和变分自动编码器(VAE)被广泛地用于模拟用户交互的生成过程。然而，这些生成模型受到 GAN 的不稳定性和 VAE 表示能力的限制等内在的局限性。这些局限性阻碍了复杂用户交互生成过程的精确建模，例如由各种干扰因素引起的噪声交互。鉴于扩散模型在图像合成中相对于传统生成模型的显著优势，我们提出了一种新的扩散推荐模型。为了在用户交互中保留个性化信息，区分反射降低了附加的噪声，避免了在图像合成中将用户交互变成纯粹的噪声。此外，我们还扩展了传统的数据模型，以解决实际推荐系统中面临的独特挑战: 大规模项目预测的高资源成本和用户偏好的时间变化。为此，我们提出了区分反射的两个扩展: L-DiffRec 聚类项用于维数压缩并在潜空间中进行扩散过程; T-DiffRec 基于交互时间戳重新加权用户交互以编码时间信息。我们在三个数据集上进行了多重设置下的广泛实验(例如干净训练、噪声训练和时间训练)。实证结果和深入的分析验证了区分共享的优越性与两个扩展的竞争基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion+Recommender+Model)|0|
|[Relation-Aware Multi-Positive Contrastive Knowledge Graph Completion with Embedding Dimension Scaling](https://doi.org/10.1145/3539618.3591756)|Bin Shang, Yinliang Zhao, Di Wang, Jun Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relation-Aware+Multi-Positive+Contrastive+Knowledge+Graph+Completion+with+Embedding+Dimension+Scaling)|0|
|[Weighted Knowledge Graph Embedding](https://doi.org/10.1145/3539618.3591784)|Zhao Zhang, Zhanpeng Guan, Fuwei Zhang, Fuzhen Zhuang, Zhulin An, Fei Wang, Yongjun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weighted+Knowledge+Graph+Embedding)|0|
|[Contrastive State Augmentations for Reinforcement Learning-Based Recommender Systems](https://doi.org/10.1145/3539618.3591656)|Zhaochun Ren, Na Huang, Yidan Wang, Pengjie Ren, Jun Ma, Jiahuan Lei, Xinlei Shi, Hengliang Luo, Joemon M. Jose, Xin Xin||Learning reinforcement learning (RL)-based recommenders from historical user-item interaction sequences is vital to generate high-reward recommendations and improve long-term cumulative benefits. However, existing RL recommendation methods encounter difficulties (i) to estimate the value functions for states which are not contained in the offline training data, and (ii) to learn effective state representations from user implicit feedback due to the lack of contrastive signals. In this work, we propose contrastive state augmentations (CSA) for the training of RL-based recommender systems. To tackle the first issue, we propose four state augmentation strategies to enlarge the state space of the offline data. The proposed method improves the generalization capability of the recommender by making the RL agent visit the local state regions and ensuring the learned value functions are similar between the original and augmented states. For the second issue, we propose introducing contrastive signals between augmented states and the state randomly sampled from other sessions to improve the state representation learning further. To verify the effectiveness of the proposed CSA, we conduct extensive experiments on two publicly accessible datasets and one dataset collected from a real-life e-commerce platform. We also conduct experiments on a simulated environment as the online evaluation setting. Experimental results demonstrate that CSA can effectively improve recommendation performance.|从历史用户项目交互序列中学习基于强化学习的推荐对于产生高回报的推荐和提高长期累积效益至关重要。然而，现有的 RL 推荐方法遇到了困难(i)估计不包含在离线训练数据中的状态的值函数，以及(ii)由于缺乏对比信号而从用户隐式反馈中学习有效的状态表示。在这项工作中，我们提出了对比状态增强(CSA)的训练基于 RL 的推荐系统。针对第一个问题，我们提出了四种状态增强策略来扩大离线数据的状态空间。该方法通过使 RL 代理访问局部状态区域，保证学习值函数在原状态和增广状态之间相似，提高了推荐器的泛化能力。对于第二个问题，我们提出在增广状态和从其他会话中随机采样的状态之间引入对比信号，以进一步改进状态表示学习。为了验证所提出的 CSA 的有效性，我们对从现实生活中的电子商务平台收集的两个公开可访问的数据集和一个数据集进行了广泛的实验。我们还进行了模拟环境的实验，作为在线评价设置。实验结果表明，CSA 能有效提高推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+State+Augmentations+for+Reinforcement+Learning-Based+Recommender+Systems)|0|
|[Multi-order Matched Neighborhood Consistent Graph Alignment in a Union Vector Space](https://doi.org/10.1145/3539618.3591735)|Wei Tang, Haifeng Sun, Jingyu Wang, Qi Qi, Jing Wang, Hao Yang, Shimin Tao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-order+Matched+Neighborhood+Consistent+Graph+Alignment+in+a+Union+Vector+Space)|0|
|[Personalized Federated Relation Classification over Heterogeneous Texts](https://doi.org/10.1145/3539618.3591748)|Ning Pang, Xiang Zhao, Weixin Zeng, Ji Wang, Weidong Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Federated+Relation+Classification+over+Heterogeneous+Texts)|0|
|[SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval](https://doi.org/10.1145/3539618.3591761)|Haitao Li, Qingyao Ai, Jia Chen, Qian Dong, Yueyue Wu, Yiqun Liu, Chong Chen, Qi Tian||Legal case retrieval, which aims to find relevant cases for a query case, plays a core role in the intelligent legal system. Despite the success that pre-training has achieved in ad-hoc retrieval tasks, effective pre-training strategies for legal case retrieval remain to be explored. Compared with general documents, legal case documents are typically long text sequences with intrinsic logical structures. However, most existing language models have difficulty understanding the long-distance dependencies between different structures. Moreover, in contrast to the general retrieval, the relevance in the legal domain is sensitive to key legal elements. Even subtle differences in key legal elements can significantly affect the judgement of relevance. However, existing pre-trained language models designed for general purposes have not been equipped to handle legal elements.   To address these issues, in this paper, we propose SAILER, a new Structure-Aware pre-traIned language model for LEgal case Retrieval. It is highlighted in the following three aspects: (1) SAILER fully utilizes the structural information contained in legal case documents and pays more attention to key legal elements, similar to how legal experts browse legal case documents. (2) SAILER employs an asymmetric encoder-decoder architecture to integrate several different pre-training objectives. In this way, rich semantic information across tasks is encoded into dense vectors. (3) SAILER has powerful discriminative ability, even without any legal annotation data. It can distinguish legal cases with different charges accurately. Extensive experiments over publicly available legal benchmarks demonstrate that our approach can significantly outperform previous state-of-the-art methods in legal case retrieval.|法律案例检索是智能法律系统的核心，其目的是为查询案例寻找相关案例。尽管在特别检索任务方面的预先培训取得了成功，但仍有待探索法律案件检索的有效预先培训战略。与一般文献相比，法律案例文献通常是具有内在逻辑结构的长文本序列。然而，大多数现有的语言模型难以理解不同结构之间的长距离依赖关系。此外，与一般检索相比，法律领域的相关性对关键的法律要素是敏感的。即使在关键法律要素方面存在细微差别，也会对相关性的判断产生重大影响。然而，为一般目的而设计的现有预先训练的语言模式尚未具备处理法律要素的能力。为了解决这些问题，本文提出了一种新的法律案例检索的结构感知预训练语言模型 SAILER。这主要体现在以下三个方面: (1) SAILER 充分利用了法律案例文档中的结构信息，更加注重关键的法律要素，类似于法律专家浏览法律案例文档的方式。(2) SAILER 采用非对称编解码体系结构集成多个不同的训练前目标。通过这种方式，跨任务的丰富语义信息被编码成密集的向量。(3)即使没有任何法律注释数据，赛勒仍具有强大的辨别能力。它可以准确地区分不同指控的法律案件。对公开可用的法律基准进行的大量实验表明，我们的方法在法律案件检索方面可以显著优于以前的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAILER:+Structure-aware+Pre-trained+Language+Model+for+Legal+Case+Retrieval)|0|
|[Triple Structural Information Modelling for Accurate, Explainable and Interactive Recommendation](https://doi.org/10.1145/3539618.3591779)|Jiahao Liu, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, Li Shang, Ning Gu||In dynamic interaction graphs, user-item interactions usually follow heterogeneous patterns, represented by different structural information, such as user-item co-occurrence, sequential information of user interactions and the transition probabilities of item pairs. However, the existing methods cannot simultaneously leverage all three structural information, resulting in suboptimal performance. To this end, we propose TriSIM4Rec, a triple structural information modeling method for accurate, explainable and interactive recommendation on dynamic interaction graphs. Specifically, TriSIM4Rec consists of 1) a dynamic ideal low-pass graph filter to dynamically mine co-occurrence information in user-item interactions, which is implemented by incremental singular value decomposition (SVD); 2) a parameter-free attention module to capture sequential information of user interactions effectively and efficiently; and 3) an item transition matrix to store the transition probabilities of item pairs. Then, we fuse the predictions from the triple structural information sources to obtain the final recommendation results. By analyzing the relationship between the SVD-based and the recently emerging graph signal processing (GSP)-based collaborative filtering methods, we find that the essence of SVD is an ideal low-pass graph filter, so that the interest vector space in TriSIM4Rec can be extended to achieve explainable and interactive recommendation, making it possible for users to actively break through the information cocoons. Experiments on six public datasets demonstrated the effectiveness of TriSIM4Rec in accuracy, explainability and interactivity.|在动态交互图中，用户-项目交互通常遵循异构模式，表现为不同的结构信息，如用户-项目共现、用户交互的序列信息和项目对的转移概率。然而，现有的方法不能同时利用所有三个结构信息，导致次优性能。为此，我们提出了一种三重结构信息建模方法 TriSIM4Rec，用于对动态交互图进行精确、可解释和交互式的推荐。具体来说，TriSIM4Rec 包括: 1)一个动态的理想低通图形过滤器，用于动态挖掘用户-项目交互中的共现信息，该过滤器通过增量奇异值分解(SVD)实现; 2)一个无参数注意模块，用于有效和高效地捕获用户交互的连续信息; 3)一个项目，用于存储项目对的过渡概率转移矩阵。然后，我们融合来自三重结构信息源的预测，得到最终的推荐结果。通过分析基于奇异值分解和最近出现的基于图形信号处理(gSP)的协同过滤方法之间的关系，我们发现奇异值分解的本质是一个理想的低通图形滤波器，因此可以扩展 TriSIM4Rec 中的兴趣向量空间，以实现可解释和交互式的推荐，使用户能够积极地突破信息茧。在六个公共数据集上的实验证明了 TriSIM4Rec 在准确性、可解释性和交互性方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Triple+Structural+Information+Modelling+for+Accurate,+Explainable+and+Interactive+Recommendation)|0|
|[Blurring-Sharpening Process Models for Collaborative Filtering](https://doi.org/10.1145/3539618.3591645)|Jeongwhan Choi, Seoyoung Hong, Noseong Park, SungBae Cho||Collaborative filtering is one of the most fundamental topics for recommender systems. Various methods have been proposed for collaborative filtering, ranging from matrix factorization to graph convolutional methods. Being inspired by recent successes of graph filtering-based methods and score-based generative models (SGMs), we present a novel concept of blurring-sharpening process model (BSPM). SGMs and BSPMs share the same processing philosophy that new information can be discovered (e.g., new images are generated in the case of SGMs) while original information is first perturbed and then recovered to its original form. However, SGMs and our BSPMs deal with different types of information, and their optimal perturbation and recovery processes have fundamental discrepancies. Therefore, our BSPMs have different forms from SGMs. In addition, our concept not only theoretically subsumes many existing collaborative filtering models but also outperforms them in terms of Recall and NDCG in the three benchmark datasets, Gowalla, Yelp2018, and Amazon-book. In addition, the processing time of our method is comparable to other fast baselines. Our proposed concept has much potential in the future to be enhanced by designing better blurring (i.e., perturbation) and sharpening (i.e., recovery) processes than what we use in this paper.|协同过滤是推荐系统最基本的课题之一。人们提出了各种各样的协同过滤方法，从矩阵分解卷积法到图卷积法。受基于图过滤和基于分数的生成模型(SGMs)的启发，我们提出了模糊锐化过程模型(BSPM)的新概念。SGMs 和 BSPM 有着相同的处理哲学，即新信息可以被发现(例如，在 SGMs 中，新图像产生了) ，而原始信息首先受到干扰，然后恢复到其原始形式。然而，SGM 和我们的 BSPM 处理不同类型的信息，他们的最优扰动和恢复过程有根本的差异。因此，我们的 BSPM 有不同于 SGM 的形式。此外，我们的概念不仅在理论上包含了许多现有的协同过滤模型，而且在三个基准数据集(Gowalla、 Yelp2018和亚马逊-book)的 Recall 和 NDCG 方面也优于它们。此外，该方法的处理时间与其他快速基线相当。我们提出的概念在未来有很大的潜力，通过设计更好的模糊(即，扰动)和锐化(即，恢复)过程比我们在本文中使用的增强。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Blurring-Sharpening+Process+Models+for+Collaborative+Filtering)|0|
|[AdaMCL: Adaptive Fusion Multi-View Contrastive Learning for Collaborative Filtering](https://doi.org/10.1145/3539618.3591632)|Guanghui Zhu, Wang Lu, Chunfeng Yuan, Yihua Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaMCL:+Adaptive+Fusion+Multi-View+Contrastive+Learning+for+Collaborative+Filtering)|0|
|[Collaborative Residual Metric Learning](https://doi.org/10.1145/3539618.3591649)|Tianjun Wei, Jianghong Ma, Tommy W. S. Chow||In collaborative filtering, distance metric learning has been applied to matrix factorization techniques with promising results. However, matrix factorization lacks the ability of capturing collaborative information, which has been remarked by recent works and improved by interpreting user interactions as signals. This paper aims to find out how metric learning connect to these signal-based models. By adopting a generalized distance metric, we discovered that in signal-based models, it is easier to estimate the residual of distances, which refers to the difference between the distances from a user to a target item and another item, rather than estimating the distances themselves. Further analysis also uncovers a link between the normalization strength of interaction signals and the novelty of recommendation, which has been overlooked by existing studies. Based on the above findings, we propose a novel model to learn a generalized distance user-item distance metric to capture user preference in interaction signals by modeling the residuals of distance. The proposed CoRML model is then further improved in training efficiency by a newly introduced approximated ranking weight. Extensive experiments conducted on 4 public datasets demonstrate the superior performance of CoRML compared to the state-of-the-art baselines in collaborative filtering, along with high efficiency and the ability of providing novelty-promoted recommendations, shedding new light on the study of metric learning-based recommender systems.|在协同过滤中，距离度量学习已应用于矩阵分解技术，并取得了良好的效果。然而，矩阵分解缺乏获取协作信息的能力，这一点已被最近的研究所证实，并通过将用户交互解释为信号得到了改善。本文旨在找出度量学习如何连接到这些基于信号的模型。通过采用广义距离度量，我们发现在基于信号的模型中，比起估计距离本身，更容易估计距离的残差，残差是指从用户到目标项目和另一个项目的距离之间的差异。进一步的分析还揭示了交互信号的归一化强度与推荐的新颖性之间的联系，这一点一直被现有的研究所忽视。基于上述发现，我们提出了一种新的模型来学习广义距离用户-项目距离度量，通过建立距离残差模型来捕捉交互信号中的用户偏好。提出的 CoRML 模型通过引入新的近似排序权进一步提高了训练效率。在4个公共数据集上进行的大量实验表明，与最先进的协同过滤基线相比，CoRML 具有更好的性能，同时具有高效率和提供新颖推荐的能力，为基于度量学习的推荐系统的研究提供了新的视角。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Residual+Metric+Learning)|0|
|[Generative-Contrastive Graph Learning for Recommendation](https://doi.org/10.1145/3539618.3591691)|Yonghui Yang, Zhengwei Wu, Le Wu, Kun Zhang, Richang Hong, Zhiqiang Zhang, Jun Zhou, Meng Wang||By treating users' interactions as a user-item graph, graph learning models have been widely deployed in Collaborative Filtering(CF) based recommendation. Recently, researchers have introduced Graph Contrastive Learning(GCL) techniques into CF to alleviate the sparse supervision issue, which first constructs contrastive views by data augmentations and then provides self-supervised signals by maximizing the mutual information between contrastive views. Despite the effectiveness, we argue that current GCL-based recommendation models are still limited as current data augmentation techniques, either structure augmentation or feature augmentation. First, structure augmentation randomly dropout nodes or edges, which is easy to destroy the intrinsic nature of the user-item graph. Second, feature augmentation imposes the same scale noise augmentation on each node, which neglects the unique characteristics of nodes on the graph. To tackle the above limitations, we propose a novel Variational Graph Generative-Contrastive Learning(VGCL) framework for recommendation. Specifically, we leverage variational graph reconstruction to estimate a Gaussian distribution of each node, then generate multiple contrastive views through multiple samplings from the estimated distributions, which builds a bridge between generative and contrastive learning. Besides, the estimated variances are tailored to each node, which regulates the scale of contrastive loss for each node on optimization. Considering the similarity of the estimated distributions, we propose a cluster-aware twofold contrastive learning, a node-level to encourage consistency of a node's contrastive views and a cluster-level to encourage consistency of nodes in a cluster. Finally, extensive experimental results on three public datasets clearly demonstrate the effectiveness of the proposed model.|通过将用户交互作为一个用户项目图，图形学习模型已经广泛应用于基于协同过滤(CF)的推荐中。近年来，研究人员将图形对比学习(Graph Contrative Learning，GCL)技术引入到 CF 中，解决了对比视图稀疏监督问题。尽管有效，我们认为目前基于 GCL 的推荐模型仍然是有限的，作为当前的数据增强技术，无论是结构增强或特征增强。首先，结构扩展随机丢弃节点或边，这很容易破坏用户项图的内在本质。其次，特征增强对每个节点进行相同尺度的噪声增强，忽略了图上节点的独特性。针对上述局限性，本文提出了一种新的变分图生成对比学习(VGCL)框架。具体来说，我们利用变分图重建来估计每个节点的正态分布，然后从估计的分布中通过多个样本生成多个对比视图，这在生成学习和对比学习之间架起了一座桥梁。此外，估计的方差是针对每个节点量身定制的，它调节了每个节点在优化时的对比损失规模。考虑到估计分布的相似性，我们提出了一种基于聚类的双重对比学习方法，一个节点级别用于增强节点对比视图的一致性，一个聚类级别用于增强聚类中节点的一致性。最后，在三个公共数据集上的大量实验结果清楚地表明了该模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative-Contrastive+Graph+Learning+for+Recommendation)|0|
|[Hydrus: Improving Personalized Quality of Experience in Short-form Video Services](https://doi.org/10.1145/3539618.3591696)|Zhiyu Yuan, Kai Ren, Gang Wang, Xin Miao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hydrus:+Improving+Personalized+Quality+of+Experience+in+Short-form+Video+Services)|0|
|[Topic-enhanced Graph Neural Networks for Extraction-based Explainable Recommendation](https://doi.org/10.1145/3539618.3591776)|Jie Shuai, Le Wu, Kun Zhang, Peijie Sun, Richang Hong, Meng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topic-enhanced+Graph+Neural+Networks+for+Extraction-based+Explainable+Recommendation)|0|
|[Strategy-aware Bundle Recommender System](https://doi.org/10.1145/3539618.3591771)|Yinwei Wei, Xiaohao Liu, Yunshan Ma, Xiang Wang, Liqiang Nie, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Strategy-aware+Bundle+Recommender+System)|0|
|[Soft Prompt Decoding for Multilingual Dense Retrieval](https://doi.org/10.1145/3539618.3591769)|Zhiqi Huang, Hansi Zeng, Hamed Zamani, James Allan||In this work, we explore a Multilingual Information Retrieval (MLIR) task, where the collection includes documents in multiple languages. We demonstrate that applying state-of-the-art approaches developed for cross-lingual information retrieval to MLIR tasks leads to sub-optimal performance. This is due to the heterogeneous and imbalanced nature of multilingual collections -- some languages are better represented in the collection and some benefit from large-scale training data. To address this issue, we present KD-SPD, a novel soft prompt decoding approach for MLIR that implicitly "translates" the representation of documents in different languages into the same embedding space. To address the challenges of data scarcity and imbalance, we introduce a knowledge distillation strategy. The teacher model is trained on rich English retrieval data, and by leveraging bi-text data, our distillation framework transfers its retrieval knowledge to the multilingual document encoder. Therefore, our approach does not require any multilingual retrieval training data. Extensive experiments on three MLIR datasets with a total of 15 languages demonstrate that KD-SPD significantly outperforms competitive baselines in all cases. We conduct extensive analyses to show that our method has less language bias and better zero-shot transfer ability towards new languages.|在这项工作中，我们探索了一个多语言信息检索(mLIR)任务，其中收集包括多种语言的文档。我们证明，将为跨语言信息检索开发的最先进的方法应用于 mLIR 任务，会导致性能欠佳。这是由于多语种集合的异质性和不平衡性——有些语言在集合中得到更好的表示，有些则得益于大规模的培训数据。为了解决这个问题，我们提出了一种新的针对 MLIR 的软提示解码方法 KD-SPD，它将不同语言的文档表示隐式地“翻译”到相同的嵌入空间中。为了解决数据稀缺和不平衡的挑战，我们引入了一种知识提取策略。教师模型是在丰富的英语检索数据上进行训练的，并且通过利用双文本数据，我们的精馏框架将其检索知识传递给多语言文档编码器。因此，我们的方法不需要任何多语言检索训练数据。在三个共有15种语言的 MLIR 数据集上的广泛实验表明，KD-SPD 在所有情况下都显著优于竞争性基线。我们进行了广泛的分析表明，我们的方法具有较少的语言偏见和更好的零-镜头转移能力的新语言。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Soft+Prompt+Decoding+for+Multilingual+Dense+Retrieval)|0|
|[Rethinking Benchmarks for Cross-modal Image-text Retrieval](https://doi.org/10.1145/3539618.3591758)|Weijing Chen, Linli Yao, Qin Jin||Image-text retrieval, as a fundamental and important branch of information retrieval, has attracted extensive research attentions. The main challenge of this task is cross-modal semantic understanding and matching. Some recent works focus more on fine-grained cross-modal semantic matching. With the prevalence of large scale multimodal pretraining models, several state-of-the-art models (e.g. X-VLM) have achieved near-perfect performance on widely-used image-text retrieval benchmarks, i.e. MSCOCO-Test-5K and Flickr30K-Test-1K. In this paper, we review the two common benchmarks and observe that they are insufficient to assess the true capability of models on fine-grained cross-modal semantic matching. The reason is that a large amount of images and texts in the benchmarks are coarse-grained. Based on the observation, we renovate the coarse-grained images and texts in the old benchmarks and establish the improved benchmarks called MSCOCO-FG and Flickr30K-FG. Specifically, on the image side, we enlarge the original image pool by adopting more similar images. On the text side, we propose a novel semi-automatic renovation approach to refine coarse-grained sentences into finer-grained ones with little human effort. Furthermore, we evaluate representative image-text retrieval models on our new benchmarks to demonstrate the effectiveness of our method. We also analyze the capability of models on fine-grained semantic comprehension through extensive experiments. The results show that even the state-of-the-art models have much room for improvement in fine-grained semantic understanding, especially in distinguishing attributes of close objects in images. Our code and improved benchmark datasets are publicly available at: https://github.com/cwj1412/MSCOCO-Flikcr30K_FG, which we hope will inspire further in-depth research on cross-modal retrieval.|图像-文本检索作为信息检索学的一个重要分支，已经引起了广泛的研究关注。这项任务的主要挑战是跨模态语义理解和匹配。最近的一些工作更多地关注于细粒度的跨情态语义匹配。随着大规模多模式预训练模型的普及，一些最先进的模型(例如 X-VLM)在广泛使用的图像-文本检索基准(例如 MSCOCO-Test-5K 和 Flickr30K-Test-1K)上取得了近乎完美的性能。在本文中，我们回顾了这两个常用的基准测试，发现它们不足以评估模型在细粒度跨模态语义匹配方面的真正能力。原因是基准测试中的大量图像和文本是粗粒度的。在此基础上，对原有基准测试中的粗粒度图像和文本进行了改进，建立了改进后的基准测试 MSCOCO-FG 和 Flickr30K-FG。具体地说，在图像方面，我们通过采用更多的相似图像来扩大原始图像池。在文本方面，我们提出了一种新的半自动更新方法，以较少的人工精力将粗粒度的句子细化为细粒度的句子。在此基础上，我们对具有代表性的图像-文本检索模型进行了评估，以验证该方法的有效性。通过大量实验，分析了模型对细粒度语义理解的能力。结果表明，即使是最先进的模型，在细粒度的语义理解方面，尤其是在图像中近似对象的属性识别方面，仍有很大的改进空间。我们的代码和改进的基准数据集可以在以下 https://github.com/cwj1412/mscoco-flikcr30k_fg 公开获得，我们希望这将激发对跨模式检索的进一步深入研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Benchmarks+for+Cross-modal+Image-text+Retrieval)|0|
|[From Region to Patch: Attribute-Aware Foreground-Background Contrastive Learning for Fine-Grained Fashion Retrieval](https://doi.org/10.1145/3539618.3591690)|Jianfeng Dong, Xiaoman Peng, Zhe Ma, Daizong Liu, Xiaoye Qu, Xun Yang, Jixiang Zhu, Baolong Liu||Attribute-specific fashion retrieval (ASFR) is a challenging information retrieval task, which has attracted increasing attention in recent years. Different from traditional fashion retrieval which mainly focuses on optimizing holistic similarity, the ASFR task concentrates on attribute-specific similarity, resulting in more fine-grained and interpretable retrieval results. As the attribute-specific similarity typically corresponds to the specific subtle regions of images, we propose a Region-to-Patch Framework (RPF) that consists of a region-aware branch and a patch-aware branch to extract fine-grained attribute-related visual features for precise retrieval in a coarse-to-fine manner. In particular, the region-aware branch is first to be utilized to locate the potential regions related to the semantic of the given attribute. Then, considering that the located region is coarse and still contains the background visual contents, the patch-aware branch is proposed to capture patch-wise attribute-related details from the previous amplified region. Such a hybrid architecture strikes a proper balance between region localization and feature extraction. Besides, different from previous works that solely focus on discriminating the attribute-relevant foreground visual features, we argue that the attribute-irrelevant background features are also crucial for distinguishing the detailed visual contexts in a contrastive manner. Therefore, a novel E-InfoNCE loss based on the foreground and background representations is further proposed to improve the discrimination of attribute-specific representation. Extensive experiments on three datasets demonstrate the effectiveness of our proposed framework, and also show a decent generalization of our RPF on out-of-domain fashion images. Our source code is available at https://github.com/HuiGuanLab/RPF.|特定属性的时尚检索(asFR)是一项具有挑战性的信息检索检索任务，近年来受到越来越多的关注。与以优化整体相似度为核心的传统时尚检索不同，ASFR 任务集中于特定属性的相似度，使得检索结果更加细粒度和可解释性。由于特定属性的相似性通常对应于图像的特定细微区域，因此我们提出了一种由区域感知分支和补丁感知分支组成的区域到补丁框架(Regional-to-Patch Framework，RPF)来提取细粒度的属性相关视觉特征，以便以粗到细的方式进行精确检索。特别地，区域感知分支首先被用来定位与给定属性的语义相关的潜在区域。然后，考虑到所定位的区域比较粗糙，并且仍然包含背景视觉内容，提出了基于补丁感知的分支来从前面的放大区域中获取与补丁相关的属性细节。这种混合结构在区域定位和特征提取之间取得了适当的平衡。此外，与以往单纯侧重于识别与属性相关的前景视觉特征的作品不同，我们认为与属性无关的背景特征对于以对比的方式识别详细的视觉背景也是至关重要的。因此，本文进一步提出了一种基于前景和背景表征的新型 E-InfoNCE 损失算法，以改善特定属性表征的识别能力。在三个数据集上的大量实验证明了我们提出的框架的有效性，同时也显示了我们的 RPF 在域外时尚图像上的良好推广。我们的源代码可以在 https://github.com/huiguanlab/rpf 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Region+to+Patch:+Attribute-Aware+Foreground-Background+Contrastive+Learning+for+Fine-Grained+Fashion+Retrieval)|0|
|[Multi-view Multi-aspect Neural Networks for Next-basket Recommendation](https://doi.org/10.1145/3539618.3591738)|Zhiying Deng, Jianjun Li, Zhiqiang Guo, Wei Liu, Li Zou, Guohui Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-view+Multi-aspect+Neural+Networks+for+Next-basket+Recommendation)|0|
|[EulerNet: Adaptive Feature Interaction Learning via Euler's Formula for CTR Prediction](https://doi.org/10.1145/3539618.3591681)|Zhen Tian, Ting Bai, Wayne Xin Zhao, JiRong Wen, Zhao Cao||Learning effective high-order feature interactions is very crucial in the CTR prediction task. However, it is very time-consuming to calculate high-order feature interactions with massive features in online e-commerce platforms. Most existing methods manually design a maximal order and further filter out the useless interactions from them. Although they reduce the high computational costs caused by the exponential growth of high-order feature combinations, they still suffer from the degradation of model capability due to the suboptimal learning of the restricted feature orders. The solution to maintain the model capability and meanwhile keep it efficient is a technical challenge, which has not been adequately addressed. To address this issue, we propose an adaptive feature interaction learning model, named as EulerNet, in which the feature interactions are learned in a complex vector space by conducting space mapping according to Euler's formula. EulerNet converts the exponential powers of feature interactions into simple linear combinations of the modulus and phase of the complex features, making it possible to adaptively learn the high-order feature interactions in an efficient way. Furthermore, EulerNet incorporates the implicit and explicit feature interactions into a unified architecture, which achieves the mutual enhancement and largely boosts the model capabilities. Such a network can be fully learned from data, with no need of pre-designed form or order for feature interactions. Extensive experiments conducted on three public datasets have demonstrated the effectiveness and efficiency of our approach. Our code is available at: https://github.com/RUCAIBox/EulerNet.|在 CTR 预测任务中，学习有效的高阶特征交互是非常关键的。然而，在线电子商务平台中计算具有大量特征的高阶特征交互是非常耗时的。大多数现有的方法手工设计一个最大顺序，并进一步从中筛选出无用的交互。虽然它们降低了高阶特征组合的指数增长所造成的高计算成本，但是由于受限特征阶次的次优学习，它们仍然受到模型能力退化的影响。保持模型能力并同时保持其有效性的解决方案是一个技术挑战，尚未得到充分解决。针对这一问题，提出了一种自适应特征交互学习模型 EulerNet。EulerNet 将特征交互的指数幂转化为复杂特征模量和相位的简单线性组合，使得高阶特征交互的自适应学习成为可能。此外，EulerNet 将隐式和显式的特征交互融合到一个统一的体系结构中，实现了相互增强，大大提高了模型的性能。这样的网络可以完全从数据中学习，不需要预先设计的形式或特征交互的顺序。在三个公共数据集上进行的大量实验已经证明了我们方法的有效性和效率。我们的代码可以在以下 https://github.com/rucaibox/eulernet 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EulerNet:+Adaptive+Feature+Interaction+Learning+via+Euler's+Formula+for+CTR+Prediction)|0|
|[FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation](https://doi.org/10.1145/3539618.3591687)|Sebastian Hofstätter, Jiecao Chen, Karthik Raman, Hamed Zamani|Technische Universität Wien; University of Massachusetts, Amherst; Google|Retrieval-augmented generation models offer many benefits over standalone language models: besides a textual answer to a given query they provide provenance items retrieved from an updateable knowledge base. However, they are also more complex systems and need to handle long inputs. In this work, we introduce FiD-Light to strongly increase the efficiency of the state-of-the-art retrieval-augmented FiD model, while maintaining the same level of effectiveness. Our FiD-Light model constrains the information flow from the encoder (which encodes passages separately) to the decoder (using concatenated encoded representations). Furthermore, we adapt FiD-Light with re-ranking capabilities through textual source pointers, to improve the top-ranked provenance precision. Our experiments on a diverse set of seven knowledge intensive tasks (KILT) show FiD-Light consistently improves the Pareto frontier between query latency and effectiveness. FiD-Light with source pointing sets substantial new state-of-the-art results on six KILT tasks for combined text generation and provenance retrieval evaluation, while maintaining reasonable efficiency.|与独立语言模型相比，检索增强生成模型提供了许多好处: 除了对给定查询的文本回答之外，它们还提供了从可更新的知识库中检索到的出处项。然而，它们也是更复杂的系统，需要处理长输入。在这项工作中，我们引入了 FiD-Light，在保持相同的效率水平的同时，强有力地提高了最先进的检索增强 FiD 模型的效率。我们的 FiD-Light 模型约束了从编码器(分别编码通道)到解码器(使用级联编码表示)的信息流。此外，我们通过文本源指针改编具有重新排序能力的 FiD-Light，以提高顶级来源精度。我们在七个不同的知识密集型任务(KILT)上的实验表明，FiD-Light 一致地改善了查询延迟和有效性之间的帕累托边界。带源点的 FiD-Light 在六个 KILT 任务上设置了大量的最新结果，用于组合文本生成和出处检索评估，同时保持合理的效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FiD-Light:+Efficient+and+Effective+Retrieval-Augmented+Text+Generation)|0|
|[PLATE: A Prompt-Enhanced Paradigm for Multi-Scenario Recommendations](https://doi.org/10.1145/3539618.3591750)|Yuhao Wang, Xiangyu Zhao, Bo Chen, Qidong Liu, Huifeng Guo, Huanshuo Liu, Yichao Wang, Rui Zhang, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PLATE:+A+Prompt-Enhanced+Paradigm+for+Multi-Scenario+Recommendations)|0|
|[LightGT: A Light Graph Transformer for Multimedia Recommendation](https://doi.org/10.1145/3539618.3591716)|Yinwei Wei, Wenqi Liu, Fan Liu, Xiang Wang, Liqiang Nie, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LightGT:+A+Light+Graph+Transformer+for+Multimedia+Recommendation)|0|
|[Law Article-Enhanced Legal Case Matching: A Causal Learning Approach](https://doi.org/10.1145/3539618.3591709)|Zhongxiang Sun, Jun Xu, Xiao Zhang, Zhenhua Dong, JiRong Wen||Legal case matching, which automatically constructs a model to estimate the similarities between the source and target cases, has played an essential role in intelligent legal systems. Semantic text matching models have been applied to the task where the source and target legal cases are considered as long-form text documents. These general-purpose matching models make the predictions solely based on the texts in the legal cases, overlooking the essential role of the law articles in legal case matching. In the real world, the matching results (e.g., relevance labels) are dramatically affected by the law articles because the contents and the judgments of a legal case are radically formed on the basis of law. From the causal sense, a matching decision is affected by the mediation effect from the cited law articles by the legal cases, and the direct effect of the key circumstances (e.g., detailed fact descriptions) in the legal cases. In light of the observation, this paper proposes a model-agnostic causal learning framework called Law-Match, under which the legal case matching models are learned by respecting the corresponding law articles. Given a pair of legal cases and the related law articles, Law-Match considers the embeddings of the law articles as instrumental variables (IVs), and the embeddings of legal cases as treatments. Using IV regression, the treatments can be decomposed into law-related and law-unrelated parts, respectively reflecting the mediation and direct effects. These two parts are then combined with different weights to collectively support the final matching prediction. We show that the framework is model-agnostic, and a number of legal case matching models can be applied as the underlying models. Comprehensive experiments show that Law-Match can outperform state-of-the-art baselines on three public datasets.|法律案件匹配是一种自动构建判断源案件与目标案件相似性的模型，在智能法律系统中发挥着重要作用。本文将语义文本匹配模型应用于源、目标法律案件作为长文本文档的任务中。这些通用匹配模型仅根据法律案件的案文进行预测，忽视了法律条款在法律案件匹配中的重要作用。在现实世界中，由于案件的内容和判决是在法律的基础上从根本上形成的，所以匹配结果(如关联标签)受到法律条文的巨大影响。从因果关系的角度来看，法律案件引用的法律条文所产生的调解效果，以及法律案件中关键情节(如详细的事实描述)的直接效果，都会影响匹配决策。基于这种观察，本文提出了一个模型无关的因果学习框架——法律匹配，在此框架下，通过尊重相应的法律条款来学习法律案例匹配模型。在给定一对法律案例和相关法律条文的情况下，Law-Match 将法律条文的嵌入视为工具变量，将法律案例的嵌入视为处理方法。利用四元回归，可以将处理分解为与法律相关的部分和与法律无关的部分，分别反映调解效果和直接效果。然后将这两部分与不同的权重相结合，共同支持最终的匹配预测。我们表明，该框架是模型无关的，一些法律案件匹配模型可以作为基础模型应用。综合实验表明，Law-Match 在三个公共数据集上的表现优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Law+Article-Enhanced+Legal+Case+Matching:+A+Causal+Learning+Approach)|0|
|[Multimodal Counterfactual Learning Network for Multimedia-based Recommendation](https://doi.org/10.1145/3539618.3591739)|Shuaiyang Li, Dan Guo, Kang Liu, Richang Hong, Feng Xue||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Counterfactual+Learning+Network+for+Multimedia-based+Recommendation)|0|
|[Dynamic Graph Evolution Learning for Recommendation](https://doi.org/10.1145/3539618.3591674)|Haoran Tang, Shiqing Wu, Guandong Xu, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Graph+Evolution+Learning+for+Recommendation)|0|
|[Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning](https://doi.org/10.1145/3539618.3591648)|Siyu Wang, Xiaocong Chen, Dietmar Jannach, Lina Yao||Reinforcement learning-based recommender systems have recently gained popularity. However, the design of the reward function, on which the agent relies to optimize its recommendation policy, is often not straightforward. Exploring the causality underlying users' behavior can take the place of the reward function in guiding the agent to capture the dynamic interests of users. Moreover, due to the typical limitations of simulation environments (e.g., data inefficiency), most of the work cannot be broadly applied in large-scale situations. Although some works attempt to convert the offline dataset into a simulator, data inefficiency makes the learning process even slower. Because of the nature of reinforcement learning (i.e., learning by interaction), it cannot collect enough data to train during a single interaction. Furthermore, traditional reinforcement learning algorithms do not have a solid capability like supervised learning methods to learn from offline datasets directly. In this paper, we propose a new model named the causal decision transformer for recommender systems (CDT4Rec). CDT4Rec is an offline reinforcement learning system that can learn from a dataset rather than from online interaction. Moreover, CDT4Rec employs the transformer architecture, which is capable of processing large offline datasets and capturing both short-term and long-term dependencies within the data to estimate the causal relationship between action, state, and reward. To demonstrate the feasibility and superiority of our model, we have conducted experiments on six real-world offline datasets and one online simulator.|基于强化学习的推荐系统最近越来越受欢迎。然而，代理人依赖于奖励函数来优化其推荐策略，这种奖励函数的设计往往并不简单。探索用户行为背后的因果关系可以代替奖励功能，引导代理捕获用户的动态兴趣。此外，由于模拟环境的典型局限性(例如，数据效率低下) ，大多数工作不能广泛应用于大规模情况。尽管有些工作试图将离线数据集转换为模拟器，但数据效率低下使得学习过程更加缓慢。由于强化学习的本质(即通过交互来学习) ，它无法收集足够的数据来训练一次交互。此外，传统的强化学习算法没有像监督式学习算法那样可以直接从离线数据集中学习的强大能力。本文提出了一种新的推荐系统因果决策转换模型(CDT4Rec)。CDT4Rec 是一个离线强化学习系统，可以从数据集而不是在线交互中学习。此外，CDT4Rec 使用转换器结构，其能够处理大型离线数据集并捕获数据中的短期和长期依赖性，以估计行动，状态和报酬之间的因果关系。为了验证该模型的可行性和优越性，我们在六个真实世界的离线数据集和一个在线模拟器上进行了实验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Decision+Transformer+for+Recommender+Systems+via+Offline+Reinforcement+Learning)|0|
|[It's Enough: Relaxing Diagonal Constraints in Linear Autoencoders for Recommendation](https://doi.org/10.1145/3539618.3591704)|Jaewan Moon, Hyeyoung Kim, Jongwuk Lee||Linear autoencoder models learn an item-to-item weight matrix via convex optimization with L2 regularization and zero-diagonal constraints. Despite their simplicity, they have shown remarkable performance compared to sophisticated non-linear models. This paper aims to theoretically understand the properties of two terms in linear autoencoders. Through the lens of singular value decomposition (SVD) and principal component analysis (PCA), it is revealed that L2 regularization enhances the impact of high-ranked PCs. Meanwhile, zero-diagonal constraints reduce the impact of low-ranked PCs, leading to performance degradation for unpopular items. Inspired by this analysis, we propose simple-yet-effective linear autoencoder models using diagonal inequality constraints, called Relaxed Linear AutoEncoder (RLAE) and Relaxed Denoising Linear AutoEncoder (RDLAE). We prove that they generalize linear autoencoders by adjusting the degree of diagonal constraints. Experimental results demonstrate that our models are comparable or superior to state-of-the-art linear and non-linear models on six benchmark datasets; they significantly improve the accuracy of long-tail items. These results also support our theoretical insights on regularization and diagonal constraints in linear autoencoders.|线性自动编码器模型通过 L2正则化和零对角约束的凸优化学习一个项目对项目的权重矩阵。尽管它们很简单，但与复杂的非线性模型相比，它们表现出了显著的性能。本文旨在从理论上理解线性自动编码器中两项的性质。通过奇异值分解(SVD)和主成分分析(PCA)透镜，我们发现二语正规化增强了高等级个人电脑的影响。与此同时，零对角线约束减少了低排名个人电脑的影响，导致不受欢迎项目的性能下降。受此分析的启发，我们提出了使用对角不等式约束的简单而有效的线性自动编码器模型，称为松弛线性自动编码器(RLAE)和松弛去噪线性自动编码器(RDLAE)。我们证明了它们通过调整对角线约束的程度来推广线性自动编码器。实验结果表明，在六个基准数据集上，我们的模型与最先进的线性和非线性模型具有可比性或优越性，它们显著提高了长尾项目的准确性。这些结果也支持我们对正则化和对角线约束的线性自动编码器的理论见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=It's+Enough:+Relaxing+Diagonal+Constraints+in+Linear+Autoencoders+for+Recommendation)|0|
|[Graph Transformer for Recommendation](https://doi.org/10.1145/3539618.3591723)|Chaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, Chao Huang||This paper presents a novel approach to representation learning in recommender systems by integrating generative self-supervised learning with graph transformer architecture. We highlight the importance of high-quality data augmentation with relevant self-supervised pretext tasks for improving performance. Towards this end, we propose a new approach that automates the self-supervision augmentation process through a rationale-aware generative SSL that distills informative user-item interaction patterns. The proposed recommender with Graph TransFormer (GFormer) that offers parameterized collaborative rationale discovery for selective augmentation while preserving global-aware user-item relationships. In GFormer, we allow the rationale-aware SSL to inspire graph collaborative filtering with task-adaptive invariant rationalization in graph transformer. The experimental results reveal that our GFormer has the capability to consistently improve the performance over baselines on different datasets. Several in-depth experiments further investigate the invariant rationale-aware augmentation from various aspects. The source code for this work is publicly available at: https://github.com/HKUDS/GFormer.|提出了一种将生成式自监督学习与图形变换结构相结合的推荐系统表示学习方法。我们强调高质量的数据增强与相关的自我监督的借口任务的重要性，以提高性能。为此，我们提出了一种新的方法，该方法通过一个基于理论的生成 SSL 来自动化自我监督增强过程，该 SSL 提取信息丰富的用户项交互模式。提出的推荐与图形转换器(GForm) ，提供参数化的协作理论发现的选择性增强，同时保持全局感知的用户项目关系。在 gform 中，我们允许基于逻辑的 SSL 激发图形协同过滤，在图形转换器中使用任务自适应的不变合理化。实验结果表明，该算法能够持续改善不同数据集的基线性能。几个深入的实验从各个方面进一步研究了不变的理论意识增强。这项工作的源代码可以在以下 https://github.com/hkuds/gformer 公开获得:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Transformer+for+Recommendation)|0|
|[Topic-oriented Adversarial Attacks against Black-box Neural Ranking Models](https://doi.org/10.1145/3539618.3591777)|YuAn Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Wei Chen, Yixing Fan, Xueqi Cheng||Neural ranking models (NRMs) have attracted considerable attention in information retrieval. Unfortunately, NRMs may inherit the adversarial vulnerabilities of general neural networks, which might be leveraged by black-hat search engine optimization practitioners. Recently, adversarial attacks against NRMs have been explored in the paired attack setting, generating an adversarial perturbation to a target document for a specific query. In this paper, we focus on a more general type of perturbation and introduce the topic-oriented adversarial ranking attack task against NRMs, which aims to find an imperceptible perturbation that can promote a target document in ranking for a group of queries with the same topic. We define both static and dynamic settings for the task and focus on decision-based black-box attacks. We propose a novel framework to improve topic-oriented attack performance based on a surrogate ranking model. The attack problem is formalized as a Markov decision process (MDP) and addressed using reinforcement learning. Specifically, a topic-oriented reward function guides the policy to find a successful adversarial example that can be promoted in rankings to as many queries as possible in a group. Experimental results demonstrate that the proposed framework can significantly outperform existing attack strategies, and we conclude by re-iterating that there exist potential risks for applying NRMs in the real world.|神经排序模型(nRM)在信息检索领域引起了广泛的关注。不幸的是，非线性回归模型可能继承了一般神经网络的对抗性弱点，这些弱点可能被黑帽搜索引擎优化从业者所利用。最近，针对 NRM 的对抗性攻击已经在配对攻击设置中得到了探索，为特定查询对目标文档产生了对抗性扰动。在本文中，我们着重研究了一种更一般的扰动类型，并介绍了面向主题的对抗性自然模型排序攻击任务，其目的是找到一种不可察觉的扰动，可以促进目标文档在同一主题的一组查询中的排序。我们为任务定义了静态和动态设置，重点关注基于决策的黑盒攻击。提出了一种基于代理排序模型的面向主题攻击性能改进框架。攻击问题被形式化为一个马可夫决策过程(mDP) ，并使用强化学习来解决。具体来说，面向主题的奖励函数引导策略找到一个成功的对抗性例子，这个例子可以在一组中尽可能多的查询中进行排名推广。实验结果表明，该框架的性能明显优于现有的攻击策略，并通过重申在现实世界中应用 NRM 存在潜在的风险得出结论。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topic-oriented+Adversarial+Attacks+against+Black-box+Neural+Ranking+Models)|0|
|[RCENR: A Reinforced and Contrastive Heterogeneous Network Reasoning Model for Explainable News Recommendation](https://doi.org/10.1145/3539618.3591753)|Hao Jiang, Chuanzhen Li, Juanjuan Cai, Jingling Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RCENR:+A+Reinforced+and+Contrastive+Heterogeneous+Network+Reasoning+Model+for+Explainable+News+Recommendation)|0|
|[Seq-HGNN: Learning Sequential Node Representation on Heterogeneous Graph](https://doi.org/10.1145/3539618.3591765)|Chenguang Du, Kaichun Yao, Hengshu Zhu, Deqing Wang, Fuzhen Zhuang, Hui Xiong||Recent years have witnessed the rapid development of heterogeneous graph neural networks (HGNNs) in information retrieval (IR) applications. Many existing HGNNs design a variety of tailor-made graph convolutions to capture structural and semantic information in heterogeneous graphs. However, existing HGNNs usually represent each node as a single vector in the multi-layer graph convolution calculation, which makes the high-level graph convolution layer fail to distinguish information from different relations and different orders, resulting in the information loss in the message passing. %insufficient mining of information. To this end, we propose a novel heterogeneous graph neural network with sequential node representation, namely Seq-HGNN. To avoid the information loss caused by the single vector node representation, we first design a sequential node representation learning mechanism to represent each node as a sequence of meta-path representations during the node message passing. Then we propose a heterogeneous representation fusion module, empowering Seq-HGNN to identify important meta-paths and aggregate their representations into a compact one. We conduct extensive experiments on four widely used datasets from Heterogeneous Graph Benchmark (HGB) and Open Graph Benchmark (OGB). Experimental results show that our proposed method outperforms state-of-the-art baselines in both accuracy and efficiency. The source code is available at https://github.com/nobrowning/SEQ_HGNN.|近年来，异质图形神经网络(HGNN)在信息检索应用方面发展迅速。许多现有的 HGNN 设计了各种定制的图形卷积来捕获异构图形中的结构和语义信息。然而，现有的 HGNN 在多层图卷积计算中通常将每个节点表示为一个向量，使得高层图卷积层无法区分不同关系和不同顺序的信息，导致信息传递中的信息丢失。信息挖掘不足百分比。为此，我们提出了一种新的具有序列节点表示的异构图神经网络，即 Seq-HGNN。为了避免单向量节点表示造成的信息丢失，我们首先设计了一种序列节点表示学习机制，在节点消息传递过程中将每个节点表示为一系列元路径表示。然后提出了一个异构表示融合模块，赋予 Seq-HGNN 识别重要元路径的能力，并将它们的表示聚合成一个紧凑的元路径。我们对异构图基准(HGB)和开放图基准(OGB)的四个广泛使用的数据集进行了广泛的实验。实验结果表明，我们提出的方法在准确性和效率方面都优于现有的基线方法。源代码可在 https://github.com/nobrowning/seq_hgnn 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Seq-HGNN:+Learning+Sequential+Node+Representation+on+Heterogeneous+Graph)|0|
|[A Lightweight Constrained Generation Alternative for Query-focused Summarization](https://doi.org/10.1145/3539618.3591936)|Zhichao Xu, Daniel Cohen||Query-focused summarization (QFS) aims to provide a summary of a document that satisfies information need of a given query and is useful in various IR applications, such as abstractive snippet generation. Current QFS approaches typically involve injecting additional information, e.g. query-answer relevance or fine-grained token-level interaction between a query and document, into a finetuned large language model. However, these approaches often require extra parameters \& training, and generalize poorly to new dataset distributions. To mitigate this, we propose leveraging a recently developed constrained generation model Neurological Decoding (NLD) as an alternative to current QFS regimes which rely on additional sub-architectures and training. We first construct lexical constraints by identifying important tokens from the document using a lightweight gradient attribution model, then subsequently force the generated summary to satisfy these constraints by directly manipulating the final vocabulary likelihood. This lightweight approach requires no additional parameters or finetuning as it utilizes both an off-the-shelf neural retrieval model to construct the constraints and a standard generative language model to produce the QFS. We demonstrate the efficacy of this approach on two public QFS collections achieving near parity with the state-of-the-art model with substantially reduced complexity.|以查询为中心的摘要(Query-focus Summary，QFS)旨在提供满足给定查询的信息需求的文档摘要，并且在各种 IR 应用程序(如抽象代码片段生成)中非常有用。当前的 QFS 方法通常涉及到向一个微调的大型语言模型中注入额外的信息，例如查询-回答相关性或查询与文档之间的细粒度令牌级交互。然而，这些方法通常需要额外的参数和训练，并且很难推广到新的数据集分布。为了缓解这种情况，我们建议利用最近开发的约束生成模型神经解码(NLD)作为替代目前依赖于额外的子架构和培训的 QFS 制度。我们首先利用一个轻量级的梯度属性模型从文档中识别出重要的标记来构造词汇约束，然后通过直接操作最终的词汇可能性来强制生成的摘要满足这些约束。这种轻量级方法不需要额外的参数或微调，因为它既利用现成的神经检索模型来构造约束，又利用标准的生成语言模型来生成 QFS。我们证明了这种方法的功效，两个公共 QFS 收集实现接近平等的国家的最先进的模型，大大降低了复杂性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Lightweight+Constrained+Generation+Alternative+for+Query-focused+Summarization)|0|
|[A Static Pruning Study on Sparse Neural Retrievers](https://doi.org/10.1145/3539618.3591941)|Carlos Lassance, Simon Lupart, Hervé Déjean, Stéphane Clinchant, Nicola Tonellotto||Sparse neural retrievers, such as DeepImpact, uniCOIL and SPLADE, have been introduced recently as an efficient and effective way to perform retrieval with inverted indexes. They aim to learn term importance and, in some cases, document expansions, to provide a more effective document ranking compared to traditional bag-of-words retrieval models such as BM25. However, these sparse neural retrievers have been shown to increase the computational costs and latency of query processing compared to their classical counterparts. To mitigate this, we apply a well-known family of techniques for boosting the efficiency of query processing over inverted indexes: static pruning. We experiment with three static pruning strategies, namely document-centric, term-centric and agnostic pruning, and we assess, over diverse datasets, that these techniques still work with sparse neural retrievers. In particular, static pruning achieves $2\times$ speedup with negligible effectiveness loss ($\leq 2\%$ drop) and, depending on the use case, even $4\times$ speedup with minimal impact on the effectiveness ($\leq 8\%$ drop). Moreover, we show that neural rerankers are robust to candidates from statically pruned indexes.|稀疏神经检索器，如 DeepImpact、 uniCOIL 和 SPLADE，作为一种有效的反向索引检索方法，近年来得到了广泛的应用。他们的目标是学习词汇的重要性，并在某些情况下，文档扩展，以提供更有效的文档排序相比，传统的单词袋检索模型，如 BM25。然而，这些稀疏的神经检索已被证明增加了计算成本和查询处理的延迟相比，他们的经典对应物。为了缓解这种情况，我们应用了一系列众所周知的技术来提高反向索引上的查询处理效率: 静态剪枝。我们试验了三种静态修剪策略，即以文档为中心的、以术语为中心的和不可知的修剪，并且我们在不同的数据集上评估，这些技术仍然适用于稀疏的神经检索器。特别是，静态修剪可以达到 $2倍的加速效果，而且效果损失可以忽略不计($leq 2% $drop) ，根据用例的不同，甚至可以达到 $4倍的加速效果，而且对效果的影响最小($leq 8% $drop)。此外，我们证明了神经重新排序器对静态剪枝索引的候选者是鲁棒的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Static+Pruning+Study+on+Sparse+Neural+Retrievers)|0|
|[Adapting Learned Sparse Retrieval for Long Documents](https://doi.org/10.1145/3539618.3591943)|Thong Nguyen, Sean MacAvaney, Andrew Yates||Learned sparse retrieval (LSR) is a family of neural retrieval methods that transform queries and documents into sparse weight vectors aligned with a vocabulary. While LSR approaches like Splade work well for short passages, it is unclear how well they handle longer documents. We investigate existing aggregation approaches for adapting LSR to longer documents and find that proximal scoring is crucial for LSR to handle long documents. To leverage this property, we proposed two adaptations of the Sequential Dependence Model (SDM) to LSR: ExactSDM and SoftSDM. ExactSDM assumes only exact query term dependence, while SoftSDM uses potential functions that model the dependence of query terms and their expansion terms (i.e., terms identified using a transformer's masked language modeling head).   Experiments on the MSMARCO Document and TREC Robust04 datasets demonstrate that both ExactSDM and SoftSDM outperform existing LSR aggregation approaches for different document length constraints. Surprisingly, SoftSDM does not provide any performance benefits over ExactSDM. This suggests that soft proximity matching is not necessary for modeling term dependence in LSR. Overall, this study provides insights into handling long documents with LSR, proposing adaptations that improve its performance.|学习稀疏检索(LSR)是一类将查询和文档转换为与词汇表对齐的稀疏权重向量的神经检索方法。虽然像 Splade 这样的 LSR 方法在处理短文时效果很好，但是它们在处理较长文档时效果如何还不清楚。我们研究了现有的将 LSR 适应于较长文档的聚合方法，发现近似评分对于 LSR 处理较长文档至关重要。为了利用这个特性，我们提出了序列依赖模型(SDM)对 LSR 的两种适应: ExactSDM 和 SoftSDM。ExactSDM 只假设精确的查询术语依赖性，而 SoftSDM 使用潜在函数对查询术语及其扩展术语的依赖性进行建模(即，使用转换器的掩蔽语言建模头标识的术语)。在 MSMARCO Document 和 TREC Robust04数据集上的实验表明，ExactSDM 和 SoftSDM 在不同文档长度约束下的性能都优于现有的 LSR 聚合方法。令人惊讶的是，与 ExactSDM 相比，SoftSDM 并没有提供任何性能优势。这表明软接近匹配对于 LSR 中的项依赖建模是不必要的。总的来说，这项研究为使用 LSR 处理长文档提供了见解，并提出了改进其性能的建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adapting+Learned+Sparse+Retrieval+for+Long+Documents)|0|
|[Affective Relevance: Inferring Emotional Responses via fNIRS Neuroimaging](https://doi.org/10.1145/3539618.3591946)|Tuukka Ruotsalo, Kalle Mäkelä, Michiel M. A. Spapé, Luis A. Leiva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Affective+Relevance:+Inferring+Emotional+Responses+via+fNIRS+Neuroimaging)|0|
|[Attacking Pre-trained Recommendation](https://doi.org/10.1145/3539618.3591949)|Yiqing Wu, Ruobing Xie, Zhao Zhang, Yongchun Zhu, Fuzhen Zhuang, Jie Zhou, Yongjun Xu, Qing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attacking+Pre-trained+Recommendation)|0|
|[Always Strengthen Your Strengths: A Drift-Aware Incremental Learning Framework for CTR Prediction](https://doi.org/10.1145/3539618.3591948)|Congcong Liu, Fei Teng, Xiwei Zhao, Zhangang Lin, Jinghe Hu, Jingping Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Always+Strengthen+Your+Strengths:+A+Drift-Aware+Incremental+Learning+Framework+for+CTR+Prediction)|0|
|[Attention-guided Multi-step Fusion: A Hierarchical Fusion Network for Multimodal Recommendation](https://doi.org/10.1145/3539618.3591950)|Yan Zhou, Jie Guo, Hao Sun, Bin Song, Fei Richard Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attention-guided+Multi-step+Fusion:+A+Hierarchical+Fusion+Network+for+Multimodal+Recommendation)|0|
|[Benchmarking Middle-Trained Language Models for Neural Search](https://doi.org/10.1145/3539618.3591956)|Hervé Déjean, Stéphane Clinchant, Carlos Lassance, Simon Lupart, Thibault Formal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Benchmarking+Middle-Trained+Language+Models+for+Neural+Search)|0|
|[Computational Versus Perceived Popularity Miscalibration in Recommender Systems](https://doi.org/10.1145/3539618.3591964)|Oleg Lesota, Gustavo Escobedo, Yashar Deldjoo, Bruce Ferwerda, Simone Kopeinik, Elisabeth Lex, Navid Rekabsaz, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Computational+Versus+Perceived+Popularity+Miscalibration+in+Recommender+Systems)|0|
|[Context-Aware Modeling via Simulated Exposure Page for CTR Prediction](https://doi.org/10.1145/3539618.3591967)|Xiang Li, Shuwei Chen, Jian Dong, Jin Zhang, Yongkang Wang, Xingxing Wang, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-Aware+Modeling+via+Simulated+Exposure+Page+for+CTR+Prediction)|0|
|[Contrastive Learning for Conversion Rate Prediction](https://doi.org/10.1145/3539618.3591968)|Wentao Ouyang, Rui Dong, Xiuwu Zhang, Chaofeng Guo, Jinmei Luo, Xiangzheng Liu, Yanlong Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+for+Conversion+Rate+Prediction)|0|
|[Curriculum Modeling the Dependence among Targets with Multi-task Learning for Financial Marketing](https://doi.org/10.1145/3539618.3591969)|Yunpeng Weng, Xing Tang, Liang Chen, Xiuqiang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curriculum+Modeling+the+Dependence+among+Targets+with+Multi-task+Learning+for+Financial+Marketing)|0|
|[Denoise to Protect: A Method to Robustify Visual Recommenders from Adversaries](https://doi.org/10.1145/3539618.3591971)|Felice Antonio Merra, Vito Walter Anelli, Tommaso Di Noia, Daniele Malitesta, Alberto Carlo Maria Mancino||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Denoise+to+Protect:+A+Method+to+Robustify+Visual+Recommenders+from+Adversaries)|0|
|[Edge-cloud Collaborative Learning with Federated and Centralized Features](https://doi.org/10.1145/3539618.3591976)|Zexi Li, Qunwei Li, Yi Zhou, Wenliang Zhong, Guannan Zhang, Chao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Edge-cloud+Collaborative+Learning+with+Federated+and+Centralized+Features)|0|
|[Evaluating Cross-modal Generative Models Using Retrieval Task](https://doi.org/10.1145/3539618.3591979)|Shivangi Bithel, Srikanta Bedathur||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+Cross-modal+Generative+Models+Using+Retrieval+Task)|0|
|[SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes](https://doi.org/10.1145/3539618.3591977)|Minghan Li, ShengChieh Lin, Xueguang Ma, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SLIM:+Sparsified+Late+Interaction+for+Multi-Vector+Retrieval+with+Inverted+Indexes)|0|
|[Forget Me Now: Fast and Exact Unlearning in Neighborhood-based Recommendation](https://doi.org/10.1145/3539618.3591989)|Sebastian Schelter, Mozhdeh Ariannezhad, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forget+Me+Now:+Fast+and+Exact+Unlearning+in+Neighborhood-based+Recommendation)|0|
|[Gradient Coordination for Quantifying and Maximizing Knowledge Transference in Multi-Task Learning](https://doi.org/10.1145/3539618.3591993)|Xuanhua Yang, Jianxin Zhao, Shaoguo Liu, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gradient+Coordination+for+Quantifying+and+Maximizing+Knowledge+Transference+in+Multi-Task+Learning)|0|
|[Model-free Reinforcement Learning with Stochastic Reward Stabilization for Recommender Systems](https://doi.org/10.1145/3539618.3592022)|Tianchi Cai, Shenliao Bao, Jiyan Jiang, Shiji Zhou, Wenpeng Zhang, Lihong Gu, Jinjie Gu, Guannan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Model-free+Reinforcement+Learning+with+Stochastic+Reward+Stabilization+for+Recommender+Systems)|0|
|[Multi-Grained Topological Pre-Training of Language Models in Sponsored Search](https://doi.org/10.1145/3539618.3592024)|Zhoujin Tian, Chaozhuo Li, Zhiqiang Zuo, Zengxuan Wen, Xinyue Hu, Xiao Han, Haizhen Huang, Senzhang Wang, Weiwei Deng, Xing Xie, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Grained+Topological+Pre-Training+of+Language+Models+in+Sponsored+Search)|0|
|[Multi-grained Representation Learning for Cross-modal Retrieval](https://doi.org/10.1145/3539618.3592025)|Shengwei Zhao, Linhai Xu, Yuying Liu, Shaoyi Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-grained+Representation+Learning+for+Cross-modal+Retrieval)|0|
|[On the Effects of Regional Spelling Conventions in Retrieval Models](https://doi.org/10.1145/3539618.3592030)|Andreas Chari, Sean MacAvaney, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Effects+of+Regional+Spelling+Conventions+in+Retrieval+Models)|0|
|[Patterns of Gender-Specializing Query Reformulation](https://doi.org/10.1145/3539618.3592034)|Amifa Raj, Bhaskar Mitra, Nick Craswell, Michael D. Ekstrand||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Patterns+of+Gender-Specializing+Query+Reformulation)|0|
|[PiTL: Cross-modal Retrieval with Weakly-supervised Vision-language Pre-training via Prompting](https://doi.org/10.1145/3539618.3592038)|Zixin Guo, TzuJui Julius Wang, Selen Pehlivan, Abduljalil Radman, Jorma Laaksonen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PiTL:+Cross-modal+Retrieval+with+Weakly-supervised+Vision-language+Pre-training+via+Prompting)|0|
|[Query-specific Variable Depth Pooling via Query Performance Prediction](https://doi.org/10.1145/3539618.3592046)|Debasis Ganguly, Emine Yilmaz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query-specific+Variable+Depth+Pooling+via+Query+Performance+Prediction)|0|
|[RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses](https://doi.org/10.1145/3539618.3592047)|Honglei Zhuang, Zhen Qin, Rolf Jagerman, Kai Hui, Ji Ma, Jing Lu, Jianmo Ni, Xuanhui Wang, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RankT5:+Fine-Tuning+T5+for+Text+Ranking+with+Ranking+Losses)|0|
|[Representation Sparsification with Hybrid Thresholding for Fast SPLADE-based Document Retrieval](https://doi.org/10.1145/3539618.3592051)|Yifan Qiao, Yingrui Yang, Shanxiu He, Tao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+Sparsification+with+Hybrid+Thresholding+for+Fast+SPLADE-based+Document+Retrieval)|0|
|[Robust Causal Inference for Recommender System to Overcome Noisy Confounders](https://doi.org/10.1145/3539618.3592055)|Zhiheng Zhang, Quanyu Dai, Xu Chen, Zhenhua Dong, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Causal+Inference+for+Recommender+System+to+Overcome+Noisy+Confounders)|0|
|[Sharpness-Aware Graph Collaborative Filtering](https://doi.org/10.1145/3539618.3592059)|Huiyuan Chen, ChinChia Michael Yeh, Yujie Fan, Yan Zheng, Junpeng Wang, Vivian Lai, Mahashweta Das, Hao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sharpness-Aware+Graph+Collaborative+Filtering)|0|
|[ExaRanker: Synthetic Explanations Improve Neural Rankers](https://doi.org/10.1145/3539618.3592067)|Fernando Ferraretto, Thiago Laitz, Roberto de Alencar Lotufo, Rodrigo Frassetto Nogueira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ExaRanker:+Synthetic+Explanations+Improve+Neural+Rankers)|0|
|[Text-to-Motion Retrieval: Towards Joint Understanding of Human Motion Data and Natural Language](https://doi.org/10.1145/3539618.3592069)|Nicola Messina, Jan Sedmidubský, Fabrizio Falchi, Tomás Rebok||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text-to-Motion+Retrieval:+Towards+Joint+Understanding+of+Human+Motion+Data+and+Natural+Language)|0|
|[TripSafe: Retrieving Safety-related Abnormal Trips in Real-time with Trajectory Data](https://doi.org/10.1145/3539618.3592074)|Yueyang Su, Di Yao, Xiaolei Zhou, Yuxuan Zhang, Yunxia Fan, Lu Bai, Jingping Bi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TripSafe:+Retrieving+Safety-related+Abnormal+Trips+in+Real-time+with+Trajectory+Data)|0|
|[Unsupervised Dense Retrieval Training with Web Anchors](https://doi.org/10.1145/3539618.3592080)|Yiqing Xie, Xiao Liu, Chenyan Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Dense+Retrieval+Training+with+Web+Anchors)|0|
|[When the Music Stops: Tip-of-the-Tongue Retrieval for Music](https://doi.org/10.1145/3539618.3592086)|Samarth Bhargav, Anne Schuth, Claudia Hauff||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+the+Music+Stops:+Tip-of-the-Tongue+Retrieval+for+Music)|0|
|[Reproducibility, Replicability, and Insights into Dense Multi-Representation Retrieval Models: from ColBERT to Col](https://doi.org/10.1145/3539618.3591916)|Xiao Wang, Craig Macdonald, Nicola Tonellotto, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reproducibility,+Replicability,+and+Insights+into+Dense+Multi-Representation+Retrieval+Models:+from+ColBERT+to+Col)|0|
|[On Stance Detection in Image Retrieval for Argumentation](https://doi.org/10.1145/3539618.3591917)|Miriam Louise Carnot, Lorenz Heinemann, Jan Braker, Tobias Schreieder, Johannes Kiesel, Maik Fröbe, Martin Potthast, Benno Stein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Stance+Detection+in+Image+Retrieval+for+Argumentation)|0|
|[Take a Fresh Look at Recommender Systems from an Evaluation Standpoint](https://doi.org/10.1145/3539618.3591931)|Aixin Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Take+a+Fresh+Look+at+Recommender+Systems+from+an+Evaluation+Standpoint)|0|
|[Where to Go Next for Recommender Systems? ID- vs. Modality-based Recommender Models Revisited](https://doi.org/10.1145/3539618.3591932)|Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, Yongxin Ni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Where+to+Go+Next+for+Recommender+Systems?+ID-+vs.+Modality-based+Recommender+Models+Revisited)|0|
|[How Important is Periodic Model update in Recommender System?](https://doi.org/10.1145/3539618.3591934)|Hyunsung Lee, Sungwook Yoo, Dongjun Lee, Jaekwang Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Important+is+Periodic+Model+update+in+Recommender+System?)|0|
|[Metric-agnostic Ranking Optimization](https://doi.org/10.1145/3539618.3591935)|Qingyao Ai, Xuanhui Wang, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metric-agnostic+Ranking+Optimization)|0|
|[Recipe-MPR: A Test Collection for Evaluating Multi-aspect Preference-based Natural Language Retrieval](https://doi.org/10.1145/3539618.3591880)|Haochen Zhang, Anton Korikov, Parsa Farinneya, Mohammad Mahdi Abdollah Pour, Manasa Bharadwaj, Ali Pesaranghader, Xi Yu Huang, Yi Xin Lok, Zhaoqi Wang, Nathan Jones, Scott Sanner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recipe-MPR:+A+Test+Collection+for+Evaluating+Multi-aspect+Preference-based+Natural+Language+Retrieval)|0|
|[The Information Retrieval Experiment Platform](https://doi.org/10.1145/3539618.3591888)|Maik Fröbe, Jan Heinrich Reimer, Sean MacAvaney, Niklas Deckers, Simon Reich, Janek Bevendorff, Benno Stein, Matthias Hagen, Martin Potthast||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Information+Retrieval+Experiment+Platform)|0|
|[RecStudio: Towards a Highly-Modularized Recommender System](https://doi.org/10.1145/3539618.3591894)|Defu Lian, Xu Huang, Xiaolong Chen, Jin Chen, Xingmei Wang, Yankai Wang, Haoran Jin, Rui Fan, Zheng Liu, Le Wu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecStudio:+Towards+a+Highly-Modularized+Recommender+System)|0|
|[MR2: A Benchmark for Multimodal Retrieval-Augmented Rumor Detection in Social Media](https://doi.org/10.1145/3539618.3591896)|Xuming Hu, Zhijiang Guo, Junzhe Chen, Lijie Wen, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MR2:+A+Benchmark+for+Multimodal+Retrieval-Augmented+Rumor+Detection+in+Social+Media)|0|
|[RL4RS: A Real-World Dataset for Reinforcement Learning based Recommender System](https://doi.org/10.1145/3539618.3591899)|Kai Wang, Zhene Zou, Minghao Zhao, Qilin Deng, Yue Shang, Yile Liang, Runze Wu, Xudong Shen, Tangjie Lyu, Changjie Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RL4RS:+A+Real-World+Dataset+for+Reinforcement+Learning+based+Recommender+System)|0|
|[iQPP: A Benchmark for Image Query Performance Prediction](https://doi.org/10.1145/3539618.3591901)|Eduard Poesina, Radu Tudor Ionescu, Josiane Mothe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iQPP:+A+Benchmark+for+Image+Query+Performance+Prediction)|0|
|[SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval](https://doi.org/10.1145/3539618.3591902)|Nandan Thakur, Kexin Wang, Iryna Gurevych, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SPRINT:+A+Unified+Toolkit+for+Evaluating+and+Demystifying+Zero-shot+Neural+Sparse+Retrieval)|0|
|[AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia Content Creation](https://doi.org/10.1145/3539618.3591903)|JhengHong Yang, Carlos Lassance, Rafael Sampaio de Rezende, Krishna Srinivasan, Miriam Redi, Stéphane Clinchant, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AToMiC:+An+Image/Text+Retrieval+Test+Collection+to+Support+Multimedia+Content+Creation)|0|
|[MobileRec: A Large Scale Dataset for Mobile Apps Recommendation](https://doi.org/10.1145/3539618.3591906)|Muhammad Hasan Maqbool, Umar Farooq, Adib Mosharrof, A. B. Siddique, Hassan Foroosh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MobileRec:+A+Large+Scale+Dataset+for+Mobile+Apps+Recommendation)|0|
|[LibVQ: A Toolkit for Optimizing Vector Quantization and Efficient Neural Retrieval](https://doi.org/10.1145/3539618.3591799)|Chaofan Li, Zheng Liu, Shitao Xiao, Yingxia Shao, Defu Lian, Zhao Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LibVQ:+A+Toolkit+for+Optimizing+Vector+Quantization+and+Efficient+Neural+Retrieval)|0|
|[VoMBaT: A Tool for Visualising Evaluation Measure Behaviour in High-Recall Search Tasks](https://doi.org/10.1145/3539618.3591802)|Wojciech Kusa, Aldo Lipani, Petr Knoth, Allan Hanbury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VoMBaT:+A+Tool+for+Visualising+Evaluation+Measure+Behaviour+in+High-Recall+Search+Tasks)|0|
|[Searching the ACL Anthology with Math Formulas and Text](https://doi.org/10.1145/3539618.3591803)|Bryan Amador, Matt Langsenkamp, Abhisek Dey, Ayush Kumar Shah, Richard Zanibbi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Searching+the+ACL+Anthology+with+Math+Formulas+and+Text)|0|
|[Tevatron: An Efficient and Flexible Toolkit for Neural Retrieval](https://doi.org/10.1145/3539618.3591805)|Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tevatron:+An+Efficient+and+Flexible+Toolkit+for+Neural+Retrieval)|0|
|[SciHarvester: Searching Scientific Documents for Numerical Values](https://doi.org/10.1145/3539618.3591808)|Maciej Rybinski, Stephen Wan, Sarvnaz Karimi, Cécile Paris, Brian Jin, Neil I. Huth, Peter J. Thorburn, Dean P. Holzworth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SciHarvester:+Searching+Scientific+Documents+for+Numerical+Values)|0|
|[A Retrieval System for Images and Videos based on Aesthetic Assessment of Visuals](https://doi.org/10.1145/3539618.3591817)|Daniel Vera Nieto, Saikishore Kalloori, Fabio Zund, Clara FernandezLabrador, Marc Willhaus, Severin Klingler, Markus H. Gross||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Retrieval+System+for+Images+and+Videos+based+on+Aesthetic+Assessment+of+Visuals)|0|
|[XpmIR: A Modular Library for Learning to Rank and Neural IR Experiments](https://doi.org/10.1145/3539618.3591818)|Yuxuan Zong, Benjamin Piwowarski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XpmIR:+A+Modular+Library+for+Learning+to+Rank+and+Neural+IR+Experiments)|0|
|[Searching for Reliable Facts over a Medical Knowledge Base](https://doi.org/10.1145/3539618.3591822)|Fabio Giachelle, Stefano Marchesin, Gianmaria Silvello, Omar Alonso||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Searching+for+Reliable+Facts+over+a+Medical+Knowledge+Base)|0|
|[Interactive Recommendation System for Meituan Waimai](https://doi.org/10.1145/3539618.3591830)|Chen Ji, Yacheng Li, Rui Li, Fei Jiang, Xiang Li, Wei Lin, Chenglong Zhang, Wei Wang, Shuyang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interactive+Recommendation+System+for+Meituan+Waimai)|0|
|[Practice and Challenges in Building a Business-oriented Search Engine Quality Metric](https://doi.org/10.1145/3539618.3591841)|Nuo Chen, Donghyun Park, Hyungae Park, Kijun Choi, Tetsuya Sakai, Jinyoung Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practice+and+Challenges+in+Building+a+Business-oriented+Search+Engine+Quality+Metric)|0|
|[Building a Graph-Based Patent Search Engine](https://doi.org/10.1145/3539618.3591842)|Sebastian Björkqvist, Juho Kallio||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Building+a+Graph-Based+Patent+Search+Engine)|0|
|[Graph Enhanced BERT for Query Understanding](https://doi.org/10.1145/3539618.3591845)|Juanhui Li, Wei Zeng, Suqi Cheng, Yao Ma, Jiliang Tang, Shuaiqiang Wang, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Enhanced+BERT+for+Query+Understanding)|0|
|[Neural Methods for Cross-Language Information Retrieval](https://doi.org/10.1145/3539618.3594244)|Eugene Yang, Dawn J. Lawrie, James Mayfield, Suraj Nair, Douglas W. Oard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Methods+for+Cross-Language+Information+Retrieval)|0|
|[Causal Recommendation: Progresses and Future Directions](https://doi.org/10.1145/3539618.3594245)|Wenjie Wang, Yang Zhang, Haoxuan Li, Peng Wu, Fuli Feng, Xiangnan He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Recommendation:+Progresses+and+Future+Directions)|0|
|[Neuro-Symbolic Representations for Information Retrieval](https://doi.org/10.1145/3539618.3594246)|Laura Dietz, Hannah Bast, Shubham Chatterjee, Jeffrey Dalton, JianYun Nie, Rodrigo Frassetto Nogueira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neuro-Symbolic+Representations+for+Information+Retrieval)|0|
|[Explainable Information Retrieval](https://doi.org/10.1145/3539618.3594249)|Avishek Anand, Procheta Sen, Sourav Saha, Manisha Verma, Mandar Mitra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Information+Retrieval)|0|
|[Proactive Conversational Agents in the Post-ChatGPT World](https://doi.org/10.1145/3539618.3594250)|Lizi Liao, Grace Hui Yang, Chirag Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proactive+Conversational+Agents+in+the+Post-ChatGPT+World)|0|
|[FLIRT: Federated Learning for Information Retrieval](https://doi.org/10.1145/3539618.3591926)|Fabio Pinelli, Gabriele Tolomei, Giovanni Trappolini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLIRT:+Federated+Learning+for+Information+Retrieval)|0|
|[Quantifying and Advancing Information Retrieval System Explainability](https://doi.org/10.1145/3539618.3591792)|Catherine Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+and+Advancing+Information+Retrieval+System+Explainability)|0|
|[Multimodal Named Entity Recognition and Relation Extraction with Retrieval-Augmented Strategy](https://doi.org/10.1145/3539618.3591790)|Xuming Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Named+Entity+Recognition+and+Relation+Extraction+with+Retrieval-Augmented+Strategy)|0|
|[Defining and Measuring Cost, Effort, and Load in Information Retrieval](https://doi.org/10.1145/3539618.3591794)|Molly McGregor||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Defining+and+Measuring+Cost,+Effort,+and+Load+in+Information+Retrieval)|0|
|[Resilient Retrieval Models for Large Collection](https://doi.org/10.1145/3539618.3591793)|Dipannita Podder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Resilient+Retrieval+Models+for+Large+Collection)|0|
|[Neural Architectures for Searching Subgraph Structures](https://doi.org/10.1145/3539618.3591791)|Radin Hamidi Rad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Architectures+for+Searching+Subgraph+Structures)|0|
|[Dense Passage Retrieval: Architectures and Augmentation Methods](https://doi.org/10.1145/3539618.3591796)|Thilina Rajapakse||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dense+Passage+Retrieval:+Architectures+and+Augmentation+Methods)|0|
|[Towards Trustworthy Recommender System: A Faithful and Responsible Recommendation Perspective](https://doi.org/10.1145/3539618.3591798)|Yang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Trustworthy+Recommender+System:+A+Faithful+and+Responsible+Recommendation+Perspective)|0|
|[Adversarial Meta Prompt Tuning for Open Compound Domain Adaptive Intent Detection](https://doi.org/10.1145/3539618.3591945)|Feiteng Fang, Min Yang, Chengming Li, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Meta+Prompt+Tuning+for+Open+Compound+Domain+Adaptive+Intent+Detection)|0|
|[Tahaqqaq: A Real-Time System for Assisting Twitter Users in Arabic Claim Verification](https://doi.org/10.1145/3539618.3591815)|Zien Sheikh Ali, Watheq Mansour, Fatima Haouari, Maram Hasanain, Tamer Elsayed, Abdulaziz AlAli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tahaqqaq:+A+Real-Time+System+for+Assisting+Twitter+Users+in+Arabic+Claim+Verification)|0|
|[Building K-Anonymous User Cohorts with Consecutive Consistent Weighted Sampling (CCWS)](https://doi.org/10.1145/3539618.3591857)|Xinyi Zheng, Weijie Zhao, Xiaoyun Li, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Building+K-Anonymous+User+Cohorts+with+Consecutive+Consistent+Weighted+Sampling+(CCWS))|0|
|[On the "Rough Use" of Machine Learning Techniques](https://doi.org/10.1145/3539618.3591872)|ChihJen Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+"Rough+Use"+of+Machine+Learning+Techniques)|0|
|[Adapting Generative Pretrained Language Model for Open-domain Multimodal Sentence Summarization](https://doi.org/10.1145/3539618.3591633)|Dengtian Lin, Liqiang Jing, Xuemeng Song, Meng Liu, Teng Sun, Liqiang Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adapting+Generative+Pretrained+Language+Model+for+Open-domain+Multimodal+Sentence+Summarization)|0|
|[SciMine: An Efficient Systematic Prioritization Model Based on Richer Semantic Information](https://doi.org/10.1145/3539618.3591764)|Fang Guo, Yun Luo, Linyi Yang, Yue Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SciMine:+An+Efficient+Systematic+Prioritization+Model+Based+on+Richer+Semantic+Information)|0|
|[Towards Multi-Interest Pre-training with Sparse Capsule Network](https://doi.org/10.1145/3539618.3591778)|Zuoli Tang, Lin Wang, Lixin Zou, Xiaolu Zhang, Jun Zhou, Chenliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Multi-Interest+Pre-training+with+Sparse+Capsule+Network)|0|
|[A Scalable Framework for Automatic Playlist Continuation on Music Streaming Services](https://doi.org/10.1145/3539618.3591628)|Walid Bendada, Guillaume SalhaGalvan, Thomas Bouabça, Tristan Cazenave||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Scalable+Framework+for+Automatic+Playlist+Continuation+on+Music+Streaming+Services)|0|
|[BotMoE: Twitter Bot Detection with Community-Aware Mixtures of Modal-Specific Experts](https://doi.org/10.1145/3539618.3591646)|Yuhan Liu, Zhaoxuan Tan, Heng Wang, Shangbin Feng, Qinghua Zheng, Minnan Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BotMoE:+Twitter+Bot+Detection+with+Community-Aware+Mixtures+of+Modal-Specific+Experts)|0|
|[Decoupled Hyperbolic Graph Attention Network for Cross-domain Named Entity Recognition](https://doi.org/10.1145/3539618.3591662)|Jingyun Xu, Yi Cai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Hyperbolic+Graph+Attention+Network+for+Cross-domain+Named+Entity+Recognition)|0|
|[StreamE: Learning to Update Representations for Temporal Knowledge Graphs in Streaming Scenarios](https://doi.org/10.1145/3539618.3591772)|Jiasheng Zhang, Jie Shao, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=StreamE:+Learning+to+Update+Representations+for+Temporal+Knowledge+Graphs+in+Streaming+Scenarios)|0|
|[Understand the Dynamic World: An End-to-End Knowledge Informed Framework for Open Domain Entity State Tracking](https://doi.org/10.1145/3539618.3591781)|Mingchen Li, Lifu Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understand+the+Dynamic+World:+An+End-to-End+Knowledge+Informed+Framework+for+Open+Domain+Entity+State+Tracking)|0|
|[BLADE: Combining Vocabulary Pruning and Intermediate Pretraining for Scaleable Neural CLIR](https://doi.org/10.1145/3539618.3591644)|Suraj Nair, Eugene Yang, Dawn J. Lawrie, James Mayfield, Douglas W. Oard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BLADE:+Combining+Vocabulary+Pruning+and+Intermediate+Pretraining+for+Scaleable+Neural+CLIR)|0|
|[Cross-Market Product-Related Question Answering](https://doi.org/10.1145/3539618.3591658)|Negin Ghasemi, Mohammad Aliannejadi, Hamed R. Bonab, Evangelos Kanoulas, Arjen P. de Vries, James Allan, Djoerd Hiemstra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Market+Product-Related+Question+Answering)|0|
|[ErrorCLR: Semantic Error Classification, Localization and Repair for Introductory Programming Assignments](https://doi.org/10.1145/3539618.3591680)|Siqi Han, Yu Wang, Xuesong Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ErrorCLR:+Semantic+Error+Classification,+Localization+and+Repair+for+Introductory+Programming+Assignments)|0|
|[Dual Semantic Knowledge Composed Multimodal Dialog Systems](https://doi.org/10.1145/3539618.3591673)|Xiaolin Chen, Xuemeng Song, Yinwei Wei, Liqiang Nie, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Semantic+Knowledge+Composed+Multimodal+Dialog+Systems)|0|
|[Mixup-based Unified Framework to Overcome Gender Bias Resurgence](https://doi.org/10.1145/3539618.3591938)|Liu Yu, Yuzhou Mao, Jin Wu, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mixup-based+Unified+Framework+to+Overcome+Gender+Bias+Resurgence)|0|
|[Calibration Learning for Few-shot Novel Product Description](https://doi.org/10.1145/3539618.3591959)|Zheng Liu, Mingjing Wu, Bo Peng, Yichao Liu, Qi Peng, Chong Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibration+Learning+for+Few-shot+Novel+Product+Description)|0|
|[Decomposing Logits Distillation for Incremental Named Entity Recognition](https://doi.org/10.1145/3539618.3591970)|Duzhen Zhang, Yahan Yu, Feilong Chen, Xiuyi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decomposing+Logits+Distillation+for+Incremental+Named+Entity+Recognition)|0|
|[Examining the Impact of Uncontrolled Variables on Physiological Signals in User Studies for Information Processing Activities](https://doi.org/10.1145/3539618.3591981)|Kaixin Ji, Damiano Spina, Danula Hettiachchi, Flora Dilys Salim, Falk Scholer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Examining+the+Impact+of+Uncontrolled+Variables+on+Physiological+Signals+in+User+Studies+for+Information+Processing+Activities)|0|
|[Fairness for both Readers and Authors: Evaluating Summaries of User Generated Content](https://doi.org/10.1145/3539618.3591986)|Garima Chhikara, Kripabandhu Ghosh, Saptarshi Ghosh, Abhijnan Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+for+both+Readers+and+Authors:+Evaluating+Summaries+of+User+Generated+Content)|0|
|[Limitations of Open-Domain Question Answering Benchmarks for Document-level Reasoning](https://doi.org/10.1145/3539618.3592011)|Ehsan Kamalloo, Charles L. A. Clarke, Davood Rafiei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Limitations+of+Open-Domain+Question+Answering+Benchmarks+for+Document-level+Reasoning)|0|
|[MDDL: A Framework for Reinforcement Learning-based Position Allocation in Multi-Channel Feed](https://doi.org/10.1145/3539618.3592018)|Xiaowen Shi, Ze Wang, Yuanying Cai, Xiaoxu Wu, Fan Yang, Guogang Liao, Yongkang Wang, Xingxing Wang, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDDL:+A+Framework+for+Reinforcement+Learning-based+Position+Allocation+in+Multi-Channel+Feed)|0|
|[On Answer Position Bias in Transformers for Question Answering](https://doi.org/10.1145/3539618.3592029)|Rafael Glater, Rodrygo L. T. Santos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Answer+Position+Bias+in+Transformers+for+Question+Answering)|0|
|[Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation](https://doi.org/10.1145/3539618.3592043)|Lei Liu, Jimmy Xiangji Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Learning+to+Mitigate+Catastrophic+Forgetting+in+Cross-lingual+Transfer+for+Open-domain+Dialogue+Generation)|0|
|[Reducing Spurious Correlations for Relation Extraction by Feature Decomposition and Semantic Augmentation](https://doi.org/10.1145/3539618.3592050)|Tianshu Yu, Min Yang, Chengming Li, Ruifeng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reducing+Spurious+Correlations+for+Relation+Extraction+by+Feature+Decomposition+and+Semantic+Augmentation)|0|
|[EmoUS: Simulating User Emotions in Task-Oriented Dialogues](https://doi.org/10.1145/3539618.3592092)|HsienChin Lin, Shutong Feng, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Michael Heck, Benjamin Matthias Ruppik, Renato Vukovic, Milica Gasic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EmoUS:+Simulating+User+Emotions+in+Task-Oriented+Dialogues)|0|
|[BizGraphQA: A Dataset for Image-based Inference over Graph-structured Diagrams from Business Domains](https://doi.org/10.1145/3539618.3591875)|Petr Babkin, William Watson, Zhiqiang Ma, Lucas Cecchi, Natraj Raman, Armineh Nourbakhsh, Sameena Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BizGraphQA:+A+Dataset+for+Image-based+Inference+over+Graph-structured+Diagrams+from+Business+Domains)|0|
|[Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection](https://doi.org/10.1145/3539618.3591882)|Martin Wessel, Tomás Horych, Terry Ruas, Akiko Aizawa, Bela Gipp, Timo Spinde||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Introducing+MBIB+-+The+First+Media+Bias+Identification+Benchmark+Task+and+Dataset+Collection)|0|
|[MetroScope: An Advanced System for Real-Time Detection and Analysis of Metro-Related Threats and Events via Twitter](https://doi.org/10.1145/3539618.3591807)|Jianfeng He, SyuanYing Wu, Abdulaziz Alhamadani, ChihFang Chen, WenFang Lu, ChangTien Lu, David Solnick, Yanlin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetroScope:+An+Advanced+System+for+Real-Time+Detection+and+Analysis+of+Metro-Related+Threats+and+Events+via+Twitter)|0|
|[FairUP: A Framework for Fairness Analysis of Graph Neural Network-Based User Profiling Models](https://doi.org/10.1145/3539618.3591814)|Mohamed Abdelrazek, Erasmo Purificato, Ludovico Boratto, Ernesto William De Luca||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairUP:+A+Framework+for+Fairness+Analysis+of+Graph+Neural+Network-Based+User+Profiling+Models)|0|
|[SONAR: Web-based Tool for Multimodal Exploration of Non-Fungible Token Inspiration Networks](https://doi.org/10.1145/3539618.3591821)|Lucio La Cava, Davide Costa, Andrea Tagarelli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SONAR:+Web-based+Tool+for+Multimodal+Exploration+of+Non-Fungible+Token+Inspiration+Networks)|0|
|[MDI: A Debiasing Method Combining Unbiased and Biased Data](https://doi.org/10.1145/3539618.3591838)|Han Zhao, Qing Cui, Xinyu Li, Rongzhou Bao, Longfei Li, Jun Zhou, Zhehao Liu, Jinghua Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDI:+A+Debiasing+Method+Combining+Unbiased+and+Biased+Data)|0|
|[A Data-centric Solution to Improve Online Performance of Customer Service Bots](https://doi.org/10.1145/3539618.3591843)|Sen Hu, Changlin Yang, Junjie Wang, Siye Liu, Teng Xu, Wangshu Zhang, Jing Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Data-centric+Solution+to+Improve+Online+Performance+of+Customer+Service+Bots)|0|
|[KATIE: A System for Key Attributes Identification in Product Knowledge Graph Construction](https://doi.org/10.1145/3539618.3591846)|Btissam Er Rahmadi, Arturo Oncevay, Yuanyi Ji, Jeff Z. Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KATIE:+A+System+for+Key+Attributes+Identification+in+Product+Knowledge+Graph+Construction)|0|
|[Synerise Monad: A Foundation Model for Behavioral Event Data](https://doi.org/10.1145/3539618.3591851)|Barbara Rychalska, Szymon Lukasik, Jacek Dabrowski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Synerise+Monad:+A+Foundation+Model+for+Behavioral+Event+Data)|0|
|[Contextual Multilingual Spellchecker for User Queries](https://doi.org/10.1145/3539618.3591861)|Sanat Sharma, Josep VallsVargas, Tracy Holloway King, François Guerin, Chirag Arora||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contextual+Multilingual+Spellchecker+for+User+Queries)|0|
|[Exploring 360-Degree View of Customers for Lookalike Modeling](https://doi.org/10.1145/3539618.3591862)|Md. Mostafizur Rahman, Daisuke Kikuta, Satyen Abrol, Yu Hirate, Toyotaro Suzumura, Pablo Loyola, Takuma Ebisu, Manoj Kondapaka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+360-Degree+View+of+Customers+for+Lookalike+Modeling)|0|
|[Evaluating Task-oriented Dialogue Systems with Users](https://doi.org/10.1145/3539618.3591788)|Clemencia Siro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+Task-oriented+Dialogue+Systems+with+Users)|0|
|[Bridging Quantitative and Qualitative Digital Experience Testing](https://doi.org/10.1145/3539618.3591873)|Ranjitha Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Quantitative+and+Qualitative+Digital+Experience+Testing)|0|
|[MGeo: Multi-Modal Geographic Language Model Pre-Training](https://doi.org/10.1145/3539618.3591728)|Ruixue Ding, Boli Chen, Pengjun Xie, Fei Huang, Xin Li, Qiang Zhang, Yao Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MGeo:+Multi-Modal+Geographic+Language+Model+Pre-Training)|0|
|[Large Language Models are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning](https://doi.org/10.1145/3539618.3591708)|Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, Yongbin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+are+Versatile+Decomposers:+Decomposing+Evidence+and+Questions+for+Table-based+Reasoning)|0|
|[DisCover: Disentangled Music Representation Learning for Cover Song Identification](https://doi.org/10.1145/3539618.3591664)|Jiahao Xun, Shengyu Zhang, Yanting Yang, Jieming Zhu, Liqun Deng, Zhou Zhao, Zhenhua Dong, Ruiqi Li, Lichao Zhang, Fei Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DisCover:+Disentangled+Music+Representation+Learning+for+Cover+Song+Identification)|0|
|[Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting](https://doi.org/10.1145/3539618.3591641)|Zhihao Wen, Yuan Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Augmenting+Low-Resource+Text+Classification+with+Graph-Grounded+Pre-training+and+Prompting)|0|
|[Smooth Operators for Effective Systematic Review Queries](https://doi.org/10.1145/3539618.3591768)|Harrisen Scells, Ferdinand Schlatt, Martin Potthast||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Smooth+Operators+for+Effective+Systematic+Review+Queries)|0|
|[Do-GOOD: Towards Distribution Shift Evaluation for Pre-Trained Visual Document Understanding Models](https://doi.org/10.1145/3539618.3591670)|Jiabang He, Yi Hu, Lei Wang, Xing Xu, Ning Liu, Hui Liu, Heng Tao Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do-GOOD:+Towards+Distribution+Shift+Evaluation+for+Pre-Trained+Visual+Document+Understanding+Models)|0|
|[Continual Learning on Dynamic Graphs via Parameter Isolation](https://doi.org/10.1145/3539618.3591652)|Peiyan Zhang, Yuchen Yan, Chaozhuo Li, Senzhang Wang, Xing Xie, Guojie Song, Sunghun Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Learning+on+Dynamic+Graphs+via+Parameter+Isolation)|0|
|[An Effective, Efficient, and Scalable Confidence-based Instance Selection Framework for Transformer-Based Text Classification](https://doi.org/10.1145/3539618.3591638)|Washington Cunha, Celso França, Guilherme Fonseca, Leonardo Rocha, Marcos André Gonçalves||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Effective,+Efficient,+and+Scalable+Confidence-based+Instance+Selection+Framework+for+Transformer-Based+Text+Classification)|0|
|[EDIndex: Enabling Fast Data Queries in Edge Storage Systems](https://doi.org/10.1145/3539618.3591676)|Qiang He, Siyu Tan, Feifei Chen, Xiaolong Xu, Lianyong Qi, Xinhong Hei, Hai Jin, Yun Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EDIndex:+Enabling+Fast+Data+Queries+in+Edge+Storage+Systems)|0|
|[Extending Label Aggregation Models with a Gaussian Process to Denoise Crowdsourcing Labels](https://doi.org/10.1145/3539618.3591685)|Dan Li, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extending+Label+Aggregation+Models+with+a+Gaussian+Process+to+Denoise+Crowdsourcing+Labels)|0|
|[Dataset Preparation for Arbitrary Object Detection: An Automatic Approach based on Web Information in English](https://doi.org/10.1145/3539618.3591661)|Shucheng Li, Boyu Chang, Bo Yang, Hao Wu, Sheng Zhong, Fengyuan Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dataset+Preparation+for+Arbitrary+Object+Detection:+An+Automatic+Approach+based+on+Web+Information+in+English)|0|
|[Leader-Generator Net: Dividing Skill and Implicitness for Conquering FairytaleQA](https://doi.org/10.1145/3539618.3591710)|Wei Peng, Wanshui Li, Yue Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leader-Generator+Net:+Dividing+Skill+and+Implicitness+for+Conquering+FairytaleQA)|0|
|[BiTimeBERT: Extending Pre-Trained Language Representations with Bi-Temporal Information](https://doi.org/10.1145/3539618.3591686)|Jiexin Wang, Adam Jatowt, Masatoshi Yoshikawa, Yi Cai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BiTimeBERT:+Extending+Pre-Trained+Language+Representations+with+Bi-Temporal+Information)|0|
|[Incorporating Structured Sentences with Time-enhanced BERT for Fully-inductive Temporal Relation Prediction](https://doi.org/10.1145/3539618.3591700)|Zhongwu Chen, Chengjin Xu, Fenglong Su, Zhen Huang, Yong Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Structured+Sentences+with+Time-enhanced+BERT+for+Fully-inductive+Temporal+Relation+Prediction)|0|
|[Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion](https://doi.org/10.1145/3539618.3591743)|Linhao Luo, YuanFang Li, Gholamreza Haffari, Shirui Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Normalizing+Flow-based+Neural+Process+for+Few-Shot+Knowledge+Graph+Completion)|0|
|[Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction](https://doi.org/10.1145/3539618.3591763)|Yunzhi Yao, Shengyu Mao, Ningyu Zhang, Xiang Chen, Shumin Deng, Xi Chen, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Schema-aware+Reference+as+Prompt+Improves+Data-Efficient+Knowledge+Graph+Construction)|0|
|[ML-LJP: Multi-Law Aware Legal Judgment Prediction](https://doi.org/10.1145/3539618.3591731)|Yifei Liu, Yiquan Wu, Yating Zhang, Changlong Sun, Weiming Lu, Fei Wu, Kun Kuang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ML-LJP:+Multi-Law+Aware+Legal+Judgment+Prediction)|0|
|[Creating a Silver Standard for Patent Simplification](https://doi.org/10.1145/3539618.3591657)|Silvia Casola, Alberto Lavelli, Horacio Saggion||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Creating+a+Silver+Standard+for+Patent+Simplification)|0|
|[Cone: Unsupervised Contrastive Opinion Extraction](https://doi.org/10.1145/3539618.3591650)|Runcong Zhao, Lin Gui, Yulan He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cone:+Unsupervised+Contrastive+Opinion+Extraction)|0|
|[Representation and Labeling Gap Bridging for Cross-lingual Named Entity Recognition](https://doi.org/10.1145/3539618.3591757)|Xinghua Zhang, Bowen Yu, Jiangxia Cao, Quangang Li, Xuebin Wang, Tingwen Liu, Hongbo Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+and+Labeling+Gap+Bridging+for+Cross-lingual+Named+Entity+Recognition)|0|
|[Unsupervised Readability Assessment via Learning from Weak Readability Signals](https://doi.org/10.1145/3539618.3591695)|Yuliang Liu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Sheng Chen, Zhaoling Chen, Qing Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Readability+Assessment+via+Learning+from+Weak+Readability+Signals)|0|
|[What If: Generating Code to Answer Simulation Questions in Chemistry Texts](https://doi.org/10.1145/3539618.3591783)|Gal Peretz, Mousa Arraf, Kira Radinsky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+If:+Generating+Code+to+Answer+Simulation+Questions+in+Chemistry+Texts)|0|
|[A Topic-aware Summarization Framework with Different Modal Side Information](https://doi.org/10.1145/3539618.3591630)|Xiuying Chen, Mingzhe Li, Shen Gao, Xin Cheng, Qiang Yang, Qishen Zhang, Xin Gao, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Topic-aware+Summarization+Framework+with+Different+Modal+Side+Information)|0|
|[RHB-Net: A Relation-aware Historical Bridging Network for Text2SQL Auto-Completion](https://doi.org/10.1145/3539618.3591759)|Bolong Zheng, Lei Bi, Ruijie Xi, Lu Chen, Yunjun Gao, Xiaofang Zhou, Christian S. Jensen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RHB-Net:+A+Relation-aware+Historical+Bridging+Network+for+Text2SQL+Auto-Completion)|0|
|[MAMO: Fine-Grained Vision-Language Representations Learning with Masked Multimodal Modeling](https://doi.org/10.1145/3539618.3591721)|Zijia Zhao, Longteng Guo, Xingjian He, Shuai Shao, Zehuan Yuan, Jing Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAMO:+Fine-Grained+Vision-Language+Representations+Learning+with+Masked+Multimodal+Modeling)|0|
|[Learn from Relational Correlations and Periodic Events for Temporal Knowledge Graph Reasoning](https://doi.org/10.1145/3539618.3591711)|Ke Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learn+from+Relational+Correlations+and+Periodic+Events+for+Temporal+Knowledge+Graph+Reasoning)|0|
|[Dynamic Mixed Membership Stochastic Block Model for Weighted Labeled Networks](https://doi.org/10.1145/3539618.3591675)|Gaël PouxMédard, Julien Velcin, Sabine Loudcher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Mixed+Membership+Stochastic+Block+Model+for+Weighted+Labeled+Networks)|0|
|[DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for Temporal Knowledge Graph Reasoning](https://doi.org/10.1145/3539618.3591671)|Shangfei Zheng, Hongzhi Yin, Tong Chen, Quoc Viet Hung Nguyen, Wei Chen, Lei Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DREAM:+Adaptive+Reinforcement+Learning+based+on+Attention+Mechanism+for+Temporal+Knowledge+Graph+Reasoning)|0|
|[SCHash: Speedy Simplicial Complex Neural Networks via Randomized Hashing](https://doi.org/10.1145/3539618.3591762)|Xuan Tan, Wei Wu, Chuan Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SCHash:+Speedy+Simplicial+Complex+Neural+Networks+via+Randomized+Hashing)|0|
|[A Critical Reexamination of Intra-List Distance and Dispersion](https://doi.org/10.1145/3539618.3591623)|Naoto Ohsaka, Riku Togashi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Critical+Reexamination+of+Intra-List+Distance+and+Dispersion)|0|
|[Contrastive Learning for Signed Bipartite Graphs](https://doi.org/10.1145/3539618.3591655)|Zeyu Zhang, Jiamou Liu, Kaiqi Zhao, Song Yang, Xianda Zheng, Yifei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+for+Signed+Bipartite+Graphs)|0|
|[Uncertainty Quantification for Extreme Classification](https://doi.org/10.1145/3539618.3591780)|JyunYu Jiang, WeiCheng Chang, Jiong Zhang, ChoJui Hsieh, HsiangFu Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty+Quantification+for+Extreme+Classification)|0|
|[A Mathematical Word Problem Generator with Structure Planning and Knowledge Enhancement](https://doi.org/10.1145/3539618.3591937)|Longhu Qin, Jiayu Liu, Zhenya Huang, Kai Zhang, Qi Liu, Binbin Jin, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Mathematical+Word+Problem+Generator+with+Structure+Planning+and+Knowledge+Enhancement)|0|
|[A Simple yet Effective Framework for Few-Shot Aspect-Based Sentiment Analysis](https://doi.org/10.1145/3539618.3591940)|Zengzhi Wang, Qiming Xie, Rui Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Simple+yet+Effective+Framework+for+Few-Shot+Aspect-Based+Sentiment+Analysis)|0|
|[A Unified Formulation for the Frequency Distribution of Word Frequencies using the Inverse Zipf's Law](https://doi.org/10.1145/3539618.3591942)|Can Özbey, Talha Çolakoglu, M. Safak Bilici, Ekin Can Erkus||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Unified+Formulation+for+the+Frequency+Distribution+of+Word+Frequencies+using+the+Inverse+Zipf's+Law)|0|
|[Bayesian Knowledge-driven Critiquing with Indirect Evidence](https://doi.org/10.1145/3539618.3591954)|Armin Toroghi, Griffin Floto, Zhenwei Tang, Scott Sanner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bayesian+Knowledge-driven+Critiquing+with+Indirect+Evidence)|0|
|[BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER](https://doi.org/10.1145/3539618.3591957)|Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, Dinesh Manocha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BioAug:+Conditional+Generation+based+Data+Augmentation+for+Low-Resource+Biomedical+NER)|0|
|[Dimension-Prompts Boost Commonsense Consolidation](https://doi.org/10.1145/3539618.3591973)|Jiazhan Feng, Chongyang Tao, Tao Shen, Chang Liu, Dongyan Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dimension-Prompts+Boost+Commonsense+Consolidation)|0|
|[DeviceGPT: A Generative Pre-Training Transformer on the Heterogenous Graph for Internet of Things](https://doi.org/10.1145/3539618.3591972)|Yimo Ren, Jinfa Wang, Hong Li, Hongsong Zhu, Limin Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeviceGPT:+A+Generative+Pre-Training+Transformer+on+the+Heterogenous+Graph+for+Internet+of+Things)|0|
|[DocGraphLM: Documental Graph Language Model for Information Extraction](https://doi.org/10.1145/3539618.3591975)|Dongsheng Wang, Zhiqiang Ma, Armineh Nourbakhsh, Kang Gu, Sameena Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DocGraphLM:+Documental+Graph+Language+Model+for+Information+Extraction)|0|
|[Exploiting Ubiquitous Mentions for Document-Level Relation Extraction](https://doi.org/10.1145/3539618.3591984)|Ruoyu Zhang, Yanzeng Li, Minhao Zhang, Lei Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Ubiquitous+Mentions+for+Document-Level+Relation+Extraction)|0|
|[Faster Dynamic Pruning via Reordering of Documents in Inverted Indexes](https://doi.org/10.1145/3539618.3591987)|Erman Yafay, Ismail Sengor Altingovde||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Faster+Dynamic+Pruning+via+Reordering+of+Documents+in+Inverted+Indexes)|0|
|[Gated Attention with Asymmetric Regularization for Transformer-based Continual Graph Learning](https://doi.org/10.1145/3539618.3591991)|Hongxiang Lin, Ruiqi Jia, Xiaoqing Lyu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gated+Attention+with+Asymmetric+Regularization+for+Transformer-based+Continual+Graph+Learning)|0|
|[HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting](https://doi.org/10.1145/3539618.3591997)|Jiaying Lu, Jiaming Shen, Bo Xiong, Wenjing Ma, Steffen Staab, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiPrompt:+Few-Shot+Biomedical+Knowledge+Fusion+via+Hierarchy-Oriented+Prompting)|0|
|[How Significant Attributes are in the Community Detection of Attributed Multiplex Networks](https://doi.org/10.1145/3539618.3591998)|Junwei Cheng, Chaobo He, Kunlin Han, Wenjie Ma, Yong Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Significant+Attributes+are+in+the+Community+Detection+of+Attributed+Multiplex+Networks)|0|
|[HyperFormer: Learning Expressive Sparse Feature Representations via Hypergraph Transformer](https://doi.org/10.1145/3539618.3591999)|Kaize Ding, Albert Jiongqian Liang, Bryan Perozzi, Ting Chen, Ruoxi Wang, Lichan Hong, Ed H. Chi, Huan Liu, Derek Zhiyuan Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyperFormer:+Learning+Expressive+Sparse+Feature+Representations+via+Hypergraph+Transformer)|0|
|[Best Prompts for Text-to-Image Models and How to Find Them](https://doi.org/10.1145/3539618.3592000)|Nikita Pavlichenko, Dmitry Ustalov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Best+Prompts+for+Text-to-Image+Models+and+How+to+Find+Them)|0|
|[LAPCA: Language-Agnostic Pretraining with Cross-Lingual Alignment](https://doi.org/10.1145/3539618.3592006)|Dmitry Abulkhanov, Nikita Sorokin, Sergey Nikolenko, Valentin Malykh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LAPCA:+Language-Agnostic+Pretraining+with+Cross-Lingual+Alignment)|0|
|[Learning from Crowds with Annotation Reliability](https://doi.org/10.1145/3539618.3592007)|Zhi Cao, Enhong Chen, Ye Huang, Shuanghong Shen, Zhenya Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+from+Crowds+with+Annotation+Reliability)|0|
|[Learning Through Interpolative Augmentation of Dynamic Curvature Spaces](https://doi.org/10.1145/3539618.3592008)|Parth Chhabra, Atula Tejaswi Neerkaje, Shivam Agarwal, Ramit Sawhney, Megh Thakkar, Preslav Nakov, Sudheer Chava||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Through+Interpolative+Augmentation+of+Dynamic+Curvature+Spaces)|0|
|[Learning to Ask Clarification Questions with Spatial Reasoning](https://doi.org/10.1145/3539618.3592009)|Yang Deng, Shuaiyi Li, Wai Lam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Ask+Clarification+Questions+with+Spatial+Reasoning)|0|
|[Learning to Ask Questions for Zero-shot Dialogue State Tracking](https://doi.org/10.1145/3539618.3592010)|Diogo Tavares, David Semedo, Alexander Rudnicky, João Magalhães||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Ask+Questions+for+Zero-shot+Dialogue+State+Tracking)|0|
|[Look Ahead: Improving the Accuracy of Time-Series Forecasting by Previewing Future Time Features](https://doi.org/10.1145/3539618.3592013)|Seonmin Kim, DongKyu Chae||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Look+Ahead:+Improving+the+Accuracy+of+Time-Series+Forecasting+by+Previewing+Future+Time+Features)|0|
|[MA-MRC: A Multi-answer Machine Reading Comprehension Dataset](https://doi.org/10.1145/3539618.3592015)|Zhiang Yue, Jingping Liu, Cong Zhang, Chao Wang, Haiyun Jiang, Yue Zhang, Xianyang Tian, Zhedong Cen, Yanghua Xiao, Tong Ruan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MA-MRC:+A+Multi-answer+Machine+Reading+Comprehension+Dataset)|0|
|[Multiple Topics Community Detection in Attributed Networks](https://doi.org/10.1145/3539618.3592026)|Chaobo He, Junwei Cheng, Guohua Chen, Yong Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiple+Topics+Community+Detection+in+Attributed+Networks)|0|
|[NC2T: Novel Curriculum Learning Approaches for Cross-Prompt Trait Scoring](https://doi.org/10.1145/3539618.3592027)|Yejin Lee, Seokwon Jeong, Hongjin Kim, Taeil Kim, SungWon Choi, Harksoo Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NC2T:+Novel+Curriculum+Learning+Approaches+for+Cross-Prompt+Trait+Scoring)|0|
|[On the Impact of Data Quality on Image Classification Fairness](https://doi.org/10.1145/3539618.3592031)|Aki Barry, Lei Han, Gianluca Demartini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Impact+of+Data+Quality+on+Image+Classification+Fairness)|0|
|[Power Norm Based Lifelong Learning for Paraphrase Generations](https://doi.org/10.1145/3539618.3592039)|Dingcheng Li, Peng Yang, Yue Zhang, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Power+Norm+Based+Lifelong+Learning+for+Paraphrase+Generations)|0|
|[Private Meeting Summarization Without Performance Loss](https://doi.org/10.1145/3539618.3592042)|Seolhwa Lee, Anders Søgaard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Private+Meeting+Summarization+Without+Performance+Loss)|0|
|[Read it Twice: Towards Faithfully Interpretable Fact Verification by Revisiting Evidence](https://doi.org/10.1145/3539618.3592049)|Xuming Hu, Zhaochen Hong, Zhijiang Guo, Lijie Wen, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Read+it+Twice:+Towards+Faithfully+Interpretable+Fact+Verification+by+Revisiting+Evidence)|0|
|[RewardTLG: Learning to Temporally Language Grounding from Flexible Reward](https://doi.org/10.1145/3539618.3592054)|Yawen Zeng, Keyu Pan, Ning Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RewardTLG:+Learning+to+Temporally+Language+Grounding+from+Flexible+Reward)|0|
|[SelfLRE: Self-refining Representation Learning for Low-resource Relation Extraction](https://doi.org/10.1145/3539618.3592058)|Xuming Hu, Junzhe Chen, Shiao Meng, Lijie Wen, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SelfLRE:+Self-refining+Representation+Learning+for+Low-resource+Relation+Extraction)|0|
|[Simple Approach for Aspect Sentiment Triplet Extraction Using Span-Based Segment Tagging and Dual Extractors](https://doi.org/10.1145/3539618.3592060)|Dongxu Li, Zhihao Yang, Yuquan Lan, Yunqi Zhang, Hui Zhao, Gang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simple+Approach+for+Aspect+Sentiment+Triplet+Extraction+Using+Span-Based+Segment+Tagging+and+Dual+Extractors)|0|
|[Surprise: Result List Truncation via Extreme Value Theory](https://doi.org/10.1145/3539618.3592066)|Dara Bahri, Che Zheng, Yi Tay, Donald Metzler, Andrew Tomkins||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Surprise:+Result+List+Truncation+via+Extreme+Value+Theory)|0|
|[The Tale of Two MSMARCO - and Their Unfair Comparisons](https://doi.org/10.1145/3539618.3592071)|Carlos Lassance, Stéphane Clinchant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Tale+of+Two+MSMARCO+-+and+Their+Unfair+Comparisons)|0|
|[Towards Robust Knowledge Tracing Models via k-Sparse Attention](https://doi.org/10.1145/3539618.3592073)|Shuyan Huang, Zitao Liu, Xiangyu Zhao, Weiqi Luo, Jian Weng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Robust+Knowledge+Tracing+Models+via+k-Sparse+Attention)|0|
|[Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction](https://doi.org/10.1145/3539618.3592072)|Xuming Hu, Zhaochen Hong, Chenwei Zhang, Irwin King, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Think+Rationally+about+What+You+See:+Continuous+Rationale+Extraction+for+Relation+Extraction)|0|
|[TrustSGCN: Learning Trustworthiness on Edge Signs for Effective Signed Graph Convolutional Networks](https://doi.org/10.1145/3539618.3592075)|MinJeong Kim, YeonChang Lee, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrustSGCN:+Learning+Trustworthiness+on+Edge+Signs+for+Effective+Signed+Graph+Convolutional+Networks)|0|
|[Unsupervised Dialogue Topic Segmentation with Topic-aware Contrastive Learning](https://doi.org/10.1145/3539618.3592081)|Haoyu Gao, Rui Wang, TingEn Lin, Yuchuan Wu, Min Yang, Fei Huang, Yongbin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Dialogue+Topic+Segmentation+with+Topic-aware+Contrastive+Learning)|0|
|[Which Matters Most in Making Fund Investment Decisions? A Multi-granularity Graph Disentangled Learning Framework](https://doi.org/10.1145/3539618.3592088)|Chunjing Gan, Binbin Hu, Bo Huang, Tianyu Zhao, Yingru Lin, Wenliang Zhong, Zhiqiang Zhang, Jun Zhou, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Which+Matters+Most+in+Making+Fund+Investment+Decisions?+A+Multi-granularity+Graph+Disentangled+Learning+Framework)|0|
|[Where Does Your News Come From? Predicting Information Pathways in Social Media](https://doi.org/10.1145/3539618.3592087)|Alexander K. Taylor, Nuan Wen, PoNien Kung, Jiaao Chen, Violet Peng, Wei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Where+Does+Your+News+Come+From?+Predicting+Information+Pathways+in+Social+Media)|0|
|[Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study](https://doi.org/10.1145/3539618.3591918)|Joakim Edin, Alexander Junge, Jakob D. Havtorn, Lasse Borgholt, Maria Maistro, Tuukka Ruotsalo, Lars Maaløe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Medical+Coding+on+MIMIC-III+and+MIMIC-IV:+A+Critical+Review+and+Replicability+Study)|0|
|[An Empirical Comparison of Web Content Extraction Algorithms](https://doi.org/10.1145/3539618.3591920)|Janek Bevendorff, Sanket Gupta, Johannes Kiesel, Benno Stein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Empirical+Comparison+of+Web+Content+Extraction+Algorithms)|0|
|[Multimodal Neural Databases](https://doi.org/10.1145/3539618.3591930)|Giovanni Trappolini, Andrea Santilli, Emanuele Rodolà, Alon Y. Halevy, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Neural+Databases)|0|
|[SocialDial: A Benchmark for Socially-Aware Dialogue Systems](https://doi.org/10.1145/3539618.3591877)|Haolan Zhan, Zhuang Li, Yufei Wang, Linhao Luo, Tao Feng, Xiaoxi Kang, Yuncheng Hua, Lizhen Qu, LayKi Soon, Suraj Sharma, Ingrid Zukerman, Zhaleh SemnaniAzad, Gholamreza Haffari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SocialDial:+A+Benchmark+for+Socially-Aware+Dialogue+Systems)|0|
|[End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models](https://doi.org/10.1145/3539618.3591879)|Barry Menglong Yao, Aditya Shah, Lichao Sun, JinHee Cho, Lifu Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Multimodal+Fact-Checking+and+Explanation+Generation:+A+Challenging+Dataset+and+Models)|0|
|[The JOKER Corpus: English-French Parallel Data for Multilingual Wordplay Recognition](https://doi.org/10.1145/3539618.3591885)|Liana Ermakova, AnneGwenn Bosser, Adam Jatowt, Tristan Miller||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+JOKER+Corpus:+English-French+Parallel+Data+for+Multilingual+Wordplay+Recognition)|0|
|[Form-NLU: Dataset for the Form Natural Language Understanding](https://doi.org/10.1145/3539618.3591886)|Yihao Ding, Siqu Long, Jiabin Huang, Kaixuan Ren, Xingxiang Luo, Hyunsuk Chung, Soyeon Caren Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Form-NLU:+Dataset+for+the+Form+Natural+Language+Understanding)|0|
|[MMEAD: MS MARCO Entity Annotations and Disambiguations](https://doi.org/10.1145/3539618.3591887)|Chris Kamphuis, Aileen Lin, Siwen Yang, Jimmy Lin, Arjen P. de Vries, Faegheh Hasibi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMEAD:+MS+MARCO+Entity+Annotations+and+Disambiguations)|0|
|[GammaGL: A Multi-Backend Library for Graph Neural Networks](https://doi.org/10.1145/3539618.3591891)|Yaoqi Liu, Cheng Yang, Tianyu Zhao, Hui Han, Siyuan Zhang, Jing Wu, Guangyu Zhou, Hai Huang, Hui Wang, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GammaGL:+A+Multi-Backend+Library+for+Graph+Neural+Networks)|0|
|[tieval: An Evaluation Framework for Temporal Information Extraction Systems](https://doi.org/10.1145/3539618.3591892)|Hugo Sousa, Ricardo Campos, Alípio Mário Jorge||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=tieval:+An+Evaluation+Framework+for+Temporal+Information+Extraction+Systems)|0|
|[HC3: A Suite of Test Collections for CLIR Evaluation over Informal Text](https://doi.org/10.1145/3539618.3591893)|Dawn J. Lawrie, James Mayfield, Douglas W. Oard, Eugene Yang, Suraj Nair, Petra Galuscáková||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HC3:+A+Suite+of+Test+Collections+for+CLIR+Evaluation+over+Informal+Text)|0|
|[BioSift: A Dataset for Filtering Biomedical Abstracts for Drug Repurposing and Clinical Meta-Analysis](https://doi.org/10.1145/3539618.3591897)|David Kartchner, Irfan AlHussaini, Haydn Turner, Jennifer Deng, Shubham Lohiya, Prasanth Bathala, Cassie S. Mitchell||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BioSift:+A+Dataset+for+Filtering+Biomedical+Abstracts+for+Drug+Repurposing+and+Clinical+Meta-Analysis)|0|
|[MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs](https://doi.org/10.1145/3539618.3591898)|Jifan Yu, Mengying Lu, Qingyang Zhong, Zijun Yao, Shangqing Tu, Zhengshan Liao, Xiaoya Li, Manli Li, Lei Hou, HaiTao Zheng, Juanzi Li, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoocRadar:+A+Fine-grained+and+Multi-aspect+Knowledge+Repository+for+Improving+Cognitive+Student+Modeling+in+MOOCs)|0|
|[DICE: a Dataset of Italian Crime Event news](https://doi.org/10.1145/3539618.3591904)|Giovanni Bonisoli, Maria Pia di Buono, Laura Po, Federica Rollo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DICE:+a+Dataset+of+Italian+Crime+Event+news)|0|
|[BDI-Sen: A Sentence Dataset for Clinical Symptoms of Depression](https://doi.org/10.1145/3539618.3591905)|Anxo Pérez, Javier Parapar, Álvaro Barreiro, Silvia LopezLarrosa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BDI-Sen:+A+Sentence+Dataset+for+Clinical+Symptoms+of+Depression)|0|
|[REFinD: Relation Extraction Financial Dataset](https://doi.org/10.1145/3539618.3591911)|Simerjot Kaur, Charese Smiley, Akshat Gupta, Joy Sain, Dongsheng Wang, Suchetha Siddagangappa, Toyin Aguda, Sameena Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REFinD:+Relation+Extraction+Financial+Dataset)|0|
|[The BETTER Cross-Language Datasets](https://doi.org/10.1145/3539618.3591910)|Ian Soboroff||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+BETTER+Cross-Language+Datasets)|0|
|[Linked-DocRED - Enhancing DocRED with Entity-Linking to Evaluate End-To-End Document-Level Information Extraction Pipelines](https://doi.org/10.1145/3539618.3591912)|PierreYves Genest, PierreEdouard Portier, Elöd EgyedZsigmond, Martino Lovisetto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Linked-DocRED+-+Enhancing+DocRED+with+Entity-Linking+to+Evaluate+End-To-End+Document-Level+Information+Extraction+Pipelines)|0|
|[A Preference Judgment Tool for Authoritative Assessment](https://doi.org/10.1145/3539618.3591801)|Mahsa Seifikar, Linh Nhi Phan Minh, Negar Arabzadeh, Charles L. A. Clarke, Mark D. Smucker||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Preference+Judgment+Tool+for+Authoritative+Assessment)|0|
|[One Stop Shop for Question-Answering Dataset Selection](https://doi.org/10.1145/3539618.3591804)|Chang Nian Chuy, Qinmin Vivian Hu, Chen Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One+Stop+Shop+for+Question-Answering+Dataset+Selection)|0|
|[Profiling and Visualizing Dynamic Pruning Algorithms](https://doi.org/10.1145/3539618.3591806)|Zhixuan Li, Joel Mackenzie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Profiling+and+Visualizing+Dynamic+Pruning+Algorithms)|0|
|[NeuralKG-ind: A Python Library for Inductive Knowledge Graph Representation Learning](https://doi.org/10.1145/3539618.3591809)|Wen Zhang, Zhen Yao, Mingyang Chen, Zhiwei Huang, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeuralKG-ind:+A+Python+Library+for+Inductive+Knowledge+Graph+Representation+Learning)|0|
|[AMICA: Alleviating Misinformation for Chinese Americans](https://doi.org/10.1145/3539618.3591810)|Xiaoxiao Shang, Ye Chen, Yi Fang, Yuhong Liu, Subramaniam Vincent||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AMICA:+Alleviating+Misinformation+for+Chinese+Americans)|0|
|[PEPO: Petition Executing Processing Optimizer Based on Natural Language Processing](https://doi.org/10.1145/3539618.3591811)|YinWei Chiu, HsiaoChing Huang, ChengJu Lee, HsunPing Hsieh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PEPO:+Petition+Executing+Processing+Optimizer+Based+on+Natural+Language+Processing)|0|
|[SEA: A Scalable Entity Alignment System](https://doi.org/10.1145/3539618.3591816)|Junyang Wu, Tianyi Li, Lu Chen, Yunjun Gao, Ziheng Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEA:+A+Scalable+Entity+Alignment+System)|0|
|[TIB AV-Analytics: A Web-based Platform for Scholarly Video Analysis and Film Studies](https://doi.org/10.1145/3539618.3591820)|Matthias Springstein, Markos Stamatakis, Margret Plank, Julian Sittel, Roman Mauer, Oksana Bulgakowa, Ralph Ewerth, Eric MüllerBudack||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TIB+AV-Analytics:+A+Web-based+Platform+for+Scholarly+Video+Analysis+and+Film+Studies)|0|
|[A Consumer Compensation System in Ride-hailing Service](https://doi.org/10.1145/3539618.3591829)|Zhe Yu, Chi Xia, Shaosheng Cao, Lin Zhou, Haibin Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Consumer+Compensation+System+in+Ride-hailing+Service)|0|
|[Dialog-to-Actions: Building Task-Oriented Dialogue System via Action-Level Generation](https://doi.org/10.1145/3539618.3591832)|Yuncheng Hua, Xiangyu Xi, Zheng Jiang, Guanwei Zhang, Chaobo Sun, Guanglu Wan, Wei Ye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dialog-to-Actions:+Building+Task-Oriented+Dialogue+System+via+Action-Level+Generation)|0|
|[Context-Aware Classification of Legal Document Pages](https://doi.org/10.1145/3539618.3591839)|Pavlos Fragkogiannis, Martina Forster, Grace E. Lee, Dell Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-Aware+Classification+of+Legal+Document+Pages)|0|
|[Enhancing Dynamic Image Advertising with Vision-Language Pre-training](https://doi.org/10.1145/3539618.3591844)|Zhoufutu Wen, Xinyu Zhao, Zhipeng Jin, Yi Yang, Wei Jia, Xiaodong Chen, Shuanglong Li, Lin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Dynamic+Image+Advertising+with+Vision-Language+Pre-training)|0|
|[Modeling Spoken Information Queries for Virtual Assistants: Open Problems, Challenges and Opportunities](https://doi.org/10.1145/3539618.3591849)|Christophe Van Gysel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Spoken+Information+Queries+for+Virtual+Assistants:+Open+Problems,+Challenges+and+Opportunities)|0|
|[Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection](https://doi.org/10.1145/3539618.3591852)|HsiuWei Yang, Abhinav Agrawal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extracting+Complex+Named+Entities+in+Legal+Documents+via+Weakly+Supervised+Object+Detection)|0|
|[Improving Programming Q&A with Neural Generative Augmentation](https://doi.org/10.1145/3539618.3591860)|Suthee Chaidaroon, Xiao Zhang, Shruti Subramaniyam, Jeffrey Svajlenko, Tanya Shourya, Iman Keivanloo, Ria Joy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Programming+Q&A+with+Neural+Generative+Augmentation)|0|
|[Uncertainty Quantification for Text Classification](https://doi.org/10.1145/3539618.3594243)|Dell Zhang, Murat Sensoy, Masoud Makrehchi, Bilyana TanevaPopova, Lin Gui, Yulan He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty+Quantification+for+Text+Classification)|0|
|[Offline Pseudo Relevance Feedback for Efficient and Effective Single-pass Dense Retrieval](https://doi.org/10.1145/3539618.3592028)|Xueru Wen, Xiaoyang Chen, Xuanang Chen, Ben He, Le Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Pseudo+Relevance+Feedback+for+Efficient+and+Effective+Single-pass+Dense+Retrieval)|-1|
|[Exploring Scenarios of Uncertainty about the Users' Preferences in Interactive Recommendation Systems](https://doi.org/10.1145/3539618.3591684)|Nícollas Silva, Thiago Silva, Henrique Hott, Yan Ribeiro, Adriano C. M. Pereira, Leonardo Rocha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Scenarios+of+Uncertainty+about+the+Users'+Preferences+in+Interactive+Recommendation+Systems)|-1|
|[Exploring the Spatiotemporal Features of Online Food Recommendation Service](https://doi.org/10.1145/3539618.3591853)|Shaochuan Lin, Jiayan Pei, Taotao Zhou, Hengxu He, Jia Jia, Ning Hu||Online Food Recommendation Service (OFRS) has remarkable spatiotemporal characteristics and the advantage of being able to conveniently satisfy users' needs in a timely manner. There have been a variety of studies that have begun to explore its spatiotemporal properties, but a comprehensive and in-depth analysis of the OFRS spatiotemporal features is yet to be conducted. Therefore, this paper studies the OFRS based on three questions: how spatiotemporal features play a role; why self-attention cannot be used to model the spatiotemporal sequences of OFRS; and how to combine spatiotemporal features to improve the efficiency of OFRS. Firstly, through experimental analysis, we systemically extracted the spatiotemporal features of OFRS, identified the most valuable features and designed an effective combination method. Secondly, we conducted a detailed analysis of the spatiotemporal sequences, which revealed the shortcomings of self-attention in OFRS, and proposed a more optimized spatiotemporal sequence method for replacing self-attention. In addition, we also designed a Dynamic Context Adaptation Model to further improve the efficiency and performance of OFRS. Through the offline experiments on two large datasets and online experiments for a week, the feasibility and superiority of our model were proven.|在线食品推荐服务(OFRS)具有显著的时空特征和能够方便、及时地满足用户需求的优势。已经有各种各样的研究开始探索它的时空特性，但是对 OFRS 时空特性的全面和深入的分析还有待进行。为此，本文从时空特征如何发挥作用、为什么自我注意不能用于 OFRS 时空序列建模以及如何结合时空特征提高 OFRS 效率三个方面对 OFRS 进行了研究。首先，通过实验分析，系统地提取了 OFRS 的时空特征，识别出最有价值的特征，并设计了一种有效的组合方法。其次，我们对时空序列进行了详细的分析，揭示了 OFRS 中自我注意的缺点，并提出了一种更优化的时空序列替代自我注意的方法。此外，我们还设计了一个动态上下文适应模型来进一步提高 OFRS 的效率和性能。通过两个大型数据集的离线实验和为期一周的在线实验，验证了该模型的可行性和优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+the+Spatiotemporal+Features+of+Online+Food+Recommendation+Service)|-1|
|[MDKG: Graph-Based Medical Knowledge-Guided Dialogue Generation](https://doi.org/10.1145/3539618.3592019)|Usman Naseem, Surendrabikram Thapa, Qi Zhang, Liang Hu, Mehwish Nasim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDKG:+Graph-Based+Medical+Knowledge-Guided+Dialogue+Generation)|-1|
