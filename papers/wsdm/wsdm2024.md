# WSDM2024 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[RecJPQ: Training Large-Catalogue Sequential Recommenders](https://doi.org/10.1145/3616855.3635821)|Aleksandr V. Petrov, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecJPQ:+Training+Large-Catalogue+Sequential+Recommenders)|2|
|[Understanding User Behavior in Carousel Recommendation Systems for Click Modeling and Learning to Rank](https://doi.org/10.1145/3616855.3635734)|Santiago de LeonMartinez||Carousels (also-known as multilists) have become the standard user interface for e-commerce platforms replacing the ranked list, the previous standard for recommender systems. While the research community has begun to focus on carousels, there are many unanswered questions and undeveloped areas when compared to the literature for ranked lists, which includes information retrieval research on the presentation of web search results. This work is an extended abstract for the RecSys 2023 Doctoral Symposium outlining a PhD project, with the main contribution of addressing the undeveloped areas in carousel recommenders: 1) the formulation of new click models and 2) learning to rank with click data.   We present two significant barriers for this contribution and the field: lack of public datasets and lack of eye tracking user studies of browsing behavior. Clicks, the standard feedback collected by recommender systems, are insufficient to understand the whole interaction process of a user with a recommender requiring system designers to make assumptions, especially on browsing behavior. Eye tracking provides a means to elucidate the process and test these assumptions. Thus, to address these barriers and encourage future work, we will conduct an eye tracking user study within a carousel movie recommendation setting and make the dataset publicly available. Moreover, the insights learned on browsing behavior will help motivate the formulation of new click models and learning to rank.|旋转木马(也称为多列表)已经成为电子商务平台的标准用户界面，取代了以前推荐系统的标准排名列表。虽然研究团体已经开始关注旋转木马，但与排名列表的文献相比，还有许多未解答的问题和未开发的领域，其中包括对网络搜索结果呈现的信息检索研究。本文是 RecSys 2023年博士研讨会的扩展摘要，概述了一个博士项目，主要贡献在于解决传送带推荐中的不发达领域: 1)制定新的点击模型，2)学习根据点击数据进行排名。我们提出了两个重要的障碍，这个贡献和领域: 缺乏公共数据集和缺乏眼球跟踪用户研究的浏览行为。点击，推荐系统收集的标准反馈，不足以理解用户与推荐系统的整个交互过程，需要系统设计者做出假设，尤其是在浏览行为方面。眼球追踪提供了一种方法来阐明这一过程，并检验这些假设。因此，为了解决这些障碍并鼓励未来的工作，我们将在旋转木马电影推荐设置中进行眼动跟踪用户研究，并使数据集公开可用。此外，学到的浏览行为的洞察力将有助于激励制定新的点击模型和学习排名。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+User+Behavior+in+Carousel+Recommendation+Systems+for+Click+Modeling+and+Learning+to+Rank)|1|
|[Vector Search with OpenAI Embeddings: Lucene Is All You Need](https://doi.org/10.1145/3616855.3635691)|Jasper Xian, Tommaso Teofili, Ronak Pradeep, Jimmy Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Vector+Search+with+OpenAI+Embeddings:+Lucene+Is+All+You+Need)|1|
|[Let the LLMs Talk: Simulating Human-to-Human Conversational QA via Zero-Shot LLM-to-LLM Interactions](https://doi.org/10.1145/3616855.3635856)|Zahra Abbasiantaeb, Yifei Yuan, Evangelos Kanoulas, Mohammad Aliannejadi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Let+the+LLMs+Talk:+Simulating+Human-to-Human+Conversational+QA+via+Zero-Shot+LLM-to-LLM+Interactions)|1|
|[MADM: A Model-agnostic Denoising Module for Graph-based Social Recommendation](https://doi.org/10.1145/3616855.3635784)|Wenze Ma, Yuexian Wang, Yanmin Zhu, Zhaobo Wang, Mengyuan Jing, Xuhao Zhao, Jiadi Yu, Feilong Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MADM:+A+Model-agnostic+Denoising+Module+for+Graph-based+Social+Recommendation)|1|
|[A Multi-Granularity-Aware Aspect Learning Model for Multi-Aspect Dense Retrieval](https://doi.org/10.1145/3616855.3635770)|Xiaojie Sun, Keping Bi, Jiafeng Guo, Sihui Yang, Qishen Zhang, Zhongyi Liu, Guannan Zhang, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Granularity-Aware+Aspect+Learning+Model+for+Multi-Aspect+Dense+Retrieval)|1|
|[LLMRec: Large Language Models with Graph Augmentation for Recommendation](https://doi.org/10.1145/3616855.3635853)|Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLMRec:+Large+Language+Models+with+Graph+Augmentation+for+Recommendation)|1|
|[Likelihood-Based Methods Improve Parameter Estimation in Opinion Dynamics Models](https://doi.org/10.1145/3616855.3635785)|Jacopo Lenti, Corrado Monti, Gianmarco De Francisci Morales||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Likelihood-Based+Methods+Improve+Parameter+Estimation+in+Opinion+Dynamics+Models)|1|
|[K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization](https://doi.org/10.1145/3616855.3635772)|Cheng Deng, Tianhang Zhang, Zhongmou He, Qiyuan Chen, Yuanyuan Shi, Yi Xu, Luoyi Fu, Weinan Zhang, Xinbing Wang, Chenghu Zhou, Zhouhan Lin, Junxian He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=K2:+A+Foundation+Language+Model+for+Geoscience+Knowledge+Understanding+and+Utilization)|1|
|[Collaboration and Transition: Distilling Item Transitions into Multi-Query Self-Attention for Sequential Recommendation](https://doi.org/10.1145/3616855.3635787)|Tianyu Zhu, Yansong Shi, Yuan Zhang, Yihong Wu, Fengran Mo, JianYun Nie||Modern recommender systems employ various sequential modules such as
self-attention to learn dynamic user interests. However, these methods are less
effective in capturing collaborative and transitional signals within user
interaction sequences. First, the self-attention architecture uses the
embedding of a single item as the attention query, which is inherently
challenging to capture collaborative signals. Second, these methods typically
follow an auto-regressive framework, which is unable to learn global item
transition patterns. To overcome these limitations, we propose a new method
called Multi-Query Self-Attention with Transition-Aware Embedding Distillation
(MQSA-TED). First, we propose an $L$-query self-attention module that employs
flexible window sizes for attention queries to capture collaborative signals.
In addition, we introduce a multi-query self-attention method that balances the
bias-variance trade-off in modeling user preferences by combining long and
short-query self-attentions. Second, we develop a transition-aware embedding
distillation module that distills global item-to-item transition patterns into
item embeddings, which enables the model to memorize and leverage transitional
signals and serves as a calibrator for collaborative signals. Experimental
results on four real-world datasets show the superiority of our proposed method
over state-of-the-art sequential recommendation methods.|现代推荐系统采用自我关注等多种顺序模块来学习动态用户兴趣。然而，这些方法在捕获用户交互序列中的协作和过渡信号方面效率较低。首先，自我注意体系结构使用嵌入单个条目作为注意查询，这对于捕获协作信号具有内在的挑战性。其次，这些方法通常遵循一个自动回归框架，该框架不能学习全局项目转换模式。为了克服这些局限性，本文提出了一种新的基于过渡意识的多查询自注意(MQSA-TED)方法。首先，我们提出了一个 $L $- query 自我注意模块，该模块使用灵活的窗口大小来进行注意查询以捕获协作信号。此外，本文还提出了一种结合长查询和短查询自注意的多查询自注意方法，平衡了偏差-方差权衡。其次，我们开发了一个具有过渡意识的嵌入蒸馏模块，该模块将全局项目到项目的过渡模式提取为项目嵌入，使模型能够记忆和利用过渡信号，并作为协作信号的校准器。在四个实际数据集上的实验结果表明，本文提出的方法优于目前最先进的顺序推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaboration+and+Transition:+Distilling+Item+Transitions+into+Multi-Query+Self-Attention+for+Sequential+Recommendation)|0|
|[Contextual MAB Oriented Embedding Denoising for Sequential Recommendation](https://doi.org/10.1145/3616855.3635798)|Zhichao Feng, Pengfei Wang, Kaiyuan Li, Chenliang Li, Shangguang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contextual+MAB+Oriented+Embedding+Denoising+for+Sequential+Recommendation)|0|
|[User Behavior Enriched Temporal Knowledge Graphs for Sequential Recommendation](https://doi.org/10.1145/3616855.3635762)|Hengchang Hu, Wei Guo, Xu Liu, Yong Liu, Ruiming Tang, Rui Zhang, MinYen Kan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Behavior+Enriched+Temporal+Knowledge+Graphs+for+Sequential+Recommendation)|0|
|[Global Heterogeneous Graph and Target Interest Denoising for Multi-behavior Sequential Recommendation](https://doi.org/10.1145/3616855.3635857)|Xuewei Li, Hongwei Chen, Jian Yu, Mankun Zhao, Tianyi Xu, Wenbin Zhang, Mei Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Global+Heterogeneous+Graph+and+Target+Interest+Denoising+for+Multi-behavior+Sequential+Recommendation)|0|
|[Attribute Simulation for Item Embedding Enhancement in Multi-interest Recommendation](https://doi.org/10.1145/3616855.3635841)|Yaokun Liu, Xiaowang Zhang, Minghui Zou, Zhiyong Feng||Although multi-interest recommenders have achieved significant progress in
the matching stage, our research reveals that existing models tend to exhibit
an under-clustered item embedding space, which leads to a low discernibility
between items and hampers item retrieval. This highlights the necessity for
item embedding enhancement. However, item attributes, which serve as effective
and straightforward side information for enhancement, are either unavailable or
incomplete in many public datasets due to the labor-intensive nature of manual
annotation tasks. This dilemma raises two meaningful questions: 1. Can we
bypass manual annotation and directly simulate complete attribute information
from the interaction data? And 2. If feasible, how to simulate attributes with
high accuracy and low complexity in the matching stage?
  In this paper, we first establish an inspiring theoretical feasibility that
the item-attribute correlation matrix can be approximated through elementary
transformations on the item co-occurrence matrix. Then based on formula
derivation, we propose a simple yet effective module, SimEmb (Item Embedding
Enhancement via Simulated Attribute), in the multi-interest recommendation of
the matching stage to implement our findings. By simulating attributes with the
co-occurrence matrix, SimEmb discards the item ID-based embedding and employs
the attribute-weighted summation for item embedding enhancement. Comprehensive
experiments on four benchmark datasets demonstrate that our approach notably
enhances the clustering of item embedding and significantly outperforms SOTA
models with an average improvement of 25.59% on Recall@20.|虽然多兴趣推荐系统在匹配阶段已经取得了显著的进展，但是我们的研究发现现有的模型倾向于表现出一种欠聚类的项目嵌入空间，导致项目之间的差异性较低，从而阻碍了项目的检索。这突出了项目嵌入增强的必要性。然而，由于人工注释任务的劳动密集性，在许多公共数据集中，作为有效和直接的增强辅助信息的项属性要么不可用，要么不完整。这个困境提出了两个有意义的问题: 1。我们是否可以绕过手动注释，直接从交互数据模拟完整的属性信息？二。如果可行，如何在匹配阶段模拟高精度、低复杂度的属性？在本文中，我们首先建立了一个鼓舞人心的理论可行性，即项目-属性相关矩阵可以通过项目共现矩阵的初等变换来近似。然后在公式推导的基础上，在匹配阶段的多兴趣推荐中，提出了一个简单而有效的模块——模拟属性项嵌入增强模块(SimEmb) ，以实现我们的研究结果。通过使用共生矩阵模拟属性，SimEmb 放弃了基于项目 ID 的嵌入，采用属性加权和的方法对项目进行嵌入增强。通过对四个基准数据集的综合实验表明，该方法显著提高了项目嵌入的聚类性能，并明显优于 SOTA 模型，在 Recall@20上平均提高了25.59% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attribute+Simulation+for+Item+Embedding+Enhancement+in+Multi-interest+Recommendation)|0|
|[Deep Evolutional Instant Interest Network for CTR Prediction in Trigger-Induced Recommendation](https://doi.org/10.1145/3616855.3635829)|Zhibo Xiao, Luwei Yang, Tao Zhang, Wen Jiang, Wei Ning, Yujiu Yang||The recommendation has been playing a key role in many industries, e.g.,
e-commerce, streaming media, social media, etc. Recently, a new recommendation
scenario, called Trigger-Induced Recommendation (TIR), where users are able to
explicitly express their instant interests via trigger items, is emerging as an
essential role in many e-commerce platforms, e.g., Alibaba.com and Amazon.
Without explicitly modeling the user's instant interest, traditional
recommendation methods usually obtain sub-optimal results in TIR. Even though
there are a few methods considering the trigger and target items simultaneously
to solve this problem, they still haven't taken into account temporal
information of user behaviors, the dynamic change of user instant interest when
the user scrolls down and the interactions between the trigger and target
items. To tackle these problems, we propose a novel method – Deep Evolutional
Instant Interest Network (DEI2N), for click-through rate prediction in TIR
scenarios. Specifically, we design a User Instant Interest Modeling Layer to
predict the dynamic change of the intensity of instant interest when the user
scrolls down. Temporal information is utilized in user behavior modeling.
Moreover, an Interaction Layer is introduced to learn better interactions
between the trigger and target items. We evaluate our method on several offline
and real-world industrial datasets. Experimental results show that our proposed
DEI2N outperforms state-of-the-art baselines. In addition, online A/B testing
demonstrates the superiority over the existing baseline in real-world
production environments.|推荐在许多行业都发挥了重要作用，例如电子商务、流媒体、社交媒体等。最近，一个新的推荐场景，称为触发诱导推荐(TIR) ，用户可以通过触发条目明确表达他们的即时兴趣，正在成为许多电子商务平台，如阿里巴巴和亚马逊的重要角色。传统的推荐方法在没有明确建立用户即时兴趣模型的情况下，往往在 TIR 中得到次优的推荐结果。针对这一问题，目前虽然有很多方法同时考虑了触发条目和目标条目，但都没有考虑到用户行为的时间信息、用户向下滚动时瞬间兴趣的动态变化以及触发条目和目标条目之间的交互作用。为了解决这些问题，我们提出了一种新的方法-深度进化即时兴趣网络(DEI2N) ，用于 TIR 场景中的点进率预测。具体来说，我们设计了一个用户即时兴趣建模层来预测用户向下滚动时即时兴趣强度的动态变化。时态信息用于用户行为建模。此外，还引入了交互层来学习触发器和目标项之间更好的交互。我们评估我们的方法在几个离线和现实世界的工业数据集。实验结果表明，我们提出的 DEI2N 性能优于最先进的基线。此外，在线 A/B 测试证明了在现实生产环境中优于现有基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Evolutional+Instant+Interest+Network+for+CTR+Prediction+in+Trigger-Induced+Recommendation)|0|
|[PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval Models](https://doi.org/10.1145/3616855.3635791)|WeiCheng Chang, JyunYu Jiang, Jiong Zhang, Mutasem AlDarabsah, Choon Hui Teo, ChoJui Hsieh, HsiangFu Yu, S. V. N. Vishwanathan||Embedding-based Retrieval Models (ERMs) have emerged as a promising framework for large-scale text retrieval problems due to powerful large language models. Nevertheless, fine-tuning ERMs to reach state-of-the-art results can be expensive due to the extreme scale of data as well as the complexity of multi-stages pipelines (e.g., pre-training, fine-tuning, distillation). In this work, we propose the PEFA framework, namely ParamEter-Free Adapters, for fast tuning of ERMs without any backward pass in the optimization. At index building stage, PEFA equips the ERM with a non-parametric k-nearest neighbor (kNN) component. At inference stage, PEFA performs a convex combination of two scoring functions, one from the ERM and the other from the kNN. Based on the neighborhood definition, PEFA framework induces two realizations, namely PEFA-XL (i.e., extra large) using double ANN indices and PEFA-XS (i.e., extra small) using a single ANN index. Empirically, PEFA achieves significant improvement on two retrieval applications. For document retrieval, regarding Recall@100 metric, PEFA improves not only pre-trained ERMs on Trivia-QA by an average of 13.2%, but also fine-tuned ERMs on NQ-320K by an average of 5.5%, respectively. For product search, PEFA improves the Recall@100 of the fine-tuned ERMs by an average of 5.3% and 14.5%, for PEFA-XS and PEFA-XL, respectively. Our code is available at https://github.com/ amzn/pecos/tree/mainline/examples/pefa-wsdm24|基于嵌入式的检索模型(ERM)由于其强大的语言模型功能而成为解决大规模文本检索问题的有力工具。然而，由于数据的极端规模以及多阶段管道的复杂性(例如，预训练、微调、精馏) ，为达到最先进的结果而对 ERM 进行微调可能是昂贵的。在这项工作中，我们提出了 PEFA 框架，即参数自由适配器，用于快速调优 ERM，而不需要在优化过程中进行任何反向传递。在索引建立阶段，PEFA 为 ERM 配备了一个非参数 k- 最近邻(kNN)分量。在推理阶段，PEFA 执行两个评分功能的凸组合，一个来自机构风险管理，另一个来自 kNN。在邻域定义的基础上，PEFA 框架引入了两种实现方法，即使用双神经网络指标的 PEFA-XL (即超大)和使用单神经网络指标的 PEFA-XS (即超小)。经验表明，PEFA 在两个检索应用程序上取得了显著的改进。就文献检索而言，在召回@100指标方面，PEFA 不仅平均提高了 Trivia-QA 上预先训练的 ERM 的13.2% ，而且平均提高了 NQ-320k 上的 ERM 的5.5% 。对于产品搜索，对于 PEFA-XS 和 PEFA-XL，PEFA 分别使经过微调的 ERM 的召回率平均提高5.3% 和14.5% 。我们的代码可以在 amzn/pecos/tree/mainline/example/pefa-wsdm24 https://github.com/找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PEFA:+Parameter-Free+Adapters+for+Large-scale+Embedding-based+Retrieval+Models)|0|
|[User Consented Federated Recommender System Against Personalized Attribute Inference Attack](https://doi.org/10.1145/3616855.3635830)|Qi Hu, Yangqiu Song||Recommender systems can be privacy-sensitive. To protect users' private
historical interactions, federated learning has been proposed in distributed
learning for user representations. Using federated recommender (FedRec)
systems, users can train a shared recommendation model on local devices and
prevent raw data transmissions and collections. However, the recommendation
model learned by a common FedRec may still be vulnerable to private information
leakage risks, particularly attribute inference attacks, which means that the
attacker can easily infer users' personal attributes from the learned model.
Additionally, traditional FedRecs seldom consider the diverse privacy
preference of users, leading to difficulties in balancing the recommendation
utility and privacy preservation. Consequently, FedRecs may suffer from
unnecessary recommendation performance loss due to over-protection and private
information leakage simultaneously. In this work, we propose a novel
user-consented federated recommendation system (UC-FedRec) to flexibly satisfy
the different privacy needs of users by paying a minimum recommendation
accuracy price. UC-FedRec allows users to self-define their privacy preferences
to meet various demands and makes recommendations with user consent.
Experiments conducted on different real-world datasets demonstrate that our
framework is more efficient and flexible compared to baselines.|推荐系统可能对隐私敏感。为了保护用户的私有历史交互，联邦学习被提出用于用户表示的分布式学习。使用联邦推荐(FedRec)系统，用户可以在本地设备上培训共享推荐模型，并防止原始数据传输和收集。然而，一个普通的联邦快递推荐模型可能仍然容易受到私人信息泄露的攻击，特别是属性推理攻击，这意味着攻击者可以很容易地从推荐模型中推断出用户的个人属性。此外，传统的 FedRecs 很少考虑用户的不同隐私偏好，导致难以平衡推荐实用程序和隐私保护。因此，由于过度保护和私人信息泄露，美联储可能同时遭受不必要的推荐性能损失。在本研究中，我们提出一个新的使用者同意的联邦推荐系统(UC-FedRec) ，以支付最低的推荐准确度价格，灵活地满足使用者不同的隐私需求。UC-FedRec 允许用户自定义他们的隐私偏好，以满足不同的需求，并在用户同意的情况下提出建议。在不同的实际数据集上进行的实验表明，我们的框架比基线更有效和灵活。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Consented+Federated+Recommender+System+Against+Personalized+Attribute+Inference+Attack)|0|
|[Multi-Intent Attribute-Aware Text Matching in Searching](https://doi.org/10.1145/3616855.3635813)|Mingzhe Li, Xiuying Chen, Jing Xiang, Qishen Zhang, Changsheng Ma, Chenchen Dai, Jinxiong Chang, Zhongyi Liu, Guannan Zhang||Text matching systems have become a fundamental service in most searching
platforms. For instance, they are responsible for matching user queries to
relevant candidate items, or rewriting the user-input query to a pre-selected
high-performing one for a better search experience. In practice, both the
queries and items often contain multiple attributes, such as the category of
the item and the location mentioned in the query, which represent condensed key
information that is helpful for matching. However, most of the existing works
downplay the effectiveness of attributes by integrating them into text
representations as supplementary information. Hence, in this work, we focus on
exploring the relationship between the attributes from two sides. Since
attributes from two ends are often not aligned in terms of number and type, we
propose to exploit the benefit of attributes by multiple-intent modeling. The
intents extracted from attributes summarize the diverse needs of queries and
provide rich content of items, which are more refined and abstract, and can be
aligned for paired inputs. Concretely, we propose a multi-intent
attribute-aware matching model (MIM), which consists of three main components:
attribute-aware encoder, multi-intent modeling, and intent-aware matching. In
the attribute-aware encoder, the text and attributes are weighted and processed
through a scaled attention mechanism with regard to the attributes' importance.
Afterward, the multi-intent modeling extracts intents from two ends and aligns
them. Herein, we come up with a distribution loss to ensure the learned intents
are diverse but concentrated, and a kullback-leibler divergence loss that
aligns the learned intents. Finally, in the intent-aware matching, the intents
are evaluated by a self-supervised masking task, and then incorporated to
output the final matching result.|文本匹配系统已经成为大多数搜索平台的基础服务。例如，它们负责将用户查询与相关候选项匹配，或者将用户输入查询重写为预先选定的高性能查询，以获得更好的搜索体验。实际上，查询和项通常都包含多个属性，例如项的类别和查询中提到的位置，这些属性表示有助于匹配的压缩键信息。然而，现有的大多数作品通过将属性作为补充信息集成到文本表示中来淡化属性的有效性。因此，本文着重从两个方面探讨属性之间的关系。由于来自两端的属性通常在数量和类型方面不一致，我们建议通过多意图建模来利用属性的优势。从属性中提取的意图总结了查询的不同需求，并提供了丰富的项目内容，这些内容更加精炼和抽象，并且可以对成对的输入进行对齐。具体地说，我们提出了一个多意图属性感知匹配模型(MIM) ，它由三个主要部分组成: 属性感知编码器、多意图建模和意图感知匹配。在属性感知编码器中，文本和属性根据属性的重要性通过缩放注意机制进行加权和处理。然后，多意图建模从两端提取意图并对齐它们。在这里，我们提出了一个分布损失，以确保学习意图的多样性，但集中，和一个 kullback-leibler 散度损失，调整了学习意图。最后，在意图感知匹配中，通过自监督掩蔽任务对意图进行评估，然后合并到一起输出最终的匹配结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Intent+Attribute-Aware+Text+Matching+in+Searching)|0|
|[Mixed Attention Network for Cross-domain Sequential Recommendation](https://doi.org/10.1145/3616855.3635801)|Guanyu Lin, Chen Gao, Yu Zheng, Jianxin Chang, Yanan Niu, Yang Song, Kun Gai, Zhiheng Li, Depeng Jin, Yong Li, Meng Wang||In modern recommender systems, sequential recommendation leverages
chronological user behaviors to make effective next-item suggestions, which
suffers from data sparsity issues, especially for new users. One promising line
of work is the cross-domain recommendation, which trains models with data
across multiple domains to improve the performance in data-scarce domains.
Recent proposed cross-domain sequential recommendation models such as PiNet and
DASL have a common drawback relying heavily on overlapped users in different
domains, which limits their usage in practical recommender systems. In this
paper, we propose a Mixed Attention Network (MAN) with local and global
attention modules to extract the domain-specific and cross-domain information.
Firstly, we propose a local/global encoding layer to capture the
domain-specific/cross-domain sequential pattern. Then we propose a mixed
attention layer with item similarity attention, sequence-fusion attention, and
group-prototype attention to capture the local/global item similarity, fuse the
local/global item sequence, and extract the user groups across different
domains, respectively. Finally, we propose a local/global prediction layer to
further evolve and combine the domain-specific and cross-domain interests.
Experimental results on two real-world datasets (each with two domains)
demonstrate the superiority of our proposed model. Further study also
illustrates that our proposed method and components are model-agnostic and
effective, respectively. The code and data are available at
https://github.com/Guanyu-Lin/MAN.|在现代推荐系统中，顺序推荐利用按时间顺序排列的用户行为来提出有效的下一项推荐，这种推荐存在数据稀疏问题，尤其是对于新用户。一个很有前途的工作领域是跨域推荐，它用跨多个域的数据来训练模型，以提高数据稀缺域的性能。最近提出的跨域顺序推荐模型，如 PiNet 和 DASL，有一个共同的缺点，即严重依赖于不同领域的重叠用户，这限制了它们在实际推荐系统中的使用。本文提出了一种基于局部和全局注意模块的混合注意网络(MAN)来提取特定领域和跨领域的信息。首先，我们提出了一个局部/全局编码层来捕获域特定/跨域的序列模式。然后提出了一个具有项目相似性注意、序列融合注意和群体原型注意的混合注意层，分别捕获局部/全局项目相似性，融合局部/全局项目序列，提取不同领域的用户群。最后，我们提出了一个局部/全局预测层，以进一步发展和结合特定领域和跨领域的利益。在两个实际数据集上的实验结果表明了该模型的优越性。进一步的研究还表明，我们提出的方法和组件是模型无关的和有效的，分别。代码和数据可在 https://github.com/guanyu-lin/man 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mixed+Attention+Network+for+Cross-domain+Sequential+Recommendation)|0|
|[Multi-Sequence Attentive User Representation Learning for Side-information Integrated Sequential Recommendation](https://doi.org/10.1145/3616855.3635815)|Xiaolin Lin, Jinwei Luo, Junwei Pan, Weike Pan, Zhong Ming, Xun Liu, Shudong Huang, Jie Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Sequence+Attentive+User+Representation+Learning+for+Side-information+Integrated+Sequential+Recommendation)|0|
|[Intent Contrastive Learning with Cross Subsequences for Sequential Recommendation](https://doi.org/10.1145/3616855.3635773)|Xiuyuan Qin, Huanhuan Yuan, Pengpeng Zhao, Guanfeng Liu, Fuzhen Zhuang, Victor S. Sheng||The user purchase behaviors are mainly influenced by their intentions (e.g., buying clothes for decoration, buying brushes for painting, etc.). Modeling a user's latent intention can significantly improve the performance of recommendations. Previous works model users' intentions by considering the predefined label in auxiliary information or introducing stochastic data augmentation to learn purposes in the latent space. However, the auxiliary information is sparse and not always available for recommender systems, and introducing stochastic data augmentation may introduce noise and thus change the intentions hidden in the sequence. Therefore, leveraging user intentions for sequential recommendation (SR) can be challenging because they are frequently varied and unobserved. In this paper, Intent contrastive learning with Cross Subsequences for sequential Recommendation (ICSRec) is proposed to model users' latent intentions. Specifically, ICSRec first segments a user's sequential behaviors into multiple subsequences by using a dynamic sliding operation and takes these subsequences into the encoder to generate the representations for the user's intentions. To tackle the problem of no explicit labels for purposes, ICSRec assumes different subsequences with the same target item may represent the same intention and proposes a coarse-grain intent contrastive learning to push these subsequences closer. Then, fine-grain intent contrastive learning is mentioned to capture the fine-grain intentions of subsequences in sequential behaviors. Extensive experiments conducted on four real-world datasets demonstrate the superior performance of the proposed ICSRec model compared with baseline methods.|用户的购买行为主要受其购买意图的影响(如购买衣服装饰、购买画笔等)。对用户的潜在意图进行建模可以显著提高推荐的性能。以往的研究通过考虑辅助信息中的预定义标签或引入随机数据增量在潜在空间中学习目的来模拟用户的意图。然而，辅助信息是稀疏的，并不总是可用于推荐系统，引入随机数据增强可能会引入噪声，从而改变意图隐藏在序列。因此，利用用户意图进行顺序推荐(SR)可能是具有挑战性的，因为它们经常变化和未被观察到。本文提出了一种基于交叉子序列的序列推荐意图对比学习(ICSRec)方法来模拟用户的潜在意图。具体来说，ICSRec 首先使用动态滑动操作将用户的连续行为分割成多个子序列，并将这些子序列带入编码器以生成用户意图的表示。为了解决目的不明确标签的问题，ICSRec 假设具有相同目标项的不同子序列可以表示相同的意图，并提出了一种粗粒度意图对比学习方法来使这些子序列更加接近。然后，提出细粒度意图对比学习来捕捉序列行为中子序列的细粒度意图。在四个实际数据集上进行的大量实验表明，与基线方法相比，所提出的 ICSRec 模型具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intent+Contrastive+Learning+with+Cross+Subsequences+for+Sequential+Recommendation)|0|
|[Debiasing Sequential Recommenders through Distributionally Robust Optimization over System Exposure](https://doi.org/10.1145/3616855.3635848)|Jiyuan Yang, Yue Ding, Yidan Wang, Pengjie Ren, Zhumin Chen, Fei Cai, Jun Ma, Rui Zhang, Zhaochun Ren, Xin Xin||Sequential recommendation (SR) models are typically trained on user-item
interactions which are affected by the system exposure bias, leading to the
user preference learned from the biased SR model not being fully consistent
with the true user preference. Exposure bias refers to the fact that user
interactions are dependent upon the partial items exposed to the user. Existing
debiasing methods do not make full use of the system exposure data and suffer
from sub-optimal recommendation performance and high variance. In this paper,
we propose to debias sequential recommenders through Distributionally Robust
Optimization (DRO) over system exposure data. The key idea is to utilize DRO to
optimize the worst-case error over an uncertainty set to safeguard the model
against distributional discrepancy caused by the exposure bias. The main
challenge to apply DRO for exposure debiasing in SR lies in how to construct
the uncertainty set and avoid the overestimation of user preference on biased
samples. Moreover, how to evaluate the debiasing effect on biased test set is
also an open question. To this end, we first introduce an exposure simulator
trained upon the system exposure data to calculate the exposure distribution,
which is then regarded as the nominal distribution to construct the uncertainty
set of DRO. Then, we introduce a penalty to items with high exposure
probability to avoid the overestimation of user preference for biased samples.
Finally, we design a debiased self-normalized inverse propensity score (SNIPS)
evaluator for evaluating the debiasing effect on the biased offline test set.
We conduct extensive experiments on two real-world datasets to verify the
effectiveness of the proposed methods. Experimental results demonstrate the
superior exposure debiasing performance of proposed methods. Codes and data are
available at \url{https://github.com/nancheng58/DebiasedSR_DRO}.|序贯推荐(SR)模型通常针对受系统暴露偏差影响的用户-项目交互进行训练，导致从偏向 SR 模型中学到的用户偏好与真实用户偏好不完全一致。暴露偏差是指用户交互依赖于暴露给用户的部分项目这一事实。现有的去偏方法没有充分利用系统曝光数据，推荐性能不理想，方差较大。本文提出了一种基于系统曝光数据的分布式鲁棒优化(DRO)方法来降低序列推荐器的偏差。其核心思想是利用 DRO 对不确定集上的最坏情况误差进行优化，以保护模型不受曝光偏差引起的分布差异的影响。如何构造不确定性集合，避免偏差样本对用户偏好的过高估计，是应用 DRO 进行 SR 曝光消偏的主要挑战。此外，如何评价偏置测试集的去偏效果也是一个悬而未决的问题。为此，我们首先介绍了一个基于系统曝光数据训练的曝光模拟器来计算曝光分布，然后将其视为标称分布来构造 DRO 的不确定度集。然后，我们引入了一个惩罚项目的高暴露概率，以避免过高估计的用户偏好偏差样本。最后，我们设计了一个去偏的自标准化逆倾向得分(SNIPS)评估器来评估有偏离离线测试集的去偏效果。为了验证该方法的有效性，我们在两个实际数据集上进行了大量的实验。实验结果表明，该方法具有较好的曝光消偏性能。代码和数据可在 url { https://github.com/nancheng58/debiasedsr_dro }获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiasing+Sequential+Recommenders+through+Distributionally+Robust+Optimization+over+System+Exposure)|0|
|[Applications of LLMs in E-Commerce Search and Product Knowledge Graph: The DoorDash Case Study](https://doi.org/10.1145/3616855.3635738)|Sudeep Das, Raghav Saboo, Chaitanya S. K. Vadrevu, Bruce Wang, Steven Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Applications+of+LLMs+in+E-Commerce+Search+and+Product+Knowledge+Graph:+The+DoorDash+Case+Study)|0|
|[AAGenRec: A Novel Approach for Mitigating Inter-task Interference in Multi-task Optimization of Sequential Behavior Modeling](https://doi.org/10.1145/3616855.3635746)|Jiawei Zhang, Shimin Yang, Liang Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AAGenRec:+A+Novel+Approach+for+Mitigating+Inter-task+Interference+in+Multi-task+Optimization+of+Sequential+Behavior+Modeling)|0|
|[To Copy, or not to Copy; That is a Critical Issue of the Output Softmax Layer in Neural Sequential Recommenders](https://doi.org/10.1145/3616855.3635755)|HawShiuan Chang, Nikhil Agarwal, Andrew McCallum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=To+Copy,+or+not+to+Copy;+That+is+a+Critical+Issue+of+the+Output+Softmax+Layer+in+Neural+Sequential+Recommenders)|0|
|[Budgeted Embedding Table For Recommender Systems](https://doi.org/10.1145/3616855.3635778)|Yunke Qu, Tong Chen, Quoc Viet Hung Nguyen, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Budgeted+Embedding+Table+For+Recommender+Systems)|0|
|[AutoPooling: Automated Pooling Search for Multi-valued Features in Recommendations](https://doi.org/10.1145/3616855.3635808)|He Wei, Yuekui Yang, Shaoping Ma, Haiyang Wu, Yangyang Tang, Meixi Liu, Yang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoPooling:+Automated+Pooling+Search+for+Multi-valued+Features+in+Recommendations)|0|
|[Linear Recurrent Units for Sequential Recommendation](https://doi.org/10.1145/3616855.3635760)|Zhenrui Yue, Yueqi Wang, Zhankui He, Huimin Zeng, Julian J. McAuley, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Linear+Recurrent+Units+for+Sequential+Recommendation)|0|
|[CharmBana: Progressive Responses with Real-Time Internet Search for Knowledge-Powered Conversations](https://doi.org/10.1145/3616855.3635702)|Revanth Gangi Reddy, Sharath Chandra Etagi Suresh, Hao Bai, Wentao Yao, Mankeerat Sidhu, Karan Aggarwal, Prathamesh Sonawane, ChengXiang Zhai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CharmBana:+Progressive+Responses+with+Real-Time+Internet+Search+for+Knowledge-Powered+Conversations)|0|
|[SIRUP: Search-based Book Recommendation Playground](https://doi.org/10.1145/3616855.3635692)|Ghazaleh Haratinezhad Torbati, Anna Tigunova, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SIRUP:+Search-based+Book+Recommendation+Playground)|0|
|[Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs](https://doi.org/10.1145/3616855.3635689)|Behnam Rahdari, Hao Ding, Ziwei Fan, Yifei Ma, Zhuotong Chen, Anoop Deoras, Branislav Kveton||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logic-Scaffolding:+Personalized+Aspect-Instructed+Recommendation+Explanation+Generation+using+LLMs)|0|
|[Effective and Efficient Transformer Models for Sequential Recommendation](https://doi.org/10.1145/3616855.3635733)|Aleksandr V. Petrov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+and+Efficient+Transformer+Models+for+Sequential+Recommendation)|0|
|[CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process](https://doi.org/10.1145/3616855.3635794)|Xiaodong Li, Jiawei Sheng, Jiangxia Cao, Wenyuan Zhang, Quangang Li, Tingwen Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CDRNP:+Cross-Domain+Recommendation+to+Cold-Start+Users+via+Neural+Process)|0|
|[Calibration-compatible Listwise Distillation of Privileged Features for CTR Prediction](https://doi.org/10.1145/3616855.3635810)|Xiaoqiang Gui, Yueyao Cheng, XiangRong Sheng, Yunfeng Zhao, Guoxian Yu, Shuguang Han, Yuning Jiang, Jian Xu, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibration-compatible+Listwise+Distillation+of+Privileged+Features+for+CTR+Prediction)|0|
|[Ranking with Long-Term Constraints](https://doi.org/10.1145/3616855.3635819)|Kianté Brantley, Zhichong Fang, Sarah Dean, Thorsten Joachims||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ranking+with+Long-Term+Constraints)|0|
|[Exploring Adapter-based Transfer Learning for Recommender Systems: Empirical Studies and Practical Insights](https://doi.org/10.1145/3616855.3635805)|Junchen Fu, Fajie Yuan, Yu Song, Zheng Yuan, Mingyue Cheng, Shenghui Cheng, Jiaqi Zhang, Jie Wang, Yunzhu Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Adapter-based+Transfer+Learning+for+Recommender+Systems:+Empirical+Studies+and+Practical+Insights)|0|
|[PEACE: Prototype lEarning Augmented transferable framework for Cross-domain rEcommendation](https://doi.org/10.1145/3616855.3635781)|Chunjing Gan, Bo Huang, Binbin Hu, Jian Ma, Zhiqiang Zhang, Jun Zhou, Guannan Zhang, Wenliang Zhong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PEACE:+Prototype+lEarning+Augmented+transferable+framework+for+Cross-domain+rEcommendation)|0|
|[Motif-based Prompt Learning for Universal Cross-domain Recommendation](https://doi.org/10.1145/3616855.3635754)|Bowen Hao, Chaoqun Yang, Lei Guo, Junliang Yu, Hongzhi Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Motif-based+Prompt+Learning+for+Universal+Cross-domain+Recommendation)|0|
|[C²DR: Robust Cross-Domain Recommendation based on Causal Disentanglement](https://doi.org/10.1145/3616855.3635809)|Menglin Kong, Jia Wang, Yushan Pan, Haiyang Zhang, Muzhou Hou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=C²DR:+Robust+Cross-Domain+Recommendation+based+on+Causal+Disentanglement)|0|
|[Inverse Learning with Extremely Sparse Feedback for Recommendation](https://doi.org/10.1145/3616855.3635797)|Guanyu Lin, Chen Gao, Yu Zheng, Yinfeng Li, Jianxin Chang, Yanan Niu, Yang Song, Kun Gai, Zhiheng Li, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inverse+Learning+with+Extremely+Sparse+Feedback+for+Recommendation)|0|
|[Pre-trained Recommender Systems: A Causal Debiasing Perspective](https://doi.org/10.1145/3616855.3635779)|Ziqian Lin, Hao Ding, Trong Nghia Hoang, Branislav Kveton, Anoop Deoras, Hao Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-trained+Recommender+Systems:+A+Causal+Debiasing+Perspective)|0|
|[Interact with the Explanations: Causal Debiased Explainable Recommendation System](https://doi.org/10.1145/3616855.3635855)|Xu Liu, Tong Yu, Kaige Xie, Junda Wu, Shuai Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interact+with+the+Explanations:+Causal+Debiased+Explainable+Recommendation+System)|0|
|[Proxy-based Item Representation for Attribute and Context-aware Recommendation](https://doi.org/10.1145/3616855.3635824)|Jinseok Seol, Minseok Gang, Sanggoo Lee, Jaehui Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proxy-based+Item+Representation+for+Attribute+and+Context-aware+Recommendation)|0|
|[LEAD: Liberal Feature-based Distillation for Dense Retrieval](https://doi.org/10.1145/3616855.3635774)|Hao Sun, Xiao Liu, Yeyun Gong, Anlei Dong, Jingwen Lu, Yan Zhang, Linjun Yang, Rangan Majumder, Nan Duan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEAD:+Liberal+Feature-based+Distillation+for+Dense+Retrieval)|0|
|[Not All Negatives Are Worth Attending to: Meta-Bootstrapping Negative Sampling Framework for Link Prediction](https://doi.org/10.1145/3616855.3635840)|Yakun Wang, Binbin Hu, Shuo Yang, Meiqi Zhu, Zhiqiang Zhang, Qiyang Zhang, Jun Zhou, Guo Ye, Huimei He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Negatives+Are+Worth+Attending+to:+Meta-Bootstrapping+Negative+Sampling+Framework+for+Link+Prediction)|0|
|[Diff-MSR: A Diffusion Model Enhanced Paradigm for Cold-Start Multi-Scenario Recommendation](https://doi.org/10.1145/3616855.3635807)|Yuhao Wang, Ziru Liu, Yichao Wang, Xiangyu Zhao, Bo Chen, Huifeng Guo, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diff-MSR:+A+Diffusion+Model+Enhanced+Paradigm+for+Cold-Start+Multi-Scenario+Recommendation)|0|
|[On the Effectiveness of Unlearning in Session-Based Recommendation](https://doi.org/10.1145/3616855.3635823)|Xin Xin, Liu Yang, Ziqi Zhao, Pengjie Ren, Zhumin Chen, Jun Ma, Zhaochun Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Effectiveness+of+Unlearning+in+Session-Based+Recommendation)|0|
|[IAI MovieBot 2.0: An Enhanced Research Platform with Trainable Neural Components and Transparent User Modeling](https://doi.org/10.1145/3616855.3635699)|Nolwenn Bernard, Ivica Kostric, Krisztian Balog||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IAI+MovieBot+2.0:+An+Enhanced+Research+Platform+with+Trainable+Neural+Components+and+Transparent+User+Modeling)|0|
|[Domain Level Interpretability: Interpreting Black-box Model with Domain-specific Embedding](https://doi.org/10.1145/3616855.3635688)|YaLin Zhang, Caizhi Tang, Lu Yu, Jun Zhou, Longfei Li, Qing Cui, Fangfang Fan, Linbo Jiang, Xiaosong Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain+Level+Interpretability:+Interpreting+Black-box+Model+with+Domain-specific+Embedding)|0|
|[Unbiased Learning to Rank: On Recent Advances and Practical Applications](https://doi.org/10.1145/3616855.3636451)|Shashank Gupta, Philipp Hager, Jin Huang, Ali Vardasbi, Harrie Oosterhuis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unbiased+Learning+to+Rank:+On+Recent+Advances+and+Practical+Applications)|0|
|[Leveraging User Simulation to Develop and Evaluate Conversational Information Access Agents](https://doi.org/10.1145/3616855.3635730)|Nolwenn Bernard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+User+Simulation+to+Develop+and+Evaluate+Conversational+Information+Access+Agents)|0|
|[Delphic Costs and Benefits in Web Search: A Utilitarian and Historical Analysis](https://doi.org/10.1145/3616855.3638208)|Andrei Z. Broder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Delphic+Costs+and+Benefits+in+Web+Search:+A+Utilitarian+and+Historical+Analysis)|0|
|[The Journey to A Knowledgeable Assistant with Retrieval-Augmented Generation (RAG)](https://doi.org/10.1145/3616855.3638207)|Xin Luna Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Journey+to+A+Knowledgeable+Assistant+with+Retrieval-Augmented+Generation+(RAG))|0|
|[LabelCraft: Empowering Short Video Recommendations with Automated Label Crafting](https://doi.org/10.1145/3616855.3635816)|Yimeng Bai, Yang Zhang, Jing Lu, Jianxin Chang, Xiaoxue Zang, Yanan Niu, Yang Song, Fuli Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LabelCraft:+Empowering+Short+Video+Recommendations+with+Automated+Label+Crafting)|0|
|[Towards Mitigating Dimensional Collapse of Representations in Collaborative Filtering](https://doi.org/10.1145/3616855.3635832)|Huiyuan Chen, Vivian Lai, Hongye Jin, Zhimeng Jiang, Mahashweta Das, Xia Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Mitigating+Dimensional+Collapse+of+Representations+in+Collaborative+Filtering)|0|
|[CL4DIV: A Contrastive Learning Framework for Search Result Diversification](https://doi.org/10.1145/3616855.3635851)|Zhirui Deng, Zhicheng Dou, Yutao Zhu, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CL4DIV:+A+Contrastive+Learning+Framework+for+Search+Result+Diversification)|0|
|[From Second to First: Mixed Censored Multi-Task Learning for Winning Price Prediction](https://doi.org/10.1145/3616855.3635838)|Jiani Huang, Zhenzhe Zheng, Yanrong Kang, Zixiao Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Second+to+First:+Mixed+Censored+Multi-Task+Learning+for+Winning+Price+Prediction)|0|
|[DiffKG: Knowledge Graph Diffusion Model for Recommendation](https://doi.org/10.1145/3616855.3635850)|Yangqin Jiang, Yuhao Yang, Lianghao Xia, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiffKG:+Knowledge+Graph+Diffusion+Model+for+Recommendation)|0|
|[Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation](https://doi.org/10.1145/3616855.3635822)|Magdalena Kaiser, Rishiraj Saha Roy, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Training+for+Conversational+Question+Answering+Models+with+Reinforced+Reformulation+Generation)|0|
|[MONET: Modality-Embracing Graph Convolutional Network and Target-Aware Attention for Multimedia Recommendation](https://doi.org/10.1145/3616855.3635817)|Yungi Kim, Taeri Kim, WonYong Shin, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MONET:+Modality-Embracing+Graph+Convolutional+Network+and+Target-Aware+Attention+for+Multimedia+Recommendation)|0|
|[Text-Video Retrieval via Multi-Modal Hypergraph Networks](https://doi.org/10.1145/3616855.3635757)|Qian Li, Lixin Su, Jiashu Zhao, Long Xia, Hengyi Cai, Suqi Cheng, Hengzhu Tang, Junfeng Wang, Dawei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text-Video+Retrieval+via+Multi-Modal+Hypergraph+Networks)|0|
|[MultiFS: Automated Multi-Scenario Feature Selection in Deep Recommender Systems](https://doi.org/10.1145/3616855.3635859)|Dugang Liu, Chaohua Yang, Xing Tang, Yejing Wang, Fuyuan Lyu, Weihong Luo, Xiuqiang He, Zhong Ming, Xiangyu Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiFS:+Automated+Multi-Scenario+Feature+Selection+in+Deep+Recommender+Systems)|0|
|[ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models](https://doi.org/10.1145/3616855.3635845)|Qijiong Liu, Nuo Chen, Tetsuya Sakai, XiaoMing Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ONCE:+Boosting+Content-based+Recommendation+with+Both+Open-+and+Closed-source+Large+Language+Models)|0|
|[Knowledge Graph Context-Enhanced Diversified Recommendation](https://doi.org/10.1145/3616855.3635803)|Xiaolong Liu, Liangwei Yang, Zhiwei Liu, Mingdai Yang, Chen Wang, Hao Peng, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Context-Enhanced+Diversified+Recommendation)|0|
|[SSLRec: A Self-Supervised Learning Framework for Recommendation](https://doi.org/10.1145/3616855.3635814)|Xubin Ren, Lianghao Xia, Yuhao Yang, Wei Wei, Tianle Wang, Xuheng Cai, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SSLRec:+A+Self-Supervised+Learning+Framework+for+Recommendation)|0|
|[Dynamic Sparse Learning: A Novel Paradigm for Efficient Recommendation](https://doi.org/10.1145/3616855.3635780)|Shuyao Wang, Yongduo Sui, Jiancan Wu, Zhi Zheng, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Sparse+Learning:+A+Novel+Paradigm+for+Efficient+Recommendation)|0|
|[Towards Better Chinese Spelling Check for Search Engines: A New Dataset and Strong Baseline](https://doi.org/10.1145/3616855.3635847)|Yue Wang, Zilong Zheng, Zecheng Tang, Juntao Li, Zhihui Liu, Kunlong Chen, Jinxiong Chang, Qishen Zhang, Zhongyi Liu, Min Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Better+Chinese+Spelling+Check+for+Search+Engines:+A+New+Dataset+and+Strong+Baseline)|0|
|[Neural Kalman Filtering for Robust Temporal Recommendation](https://doi.org/10.1145/3616855.3635837)|Jiafeng Xia, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, Li Shang, Ning Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Kalman+Filtering+for+Robust+Temporal+Recommendation)|0|
|[Unified Pretraining for Recommendation via Task Hypergraphs](https://doi.org/10.1145/3616855.3635811)|Mingdai Yang, Zhiwei Liu, Liangwei Yang, Xiaolong Liu, Chen Wang, Hao Peng, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Pretraining+for+Recommendation+via+Task+Hypergraphs)|0|
|[COTER: Conditional Optimal Transport meets Table Retrieval](https://doi.org/10.1145/3616855.3635796)|Xun Yao, Zhixin Zhang, Xinrong Hu, Jie (Jack) Yang, Yi Guo, Daniel (Dianliang) Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COTER:+Conditional+Optimal+Transport+meets+Table+Retrieval)|0|
|[IncMSR: An Incremental Learning Approach for Multi-Scenario Recommendation](https://doi.org/10.1145/3616855.3635828)|Kexin Zhang, Yichao Wang, Xiu Li, Ruiming Tang, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IncMSR:+An+Incremental+Learning+Approach+for+Multi-Scenario+Recommendation)|0|
|[Defense Against Model Extraction Attacks on Recommender Systems](https://doi.org/10.1145/3616855.3635751)|Sixiao Zhang, Hongzhi Yin, Hongxu Chen, Cheng Long||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Defense+Against+Model+Extraction+Attacks+on+Recommender+Systems)|0|
|[GEMRec: Towards Generative Model Recommendation](https://doi.org/10.1145/3616855.3635700)|Yuanhe Guo, Haoming Liu, Hongyi Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GEMRec:+Towards+Generative+Model+Recommendation)|0|
|[Making Small Language Models Better Multi-task Learners with Mixture-of-Task-Adapters](https://doi.org/10.1145/3616855.3635690)|Yukang Xie, Chengyu Wang, Junbing Yan, Jiyong Zhou, Feiqi Deng, Jun Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Making+Small+Language+Models+Better+Multi-task+Learners+with+Mixture-of-Task-Adapters)|0|
|[Grounded and Transparent Response Generation for Conversational Information-Seeking Systems](https://doi.org/10.1145/3616855.3635727)|Weronika Lajewska||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Grounded+and+Transparent+Response+Generation+for+Conversational+Information-Seeking+Systems)|0|
|[Augmenting Keyword-based Search in Mobile Applications Using LLMs](https://doi.org/10.1145/3616855.3635745)|Harikrishnan C, Giridhar Sreenivasa Murthy, Kumar Rangarajan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Augmenting+Keyword-based+Search+in+Mobile+Applications+Using+LLMs)|0|
|[Recent Advances in Refinement Recommendations](https://doi.org/10.1145/3616855.3635747)|Akshay Jagatap, Sachin Farfade||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recent+Advances+in+Refinement+Recommendations)|0|
|[Scaling Up LLM Reviews for Google Ads Content Moderation](https://doi.org/10.1145/3616855.3635736)|Wei Qiao, Tushar Dogra, Otilia Stretcu, YuHan Lyu, Tiantian Fang, Dongjin Kwon, ChunTa Lu, Enming Luo, Yuan Wang, ChihChun Chia, Ariel Fuxman, Fangzhou Wang, Ranjay Krishna, Mehmet Tek||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Up+LLM+Reviews+for+Google+Ads+Content+Moderation)|0|
|[Customer Understanding for Recommender Systems](https://doi.org/10.1145/3616855.3635742)|Md. Mostafizur Rahman, Yu Hirate||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Customer+Understanding+for+Recommender+Systems)|0|
|["Maya"- A Conversational Shopping Assistant for Fashion at Myntra](https://doi.org/10.1145/3616855.3635740)|Akhil Raj, Hrishikesh Ganu, Saikat Kumar Das, R. Sandeep, Satyajeet Singh, Sreekanth Vempati||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="Maya"-+A+Conversational+Shopping+Assistant+for+Fashion+at+Myntra)|0|
|[Fresh Content Recommendation at Scale: A Multi-funnel Solution and the Potential of LLMs](https://doi.org/10.1145/3616855.3635749)|Jianling Wang, Haokai Lu, Minmin Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fresh+Content+Recommendation+at+Scale:+A+Multi-funnel+Solution+and+the+Potential+of+LLMs)|0|
|[Lessons Learnt from Building Friend Recommendation Systems](https://doi.org/10.1145/3616855.3635750)|Jun Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lessons+Learnt+from+Building+Friend+Recommendation+Systems)|0|
|[Leveraging Multimodal Features and Item-level User Feedback for Bundle Construction](https://doi.org/10.1145/3616855.3635854)|Yunshan Ma, Xiaohao Liu, Yinwei Wei, Zhulin Tao, Xiang Wang, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Multimodal+Features+and+Item-level+User+Feedback+for+Bundle+Construction)|0|
|[Cost-Effective Active Learning for Bid Exploration in Online Advertising](https://doi.org/10.1145/3616855.3635839)|Zixiao Wang, Zhenzhe Zheng, Yanrong Kang, Jiani Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cost-Effective+Active+Learning+for+Bid+Exploration+in+Online+Advertising)|0|
|[LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection](https://doi.org/10.1145/3616855.3635843)|Zijian Cai, Zhaoxuan Tan, Zhenyu Lei, Zifeng Zhu, Hongrui Wang, Qinghua Zheng, Minnan Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LMBot:+Distilling+Graph+Knowledge+into+Language+Model+for+Graph-less+Deployment+in+Twitter+Bot+Detection)|0|
|[Long-Term Value of Exploration: Measurements, Findings and Algorithms](https://doi.org/10.1145/3616855.3635833)|Yi Su, Xiangyu Wang, Elaine Ya Le, Liang Liu, Yuening Li, Haokai Lu, Benjamin Lipshitz, Sriraj Badam, Lukasz Heldt, Shuchao Bi, Ed H. Chi, Cristos Goodrow, SuLin Wu, Lexi Baugher, Minmin Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long-Term+Value+of+Exploration:+Measurements,+Findings+and+Algorithms)|0|
|[Unified Visual Preference Learning for User Intent Understanding](https://doi.org/10.1145/3616855.3635858)|Yihua Wen, Si Chen, Yu Tian, Wanxian Guan, Pengjie Wang, Hongbo Deng, Jian Xu, Bo Zheng, Zihao Li, Lixin Zou, Chenliang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Visual+Preference+Learning+for+User+Intent+Understanding)|0|
|[Framework for Bias Detection in Machine Learning Models: A Fairness Approach](https://doi.org/10.1145/3616855.3635731)|Alveiro Alonso Rosado Gomez, Maritza Liliana CalderónBenavides||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Framework+for+Bias+Detection+in+Machine+Learning+Models:+A+Fairness+Approach)|0|
|[IDoFew: Intermediate Training Using Dual-Clustering in Language Models for Few Labels Text Classification](https://doi.org/10.1145/3616855.3635849)|Abdullah Alsuhaibani, Hamad Zogan, Imran Razzak, Shoaib Jameel, Guandong Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IDoFew:+Intermediate+Training+Using+Dual-Clustering+in+Language+Models+for+Few+Labels+Text+Classification)|0|
|[MAD: Multi-Scale Anomaly Detection in Link Streams](https://doi.org/10.1145/3616855.3635834)|Esteban Bautista, Laurent Brisson, Cécile Bothorel, Grégory Smits||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAD:+Multi-Scale+Anomaly+Detection+in+Link+Streams)|0|
|[Customized and Robust Deep Neural Network Watermarking](https://doi.org/10.1145/3616855.3635812)|TzuYun Chien, ChihYa Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Customized+and+Robust+Deep+Neural+Network+Watermarking)|0|
|[Incomplete Graph Learning via Attribute-Structure Decoupled Variational Auto-Encoder](https://doi.org/10.1145/3616855.3635769)|Xinke Jiang, Zidi Qin, Jiarong Xu, Xiang Ao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incomplete+Graph+Learning+via+Attribute-Structure+Decoupled+Variational+Auto-Encoder)|0|
|[Source Free Graph Unsupervised Domain Adaptation](https://doi.org/10.1145/3616855.3635802)|Haitao Mao, Lun Du, Yujia Zheng, Qiang Fu, Zelin Li, Xu Chen, Shi Han, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Source+Free+Graph+Unsupervised+Domain+Adaptation)|0|
|[PhoGAD: Graph-based Anomaly Behavior Detection with Persistent Homology Optimization](https://doi.org/10.1145/3616855.3635783)|Ziqi Yuan, Haoyi Zhou, Tianyu Chen, Jianxin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PhoGAD:+Graph-based+Anomaly+Behavior+Detection+with+Persistent+Homology+Optimization)|0|
|[The Devil is in the Data: Learning Fair Graph Neural Networks via Partial Knowledge Distillation](https://doi.org/10.1145/3616855.3635768)|Yuchang Zhu, Jintang Li, Liang Chen, Zibin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Devil+is+in+the+Data:+Learning+Fair+Graph+Neural+Networks+via+Partial+Knowledge+Distillation)|0|
|[Dance with Labels: Dual-Heterogeneous Label Graph Interaction for Multi-intent Spoken Language Understanding](https://doi.org/10.1145/3616855.3635782)|Zhihong Zhu, Xuxin Cheng, Hongxiang Li, Yaowei Li, Yuexian Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dance+with+Labels:+Dual-Heterogeneous+Label+Graph+Interaction+for+Multi-intent+Spoken+Language+Understanding)|0|
|[Wildfire: A Twitter Social Sensing Platform for Layperson](https://doi.org/10.1145/3616855.3635704)|Zeyu Zhang, Zhengyuan Zhu, Haiqi Zhang, Foram Patel, Josue Caraballo, Patrick Hennecke, Chengkai Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wildfire:+A+Twitter+Social+Sensing+Platform+for+Layperson)|0|
|[Bridging Text Data and Graph Data: Towards Semantics and Structure-aware Knowledge Discovery](https://doi.org/10.1145/3616855.3636450)|Bowen Jin, Yu Zhang, Sha Li, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Text+Data+and+Graph+Data:+Towards+Semantics+and+Structure-aware+Knowledge+Discovery)|0|
|[Practical Bandits: An Industry Perspective](https://doi.org/10.1145/3616855.3636449)|Bram van den Akker, Olivier Jeunen, Ying Li, Ben London, Zahra Nazari, Devesh Parekh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Bandits:+An+Industry+Perspective)|0|
|[Automated Tailoring of Large Language Models for Industry-Specific Downstream Tasks](https://doi.org/10.1145/3616855.3635743)|Shreya Saxena, Siva Prasad, Muneeswaran I, Advaith Shankar, Varun V, Saisubramaniam Gopalakrishnan, Vishal Vaddina||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Tailoring+of+Large+Language+Models+for+Industry-Specific+Downstream+Tasks)|0|
|[Unlocking Human Curiosity](https://doi.org/10.1145/3616855.3637631)|Elizabeth Reid||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+Human+Curiosity)|0|
|[Unveiling AI-Driven Collective Action for a Worker-Centric Future](https://doi.org/10.1145/3616855.3637633)|Saiph Savage||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+AI-Driven+Collective+Action+for+a+Worker-Centric+Future)|0|
|[What I Learned from Spending a Dozen Years in the Dark Web](https://doi.org/10.1145/3616855.3637632)|Nicolas Christin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+I+Learned+from+Spending+a+Dozen+Years+in+the+Dark+Web)|0|
|[Professional Network Matters: Connections Empower Person-Job Fit](https://doi.org/10.1145/3616855.3635852)|Hao Chen, Lun Du, Yuxuan Lu, Qiang Fu, Xu Chen, Shi Han, Yanbin Kang, Guangming Lu, Zi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Professional+Network+Matters:+Connections+Empower+Person-Job+Fit)|0|
|[Empathetic Response Generation with Relation-aware Commonsense Knowledge](https://doi.org/10.1145/3616855.3635836)|Changyu Chen, Yanran Li, Chen Wei, Jianwei Cui, Bin Wang, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empathetic+Response+Generation+with+Relation-aware+Commonsense+Knowledge)|0|
|[Exploiting Duality in Open Information Extraction with Predicate Prompt](https://doi.org/10.1145/3616855.3635799)|Zhen Chen, Jingping Liu, Deqing Yang, Yanghua Xiao, Huimin Xu, Zongyu Wang, Rui Xie, Yunsen Xian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Duality+in+Open+Information+Extraction+with+Predicate+Prompt)|0|
|[Overlapping and Robust Edge-Colored Clustering in Hypergraphs](https://doi.org/10.1145/3616855.3635792)|Alex Crane, Brian Lavallee, Blair D. Sullivan, Nate Veldt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Overlapping+and+Robust+Edge-Colored+Clustering+in+Hypergraphs)|0|
|[TemporalMed: Advancing Medical Dialogues with Time-Aware Responses in Large Language Models](https://doi.org/10.1145/3616855.3635860)|Yuyan Chen, Jin Zhao, Zhihao Wen, Zhixu Li, Yanghua Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TemporalMed:+Advancing+Medical+Dialogues+with+Time-Aware+Responses+in+Large+Language+Models)|0|
|[CroSSL: Cross-modal Self-Supervised Learning for Time-series through Latent Masking](https://doi.org/10.1145/3616855.3635795)|Shohreh Deldari, Dimitris Spathis, Mohammad Malekzadeh, Fahim Kawsar, Flora D. Salim, Akhil Mathur||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CroSSL:+Cross-modal+Self-Supervised+Learning+for+Time-series+through+Latent+Masking)|0|
|[Guardian: Guarding against Gradient Leakage with Provable Defense for Federated Learning](https://doi.org/10.1145/3616855.3635758)|Mingyuan Fan, Yang Liu, Cen Chen, Chengyu Wang, Minghui Qiu, Wenmeng Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Guardian:+Guarding+against+Gradient+Leakage+with+Provable+Defense+for+Federated+Learning)|0|
|[TTC-QuAli: A Text-Table-Chart Dataset for Multimodal Quantity Alignment](https://doi.org/10.1145/3616855.3635777)|Haoyu Dong, Haochen Wang, Anda Zhou, Yue Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TTC-QuAli:+A+Text-Table-Chart+Dataset+for+Multimodal+Quantity+Alignment)|0|
|[DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting](https://doi.org/10.1145/3616855.3635788)|Tianyu Fu, Chiyue Wei, Yu Wang, Rex Ying||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeSCo:+Towards+Generalizable+and+Scalable+Deep+Subgraph+Counting)|0|
|[CausalMMM: Learning Causal Structure for Marketing Mix Modeling](https://doi.org/10.1145/3616855.3635766)|Chang Gong, Di Yao, Lei Zhang, Sheng Chen, Wenbin Li, Yueyang Su, Jingping Bi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CausalMMM:+Learning+Causal+Structure+for+Marketing+Mix+Modeling)|0|
|[SCAD: Subspace Clustering based Adversarial Detector](https://doi.org/10.1145/3616855.3635835)|Xinrong Hu, Wushuan Chen, Jie Yang, Yi Guo, Xun Yao, Bangchao Wang, Junping Liu, Ce Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SCAD:+Subspace+Clustering+based+Adversarial+Detector)|0|
|[Capturing Temporal Node Evolution via Self-supervised Learning: A New Perspective on Dynamic Graph Learning](https://doi.org/10.1145/3616855.3635765)|Lingwen Liu, Guangqi Wen, Peng Cao, Jinzhu Yang, Weiping Li, Osmar R. Zaïane||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Capturing+Temporal+Node+Evolution+via+Self-supervised+Learning:+A+New+Perspective+on+Dynamic+Graph+Learning)|0|
|[Generative Models for Complex Logical Reasoning over Knowledge Graphs](https://doi.org/10.1145/3616855.3635804)|Yu Liu, Yanan Cao, Shi Wang, Qingyue Wang, Guanqun Bi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Models+for+Complex+Logical+Reasoning+over+Knowledge+Graphs)|0|
|[A Linguistic Grounding-Infused Contrastive Learning Approach for Health Mention Classification on Social Media](https://doi.org/10.1145/3616855.3635763)|Usman Naseem, Jinman Kim, Matloob Khushi, Adam G. Dunn||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Linguistic+Grounding-Infused+Contrastive+Learning+Approach+for+Health+Mention+Classification+on+Social+Media)|0|
|[GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction](https://doi.org/10.1145/3616855.3635767)|Amit Roy, Juan Shu, Jia Li, Carl Yang, Olivier Elshocht, Jeroen Smeets, Pan Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAD-NR:+Graph+Anomaly+Detection+via+Neighborhood+Reconstruction)|0|
|[Ad-load Balancing via Off-policy Learning in a Content Marketplace](https://doi.org/10.1145/3616855.3635846)|Hitesh Sagtani, Madan Gopal Jhawar, Rishabh Mehrotra, Olivier Jeunen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ad-load+Balancing+via+Off-policy+Learning+in+a+Content+Marketplace)|0|
|[ProGAP: Progressive Graph Neural Networks with Differential Privacy Guarantees](https://doi.org/10.1145/3616855.3635761)|Sina Sajadmanesh, Daniel GaticaPerez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ProGAP:+Progressive+Graph+Neural+Networks+with+Differential+Privacy+Guarantees)|0|
|[Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling](https://doi.org/10.1145/3616855.3635825)|Marija Sakota, Maxime Peyrard, Robert West||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fly-Swat+or+Cannon?+Cost-Effective+Language+Model+Choice+via+Meta-Modeling)|0|
|[Causality Guided Disentanglement for Cross-Platform Hate Speech Detection](https://doi.org/10.1145/3616855.3635771)|Paras Sheth, Raha Moraffah, Tharindu S. Kumarage, Aman Chadha, Huan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality+Guided+Disentanglement+for+Cross-Platform+Hate+Speech+Detection)|0|
|[Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study](https://doi.org/10.1145/3616855.3635752)|Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Table+Meets+LLM:+Can+Large+Language+Models+Understand+Structured+Table+Data?+A+Benchmark+and+Empirical+Study)|0|
|[Rethinking and Simplifying Bootstrapped Graph Latents](https://doi.org/10.1145/3616855.3635842)|Wangbin Sun, Jintang Li, Liang Chen, Bingzhe Wu, Yatao Bian, Zibin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+and+Simplifying+Bootstrapped+Graph+Latents)|0|
|[Temporal Blind Spots in Large Language Models](https://doi.org/10.1145/3616855.3635818)|Jonas Wallat, Adam Jatowt, Avishek Anand||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Blind+Spots+in+Large+Language+Models)|0|
|[Efficient, Direct, and Restricted Black-Box Graph Evasion Attacks to Any-Layer Graph Neural Networks via Influence Function](https://doi.org/10.1145/3616855.3635826)|Binghui Wang, Minhua Lin, Tianxiang Zhou, Pan Zhou, Ang Li, Meng Pang, Hai Helen Li, Yiran Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient,+Direct,+and+Restricted+Black-Box+Graph+Evasion+Attacks+to+Any-Layer+Graph+Neural+Networks+via+Influence+Function)|0|
|[CityCAN: Causal Attention Network for Citywide Spatio-Temporal Forecasting](https://doi.org/10.1145/3616855.3635764)|Chengxin Wang, Yuxuan Liang, Gary Tan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CityCAN:+Causal+Attention+Network+for+Citywide+Spatio-Temporal+Forecasting)|0|
|[Distribution Consistency based Self-Training for Graph Neural Networks with Sparse Labels](https://doi.org/10.1145/3616855.3635793)|Fali Wang, Tianxiang Zhao, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distribution+Consistency+based+Self-Training+for+Graph+Neural+Networks+with+Sparse+Labels)|0|
|[FairIF: Boosting Fairness in Deep Learning via Influence Functions with Validation Set Sensitive Attributes](https://doi.org/10.1145/3616855.3635844)|Haonan Wang, Ziwei Wu, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairIF:+Boosting+Fairness+in+Deep+Learning+via+Influence+Functions+with+Validation+Set+Sensitive+Attributes)|0|
|[NeuralReconciler for Hierarchical Time Series Forecasting](https://doi.org/10.1145/3616855.3635806)|Shiyu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeuralReconciler+for+Hierarchical+Time+Series+Forecasting)|0|
|[Follow the LIBRA: Guiding Fair Policy for Unified Impression Allocation via Adversarial Rewarding](https://doi.org/10.1145/3616855.3635756)|Xiaoyu Wang, Yonghui Guo, Bin Tan, Tao Yang, Dongbo Huang, Lan Xu, Hao Zhou, Xiangyang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Follow+the+LIBRA:+Guiding+Fair+Policy+for+Unified+Impression+Allocation+via+Adversarial+Rewarding)|0|
|[Continuous-time Autoencoders for Regular and Irregular Time Series Imputation](https://doi.org/10.1145/3616855.3635831)|Hyowon Wi, Yehjin Shin, Noseong Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continuous-time+Autoencoders+for+Regular+and+Irregular+Time+Series+Imputation)|0|
|[Hierarchical Multimodal Pre-training for Visually Rich Webpage Understanding](https://doi.org/10.1145/3616855.3635753)|Hongshen Xu, Lu Chen, Zihan Zhao, Da Ma, Ruisheng Cao, Zichen Zhu, Kai Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Multimodal+Pre-training+for+Visually+Rich+Webpage+Understanding)|0|
|[Towards Alignment-Uniformity Aware Representation in Graph Contrastive Learning](https://doi.org/10.1145/3616855.3635789)|Rong Yan, Peng Bao, Xiao Zhang, Zhongyi Liu, Hui Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Alignment-Uniformity+Aware+Representation+in+Graph+Contrastive+Learning)|0|
|[GAP: A Grammar and Position-Aware Framework for Efficient Recognition of Multi-Line Mathematical Formulas](https://doi.org/10.1145/3616855.3635776)|Zhe Yang, Qi Liu, Kai Zhang, Shiwei Tong, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAP:+A+Grammar+and+Position-Aware+Framework+for+Efficient+Recognition+of+Multi-Line+Mathematical+Formulas)|0|
|[Maximizing Malicious Influence in Node Injection Attack](https://doi.org/10.1145/3616855.3635790)|Xiao Zhang, Peng Bao, Shirui Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Maximizing+Malicious+Influence+in+Node+Injection+Attack)|0|
|[Interpretable Imitation Learning with Dynamic Causal Relations](https://doi.org/10.1145/3616855.3635827)|Tianxiang Zhao, Wenchao Yu, Suhang Wang, Lu Wang, Xiang Zhang, Yuncong Chen, Yanchi Liu, Wei Cheng, Haifeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Imitation+Learning+with+Dynamic+Causal+Relations)|0|
|[RDGCN: Reinforced Dependency Graph Convolutional Network for Aspect-based Sentiment Analysis](https://doi.org/10.1145/3616855.3635775)|Xusheng Zhao, Hao Peng, Qiong Dai, Xu Bai, Huailiang Peng, Yanbing Liu, Qinglang Guo, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RDGCN:+Reinforced+Dependency+Graph+Convolutional+Network+for+Aspect-based+Sentiment+Analysis)|0|
|[CreST: A Credible Spatiotemporal Learning Framework for Uncertainty-aware Traffic Forecasting](https://doi.org/10.1145/3616855.3635759)|Zhengyang Zhou, Jiahao Shi, Hongbo Zhang, Qiongyu Chen, Xu Wang, Hongyang Chen, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CreST:+A+Credible+Spatiotemporal+Learning+Framework+for+Uncertainty-aware+Traffic+Forecasting)|0|
|[Pitfalls in Link Prediction with Graph Neural Networks: Understanding the Impact of Target-link Inclusion & Better Practices](https://doi.org/10.1145/3616855.3635786)|Jing Zhu, Yuhang Zhou, Vassilis N. Ioannidis, Shengyi Qian, Wei Ai, Xiang Song, Danai Koutra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pitfalls+in+Link+Prediction+with+Graph+Neural+Networks:+Understanding+the+Impact+of+Target-link+Inclusion+&+Better+Practices)|0|
|[MultiSPANS: A Multi-range Spatial-Temporal Transformer Network for Traffic Forecast via Structural Entropy Optimization](https://doi.org/10.1145/3616855.3635820)|Dongcheng Zou, Senzhang Wang, Xuefeng Li, Hao Peng, Yuandong Wang, Chunyang Liu, Kehua Sheng, Bo Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiSPANS:+A+Multi-range+Spatial-Temporal+Transformer+Network+for+Traffic+Forecast+via+Structural+Entropy+Optimization)|0|
|[WordGraph: A Python Package for Reconstructing Interactive Causal Graphical Models from Text Data](https://doi.org/10.1145/3616855.3635698)|Amine Ferdjaoui, Séverine Affeldt, Mohamed Nadif||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WordGraph:+A+Python+Package+for+Reconstructing+Interactive+Causal+Graphical+Models+from+Text+Data)|0|
|[EvidenceQuest: An Interactive Evidence Discovery System for Explainable Artificial Intelligence](https://doi.org/10.1145/3616855.3635697)|Ambreen Hanif, Amin Beheshti, Xuyun Zhang, Steven Wood, Boualem Benatallah, EuJin Foo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EvidenceQuest:+An+Interactive+Evidence+Discovery+System+for+Explainable+Artificial+Intelligence)|0|
|[Ginkgo-P: General Illustrations of Knowledge Graphs for Openness as a Platform](https://doi.org/10.1145/3616855.3635701)|Blaine Hill, Lihui Liu, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ginkgo-P:+General+Illustrations+of+Knowledge+Graphs+for+Openness+as+a+Platform)|0|
|[Real-time E-bike Route Planning with Battery Range Prediction](https://doi.org/10.1145/3616855.3635696)|Zhao Li, Guoqi Ren, Yongchun Gu, Siwei Zhou, Xuanwu Liu, Jiaming Huang, Ming Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Real-time+E-bike+Route+Planning+with+Battery+Range+Prediction)|0|
|[An Interpretable Brain Graph Contrastive Learning Framework for Brain Disorder Analysis](https://doi.org/10.1145/3616855.3635695)|Xuexiong Luo, Guangwei Dong, Jia Wu, Amin Beheshti, Jian Yang, Shan Xue||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Interpretable+Brain+Graph+Contrastive+Learning+Framework+for+Brain+Disorder+Analysis)|0|
|[Future Timelines: Extraction and Visualization of Future-related Content From News Articles](https://doi.org/10.1145/3616855.3635693)|Juwal Regev, Adam Jatowt, Michael Färber||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Future+Timelines:+Extraction+and+Visualization+of+Future-related+Content+From+News+Articles)|0|
|[Temporal Graph Analysis with TGX](https://doi.org/10.1145/3616855.3635694)|Razieh Shirzadkhani, Shenyang Huang, Elahe Kooshafar, Reihaneh Rabbany, Farimah Poursafaei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Graph+Analysis+with+TGX)|0|
|[A Scalable Open-Source System for Segmenting Urban Areas with Road Networks](https://doi.org/10.1145/3616855.3635703)|Ming Zhang, Yanyan Li, Jianguo Duan, Jizhou Huang, Jingbo Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Scalable+Open-Source+System+for+Segmenting+Urban+Areas+with+Road+Networks)|0|
|[Some Useful Things to Know When Combining IR and NLP: The Easy, the Hard and the Ugly](https://doi.org/10.1145/3616855.3636452)|Omar Alonso, Kenneth Church||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Some+Useful+Things+to+Know+When+Combining+IR+and+NLP:+The+Easy,+the+Hard+and+the+Ugly)|0|
|[Introduction to Responsible AI](https://doi.org/10.1145/3616855.3636455)|Ricardo BaezaYates||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Introduction+to+Responsible+AI)|0|
|[Towards Trustworthy Large Language Models](https://doi.org/10.1145/3616855.3636454)|Sanmi Koyejo, Bo Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Trustworthy+Large+Language+Models)|0|
|[Strategic ML: How to Learn With Data That 'Behaves'](https://doi.org/10.1145/3616855.3636453)|Nir Rosenfeld||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Strategic+ML:+How+to+Learn+With+Data+That+'Behaves')|0|
|[Learning Opinion Dynamics from Data](https://doi.org/10.1145/3616855.3635729)|Jacopo Lenti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Opinion+Dynamics+from+Data)|0|
|[Gaussian Graphical Model-Based Clustering of Time Series Data](https://doi.org/10.1145/3616855.3635728)|Kohei Obata||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gaussian+Graphical+Model-Based+Clustering+of+Time+Series+Data)|0|
|[Using Causal Inference to Solve Uncertainty Issues in Dataset Shift](https://doi.org/10.1145/3616855.3635732)|Song Shuang, Muhammad Syafiq Bin Mohd Pozi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+Causal+Inference+to+Solve+Uncertainty+Issues+in+Dataset+Shift)|0|
|[Multi-Granular Text Classification with Minimal Supervision](https://doi.org/10.1145/3616855.3635735)|Yunyi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granular+Text+Classification+with+Minimal+Supervision)|0|
|[Scaling Use-case Based Shopping using LLMs](https://doi.org/10.1145/3616855.3635748)|Sachin Farfade, Sachin Vernekar, Vineet Chaoji, Rajdeep Mukherjee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Use-case+Based+Shopping+using+LLMs)|0|
|[HealAI: A Healthcare LLM for Effective Medical Documentation](https://doi.org/10.1145/3616855.3635739)|Sagar Goyal, Eti Rastogi, Sree Prasanna Rajagopal, Dong Yuan, Fen Zhao, Jai Chintagunta, Gautam Naik, Jeff Ward||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HealAI:+A+Healthcare+LLM+for+Effective+Medical+Documentation)|0|
|[Mitigating Factual Inconsistency and Hallucination in Large Language Models](https://doi.org/10.1145/3616855.3635744)|Muneeswaran I, Advaith Shankar, Varun V, Saisubramaniam Gopalakrishnan, Vishal Vaddina||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Factual+Inconsistency+and+Hallucination+in+Large+Language+Models)|0|
|[Foundation Models for Aerial Robotics](https://doi.org/10.1145/3616855.3638206)|Ashish Kapoor||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Foundation+Models+for+Aerial+Robotics)|0|
|[Journey of Hallucination-minimized Generative AI Solutions for Financial Decision Makers](https://doi.org/10.1145/3616855.3635737)|Sohini Roychowdhury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Journey+of+Hallucination-minimized+Generative+AI+Solutions+for+Financial+Decision+Makers)|0|
|[Accelerating Pharmacovigilance using Large Language Models](https://doi.org/10.1145/3616855.3635741)|Mukkamala Venkata Sai Prakash, Ganesh Parab, Meghana Veeramalla, Siddartha Reddy, Varun V, Saisubramaniam Gopalakrishnan, Vishal Pagidipally, Vishal Vaddina||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+Pharmacovigilance+using+Large+Language+Models)|0|
|[Automated Topic Generation for the Mexican Platform for Access to Government Public Information During the Period 2003-2020](https://doi.org/10.1145/3616855.3636502)|Hermelando CruzPérez, Alejandro MolinaVillegas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Topic+Generation+for+the+Mexican+Platform+for+Access+to+Government+Public+Information+During+the+Period+2003-2020)|0|
|[Profiling Urban Mobility Patterns with High Spatial and Temporal Resolution: A Deep Dive into Cellphone Geo-position Data](https://doi.org/10.1145/3616855.3636504)|José Ignacio Huertas, Luisa Fernanda Chaparro Sierra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Profiling+Urban+Mobility+Patterns+with+High+Spatial+and+Temporal+Resolution:+A+Deep+Dive+into+Cellphone+Geo-position+Data)|0|
|[Integrating Knowledge Graph Data with Large Language Models for Explainable Inference](https://doi.org/10.1145/3616855.3636507)|Carlos Efrain Quintero Narvaez, Raúl Monroy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Knowledge+Graph+Data+with+Large+Language+Models+for+Explainable+Inference)|0|
|[Genomic-World Fungi Data: Synteny Part](https://doi.org/10.1145/3616855.3636505)|Pedro EscobarTurriza, Luis MuñozMiranda, Alejandro PereiraSantana||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Genomic-World+Fungi+Data:+Synteny+Part)|0|
|[Preserving Heritage: Developing a Translation Tool for Indigenous Dialects](https://doi.org/10.1145/3616855.3637828)|Melissa Robles, Cristian A. Martínez, Juan C. Prieto, Sara Palacios, Rubén Manrique||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preserving+Heritage:+Developing+a+Translation+Tool+for+Indigenous+Dialects)|0|
|[Automatic Extraction of Patterns in Digital News Articles of Femicides occurred in Mexico by Text Mining Techniques](https://doi.org/10.1145/3616855.3636503)|Jonathan ZárateCartas, Alejandro MolinaVillegas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Extraction+of+Patterns+in+Digital+News+Articles+of+Femicides+occurred+in+Mexico+by+Text+Mining+Techniques)|0|
|[Integrity 2024: Integrity in Social Networks and Media](https://doi.org/10.1145/3616855.3635721)|Lluís Garcia Pueyo, Symeon Papadopoulos, Prathyusha Senthil Kumar, Aristides Gionis, Panayiotis Tsaparas, Vasilis Verroios, Giuseppe Manco, Anton Andryeyev, Stefano Cresci, Timos Sellis, Anthony McCosker||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrity+2024:+Integrity+in+Social+Networks+and+Media)|0|
