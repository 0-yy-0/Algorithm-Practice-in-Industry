# WWW2023 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Automated Ontology Evaluation: Evaluating Coverage and Correctness using a Domain Corpus](https://doi.org/10.1145/3543873.3587617)|Antonio Zaitoun, Tomer Sagi, Katja Hose||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Ontology+Evaluation:+Evaluating+Coverage+and+Correctness+using+a+Domain+Corpus)|2|
|[Reinforcement Learning-based Counter-Misinformation Response Generation: A Case Study of COVID-19 Vaccine Misinformation](https://doi.org/10.1145/3543507.3583388)|Bing He, Mustaque Ahamad, Srijan Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Learning-based+Counter-Misinformation+Response+Generation:+A+Case+Study+of+COVID-19+Vaccine+Misinformation)|2|
|[A Concept Knowledge Graph for User Next Intent Prediction at Alipay](https://doi.org/10.1145/3543873.3587308)|Yacheng He, Qianghuai Jia, Lin Yuan, Ruopeng Li, Yixin Ou, Ningyu Zhang|Zhejiang University, China; Ant Group, China|This paper illustrates the technologies of user next intent prediction with a concept knowledge graph. The system has been deployed on the Web at Alipay, serving more than 100 million daily active users. To explicitly characterize user intent, we propose AlipayKG, which is an offline concept knowledge graph in the Life-Service domain modeling the historical behaviors of users, the rich content interacted by users and the relations between them. We further introduce a Transformer-based model which integrates expert rules from the knowledge graph to infer the online user's next intent. Experimental results demonstrate that the proposed system can effectively enhance the performance of the downstream tasks while retaining explainability.|本文用概念知识图说明了用户下一意图预测技术。该系统已经部署在支付宝的网站上，为超过1亿日活跃用户提供服务。为了明确表征用户意图，本文提出了 AlipayKG，它是生活服务领域中的一个离线概念知识图，对用户的历史行为、用户交互的丰富内容以及用户之间的关系进行建模。我们进一步介绍了一个基于 Transformer 的模型，该模型集成了来自知识图的专家规则，以推断在线用户的下一个意图。实验结果表明，该系统能够有效地提高下游任务的性能，同时保持可解释性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Concept+Knowledge+Graph+for+User+Next+Intent+Prediction+at+Alipay)|1|
|[Interaction-level Membership Inference Attack Against Federated Recommender Systems](https://doi.org/10.1145/3543507.3583359)|Wei Yuan, Chaoqun Yang, Quoc Viet Hung Nguyen, Lizhen Cui, Tieke He, Hongzhi Yin|Shandong University, China; Nanjing University, China; Griffith University, Australia; The University of Queensland, Australia|The marriage of federated learning and recommender system (FedRec) has been widely used to address the growing data privacy concerns in personalized recommendation services. In FedRecs, users' attribute information and behavior data (i.e., user-item interaction data) are kept locally on their personal devices, therefore, it is considered a fairly secure approach to protect user privacy. As a result, the privacy issue of FedRecs is rarely explored. Unfortunately, several recent studies reveal that FedRecs are vulnerable to user attribute inference attacks, highlighting the privacy concerns of FedRecs. In this paper, we further investigate the privacy problem of user behavior data (i.e., user-item interactions) in FedRecs. Specifically, we perform the first systematic study on interaction-level membership inference attacks on FedRecs. An interaction-level membership inference attacker is first designed, and then the classical privacy protection mechanism, Local Differential Privacy (LDP), is adopted to defend against the membership inference attack. Unfortunately, the empirical analysis shows that LDP is not effective against such new attacks unless the recommendation performance is largely compromised. To mitigate the interaction-level membership attack threats, we design a simple yet effective defense method to significantly reduce the attacker's inference accuracy without losing recommendation performance. Extensive experiments are conducted with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on three real-world recommendation datasets (MovieLens-100K, Steam-200K, and Amazon Cell Phone), and the experimental results show the effectiveness of our solutions.|联邦学习与推荐系统的结合(FedRec)已被广泛用于解决个性化推荐服务中日益增长的数据隐私问题。在 FedRecs 中，用户的属性信息和行为数据(即用户项交互数据)保存在他们的个人设备上，因此，它被认为是保护用户隐私的一种相当安全的方法。因此，FedRecs 的隐私问题很少被探讨。不幸的是，最近的一些研究表明，联邦医疗记录系统容易受到用户属性推理攻击，突出了联邦医疗记录系统的隐私问题。在本文中，我们进一步研究了 FedRecs 中用户行为数据(即用户项交互)的隐私问题。具体来说，我们对 FedRecs 的交互层次成员推理攻击进行了第一次系统研究。首先设计了一个交互级别的成员推断攻击，然后采用经典的隐私保护机制，即本地差分隐私(lDP)来抵御成员推断攻击。遗憾的是，实证分析表明，除非推荐性能受到很大影响，否则 LDP 无法有效地抵抗这种新的攻击。为了减轻交互级别的成员攻击威胁，我们设计了一种简单而有效的防御方法，在不损失推荐性能的前提下显著降低攻击者的推断精度。在三个真实世界的推荐数据集(MovieLens-100K，Stream-200K 和 Amazon Cell Phone)上，用两个广泛使用的 FedRecs (Fed-NCF 和 Fed-LightGCN)进行了广泛的实验，实验结果显示了我们的解决方案的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interaction-level+Membership+Inference+Attack+Against+Federated+Recommender+Systems)|1|
|[Learning with Exposure Constraints in Recommendation Systems](https://doi.org/10.1145/3543507.3583320)|Omer BenPorat, Rotem Torkan|Faculty of Data and Decision Sciences, Technion - Israel Institute of Technology, Israel|Recommendation systems are dynamic economic systems that balance the needs of multiple stakeholders. A recent line of work studies incentives from the content providers' point of view. Content providers, e.g., vloggers and bloggers, contribute fresh content and rely on user engagement to create revenue and finance their operations. In this work, we propose a contextual multi-armed bandit setting to model the dependency of content providers on exposure. In our model, the system receives a user context in every round and has to select one of the arms. Every arm is a content provider who must receive a minimum number of pulls every fixed time period (e.g., a month) to remain viable in later rounds; otherwise, the arm departs and is no longer available. The system aims to maximize the users' (content consumers) welfare. To that end, it should learn which arms are vital and ensure they remain viable by subsidizing arm pulls if needed. We develop algorithms with sub-linear regret, as well as a lower bound that demonstrates that our algorithms are optimal up to logarithmic factors.|推荐系统是平衡多个利益相关者需求的动态经济系统。最近的一项工作是从内容提供商的角度研究激励机制。内容提供商，例如，视频博客和博客，贡献新的内容，并依靠用户参与来创造收入和资助他们的业务。在这项工作中，我们提出了一个上下文多臂老虎机设置来模拟内容提供者对曝光的依赖。在我们的模型中，系统在每一轮中接收一个用户上下文，并且必须选择一个武器。每只手臂都是一个内容提供者，它必须在每个固定的时间段(例如，一个月)接受最少数量的拉动，以便在以后的回合中保持活力; 否则，这只手臂就会离开，不再可用。该系统旨在最大化用户(内容消费者)的福利。为此，它应该了解哪些武器是至关重要的，并确保他们保持可行的补贴，如果需要的手臂拉。我们开发的算法与次线性遗憾，以及一个下限，表明我们的算法是最优的对数因素。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+with+Exposure+Constraints+in+Recommendation+Systems)|1|
|[On How Zero-Knowledge Proof Blockchain Mixers Improve, and Worsen User Privacy](https://doi.org/10.1145/3543507.3583217)|Zhipeng Wang, Stefanos Chaliasos, Kaihua Qin, Liyi Zhou, Lifeng Gao, Pascal Berrang, Benjamin Livshits, Arthur Gervais||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+How+Zero-Knowledge+Proof+Blockchain+Mixers+Improve,+and+Worsen+User+Privacy)|1|
|[To Store or Not? Online Data Selection for Federated Learning with Limited Storage](https://doi.org/10.1145/3543507.3583426)|Chen Gong, Zhenzhe Zheng, Fan Wu, Yunfeng Shao, Bingshuai Li, Guihai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=To+Store+or+Not?+Online+Data+Selection+for+Federated+Learning+with+Limited+Storage)|1|
|[Chain of Explanation: New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech](https://doi.org/10.1145/3543873.3587320)|Fan Huang, Haewoon Kwak, Jisun An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Chain+of+Explanation:+New+Prompting+Method+to+Generate+Quality+Natural+Language+Explanation+for+Implicit+Hate+Speech)|1|
|[NeuKron: Constant-Size Lossy Compression of Sparse Reorderable Matrices and Tensors](https://doi.org/10.1145/3543507.3583226)|Taehyung Kwon, Jihoon Ko, Jinhong Jung, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeuKron:+Constant-Size+Lossy+Compression+of+Sparse+Reorderable+Matrices+and+Tensors)|1|
|[Hierarchical Knowledge Graph Learning Enabled Socioeconomic Indicator Prediction in Location-Based Social Network](https://doi.org/10.1145/3543507.3583239)|Zhilun Zhou, Yu Liu, Jingtao Ding, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Knowledge+Graph+Learning+Enabled+Socioeconomic+Indicator+Prediction+in+Location-Based+Social+Network)|1|
|[Characterization of Simplicial Complexes by Counting Simplets Beyond Four Nodes](https://doi.org/10.1145/3543507.3583332)|Hyunju Kim, Jihoon Ko, Fanchen Bu, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Characterization+of+Simplicial+Complexes+by+Counting+Simplets+Beyond+Four+Nodes)|1|
|[KRACL: Contrastive Learning with Graph Context Modeling for Sparse Knowledge Graph Completion](https://doi.org/10.1145/3543507.3583412)|Zhaoxuan Tan, Zilong Chen, Shangbin Feng, Qingyue Zhang, Qinghua Zheng, Jundong Li, Minnan Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KRACL:+Contrastive+Learning+with+Graph+Context+Modeling+for+Sparse+Knowledge+Graph+Completion)|1|
|[Migration Reframed? A multilingual analysis on the stance shift in Europe during the Ukrainian crisis](https://doi.org/10.1145/3543507.3583442)|Sergej Wildemann, Claudia Niederée, Erick Elejalde||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Migration+Reframed?+A+multilingual+analysis+on+the+stance+shift+in+Europe+during+the+Ukrainian+crisis)|1|
|[Multitask Peer Prediction With Task-dependent Strategies](https://doi.org/10.1145/3543507.3583292)|Yichi Zhang, Grant Schoenebeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multitask+Peer+Prediction+With+Task-dependent+Strategies)|1|
|[High-Effort Crowds: Limited Liability via Tournaments](https://doi.org/10.1145/3543507.3583334)|Yichi Zhang, Grant Schoenebeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=High-Effort+Crowds:+Limited+Liability+via+Tournaments)|1|
|[Knowledge-infused Contrastive Learning for Urban Imagery-based Socioeconomic Prediction](https://doi.org/10.1145/3543507.3583876)|Yu Liu, Xin Zhang, Jingtao Ding, Yanxin Xi, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-infused+Contrastive+Learning+for+Urban+Imagery-based+Socioeconomic+Prediction)|1|
|[Dynamic Embedding-based Retrieval for Personalized Item Recommendations at Instacart](https://doi.org/10.1145/3543873.3587668)|Chuanwei Ruan, Allan Stewart, Han Li, Ryan Ye, David Vengerov, Haixun Wang|Instacart, USA|Personalization is essential in e-commerce, with item recommendation as a critical task. In this paper, we describe a hybrid embedding-based retrieval system for real-time personalized item recommendations on Instacart. Our system addresses unique challenges in the multi-source retrieval system, and includes several key components to make it highly personalized and dynamic. Specifically, our system features a hybrid embedding model that includes a long-term user interests embedding model and a real-time session-based model, which are combined to capture users’ immediate intents and historical interactions. Additionally, we have developed a contextual bandit solution to dynamically adjust the number of candidates from each source and optimally allocate retrieval slots given a limited computational budget. Our modeling and system optimization efforts have enabled us to provide highly personalized item recommendations in real-time at scale to all our customers, including new and long-standing users.|个性化在电子商务中是必不可少的，项目推荐是一项关键任务。本文描述了一个基于嵌入的混合检索系统，用于 Instacart 上的实时个性化项目推荐。我们的系统解决了多源检索系统中的独特挑战，并包含了几个关键组件，使其具有高度的个性化和动态性。具体来说，我们的系统采用混合嵌入模型，包括长期用户兴趣嵌入模型和基于实时会话的嵌入模型，它们结合起来捕获用户的直接意图和历史交互。此外，我们已经开发了一个上下文盗贼解决方案来动态调整每个来源的候选人数量，并在有限的计算预算下优化分配检索时隙。我们的建模和系统优化工作，使我们能够提供高度个性化的项目推荐的实时规模，我们的所有客户，包括新的和长期的用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Embedding-based+Retrieval+for+Personalized+Item+Recommendations+at+Instacart)|0|
|[A Multi-Granularity Matching Attention Network for Query Intent Classification in E-commerce Retrieval](https://doi.org/10.1145/3543873.3584639)|Chunyuan Yuan, Yiming Qiu, Mingming Li, Haiqing Hu, Songlin Wang, Sulong Xu|JD.com, Beijing, China, China|Query intent classification, which aims at assisting customers to find desired products, has become an essential component of the e-commerce search. Existing query intent classification models either design more exquisite models to enhance the representation learning of queries or explore label-graph and multi-task to facilitate models to learn external information. However, these models cannot capture multi-granularity matching features from queries and categories, which makes them hard to mitigate the gap in the expression between informal queries and categories.   This paper proposes a Multi-granularity Matching Attention Network (MMAN), which contains three modules: a self-matching module, a char-level matching module, and a semantic-level matching module to comprehensively extract features from the query and a query-category interaction matrix. In this way, the model can eliminate the difference in expression between queries and categories for query intent classification. We conduct extensive offline and online A/B experiments, and the results show that the MMAN significantly outperforms the strong baselines, which shows the superiority and effectiveness of MMAN. MMAN has been deployed in production and brings great commercial value for our company.|查询意图分类已经成为电子商务搜索的一个重要组成部分，其目的是帮助客户找到期望的产品。现有的查询意图分类模型要么设计更精细的模型来增强查询的表示学习，要么探索标签图和多任务来促进模型学习外部信息。然而，这些模型不能从查询和类别中捕获多粒度匹配特性，这使得它们很难缩小非正式查询和类别之间的表达差距。提出了一种多粒度匹配注意网络(MMAN)模型，该模型包括三个模块: 自匹配模块、字符级匹配模块和语义级匹配模块。通过这种方式，该模型可以消除查询和类别之间在查询意图分类方面的表达差异。我们进行了大量的离线和在线 A/B 实验，结果表明，MMAN 的性能明显优于强基线，显示了 MMAN 的优越性和有效性。MMAN 已投入生产，为公司带来了巨大的商业价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Granularity+Matching+Attention+Network+for+Query+Intent+Classification+in+E-commerce+Retrieval)|0|
|[Divide and Conquer: Towards Better Embedding-based Retrieval for Recommender Systems from a Multi-task Perspective](https://doi.org/10.1145/3543873.3584629)|Yuan Zhang, Xue Dong, Weijie Ding, Biao Li, Peng Jiang, Kun Gai|Shandong University, China; Kuaishou Technology, China; Unaffiliated, China|Embedding-based retrieval (EBR) methods are widely used in modern recommender systems thanks to its simplicity and effectiveness. However, along the journey of deploying and iterating on EBR in production, we still identify some fundamental issues in existing methods. First, when dealing with large corpus of candidate items, EBR models often have difficulties in balancing the performance on distinguishing highly relevant items (positives) from both irrelevant ones (easy negatives) and from somewhat related yet not competitive ones (hard negatives). Also, we have little control in the diversity and fairness of the retrieval results because of the ``greedy'' nature of nearest vector search. These issues compromise the performance of EBR methods in large-scale industrial scenarios. This paper introduces a simple and proven-in-production solution to overcome these issues. The proposed solution takes a divide-and-conquer approach: the whole set of candidate items are divided into multiple clusters and we run EBR to retrieve relevant candidates from each cluster in parallel; top candidates from each cluster are then combined by some controllable merging strategies. This approach allows our EBR models to only concentrate on discriminating positives from mostly hard negatives. It also enables further improvement from a multi-tasking learning (MTL) perspective: retrieval problems within each cluster can be regarded as individual tasks; inspired by recent successes in prompting and prefix-tuning, we propose an efficient task adaption technique further boosting the retrieval performance within each cluster with negligible overheads.|嵌入式检索方法以其简单有效的特点在现代推荐系统中得到了广泛的应用。然而，在生产中部署和迭代 EBR 的过程中，我们仍然发现了现有方法中的一些基本问题。首先，在处理大量候选项目时，EBR 模型往往难以平衡区分高度相关项目(正面)和无关项目(简单负面)以及有些相关但没有竞争性的项目(硬负面)。此外，由于最近向量搜索的“贪婪”特性，我们对检索结果的多样性和公平性几乎没有控制。这些问题影响了 EBR 方法在大规模工业场景中的性能。本文介绍了一个简单且已经在生产中得到验证的解决方案来克服这些问题。该解决方案采用分而治之的方法: 将整个候选项集划分为多个集群，并运行 EBR 并行地从每个集群中检索相关候选项; 然后通过一些可控的合并策略将每个集群中的最优候选项集合起来。这种方法允许我们的 EBR 模型只集中于区分正面和大多数硬负面。它还能从多任务学习(MTL)的角度进一步改进: 每个集群中的检索问题可以被视为单个任务; 受最近在提示和前缀调优方面的成功启发，我们提出了一种有效的任务适应技术，进一步提高了每个集群中的检索性能，开销可以忽略不计。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Divide+and+Conquer:+Towards+Better+Embedding-based+Retrieval+for+Recommender+Systems+from+a+Multi-task+Perspective)|0|
|[Expressive user embedding from churn and recommendation multi-task learning](https://doi.org/10.1145/3543873.3587306)|Huajun Bai, Davide Liu, Thomas Hirtz, Alexandre Boulenger|Genify, United Arab Emirates; Tsinghua University, China; Genify, China|In this paper, we present a Multi-Task model for Recommendation and Churn prediction (MT) in the retail banking industry. The model leverages a hard parameter-sharing framework and consists of a shared multi-stack encoder with multi-head self-attention and two fully connected task heads. It is trained to achieve two multi-class classification tasks: predicting product churn and identifying the next-best products (NBP) for users, individually. Our experiments demonstrate the superiority of the multi-task model compared to its single-task versions, reaching top-1 precision at 78.1% and 77.6%, for churn and NBP prediction respectively. Moreover, we find that the model learns a coherent and expressive high-level representation reflecting user intentions related to both tasks. There is a clear separation between users with acquisitions and users with churn. In addition, acquirers are more tightly clustered compared to the churners. The gradual separability of churning and acquiring users, who diverge in intent, is a desirable property. It provides a basis for model explainability, critical to industry adoption, and also enables other downstream applications. These potential additional benefits, beyond reducing customer attrition and increasing product use–two primary concerns of businesses, make such a model even more valuable.|本文提出了一个零售银行业推荐和流失预测的多任务模型。该模型利用一个硬参数共享框架，由一个具有多头自注意的共享多栈编码器和两个完全连接的任务头组成。它被训练以完成两个多类别的分类任务: 预测产品流失和为用户分别识别次优产品(NBP)。我们的实验证明了多任务模型相对于单任务模型的优越性，在流失预测和 NBP 预测方面分别达到了78.1% 和77.6% 的 Top-1精度。此外，我们发现该模型学习了一个连贯的和表达的高层次表示，反映了与两个任务相关的用户意图。并购用户和流失用户之间有明显的区别。此外，与搅拌器相比，收购者更紧密地聚集在一起。搅动用户和获取用户的逐渐可分性，这是一个可取的特性，因为用户的意图不同。它为模型的可解释性提供了基础，对于工业的采用至关重要，并且还支持其他下游应用程序。这些潜在的额外好处，除了减少客户流失和增加产品使用(企业的两个主要关注点)之外，使得这种模式更加有价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expressive+user+embedding+from+churn+and+recommendation+multi-task+learning)|0|
|[Continual Transfer Learning for Cross-Domain Click-Through Rate Prediction at Taobao](https://doi.org/10.1145/3543873.3584625)|Lixin Liu, Yanling Wang, Tianming Wang, Dong Guan, Jiawei Wu, Jingxu Chen, Rong Xiao, Wenxiang Zhu, Fei Fang|Alibaba Group, China; Alibaba group, China; Renmin University of China, China|As one of the largest e-commerce platforms in the world, Taobao's recommendation systems (RSs) serve the demands of shopping for hundreds of millions of customers. Click-Through Rate (CTR) prediction is a core component of the RS. One of the biggest characteristics in CTR prediction at Taobao is that there exist multiple recommendation domains where the scales of different domains vary significantly. Therefore, it is crucial to perform cross-domain CTR prediction to transfer knowledge from large domains to small domains to alleviate the data sparsity issue. However, existing cross-domain CTR prediction methods are proposed for static knowledge transfer, ignoring that all domains in real-world RSs are continually time-evolving. In light of this, we present a necessary but novel task named Continual Transfer Learning (CTL), which transfers knowledge from a time-evolving source domain to a time-evolving target domain. In this work, we propose a simple and effective CTL model called CTNet to solve the problem of continual cross-domain CTR prediction at Taobao, and CTNet can be trained efficiently. Particularly, CTNet considers an important characteristic in the industry that models has been continually well-trained for a very long time. So CTNet aims to fully utilize all the well-trained model parameters in both source domain and target domain to avoid losing historically acquired knowledge, and only needs incremental target domain data for training to guarantee efficiency. Extensive offline experiments and online A/B testing at Taobao demonstrate the efficiency and effectiveness of CTNet. CTNet is now deployed online in the recommender systems of Taobao, serving the main traffic of hundreds of millions of active users.|作为世界上最大的电子商务平台之一，淘宝的推荐系统(RS)为数以亿计的顾客提供购物服务。点进率预测是遥感的核心组成部分。淘宝网点击率预测的最大特点之一是存在多个推荐域，不同域的规模差异很大。因此，进行跨域 CTR 预测，将知识从大域转移到小域，以缓解数据稀疏性问题至关重要。然而，现有的跨域 CTR 预测方法都是针对静态知识转移而提出的，忽略了现实 RSS 中的所有域都是不断时间演化的。鉴于此，我们提出了一个必要的，但新颖的任务称为连续转移学习(CTL) ，它将知识从一个时间演化的源领域转移到一个时间演化的目标领域。本文提出了一种简单有效的 CTL 模型 CTNet 来解决淘宝网连续跨域 CTR 预测问题，可以有效地训练 CTNet。特别是，CTNet 认为模特行业的一个重要特征是模特长期以来一直受到良好的培训。因此，CTNet 的目标是充分利用源域和目标域中所有训练有素的模型参数，避免丢失历史获得的知识，只需要增量的目标域数据进行训练，以保证训练效率。在淘宝上的大量离线实验和在线 A/B 测试证明了 CTNet 的效率和有效性。CTNet 现已部署在淘宝网的推荐系统中，为数亿活跃用户的主要流量提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Transfer+Learning+for+Cross-Domain+Click-Through+Rate+Prediction+at+Taobao)|0|
|[MAKE: Vision-Language Pre-training based Product Retrieval in Taobao Search](https://doi.org/10.1145/3543873.3584627)|Xiaoyang Zheng, Zilong Wang, Sen Li, Ke Xu, Tao Zhuang, Qingwen Liu, Xiaoyi Zeng|; Alibaba Group, China|Taobao Search consists of two phases: the retrieval phase and the ranking phase. Given a user query, the retrieval phase returns a subset of candidate products for the following ranking phase. Recently, the paradigm of pre-training and fine-tuning has shown its potential in incorporating visual clues into retrieval tasks. In this paper, we focus on solving the problem of text-to-multimodal retrieval in Taobao Search. We consider that users' attention on titles or images varies on products. Hence, we propose a novel Modal Adaptation module for cross-modal fusion, which helps assigns appropriate weights on texts and images across products. Furthermore, in e-commerce search, user queries tend to be brief and thus lead to significant semantic imbalance between user queries and product titles. Therefore, we design a separate text encoder and a Keyword Enhancement mechanism to enrich the query representations and improve text-to-multimodal matching. To this end, we present a novel vision-language (V+L) pre-training methods to exploit the multimodal information of (user query, product title, product image). Extensive experiments demonstrate that our retrieval-specific pre-training model (referred to as MAKE) outperforms existing V+L pre-training methods on the text-to-multimodal retrieval task. MAKE has been deployed online and brings major improvements on the retrieval system of Taobao Search.|淘宝搜索包括两个阶段: 检索阶段和排名阶段。给定一个用户查询，检索阶段返回下一个排序阶段的候选产品的子集。最近，预先训练和微调的范式已经显示了其在将视觉线索纳入检索任务方面的潜力。本文主要研究淘宝搜索中文本到多模式检索的问题。我们认为用户对标题或图片的关注因产品而异。因此，我们提出了一个新的模态适应模块的跨模态融合，这有助于分配适当的权重的文本和图像跨产品。此外，在电子商务搜索中，用户查询往往是简短的，从而导致用户查询和产品标题之间的语义严重失衡。因此，我们设计了一个单独的文本编码器和一个关键字增强机制，以丰富查询表示和改善文本到多模式匹配。为此，我们提出了一种新的视觉语言(V + L)预训练方法来利用多模态信息(用户查询、产品标题、产品图像)。大量的实验表明，我们的检索特定的预训练模型(简称 MAKE)在文本到多模态检索任务上优于现有的 V + L 预训练方法。MAKE 已经在线部署，并对淘宝搜索的检索系统进行了重大改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MAKE:+Vision-Language+Pre-training+based+Product+Retrieval+in+Taobao+Search)|0|
|[HAPENS: Hardness-Personalized Negative Sampling for Implicit Collaborative Filtering](https://doi.org/10.1145/3543873.3584631)|Haoxin Liu, Pu Zhao, Si Qin, Yong Shi, Mirror Xu, Qingwei Lin, Dongmei Zhang|Microsoft Research, China; Microsoft Bing, China|For training implicit collaborative filtering (ICF) models, hard negative sampling (HNS) has become a state-of-the-art solution for obtaining negative signals from massive uninteracted items. However, selecting appropriate hardness levels for personalized recommendations remains a fundamental, yet underexplored, problem. Previous HNS works have primarily adjusted the hardness level by tuning a single hyperparameter. However, applying the same hardness level to each user is unsuitable due to varying user behavioral characteristics, the quantity and quality of user records, and different consistencies of models’ inductive biases. Moreover, increasing the number of hyperparameters is not practical due to the massive number of users. To address this important and challenging problem, we propose a model-agnostic and practical approach called hardness-personalized negative sampling (HAPENS). HAPENS uses a two-stage approach: in stage one, it trains the ICF model with a customized objective function that optimizes its worst performance on each user’s interacted item set. In stage two, it utilizes these worst performances as personalized hardness levels with a well-designed sampling distribution, and trains the final model with the same architecture. We evaluated HAPENS on the collected Bing advertising dataset and one public dataset, and the comprehensive experimental results demonstrate its robustness and superiority. Moreover, HAPENS has delivered significant benefits to the Bing advertising system. To the best of our knowledge, we are the first to study this important and challenging problem.|对于训练内隐协同过滤模型(ICF) ，硬负采样(hNS)已成为从大量未交互项目中获取负信号的最新解决方案。然而，为个性化推荐选择合适的硬度水平仍然是一个基本的、尚未得到充分探索的问题。以往的 HNS 工作主要是通过调整单个超参数来调整硬度水平。然而，由于不同的用户行为特征、用户记录的数量和质量以及模型归纳偏差的不同一致性，对每个用户应用相同的硬度水平是不合适的。此外，由于用户数量庞大，增加超参数的数量是不切实际的。为了解决这一重要而具有挑战性的问题，我们提出了一种模型不可知的实用方法，称为硬度个性化阴性采样(HAPENS)。HAPENS 使用两阶段的方法: 在第一阶段，它使用一个定制的目标函数来训练 ICF 模型，该目标函数在每个用户的交互项集上优化其最差的性能。在第二阶段，它利用这些最差的性能作为个性化的硬度水平，具有设计良好的采样分布，并训练最终模型具有相同的架构。我们对搜集到的 Bing 广告数据集和一个公共数据集进行了 HAPENS 评估，综合实验结果表明了 HAPENS 的鲁棒性和优越性。此外，HAPENS 为必应广告系统带来了巨大的好处。据我们所知，我们是第一个研究这个重要而富有挑战性的问题的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HAPENS:+Hardness-Personalized+Negative+Sampling+for+Implicit+Collaborative+Filtering)|0|
|[Que2Engage: Embedding-based Retrieval for Relevant and Engaging Products at Facebook Marketplace](https://doi.org/10.1145/3543873.3584633)|Yunzhong He, Yuxin Tian, Mengjiao Wang, Feier Chen, Licheng Yu, Maolong Tang, Congcong Chen, Ning Zhang, Bin Kuang, Arul Prakash|Meta, USA; University of California, Merced, USA|Embedding-based Retrieval (EBR) in e-commerce search is a powerful search retrieval technique to address semantic matches between search queries and products. However, commercial search engines like Facebook Marketplace Search are complex multi-stage systems optimized for multiple business objectives. At Facebook Marketplace, search retrieval focuses on matching search queries with relevant products, while search ranking puts more emphasis on contextual signals to up-rank the more engaging products. As a result, the end-to-end searcher experience is a function of both relevance and engagement, and the interaction between different stages of the system. This presents challenges to EBR systems in order to optimize for better searcher experiences. In this paper we presents Que2Engage, a search EBR system built towards bridging the gap between retrieval and ranking for end-to-end optimizations. Que2Engage takes a multimodal & multitask approach to infuse contextual information into the retrieval stage and to balance different business objectives. We show the effectiveness of our approach via a multitask evaluation framework and thorough baseline comparisons and ablation studies. Que2Engage is deployed on Facebook Marketplace Search and shows significant improvements in searcher engagement in two weeks of A/B testing.|电子商务搜索中的嵌入式检索(EBR)是解决搜索查询与产品之间语义匹配的一种强有力的检索技术。然而，像 Facebook Marketplace Search 这样的商业搜索引擎是为多个业务目标而优化的复杂的多阶段系统。在 Facebook Marketplace，搜索检索侧重于将搜索查询与相关产品进行匹配，而搜索排名更侧重于上下文信号，以提升更具吸引力的产品的排名。因此，端到端的搜索体验是相关性和参与度的函数，以及系统不同阶段之间的相互作用。这对 EBR 系统提出了挑战，以便优化更好的搜索体验。本文介绍了 Que2Engage，这是一个搜索 EBR 系统，旨在弥合检索和排序之间的差距，以实现端到端的优化。Que2Engage 采用多模态和多任务的方法将上下文信息注入检索阶段，并平衡不同的业务目标。我们通过一个多任务评估框架和彻底的基线比较和消融研究来展示我们的方法的有效性。Que2Engage 部署在 Facebook Marketplace Search 上，并在两周的 A/B 测试中显示出搜索者参与度的显著改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Que2Engage:+Embedding-based+Retrieval+for+Relevant+and+Engaging+Products+at+Facebook+Marketplace)|0|
|[Learning Multi-Stage Multi-Grained Semantic Embeddings for E-Commerce Search](https://doi.org/10.1145/3543873.3584638)|Binbin Wang, Mingming Li, Zhixiong Zeng, Jingwei Zhuo, Songlin Wang, Sulong Xu, Bo Long, Weipeng Yan|JD.com, China|Retrieving relevant items that match users' queries from billion-scale corpus forms the core of industrial e-commerce search systems, in which embedding-based retrieval (EBR) methods are prevailing. These methods adopt a two-tower framework to learn embedding vectors for query and item separately and thus leverage efficient approximate nearest neighbor (ANN) search to retrieve relevant items. However, existing EBR methods usually ignore inconsistent user behaviors in industrial multi-stage search systems, resulting in insufficient retrieval efficiency with a low commercial return. To tackle this challenge, we propose to improve EBR methods by learning Multi-level Multi-Grained Semantic Embeddings(MMSE). We propose the multi-stage information mining to exploit the ordered, clicked, unclicked and random sampled items in practical user behavior data, and then capture query-item similarity via a post-fusion strategy. We then propose multi-grained learning objectives that integrate the retrieval loss with global comparison ability and the ranking loss with local comparison ability to generate semantic embeddings. Both experiments on a real-world billion-scale dataset and online A/B tests verify the effectiveness of MMSE in achieving significant performance improvements on metrics such as offline recall and online conversion rate (CVR).|基于嵌入式检索(EBR)方法是工业电子商务搜索系统的核心，它可以从数十亿规模的语料库中检索出与用户查询相匹配的相关项目。这些方法采用双塔架构，分别学习查询和项目的嵌入向量，从而利用有效的近似最近邻(ANN)搜索来检索相关项目。然而，现有的 EBR 方法往往忽略了工业多阶段搜索系统中不一致的用户行为，导致检索效率不足，商业收益较低。为了解决这一问题，我们提出通过学习多级多粒度语义嵌入(MMSE)来改进 EBR 方法。提出了一种基于多阶段信息挖掘的方法，利用实际用户行为数据中的有序、点击、未点击和随机抽样条目，通过后融合策略获取查询条目的相似性。然后提出多粒度学习目标，将检索损失与全局比较能力、排序损失与局部比较能力相结合，生成语义嵌入。在真实世界的十亿级数据集上的实验和在线 A/B 测试都验证了 MMSE 在离线召回率和在线转换率(CVR)等指标上实现显著性能改进的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Multi-Stage+Multi-Grained+Semantic+Embeddings+for+E-Commerce+Search)|0|
|[CAM2: Conformity-Aware Multi-Task Ranking Model for Large-Scale Recommender Systems](https://doi.org/10.1145/3543873.3584657)|Ameya Raul, Amey Porobo Dharwadker, Brad Schumitsch|Meta Inc., USA|Learning large-scale industrial recommender system models by fitting them to historical user interaction data makes them vulnerable to conformity bias. This may be due to a number of factors, including the fact that user interests may be difficult to determine and that many items are often interacted with based on ecosystem factors other than their relevance to the individual user. In this work, we introduce CAM2, a conformity-aware multi-task ranking model to serve relevant items to users on one of the largest industrial recommendation platforms. CAM2 addresses these challenges systematically by leveraging causal modeling to disentangle users' conformity to popular items from their true interests. This framework is generalizable and can be scaled to support multiple representations of conformity and user relevance in any large-scale recommender system. We provide deeper practical insights and demonstrate the effectiveness of the proposed model through improvements in offline evaluation metrics compared to our production multi-task ranking model. We also show through online experiments that the CAM2 model results in a significant 0.50% increase in aggregated user engagement, coupled with a 0.21% increase in daily active users on Facebook Watch, a popular video discovery and sharing platform serving billions of users.|通过将大规模工业推荐系统模型与历史用户交互数据进行拟合，使其容易受到一致性偏差的影响。这可能是由于若干因素，包括用户的兴趣可能难以确定，而且许多项目往往基于生态系统因素而不是它们与个别用户的相关性进行交互。在这项工作中，我们介绍了 CAM2，一个整合意识的多任务排序模型，以服务于相关项目的用户在一个最大的行业推荐平台。CAM2通过利用因果建模系统地解决这些挑战，从用户的真实兴趣中分离出用户对流行项目的一致性。这个框架是可以推广的，可以扩展到支持任何大规模推荐系统中的多种一致性和用户相关性的表示。我们提供了更深入的实践见解，并证明了该模型的有效性，通过改进离线评估指标相比，我们的生产多任务排序模型。我们还通过在线实验表明，CAM2模型显著增加了0.50% 的聚合用户参与度，同时 Facebook Watch 的日常活跃用户增加了0.21% 。 Facebook Watch 是一个流行的视频发现和分享平台，服务于数十亿用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAM2:+Conformity-Aware+Multi-Task+Ranking+Model+for+Large-Scale+Recommender+Systems)|0|
|[A Deep Behavior Path Matching Network for Click-Through Rate Prediction](https://doi.org/10.1145/3543873.3584662)|Jian Dong, Yisong Yu, Yapeng Zhang, Yimin Lv, Shuli Wang, Beihong Jin, Yongkang Wang, Xingxing Wang, Dong Wang|Meituan Ltd., China; Institute of Software, Chinese Academy of Sciences, China and University of Chinese Academy of Sciences, China; Meituan Ltd, China|User behaviors on an e-commerce app not only contain different kinds of feedback on items but also sometimes imply the cognitive clue of the user's decision-making. For understanding the psychological procedure behind user decisions, we present the behavior path and propose to match the user's current behavior path with historical behavior paths to predict user behaviors on the app. Further, we design a deep neural network for behavior path matching and solve three difficulties in modeling behavior paths: sparsity, noise interference, and accurate matching of behavior paths. In particular, we leverage contrastive learning to augment user behavior paths, provide behavior path self-activation to alleviate the effect of noise, and adopt a two-level matching mechanism to identify the most appropriate candidate. Our model shows excellent performance on two real-world datasets, outperforming the state-of-the-art CTR model. Moreover, our model has been deployed on the Meituan food delivery platform and has accumulated 1.6% improvement in CTR and 1.8% improvement in advertising revenue.|用户在电子商务应用程序上的行为不仅包含对项目的不同类型的反馈，而且有时还意味着用户决策的认知线索。为了理解用户决策背后的心理过程，我们提出了行为路径，并建议匹配用户的当前行为路径和历史行为路径，以预测用户在应用程序上的行为。进一步，我们设计了一个用于行为路径匹配的深层神经网络，解决了行为路径建模中的三个难点: 稀疏性、噪声干扰和行为路径的精确匹配。特别地，我们利用对比学习来增强用户的行为路径，提供行为路径自激活来减轻噪声的影响，并采用两级匹配机制来确定最合适的候选者。我们的模型在两个真实世界的数据集上显示了出色的性能，优于最先进的 CTR 模型。此外，我们的模型已经部署在美团食品配送平台上，点击率累计提高了1.6% ，广告收入累计提高了1.8% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Deep+Behavior+Path+Matching+Network+for+Click-Through+Rate+Prediction)|0|
|[Cross-lingual Search for e-Commerce based on Query Translatability and Mixed-Domain Fine-Tuning](https://doi.org/10.1145/3543873.3587660)|Jesus PerezMartin, Jorge GomezRobles, Asier GutiérrezFandiño, Pankaj Adsul, Sravanthi Rajanala, Leonardo Lezcano||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-lingual+Search+for+e-Commerce+based+on+Query+Translatability+and+Mixed-Domain+Fine-Tuning)|0|
|[Enhancing User Personalization in Conversational Recommenders](https://doi.org/10.1145/3543507.3583192)|Allen Lin, Ziwei Zhu, Jianling Wang, James Caverlee|Texas A&M University, USA; George Mason University, USA|Conversational recommenders are emerging as a powerful tool to personalize a user's recommendation experience. Through a back-and-forth dialogue, users can quickly hone in on just the right items. Many approaches to conversational recommendation, however, only partially explore the user preference space and make limiting assumptions about how user feedback can be best incorporated, resulting in long dialogues and poor recommendation performance. In this paper, we propose a novel conversational recommendation framework with two unique features: (i) a greedy NDCG attribute selector, to enhance user personalization in the interactive preference elicitation process by prioritizing attributes that most effectively represent the actual preference space of the user; and (ii) a user representation refiner, to effectively fuse together the user preferences collected from the interactive elicitation process to obtain a more personalized understanding of the user. Through extensive experiments on four frequently used datasets, we find the proposed framework not only outperforms all the state-of-the-art conversational recommenders (in terms of both recommendation performance and conversation efficiency), but also provides a more personalized experience for the user under the proposed multi-groundtruth multi-round conversational recommendation setting.|对话式推荐正在成为个性化用户推荐体验的强大工具。通过反复的对话，用户可以快速找到正确的项目。然而，许多会话推荐方法只是部分地探索了用户偏好空间，并对如何最好地整合用户反馈进行了有限的假设，导致了冗长的对话和糟糕的推荐性能。本文提出了一种新的会话推荐框架，该框架具有两个独特的特征: (1)贪婪的 NDCG 属性选择器，通过对最有效地表示用户实际偏好空间的属性进行优先排序，增强交互式偏好启发过程中的用户个性化; (2)用户表示细化器，有效地融合交互式启发过程中收集到的用户偏好，以获得对用户更个性化的理解。通过对四个常用数据集的大量实验，我们发现该框架不仅在推荐性能和会话效率方面优于所有最先进的会话推荐器，而且在提出的多地面真相多轮会话推荐设置下为用户提供了更加个性化的体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+User+Personalization+in+Conversational+Recommenders)|0|
|[Dual-interest Factorization-heads Attention for Sequential Recommendation](https://doi.org/10.1145/3543507.3583278)|Guanyu Lin, Chen Gao, Yu Zheng, Jianxin Chang, Yanan Niu, Yang Song, Zhiheng Li, Depeng Jin, Yong Li|kuaishou, China; Tsinghua University, China; Department of Electronic Engineering, Tsinghua University, China|Accurate user interest modeling is vital for recommendation scenarios. One of the effective solutions is the sequential recommendation that relies on click behaviors, but this is not elegant in the video feed recommendation where users are passive in receiving the streaming contents and return skip or no-skip behaviors. Here skip and no-skip behaviors can be treated as negative and positive feedback, respectively. With the mixture of positive and negative feedback, it is challenging to capture the transition pattern of behavioral sequence. To do so, FeedRec has exploited a shared vanilla Transformer, which may be inelegant because head interaction of multi-heads attention does not consider different types of feedback. In this paper, we propose Dual-interest Factorization-heads Attention for Sequential Recommendation (short for DFAR) consisting of feedback-aware encoding layer, dual-interest disentangling layer and prediction layer. In the feedback-aware encoding layer, we first suppose each head of multi-heads attention can capture specific feedback relations. Then we further propose factorization-heads attention which can mask specific head interaction and inject feedback information so as to factorize the relation between different types of feedback. Additionally, we propose a dual-interest disentangling layer to decouple positive and negative interests before performing disentanglement on their representations. Finally, we evolve the positive and negative interests by corresponding towers whose outputs are contrastive by BPR loss. Experiments on two real-world datasets show the superiority of our proposed method against state-of-the-art baselines. Further ablation study and visualization also sustain its effectiveness. We release the source code here: https://github.com/tsinghua-fib-lab/WWW2023-DFAR.|准确的用户兴趣建模对于推荐场景至关重要。其中一个有效的解决方案是依赖于点击行为的顺序推荐，但是在视频提要推荐中这并不优雅，因为用户在接收流内容和返回跳过或不跳过行为时是被动的。在这里，跳过和不跳过行为可以分别视为负反馈和正反馈。由于正反馈和负反馈的混合，捕捉行为序列的转换模式具有挑战性。为此，FeedRec 利用了一个共享的香草变压器，这可能是不雅的，因为多头注意的头部交互没有考虑不同类型的反馈。本文提出了由反馈感知编码层、双兴趣分解层和预测层组成的双兴趣分解顺序推荐系统。在反馈感知编码层，我们首先假设多头注意的每个头都能捕获特定的反馈关系。然后进一步提出因子分解-头注意，它可以掩盖特定的头交互，并注入反馈信息，从而对不同类型的反馈之间的关系进行因子分解。此外，我们提出了一个双利益解缠层，以解耦正面和负面的利益之前，执行解缠的表示。最后，我们通过相应的塔进行正负利益演化，其输出由于业务流程重组损失而具有对比性。在两个实际数据集上的实验表明了我们提出的方法对最先进的基线的优越性。进一步的消融研究和可视化也支持其有效性。我们在这里发布源代码:  https://github.com/tsinghua-fib-lab/www2023-dfar。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-interest+Factorization-heads+Attention+for+Sequential+Recommendation)|0|
|[A Cross-Media Retrieval System for Web-SNS-Map Using Suggested Keywords Generating and Ranking Method Based on Search Characteristics](https://doi.org/10.1145/3543873.3587344)|Da Li, Masaki Sugihashi, Tadahiko Kumamoto, Yukiko Kawai|Chiba Institute of Technology, Japan; Fukuoka University, Japan; Kyoto Sangyo University, Japan|The research on multimedia retrieval has lasted for several decades. However, past efforts generally focused on single-media retrieval, where the queries and retrieval results belong to the same media (platform) type, such as social media platforms or search engines. In single-media retrieval, users have to select search media or options based on search characteristics such as contents, time, or spatial distance, they might be unable to retrieve correct results mixed in other media if they carelessly forget to select. In this study, we propose a cross-media retrieval system using suggestion generation methods to integrate three search characteristics of the Web (textual content-based retrieval), SNS (timeliness), and map (spatial distance-aware retrieval). In our previous research, we attempted to improve search efficiency using clustering methods to provide search results to users through related terms, etc. In this paper, we focus on the search efficiency of multiple search media. We utilize Google search engine to obtain the retrieval content from the Web, Twitter to obtain timely information from SNSs, and Google Maps to get geographical information from maps. We apply the obtained retrieval results to analyze the similarities between them by clustering. Then, we generate relevant suggestions and provide them to users. Moreover, we validate the effectiveness of the search results generated by our proposed system.|多媒体检索的研究已经持续了几十年。然而，过去的努力通常集中在单媒体检索，其中查询和检索结果属于相同的媒体(平台)类型，如社会媒体平台或搜索引擎。在单媒体检索中，用户必须根据内容、时间或空间距离等搜索特征选择搜索媒体或选项，如果不小心忘记选择，可能无法检索混合在其他媒体中的正确结果。在本研究中，我们提出一个跨媒体检索系统，利用建议产生的方法来整合网页(文本内容检索)、 SNS (及时性)和地图(空间距离感知检索)的三个搜索特性。在我们以前的研究中，我们尝试使用聚类方法来提高搜索效率，通过相关词汇等为用户提供搜索结果。本文主要研究多种搜索媒体的搜索效率。我们利用谷歌搜索引擎从网络中获取检索内容，利用 Twitter 从 SNS 中获取及时信息，利用谷歌地图从地图中获取地理信息。我们应用所得到的检索结果，通过聚类分析它们之间的相似性。然后，我们生成相关的建议并提供给用户。此外，我们还验证了该系统所产生的搜索结果的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Cross-Media+Retrieval+System+for+Web-SNS-Map+Using+Suggested+Keywords+Generating+and+Ranking+Method+Based+on+Search+Characteristics)|0|
|[A Knowledge Enhanced Hierarchical Fusion Network for CTR Prediction under Account Search Scenario in WeChat](https://doi.org/10.1145/3543873.3584650)|Yuanzhou Yao, Zhao Zhang, Kaijia Yang, Huasheng Liang, Qiang Yan, Fuzheng Zhuang, Yongjun Xu, Boyu Diao, Chao Li|WeChat, Tencent, China; Zhejiang Lab, China; Institute of Computing Technology, Chinese Academy of Sciences, China; Institute of Artificial Intelligence, Beihang University, China|Click-through rate (CTR) estimation plays as a pivotal function module in various online services. Previous studies mainly apply CTR models to the field of recommendation or online advertisement. Indeed, CTR is also critical in information retrieval, since the CTR probability can serve as a valuable feature for a query-document pair. In this paper, we study the CTR task under account search scenario in WeChat, where users search official accounts or mini programs corresponding to an organization. Despite the large number of CTR models, directly applying them to our task is inappropriate since the account retrieval task has a number of specific characteristics. E.g., different from traditional user-centric CTR models, in our task, CTR prediction is query-centric and does not model user information. In addition, queries and accounts are short texts, and heavily rely on prior knowledge and semantic understanding. These characteristics require us to specially design a CTR model for the task. To this end, we propose a novel CTR prediction model named Knowledge eNhanced hIerarchical Fusion nEtwork (KNIFE). Specifically, to tackle the prior information problem, we mine the knowledge graph of accounts as side information; to enhance the representations of queries, we construct a bipartite graph for queries and accounts. In addition, a hierarchical network structure is proposed to fuse the representations of different information in a fine-grained manner. Finally, the representations of queries and accounts are obtained from this hierarchical network and fed into the CTR model together with other features for prediction. We conduct extensive experiments against 12 existing models across two industrial datasets. Both offline and online A/B test results indicate the effectiveness of KNIFE.|在各种网上服务中，点进率评估是一个关键的功能模块。以往的研究主要将点击率模型应用于推荐或在线广告领域。实际上，点击率在信息检索中也很关键，因为点击率可以作为查询-文档对的一个有价值的特性。本文研究了微信中用户搜索官方账号或与组织对应的小程序的帐号搜索情景下的点击率任务。尽管有大量的点击率检索模型，但由于账户检索任务具有许多特殊性，直接将其应用于我们的任务是不合适的。例如，与传统的以用户为中心的 CTR 模型不同，在我们的任务中，CTR 预测是以查询为中心的，不对用户信息建模。此外，查询和帐户是简短的文本，并且严重依赖于先前的知识和语义理解。这些特性要求我们为任务专门设计一个 CTR 模型。为此，我们提出了一种新的 CTR 预测模型——知识增强分层融合网络(KNIFE)。具体来说，为了解决先验信息问题，我们挖掘帐户的知识图作为边信息; 为了增强查询的表示，我们为查询和帐户构造一个二分图。此外，提出了一种分层网络结构，以细粒度的方式融合不同信息的表示。最后，从这个层次网络中获得查询和帐户的表示，并将其与其他用于预测的特征一起反馈到 CTR 模型中。我们对两个工业数据集中的12个现有模型进行了广泛的实验。离线和在线 A/B 测试结果均表明了 KNIFE 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Knowledge+Enhanced+Hierarchical+Fusion+Network+for+CTR+Prediction+under+Account+Search+Scenario+in+WeChat)|0|
|[Multi-Objective Ranking to Boost Navigational Suggestions in eCommerce AutoComplete](https://doi.org/10.1145/3543873.3584649)|Sonali Singh, Sachin Farfade, Prakash Mandayam Comar|Amazon, India|Query AutoComplete (QAC) helps customers complete their search queries quickly by suggesting completed queries. QAC on eCommerce sites usually employ Learning to Rank (LTR) approaches based on customer behaviour signals such as clicks and conversion rates to optimize business metrics. However, they do not exclusively optimize for the quality of suggested queries which results in lack of navigational suggestions like product categories and attributes, e.g., "sports shoes" and "white shoes" for query "shoes". We propose to improve the quality of query suggestions by introducing navigational suggestions without impacting the business metrics. For this purpose, we augment the customer behaviour (CB) based objective with Query-Quality (QQ) objective and assemble them with trainable mixture weights to define multi-objective optimization function. We propose to optimize this multi-objective function by implementing ALMO algorithm to obtain a model robust against any mixture weight. We show that this formulation improves query relevance on an eCommerce QAC dataset by at least 13% over the baseline Deep Pairwise LTR (DeepPLTR) with minimal impact on MRR and results in a lift of 0.26% in GMV in an online A/B test. We also evaluated our approach on public search logs datasets and got improvement in query relevance by using query coherence as QQ objective.|QueryAutoComplete (QAC)通过建议已完成的查询，帮助客户快速完成搜索查询。电子商务网站上的 QAC 通常采用基于客户行为信号(如点击率和转换率)的学习排名(LTR)方法来优化业务指标。然而，它们并不专门针对建议查询的质量进行优化，这会导致缺乏像产品类别和属性这样的导航建议，例如，“运动鞋”和查询“鞋子”的“白鞋子”。我们建议通过引入导航建议而不影响业务度量来提高查询建议的质量。为此，我们将基于顾客行为(CB)的目标与查询质量(QQ)目标相结合，并用可训练的混合权重组合它们来定义多目标优化函数。我们提出通过实现 ALMO 算法来优化这个多目标函数，以获得对任意混合权重的鲁棒模型。我们表明，这种制定方法使电子商务 QAC 数据集的查询相关性比基线 Deep Pairwise LTR (DeepPLTR)至少提高了13% ，对 MRR 的影响最小，并且在线 A/B 测试中导致 GMV 升高0.26% 。对公共检索日志数据集的检索方法进行了评估，并以查询一致性为 QQ 目标，提高了查询相关性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Objective+Ranking+to+Boost+Navigational+Suggestions+in+eCommerce+AutoComplete)|0|
|[Personalization and Recommendations in Search](https://doi.org/10.1145/3543873.3589749)|Sudarshan Lamkhede, Anlei Dong, Moumita Bhattacharya, Hongning Wang|Microsoft Bing, USA; Dept. of Computer Science, University of Virginia, USA; Netflix Research, USA|The utility of a search system for its users can be further enhanced by providing personalized results and recommendations within the search context. However, the research discussions around these aspects of search remain fragmented across different conferences and workshops. Hence, this workshop aims to bring together researchers and practitioners from industry and academia to engage in the discussions of algorithmic and system challenges in search personalization and effectively recommending within search context.|通过在搜索上下文中提供个性化的结果和建议，可以进一步加强搜索系统对用户的效用。然而，围绕搜索这些方面的研究讨论在不同的会议和研讨会上仍然支离破碎。因此，这个研讨会的目的是聚集业界和学术界的研究人员和从业人员，参与讨论在搜索个性化和有效推荐搜索背景下的算法和系统挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalization+and+Recommendations+in+Search)|0|
|[Cooperative Retriever and Ranker in Deep Recommenders](https://doi.org/10.1145/3543507.3583422)|Xu Huang, Defu Lian, Jin Chen, Liu Zheng, Xing Xie, Enhong Chen|; University of Electronic Science and Technology of China, China; Microsoft Research Asia, China; University of Science and Technology of China, China|Deep recommender systems (DRS) are intensively applied in modern web services. To deal with the massive web contents, DRS employs a two-stage workflow: retrieval and ranking, to generate its recommendation results. The retriever aims to select a small set of relevant candidates from the entire items with high efficiency; while the ranker, usually more precise but time-consuming, is supposed to further refine the best items from the retrieved candidates. Traditionally, the two components are trained either independently or within a simple cascading pipeline, which is prone to poor collaboration effect. Though some latest works suggested to train retriever and ranker jointly, there still exist many severe limitations: item distribution shift between training and inference, false negative, and misalignment of ranking order. As such, it remains to explore effective collaborations between retriever and ranker.|深度推荐系统(DRS)在现代 Web 服务中得到了广泛的应用。为了处理海量的网络内容，DRS 采用了两个阶段的工作流程: 检索和排名，以生成其推荐结果。检索器的目标是从整个项目中高效地选择一小部分相关候选项; 而排名器通常更精确但更耗时，应该从检索到的候选项中进一步提炼出最好的项目。传统上，这两个组件要么单独训练，要么在一个简单的级联管道中训练，这样容易产生较差的协作效果。虽然最新的一些研究提出了联合训练检索器和排序器，但仍然存在很多严重的局限性: 训练和推理之间的项目分布转移、错误否定和排序顺序不一致。因此，仍然需要探索检索器和排名器之间的有效协作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cooperative+Retriever+and+Ranker+in+Deep+Recommenders)|0|
|[Modeling Temporal Positive and Negative Excitation for Sequential Recommendation](https://doi.org/10.1145/3543507.3583463)|Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao|University of Technology Sydney, Australia; CSIRO's Data 61, Australia and The University of New South Wales, Australia; The University of New South Wales, Australia|Sequential recommendation aims to predict the next item which interests users via modeling their interest in items over time. Most of the existing works on sequential recommendation model users’ dynamic interest in specific items while overlooking users’ static interest revealed by some static attribute information of items, e.g., category, brand. Moreover, existing works often only consider the positive excitation of a user’s historical interactions on his/her next choice on candidate items while ignoring the commonly existing negative excitation, resulting in insufficiently modeling dynamic interest. The overlook of static interest and negative excitation will lead to incomplete interest modeling and thus impedes the recommendation performance. To this end, in this paper, we propose modeling both static interest and negative excitation for dynamic interest to further improve the recommendation performance. Accordingly, we design a novel Static-Dynamic Interest Learning (SDIL) framework featured with a novel Temporal Positive and Negative Excitation Modeling (TPNE) module for accurate sequential recommendation. TPNE is specially designed for comprehensively modeling dynamic interest based on temporal positive and negative excitation learning. Extensive experiments on three real-world datasets show that SDIL can effectively capture both static and dynamic interest and outperforms state-of-the-art baselines.|序贯推荐旨在通过建立用户对项目的兴趣模型来预测下一个用户感兴趣的项目。现有的序贯推荐模型大多是建立在用户对特定项目的动态兴趣的基础上，忽略了项目的静态属性信息(如类别、品牌等)所揭示的用户的静态兴趣。此外，现有的作品往往只考虑用户的历史交互作用对他/她的下一个选择的候选项的正激励，而忽略了普遍存在的负激励，导致不足的建模动态兴趣。忽视静态兴趣和负激励会导致兴趣建模的不完整，从而影响推荐性能。为此，本文提出了静态兴趣模型和动态兴趣的负激励模型，以进一步提高推荐性能。因此，我们设计了一个新颖的静态-动态兴趣学习(SDIL)框架，该框架具有一个新颖的时态正负激励建模(TPNE)模块，用于准确的顺序推荐。TPNE 是一种基于时间正负激励学习的动态兴趣综合建模方法。在三个实际数据集上的大量实验表明，SDIL 能够有效地捕获静态和动态兴趣，并且性能优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Temporal+Positive+and+Negative+Excitation+for+Sequential+Recommendation)|0|
|[Beyond Two-Tower: Attribute Guided Representation Learning for Candidate Retrieval](https://doi.org/10.1145/3543507.3583254)|Hongyu Shan, Qishen Zhang, Zhongyi Liu, Guannan Zhang, Chenliang Li|Wuhan University, China; antgroup, China|Candidate retrieval is a key part of the modern search engines whose goal is to find candidate items that are semantically related to the query from a large item pool. The core difference against the later ranking stage is the requirement of low latency. Hence, two-tower structure with two parallel yet independent encoder for both query and item is prevalent in many systems. In these efforts, the semantic information of a query and a candidate item is fed into the corresponding encoder and then use their representations for retrieval. With the popularity of pre-trained semantic models, the state-of-the-art for semantic retrieval tasks has achieved the significant performance gain. However, the capacity of learning relevance signals is still limited by the isolation between the query and the item. The interaction-based modeling between the query and the item has been widely validated to be useful for the ranking stage, where more computation cost is affordable. Here, we are quite initerested in an demanding question: how to exploiting query-item interaction-based learning to enhance candidate retrieval and still maintain the low computation cost. Note that an item usually contain various heteorgeneous attributes which could help us understand the item characteristics more precisely. To this end, we propose a novel attribute guided representation learning framework (named AGREE) to enhance the candidate retrieval by exploiting query-attribute relevance. The key idea is to couple the query and item representation learning together during the training phase, but also enable easy decoupling for efficient inference. Specifically, we introduce an attribute fusion layer in the item side to identify most relevant item features for item representation. On the query side, an attribute-aware learning process is introduced to better infer the search intent also from these attributes. After model training, we then decouple the attribute information away from the query encoder, which guarantees the low latency for the inference phase. Extensive experiments over two real-world large-scale datasets demonstrate the superiority of the proposed AGREE against several state-of-the-art technical alternatives. Further online A/B test from AliPay search servise also show that AGREE achieves substantial performance gain over four business metrics. Currently, the proposed AGREE has been deployed online in AliPay for serving major traffic.|候选检索是现代搜索引擎的一个关键部分，其目标是从一个大的项目池中查找与查询语义相关的候选项。与后期排名阶段的核心区别在于对低延迟的要求。因此，双塔结构的两个并行但独立的编码器的查询和项目是普遍存在的许多系统。在这些工作中，查询和候选项的语义信息被输入到相应的编码器中，然后使用它们的表示进行检索。随着预训练语义模型的普及，语义检索任务的性能得到了显著提高。然而，相关信号的学习能力仍然受到查询与项目之间隔离的限制。基于交互的查询和项目之间的建模已被广泛验证是有用的排名阶段，其中更多的计算成本是负担得起的。如何利用基于查询项交互的学习来提高候选检索的效率，同时保持较低的计算成本，是本文研究的热点问题。注意，项目通常包含各种异构属性，这些属性可以帮助我们更精确地理解项目特征。为此，我们提出了一种新的属性引导表示学习框架(AGREE) ，利用查询-属性相关性来增强候选检索。其核心思想是在训练阶段将查询和项目表示学习耦合在一起，同时也为有效的推理提供了简单的解耦。具体来说，我们在项目端引入一个属性融合层来识别项目表示中最相关的项目特征。在查询方面，引入了一个感知属性的学习过程，以更好地从这些属性中推断出搜索意图。经过模型训练后，将属性信息与查询编码器解耦，保证了推理阶段的低延迟。通过两个现实世界大规模数据集的大量实验证明了所提议的 AGREE 相对于几种最先进的技术选择的优越性。支付宝搜索服务的进一步在线 A/B 测试也表明，AGREE 在四个业务指标上取得了显著的性能提升。目前，拟议的《支付宝协议》已在支付宝网上部署，以服务主要流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Two-Tower:+Attribute+Guided+Representation+Learning+for+Candidate+Retrieval)|0|
|[Improving Content Retrievability in Search with Controllable Query Generation](https://doi.org/10.1145/3543507.3583261)|Gustavo Penha, Enrico Palumbo, Maryam Aziz, Alice Wang, Hugues Bouchard|Spotify, USA; Spotify, Spain; Spotify, Italy; Spotify, Netherlands|An important goal of online platforms is to enable content discovery, i.e. allow users to find a catalog entity they were not familiar with. A pre-requisite to discover an entity, e.g. a book, with a search engine is that the entity is retrievable, i.e. there are queries for which the system will surface such entity in the top results. However, machine-learned search engines have a high retrievability bias, where the majority of the queries return the same entities. This happens partly due to the predominance of narrow intent queries, where users create queries using the title of an already known entity, e.g. in book search 'harry potter'. The amount of broad queries where users want to discover new entities, e.g. in music search 'chill lyrical electronica with an atmospheric feeling to it', and have a higher tolerance to what they might find, is small in comparison. We focus here on two factors that have a negative impact on the retrievability of the entities (I) the training data used for dense retrieval models and (II) the distribution of narrow and broad intent queries issued in the system. We propose CtrlQGen, a method that generates queries for a chosen underlying intent-narrow or broad. We can use CtrlQGen to improve factor (I) by generating training data for dense retrieval models comprised of diverse synthetic queries. CtrlQGen can also be used to deal with factor (II) by suggesting queries with broader intents to users. Our results on datasets from the domains of music, podcasts, and books reveal that we can significantly decrease the retrievability bias of a dense retrieval model when using CtrlQGen. First, by using the generated queries as training data for dense models we make 9% of the entities retrievable (go from zero to non-zero retrievability). Second, by suggesting broader queries to users, we can make 12% of the entities retrievable in the best case.|在线平台的一个重要目标是支持内容发现，即允许用户找到他们不熟悉的目录实体。使用搜索引擎发现一个实体(例如一本书)的先决条件是该实体是可检索的，也就是说，有一些查询系统将在顶部结果中显示该实体。然而，机器学习搜索引擎有很高的可检索性偏差，其中大多数查询返回相同的实体。这部分是由于狭义意图查询的优势，用户使用已知实体的标题创建查询，例如在图书搜索“哈利波特”。用户希望发现新实体的广泛查询的数量，例如在音乐搜索“寒冷的抒情电子乐与大气的感觉”，并有一个更高的容忍度，他们可能会发现，相比之下是小的。这里我们重点讨论对实体的可检索性有负面影响的两个因素(I)用于密集检索模型的训练数据和(II)系统中发出的狭义和广义意图查询的分布。我们提出了 CtrlQGen，一种为选定的底层意图生成查询的方法——狭义的或者广义的。我们可以使用 CtrlQGen 通过为由不同合成查询组成的密集检索模型生成训练数据来改进 factor (I)。CtrlQGen 还可以通过向用户建议具有更广泛意图的查询来处理 factor (II)。我们对音乐、播客和书籍领域的数据集的研究结果表明，当使用 CtrlQGen 时，我们可以显著降低密集检索模型的可检索性偏差。首先，通过使用生成的查询作为密集模型的训练数据，我们使9% 的实体可检索(从零到非零可检索性)。其次，通过向用户建议更广泛的查询，我们可以使12% 的实体在最佳情况下可检索。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Content+Retrievability+in+Search+with+Controllable+Query+Generation)|0|
|[PIE: Personalized Interest Exploration for Large-Scale Recommender Systems](https://doi.org/10.1145/3543873.3584656)|Khushhall Chandra Mahajan, Amey Porobo Dharwadker, Romil Shah, Simeng Qu, Gaurav Bang, Brad Schumitsch|Meta Inc., USA|Recommender systems are increasingly successful in recommending personalized content to users. However, these systems often capitalize on popular content. There is also a continuous evolution of user interests that need to be captured, but there is no direct way to systematically explore users' interests. This also tends to affect the overall quality of the recommendation pipeline as training data is generated from the candidates presented to the user. In this paper, we present a framework for exploration in large-scale recommender systems to address these challenges. It consists of three parts, first the user-creator exploration which focuses on identifying the best creators that users are interested in, second the online exploration framework and third a feed composition mechanism that balances explore and exploit to ensure optimal prevalence of exploratory videos. Our methodology can be easily integrated into an existing large-scale recommender system with minimal modifications. We also analyze the value of exploration by defining relevant metrics around user-creator connections and understanding how this helps the overall recommendation pipeline with strong online gains in creator and ecosystem value. In contrast to the regression on user engagement metrics generally seen while exploring, our method is able to achieve significant improvements of 3.50% in strong creator connections and 0.85% increase in novel creator connections. Moreover, our work has been deployed in production on Facebook Watch, a popular video discovery and sharing platform serving billions of users.|推荐系统在向用户推荐个性化内容方面越来越成功。然而，这些系统往往利用流行的内容。用户兴趣的不断演变也需要被捕捉，但是没有直接的方法来系统地探索用户的兴趣。这也往往影响推荐管道的总体质量，因为培训数据是从向用户提供的候选人中产生的。在本文中，我们提出了一个大规模推荐系统的探索框架，以解决这些挑战。它由三部分组成，第一部分是用户创建者探索，侧重于确定用户感兴趣的最佳创建者，第二部分是在线探索框架，第三部分是平衡探索和利用的馈送组合机制，以确保探索性视频的最佳流行。我们的方法可以很容易地集成到一个现有的大规模推荐系统中，只需要做很少的修改。我们还通过定义用户-创建者连接的相关度量来分析探索的价值，并了解这如何帮助整个推荐流水线在创建者和生态系统价值方面获得强大的在线收益。与探索过程中常见的用户参与度指标的回归相比，我们的方法能够在强创作者关系中获得3.50% 的显著提高，在新创作者关系中获得0.85% 的显著提高。此外，我们的工作已经部署在 Facebook Watch 上，这是一个流行的视频发现和分享平台，为数十亿用户提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIE:+Personalized+Interest+Exploration+for+Large-Scale+Recommender+Systems)|0|
|[Improving Product Search with Season-Aware Query-Product Semantic Similarity](https://doi.org/10.1145/3543873.3587625)|Haoming Chen, Yetian Chen, Jingjing Meng, Yang Jiao, Yikai Ni, Yan Gao, Michinari Momma, Yi Sun|Harvard University, USA; Amazon.com, USA|Product search for online shopping should be season-aware, i.e., presenting seasonally relevant products to customers. In this paper, we propose a simple yet effective solution to improve seasonal relevance in product search by incorporating seasonality into language models for semantic matching. We first identify seasonal queries and products by analyzing implicit seasonal contexts through time-series analysis over the past year. Then we introduce explicit seasonal contexts by enhancing the query representation with a season token according to when the query is issued. A new season-enhanced BERT model (SE-BERT) is also proposed to learn the semantic similarity between the resulting seasonal queries and products. SE-BERT utilizes Multi-modal Adaption Gate (MAG) to augment the season-enhanced semantic embedding with other contextual information such as product price and review counts for robust relevance prediction. To better align with the ranking objective, a listwise loss function (neural NDCG) is used to regularize learning. Experimental results validate the effectiveness of the proposed method, which outperforms existing solutions for query-product relevance prediction in terms of NDCG and Price Weighted Purchases (PWP).|网上购物的产品搜寻应具有季节性，即向顾客展示季节性相关的产品。在本文中，我们提出了一个简单而有效的解决方案，以改善产品搜索的季节性相关性，将季节性纳入语义匹配的语言模型。我们首先通过对过去一年的时间序列分析，分析隐含的季节性背景，识别出季节性查询和产品。然后根据查询发出的时间，使用季节标记增强查询表示，从而引入明确的季节上下文。提出了一种新的季节增强 BERT 模型(SE-BERT) ，用于学习产生的季节查询与产品之间的语义相似性。该算法利用多模态自适应门(MAG)增强季节增强语义嵌入，并结合产品价格和评论计数等上下文信息进行鲁棒相关性预测。为了更好地与排名目标保持一致，一个列表损失函数(神经 NDCG)被用来规范学习。实验结果验证了该方法的有效性，在 NDCG 和价格加权购买(PWP)方面优于现有的查询产品相关性预测方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Product+Search+with+Season-Aware+Query-Product+Semantic+Similarity)|0|
|[Blend and Match: Distilling Semantic Search Models with Different Inductive Biases and Model Architectures](https://doi.org/10.1145/3543873.3587629)|Hamed Bonab, Ashutosh Joshi, Ravi Bhatia, Ankit Gandhi, Vijay Huddar, Juhi Naik, Mutasem AlDarabsah, Choon Hui Teo, Jonathan May, Tarun Agarwal, Vaclav Petricek|Amazon, USA and USC Information Sciences Institute, USA; Amazon, India; Amazon, USA|Commercial search engines use different semantic models to augment lexical matches. These models provide candidate items for a user’s query from a target space of millions to billions of items. Models with different inductive biases provide relatively different predictions, making it desirable to launch multiple semantic models in production. However, latency and resource constraints make simultaneously deploying multiple models impractical. In this paper, we introduce a distillation approach, called Blend and Match (BM), to unify two different semantic search models into a single model. We use a Bi-encoder semantic matching model as our primary model and propose a novel loss function to incorporate eXtreme Multi-label Classification (XMC) predictions as the secondary model. Our experiments conducted on two large-scale datasets, collected from a popular e-commerce store, show that our proposed approach significantly improves the recall of the primary Bi-encoder model by 11% to 17% with a minimal loss in precision. We show that traditional knowledge distillation approaches result in a sub-optimal performance for our problem setting, and our BM approach yields comparable rankings with strong Rank Fusion (RF) methods used only if one could deploy multiple models.|商业搜索引擎使用不同的语义模型来增加词汇匹配。这些模型为用户的查询提供从数百万到数十亿的候选项。具有不同归纳偏差的模型提供了相对不同的预测，因此在生产环境中启动多个语义模型是可取的。然而，延迟和资源限制使得同时部署多个模型不切实际。在本文中，我们引入了一种称为“混合与匹配”(Blend and Match，BM)的提取方法，将两个不同的语义搜索模型统一到一个单一的模型中。我们使用一个双编码器语义匹配模型作为我们的主要模型，并提出了一个新的损失函数合并 eXtreme 多标签分类(XMC)预测作为次要模型。我们在两个大规模数据集上进行的实验，从一个流行的电子商务商店收集，表明我们提出的方法显着提高了11% 至17% 的主要双编码器模型的召回率，最小的精度损失。我们表明，传统的知识提取方法导致次优的性能为我们的问题设置，和我们的 BM 方法产生可比的排名与强秩融合(RF)方法只有当一个人可以部署多个模型使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Blend+and+Match:+Distilling+Semantic+Search+Models+with+Different+Inductive+Biases+and+Model+Architectures)|0|
|[Joint Internal Multi-Interest Exploration and External Domain Alignment for Cross Domain Sequential Recommendation](https://doi.org/10.1145/3543507.3583366)|Weiming Liu, Xiaolin Zheng, Chaochao Chen, Jiajie Su, Xinting Liao, Mengling Hu, Yanchao Tan|Fuzhou Univerisity, China; Zhejiang University, China|Sequential Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge and users’ historical behaviors for the next-item prediction. In this paper, we focus on the cross-domain sequential recommendation problem. This commonly exist problem is rather challenging from two perspectives, i.e., the implicit user historical rating sequences are difficult in modeling and the users/items on different domains are mostly non-overlapped. Most previous sequential CDR approaches cannot solve the cross-domain sequential recommendation problem well, since (1) they cannot sufficiently depict the users’ actual preferences, (2) they cannot leverage and transfer useful knowledge across domains. To tackle the above issues, we propose joint Internal multi-interest exploration and External domain alignment for cross domain Sequential Recommendation model (IESRec). IESRec includes two main modules, i.e., internal multi-interest exploration module and external domain alignment module. To reflect the users’ diverse characteristics with multi-interests evolution, we first propose internal temporal optimal transport method in the internal multi-interest exploration module. We further propose external alignment optimal transport method in the external domain alignment module to reduce domain discrepancy for the item embeddings. Our empirical studies on Amazon datasets demonstrate that IESRec significantly outperforms the state-of-the-art models.|序贯跨域推荐(CDR)是一种利用不同领域知识和用户历史行为进行下一个项目预测的方法。本文主要研究跨域序列推荐问题。这个常见的问题从两个方面来看都是相当具有挑战性的，即隐式用户历史评分序列难以建模，而且不同领域的用户/项目大多是非重叠的。以往的顺序 CDR 方法不能很好地解决跨域顺序推荐问题，因为(1)它们不能充分描述用户的实际偏好，(2)它们不能利用和跨域传递有用的知识。为了解决上述问题，我们提出了跨域序列推荐模型(IESRec)的内部多利益探索和外部域对齐的联合方法。IESRec 主要包括两个模块，即内部多兴趣探索模块和外部域对齐模块。为了反映用户的多样性特征和多种利益的演化，我们首先在内部多种利益探索模块中提出了内部时间最优传输方法。进一步提出了外域对齐模块中的外域对齐最优传输方法，以减少项目嵌入时的域差异。我们对亚马逊数据集的实证研究表明，IESRec 明显优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Internal+Multi-Interest+Exploration+and+External+Domain+Alignment+for+Cross+Domain+Sequential+Recommendation)|0|
|[Latent User Intent Modeling for Sequential Recommenders](https://doi.org/10.1145/3543873.3584641)|Bo Chang, Alexandros Karatzoglou, Yuyan Wang, Can Xu, Ed H. Chi, Minmin Chen|Google, USA|Sequential recommender models are essential components of modern industrial recommender systems. These models learn to predict the next items a user is likely to interact with based on his/her interaction history on the platform. Most sequential recommenders however lack a higher-level understanding of user intents, which often drive user behaviors online. Intent modeling is thus critical for understanding users and optimizing long-term user experience. We propose a probabilistic modeling approach and formulate user intent as latent variables, which are inferred based on user behavior signals using variational autoencoders (VAE). The recommendation policy is then adjusted accordingly given the inferred user intent. We demonstrate the effectiveness of the latent user intent modeling via offline analyses as well as live experiments on a large-scale industrial recommendation platform.|序贯推荐模型是现代工业推荐系统的重要组成部分。这些模型学习根据用户在平台上的交互历史来预测用户可能与之交互的下一个项目。然而，大多数顺序推荐系统缺乏对用户意图的更高层次的理解，这往往会驱动用户在线行为。因此，意图建模对于理解用户和优化长期用户体验至关重要。提出了一种基于变分自动编码器(VAE)的基于用户行为信号的概率建模方法，并将用户意图表示为潜变量。然后根据推断出的用户意图相应地调整推荐策略。通过离线分析以及在大规模工业推荐平台上的实验，验证了潜在用户意图建模的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Latent+User+Intent+Modeling+for+Sequential+Recommenders)|0|
|[Deep Neural Network with LinUCB: A Contextual Bandit Approach for Personalized Recommendation](https://doi.org/10.1145/3543873.3587684)|Qicai Shi, Feng Xiao, Douglas Pickard, Inga Chen, Liang Chen|Disneystreaming, China; Disneystreaming, USA|Recommender systems are widely used in many Web applications to recommend items which are relevant to a user’s preferences. However, focusing on exploiting user preferences while ignoring exploration will lead to biased feedback and hurt the user’s experience in the long term. The Mutli-Armed Bandit (MAB) is introduced to balance the tradeoff between exploitation and exploration. By utilizing context information in the reward function, contextual bandit algorithms lead to better performance compared to context-free bandit algorithms. However, existing contextual bandit algorithms either assume a linear relation between the expected reward and context features, whose representation power gets limited, or use a deep neural network in the reward function which is impractical in implementation. In this paper, we propose a new contextual bandit algorithm, DeepLinUCB, which leverages the representation power of deep neural network to transform the raw context features in the reward function. Specifically, this deep neural network is dedicated to the recommender system, which is efficient and practical in real-world applications. Furthermore, we conduct extensive experiments in our online recommender system using requests from real-world scenarios and show that DeepLinUCB is efficient and outperforms other bandit algorithms.|在许多 Web 应用程序中，推荐系统被广泛用于推荐与用户首选项相关的项目。然而，只关注用户偏好而忽视探索将导致偏见的反馈，从长远来看会损害用户的体验。为了平衡开发与勘探之间的权衡，引进了多臂匪。通过在奖励函数中利用上下文信息，上下文盗贼算法比无上下文盗贼算法具有更好的性能。然而，现有的上下文盗贼算法要么假定期望奖励与上下文特征之间存在线性关系，其表示能力受到限制，要么在奖励函数中使用深度神经网络，这在实现上是不切实际的。本文提出了一种新的上下文盗贼算法 DeepLinUCB，该算法利用深层神经网络的表示能力来转换奖励函数中的原始上下文特征。具体来说，这种深层神经网络专门用于推荐系统，在实际应用中非常有效和实用。此外，我们使用来自现实场景的请求，在我们的在线推荐系统中进行了大量的实验，结果表明 DeepLinUCB 是高效的，并且优于其他盗贼算法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Neural+Network+with+LinUCB:+A+Contextual+Bandit+Approach+for+Personalized+Recommendation)|0|
|[Contrastive Collaborative Filtering for Cold-Start Item Recommendation](https://doi.org/10.1145/3543507.3583286)|Zhihui Zhou, Lilin Zhang, Ning Yang|Sichuan University, China|The cold-start problem is a long-standing challenge in recommender systems. As a promising solution, content-based generative models usually project a cold-start item's content onto a warm-start item embedding to capture collaborative signals from item content so that collaborative filtering can be applied. However, since the training of the cold-start recommendation models is conducted on warm datasets, the existent methods face the issue that the collaborative embeddings of items will be blurred, which significantly degenerates the performance of cold-start item recommendation. To address this issue, we propose a novel model called Contrastive Collaborative Filtering for Cold-start item Recommendation (CCFCRec), which capitalizes on the co-occurrence collaborative signals in warm training data to alleviate the issue of blurry collaborative embeddings for cold-start item recommendation. In particular, we devise a contrastive collaborative filtering (CF) framework, consisting of a content CF module and a co-occurrence CF module to generate the content-based collaborative embedding and the co-occurrence collaborative embedding for a training item, respectively. During the joint training of the two CF modules, we apply a contrastive learning between the two collaborative embeddings, by which the knowledge about the co-occurrence signals can be indirectly transferred to the content CF module, so that the blurry collaborative embeddings can be rectified implicitly by the memorized co-occurrence collaborative signals during the applying phase. Together with the sound theoretical analysis, the extensive experiments conducted on real datasets demonstrate the superiority of the proposed model. The codes and datasets are available on https://github.com/zzhin/CCFCRec.|在推荐系统中，冷启动问题是一个长期存在的挑战。作为一种有前途的解决方案，基于内容的生成模型通常将一个冷启动项目的内容投射到一个嵌入的热启动项目上，以从项目内容中捕获协作信号，从而可以应用协同过滤。然而，由于冷启动推荐模型的训练是在暖数据集上进行的，现有的方法面临着项目协同嵌入模糊的问题，这严重影响了冷启动项目推荐的性能。为了解决这个问题，我们提出了一个新的模型，称为冷启动项目推荐对比协同过滤(CCFCrec) ，它利用共现协作信号在暖培训数据，以减轻问题模糊的协作嵌入冷启动项目推荐。特别地，我们设计了一个对比协同过滤(CF)框架，由一个内容 CF 模块和一个共现 CF 模块组成，分别为一个培训项目生成基于内容的协同嵌入和共现协同嵌入。在两个 CF 模块的联合训练中，我们对两个协同嵌入进行了对比学习，通过对比学习可以将关于共现信号的知识间接转移到内容 CF 模块中，从而在应用阶段可以通过记忆共现协同信号来隐式纠正模糊的协同嵌入。通过在实际数据集上的大量实验，结合理论分析，证明了该模型的优越性。代码和数据集可在 https://github.com/zzhin/ccfcrec 上获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Collaborative+Filtering+for+Cold-Start+Item+Recommendation)|0|
|[ColdNAS: Search to Modulate for User Cold-Start Recommendation](https://doi.org/10.1145/3543507.3583344)|Shiguang Wu, Yaqing Wang, Qinghe Jing, Daxiang Dong, Dejing Dou, Quanming Yao|Baidu Inc., China; Electronic Engineering, Tsinghua University, China|Making personalized recommendation for cold-start users, who only have a few interaction histories, is a challenging problem in recommendation systems. Recent works leverage hypernetworks to directly map user interaction histories to user-specific parameters, which are then used to modulate predictor by feature-wise linear modulation function. These works obtain the state-of-the-art performance. However, the physical meaning of scaling and shifting in recommendation data is unclear. Instead of using a fixed modulation function and deciding modulation position by expertise, we propose a modulation framework called ColdNAS for user cold-start problem, where we look for proper modulation structure, including function and position, via neural architecture search. We design a search space which covers broad models and theoretically prove that this search space can be transformed to a much smaller space, enabling an efficient and robust one-shot search algorithm. Extensive experimental results on benchmark datasets show that ColdNAS consistently performs the best. We observe that different modulation functions lead to the best performance on different datasets, which validates the necessity of designing a searching-based method. Codes are available at https://github.com/LARS-research/ColdNAS.|在推荐系统中，为只有少量交互历史的冷启动用户进行个性化推荐是一个具有挑战性的问题。最近的研究利用超网络将用户交互历史直接映射到用户特定的参数，然后用特征线性调制函数对预测器进行调制。这些作品获得了最先进的表演水平。然而，推荐数据的缩放和转移的物理意义尚不清楚。为了解决用户冷启动问题，我们提出了一种称为 ColdNAS 的调制框架，该框架通过神经结构搜索寻找合适的调制结构，包括功能和位置，而不是使用固定的调制函数来确定调制位置。我们设计了一个覆盖广泛模型的搜索空间，并从理论上证明了这个搜索空间可以转换成更小的空间，从而实现了一种高效、鲁棒的一次性搜索算法。在基准数据集上的大量实验结果表明，ColdNAS 始终表现最好。我们观察到不同的调制函数对不同的数据集产生最佳的性能，这验证了设计一种基于搜索的方法的必要性。密码可在 https://github.com/lars-research/coldnas 索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ColdNAS:+Search+to+Modulate+for+User+Cold-Start+Recommendation)|0|
|[Improving the Relevance of Product Search for Queries with Negations](https://doi.org/10.1145/3543873.3587319)|Felice Antonio Merra, Omar Zaidan, Fabricio de Sousa Nascimento|Amazon, Japan; Amazon, Germany|Product search engines (PSEs) play an essential role in retail websites as they make it easier for users to retrieve relevant products within large catalogs. Despite the continuous progress that has led to increasingly accurate search engines, a limited focus has been given to their performance on queries with negations. Indeed, while we would expect to retrieve different products for the queries “iPhone 13 cover with ring” and “iPhone 13 cover without ring”, this does not happen in popular PSEs with the latter query containing results with the unwanted ring component. The limitation of modern PSEs in understanding negations motivates the need for further investigation. In this work, we start by defining the negation intent in users queries. Then, we design a transformer-based model, named Negation Detector for Queries (ND4Q), that reaches optimal performance in negation detection (+95% on accuracy metrics). Finally, having built the first negation detector for product search queries, we propose a negation-aware filtering strategy, named Filtering Irrelevant Products (FIP). The promising experimental results in improve the PSE relevance performance using FIP (+9.41% on [email protected] for queries where the negation starts with "without") pave the way to additional research effort towards negation-aware PSEs.|产品搜索引擎(PSE)在零售网站中发挥着重要作用，因为它们使用户更容易在大型目录中检索相关产品。尽管不断取得进展，导致搜索引擎越来越准确，但对否定查询的性能关注有限。事实上，虽然我们期望检索不同的产品的查询“ iPhone13盖有戒指”和“ iPhone13盖无戒指”，这不会发生在流行的 PSE 与后者的查询包含不想要的戒指组件的结果。现代 PSE 在理解否定方面的局限性促使了进一步研究的必要性。在这项工作中，我们首先定义用户查询中的否定意图。然后，我们设计了一个基于变压器的模型，称为查询否定检测器(ND4Q) ，它在否定检测中达到了最佳的性能(在准确性指标上 + 95%)。最后，在构建了产品搜索查询的第一个否定检测器的基础上，提出了一种基于否定感知的过滤策略——过滤不相关产品(FIP)。使用 FIP (对于否定以“无”开头的查询，[ email protected ]增加9.41%)改善 PSE 相关性的有希望的实验结果为针对具有否定意识的 PSE 的额外研究努力铺平了道路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+the+Relevance+of+Product+Search+for+Queries+with+Negations)|0|
|[Movie Ticket, Popcorn, and Another Movie Next Weekend: Time-Aware Service Sequential Recommendation for User Retention](https://doi.org/10.1145/3543873.3584628)|Xiaoyan Yang, Dong Wang, Binbin Hu, Dan Yang, Yue Shen, Jinjie Gu, Zhiqiang Zhang, Shiwei Lyu, Haipeng Zhang, Guannan Zhang|Ant Group, China; ShanghaiTech University, China|When a customer sees a movie recommendation, she may buy the ticket right away, which is the immediate feedback that helps improve the recommender system. Alternatively, she may choose to come back later and this long-term feedback is also modeled to promote user retention. However, the long-term feedback comes with non-trivial challenges in understanding user retention: the complicated correlation between current demands and follow-up demands, coupled with the periodicity of services. For instance, before the movie, the customer buys popcorn through the App, which temporally correlates with the initial movie recommendation. Days later, she checks the App for new movies, as a weekly routine. To address this complexity in a more fine-grained revisit modeling, we propose Time Aware Service Sequential Recommendation (TASSR) for user retention, which is equipped with a multi-task design and an In-category TimeSeqBlock module. Large-scale online and offline experiments demonstrate its significant advantages over competitive baselines.|当顾客看到一部电影的推荐信时，她可能会马上买票，这是一种即时的反馈，有助于提高推荐系统。或者，她可以选择以后再来，这种长期的反馈也被建模以促进用户保留。然而，长期的反馈在理解用户保留方面带来了重大挑战: 当前需求和后续需求之间的复杂关系，以及服务的周期性。例如，在看电影之前，客户通过 App 购买爆米花，这在时间上与最初的电影推荐相关。几天后，她每周例行检查应用程序是否有新电影。为了在更细粒度的再访问建模中解决这一复杂性，我们提出了用于用户保持的时间感知服务序列推荐(TASSR) ，该推荐配备了多任务设计和同类 TimeSeqBlock 模块。大规模的在线和离线实验证明了它相对于竞争基线的显著优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Movie+Ticket,+Popcorn,+and+Another+Movie+Next+Weekend:+Time-Aware+Service+Sequential+Recommendation+for+User+Retention)|0|
|[Unified Vision-Language Representation Modeling for E-Commerce Same-style Products Retrieval](https://doi.org/10.1145/3543873.3584632)|Ben Chen, Linbo Jin, Xinxin Wang, Dehong Gao, Wen Jiang, Wei Ning|Alibaba Group, China; Aliaba Group, China|Same-style products retrieval plays an important role in e-commerce platforms, aiming to identify the same products which may have different text descriptions or images. It can be used for similar products retrieval from different suppliers or duplicate products detection of one supplier. Common methods use the image as the detected object, but they only consider the visual features and overlook the attribute information contained in the textual descriptions, and perform weakly for products in image less important industries like machinery, hardware tools and electronic component, even if an additional text matching module is added. In this paper, we propose a unified vision-language modeling method for e-commerce same-style products retrieval, which is designed to represent one product with its textual descriptions and visual contents. It contains one sampling skill to collect positive pairs from user click log with category and relevance constrained, and a novel contrastive loss unit to model the image, text, and image+text representations into one joint embedding space. It is capable of cross-modal product-to-product retrieval, as well as style transfer and user-interactive search. Offline evaluations on annotated data demonstrate its superior retrieval performance, and online testings show it can attract more clicks and conversions. Moreover, this model has already been deployed online for similar products retrieval in alibaba.com, the largest B2B e-commerce platform in the world.|同类产品检索在电子商务平台中起着重要作用，其目的是识别具有不同文本描述或图像的同类产品。它可用于从不同供应商检索相似产品或检测一个供应商的重复产品。一般的检测方法都是以图像作为检测对象，但它们只考虑视觉特征，忽略了文本描述中的属性信息，对于机械、硬件工具和电子元件等图像不太重要的行业的产品，即使增加了额外的文本匹配模块，检测效果也很差。本文提出了一种统一的电子商务同类产品检索的视觉语言建模方法。它包含一种采样技巧，用于从类别和相关性受限的用户点击日志中收集正对，以及一种新的对比度损失单元，用于将图像、文本和图像 + 文本表示建模为一个联合嵌入空间。它能够进行跨模式的产品对产品检索，以及样式转移和用户交互式搜索。对注释数据的离线评估表明它具有优越的检索性能，在线测试表明它可以吸引更多的点击和转换。此外，该模型已经在全球最大的 B2B 电子商务平台阿里巴巴网站(alibaba.com)的类似产品检索中得到应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Vision-Language+Representation+Modeling+for+E-Commerce+Same-style+Products+Retrieval)|0|
|[Task Adaptive Multi-learner Network for Joint CTR and CVR Estimation](https://doi.org/10.1145/3543873.3584653)|Xiaofan Liu, Qinglin Jia, Chuhan Wu, Jingjie Li, Quanyu Dai, Lin Bo, Rui Zhang, Ruiming Tang|ruizhang.info, China; Huawei Noah's Ark Lab, China; Renmin University of China, China; Beijing University of Posts and Telecommunications, China|CTR and CVR are critical factors in personalized applications, and many methods jointly estimate them via multi-task learning to alleviate the ultra-sparsity of conversion behaviors. However, it is still difficult to predict CVR accurately and robustly due to the limited and even biased knowledge extracted by the single model tower optimized on insufficient conversion samples. In this paper, we propose a task adaptive multi-learner (TAML) framework for joint CTR and CVR prediction. We design a hierarchical task adaptive knowledge representation module with different experts to capture knowledge in different granularities, which can effectively exploit the commonalities between CTR and CVR estimation tasks meanwhile keeping their unique characteristics. We apply multiple learners to extract data knowledge from various views and fuse their predictions to obtain accurate and robust scores. To facilitate knowledge sharing across learners, we further perform self-distillation that uses the fused scores to teach different learners. Thorough offline and online experiments show the superiority of TAML in different Ad ranking tasks, and we have deployed it in Huawei’s online advertising platform to serve the main traffic.|CTR 和 CVR 是个性化应用中的关键因素，多种方法通过多任务学习来联合估计它们，以减轻转换行为的超稀疏性。然而，由于单模型塔在转换样本不足的情况下进行了优化，提取的知识有限，甚至有偏差，因此仍然难以准确、稳健地预测 CVR。本文提出了一个任务自适应多学习器(TAML)框架，用于联合 CTR 和 CVR 预测。设计了一个分层任务自适应知识表示模块，采用不同的专家来获取不同粒度的知识，有效地利用了 CTR 和 CVR 估计任务的共性，同时保持了它们的独特性。我们应用多个学习者从不同的角度提取数据知识，并融合他们的预测，以获得准确和稳健的分数。为了促进学习者之间的知识共享，我们进一步使用融合分数来教授不同的学习者。通过线下和线上的实验，我们发现了 TAML 在不同广告排名任务中的优势，并将其应用于华为的在线广告平台，为主要流量提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task+Adaptive+Multi-learner+Network+for+Joint+CTR+and+CVR+Estimation)|0|
|[Deep Intention-Aware Network for Click-Through Rate Prediction](https://doi.org/10.1145/3543873.3584661)|Yaxian Xia, Yi Cao, Sihao Hu, Tong Liu, Lingling Lu|Alibaba Group, China; Georgia Institute of Technology, USA; Zhejiang University, China|E-commerce platforms provide entrances for customers to enter mini-apps that can meet their specific shopping requirements. Trigger items displayed on entrance icons can attract more entering. However, conventional Click-Through-Rate (CTR) prediction models, which ignore user instant interest in trigger item, fail to be applied to the new recommendation scenario dubbed Trigger-Induced Recommendation in Mini-Apps (TIRA). Moreover, due to the high stickiness of customers to mini-apps, we argue that existing trigger-based methods that over-emphasize the importance of trigger items, are undesired for TIRA, since a large portion of customer entries are because of their routine shopping habits instead of triggers. We identify that the key to TIRA is to extract customers' personalized entering intention and weigh the impact of triggers based on this intention. To achieve this goal, we convert CTR prediction for TIRA into a separate estimation form, and present Deep Intention-Aware Network (DIAN) with three key elements: 1) Intent Net that estimates user's entering intention, i.e., whether he/she is affected by the trigger or by the habits; 2) Trigger-Aware Net and 3) Trigger-Free Net that estimate CTRs given user's intention is to the trigger-item and the mini-app respectively. Following a joint learning way, DIAN can both accurately predict user intention and dynamically balance the results of trigger-free and trigger-based recommendations based on the estimated intention. Experiments show that DIAN advances state-of-the-art performance in a large real-world dataset, and brings a 9.39% lift of online Item Page View and 4.74% CTR for Juhuasuan, a famous mini-app of Taobao.|电子商务平台为客户提供了进入迷你应用程序，可以满足他们的具体购物需求。触发项目显示在入口图标可以吸引更多的进入。然而，传统的点击率(Click-Through-Rate，CTR)预测模型忽略了用户对触发条目的即时兴趣，无法应用于被称为微型应用程序中的触发诱导推荐(Trigger-)的新推荐场景。此外，由于客户对迷你应用程序的高粘性，我们认为，现有的基于触发器的方法，过分强调触发项目的重要性，是不希望 TIRA，因为大部分客户进入是因为他们的日常购物习惯，而不是触发器。我们认为，TIRA 的关键是提取顾客的个性化进入意图，并根据这一意图权衡触发因素的影响。为了实现这一目标，我们将 TIRA 的 CTR 预测转化为一个单独的估计形式，并提出深度意图感知网络(DIAN)的三个关键要素: 1)意图网络，估计用户的进入意图，即他/她是否受到触发器或习惯的影响; 2)触发感知网络和3)无触发网络，估计给定用户意图的 CTR 分别是触发项目和迷你应用程序。DIAN 采用联合学习的方法，既能准确预测用户意图，又能根据预测意图动态平衡无触发和基于触发的推荐结果。实验表明，DIAN 在一个大型现实数据集中提升了最先进的性能，使在线项目页面查看率提高了9.39% ，淘宝著名小应用聚花酸的点击率提高了4.74% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Intention-Aware+Network+for+Click-Through+Rate+Prediction)|0|
|[Search Personalization at Netflix](https://doi.org/10.1145/3543873.3587675)|Vito Ostuni, Christoph Kofler, Manjesh Nilange, Sudarshan Lamkhede, Dan Zylberglejd|Netflix Inc., USA|At Netflix, personalization plays a key role in several aspects of our user experience, from ranking titles to constructing an optimal Homepage. Although personalization is a well established research field, its application to search presents unique problems and opportunities. In this paper, we describe the evolution of Search personalization at Netflix, its unique challenges, and provide a high level overview of relevant solutions.|在 Netflix，个性化在我们的用户体验的几个方面起着关键作用，从排名标题到建立一个最佳的主页。虽然个性化是一个成熟的研究领域，但是它在搜索中的应用却带来了独特的问题和机遇。在本文中，我们描述了在 Netflix 搜索个性化的演变，其独特的挑战，并提供了相关解决方案的高层次概述。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search+Personalization+at+Netflix)|0|
|[Pretrained Embeddings for E-commerce Machine Learning: When it Fails and Why?](https://doi.org/10.1145/3543873.3587669)|Da Xu, Bo Yang|LinkedIn, USA; Amazon, USA|The use of pretrained embeddings has become widespread in modern e-commerce machine learning (ML) systems. In practice, however, we have encountered several key issues when using pretrained embedding in a real-world production system, many of which cannot be fully explained by current knowledge. Unfortunately, we find that there is a lack of a thorough understanding of how pre-trained embeddings work, especially their intrinsic properties and interactions with downstream tasks. Consequently, it becomes challenging to make interactive and scalable decisions regarding the use of pre-trained embeddings in practice.   Our investigation leads to two significant discoveries about using pretrained embeddings in e-commerce applications. Firstly, we find that the design of the pretraining and downstream models, particularly how they encode and decode information via embedding vectors, can have a profound impact. Secondly, we establish a principled perspective of pre-trained embeddings via the lens of kernel analysis, which can be used to evaluate their predictability, interactively and scalably. These findings help to address the practical challenges we faced and offer valuable guidance for successful adoption of pretrained embeddings in real-world production. Our conclusions are backed by solid theoretical reasoning, benchmark experiments, as well as online testings.|在现代电子商务机器学习(ML)系统中，预训练嵌入技术已经得到了广泛的应用。然而，在实践中，我们遇到了几个关键问题，当使用预训练嵌入在一个真实的生产系统，其中许多不能完全解释现有的知识。不幸的是，我们发现缺乏对预先训练的嵌入如何工作的透彻理解，特别是它们的内在属性和与下游任务的交互。因此，在实践中使用预先训练的嵌入方法时，做出交互式和可扩展的决策变得具有挑战性。我们的调查导致两个重要的发现，使用预训练嵌入在电子商务应用程序。首先，我们发现预训练和下游模型的设计，特别是它们如何通过嵌入向量对信息进行编码和解码，会产生深远的影响。其次，通过核分析的视角，建立了预训练嵌入的原则性视角，可以用来评估预训练嵌入的可预测性、交互性和可扩展性。这些发现有助于解决我们面临的实际挑战，并为在现实生产中成功采用预先培训的嵌入提供了宝贵的指导。我们的结论得到了可靠的理论推理、基准实验以及在线测试的支持。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pretrained+Embeddings+for+E-commerce+Machine+Learning:+When+it+Fails+and+Why?)|0|
|[GELTOR: A Graph Embedding Method based on Listwise Learning to Rank](https://doi.org/10.1145/3543507.3583193)|Masoud Reyhani Hamedani, JinSu Ryu, SangWook Kim|Hanyang University, Republic of Korea|Similarity-based embedding methods have introduced a new perspective on graph embedding by conforming the similarity distribution of latent vectors in the embedding space to that of nodes in the graph; they show significant effectiveness over conventional embedding methods in various machine learning tasks. In this paper, we first point out the three drawbacks of existing similarity-based embedding methods: inaccurate similarity computation, conflicting optimization goal, and impairing in/out-degree distributions. Then, motivated by these drawbacks, we propose AdaSim*, a novel similarity measure for graphs that is conducive to the similarity-based graph embedding. We finally propose GELTOR, an effective embedding method that employs AdaSim* as a node similarity measure and the concept of learning-to-rank in the embedding process. Contrary to existing methods, GELTOR does not learn the similarity scores distribution; instead, for any target node, GELTOR conforms the ranks of its top-t similar nodes in the embedding space to their original ranks based on AdaSim* scores. We conduct extensive experiments with six real-world datasets to evaluate the effectiveness of GELTOR in graph reconstruction, link prediction, and node classification tasks. Our experimental results show that (1) AdaSim* outperforms AdaSim, RWR, and MCT in computing nodes similarity in graphs, (2) our GETLOR outperforms existing state-of-the-arts and conventional embedding methods in most cases of the above machine learning tasks, thereby implying that learning-to-rank is beneficial to graph embedding.|基于相似性的嵌入方法通过调整嵌入空间中潜在向量与图中节点的相似性分布，为图的嵌入提供了一个新的视角，它们在各种机器学习任务中显示出比传统的嵌入方法更为有效的效果。本文首先指出了现有的基于相似度的嵌入方法存在的三个缺点: 相似度计算不准确、优化目标冲突和损伤内外度分布。然后，基于这些缺点，我们提出了 AdaSim * ，这是一种新的图的相似性度量，有利于基于相似性的图嵌入。最后提出了一种有效的嵌入方法 GELTOR，该方法采用 AdaSim * 作为节点相似性度量，并在嵌入过程中引入了学习排序的概念。与现有的方法相反，GELTOR 不学习相似度分数分布; 相反，对于任何目标节点，GELTOR 根据 AdaSim * 分数将其嵌入空间中的顶部 -t 相似节点的排名与其原始排名保持一致。我们使用六个真实世界的数据集进行了广泛的实验，以评估 GELTOR 在图重建、链路预测和节点分类任务中的有效性。我们的实验结果表明: (1) AdaSim * 在计算图中节点相似度方面优于 AdaSim，RWR 和 MCT; (2)在上述机器学习任务的大多数情况下，我们的 GETLOR 优于现有的最先进的和传统的嵌入方法，从而意味着学习排序有利于图嵌入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GELTOR:+A+Graph+Embedding+Method+based+on+Listwise+Learning+to+Rank)|0|
|[On the Theories Behind Hard Negative Sampling for Recommendation](https://doi.org/10.1145/3543507.3583223)|Wentao Shi, Jiawei Chen, Fuli Feng, Jizhi Zhang, Junkang Wu, Chongming Gao, Xiangnan He|Zhejiang University, China; University of Science and Technology of China, China|Negative sampling has been heavily used to train recommender models on large-scale data, wherein sampling hard examples usually not only accelerates the convergence but also improves the model accuracy. Nevertheless, the reasons for the effectiveness of Hard Negative Sampling (HNS) have not been revealed yet. In this work, we fill the research gap by conducting thorough theoretical analyses on HNS. Firstly, we prove that employing HNS on the Bayesian Personalized Ranking (BPR) learner is equivalent to optimizing One-way Partial AUC (OPAUC). Concretely, the BPR equipped with Dynamic Negative Sampling (DNS) is an exact estimator, while with softmax-based sampling is a soft estimator. Secondly, we prove that OPAUC has a stronger connection with Top-K evaluation metrics than AUC and verify it with simulation experiments. These analyses establish the theoretical foundation of HNS in optimizing Top-K recommendation performance for the first time. On these bases, we offer two insightful guidelines for effective usage of HNS: 1) the sampling hardness should be controllable, e.g., via pre-defined hyper-parameters, to adapt to different Top-K metrics and datasets; 2) the smaller the $K$ we emphasize in Top-K evaluation metrics, the harder the negative samples we should draw. Extensive experiments on three real-world benchmarks verify the two guidelines.|负抽样已经被广泛用于大规模数据的推荐模型训练，而硬实例抽样不仅可以加快模型的收敛速度，而且可以提高模型的精度。然而，硬性负样本(HNS)有效性的原因尚未被揭示。本文通过对 HNS 进行深入的理论分析，填补了研究空白。首先，我们证明了对贝叶斯个性化排序(BPR)学习者使用 HNS 等价于优化单向部分 AUC (OPAUC)。具体来说，装有动态负抽样(DNS)的 BPR 是一个精确估计量，而基于软最大抽样的 BPR 是一个软估计量。其次，我们证明了 OPAUC 与 Top-K 评价指标之间的联系比 AUC 更强，并通过仿真实验进行了验证。这些分析首次为 HNS 优化 Top-K 推荐性能奠定了理论基础。在此基础上，我们为有效使用 HNS 提供了两个有见地的指导方针: 1)抽样硬度应该是可控的，例如，通过预定义的超参数，以适应不同的 Top-K 指标和数据集; 2)我们在 Top-K 评估指标中强调的 $K $越小，我们应该抽取的负面样本就越难。在三个真实世界的基准上进行的大量实验验证了这两条准则。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Theories+Behind+Hard+Negative+Sampling+for+Recommendation)|0|
|[A Counterfactual Collaborative Session-based Recommender System](https://doi.org/10.1145/3543507.3583321)|Wenzhuo Song, Shoujin Wang, Yan Wang, Kunpeng Liu, Xueyan Liu, Minghao Yin|University of Technology Sydney, Australia; Portland State University, USA; Macquarie University, Australia; Jilin University, China; Northeast Normal University, China|Most session-based recommender systems (SBRSs) focus on extracting information from the observed items in the current session of a user to predict a next item, ignoring the causes outside the session (called outer-session causes, OSCs) that influence the user's selection of items. However, these causes widely exist in the real world, and few studies have investigated their role in SBRSs. In this work, we analyze the causalities and correlations of the OSCs in SBRSs from the perspective of causal inference. We find that the OSCs are essentially the confounders in SBRSs, which leads to spurious correlations in the data used to train SBRS models. To address this problem, we propose a novel SBRS framework named COCO-SBRS (COunterfactual COllaborative Session-Based Recommender Systems) to learn the causality between OSCs and user-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised approach to pre-train a recommendation model by designing pseudo-labels of causes for each user's selection of the item in data to guide the training process. Next, COCO-SBRS adopts counterfactual inference to recommend items based on the outputs of the pre-trained recommendation model considering the causalities to alleviate the data sparsity problem. As a result, COCO-SBRS can learn the causalities in data, preventing the model from learning spurious correlations. The experimental results of our extensive experiments conducted on three real-world datasets demonstrate the superiority of our proposed framework over ten representative SBRSs.|大多数基于会话的推荐系统(SBS)专注于从用户当前会话中观察到的项目中提取信息来预测下一个项目，而忽略了会话之外影响用户选择项目的原因(称为外部会话原因，OSC)。然而，这些原因在现实世界中普遍存在，很少有研究探讨它们在 SBRS 中的作用。本文从因果推理的角度分析了 SBRS 中 OSCs 的因果关系及其相关性。我们发现 OSC 本质上是 SBRS 中的混杂因素，这导致了用于训练 SBRS 模型的数据中存在虚假的相关性。为了解决这一问题，我们提出了一种新的 SBRS 框架 COCO-SBRS (COCO-SBRS，非事实协作的基于会话的推荐系统)来了解在 SBRS 中 OSC 和用户项目交互之间的因果关系。COCO-SBRS 首先采用自我监督的方法对推荐模型进行预训练，为每个用户选择数据中项目的原因设计伪标签，以指导训练过程。其次，COCO-SBRS 采用反事实推理方法，根据预训练推荐模型的输出结果进行推荐，考虑因果关系，以缓解数据稀疏问题。因此，COCO-SBRS 模型可以学习数据中的因果关系，防止模型学习虚假的相关性。我们在三个实际数据集上进行的大量实验结果表明，我们提出的框架优于十个具有代表性的 SBRS。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Counterfactual+Collaborative+Session-based+Recommender+System)|0|
|[Debiased Contrastive Learning for Sequential Recommendation](https://doi.org/10.1145/3543507.3583361)|Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang, Da Luo, Kangyi Lin||Current sequential recommender systems are proposed to tackle the dynamic user preference learning with various neural techniques, such as Transformer and Graph Neural Networks (GNNs). However, inference from the highly sparse user behavior data may hinder the representation ability of sequential pattern encoding. To address the label shortage issue, contrastive learning (CL) methods are proposed recently to perform data augmentation in two fashions: (i) randomly corrupting the sequence data (e.g. stochastic masking, reordering); (ii) aligning representations across pre-defined contrastive views. Although effective, we argue that current CL-based methods have limitations in addressing popularity bias and disentangling of user conformity and real interest. In this paper, we propose a new Debiased Contrastive learning paradigm for Recommendation (DCRec) that unifies sequential pattern encoding with global collaborative relation modeling through adaptive conformity-aware augmentation. This solution is designed to tackle the popularity bias issue in recommendation systems. Our debiased contrastive learning framework effectively captures both the patterns of item transitions within sequences and the dependencies between users across sequences. Our experiments on various real-world datasets have demonstrated that DCRec significantly outperforms state-of-the-art baselines, indicating its efficacy for recommendation. To facilitate reproducibility of our results, we make our implementation of DCRec publicly available at: https://github.com/HKUDS/DCRec.|目前的顺序推荐系统主要采用变压器和图形神经网络(GNN)等多种神经网络技术来解决动态用户偏好学习问题。然而，从高度稀疏的用户行为数据中进行推断可能会阻碍序列模式编码的表示能力。为了解决标签短缺问题，最近提出了对比学习(CL)方法，以两种方式进行数据增强: (i)随机破坏序列数据(例如随机掩蔽，重新排序) ; (ii)跨预定义的对比视图对齐表示。虽然有效，但我们认为目前基于 CL 的方法在解决流行偏差和用户一致性与真实兴趣的分离方面存在局限性。本文提出了一种新的无偏对比推荐学习范式，它通过自适应整合意识增强将序列模式编码与全局协作关系建模相结合。该解决方案旨在解决推荐系统中的流行偏差问题。我们的去偏差对比学习框架有效地捕获了序列中的项目转换模式和用户之间的依赖关系。我们在各种真实世界数据集上的实验表明，DCREc 显著优于最先进的基线，表明其推荐功效。为了便于重复我们的结果，我们将我们的 DCRec 的实现公布于以下 https://github.com/hkuds/DCRec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiased+Contrastive+Learning+for+Sequential+Recommendation)|0|
|[Learning Vector-Quantized Item Representation for Transferable Sequential Recommenders](https://doi.org/10.1145/3543507.3583434)|Yupeng Hou, Zhankui He, Julian J. McAuley, Wayne Xin Zhao|UC San Diego, USA; Renmin University of China, China; Beijing Key Laboratory of Big Data Management and Analysis Methods, Renmin University of China, China|Recently, the generality of natural language text has been leveraged to develop transferable recommender systems. The basic idea is to employ pre-trained language models~(PLM) to encode item text into item representations. Despite the promising transferability, the binding between item text and item representations might be too tight, leading to potential problems such as over-emphasizing the effect of text features and exaggerating the negative impact of domain gap. To address this issue, this paper proposes VQ-Rec, a novel approach to learning Vector-Quantized item representations for transferable sequential Recommenders. The main novelty of our approach lies in the new item representation scheme: it first maps item text into a vector of discrete indices (called item code), and then employs these indices to lookup the code embedding table for deriving item representations. Such a scheme can be denoted as "text $\Longrightarrow$ code $\Longrightarrow$ representation". Based on this representation scheme, we further propose an enhanced contrastive pre-training approach, using semi-synthetic and mixed-domain code representations as hard negatives. Furthermore, we design a new cross-domain fine-tuning method based on a differentiable permutation-based network. Extensive experiments conducted on six public benchmarks demonstrate the effectiveness of the proposed approach, in both cross-domain and cross-platform settings. Code and pre-trained model are available at: https://github.com/RUCAIBox/VQ-Rec.|近年来，人们利用自然语言文本的通用性来开发可转移的推荐系统。其基本思想是使用预先训练好的语言模型 ~ (PLM)将项目文本编码成项目表示。项目文本与项目表征之间的联系过于紧密，可能导致过分强调文本特征的作用，夸大领域差距的负面影响等问题。为了解决这一问题，本文提出了一种新的学习矢量量化项目表示的方法 VQ-Rec。该方法的主要创新点在于新的项目表示方案: 它首先将项目文本映射到一个离散索引的向量(称为项目代码) ，然后使用这些索引查找代码嵌入表以获得项目表示。这样的方案可以表示为“ text $Longrightarrow $code $Longrightarrow $代表”。基于这种表示方案，我们进一步提出了一种增强的对比预训练方法，使用半合成和混合域代码表示作为硬负数。在此基础上，设计了一种新的基于可微置换网络的跨域微调方法。在六个公共基准上进行的大量实验证明了该方法在跨领域和跨平台环境中的有效性。代码和预先训练的模型可在以下 https://github.com/rucaibox/vq-rec 找到:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Vector-Quantized+Item+Representation+for+Transferable+Sequential+Recommenders)|0|
|[KAE-Informer: A Knowledge Auto-Embedding Informer for Forecasting Long-Term Workloads of Microservices](https://doi.org/10.1145/3543507.3583288)|Qin Hua, Dingyu Yang, Shiyou Qian, Hanwen Hu, Jian Cao, Guangtao Xue|Alibaba Group, China; Shanghai Jiao Tong University, China|Accurately forecasting workloads in terms of throughput that is quantified as queries per second (QPS) is essential for microservices to elastically adjust their resource allocations. However, long-term QPS prediction is challenging in two aspects: 1) generality across various services with different temporal patterns, 2) characterization of intricate QPS sequences which are entangled by multiple components. In this paper, we propose a knowledge auto-embedding Informer network (KAE-Informer) for forecasting the long-term QPS sequences of microservices. By analyzing a large number of microservice traces, we discover that there are two main decomposable and predictable components in QPS sequences, namely global trend & dominant periodicity (TP) and low-frequency residual patterns with long-range dependencies. These two components are important for accurately forecasting long-term QPS. First, KAE-Informer embeds the knowledge of TP components through mathematical modeling. Second, KAE-Informer designs a convolution ProbSparse self-attention mechanism and a multi-layer event discrimination scheme to extract and embed the knowledge of local context awareness and event regression effect implied in residual components, respectively. We conduct experiments based on three real datasets including a QPS dataset collected from 40 microservices. The experiment results show that KAE-Informer achieves a reduction of MAPE, MAE and RMSE by about 16.6%, 17.6% and 23.1% respectively, compared to the state-of-the-art models.|根据每秒查询(QPS)量化的吞吐量准确预测工作负载对于微服务弹性调整其资源分配至关重要。然而，长期的 QPS 预测在两个方面具有挑战性: 1)不同时间模式的服务之间的一般性，2)被多个组件纠缠在一起的复杂的 QPS 序列的角色塑造。本文提出了一种基于知识自动嵌入的信息网络(KAE-Informer)来预测微服务的长期 QPS 序列。通过对大量微服务跟踪的分析，发现 QPS 序列中存在两个主要的可分解和可预测成分，即全局趋势和主周期(TP)和具有长程依赖性的低频残差模式。这两个组成部分是准确预测长期 QPS 的重要组成部分。首先，KAE-Informer 通过数学建模嵌入 TP 元件的知识。其次，KAE-Informer 分别设计了一种卷积 Probse 自注意机制和一种多层次事件识别方案来提取和嵌入残差分量中隐含的局部上下文感知和事件回归效应的知识。我们基于三个实际数据集进行实验，其中包括从40个微服务中收集的 QPS 数据集。实验结果表明，与现有的模型相比，KAE-Informer 的 MAPE、 MAE 和 RMSE 分别降低了约16.6% 、17.6% 和23.1% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KAE-Informer:+A+Knowledge+Auto-Embedding+Informer+for+Forecasting+Long-Term+Workloads+of+Microservices)|0|
|[Propaganda Política Pagada: Exploring U.S. Political Facebook Ads en Español](https://doi.org/10.1145/3543507.3583425)|Bruno Coelho, Tobias Lauinger, Laura Edelson, Ian Goldstein, Damon McCoy|New York University, USA|In 2021, the U.S. Hispanic population totaled 62.5 million people, 68% of whom spoke Spanish in their homes. To date, it is unclear which political advertisers address this audience in their preferred language, and whether they do so differently than for English-speaking audiences. In this work, we study differences between political Facebook ads in English and Spanish during 2020, the latest U.S. presidential election. Political advertisers spent $ 1.48 B in English, but only $ 28.8 M in Spanish, disproportionately little compared to the share of Spanish speakers in the population. We further find a lower proportion of election-related advertisers (which additionally are more liberal-leaning than in the English set), and a higher proportion of government agencies in the set of Spanish ads. We perform multilingual topic classification, finding that the most common ad topics in English were also present in Spanish, but to a different extent, and with a different composition of advertisers. Thus, Spanish speakers are served different types of ads from different types of advertisers than English speakers, and in lower amounts; these results raise the question of whether political communication through Facebook ads may be inequitable and effectively disadvantaging the sizeable minority of Spanish speakers in the U.S. population.|2021年，美国西班牙裔人口总数为6250万，其中68% 的人在家里说西班牙语。到目前为止，还不清楚哪些政治广告主用自己喜欢的语言向这些受众发表演讲，以及他们的做法是否与英语受众不同。在这项工作中，我们研究了2020年美国总统大选期间 Facebook 上英语和西班牙语的政治广告之间的差异。政治广告客户在英语广告上花费了14.8亿美元，但在西班牙语广告上只花费了2880万美元，与说西班牙语的人口比例相比，这个数字不成比例。我们进一步发现，与选举有关的广告客户比例较低(此外，这些广告客户比英语广告客户更倾向于自由派) ，而在西班牙语广告客户中，政府机构的比例较高。我们进行了多语言话题分类，发现英语中最常见的广告话题也出现在西班牙语中，但程度不同，广告主的构成也不同。因此，说西班牙语的人比说英语的人得到了不同类型的广告，而且数量较少; 这些结果提出了一个问题: 通过 Facebook 广告进行的政治交流是否不公平，是否有效地损害了美国人口中说西班牙语的少数人的利益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Propaganda+Política+Pagada:+Exploring+U.S.+Political+Facebook+Ads+en+Español)|0|
|[Learning Denoised and Interpretable Session Representation for Conversational Search](https://doi.org/10.1145/3543507.3583265)|Kelong Mao, Hongjin Qian, Fengran Mo, Zhicheng Dou, Bang Liu, Xiaohua Cheng, Zhao Cao|Renmin University of China, China; Université de Montréal, Canada; Huawei Poisson Lab, China; RALI & Mila, Université de Montréal, Canada|Conversational search supports multi-turn user-system interactions to solve complex information needs. Compared with the traditional single-turn ad-hoc search, conversational search faces a more complex search intent understanding problem because a conversational search session is much longer and contains many noisy tokens. However, existing conversational dense retrieval solutions simply fine-tune the pre-trained ad-hoc query encoder on limited conversational search data, which are hard to achieve satisfactory performance in such a complex conversational search scenario. Meanwhile, the learned latent representation also lacks interpretability that people cannot perceive how the model understands the session. To tackle the above drawbacks, we propose a sparse Lexical-based Conversational REtriever (LeCoRE), which extends the SPLADE model with two well-matched multi-level denoising methods uniformly based on knowledge distillation and external query rewrites to generate denoised and interpretable lexical session representation. Extensive experiments on four public conversational search datasets in both normal and zero-shot evaluation settings demonstrate the strong performance of LeCoRE towards more effective and interpretable conversational search.|会话搜索支持多回合的用户-系统交互，以解决复杂的信息需求。与传统的单向自组织搜索相比，会话搜索面临着更复杂的搜索意图理解问题，因为会话搜索会话更长，且包含大量噪声标记。然而，现有的会话密集检索解决方案只是在有限的会话搜索数据上对预先训练好的自组织查询编码器进行微调，难以在如此复杂的会话搜索场景中获得令人满意的性能。同时，习得的潜在表征也缺乏可解释性，人们无法感知模型是如何理解会话的。针对上述缺点，本文提出了一种基于稀疏词汇的会话检索(Conversational REtriever，LeCoRE)算法，该算法扩展了 SPLADE 模型，采用基于知识提取和外部查询重写的两种匹配性较好的多级去噪方法，均匀地生成去噪和可解释的词汇会话表示。对四个公共会话搜索数据集在正常和零拍评估环境下的大量实验表明，LeCoRE 在更有效和可解释的会话搜索方面具有很强的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Denoised+and+Interpretable+Session+Representation+for+Conversational+Search)|0|
|[Fairly Adaptive Negative Sampling for Recommendations](https://doi.org/10.1145/3543507.3583355)|Xiao Chen, Wenqi Fan, Jingfan Chen, Haochen Liu, Zitao Liu, Zhaoxiang Zhang, Qing Li||Pairwise learning strategies are prevalent for optimizing recommendation models on implicit feedback data, which usually learns user preference by discriminating between positive (i.e., clicked by a user) and negative items (i.e., obtained by negative sampling). However, the size of different item groups (specified by item attribute) is usually unevenly distributed. We empirically find that the commonly used uniform negative sampling strategy for pairwise algorithms (e.g., BPR) can inherit such data bias and oversample the majority item group as negative instances, severely countering group fairness on the item side. In this paper, we propose a Fairly adaptive Negative sampling approach (FairNeg), which improves item group fairness via adaptively adjusting the group-level negative sampling distribution in the training process. In particular, it first perceives the model's unfairness status at each step and then adjusts the group-wise sampling distribution with an adaptive momentum update strategy for better facilitating fairness optimization. Moreover, a negative sampling distribution Mixup mechanism is proposed, which gracefully incorporates existing importance-aware sampling techniques intended for mining informative negative samples, thus allowing for achieving multiple optimization purposes. Extensive experiments on four public datasets show our proposed method's superiority in group fairness enhancement and fairness-utility tradeoff.|成对学习策略普遍用于优化隐性反馈数据的推荐模型，它通常通过区分正面(即用户点击)和负面(即通过负面抽样获得)来学习用户偏好。但是，不同项目组(由项目属性指定)的大小通常是不均匀分布的。实证结果表明，成对算法中常用的一致负抽样策略(如 BPR)会继承这种数据偏差，并将多数项目组作为负实例过度抽样，严重影响项目方的群体公平性。本文提出了一种公平自适应负抽样方法(FairNeg) ，该方法通过在训练过程中自适应调整组级负抽样分布来提高项目组的公平性。特别地，它首先在每个步骤中感知模型的不公平状态，然后利用自适应动量更新策略调整分组抽样分布，以更好地促进公平性优化。此外，提出了负抽样分布混合机制，它优雅地结合了现有的重要性感知抽样技术，旨在挖掘信息负样本，从而实现多种优化目的。在四个公共数据集上的大量实验表明，该方法在增强群体公平性和公平-效用权衡方面具有优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairly+Adaptive+Negative+Sampling+for+Recommendations)|0|
|[CNSVRE: A Query Reformulated Search System with Explainable Summarization for Virtual Research Environment](https://doi.org/10.1145/3543873.3587360)|Na Li, Yangjun Zhang, Zhiming Zhao|University of Amsterdam, Netherlands|Computational notebook environments have drawn broad attention in data-centric research applications, e.g., virtual research environment, for exploratory data analysis and algorithm prototyping. Vanilla computational notebook search solutions have been proposed but they do not pay much attention to the information needs of scientific researchers. Previous studies either treat computational notebook search as a code search problem or focus on content-based computational notebook search. The queries being considered are neither research-concerning nor diversified whereas researchers’ information needs are highly specialized and complex. Moreover, relevance evaluation for computational notebooks is tricky and unreliable since computational notebooks contain fragments of text and code and are usually poorly organized. To solve the above challenges, we propose a computational notebook search system for virtual research environment (VRE), i.e., CNSVRE, with scientific query reformulation and computational notebook summarization. We conduct a user study to demonstrate the effectiveness, efficiency, and satisfaction with the system.|计算机笔记本环境在以数据为中心的研究应用中引起了广泛的关注，例如用于探索性数据分析和算法原型的虚拟研究环境。香草计算笔记本搜索解决方案已经提出，但他们没有太多的关注科学研究人员的信息需求。以往的研究要么将计算笔记本搜索视为一个代码搜索问题，要么将重点放在基于内容的计算笔记本搜索上。被考虑的查询既不涉及研究，也不多样化，而研究人员的信息需求是高度专业化和复杂化的。此外，计算笔记本的相关性评估是棘手和不可靠的，因为计算笔记本包含文本和代码片段，通常组织不良。为了解决上述挑战，我们提出了一个虚拟研究环境(即 CNSVRE)的计算笔记本搜索系统，该系统具有科学的查询重构和计算笔记本摘要。我们进行了用户研究，以证明系统的有效性、效率和满意度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CNSVRE:+A+Query+Reformulated+Search+System+with+Explainable+Summarization+for+Virtual+Research+Environment)|0|
|[Personalized style recommendation via reinforcement learning](https://doi.org/10.1145/3543873.3587367)|Jiyun Luo, Kurchi Subhra Hazra, Wenyu Huo, Rui Li, Abhijit Mahabal|Pinterest Inc., USA|Pinterest fashion and home decor searchers often have different style tastes. Some existing work adopts users’ past engagement to infer style preference. These methods cannot help users discover new styles. Other work requires users to provide text or visual signals to describe their style preference, but users often are not familiar with style terms and do not have the right image to start with. In this paper, we propose a reinforcement learning (RL) method to help users explore and exploit style space without requiring extra user input. Experimental results show that our method improves the success rate of Pinterest fashion and home decor searches by 34.8%.|Pinterest 时尚和家居装饰搜索往往有不同的风格品味。现有的一些工作采用用户过去的接触来推断风格偏好。这些方法不能帮助用户发现新样式。其他工作需要用户提供文本或视觉信号来描述他们的风格偏好，但用户往往不熟悉风格术语，并没有正确的图像开始。在这篇文章中，我们提出了一个强化学习(RL)方法来帮助用户探索和开发样式空间，而不需要额外的用户输入。实验结果表明，该方法提高了 Pinterest 时装和家居装饰搜索的成功率34.8% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+style+recommendation+via+reinforcement+learning)|0|
|[HierCat: Hierarchical Query Categorization from Weakly Supervised Data at Facebook Marketplace](https://doi.org/10.1145/3543873.3584622)|Yunzhong He, Cong Zhang, Ruoyan Kong, Chaitanya Kulkarni, Qing Liu, Ashish Gandhe, Amit Nithianandan, Arul Prakash|Meta, USA; University of Minnesota Twin Cities, USA|Query categorization at customer-to-customer e-commerce platforms like Facebook Marketplace is challenging due to the vagueness of search intent, noise in real-world data, and imbalanced training data across languages. Its deployment also needs to consider challenges in scalability and downstream integration in order to translate modeling advances into better search result relevance. In this paper we present HierCat, the query categorization system at Facebook Marketplace. HierCat addresses these challenges by leveraging multi-task pre-training of dual-encoder architectures with a hierarchical inference step to effectively learn from weakly supervised training data mined from searcher engagement. We show that HierCat not only outperforms popular methods in offline experiments, but also leads to 1.4% improvement in NDCG and 4.3% increase in searcher engagement at Facebook Marketplace Search in online A/B testing.|像 Facebook Marketplace 这样的客户对客户的电子商务平台，由于搜索意图的模糊性、现实世界数据中的噪音以及跨语言的不平衡训练数据，查询分类是一个挑战。它的部署还需要考虑可伸缩性和下游集成方面的挑战，以便将建模进展转化为更好的搜索结果相关性。本文介绍了 Facebook Marketplace 的查询分类系统 HierCat。HierCat 通过利用双重编码器架构的多任务预训练和分层推理步骤来解决这些挑战，以有效地学习从搜索引擎参与中挖掘的弱监督训练数据。我们发现 HierCat 不仅在离线实验中表现优于流行的方法，而且在线 A/B 测试中导致 NDCG 改善1.4% ，Facebook Marketplace Search 的搜索者参与度提高4.3% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HierCat:+Hierarchical+Query+Categorization+from+Weakly+Supervised+Data+at+Facebook+Marketplace)|0|
|[Search-based Recommendation: the Case for Difficult Predictions](https://doi.org/10.1145/3543873.3587374)|Ghazaleh Haratinezhad Torbati, Gerhard Weikum, Andrew Yates|Max Planck Institute for Informatics, Germany; University of Amsterdam, Netherlands|Recommender systems have achieved impressive results on benchmark datasets. However, the numbers are often influenced by assumptions made on the data and evaluation mode. This work questions and revises these assumptions, to study and improve the quality, particularly for the difficult case of search-based recommendations. Users start with a personally liked item as a query and look for similar items that match their tastes. User satisfaction requires discovering truly unknown items: new authors of books rather than merely more books of known writers. We propose a unified system architecture that combines interaction-based and content-based signals and leverages language models for Transformer-powered predictions. We present new techniques for selecting negative training samples, and investigate their performance in the underexplored search-based evaluation mode.|推荐系统在基准数据集上取得了令人印象深刻的成果。然而，这些数字往往受到对数据和评估模式的假设的影响。本文对这些假设进行了质疑和修正，以研究和提高质量，特别是针对困难案例的基于搜索的推荐。用户从一个个人喜欢的项目开始查询，然后寻找与他们口味相符的类似项目。用户满意度要求发现真正未知的项目: 书籍的新作者，而不仅仅是知名作家的书籍。我们提出了一个统一的系统体系结构，它结合了基于交互和基于内容的信号，并利用语言模型进行基于 Transformer 的预测。我们提出了选择负训练样本的新技术，并研究了它们在基于搜索的评估模式中的表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search-based+Recommendation:+the+Case+for+Difficult+Predictions)|0|
|[Reweighting Clicks with Dwell Time in Recommendation](https://doi.org/10.1145/3543873.3584624)|Ruobing Xie, Lin Ma, Shaoliang Zhang, Feng Xia, Leyu Lin|WeChat, Tencent, China|The click behavior is the most widely-used user positive feedback in recommendation. However, simply considering each click equally in training may suffer from clickbaits and title-content mismatching, and thus fail to precisely capture users' real satisfaction on items. Dwell time could be viewed as a high-quality quantitative indicator of user preferences on each click, while existing recommendation models do not fully explore the modeling of dwell time. In this work, we focus on reweighting clicks with dwell time in recommendation. Precisely, we first define a new behavior named valid read, which helps to select high-quality click instances for different users and items via dwell time. Next, we propose a normalized dwell time function to reweight click signals in training for recommendation. The Click reweighting model achieves significant improvements on both offline and online evaluations in real-world systems.|点击行为是推荐中使用最广泛的用户正面反馈。然而，在培训中仅仅考虑每一次点击的平等性可能会遭受点击诱惑和标题内容不匹配的问题，因此不能准确地捕捉用户对项目的真正满意度。停留时间可以被视为每次点击时用户偏好的高质量定量指标，而现有的推荐模型并没有充分探索停留时间的建模。在这项工作中，我们将重点放在用推荐中的停留时间重新加权点击。确切地说，我们首先定义一个名为有效读的新行为，它有助于通过停留时间为不同的用户和项目选择高质量的单击实例。接下来，我们提出了一个规范化的停留时间函数来重新加权点击信号的训练推荐。Click 重新加权模型在现实世界系统的离线和在线评估方面都取得了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reweighting+Clicks+with+Dwell+Time+in+Recommendation)|0|
|[Disentangled Causal Embedding With Contrastive Learning For Recommender System](https://doi.org/10.1145/3543873.3584637)|Weiqi Zhao, Dian Tang, Xin Chen, Dawei Lv, Daoli Ou, Biao Li, Peng Jiang, Kun Gai|Kuaishou Technology, China; Unaffiliated, China|Recommender systems usually rely on observed user interaction data to build personalized recommendation models, assuming that the observed data reflect user interest. However, user interacting with an item may also due to conformity, the need to follow popular items. Most previous studies neglect user's conformity and entangle interest with it, which may cause the recommender systems fail to provide satisfying results. Therefore, from the cause-effect view, disentangling these interaction causes is a crucial issue. It also contributes to OOD problems, where training and test data are out-of-distribution. Nevertheless, it is quite challenging as we lack the signal to differentiate interest and conformity. The data sparsity of pure cause and the items' long-tail problem hinder disentangled causal embedding. In this paper, we propose DCCL, a framework that adopts contrastive learning to disentangle these two causes by sample augmentation for interest and conformity respectively. Futhermore, DCCL is model-agnostic, which can be easily deployed in any industrial online system. Extensive experiments are conducted over two real-world datasets and DCCL outperforms state-of-the-art baselines on top of various backbone models in various OOD environments. We also demonstrate the performance improvements by online A/B testing on Kuaishou, a billion-user scale short-video recommender system.|推荐系统通常依赖于观察到的用户交互数据来建立个性化的推荐模型，假设观察到的数据反映了用户的兴趣。然而，用户与一个项目的互动也可能是由于一致性，需要遵循流行的项目。以往的大多数研究忽视了用户的一致性，并与之产生利益纠葛，这可能导致推荐系统不能提供令人满意的结果。因此，从因果观点来看，解开这些相互作用的原因是一个至关重要的问题。它还会导致面向对象设计(OOD)问题，即培训和测试数据分布不均。然而，这是相当具有挑战性的，因为我们缺乏区分兴趣和一致性的信号。纯因果关系的数据稀疏性和项目的长尾问题阻碍了因果关系的解纠缠嵌入。在本文中，我们提出了 DCCL，一个采用对比学习的框架，分别通过兴趣和从众的样本增加来解决这两个原因。此外，DCCL 是模型无关的，可以很容易地部署在任何工业在线系统。在两个真实世界的数据集上进行了广泛的实验，DCCL 在各种面向对象设计(OOD)环境中的各种骨干模型上的表现优于最先进的基线。我们还通过在 Kuaishou 的在线 A/B 测试展示了性能改进，这是一个拥有10亿用户规模的短视频推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Causal+Embedding+With+Contrastive+Learning+For+Recommender+System)|0|
|[Confidence Ranking for CTR Prediction](https://doi.org/10.1145/3543873.3584643)|Jian Zhu, Congcong Liu, Pei Wang, Xiwei Zhao, Zhangang Lin, Jingping Shao|JD.com, China|Model evolution and data updating are two common phenomena in large-scale real-world machine learning applications, e.g. ads and recommendation systems. To adapt, the real-world system typically retrain with all available data and online learn with recently available data to update the models periodically with the goal of better serving performance. In this paper, we propose a novel framework, named Confidence Ranking, which designs the optimization objective as a ranking function with two different models. Our confidence ranking loss allows direct optimization of the logits output for different convex surrogate functions of metrics, e.g. AUC and Accuracy depending on the target task and dataset. Armed with our proposed methods, our experiments show that the introduction of confidence ranking loss can outperform all baselines on the CTR prediction tasks of public and industrial datasets. This framework has been deployed in the advertisement system of JD.com to serve the main traffic in the fine-rank stage.|模型演化和数据更新是广告和推荐系统等大规模真实世界机器学习应用中的两种常见现象。为了适应这种情况，现实世界中的系统通常使用所有可用的数据进行再培训，并使用最近可用的数据进行在线学习，以便定期更新模型，从而更好地服务于性能。在本文中，我们提出了一个新的框架，称为置信排序，设计的优化目标为一个排序函数与两个不同的模型。我们的置信度排序损失允许直接优化不同凸性度量替代函数的 logit 输出，例如 AUC 和精度取决于目标任务和数据集。实验结果表明，在公共数据集和工业数据集的 CTR 预测任务中，置信度排序损失的引入能够优于所有基线。该框架已经部署在京东的广告系统中，服务于精品阶段的主流流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Confidence+Ranking+for+CTR+Prediction)|0|
|[Personalised Search in E-Comm Groceries](https://doi.org/10.1145/3543873.3587588)|Ramprabhu Murugesan, Anuja Sharan|Walmart labs, India; Walmart Labs, India|Personalized Search(henceforth called P10d Search) focuses to deliver user-specific search results based on the previous purchases. Search engine retrieves the result based on the defined relevancy algorithm. When a user searches a keyword, search engine constructs the search query based on the defined searchable fields/attributes along with configured relevancy algorithm. Position of the item retrieved in search results is determined by the search algorithm based on the search term. The results are further refined or ranked based on different click stream signals, product features, market data to provide much relevant results. Personalisation provides the ranked the list of items for a given user based on past purchases. Personalisation is agnostic of search query and takes user id, cart additions, site taxonomy and user’s shopping history as input signals. In summary, search engine queries data based on relevancy and personalisation engine retrieves based purely on purchases. Goal of personalised search is to enhance the search results by adding personalised results without affecting the search relevance.|个性化检索(以下简称 P10d 搜索)的重点是提供基于以前购买的特定用户的搜索结果。搜索引擎根据定义的相关算法检索结果。当用户搜索关键字时，搜索引擎根据定义的可搜索字段/属性以及配置的相关性算法构造搜索查询。在搜索结果中检索到的项的位置由基于搜索项的搜索算法确定。根据不同的点击流信号、产品特点、市场数据对结果进行进一步细化或排序，以提供更多相关的结果。个性化为给定用户提供了基于过去购买的商品的排名列表。个性化是不可知的搜索查询，并采取用户 ID，购物车添加，网站分类和用户的购物历史作为输入信号。总之，搜索引擎查询数据的相关性和个性化引擎检索纯粹基于购买。个性化搜索的目标是在不影响搜索相关性的情况下，通过添加个性化搜索结果来提高搜索结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalised+Search+in+E-Comm+Groceries)|0|
|[Graph Embedding for Mapping Interdisciplinary Research Networks](https://doi.org/10.1145/3543873.3587570)|Eoghan Cunningham, Derek Greene|University College Dublin, Ireland|Representation learning is the first step in automating tasks such as research paper recommendation, classification, and retrieval. Due to the accelerating rate of research publication, together with the recognised benefits of interdisciplinary research, systems that facilitate researchers in discovering and understanding relevant works from beyond their immediate school of knowledge are vital. This work explores different methods of research paper representation (or document embedding), to identify those methods that are capable of preserving the interdisciplinary implications of research papers in their embeddings. In addition to evaluating state of the art methods of document embedding in a interdisciplinary citation prediction task, we propose a novel Graph Neural Network architecture designed to preserve the key interdisciplinary implications of research articles in citation network node embeddings. Our proposed method outperforms other GNN-based methods in interdisciplinary citation prediction, without compromising overall citation prediction performance.|表示学习是研究论文推荐、分类和检索等任务自动化的第一步。由于研究发表的速度加快，再加上科际整合的公认好处，有助研究人员发现和理解其直接学校知识以外的相关著作的系统是至关重要的。本文探讨了研究论文表示(或文档嵌入)的不同方法，以确定哪些方法能够在其嵌入过程中保持研究论文的跨学科含义。除了评估在跨学科引文预测任务中嵌入文档的最新方法之外，我们还提出了一种新的图形神经网络体系结构，旨在保存引文网络节点嵌入中研究论文的关键跨学科含义。我们提出的方法在跨学科引文预测方面优于其他基于 GNN 的方法，而不影响整体的引文预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Embedding+for+Mapping+Interdisciplinary+Research+Networks)|0|
|[Deep Passage Retrieval in E-Commerce](https://doi.org/10.1145/3543873.3587624)|Vinay Rao Dandin, Ozan Ersoy, Kyung Hyuk Kim|Flipkart US R&D Center, USA|We have developed a conversational assistant called the Decision Assistant (DA) to help customers make purchase decisions. To answer customer queries successfully, we use a question and answering (QnA) system that retrieves data on product pages and extracts answers. With various data sources available on the product pages, we deal with unique challenges such as different terminologies and data formats for successful answer retrieval. In this paper, we propose two different bi-encoder architectures for retrieving data from each of the two data sources considered – product descriptions and specifications. The proposed architectures beat the baseline approaches while maintaining a high recall and low latency in production. We envision that the proposed approaches can be widely applicable to other e-commerce QnA systems.|我们已经开发了一个称为决策助理(DA)的会话助理来帮助客户做出购买决策。为了成功地回答客户的查询，我们使用一个问答(QnA)系统来检索产品页面上的数据并提取答案。随着各种数据源可在产品页面，我们处理独特的挑战，如不同的术语和数据格式，以成功的答案检索。在本文中，我们提出了两种不同的双编码器体系结构来检索数据从每个两个数据源考虑-产品描述和规格。所提出的体系结构打破了基线方法，同时在生产中保持了较高的召回率和较低的延迟。我们设想所提出的方法可以广泛应用于其他电子商务 QnA 系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Passage+Retrieval+in+E-Commerce)|0|
|[Quantize Sequential Recommenders Without Private Data](https://doi.org/10.1145/3543507.3583351)|Lingfeng Shi, Yuang Liu, Jun Wang, Wei Zhang|East China Normal University, China|Deep neural networks have achieved great success in sequential recommendation systems. While maintaining high competence in user modeling and next-item recommendation, these models have long been plagued by the numerous parameters and computation, which inhibit them to be deployed on resource-constrained mobile devices. Model quantization, as one of the main paradigms for compression techniques, converts float parameters to low-bit values to reduce parameter redundancy and accelerate inference. To avoid drastic performance degradation, it usually requests a fine-tuning phase with an original dataset. However, the training set of user-item interactions is not always available due to transmission limits or privacy concerns. In this paper, we propose a novel framework to quantize sequential recommenders without access to any real private data. A generator is employed in the framework to synthesize fake sequence samples to feed the quantized sequential recommendation model and minimize the gap with a full-precision sequential recommendation model. The generator and the quantized model are optimized with a min-max game — alternating discrepancy estimation and knowledge transfer. Moreover, we devise a two-level discrepancy modeling strategy to transfer information between the quantized model and the full-precision model. The extensive experiments of various recommendation networks on three public datasets demonstrate the effectiveness of the proposed framework.|深层神经网络在序贯推荐系统中取得了巨大的成功。尽管这些模型在用户建模和下一个项目推荐方面保持了很高的能力，但长期以来，这些模型一直受到众多参数和计算的困扰，这些参数和计算阻碍了它们被部署到资源受限的移动设备上。模型量化作为压缩技术的主要范式之一，将浮点参数转换为低位值，以减少参数冗余，加速推理。为了避免严重的性能下降，它通常要求对原始数据集进行微调。然而，由于传输限制或隐私问题，用户项交互的训练集并不总是可用的。在本文中，我们提出了一个新的框架，量化顺序推荐没有访问任何真正的私有数据。该框架采用生成器对伪序列样本进行合成，以满足量化序列推荐模型的要求，同时采用全精度序列推荐模型使推荐间隔最小化。利用最小-最大对策-交替差异估计和知识转移对生成器和量化模型进行优化。此外，我们还设计了一个两层差异建模策略来传递量化模型和全精度模型之间的信息。在三个公共数据集上对各种推荐网络进行了广泛的实验，证明了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantize+Sequential+Recommenders+Without+Private+Data)|0|
|[Adap-τ : Adaptively Modulating Embedding Magnitude for Recommendation](https://doi.org/10.1145/3543507.3583363)|Jiawei Chen, Junkang Wu, Jiancan Wu, Xuezhi Cao, Sheng Zhou, Xiangnan He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adap-τ+:+Adaptively+Modulating+Embedding+Magnitude+for+Recommendation)|0|
|[Clustered Embedding Learning for Recommender Systems](https://doi.org/10.1145/3543507.3583362)|Yizhou Chen, Guangda Huzhang, Anxiang Zeng, Qingtao Yu, Hui Sun, HengYi Li, Jingyi Li, Yabo Ni, Han Yu, Zhiming Zhou|Shanghai University of Finance and Economics, China; SCSE, Nanyang Technological University, Singapore; Shopee Pte Ltd., Singapore|In recent years, recommender systems have advanced rapidly, where embedding learning for users and items plays a critical role. A standard method learns a unique embedding vector for each user and item. However, such a method has two important limitations in real-world applications: 1) it is hard to learn embeddings that generalize well for users and items with rare interactions on their own; and 2) it may incur unbearably high memory costs when the number of users and items scales up. Existing approaches either can only address one of the limitations or have flawed overall performances. In this paper, we propose Clustered Embedding Learning (CEL) as an integrated solution to these two problems. CEL is a plug-and-play embedding learning framework that can be combined with any differentiable feature interaction model. It is capable of achieving improved performance, especially for cold users and items, with reduced memory cost. CEL enables automatic and dynamic clustering of users and items in a top-down fashion, where clustered entities jointly learn a shared embedding. The accelerated version of CEL has an optimal time complexity, which supports efficient online updates. Theoretically, we prove the identifiability and the existence of a unique optimal number of clusters for CEL in the context of nonnegative matrix factorization. Empirically, we validate the effectiveness of CEL on three public datasets and one business dataset, showing its consistently superior performance against current state-of-the-art methods. In particular, when incorporating CEL into the business model, it brings an improvement of $+0.6\%$ in AUC, which translates into a significant revenue gain; meanwhile, the size of the embedding table gets $2650$ times smaller.|近年来，推荐系统发展迅速，其中用户和项目的嵌入式学习起着至关重要的作用。标准方法为每个用户和项学习唯一的嵌入向量。然而，这种方法在实际应用中有两个重要的局限性: 1)很难学习嵌入式技术，这种技术可以很好地适用于用户和具有罕见交互的项目; 2)当用户和项目的数量增加时，它可能会产生难以忍受的高内存成本。现有的方法要么只能解决其中的一个限制，要么具有有缺陷的整体性能。在本文中，我们提出了集群嵌入式学习(CEL)作为这两个问题的综合解决方案。CEL 是一个即插即用的嵌入式学习框架，可以与任何可微的特征交互模型相结合。它能够提高性能，特别是对于冷用户和项目，同时降低内存成本。CEL 以自顶向下的方式支持用户和项目的自动和动态集群，集群实体可以在这种方式下联合学习共享嵌入。CEL 的加速版本具有最佳的时间复杂度，支持高效的在线更新。理论上，我们证明了在非负矩阵分解的情况下，CEL 的可识别性和唯一最优簇数的存在性。通过实验，我们验证了 CEL 在三个公共数据集和一个业务数据集上的有效性，显示了与当前最先进的方法相比，CEL 始终具有优越的性能。特别是，当将 CEL 融入到商业模式中时，它在 AUC 中带来了 $+ 0.6% 的改进，这意味着显著的收入增长; 与此同时，嵌入表的大小变小了2650美元。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clustered+Embedding+Learning+for+Recommender+Systems)|0|
|[MMMLP: Multi-modal Multilayer Perceptron for Sequential Recommendations](https://doi.org/10.1145/3543507.3583378)|Jiahao Liang, Xiangyu Zhao, Muyang Li, Zijian Zhang, Wanyu Wang, Haochen Liu, Zitao Liu|Michigan State University, USA; Jilin University, China and City University of Hong Kong, Hong Kong; City University of Hong Kong, Hong Kong; University of Sydney, Australia; Guangdong Institute of Smart Education, Jinan University, China|Sequential recommendation aims to offer potentially interesting products to users by capturing their historical sequence of interacted items. Although it has facilitated extensive physical scenarios, sequential recommendation for multi-modal sequences has long been neglected. Multi-modal data that depicts a user’s historical interactions exists ubiquitously, such as product pictures, textual descriptions, and interacted item sequences, providing semantic information from multiple perspectives that comprehensively describe a user’s preferences. However, existing sequential recommendation methods either fail to directly handle multi-modality or suffer from high computational complexity. To address this, we propose a novel Multi-Modal Multi-Layer Perceptron (MMMLP) for maintaining multi-modal sequences for sequential recommendation. MMMLP is a purely MLP-based architecture that consists of three modules - the Feature Mixer Layer, Fusion Mixer Layer, and Prediction Layer - and has an edge on both efficacy and efficiency. Extensive experiments show that MMMLP achieves state-of-the-art performance with linear complexity. We also conduct ablating analysis to verify the contribution of each component. Furthermore, compatible experiments are devised, and the results show that the multi-modal representation learned by our proposed model generally benefits other recommendation models, emphasizing our model’s ability to handle multi-modal information. We have made our code available online to ease reproducibility1.|顺序推荐旨在通过获取用户交互项的历史顺序，为用户提供潜在有趣的产品。虽然它促进了广泛的物理场景，多模态序列的顺序推荐长期以来被忽视。描述用户历史交互的多模态数据无处不在，比如产品图片、文本描述和交互式项目序列，从多个角度提供语义信息，全面描述用户的偏好。然而，现有的顺序推荐方法要么不能直接处理多模态问题，要么计算复杂度较高。为了解决这个问题，我们提出了一种新的多模态多层感知器(MMMLP)来维护多模态序列的顺序推荐。MMLP 是一个纯粹基于 MLP 的架构，它由三个模块组成——特征混合层、融合混合层和预测层——并且在功效和效率方面都有优势。大量的实验表明，MMLP 在线性复杂度方面达到了最先进的性能。我们还进行了烧蚀分析，以验证每个组分的贡献。此外，设计了相容性实验，结果表明，我们提出的模型学习的多模态表示一般有利于其他推荐模型，强调我们的模型的能力，处理多模态信息。我们已经在网上提供了我们的代码，以便于重现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMMLP:+Multi-modal+Multilayer+Perceptron+for+Sequential+Recommendations)|0|
|[AutoMLP: Automated MLP for Sequential Recommendations](https://doi.org/10.1145/3543507.3583440)|Muyang Li, Zijian Zhang, Xiangyu Zhao, Wanyu Wang, Minghao Zhao, Runze Wu, Ruocheng Guo|Bytedance AI Lab UK, United Kingdom; City University of Hong Kong, Hong Kong and Jilin University, China; City University of Hong Kong, Hong Kong; Fuxi AI Lab, NetEase, China; City University of Hong Kong, Hong Kong and University of Sydney, Australia|Sequential recommender systems aim to predict users' next interested item given their historical interactions. However, a long-standing issue is how to distinguish between users' long/short-term interests, which may be heterogeneous and contribute differently to the next recommendation. Existing approaches usually set pre-defined short-term interest length by exhaustive search or empirical experience, which is either highly inefficient or yields subpar results. The recent advanced transformer-based models can achieve state-of-the-art performances despite the aforementioned issue, but they have a quadratic computational complexity to the length of the input sequence. To this end, this paper proposes a novel sequential recommender system, AutoMLP, aiming for better modeling users' long/short-term interests from their historical interactions. In addition, we design an automated and adaptive search algorithm for preferable short-term interest length via end-to-end optimization. Through extensive experiments, we show that AutoMLP has competitive performance against state-of-the-art methods, while maintaining linear computational complexity.|顺序推荐系统的目的是预测用户的下一个感兴趣的项目给予他们的历史交互。然而，一个长期存在的问题是如何区分用户的长期和短期利益，这可能是不同的，并作出不同的贡献下一个建议。现有方法通常通过穷举搜索或实证经验来设定预先确定的短期利率长度，这种方法要么效率极低，要么效果不佳。尽管存在上述问题，最近的先进的基于变压器的模型能够实现最先进的性能，但是它们对于输入序列的长度具有二次计算复杂度。为此，本文提出了一种新的顺序推荐系统—— AutoMLP，旨在从用户的历史交互中更好地建立用户的长期/短期兴趣模型。此外，我们设计了一个自动化和自适应的搜索算法，通过端到端优化较好的短期兴趣长度。通过大量的实验，我们发现 AutoMLP 在保持线性计算复杂度的同时，具有与最先进的方法相竞争的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoMLP:+Automated+MLP+for+Sequential+Recommendations)|0|
|[NASRec: Weight Sharing Neural Architecture Search for Recommender Systems](https://doi.org/10.1145/3543507.3583446)|Tunhou Zhang, Dehua Cheng, Yuchen He, Zhengxing Chen, Xiaoliang Dai, Liang Xiong, Feng Yan, Hai Li, Yiran Chen, Wei Wen|Duke University, USA; Meta AI, USA; University of Houston, USA|The rise of deep neural networks offers new opportunities in optimizing recommender systems. However, optimizing recommender systems using deep neural networks requires delicate architecture fabrication. We propose NASRec, a paradigm that trains a single supernet and efficiently produces abundant models/sub-architectures by weight sharing. To overcome the data multi-modality and architecture heterogeneity challenges in the recommendation domain, NASRec establishes a large supernet (i.e., search space) to search the full architectures. The supernet incorporates versatile choice of operators and dense connectivity to minimize human efforts for finding priors. The scale and heterogeneity in NASRec impose several challenges, such as training inefficiency, operator-imbalance, and degraded rank correlation. We tackle these challenges by proposing single-operator any-connection sampling, operator-balancing interaction modules, and post-training fine-tuning. Our crafted models, NASRecNet, show promising results on three Click-Through Rates (CTR) prediction benchmarks, indicating that NASRec outperforms both manually designed models and existing NAS methods with state-of-the-art performance. Our work is publicly available at https://github.com/facebookresearch/NasRec.|深层神经网络的兴起为优化推荐系统提供了新的机会。然而，使用深层神经网络优化推荐系统需要精细的架构制作。我们提出 NASRec，一个训练单个超级网络并通过权重分享有效地产生丰富的模型/子架构的范例。为了克服推荐域中的数据多态性和体系结构异构性挑战，NASRec 建立了一个大型超网(即搜索空间)来搜索完整的体系结构。超级网结合了多种操作员的选择和密集的连接，以最大限度地减少人的努力，找到前科。NASRec 的规模和异质性带来了一些挑战，如培训效率低下、操作员失衡和等级相关性降低。我们通过提出单操作者任意连接采样、操作者平衡交互模块和训练后微调来应对这些挑战。我们精心设计的模型 NASRecNet 在三个点击率(Click-Through Rate，CTR)预测基准上显示出有希望的结果，表明 NASRecc 的性能优于手工设计的模型和现有的 NAS 方法，具有最先进的性能。我们的工作 https://github.com/facebookresearch/nasrec 公开。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NASRec:+Weight+Sharing+Neural+Architecture+Search+for+Recommender+Systems)|0|
|[Membership Inference Attacks Against Sequential Recommender Systems](https://doi.org/10.1145/3543507.3583447)|Zhihao Zhu, Chenwang Wu, Rui Fan, Defu Lian, Enhong Chen|University of Science and Technology of China, China|Recent studies have demonstrated the vulnerability of recommender systems to membership inference attacks, which determine whether a user’s historical data was utilized for model training, posing serious privacy leakage issues. Existing works assumed that member and non-member users follow different recommendation modes, and then infer membership based on the difference vector between the user’s historical behaviors and the recommendation list. The previous frameworks are invalid against inductive recommendations, such as sequential recommendations, since the disparities of difference vectors constructed by the recommendations between members and non-members become imperceptible. This motivates us to dig deeper into the target model. In addition, most MIA frameworks assume that they can obtain some in-distribution data from the same distribution of the target data, which is hard to gain in recommender system. To address these difficulties, we propose a Membership Inference Attack framework against sequential recommenders based on Model Extraction(ME-MIA). Specifically, we train a surrogate model to simulate the target model based on two universal loss functions. For a given behavior sequence, the loss functions ensure the recommended items and corresponding rank of the surrogate model are consistent with the target model’s recommendation. Due to the special training mode of the surrogate model, it is hard to judge which user is its member(non-member). Therefore, we establish a shadow model and use shadow model’s members(non-members) to train the attack model later. Next, we build a user feature generator to construct representative feature vectors from the shadow(surrogate) model. The crafting feature vectors are finally input into the attack model to identify users’ membership. Furthermore, to tackle the high cost of obtaining in-distribution data, we develop two variants of ME-MIA, realizing data-efficient and even data-free MIA by fabricating authentic in-distribution data. Notably, the latter is impossible in the previous works. Finally, we evaluate ME-MIA against multiple sequential recommendation models on three real-world datasets. Experimental results show that ME-MIA and its variants can achieve efficient extraction and outperform state-of-the-art algorithms in terms of attack performance.|最近的研究表明，推荐系统容易受到成员推断攻击，这决定了用户的历史数据是否被用于模型训练，造成严重的隐私泄露问题。现有的研究假设成员用户和非成员用户遵循不同的推荐模式，然后根据用户历史行为和推荐列表之间的差异向量推断成员关系。以前的框架对于归纳推荐(如顺序推荐)是无效的，因为成员和非成员之间由推荐构造的差异向量的差异变得不可察觉。这促使我们更深入地研究目标模型。此外，大多数 MIA 框架都假定它们可以从目标数据的同一分布中获得一些分布内数据，而这在推荐系统中是很难获得的。为了解决这些问题，我们提出了一个基于模型提取(ME-MIA)的针对顺序推荐的成员推理攻击框架。具体来说，我们训练了一个代理模型来模拟目标模型基于两个通用的损失函数。对于给定的行为序列，损失函数保证代理模型的推荐项和相应的等级与目标模型的推荐一致。由于代理模型的特殊训练模式，很难判断哪个用户是它的成员(非成员)。因此，我们建立了一个阴影模型，然后利用阴影模型的成员(非成员)来训练攻击模型。接下来，我们构建一个用户特征生成器来从阴影(代理)模型中构造具有代表性的特征向量。最后将特征向量输入到攻击模型中，识别用户的隶属关系。此外，为了解决获取内部分发数据的高成本问题，我们开发了两种不同的 ME-MIA，通过制作真实的内部分发数据来实现数据高效甚至无数据的 MIA。值得注意的是，后者在前面的作品中是不可能的。最后，我们在三个实际数据集上对多个顺序推荐模型进行 ME-MIA 评估。实验结果表明，ME-MIA 算法及其变体能够实现有效的提取，并且在攻击性能方面优于目前最先进的算法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Membership+Inference+Attacks+Against+Sequential+Recommender+Systems)|0|
|[Communicative MARL-based Relevance Discerning Network for Repetition-Aware Recommendation](https://doi.org/10.1145/3543507.3583459)|Kaiyuan Li, Pengfei Wang, Haitao Wang, Qiang Liu, Xingxing Wang, Dong Wang, Shangguang Wang|Meituan, China; Beijing University of Posts and Telecommunications, China|The repeated user-item interaction now is becoming a common phenomenon in the e-commerce scenario. Due to its potential economic profit, various models are emerging to predict which item will be re-interacted based on the user-item interactions. In this specific scenario, item relevance is a critical factor that needs to be concerned, which tends to have different effects on the succeeding re-interacted one (i.e., stimulating or delaying its emergence). It is necessary to make a detailed discernment of item relevance for a better repetition-aware recommendation. Unfortunately, existing works usually mixed all these types, which may disturb the learning process and result in poor performance. In this paper, we introduce a novel Communicative MARL-based Relevance Discerning Network (CARDfor short) to automatically discern the item relevance for a better repetition-aware recommendation. Specifically, CARDformalizes the item relevance discerning problem into a communication selection process in MARL. CARDtreats each unique interacted item as an agent and defines three different communication types over agents, which are stimulative, inhibitive, and noisy respectively. After this, CARDutilizes a Gumbel-enhanced classifier to distinguish the communication types among agents, and an attention-based Reactive Point Process is further designed to transmit the well-discerned stimulative and inhibitive incentives separately among all agents to make an effective collaboration for repetition decisions. Experimental results on two real-world e-commerce datasets show that our proposed method outperforms the state-of-the-art recommendation methods in terms of both sequential and repetition-aware recommenders. Furthermore, CARDis also deployed in the online sponsored search advertising system in Meituan, obtaining a performance improvement of over 1.5% and 1.2% in CTR and effective Cost Per Mille (eCPM) respectively, which is significant to the business.|重复的用户-项目交互现在正在成为电子商务场景中的一个普遍现象。由于其潜在的经济利益，各种模型正在出现，以预测哪些项目将重新交互的基础上，用户项目的交互。在这个特定的场景中，项目相关性是一个需要关注的关键因素，它往往对后续的重新相互作用有不同的影响(即，刺激或延迟其出现)。有必要对项目的相关性进行详细的识别，以便更好地提出有重复意识的建议。不幸的是，现有的作品往往混合了所有这些类型，这可能会干扰学习过程，导致较差的表现。本文介绍了一种新的基于交际 MARL 的关联识别网络(CARD) ，该网络可以自动识别项目的相关性，从而获得更好的重复感知推荐。特别地，CARD 将项目相关性识别问题形式化为 MARL 中的通信选择过程。CARD 将每个独特的交互项目视为一个代理，并定义了代理上的三种不同的通信类型，分别是刺激性、抑制性和噪声性。此后，CARD 利用 Gumbel 增强的分类器来区分代理人之间的通信类型，并进一步设计基于注意力的反应点过程，以在所有代理人之间分别传递明确的刺激和抑制激励，以便为重复决策进行有效的协作。在两个实际电子商务数据集上的实验结果表明，该方法在顺序推荐和重复推荐方面都优于目前最先进的推荐方法。此外，CARD 还部署在在线赞助的搜索广告系统中，美团点击率和有效每公里成本(eCPM)分别提高了1.5% 和1.2% ，这对业务具有重要意义。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Communicative+MARL-based+Relevance+Discerning+Network+for+Repetition-Aware+Recommendation)|0|
|[Personalized Graph Signal Processing for Collaborative Filtering](https://doi.org/10.1145/3543507.3583466)|Jiahao Liu, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, Li Shang, Ning Gu|Amazon, USA; Microsoft Research Asia, China; School of Computer Science, Fudan University, China and Shanghai Key Laboratory of Data Science, Fudan University, China|The collaborative filtering (CF) problem with only user-item interaction information can be solved by graph signal processing (GSP), which uses low-pass filters to smooth the observed interaction signals on the similarity graph to obtain the prediction signals. However, the interaction signal may not be sufficient to accurately characterize user interests and the low-pass filters may ignore the useful information contained in the high-frequency component of the observed signals, resulting in suboptimal accuracy. To this end, we propose a personalized graph signal processing (PGSP) method for collaborative filtering. Firstly, we design the personalized graph signal containing richer user information and construct an augmented similarity graph containing more graph topology information, to more effectively characterize user interests. Secondly, we devise a mixed-frequency graph filter to introduce useful information in the high-frequency components of the observed signals by combining an ideal low-pass filter that smooths signals globally and a linear low-pass filter that smooths signals locally. Finally, we combine the personalized graph signal, the augmented similarity graph and the mixed-frequency graph filter by proposing a pipeline consisting of three key steps: pre-processing, graph convolution and post-processing. Extensive experiments show that PGSP can achieve superior accuracy compared with state-of-the-art CF methods and, as a nonparametric method, PGSP has very high training efficiency.|图形信号处理(gSP)可以解决只有用户-项目交互信息的协同过滤(CF)问题，它使用低通滤波器平滑相似图上观察到的交互信号，以获得预测信号。然而，交互信号可能不足以准确地表征用户的兴趣，而且低通滤波器可能会忽略观测信号的高频分量中包含的有用信息，从而导致次优精度。为此，我们提出了一个个性化的图形信号处理(PgSP)方法来处理协同过滤。首先，设计了包含更丰富用户信息的个性化图形信号，构造了包含更多图形拓扑信息的增广相似度图，以更有效地刻画用户兴趣。其次，我们设计了一个混合频率图形滤波器，通过结合理想的低通滤波器对信号进行全局平滑和线性低通滤波器对信号进行局部平滑，从而在观测信号的高频成分中引入有用的信息。最后，结合个性化图形信号、增强相似图和混合频率图滤波，提出了一种由预处理、图卷积和后处理三个关键步骤组成的流水线。大量的实验表明，与现有的 CF 方法相比，PGSP 具有更高的精度，并且作为一种非参数方法，PGSP 具有很高的训练效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Graph+Signal+Processing+for+Collaborative+Filtering)|0|
|[Multi-Task Recommendations with Reinforcement Learning](https://doi.org/10.1145/3543507.3583467)|Ziru Liu, Jiejie Tian, Qingpeng Cai, Xiangyu Zhao, Jingtong Gao, Shuchang Liu, Dayou Chen, Tonghao He, Dong Zheng, Peng Jiang, Kun Gai|Kuaishou, China; Unaffiliated, China; City University of Hong Kong, China|In recent years, Multi-task Learning (MTL) has yielded immense success in Recommender System (RS) applications. However, current MTL-based recommendation models tend to disregard the session-wise patterns of user-item interactions because they are predominantly constructed based on item-wise datasets. Moreover, balancing multiple objectives has always been a challenge in this field, which is typically avoided via linear estimations in existing works. To address these issues, in this paper, we propose a Reinforcement Learning (RL) enhanced MTL framework, namely RMTL, to combine the losses of different recommendation tasks using dynamic weights. To be specific, the RMTL structure can address the two aforementioned issues by (i) constructing an MTL environment from session-wise interactions and (ii) training multi-task actor-critic network structure, which is compatible with most existing MTL-based recommendation models, and (iii) optimizing and fine-tuning the MTL loss function using the weights generated by critic networks. Experiments on two real-world public datasets demonstrate the effectiveness of RMTL with a higher AUC against state-of-the-art MTL-based recommendation models. Additionally, we evaluate and validate RMTL's compatibility and transferability across various MTL models.|近年来，多任务学习在推荐系统应用方面取得了巨大的成功。然而，目前基于 MTL 的推荐模型倾向于忽略用户项目交互的会话模式，因为它们主要是基于项目数据集构建的。此外，平衡多个目标一直是这个领域的一个挑战，这通常是通过现有工作中的线性估计来避免的。为了解决这些问题，在本文中，我们提出了一个强化学习增强的 MTL 框架，即 RMTL，它使用动态权重来组合不同推荐任务的丢失。具体来说，RMTL 结构可以解决上述两个问题: (1)通过会话交互构建 MTL 环境; (2)训练与大多数基于 MTL 的推荐模型兼容的多任务参与者-评论者网络结构; (3)利用评论者网络生成的权重优化和微调 MTL 损失函数。在两个真实世界的公共数据集上的实验证明了具有较高 AUC 的 RMTL 对基于最新 MTL 的推荐模型的有效性。此外，我们评估和验证 RMTL 的兼容性和跨各种 MTL 模型的可转移性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Recommendations+with+Reinforcement+Learning)|0|
|[A Self-Correcting Sequential Recommender](https://doi.org/10.1145/3543507.3583479)|Yujie Lin, Chenyang Wang, Zhumin Chen, Zhaochun Ren, Xin Xin, Qiang Yan, Maarten de Rijke, Xiuzhen Cheng, Pengjie Ren|Shandong University, China; WeChat, Tencent, China; University of Amsterdam, Netherlands|Sequential recommendations aim to capture users' preferences from their historical interactions so as to predict the next item that they will interact with. Sequential recommendation methods usually assume that all items in a user's historical interactions reflect her/his preferences and transition patterns between items. However, real-world interaction data is imperfect in that (i) users might erroneously click on items, i.e., so-called misclicks on irrelevant items, and (ii) users might miss items, i.e., unexposed relevant items due to inaccurate recommendations. To tackle the two issues listed above, we propose STEAM, a Self-correcTing sEquentiAl recoMmender. STEAM first corrects an input item sequence by adjusting the misclicked and/or missed items. It then uses the corrected item sequence to train a recommender and make the next item prediction.We design an item-wise corrector that can adaptively select one type of operation for each item in the sequence. The operation types are 'keep', 'delete' and 'insert.' In order to train the item-wise corrector without requiring additional labeling, we design two self-supervised learning mechanisms: (i) deletion correction (i.e., deleting randomly inserted items), and (ii) insertion correction (i.e., predicting randomly deleted items). We integrate the corrector with the recommender by sharing the encoder and by training them jointly. We conduct extensive experiments on three real-world datasets and the experimental results demonstrate that STEAM outperforms state-of-the-art sequential recommendation baselines. Our in-depth analyses confirm that STEAM benefits from learning to correct the raw item sequences.|序贯推荐旨在从用户的历史交互中获取他们的偏好，从而预测他们将要交互的下一个项目。顺序推荐方法通常假设用户历史交互中的所有项目都反映了用户的偏好和项目之间的转换模式。然而，真实世界的交互数据是不完美的，因为(i)用户可能会错误地点击项目，即所谓的不相关项目的错误点击，以及(ii)用户可能会错过项目，即由于不准确的推荐而未公开的相关项目。为了解决上面列出的两个问题，我们提出 STEAM，一个自我修正的 sEquentiAl 推荐器。STEAM 首先通过调整错误点击和/或错过的项目来更正输入项目序列。然后使用校正后的项目序列来训练推荐者并对下一个项目进行预测。我们设计了一个项目校正器，它可以自适应地为序列中的每个项目选择一种操作类型。操作类型为“ keep”、“ delete”和“ insert”。为了训练项目校正器而不需要额外的标签，我们设计了两个自我监督学习机制: (i)删除校正(即删除随机插入的项目)和(ii)插入校正(即预测随机删除的项目)。我们通过共享编码器和共同训练，将校正器和推荐器结合起来。我们在三个真实世界的数据集上进行了广泛的实验，实验结果表明 STEAM 的性能优于最先进的顺序推荐基线。我们的深入分析证实，STEAM 受益于学习纠正原始项目序列。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Self-Correcting+Sequential+Recommender)|0|
|[Confident Action Decision via Hierarchical Policy Learning for Conversational Recommendation](https://doi.org/10.1145/3543507.3583536)|Heeseon Kim, Hyeongjun Yang, KyongHo Lee|Department of Computer Science, Yonsei University, Republic of Korea|Conversational recommender systems (CRS) aim to acquire a user’s dynamic interests for a successful recommendation. By asking about his/her preferences, CRS explore current needs of a user and recommend items of interest. However, previous works may not determine a proper action in a timely manner which leads to the insufficient information gathering and the waste of conversation turns. Since they learn a single decision policy, it is difficult for them to address the general decision problems in CRS. Besides, existing methods do not distinguish whether the past behaviors inferred from the historical interactions are closely related to the user’s current preference. To address these issues, we propose a novel Hierarchical policy learning based Conversational Recommendation framework (HiCR). HiCR formulates the multi-round decision making process as a hierarchical policy learning scheme, which consists of both a high-level policy and a low-level policy. In detail, the high-level policy aims to determine what type of action to take, such as a recommendation or a query, by observing the comprehensive conversation information. According to the decided action type, the low-level policy selects a specific action, such as which attribute to ask or which item to recommend. The hierarchical conversation policy enables CRS to decide an optimal action, resulting in reducing the unnecessary consumption of conversation turns and the continuous failure of recommendations. Furthermore, in order to filter out the unnecessary historical information when enriching the current user preference, we extract and utilize the informative past behaviors that are attentive to the current needs. Empirical experiments on four real-world datasets show the superiority of our approach against the current state-of-the-art methods.|会话推荐系统(CRS)的目标是获取用户的动态兴趣，从而实现成功的推荐。通过询问用户的偏好，CRS 探索用户当前的需求并推荐感兴趣的项目。然而，以往的作品不能及时确定适当的行动，导致信息收集不足和谈话的浪费。由于他们只学习单一的决策策略，因此很难解决 CRS 中的一般决策问题。此外，现有的方法不能区分从历史交互中推断出的过去行为是否与用户当前的偏好密切相关。为了解决这些问题，我们提出了一种新的基于层次策略学习的会话推荐框架(HiCR)。HiCR 将多轮决策过程描述为一个分层的决策学习方案，该方案由高层决策和低层决策两部分组成。具体来说，高级策略旨在通过观察全面的会话信息来确定采取何种类型的操作，比如推荐或查询。根据确定的操作类型，底层策略选择一个特定的操作，比如询问哪个属性或推荐哪个项目。分层对话策略使 CRS 能够决定一个最优的操作，从而减少不必要的话轮消耗和建议的持续失败。此外，为了在丰富当前用户偏好时过滤掉不必要的历史信息，我们提取并利用了关注当前需求的信息性过去行为。在四个真实世界数据集上的实验表明了我们的方法相对于当前最先进的方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Confident+Action+Decision+via+Hierarchical+Policy+Learning+for+Conversational+Recommendation)|0|
|[Mutual Wasserstein Discrepancy Minimization for Sequential Recommendation](https://doi.org/10.1145/3543507.3583529)|Ziwei Fan, Zhiwei Liu, Hao Peng, Philip S. Yu|Beihang University, USA; Salesforce AI Research, USA; University of Illinois Chicago, USA|Self-supervised sequential recommendation significantly improves recommendation performance by maximizing mutual information with well-designed data augmentations. However, the mutual information estimation is based on the calculation of Kullback Leibler divergence with several limitations, including asymmetrical estimation, the exponential need of the sample size, and training instability. Also, existing data augmentations are mostly stochastic and can potentially break sequential correlations with random modifications. These two issues motivate us to investigate an alternative robust mutual information measurement capable of modeling uncertainty and alleviating KL divergence limitations. To this end, we propose a novel self-supervised learning framework based on Mutual WasserStein discrepancy minimization MStein for the sequential recommendation. We propose the Wasserstein Discrepancy Measurement to measure the mutual information between augmented sequences. Wasserstein Discrepancy Measurement builds upon the 2-Wasserstein distance, which is more robust, more efficient in small batch sizes, and able to model the uncertainty of stochastic augmentation processes. We also propose a novel contrastive learning loss based on Wasserstein Discrepancy Measurement. Extensive experiments on four benchmark datasets demonstrate the effectiveness of MStein over baselines. More quantitative analyses show the robustness against perturbations and training efficiency in batch size. Finally, improvements analysis indicates better representations of popular users or items with significant uncertainty. The source code is at https://github.com/zfan20/MStein.|自监督顺序推荐通过设计良好的数据增强最大化互信息，显著提高了推荐性能。然而，互信息估计是基于 Kullback Leibler 散度的计算，具有不对称估计、样本量的指数需求和训练不稳定性等局限性。此外，现有的数据扩充大多是随机的，并可能打破随机修改顺序相关性。这两个问题促使我们研究一种可替代的鲁棒互信息测量方法，该方法能够对不确定性进行建模并减轻 KL 发散的限制。为此，我们提出了一种新的基于 Mutual WasserStein 差异最小化 MStein 的自监督学习框架，用于顺序推荐。我们提出了 Wasserstein 差异度量来度量增广序列之间的互信息。Wasserstein 误差测度建立在2-Wasserstein 距离的基础上，该距离在小批量情况下具有更强的鲁棒性和更高的效率，能够对随机增量过程的不确定性进行建模。我们还提出了一种新的基于 Wasserstein 差异度量的对比学习损失。在四个基准数据集上的大量实验证明了 MStein 在基线上的有效性。进一步的定量分析表明，该算法具有较强的抗干扰能力，并且在批量情况下具有较高的训练效率。最后，改进分析表明，流行用户或具有显著不确定性的项目的表示更好。源代码在 https://github.com/zfan20/mstein。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mutual+Wasserstein+Discrepancy+Minimization+for+Sequential+Recommendation)|0|
|[Automatic Feature Selection By One-Shot Neural Architecture Search In Recommendation Systems](https://doi.org/10.1145/3543507.3583444)|He Wei, Yuekui Yang, Haiyang Wu, Yangyang Tang, Meixi Liu, Jianfeng Li|Machine learning platform department, TEG, Tencent, China; Machine learning platform department, TEG, Tencent, China and Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Tsinghua University, China|Feature selection is crucial in large-scale recommendation system, which can not only reduce the computational cost, but also improve the recommendation efficiency. Most existing works rank the features and then select the top-k ones as the final feature subset. However, they assess feature importance individually and ignore the interrelationship between features. Consequently, multiple features with high relevance may be selected simultaneously, resulting in sub-optimal result. In this work, we solve this problem by proposing an AutoML-based feature selection framework that can automatically search the optimal feature subset. Specifically, we first embed the search space into a weight-sharing Supernet. Then, a two-stage neural architecture search method is employed to evaluate the feature quality. In the first stage, a well-designed sampling method considering feature convergence fairness is applied to train the Supernet. In the second stage, a reinforcement learning method is used to search for the optimal feature subset efficiently. The Experimental results on two real datasets demonstrate the superior performance of new framework over other solutions. Our proposed method obtain significant improvement with a 20% reduction in the amount of features on the Criteo. More validation experiments demonstrate the ability and robustness of the framework.|特征选择是大规模推荐系统的关键，它不仅可以降低计算量，而且可以提高推荐效率。大多数已有的作品对特征进行排序，然后选择最上面的 k 个特征作为最终的特征子集。然而，他们单独评估特征的重要性，而忽略了特征之间的相互关系。因此，可以同时选择多个高相关性的特征，从而导致次优结果。针对这一问题，本文提出了一种基于 AutoML 的特征选择框架，该框架可以自动搜索最优特征子集。具体来说，我们首先将搜索空间嵌入到一个权重共享的超级网络中。然后，采用两阶段神经网络结构搜索方法对特征质量进行评价。在第一阶段，采用一种设计良好的考虑特征收敛公平性的抽样方法对超网进行训练。在第二阶段，使用强化学习方法有效地搜索最优特征子集。在两个实际数据集上的实验结果表明，新框架的性能优于其他解决方案。我们提出的方法获得了显着的改进，在标准的数量减少了20% 的特征。更多的验证实验证明了该框架的能力和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Feature+Selection+By+One-Shot+Neural+Architecture+Search+In+Recommendation+Systems)|0|
|[Catch: Collaborative Feature Set Search for Automated Feature Engineering](https://doi.org/10.1145/3543507.3583527)|Guoshan Lu, Haobo Wang, Saisai Yang, Jing Yuan, Guozheng Yang, Cheng Zang, Gang Chen, Junbo Zhao|Zheshang Bank Co., Ltd., China; Zhejiang University, China; Institute of Computing Innovation, Zhejiang University, China|Feature engineering often plays a crucial role in building mining systems for tabular data, which traditionally requires experienced human experts to perform. Thanks to the rapid advances in reinforcement learning, it has offered an automated alternative, i.e. automated feature engineering (AutoFE). In this work, through scrutiny of the prior AutoFE methods, we characterize several research challenges that remained in this regime, concerning system-wide efficiency, efficacy, and practicality toward production. We then propose Catch, a full-fledged new AutoFE framework that comprehensively addresses the aforementioned challenges. The core to Catch composes a hierarchical-policy reinforcement learning scheme that manifests a collaborative feature engineering exploration and exploitation grounded on the granularity of the whole feature set. At a higher level of the hierarchy, a decision-making module controls the post-processing of the attained feature engineering transformation. We extensively experiment with Catch on 26 academic standardized tabular datasets and 9 industrialized real-world datasets. Measured by numerous metrics and analyses, Catch establishes a new state-of-the-art, from perspectives performance, latency as well as its practicality towards production. Source code1 can be found at https://github.com/1171000709/Catch.|在构建表格数据挖掘系统时，特征工程往往起着至关重要的作用，表格数据挖掘传统上需要有经验的人类专家来完成。由于强化学习的快速发展，它提供了一种自动化的替代方案，即自动化特征工程(AutoFE)。在这项工作中，通过审查以前的自动有限元方法，我们描述了几个研究挑战，仍然在这个制度，关于系统的效率，效率和实用性的生产。然后，我们建议使用 Catch，这是一个成熟的新的 AutoFE 框架，可以全面解决上述挑战。Core to Catch 组成了一个层次化的策略强化学习方案，体现了基于整个特性集粒度的协同特性工程探索和开发。在层次结构的更高层次上，决策模块控制所获得的特征工程变换的后处理。我们对26个学术标准化表格数据集和9个工业化真实世界数据集进行了广泛的实验。通过大量的度量和分析，Catch 从性能、延迟以及对生产的实用性的角度建立了一个新的最先进的状态。源代码1可在 https://github.com/1171000709/catch 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Catch:+Collaborative+Feature+Set+Search+for+Automated+Feature+Engineering)|0|
|[The Hitchhiker's Guide to Facebook Web Tracking with Invisible Pixels and Click IDs](https://doi.org/10.1145/3543507.3583311)|Paschalis Bekos, Panagiotis Papadopoulos, Evangelos P. Markatos, Nicolas Kourtellis|Telefonica Research, Spain; FORTH, Greece; University of Crete/FORTH, Greece|Over the past years, advertisement companies have used various tracking methods to persistently track users across the web. Such tracking methods usually include first and third-party cookies, cookie synchronization, as well as a variety of fingerprinting mechanisms. Facebook (FB) recently introduced a new tagging mechanism that attaches a one-time tag as a URL parameter (FBCLID) on outgoing links to other websites. Although such a tag does not seem to have enough information to persistently track users, we demonstrate that despite its ephemeral nature, when combined with FB Pixel, it can aid in persistently monitoring user browsing behavior across i) different websites, ii) different actions on each website, iii) time, i.e., both in the past as well as in the future. We refer to this online monitoring of users as FB web tracking. We find that FB Pixel tracks a wide range of user activities on websites with alarming detail, especially on websites classified as sensitive categories under GDPR. Also, we show how the FBCLID tag can be used to match, and thus de-anonymize, activities of online users performed in the distant past (even before those users had a FB account) tracked by FB Pixel. In fact, by combining this tag with cookies that have rolling expiration dates, FB can also keep track of users' browsing activities in the future as well. Our experimental results suggest that 23% of the 10k most popular websites have adopted this technology, and can contribute to this activity tracking on the web. Furthermore, our longitudinal study shows that this type of user activity tracking can go as far back as 2015. Simply said, if a user creates for the first time a FB account today, FB could, under some conditions, match their anonymously collected past web browsing activity to their newly created FB profile, from as far back as 2015 and continue tracking their activity in the future.|在过去的几年里，广告公司使用了各种各样的跟踪方法来持续跟踪网络上的用户。这种跟踪方法通常包括第一方和第三方 cookie、 cookie 同步以及各种指纹识别机制。Facebook (FB)最近推出了一种新的标签机制，它将一次性标签作为 URL 参数(FBCLID)附加到其他网站的外向链接上。虽然这样的标签似乎没有足够的信息来持续跟踪用户，我们证明，尽管它的短暂性质，当结合 FB 像素，它可以帮助持续监测用户浏览行为在 i)不同的网站，ii)不同的行动在每个网站，iii)时间，即在过去和未来。我们把这种对用户的在线监控称为 FB 网络跟踪。我们发现，FB 像素跟踪广泛的用户活动的网站具有惊人的细节，特别是在网站归类为敏感类别下的 GDPR。此外，我们展示了如何使用 FBCLID 标签来匹配，从而去匿名，在线用户的活动执行在遥远的过去(甚至在那些用户有一个 FB 帐户之前)由 FB 像素跟踪。事实上，通过将这个标签与具有滚动过期日期的 cookie 相结合，FB 还可以跟踪用户未来的浏览活动。我们的实验结果表明，23% 的10k 最受欢迎的网站已经采用了这项技术，并可以有助于在网上跟踪这项活动。此外，我们的追踪研究显示，这种类型的用户活动跟踪可以追溯到2015年。简单地说，如果一个用户今天第一次创建一个 FB 帐户，FB 可以，在某些条件下，匹配他们的匿名收集过去的网页浏览活动和他们新创建的 FB 配置文件，从2015年开始，并在未来继续跟踪他们的活动。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Hitchhiker's+Guide+to+Facebook+Web+Tracking+with+Invisible+Pixels+and+Click+IDs)|0|
|[Atrapos: Real-time Evaluation of Metapath Query Workloads](https://doi.org/10.1145/3543507.3583322)|Serafeim Chatzopoulos, Thanasis Vergoulis, Dimitrios Skoutas, Theodore Dalamagas, Christos Tryfonopoulos, Panagiotis Karras|University of the Peloponnese, Greece; University of the Peloponnese, Greece and IMSI, Athena RC, Greece; IMSI, Athena RC, Greece; Aarhus University, Denmark|Heterogeneous information networks (HINs) represent different types of entities and relationships between them. Exploring and mining HINs relies on metapath queries that identify pairs of entities connected by relationships of diverse semantics. While the real-time evaluation of metapath query workloads on large, web-scale HINs is highly demanding in computational cost, current approaches do not exploit interrelationships among the queries. In this paper, we present Atrapos, a new approach for the real-time evaluation of metapath query workloads that leverages a combination of efficient sparse matrix multiplication and intermediate result caching. Atrapos selects intermediate results to cache and reuse by detecting frequent sub-metapaths among workload queries in real time, using a tailor-made data structure, the Overlap Tree, and an associated caching policy. Our experimental study on real data shows that Atrapos  accelerates exploratory data analysis and mining on HINs, outperforming off-the-shelf caching approaches and state-of-the-art research prototypes in all examined scenarios.|异构信息网络(HIN)表示不同类型的实体以及它们之间的关系。探索和挖掘 HIN 依赖于元路径查询，这些查询标识由不同语义关系连接的实体对。尽管对大型 Web 规模 HIN 上的元路径查询工作负载进行实时评估对计算成本要求很高，但目前的方法没有利用查询之间的相互关系。在这篇文章中，我们介绍了一种新的实时评估元路径查询工作负载的方法—— Arapos，它结合了高效的稀疏矩阵乘法和中间结果缓存。Apapos 通过实时检测工作负载查询之间频繁的子元路径，使用量身定制的数据结构、重叠树和相关的缓存策略来选择缓存和重用的中间结果。我们对真实数据的实验研究表明，在所有经过检验的场景中，阿特波斯加速了 HIN 的探索性数据分析和挖掘，表现优于现成的缓存方法和最先进的研究原型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Atrapos:+Real-time+Evaluation+of+Metapath+Query+Workloads)|0|
|[TRAVERS: A Diversity-Based Dynamic Approach to Iterative Relevance Search over Knowledge Graphs](https://doi.org/10.1145/3543507.3583429)|Ziyang Li, Yu Gu, Yulin Shen, Wei Hu, Gong Cheng|Ohio State University, USA; State Key Laboratory for Novel Software Technology, Nanjing University, China|Relevance search over knowledge graphs seeks top-ranked answer entities that are most relevant to a query entity. Since the semantics of relevance varies with the user need and its formalization is difficult for non-experts, existing methods infer semantics from user-provided example answer entities. However, a user may provide very few examples, even none at the beginning of interaction, thereby limiting the effectiveness of such methods. In this paper, we vision a more practical scenario called labeling-based iterative relevance search: instead of effortfully inputting example answer entities, the user effortlessly (e.g., implicitly) labels current answer entities, and is rewarded with improved answer entities in the next iteration. To realize the scenario, our approach TRAVERS incorporates two rankers: a diversity-oriented ranker for supporting cold start and avoiding converging to sub-optimum caused by noisy labels, and a relevance-oriented ranker capable of handling unbalanced labels. Moreover, the two rankers and their combination dynamically evolve over iterations. TRAVERS outperformed a variety of baselines in experiments with simulated and real user behavior.|基于知识图的相关性搜索寻找与查询实体最相关的排名最高的答案实体。由于相关性的语义随用户需求而变化，而且对于非专家来说，相关性的形式化很困难，现有的方法都是从用户提供的示例答案实体中推断语义。然而，用户可能只提供很少的例子，甚至在交互开始时没有例子，从而限制了这些方法的有效性。在本文中，我们设想了一个更实际的场景，叫做基于标签的迭代相关性搜索: 用户不必费力地输入示例答案实体，而是毫不费力地(例如，隐式地)标记当前答案实体，并在下一次迭代中得到改进的答案实体。为了实现该方案，我们的方法 TRAVERS 包含两个排序器: 一个面向多样性的排序器支持冷启动，避免收敛到次优由于噪声标签，和一个相关性导向的排序器能够处理不平衡的标签。此外，这两个排名及其组合在迭代中动态演化。在模拟和真实用户行为的实验中，TRAVERS 的表现优于各种基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TRAVERS:+A+Diversity-Based+Dynamic+Approach+to+Iterative+Relevance+Search+over+Knowledge+Graphs)|0|
|[Message Function Search for Knowledge Graph Embedding](https://doi.org/10.1145/3543507.3583546)|Shimin Di, Lei Chen|The Hong Kong University of Secience and Technology, China; The Hong Kong University of Science and Technology (Guangzhou), China|Recently, many promising embedding models have been proposed to embed knowledge graphs (KGs) and their more general forms, such as n-ary relational data (NRD) and hyper-relational KG (HKG). To promote the data adaptability and performance of embedding models, KG searching methods propose to search for suitable models for a given KG data set. But they are restricted to a single KG form, and the searched models are restricted to a single type of embedding model. To tackle such issues, we propose to build a search space for the message function in graph neural networks (GNNs). However, it is a non-trivial task. Existing message function designs fix the structures and operators, which makes them difficult to handle different KG forms and data sets. Therefore, we first design a novel message function space, which enables both structures and operators to be searched for the given KG form (including KG, NRD, and HKG) and data. The proposed space can flexibly take different KG forms as inputs and is expressive to search for different types of embedding models. Especially, some existing message function designs and some classic KG embedding models can be instantiated as special cases of our space. We empirically show that the searched message functions are data-dependent, and can achieve leading performance on benchmark KGs, NRD, and HKGs.|近年来，人们提出了许多有前途的嵌入模型来嵌入知识图(KG)及其更一般的形式，如 n 元关系数据(NRD)和超关系 KG (HKG)。为了提高嵌入模型的数据适应性和性能，KG 搜索方法提出为给定的 KG 数据集寻找合适的模型。但是它们仅限于单一的 KG 形式，所搜索的模型仅限于单一类型的嵌入模型。为了解决这些问题，我们提出在图神经网络(GNN)中建立一个消息函数的搜索空间。然而，这是一项非常重要的任务。现有的消息功能设计固定了结构和操作符，使得它们难以处理不同的 KG 表单和数据集。因此，我们首先设计一个新的消息函数空间，它允许搜索给定的 KG 表单(包括 KG、 NRD 和 HKG)和数据的结构和操作符。该空间可以灵活地采用不同的 KG 形式作为输入，具有表达性，可以搜索不同类型的嵌入模型。特别是，现有的一些消息函数设计和一些经典的 KG 嵌入模型可以作为我们空间的特例进行实例化。实验结果表明，搜索消息函数具有数据依赖性，可以在基准幼儿园、 NRD 幼儿园和 HKG 幼儿园中取得领先的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Message+Function+Search+for+Knowledge+Graph+Embedding)|0|
|[FINGER: Fast Inference for Graph-based Approximate Nearest Neighbor Search](https://doi.org/10.1145/3543507.3583318)|Patrick H. Chen, WeiCheng Chang, JyunYu Jiang, HsiangFu Yu, Inderjit S. Dhillon, ChoJui Hsieh||Approximate K-Nearest Neighbor Search (AKNNS) has now become ubiquitous in modern applications, for example, as a fast search procedure with two tower deep learning models. Graph-based methods for AKNNS in particular have received great attention due to their superior performance. These methods rely on greedy graph search to traverse the data points as embedding vectors in a database. Under this greedy search scheme, we make a key observation: many distance computations do not influence search updates so these computations can be approximated without hurting performance. As a result, we propose FINGER, a fast inference method to achieve efficient graph search. FINGER approximates the distance function by estimating angles between neighboring residual vectors with low-rank bases and distribution matching. The approximated distance can be used to bypass unnecessary computations, which leads to faster searches. Empirically, accelerating a popular graph-based method named HNSW by FINGER is shown to outperform existing graph-based methods by 20%-60% across different benchmark datasets.|近似 K 最近邻搜索(AKNNS)已经成为现代应用中普遍存在的问题，例如，作为一种具有两个塔式深度学习模型的快速搜索过程。基于图的 AKNNS 方法由于其优越的性能而受到了广泛的关注。这些方法依赖于贪婪图搜索，以嵌入向量的形式遍历数据库中的数据点。在这种贪婪的搜索方案下，我们做了一个关键的观察: 许多距离计算不影响搜索更新，所以这些计算可以近似而不损害性能。因此，我们提出了 FINGER，一种快速的推理方法来实现有效的图搜索。FINGER 通过估计低秩基相邻残差向量之间的夹角和分布匹配来逼近距离函数。近似距离可以用来绕过不必要的计算，从而导致更快的搜索。经验表明，通过 FINGER 加速一种流行的基于图的方法 HNSW，在不同的基准数据集上比现有的基于图的方法的性能提高了20% -60% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FINGER:+Fast+Inference+for+Graph-based+Approximate+Nearest+Neighbor+Search)|0|
|[Match4Match: Enhancing Text-Video Retrieval by Maximum Flow with Minimum Cost](https://doi.org/10.1145/3543507.3583365)|Zhongjie Duan, Chengyu Wang, Cen Chen, Wenmeng Zhou, Jun Huang, Weining Qian|East China Normal University, China; Alibaba Group, China|With the explosive growth of video and text data on the web, text-video retrieval has become a vital task for online video platforms. Recently, text-video retrieval methods based on pre-trained models have attracted a lot of attention. However, existing methods cannot effectively capture the fine-grained information in videos, and typically suffer from the hubness problem where a collection of similar videos are retrieved by a large number of different queries. In this paper, we propose Match4Match, a new text-video retrieval method based on CLIP (Contrastive Language-Image Pretraining) and graph optimization theories. To balance calculation efficiency and model accuracy, Match4Match seamlessly supports three inference modes for different application scenarios. In fast vector retrieval mode, we embed texts and videos in the same space and employ a vector retrieval engine to obtain the top K videos. In fine-grained alignment mode, our method fully utilizes the pre-trained knowledge of the CLIP model to align words with corresponding video frames, and uses the fine-grained information to compute text-video similarity more accurately. In flow-style matching mode, to alleviate the detrimental impact of the hubness problem, we model the retrieval problem as a combinatorial optimization problem and solve it using maximum flow with minimum cost algorithm. To demonstrate the effectiveness of our method, we conduct experiments on five public text-video datasets. The overall performance of our proposed method outperforms state-of-the-art methods. Additionally, we evaluate the computational efficiency of Match4Match. Benefiting from the three flexible inference modes, Match4Match can respond to a large number of query requests with low latency or achieve high recall with acceptable time consumption.|随着网络视频和文本数据的爆炸式增长，文本视频检索已经成为在线视频平台的一项重要任务。近年来，基于预训练模型的文本视频检索方法引起了人们的广泛关注。然而，现有的方法不能有效地捕获视频中的细粒度信息，通常会遇到集线器问题，即大量不同的查询检索相似的视频集合。本文提出了一种基于对比语言-图像预训练(CLIP)和图形优化理论的文本-视频检索方法 Match4Match。为了平衡计算效率和模型精度，Match4Match 无缝支持针对不同应用场景的三种推理模式。在快速矢量检索模式下，我们将文本和视频嵌入到同一空间中，并使用矢量检索引擎获取最高 K 视频。在细粒度对齐模式下，该方法充分利用 CLIP 模型的预训练知识对相应的视频帧进行单词对齐，并利用细粒度信息更准确地计算文本-视频的相似度。在流式匹配模式下，为了减轻中继问题的不利影响，我们将检索问题建模为一个组合优化问题，并使用最大流和最小成本算法解决该问题。为了验证该方法的有效性，我们在五个公共文本视频数据集上进行了实验。我们提出的方法的总体性能优于最先进的方法。此外，我们还评估了 Match4Match 的计算效率。Match4Match 得益于这三种灵活的推理模式，可以以较低的延迟响应大量查询请求，或者以可接受的时间消耗实现高召回率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Match4Match:+Enhancing+Text-Video+Retrieval+by+Maximum+Flow+with+Minimum+Cost)|0|
|[Zero-shot Clarifying Question Generation for Conversational Search](https://doi.org/10.1145/3543507.3583420)|Zhenduo Wang, Yuancheng Tu, Corby Rosset, Nick Craswell, Ming Wu, Qingyao Ai|Tsinghua University, China; GitHub Inc, USA; University of Utah, USA; Microsoft Corp, USA|A long-standing challenge for search and conversational assistants is query intention detection in ambiguous queries. Asking clarifying questions in conversational search has been widely studied and considered an effective solution to resolve query ambiguity. Existing work have explored various approaches for clarifying question ranking and generation. However, due to the lack of real conversational search data, they have to use artificial datasets for training, which limits their generalizability to real-world search scenarios. As a result, the industry has shown reluctance to implement them in reality, further suspending the availability of real conversational search interaction data. The above dilemma can be formulated as a cold start problem of clarifying question generation and conversational search in general. Furthermore, even if we do have large-scale conversational logs, it is not realistic to gather training data that can comprehensively cover all possible queries and topics in open-domain search scenarios. The risk of fitting bias when training a clarifying question retrieval/generation model on incomprehensive dataset is thus another important challenge.   In this work, we innovatively explore generating clarifying questions in a zero-shot setting to overcome the cold start problem and we propose a constrained clarifying question generation system which uses both question templates and query facets to guide the effective and precise question generation. The experiment results show that our method outperforms existing state-of-the-art zero-shot baselines by a large margin. Human annotations to our model outputs also indicate our method generates 25.2\% more natural questions, 18.1\% more useful questions, 6.1\% less unnatural and 4\% less useless questions.|模糊查询中的查询意图检测一直是搜索和会话助手面临的挑战。在会话搜索中提出澄清问题被广泛研究，被认为是解决查询歧义的有效方法。现有的工作已经探索了各种方法来澄清问题的排序和生成。然而，由于缺乏真实的会话搜索数据，他们不得不使用人工数据集进行训练，这限制了他们对真实世界搜索场景的普遍性。结果，业界表现出不愿意在现实中实现它们，进一步暂停了真正的会话搜索交互数据的可用性。上述困境可以概括为澄清问题生成和一般会话搜索的冷启动问题。此外，即使我们有大规模的会话日志，收集能够全面涵盖开放域搜索场景中所有可能的查询和主题的培训数据也是不现实的。因此，在不全面的数据集上训练澄清问题检索/生成模型时，拟合偏差的风险是另一个重要的挑战。在这项工作中，我们创新性地探索了在零拍环境下生成澄清问题来克服冷启动问题，并提出了一个有约束的澄清问题生成系统，该系统使用问题模板和查询面来指导有效和准确的问题生成。实验结果表明，我们的方法比现有的最先进的零拍摄基线有很大的优势。我们的模型输出的人工注释也表明我们的方法产生了25.2% 更自然的问题，18.1% 更有用的问题，6.1% 更少的非自然的和4% 更少的无用的问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Clarifying+Question+Generation+for+Conversational+Search)|0|
|[Everything Evolves in Personalized PageRank](https://doi.org/10.1145/3543507.3583474)|Zihao Li, Dongqi Fu, Jingrui He|University of Illinois at Urbana-Champaign, USA|Personalized PageRank, as a graphical model, has been proven as an effective solution in many applications such as web page search, recommendation, etc. However, in the real world, the setting of personalized PageRank is usually dynamic like the evolving World Wide Web. On the one hand, the outdated PageRank solution can be sub-optimal for ignoring the evolution pattern. On the other hand, solving the solution from the scratch at each timestamp causes costly computation complexity. Hence, in this paper, we aim to solve the Personalized PageRank effectively and efficiently in a fully dynamic setting, i.e., every component in the Personalized PageRank formula is dependent on time. To this end, we propose the EvePPR method that can track the exact personalized PageRank solution at each timestamp in the fully dynamic setting, and we theoretically and empirically prove the accuracy and time complexity of EvePPR. Moreover, we apply EvePPR to solve the dynamic knowledge graph alignment task, where a fully dynamic setting is necessary but complex. The experiments show that EvePPR outperforms the state-of-the-art baselines for similar nodes retrieval across graphs.|个性化 PageRank 作为一种图形化模型，已被证明是网页搜索、推荐等应用中的一种有效解决方案。然而，在现实世界中，个性化 PageRank 的设置通常是动态的，就像不断发展的万维网一样。一方面，过时的 PageRank 解决方案可能是次优的，因为它忽略了进化模式。另一方面，在每个时间戳从零开始求解解决方案会导致昂贵的计算复杂度。因此，本文的目标是在一个完全动态的环境下有效地解决个性化 PageRank 问题，也就是说，个性化 PageRank 公式中的每个组成部分都依赖于时间。为此，我们提出了 EvePPR 方法，该方法可以在完全动态的环境下精确跟踪每个时间戳的个性化 PageRank 解，并从理论和实验上证明了 EvePPR 方法的准确性和时间复杂度。此外，我们应用 EvePPR 来解决动态知识图对齐任务，其中一个完全动态的设置是必要的，但是复杂的。实验表明，EvePPR 在跨图检索相似节点时优于最新的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Everything+Evolves+in+Personalized+PageRank)|0|
|[Incorporating Explicit Subtopics in Personalized Search](https://doi.org/10.1145/3543507.3583488)|Shuting Wang, Zhicheng Dou, Jing Yao, Yujia Zhou, JiRong Wen|Renmin University of China, China and Engineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Educationf Education, China; Renmin University of China, China; Social Computing Group, Microsoft Research Asia, China|The key to personalized search is modeling user intents to tailor returned results for different users. Existing personalized methods mainly focus on learning implicit user interest vectors. In this paper, we propose ExpliPS, a personalized search model that explicitly incorporates query subtopics into personalization. It models the user’s current intent by estimating the user’s preference over the subtopics of the current query and personalizes the results over the weighted subtopics. We think that in such a way, personalized search could be more explainable and stable. Specifically, we first employ a semantic encoder to learn the representations of the user’s historical behaviours. Then with the historical behaviour representations, a subtopic preference encoder is devised to predict the user’s subtopic preferences on the current query. Finally, we rerank the candidates via a subtopic-aware ranker that prioritizes the documents relevant to the user-preferred subtopics. Experimental results show our model ExpliPS outperforms the state-of-the-art personalized web search models with explainable and stable results.|个性化检索的关键是建立用户意图模型，为不同的用户定制返回的结果。现有的个性化方法主要侧重于学习隐式用户兴趣向量。在这篇文章中，我们提出了 expliPS，一个明确地将查询子主题合并到个性化中的个性化检索模型。它通过估计用户对当前查询的子主题的偏好来建模用户的当前意图，并对加权子主题的结果进行个性化处理。我们认为，通过这种方式，个性化检索可以更容易解释，也更稳定。具体来说，我们首先使用一个语义编码器来学习用户历史行为的表示。然后结合历史行为表示，设计了一种子主题偏好编码器来预测用户对当前查询的子主题偏好。最后，我们通过一个子主题感知排名器对候选人进行重新排名，该排名器对与用户首选子主题相关的文档进行优先排序。实验结果表明，该模型的性能优于目前最先进的个性化网络搜索模型，结果具有可解释性和稳定性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Explicit+Subtopics+in+Personalized+Search)|0|
|[Optimizing Feature Set for Click-Through Rate Prediction](https://doi.org/10.1145/3543507.3583545)|Fuyuan Lyu, Xing Tang, Dugang Liu, Liang Chen, Xiuqiang He, Xue Liu|Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), China; McGill University, Canada; FiT, Tencent, China|Click-through prediction (CTR) models transform features into latent vectors and enumerate possible feature interactions to improve performance based on the input feature set. Therefore, when selecting an optimal feature set, we should consider the influence of both feature and its interaction. However, most previous works focus on either feature field selection or only select feature interaction based on the fixed feature set to produce the feature set. The former restricts search space to the feature field, which is too coarse to determine subtle features. They also do not filter useless feature interactions, leading to higher computation costs and degraded model performance. The latter identifies useful feature interaction from all available features, resulting in many redundant features in the feature set. In this paper, we propose a novel method named OptFS to address these problems. To unify the selection of feature and its interaction, we decompose the selection of each feature interaction into the selection of two correlated features. Such a decomposition makes the model end-to-end trainable given various feature interaction operations. By adopting feature-level search space, we set a learnable gate to determine whether each feature should be within the feature set. Because of the large-scale search space, we develop a learning-by-continuation training scheme to learn such gates. Hence, OptFS generates the feature set only containing features which improve the final prediction results. Experimentally, we evaluate OptFS on three public datasets, demonstrating OptFS can optimize feature sets which enhance the model performance and further reduce both the storage and computational cost.|点击预测(CTR)模型将特征转换为潜在向量，并列举可能的特征交互，以提高基于输入特征集的性能。因此，在选择最优特征集时，应同时考虑特征及其相互作用的影响。然而，以往的工作主要集中在特征字段的选择或者仅仅基于固定特征集选择特征交互来产生特征集。前者将搜索空间限制在特征域内，特征域太粗，无法确定细微的特征。它们也不过滤无用的特征交互，导致更高的计算成本和降低模型性能。后者从所有可用的特征中识别出有用的特征交互，从而导致特征集中的许多冗余特征。在本文中，我们提出了一种新的方法称为 OptFS 来解决这些问题。为了统一特征选择和特征交互，将每个特征交互的选择分解为两个相关特征的选择。这样的分解使得模型在给定各种特征交互操作的情况下可以进行端到端的训练。通过采用特征级搜索空间，我们设置了一个可学习的门来确定每个特征是否应该在特征集中。由于搜索空间较大，我们提出了一种基于连续学习的训练方案来学习这类门。因此，OptFS 生成的特征集仅包含改善最终预测结果的特征。在实验上，我们对三个公共数据集上的 OptFS 进行了评估，结果表明 OptFS 可以优化特征集，从而提高模型的性能，进一步降低存储和计算成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Feature+Set+for+Click-Through+Rate+Prediction)|0|
|[Filtered-DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters](https://doi.org/10.1145/3543507.3583552)|Siddharth Gollapudi, Neel Karia, Varun Sivashankar, Ravishankar Krishnaswamy, Nikit Begwani, Swapnil Raz, Yiyong Lin, Yin Zhang, Neelam Mahapatro, Premkumar Srinivasan, Amit Singh, Harsha Vardhan Simhadri|Columbia University, USA; Microsoft Research, India; Microsoft, USA; Microsoft, India; Microsoft Research, USA|As Approximate Nearest Neighbor Search (ANNS)-based dense retrieval becomes ubiquitous for search and recommendation scenarios, efficiently answering filtered ANNS queries has become a critical requirement. Filtered ANNS queries ask for the nearest neighbors of a query’s embedding from the points in the index that match the query’s labels such as date, price range, language. There has been little prior work on algorithms that use label metadata associated with vector data to build efficient indices for filtered ANNS queries. Consequently, current indices have high search latency or low recall which is not practical in interactive web-scenarios. We present two algorithms with native support for faster and more accurate filtered ANNS queries: one with streaming support, and another based on batch construction. Central to our algorithms is the construction of a graph-structured index which forms connections not only based on the geometry of the vector data, but also the associated label set. On real-world data with natural labels, both algorithms are an order of magnitude or more efficient for filtered queries than the current state of the art algorithms. The generated indices also be queried from an SSD and support thousands of queries per second at over [email protected]|随着基于近似最近邻搜索(ANNS)的密集检索在搜索和推荐场景中的普及，有效地回答经过滤的 ANNS 查询已成为一个关键要求。经过过滤的 ANNS 查询要求查询嵌入的最近邻居从索引中匹配查询标签的点，如日期，价格范围，语言。使用与矢量数据相关联的标签元数据为经过过滤的 ANNS 查询构建高效索引的算法之前几乎没有研究。因此，当前的索引具有较高的搜索延迟或较低的召回率，这在交互式网络场景中是不实用的。我们提出了两个算法与本地支持更快，更准确的过滤 ANNS 查询: 一个流支持，另一个基于批量构造。我们算法的核心是构造一个图结构索引，它不仅根据矢量数据的几何形状，而且根据相关的标签集形成连接。对于带有自然标签的真实世界数据，这两种算法对于过滤查询来说都是一种数量级，或者比目前最先进的算法效率更高。生成的索引也可以从 SSD 查询，并支持每秒在 over [ email protected ]处的数千个查询|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Filtered-DiskANN:+Graph+Algorithms+for+Approximate+Nearest+Neighbor+Search+with+Filters)|0|
|[P-MMF: Provider Max-min Fairness Re-ranking in Recommender System](https://doi.org/10.1145/3543507.3583296)|Chen Xu, Sirui Chen, Jun Xu, Weiran Shen, Xiao Zhang, Gang Wang, Zhenhua Dong||In this paper, we address the issue of recommending fairly from the aspect of providers, which has become increasingly essential in multistakeholder recommender systems. Existing studies on provider fairness usually focused on designing proportion fairness (PF) metrics that first consider systematic fairness. However, sociological researches show that to make the market more stable, max-min fairness (MMF) is a better metric. The main reason is that MMF aims to improve the utility of the worst ones preferentially, guiding the system to support the providers in weak market positions. When applying MMF to recommender systems, how to balance user preferences and provider fairness in an online recommendation scenario is still a challenging problem. In this paper, we proposed an online re-ranking model named Provider Max-min Fairness Re-ranking (P-MMF) to tackle the problem. Specifically, P-MMF formulates provider fair recommendation as a resource allocation problem, where the exposure slots are considered the resources to be allocated to providers and the max-min fairness is used as the regularizer during the process. We show that the problem can be further represented as a regularized online optimizing problem and solved efficiently in its dual space. During the online re-ranking phase, a momentum gradient descent method is designed to conduct the dynamic re-ranking. Theoretical analysis showed that the regret of P-MMF can be bounded. Experimental results on four public recommender datasets demonstrated that P-MMF can outperformed the state-of-the-art baselines. Experimental results also show that P-MMF can retain small computationally costs on a corpus with the large number of items.|在本文中，我们从提供者的角度讨论了公平推荐的问题，这在多利益相关者推荐系统中已经变得越来越重要。现有的关于提供者公平性的研究通常集中在设计比例公平性(PF)指标时首先考虑系统公平性。然而，社会学研究表明，为了使市场更加稳定，极大极小公平(MMF)是一个更好的衡量标准。主要原因在于，货币市场基金旨在优先提高最差的基金的效用，引导金融体系支持处于弱势市场地位的基金提供者。在将 MMF 应用于推荐系统时，如何在在线推荐场景中平衡用户偏好和提供者公平性仍然是一个具有挑战性的问题。在这篇文章中，我们提出了一个在线重新排序模型——提供者极大极小公平重新排序(P-MMF)来解决这个问题。具体来说，P-MMF 将提供商公平推荐制定为一个资源分配问题，其中风险承担时段被视为将分配给提供商的资源，而极大极小公平则被用作过程中的规范者。证明了该问题可以进一步表示为正则化在线优化问题，并在其对偶空间中有效地求解。在在线重新排名阶段，动量梯度下降法方法被设计用于进行动态重新排名。理论分析表明，P-MMF 的遗憾是有限的。对四个公共推荐数据集的实验结果表明，P-MMF 能够优于最先进的基线。实验结果还表明，P-MMF 能够在项目数量较多的语料库上保持较小的计算开销。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=P-MMF:+Provider+Max-min+Fairness+Re-ranking+in+Recommender+System)|0|
|[Dual Intent Enhanced Graph Neural Network for Session-based New Item Recommendation](https://doi.org/10.1145/3543507.3583526)|Di Jin, Luzhi Wang, Yizhen Zheng, Guojie Song, Fei Jiang, Xiang Li, Wei Lin, Shirui Pan|School of Information and Communication Technology, Griffith University, Australia; College of Intelligence and Computing, Tianjin University, China; Department of Data Science and AI, Faculty of IT, Monash University, Australia; Meituan, China; Professional, China; School of Intelligence Science and Technology, Peking University, China|Recommender systems are essential to various fields, e.g., e-commerce, e-learning, and streaming media. At present, graph neural networks (GNNs) for session-based recommendations normally can only recommend items existing in users' historical sessions. As a result, these GNNs have difficulty recommending items that users have never interacted with (new items), which leads to a phenomenon of information cocoon. Therefore, it is necessary to recommend new items to users. As there is no interaction between new items and users, we cannot include new items when building session graphs for GNN session-based recommender systems. Thus, it is challenging to recommend new items for users when using GNN-based methods. We regard this challenge as '\textbf{G}NN \textbf{S}ession-based \textbf{N}ew \textbf{I}tem \textbf{R}ecommendation (GSNIR)'. To solve this problem, we propose a dual-intent enhanced graph neural network for it. Due to the fact that new items are not tied to historical sessions, the users' intent is difficult to predict. We design a dual-intent network to learn user intent from an attention mechanism and the distribution of historical data respectively, which can simulate users' decision-making process in interacting with a new item. To solve the challenge that new items cannot be learned by GNNs, inspired by zero-shot learning (ZSL), we infer the new item representation in GNN space by using their attributes. By outputting new item probabilities, which contain recommendation scores of the corresponding items, the new items with higher scores are recommended to users. Experiments on two representative real-world datasets show the superiority of our proposed method. The case study from the real-world verifies interpretability benefits brought by the dual-intent module and the new item reasoning module. The code is available at Github: https://github.com/Ee1s/NirGNN|推荐系统对于电子商务、电子学习和流媒体等各个领域都是必不可少的。目前，基于会话推荐的图神经网络(GNN)通常只能推荐用户历史会话中存在的项目。因此，这些 GNN 很难推荐用户从未接触过的项目(新项目) ，从而导致信息茧现象。因此，有必要向用户推荐新项目。由于新项目和用户之间没有交互，所以在为基于 GNN 会话的推荐系统构建会话图时，我们不能包含新项目。因此，在使用基于 GNN 的方法时，向用户推荐新项目是一个挑战。我们将此挑战视为“ textbf { G } NN textbf { S } session-based textbf { N } ew textbf { I } tem textbf { R }推荐(GSNIR)”。为了解决这一问题，我们提出了一种双意图增强的图神经网络。由于新条目不与历史会话相关联，因此很难预测用户的意图。设计了一个双意图网络，分别从注意机制和历史数据分布中学习用户意图，模拟用户在与新项目交互时的决策过程。为了解决 GNN 无法学习新项目的问题，受零点学习(ZSL)的启发，我们利用 GNN 空间中新项目的属性来推断新项目的表示。通过输出新项目概率，其中包含相应项目的推荐分数，新项目的分数越高，推荐给用户。在两个具有代表性的实际数据集上的实验表明了该方法的优越性。通过实际案例分析，验证了双意图模块和新的项目推理模块所带来的可解释性优势。代码可以在 Github:  https://Github.com/ee1s/nirgnn 上找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Intent+Enhanced+Graph+Neural+Network+for+Session-based+New+Item+Recommendation)|0|
|[Cross-domain recommendation via user interest alignment](https://doi.org/10.1145/3543507.3583263)|Chuang Zhao, Hongke Zhao, Ming HE, Jian Zhang, Jianping Fan|School of Cyberspace Security, Hangzhou Dianzi University, China; College of Management and Economics, Tianjin University, China and AI Lab at Lenovo Research, China; College of Management and Economics, Tianjin University, China; AI Lab at Lenovo Research, China|Cross-domain recommendation aims to leverage knowledge from multiple domains to alleviate the data sparsity and cold-start problems in traditional recommender systems. One popular paradigm is to employ overlapping user representations to establish domain connections, thereby improving recommendation performance in all scenarios. Nevertheless, the general practice of this approach is to train user embeddings in each domain separately and then aggregate them in a plain manner, often ignoring potential cross-domain similarities between users and items. Furthermore, considering that their training objective is recommendation task-oriented without specific regularizations, the optimized embeddings disregard the interest alignment among user's views, and even violate the user's original interest distribution. To address these challenges, we propose a novel cross-domain recommendation framework, namely COAST, to improve recommendation performance on dual domains by perceiving the cross-domain similarity between entities and aligning user interests. Specifically, we first construct a unified cross-domain heterogeneous graph and redefine the message passing mechanism of graph convolutional networks to capture high-order similarity of users and items across domains. Targeted at user interest alignment, we develop deep insights from two more fine-grained perspectives of user-user and user-item interest invariance across domains by virtue of affluent unsupervised and semantic signals. We conduct intensive experiments on multiple tasks, constructed from two large recommendation data sets. Extensive results show COAST consistently and significantly outperforms state-of-the-art cross-domain recommendation algorithms as well as classic single-domain recommendation methods.|跨域推荐的目的是利用来自多个域的知识来缓解传统推荐系统中的数据稀疏和冷启动问题。一个流行的范例是使用重叠的用户表示来建立域连接，从而在所有场景中提高推荐性能。然而，这种方法的一般实践是分别训练每个域中的用户嵌入，然后以简单的方式聚合它们，通常忽略用户和项目之间潜在的跨域相似性。此外，考虑到其训练目标是面向推荐任务的，没有具体的规范化，优化嵌入无视用户视图之间的兴趣一致性，甚至违背了用户原有的兴趣分布。为了应对这些挑战，我们提出了一种新的跨域推荐框架，即 COAST，通过感知实体之间的跨域相似性和调整用户兴趣来提高双域推荐的性能。具体来说，我们首先构建一个统一的跨域异构图，重新定义图卷积网络的消息传递机制，以获取跨域用户和项目的高阶相似性。针对用户兴趣对齐，我们从用户-用户和用户项目兴趣不变性的两个更细粒度的角度，通过丰富的无监督和语义信号，开发深刻的见解。我们对两个大型推荐数据集构建的多个任务进行了深入的实验。广泛的结果表明，COAST 始终如一地显著优于最先进的跨域推荐算法和经典的单域推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-domain+recommendation+via+user+interest+alignment)|0|
|[A Semantic Partitioning Method for Large-Scale Training of Knowledge Graph Embeddings](https://doi.org/10.1145/3543873.3587537)|Yuhe Bai|Sorbonne University, France|In recent years, knowledge graph embeddings have achieved great success. Many methods have been proposed and achieved state-of-the-art results in various tasks. However, most of the current methods present one or more of the following problems: (i) They only consider fact triplets, while ignoring the ontology information of knowledge graphs. (ii) The obtained embeddings do not contain much semantic information. Therefore, using these embeddings for semantic tasks is problematic. (iii) They do not enable large-scale training. In this paper, we propose a new algorithm that incorporates the ontology of knowledge graphs and partitions the knowledge graph based on classes to include more semantic information for parallel training of large-scale knowledge graph embeddings. Our preliminary results show that our algorithm performs well on several popular benchmarks.|近年来，知识图嵌入技术取得了很大的成功。已经提出了许多方法，并在各种任务中取得了最新的成果。然而，目前的大多数方法都存在以下一个或多个问题: (i)它们只考虑事实三元组，而忽略了知识图的本体信息。(ii)所得的嵌入资料并无太多语义信息。因此，将这些嵌入用于语义任务是有问题的。(iii)不能进行大规模培训。在本文中，我们提出了一个新的算法，它结合了知识图的本体和基于类的知识图划分，以包括更多的语义信息并行训练大规模的知识图嵌入。我们的初步结果表明，我们的算法在几个流行的基准测试中表现良好。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Semantic+Partitioning+Method+for+Large-Scale+Training+of+Knowledge+Graph+Embeddings)|0|
|[Intent-Aware Propensity Estimation via Click Pattern Stratification](https://doi.org/10.1145/3543873.3587610)|Ehsan Ebrahimzadeh, Alex Cozzi, Abraham Bagherjeiran|Search Ranking and Monetization, eBay, USA|Counterfactual learning to rank via inverse propensity weighting is the most popular approach to train ranking models using biased implicit user feedback from logged search data. Standard click propensity estimation techniques rely on simple models of user browsing behavior that primarily account for the attributes of the presentation context that affect whether the relevance of an item to the search context is observed. Most notably, the inherent effect of the listwise presentation of the items on users’ propensity for engagement is captured in the position of the presented items on the search result page. In this work, we enrich this position bias based click propensity model by proposing an observation model that further incorporates the underlying search intent, as reflected in the user’s click pattern in the search context. Our approach does not require an intent prediction model based on the content of the search context. Instead, we rely on a simple, yet effective, non-causal estimate of the user’s browsing intent from the number of click events in the search context. We empirically characterize the distinct rank decay patterns of the estimated click propensities in the characterized intent classes. In particular, we demonstrate a sharper decay of click propensities in top ranks for the intent class identified by sparse user clicks and the higher likelihood of observing clicks in lower ranks for the intent class identified by higher number of user clicks. We show that the proposed intent-aware propensity estimation technique helps with training ranking models with more effective personalization and generalization power through empirical results for a ranking task in a major e-commerce platform.|通过逆倾向加权反事实学习排序是最流行的方法来训练排序模型使用有偏见的隐式用户反馈的日志搜索数据。标准的点击倾向评估技术依赖于用户浏览行为的简单模型，这些模型主要解释了表示上下文的属性，这些属性影响了项目与搜索上下文的相关性是否被观察到。最值得注意的是，在搜索结果页面上呈现的项目的位置捕捉到了项目列表方式对用户参与倾向的内在影响。在这项工作中，我们丰富了这个基于位置偏差的点击倾向模型，通过提出一个观察模型，进一步结合潜在的搜索意图，如反映在用户的点击模式在搜索上下文。我们的方法不需要基于搜索上下文内容的意图预测模型。相反，我们依赖于从搜索上下文中的点击事件数量对用户的浏览意图进行简单而有效的非因果估计。我们经验性地描述了特征意图类中估计的点击倾向的不同秩衰减模式。特别是，我们证明了通过稀疏的用户点击识别的意图类别的顶级点击倾向的更强烈的衰减，以及通过更高数量的用户点击识别的意图类别在较低级别中观察到点击的可能性更高。通过对一个大型电子商务平台的排序任务进行实证分析，我们发现提出的意图感知倾向估计技术有助于训练排序模型，使其具有更有效的个性化和泛化能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intent-Aware+Propensity+Estimation+via+Click+Pattern+Stratification)|0|
|[Disentangling Degree-related Biases and Interest for Out-of-Distribution Generalized Directed Network Embedding](https://doi.org/10.1145/3543507.3583271)|Hyunsik Yoo, YeonChang Lee, Kijung Shin, SangWook Kim|Korea Advanced Institute of Science and Technology, Republic of Korea; Georgia Institute of Technology, USA; Hanyang University, Republic of Korea|The goal of directed network embedding is to represent the nodes in a given directed network as embeddings that preserve the asymmetric relationships between nodes. While a number of directed network embedding methods have been proposed, we empirically show that the existing methods lack out-of-distribution generalization abilities against degree-related distributional shifts. To mitigate this problem, we propose ODIN (Out-of-Distribution Generalized Directed Network Embedding), a new directed NE method where we model multiple factors in the formation of directed edges. Then, for each node, ODIN learns multiple embeddings, each of which preserves its corresponding factor, by disentangling interest factors and biases related to in- and out-degrees of nodes. Our experiments on four real-world directed networks demonstrate that disentangling multiple factors enables ODIN to yield out-of-distribution generalized embeddings that are consistently effective under various degrees of shifts in degree distributions. Specifically, ODIN universally outperforms 9 state-of-the-art competitors in 2 LP tasks on 4 real-world datasets under both identical distribution (ID) and non-ID settings. The code is available at https://github.com/hsyoo32/odin.|有向网络嵌入的目的是将给定有向网络中的节点表示为保持节点间不对称关系的嵌入。虽然已经提出了一些有向网络嵌入方法，但是实验表明，现有的方法缺乏对度相关分布偏移的分布外泛化能力。为了解决这一问题，我们提出了一种新的有向网络嵌入方法 ODIN (Out-of-Distribution Generalization Directed Network Embedding) ，该方法对有向边的形成过程中的多个因素进行建模。然后，对于每个节点，ODIN 通过分离与节点内外度相关的兴趣因子和偏差来学习多个嵌入，每个嵌入保留相应的因子。我们在四个真实世界的定向网络上的实验表明，解开多个因素使 ODIN 能够产生分布外的广义嵌入，在度分布的不同程度的转移下一致有效。具体而言，ODIN 在4个真实世界数据集的2个 LP 任务中，在相同的分布(ID)和非 ID 设置下，普遍优于9个最先进的竞争对手。密码可在 https://github.com/hsyoo32/odin 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangling+Degree-related+Biases+and+Interest+for+Out-of-Distribution+Generalized+Directed+Network+Embedding)|0|
|[Fine-tuning Partition-aware Item Similarities for Efficient and Scalable Recommendation](https://doi.org/10.1145/3543507.3583240)|Tianjun Wei, Jianghong Ma, Tommy W. S. Chow|Harbin Institute of Technology, China; City University of Hong Kong, Hong Kong|Collaborative filtering (CF) is widely searched in recommendation with various types of solutions. Recent success of Graph Convolution Networks (GCN) in CF demonstrates the effectiveness of modeling high-order relationships through graphs, while repetitive graph convolution and iterative batch optimization limit their efficiency. Instead, item similarity models attempt to construct direct relationships through efficient interaction encoding. Despite their great performance, the growing item numbers result in quadratic growth in similarity modeling process, posing critical scalability problems. In this paper, we investigate the graph sampling strategy adopted in latest GCN model for efficiency improving, and identify the potential item group structure in the sampled graph. Based on this, we propose a novel item similarity model which introduces graph partitioning to restrict the item similarity modeling within each partition. Specifically, we show that the spectral information of the original graph is well in preserving global-level information. Then, it is added to fine-tune local item similarities with a new data augmentation strategy acted as partition-aware prior knowledge, jointly to cope with the information loss brought by partitioning. Experiments carried out on 4 datasets show that the proposed model outperforms state-of-the-art GCN models with 10x speed-up and item similarity models with 95\% parameter storage savings.|协同过滤(CF)在推荐中被广泛搜索，提供了各种类型的解决方案。最近，图卷积网络(GCN)在 CF 中的成功证明了通过图建立高阶关系的有效性，而重复图卷积和迭代批处理优化限制了它们的效率。相反，项目相似性模型试图通过有效的交互编码来构建直接关系。尽管它们具有很好的性能，但是在相似性建模过程中，项目数量的增长会导致二次增长，从而产生关键的可扩展性问题。本文研究了最新 GCN 模型中为提高效率而采用的图抽样策略，并识别了抽样图中潜在的项目组结构。在此基础上，提出了一种新的项目相似度模型，该模型引入图划分来约束项目相似度建模。具体地说，我们证明了原始图的光谱信息在保持全局水平信息方面是很好的。然后加入一种新的数据增强策略作为分区感知的先验知识，对局部项相似性进行微调，共同应对分区带来的信息丢失。在4个数据集上进行的实验表明，该模型比最新的 GCN 模型具有10倍的加速度和项目相似度，节省了95% 的参数存储空间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fine-tuning+Partition-aware+Item+Similarities+for+Efficient+and+Scalable+Recommendation)|0|
|[Multi-Behavior Recommendation with Cascading Graph Convolution Networks](https://doi.org/10.1145/3543507.3583439)|Zhiyong Cheng, Sai Han, Fan Liu, Lei Zhu, Zan Gao, Yuxin Peng|School of Computing, National University of Singapore, Singapore; Wangxuan Institute of Computer Technology, Peking University, China and Peng Cheng Laboratory, China; Shandong Artificial Intelligence Institute, Qilu University of Technology (Shandong Academy of Sciences), China; School of Information Science and Engineering, Shandong Normal University, China|Multi-behavior recommendation, which exploits auxiliary behaviors (e.g., click and cart) to help predict users' potential interactions on the target behavior (e.g., buy), is regarded as an effective way to alleviate the data sparsity or cold-start issues in recommendation. Multi-behaviors are often taken in certain orders in real-world applications (e.g., click>cart>buy). In a behavior chain, a latter behavior usually exhibits a stronger signal of user preference than the former one does. Most existing multi-behavior models fail to capture such dependencies in a behavior chain for embedding learning. In this work, we propose a novel multi-behavior recommendation model with cascading graph convolution networks (named MB-CGCN). In MB-CGCN, the embeddings learned from one behavior are used as the input features for the next behavior's embedding learning after a feature transformation operation. In this way, our model explicitly utilizes the behavior dependencies in embedding learning. Experiments on two benchmark datasets demonstrate the effectiveness of our model on exploiting multi-behavior data. It outperforms the best baseline by 33.7% and 35.9% on average over the two datasets in terms of Recall@10 and NDCG@10, respectively.|多行为推荐利用辅助行为(如点击和购物车)来帮助预测用户在目标行为(如购买)上的潜在交互，被认为是缓解推荐中数据稀疏或冷启动问题的有效方法。在实际应用程序中，多行为通常按照特定的顺序执行(例如，单击 > 购物车 > 购买)。在行为链中，后一种行为通常比前一种行为表现出更强的用户偏好信号。大多数现有的多行为模型无法在嵌入式学习的行为链中捕获这种依赖关系。提出了一种新的具有级联图卷积网络的多行为推荐模型(MB-CGCN)。在 MB-CGCN 中，从一个行为中学习的嵌入作为特征转换操作后下一个行为的嵌入学习的输入特征。通过这种方式，我们的模型明确地利用了嵌入式学习中的行为依赖。在两个基准数据集上的实验证明了该模型对多行为数据的有效性。以 Recall@10和 NDCG@10计算，该方法比最佳基线的平均值分别高出33.7% 和35.9% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavior+Recommendation+with+Cascading+Graph+Convolution+Networks)|0|
|[Cross-domain Recommendation with Behavioral Importance Perception](https://doi.org/10.1145/3543507.3583494)|Hong Chen, Xin Wang, Ruobing Xie, Yuwei Zhou, Wenwu Zhu|WeChat Search Application Department, Tencent, China; Department of Computer Science and Technology, Tsinghua University, China|Cross-domain recommendation (CDR) aims to leverage the source domain information to provide better recommendation for the target domain, which is widely adopted in recommender systems to alleviate the data sparsity and cold-start problems. However, existing CDR methods mostly focus on designing effective model architectures to transfer the source domain knowledge, ignoring the behavior-level effect during the loss optimization process, where behaviors regarding different aspects in the source domain may have different importance for the CDR model optimization. The ignorance of the behavior-level effect will cause the carefully designed model architectures ending up with sub-optimal parameters, which limits the recommendation performance. To tackle the problem, we propose a generic behavioral importance-aware optimization framework for cross-domain recommendation (BIAO). Specifically, we propose a behavioral perceptron which predicts the importance of each source behavior according to the corresponding item’s global impact and local user-specific impact. The joint optimization process of the CDR model and the behavioral perceptron is formulated as a bi-level optimization problem. In the lower optimization, only the CDR model is updated with weighted source behavior loss and the target domain loss, while in the upper optimization, the behavioral perceptron is updated with implicit gradient from a developing dataset obtained through the proposed reorder-and-reuse strategy. Extensive experiments show that our proposed optimization framework consistently improves the performance of different cross-domain recommendation models in 7 cross-domain scenarios, demonstrating that our method can serve as a generic and powerful tool for cross-domain recommendation1.|跨域推荐(CDR)是利用源域信息为目标域提供更好的推荐，在推荐系统中被广泛采用以缓解数据稀疏和冷启动问题。然而，现有的 CDR 方法大多侧重于设计有效的模型结构来传递源域知识，忽略了损失优化过程中的行为级效应，其中源域中不同方面的行为对 CDR 模型优化的重要性不同。对行为级效应的忽视将导致精心设计的模型结构最终得到次优参数，从而限制了推荐性能。为了解决这个问题，我们提出了一个通用的跨域推荐的行为重要性感知优化框架(BIAO)。具体来说，我们提出了一种行为感知器，它根据相应项目的全局影响和局部用户特定影响来预测每个源行为的重要性。CDR 模型和行为感知器的联合优化过程是一个双层次的最佳化问题。在下层优化中，只对 CDR 模型进行加权源行为丢失和目标域丢失的更新，而在上层优化中，行为感知器通过提出的重排序和重用策略从一个正在发展的数据集中获得隐式梯度更新。大量的实验表明，我们提出的优化框架在7个跨领域场景中始终如一地提高了不同跨领域推荐模型的性能，表明我们的方法可以作为跨领域推荐的一个通用和强大的工具1。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-domain+Recommendation+with+Behavioral+Importance+Perception)|0|
|[Multi-Lingual Multi-Partite Product Title Matching](https://doi.org/10.1145/3543873.3587322)|HuanLin Tay, WeiJie Tay, Hady W. Lauw|Singapore Management University, Singapore|In a globalized marketplace, one could access products or services from almost anywhere. However, resolving which product in one language corresponds to another product in a different language remains an under-explored problem. We explore this from two perspectives. First, given two products of different languages, how to assess their similarity that could signal a potential match. Second, given products from various languages, how to arrive at a multi-partite clustering that respects cardinality constraints efficiently. We describe algorithms for each perspective and integrate them into a promising solution validated on real-world datasets.|在一个全球化的市场中，人们几乎可以从任何地方获得产品或服务。然而，解决一种语言中的哪种产品对应于另一种语言中的另一种产品仍然是一个尚未得到充分探讨的问题。我们从两个角度来探讨这个问题。首先，给定两种不同语言的产品，如何评估它们的相似性，这可能标志着潜在的匹配。其次，给定来自不同语言的产品，如何有效地得到一个尊重基数约束的多部分聚类。我们描述每个视角的算法，并将它们集成到一个在真实世界数据集上验证的有希望的解决方案中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Lingual+Multi-Partite+Product+Title+Matching)|0|
|[Multi-interest Recommendation on Shopping for Others](https://doi.org/10.1145/3543873.3587341)|Shuang Li, Yaokun Liu, Xiaowang Zhang, Yuexian Hou, Zhiyong Feng|Tianjin University, China, China; Tianjin University, China|Existing recommendation methods based on multi-interest frameworks effectively model users from multiple aspects to represent complex user interests. However, more research still needs to be done on the behavior of users shopping for others. We propose a Multi-Demander Recommendation (MDR) model to learn different people’s interests from a sequence of actions. We first decouple the feature embeddings of items to learn the static preferences of different demanders. Next, a weighted directed global graph is constructed to model the associations among item categories. We partition short sequences by time intervals and look up category embeddings from the graph to capture dynamic intents. Finally, preferences and intentions are combined with learning the interests of different demanders. The conducted experiments demonstrate that our model improves the accuracy of recommendations.|现有的基于多兴趣框架的推荐方法能够有效地从多个方面对用户进行建模，以表达复杂的用户兴趣。然而，还需要对用户为他人购物的行为进行更多的研究。我们提出了一个多需求推荐(MDR)模型，从一系列的行动中了解不同人的兴趣。首先解耦项目的特征嵌入，学习不同需求者的静态偏好。然后，构造一个加权有向全局图来模拟项目类别之间的关联。我们根据时间间隔对短序列进行划分，并从图中查找类别嵌入以捕获动态意图。最后，将偏好和意图与学习不同需求者的兴趣结合起来。实验表明，该模型提高了推荐的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-interest+Recommendation+on+Shopping+for+Others)|0|
|[Explicit and Implicit Semantic Ranking Framework](https://doi.org/10.1145/3543873.3584621)|Xiaofeng Zhu, Thomas Lin, Vishal Anand, Matthew Calderwood, Eric ClausenBrown, Gord Lueck, Wenwai Yim, Cheng Wu|Microsoft Corporation, USA; Nuance Communications, USA|The core challenge in numerous real-world applications is to match an inquiry to the best document from a mutable and finite set of candidates. Existing industry solutions, especially latency-constrained services, often rely on similarity algorithms that sacrifice quality for speed. In this paper we introduce a generic semantic learning-to-rank framework, Self-training Semantic Cross-attention Ranking (sRank). This transformer-based framework uses linear pairwise loss with mutable training batch sizes and achieves quality gains and high efficiency, and has been applied effectively to show gains on two industry tasks at Microsoft over real-world large-scale data sets: Smart Reply (SR) and Ambient Clinical Intelligence (ACI). In Smart Reply, $sRank$ assists live customers with technical support by selecting the best reply from predefined solutions based on consumer and support agent messages. It achieves 11.7% gain in offline top-one accuracy on the SR task over the previous system, and has enabled 38.7% time reduction in composing messages in telemetry recorded since its general release in January 2021. In the ACI task, sRank selects relevant historical physician templates that serve as guidance for a text summarization model to generate higher quality medical notes. It achieves 35.5% top-one accuracy gain, along with 46% relative ROUGE-L gain in generated medical notes.|在许多实际应用程序中的核心挑战是将查询与来自一组可变且有限的候选文档的最佳文档匹配。现有的行业解决方案，尤其是延迟受限的服务，通常依赖于牺牲质量以提高速度的相似性算法。本文介绍了一个通用的语义学习排序框架——自训练语义交叉注意排序(sRank)。这种基于变压器的框架使用线性成对损失和可变的训练批量大小，实现了质量增益和高效率，并已有效地应用于显示在两个行业任务中的收益在微软超过现实世界的大规模数据集: 智能应答(SR)和环境临床智能(ACI)。在智能答复中，$sRank $通过从基于消费者和支持代理消息的预定义解决方案中选择最佳答复，为现场客户提供技术支持。与之前的系统相比，它在离线状态下获得了11.7% 的最高准确率，并且自2021年1月发布以来，在遥测信息的合成方面减少了38.7% 的时间。在 ACI 任务中，sRank 选择相关的历史医生模板作为文本摘要模型的指导，以生成更高质量的医疗笔记。它实现了35.5% 的最高一级准确性增益，以及46% 的相对 ROUGE-L 增益在生成的医疗记录。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explicit+and+Implicit+Semantic+Ranking+Framework)|0|
|[MPKGAC: Multimodal Product Attribute Completion in E-commerce](https://doi.org/10.1145/3543873.3584623)|Kai Wang, Jianzhi Shao, Tao Zhang, Qijin Chen, Chengfu Huo|Alibaba Group, China|Product attributes can display the selling points of products, helping users find their desired products in search results. However, product attributes are typically incomplete. In e-commerce, products have multimodal features, including original attributes, images, and texts. How to make full use of the multimodal data to complete the missing attributes is the key challenge. To this end, we propose MPKGAC, a powerful three-stream framework that handles multimodal product data for attribute completion. We build a multimodal product knowledge graph (KG) from the multimodal features, and then convert the attribute completion problem into a multimodal KG completion task. MPKGAC encodes each modality separately, fuses them adaptively, and integrates multimodal decoders for prediction. Experiments show that MPKGAC outperforms the best baseline by 6.2% in [email protected] MPKGAC is employed to enrich selling points of the women’s clothing industry at Alibaba.com.cn and improves the click-through rate (CTR) by a relative 2.14%.|产品属性可以显示产品的销售点，帮助用户在搜索结果中找到他们想要的产品。但是，产品属性通常是不完整的。在电子商务中，产品具有多模态特征，包括原始属性、图像和文本。如何充分利用多模态数据来完成缺失的属性是一个关键的挑战。为此，我们提出了 MPKGAC，一个强大的三流框架，处理多通道产品数据的属性完成。首先根据多模态特征构造多模态产品知识图，然后将属性完成问题转化为多模态产品完成任务。MPKGAC 对每种模式分别进行编码，自适应地进行融合，并集成多模式解码器进行预测。实验表明，在阿里巴巴网站上，MPKGAC 的表现优于最佳基线6.2% ，提高了女装行业的销售点，提高了相对2.14% 的点进率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MPKGAC:+Multimodal+Product+Attribute+Completion+in+E-commerce)|0|
|[Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching](https://doi.org/10.1145/3543873.3584626)|Xinping Zhao, Ying Zhang, Qiang Xiao, Yuming Ren, Yingchun Yang|NetEase Cloud Music, NetEase Inc., China; Zhejiang University, China and NetEase Cloud Music, NetEase Inc., China; Zhejiang University, China|We study a particular matching task we call Music Cold-Start Matching. In short, given a cold-start song request, we expect to retrieve songs with similar audiences and then fastly push the cold-start song to the audiences of the retrieved songs to warm up it. However, there are hardly any studies done on this task. Therefore, in this paper, we will formalize the problem of Music Cold-Start Matching detailedly and give a scheme. During the offline training, we attempt to learn high-quality song representations based on song content features. But, we find supervision signals typically follow power-law distribution causing skewed representation learning. To address this issue, we propose a novel contrastive learning paradigm named Bootstrapping Contrastive Learning (BCL) to enhance the quality of learned representations by exerting contrastive regularization. During the online serving, to locate the target audiences more accurately, we propose Clustering-based Audience Targeting (CAT) that clusters audience representations to acquire a few cluster centroids and then locate the target audiences by measuring the relevance between the audience representations and the cluster centroids. Extensive experiments on the offline dataset and online system demonstrate the effectiveness and efficiency of our method. Currently, we have deployed it on NetEase Cloud Music, affecting millions of users.|我们研究一个特殊的匹配任务，我们称之为音乐冷启动匹配。简而言之，给定一个冷启动歌曲请求，我们期望检索具有相似受众的歌曲，然后快速将冷启动歌曲推送给被检索歌曲的受众进行预热。然而，几乎没有任何关于这项任务的研究。因此，本文将音乐冷启动匹配问题进行了详细的形式化描述，并给出了一个解决方案。在离线训练中，我们尝试根据歌曲的内容特征来学习高质量的歌曲表现。但是，我们发现监督信号具有典型的幂律分布特征，从而导致了偏态表征学习。为了解决这一问题，我们提出了一种新的对比学习范式——自举对比学习(BCL) ，通过运用对比正则化来提高学习表征的质量。在在线服务过程中，为了更准确地定位目标受众，我们提出了基于聚类的受众定位(CAT)方法，即通过聚类获取受众表征的几个聚类中心，然后通过测量受众表征与聚类中心之间的相关性来定位目标受众。在离线数据集和在线系统上的大量实验证明了该方法的有效性和高效性。目前，我们已经在网易云音乐上部署了它，影响了数百万用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bootstrapping+Contrastive+Learning+Enhanced+Music+Cold-Start+Matching)|0|
|[Reinforcing User Retention in a Billion Scale Short Video Recommender System](https://doi.org/10.1145/3543873.3584640)|Qingpeng Cai, Shuchang Liu, Xueliang Wang, Tianyou Zuo, Wentao Xie, Bin Yang, Dong Zheng, Peng Jiang, Kun Gai|Kuaishou Technology, China; Unaffiliated, China|Recently, short video platforms have achieved rapid user growth by recommending interesting content to users. The objective of the recommendation is to optimize user retention, thereby driving the growth of DAU (Daily Active Users). Retention is a long-term feedback after multiple interactions of users and the system, and it is hard to decompose retention reward to each item or a list of items. Thus traditional point-wise and list-wise models are not able to optimize retention. In this paper, we choose reinforcement learning methods to optimize the retention as they are designed to maximize the long-term performance. We formulate the problem as an infinite-horizon request-based Markov Decision Process, and our objective is to minimize the accumulated time interval of multiple sessions, which is equal to improving the app open frequency and user retention. However, current reinforcement learning algorithms can not be directly applied in this setting due to uncertainty, bias, and long delay time incurred by the properties of user retention. We propose a novel method, dubbed RLUR, to address the aforementioned challenges. Both offline and live experiments show that RLUR can significantly improve user retention. RLUR has been fully launched in Kuaishou app for a long time, and achieves consistent performance improvement on user retention and DAU.|最近，短视频平台通过向用户推荐有趣的内容实现了用户的快速增长。推荐的目的是优化用户保持率，从而推动 DAU (每日活跃用户)的增长。保留是用户和系统进行多次交互后的长期反馈，很难将保留奖励分解为每个项目或一个项目列表。因此，传统的点模型和列表模型不能优化保留。在本文中，我们选择强化学习方法来优化保留，因为它们旨在最大限度地提高长期绩效。我们把这个问题表述为一个基于无限期请求的马可夫决策过程，我们的目标是最小化多个会话的累积时间间隔，这相当于提高应用程序的开放频率和用户保持率。然而，由于用户保持特性的不确定性、偏差和长时间延迟，现有的强化学习算法不能直接应用于这种设置。我们提出了一种新的方法，称为 RLUR，以解决上述挑战。离线和现场实验都表明，RLUR 可以显著提高用户保持率。RLUR 已经在 Kuaishou 应用程序中全面推出很长时间了，并且在用户保留和 DAU 方面取得了持续的性能改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcing+User+Retention+in+a+Billion+Scale+Short+Video+Recommender+System)|0|
|[Jointly modeling products and resource pages for task-oriented recommendation](https://doi.org/10.1145/3543873.3584642)|Brendan Duncan, Surya Kallumadi, Taylor BergKirkpatrick, Julian J. McAuley|UC San Diego, USA; Lowe's Companies, Inc., USA|Modeling high-level user intent in recommender systems can improve performance, although it is often difficult to obtain a ground truth measure of this intent. In this paper, we investigate a novel way to obtain such an intent signal by leveraging resource pages associated with a particular task. We jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users. Our experiments consider the domain of home improvement product recommendation, where resource pages are DIY (do-it-yourself) project pages from Lowes.com. Each DIY page provides a list of tools, materials, and step-by-step instructions to complete a DIY project, such as building a deck, installing cabinets, and fixing a leaking pipe. We use this data as an indicator of the intended project, which is a natural high-level intent signal for home improvement shoppers. We then extend a state-of-the-art system to incorporate this new intent data, and show a significant improvement in the ability of the system to recommend products. We further demonstrate that our system can be used to successfully recommend DIY project pages to users. We have taken initial steps towards deploying our method for project recommendation in production on the Lowe’s website and for recommendations through marketing emails.|在推荐系统中建模高级用户意图可以提高性能，尽管通常很难获得这种意图的地面真实度量。在本文中，我们研究了一种通过利用与特定任务相关联的资源页来获得这种意图信号的新方法。我们联合对产品交互和资源页交互进行建模，以创建一个可以向用户推荐产品和资源页的系统。我们的实验考虑了家装产品推荐领域，其中的资源页面是来自 Lowes.com 的 DIY (DIY-it-yourself)项目页面。每一个 DIY 页面都提供了一系列的工具、材料和一步一步的指导来完成一个 DIY 项目，例如建造一个甲板、安装橱柜和修复一个泄漏的管道。我们使用这些数据作为预期项目的指标，这对于家装购物者来说是一个自然的高层次的意图信号。然后，我们扩展了一个最先进的系统来合并这些新的意图数据，并显示系统推荐产品的能力有了显著的提高。我们进一步演示了我们的系统可以用来成功地向用户推荐 DIY 项目页面。我们已经采取了初步步骤，部署我们的方法，项目推荐生产在劳的网站上，并通过营销电子邮件的建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Jointly+modeling+products+and+resource+pages+for+task-oriented+recommendation)|0|
|[Meta-Generator Enhanced Multi-Domain Recommendation](https://doi.org/10.1145/3543873.3584652)|Yingyi Zhang, Xianneng Li, Yahe Yu, Jian Tang, Huanfang Deng, Junya Lu, Yeyin Zhang, Qiancheng Jiang, Yunsen Xian, Liqian Yu, Han Liu|Dalian University of Technology, China; Meituan, China; Meituan-Dianping Group, China|Large-scale e-commercial platforms usually contain multiple business fields, which require industrial algorithms to characterize user intents across multiple domains. Numerous efforts have been made in user multi-domain intent modeling to achieve state-of-the-art performance. However, existing methods mainly focus on the domains having rich user information, which makes implementation to domains with sparse or rare user behavior meet with mixed success. Hence, in this paper, we propose a novel method named Meta-generator enhanced multi-Domain model (MetaDomain) to address the above issue. MetaDomain mainly includes two steps, 1) users’ multi-domain intent representation and 2) users’ multi-domain intent fusion. Specifically, in users’ multi-domain intent representation, we use the gradient information from a domain intent extractor to train the domain intent meta-generator, where the domain intent extractor has the input of users’ sequence feature and domain meta-generator has the input of users’ basic feature, hence the capability of generating users’ intent with sparse behavior. Afterward, in users’ multi-domain intent fusion, a domain graph is used to represent the high-order multi-domain connectivity. Extensive experiments have been carried out under a real-world industrial platform named Meituan. Both offline and rigorous online A/B tests under the billion-level data scale demonstrate the superiority of the proposed MetaDomain method over the state-of-the-art baselines. Furthermore comparing with the method using multi-domain sequence features, MetaDomain can reduce the serving latency by 20%. Currently, MetaDomain has been deployed in Meituan one of the largest worldwide Online-to-Offline(O2O) platforms.|大型电子商务平台通常包含多个业务字段，这需要工业算法来描述跨多个域的用户意图。在用户多领域意图建模方面做了大量工作，以实现最先进的性能。然而，现有的方法主要集中在具有丰富用户信息的域上，这使得对于用户行为稀疏或罕见的域的实现成败参半。为此，本文提出了一种新的元生成器增强型多域模型(MetaDomain)来解决上述问题。元域主要包括两个步骤: 1)用户的多域意图表示和2)用户的多域意图融合。具体来说，在用户的多领域意图表示中，我们利用领域意图提取器的梯度信息来训练领域意图元生成器，其中领域意图提取器输入用户的序列特征，领域元生成器输入用户的基本特征，从而具有生成稀疏行为的用户意图的能力。然后，在用户的多域意图融合中，使用一个域图来表示高阶多域连通性。在一个名为“美团”的真实工业平台下，人们进行了广泛的实验。在十亿级数据规模下的离线和严格的在线 A/B 测试都证明了提出的 MetaDomain 方法相对于最先进的基线的优越性。此外，与采用多域序列特征的方法相比，元域可以减少20% 的服务延迟。目前，MetaDomain 已经部署在全球最大的在线到离线(o2O)平台之一的美团上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Generator+Enhanced+Multi-Domain+Recommendation)|0|
|[Integrated Ranking for News Feed with Reinforcement Learning](https://doi.org/10.1145/3543873.3584651)|Menghui Zhu, Wei Xia, Weiwen Liu, Yifan Liu, Ruiming Tang, Weinan Zhang|Shanghai Jiao Tong University, China; Huawei Noah?s Ark Lab, China|With the development of recommender systems, it becomes an increasingly common need to mix multiple item sequences from different sources. Therefore, the integrated ranking stage is proposed to be responsible for this task with re-ranking models. However, existing methods ignore the relation between the sequences, thus resulting in local optimum over the interaction session. To resolve this challenge, in this paper, we propose a new model named NFIRank (News Feed Integrated Ranking with reinforcement learning) and formulate the whole interaction session as a MDP (Markov Decision Process). Sufficient offline experiments are provided to verify the effectiveness of our model. In addition, we deployed our model on Huawei Browser and gained 1.58% improvements in CTR compared with the baseline in online A/B test. Code will be available at https://gitee.com/mindspore/models/tree/master/research/recommend/NFIRank.|随着推荐系统的发展，混合来自不同来源的多个项目序列的需求变得越来越普遍。因此，提出综合排序阶段负责这一任务的重新排序模型。然而，现有的方法忽略了序列之间的关系，从而导致局部最优的交互会话。为了解决这个问题，在本文中，我们提出了一个新的模型 NFIRank (带强化学习的新闻源综合排名) ，并将整个交互会话表示为一个 MDP (马可夫决策过程)。通过离线实验验证了模型的有效性。此外，我们在华为浏览器上部署了我们的模型，与在线 A/B 测试的基线相比，点击率提高了1.58% 。密码将在 https://gitee.com/mindspore/models/tree/master/research/recommend/nfirank 公布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrated+Ranking+for+News+Feed+with+Reinforcement+Learning)|0|
|[Measuring e-Commerce Metric Changes in Online Experiments](https://doi.org/10.1145/3543873.3584654)|C. H. Bryan Liu, Emma J. McCoy|ASOS.com, United Kingdom and Imperial College London, United Kingdom; London School of Economics and Political Science, United Kingdom|Digital technology organizations routinely use online experiments (e.g. A/B tests) to guide their product and business decisions. In e-commerce, we often measure changes to transaction- or item-based business metrics such as Average Basket Value (ABV), Average Basket Size (ABS), and Average Selling Price (ASP); yet it remains a common pitfall to ignore the dependency between the value/size of transactions/items during experiment design and analysis. We present empirical evidence on such dependency, its impact on measurement uncertainty, and practical implications on A/B test outcomes if left unmitigated. By making the evidence available, we hope to drive awareness of the pitfall among experimenters in e-commerce and hence encourage the adoption of established mitigation approaches. We also share lessons learned when incorporating selected mitigation approaches into our experimentation analysis platform currently in production.|数字技术组织经常使用在线实验(例如 A/B 测试)来指导他们的产品和商业决策。在电子商务中，我们经常衡量基于交易或项目的业务指标的变化，如平均篮子价值(ABV)、平均篮子大小(ABS)和平均销售价格(ASP) ; 然而，在实验设计和分析过程中忽视交易/项目的价值/大小之间的依赖性仍然是一个常见的陷阱。我们介绍了这种依赖性的经验证明，它对测量不确定性的影响，以及如果不加以缓解的话对 A/B 测试结果的实际影响。通过提供证据，我们希望提高电子商务实验者对这一陷阱的认识，从而鼓励采用既定的缓解办法。我们还分享了将选定的缓解方法纳入我们目前正在生产的实验分析平台的经验教训。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+e-Commerce+Metric+Changes+in+Online+Experiments)|0|
|[Improve retrieval of regional titles in streaming services with dense retrieval](https://doi.org/10.1145/3543873.3587619)|Bhargav Upadhyay, Tejas Khairnar, Anup Kotalwar|Amazon, India|Customers search for movie and series titles released across the world on streaming services like primevideo.com (PV), netflix.com (Netflix). In non-English speaking countries like India, Nepal and many others, the regional titles are transliterated from native language to English and are being searched in English. Given that there can be multiple transliterations possible for almost all the titles, searching for a regional title can be a very frustrating customer experience if these nuances are not handled correctly by the search system. Typing errors make the problem even more challenging. Streaming services uses spell correction and auto-suggestions/auto-complete features to address this issue up to certain extent. Auto-suggest fails when user searches keywords not in scope of the auto-suggest. Spell correction is effective at correcting common typing errors but as these titles doesn’t follow strict grammar rules and new titles constantly added to the catalog, spell correction have limited success. With recent progress in deep learning (DL), embedding vectors based dense retrieval is being used extensively to retrieve semantically relevant documents for a given query. In this work, we have used dense retrieval to address the noise introduced by transliteration variations and typing errors to improve retrieval of regional media titles. In the absent of any relevant dataset to test our hypothesis, we created a new dataset of 40K query title pairs from PV search logs. We also created a baseline by bench-marking PV’s performance on test data. We present an extensive study on the impact of 1. pre-training, 2. data augmentation, 3. positive to negative sample ratio, and 4. choice of loss function on retrieval performance. Our best model has shown 51.24% improvement in [email protected] over PV baseline.|客户可以通过流媒体服务搜索世界各地发行的电影和剧集，比如 primeideo.com (PV)、 Netflix.com (Netflix)。在非英语国家，如印度、尼泊尔和许多其他国家，地区标题被从母语音译成英语，并用英语进行搜索。鉴于几乎所有标题都可能有多种音译，如果搜索系统不能正确处理这些细微差别，那么搜索地区标题可能是一种非常令人沮丧的客户体验。键入错误使问题更具挑战性。流媒体服务使用拼写修正和自动建议/自动完成功能在一定程度上解决了这个问题。当用户搜索不在自动建议范围内的关键字时，自动建议失败。拼写纠正在纠正常见的打字错误方面是有效的，但是由于这些标题没有遵循严格的语法规则，而且新标题不断地添加到目录中，拼写纠正的成功有限。随着深度学习(DL)技术的发展，基于嵌入向量的密集检索技术被广泛应用于给定查询的语义相关文档检索。在本研究中，我们利用密集检索来解决音译变异和打字错误所引起的噪音问题，以提高地区性媒体标题的检索效率。在缺乏相关数据集来检验我们的假设的情况下，我们从 PV 搜索日志中创建了一个40K 查询标题对的新数据集。我们还通过在测试数据上标记 PV 的性能来创建基线。我们提出了一个广泛的研究影响1。训练前2分钟。数据增强，3。正负样本比率，以及4。损失函数对检索性能的选择。我们最好的模型已经显示了51.24% 的改善[电子邮件保护]超过 PV 基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improve+retrieval+of+regional+titles+in+streaming+services+with+dense+retrieval)|0|
|[hp-frac: An index to determine Awarded Researchers](https://doi.org/10.1145/3543873.3587597)|Aashay Singhal, Kamalakar Karlapalem|International Institute of Information Technology, Hyderabad, India|In order to advance academic research, it is important to assess and evaluate the academic influence of researchers and the findings they produce. Citation metrics are universally used methods to evaluate researchers. Amongst the several variations of citation metrics, the h-index proposed by Hirsch has become the leading measure. Recent work shows that h-index is not an effective measure to determine scientific impact - due to changing authorship patterns. This can be mitigated by using h-index of a paper to compute h-index of an author. We show that using fractional allocation of h-index gives better results. In this work, we reapply two indices based on the h-index of a single paper. The indices are referred to as: hp-index and hp-frac-index. We run large-scale experiments in three different fields with about a million publications and 3,000 authors. Our experiments show that hp-frac-index provides a unique ranking when compared to h-index. It also performs better than h-index in providing higher ranks to the awarded researcher.|为了推进学术研究，评估和评估研究人员的学术影响力和他们的发现是非常重要的。引文指标是评价科研人员的普遍方法。在引文指标的众多变化中，赫希提出的 h 指标已经成为引文指标的主导指标。最近的研究表明，由于作者模式的改变，h 指数不是确定科学影响的有效方法。这可以通过使用论文的 h- 索引来计算作者的 h- 索引来减轻。我们表明，使用分数分配的 h 指标给出了更好的结果。在这项工作中，我们重新应用两个指标的基础上的单一文件的 h-索引。这些指数被称为: hp-index 和 hp-frac-index。我们在三个不同的领域进行了大规模的实验，发表了大约一百万篇论文，有3000名作者。我们的实验表明，与 h 指数相比，hp-frac 指数提供了一个唯一的排名。在为获奖研究人员提供更高的排名方面，它也比 h-index 表现得更好。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=hp-frac:+An+index+to+determine+Awarded+Researchers)|0|
|[Application of an ontology for model cards to generate computable artifacts for linking machine learning information from biomedical research](https://doi.org/10.1145/3543873.3587601)|Muhammad Amith, Licong Cui, Kirk Roberts, Cui Tao|Department of Information Science, University of North Texas, USA; School of Biomedical Informatics, The University of Texas Health Science Center at Houston, USA; School of Biomedical Informatics, University of Texas Health Science Center at Houston, USA|Model card reports provide a transparent description of machine learning models which includes information about their evaluation, limitations, intended use, etc. Federal health agencies have expressed an interest in model cards report for research studies using machine-learning based AI. Previously, we have developed an ontology model for model card reports to structure and formalize these reports. In this paper, we demonstrate a Java-based library (OWL API, FaCT++) that leverages our ontology to publish computable model card reports. We discuss future directions and other use cases that highlight applicability and feasibility of ontology-driven systems to support FAIR challenges.|模型卡片报告提供了机器学习模型的透明描述，包括它们的评估、限制、预期用途等信息。联邦卫生机构对使用基于机器学习的人工智能的研究报告模型卡表示了兴趣。在此之前，我们已经开发了一个模型卡片报告的本体模型来构造和形式化这些报告。在本文中，我们演示了一个基于 Java 的库(OWL API，FaCT + +) ，它利用我们的本体来发布可计算模型卡报告。我们讨论未来的方向和其他用例，突出本体驱动的系统的适用性和可行性，以支持 FAIR 的挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Application+of+an+ontology+for+model+cards+to+generate+computable+artifacts+for+linking+machine+learning+information+from+biomedical+research)|0|
|[Stance Inference in Twitter through Graph Convolutional Collaborative Filtering Networks with Minimal Supervision](https://doi.org/10.1145/3543873.3587640)|Zhiwei Zhou, Erick Elejalde|Leibniz Universität Hannover, L3S Research Center, Germany|Social Media (SM) has become a stage for people to share thoughts, emotions, opinions, and almost every other aspect of their daily lives. This abundance of human interaction makes SM particularly attractive for social sensing. Especially during polarizing events such as political elections or referendums, users post information and encourage others to support their side, using symbols such as hashtags to represent their attitudes. However, many users choose not to attach hashtags to their messages, use a different language, or show their position only indirectly. Thus, automatically identifying their opinions becomes a more challenging task. To uncover these implicit perspectives, we propose a collaborative filtering model based on Graph Convolutional Networks that exploits the textual content in messages and the rich connections between users and topics. Moreover, our approach only requires a small annotation effort compared to state-of-the-art solutions. Nevertheless, the proposed model achieves competitive performance in predicting individuals' stances. We analyze users' attitudes ahead of two constitutional referendums in Chile in 2020 and 2022. Using two large Twitter datasets, our model achieves improvements of 3.4% in recall and 3.6% in accuracy over the baselines.|社交媒体(SM)已经成为人们分享思想、情感、观点以及日常生活中几乎所有其他方面的一个舞台。这种丰富的人际互动使 SM 对社会感知特别有吸引力。特别是在政治选举或公民投票等两极分化的活动中，用户发布信息并鼓励其他人支持他们的立场，使用标签等符号来表达他们的态度。但是，许多用户选择不在消息中附加标签，不使用其他语言，或者只间接显示自己的位置。因此，自动识别他们的观点成为一项更具挑战性的任务。为了揭示这些隐含的观点，我们提出了一个基于图形卷积网络的协同过滤模型，该模型利用消息中的文本内容以及用户和主题之间的丰富联系。此外，与最先进的解决方案相比，我们的方法只需要很少的注释工作。然而，所提出的模型在预测个体的立场方面达到了竞争性的表现。我们分析了2020年和2022年智利两次宪法公投前用户的态度。使用两个大型的 Twitter 数据集，我们的模型比基线数据集提高了3.4% 的召回率和3.6% 的准确率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stance+Inference+in+Twitter+through+Graph+Convolutional+Collaborative+Filtering+Networks+with+Minimal+Supervision)|0|
|[Retrieving false claims on Twitter during the Russia-Ukraine conflict](https://doi.org/10.1145/3543873.3587571)|Valerio La Gatta, Chiyu Wei, Luca Luceri, Francesco Pierri, Emilio Ferrara|Information Sciences Institute, University of Southern California, USA; Information Sciences Institute, University of Southern California, USA and University of Naples Federico II, Italy; Politecnico di Milano, Italy and Information Sciences Institute, University of Southern California, USA|Nowadays, false and unverified information on social media sway individuals' perceptions during major geo-political events and threaten the quality of the whole digital information ecosystem. Since the Russian invasion of Ukraine, several fact-checking organizations have been actively involved in verifying stories related to the conflict that circulated online. In this paper, we leverage a public repository of fact-checked claims to build a methodological framework for automatically identifying false and unsubstantiated claims spreading on Twitter in February 2022. Our framework consists of two sequential models: First, the claim detection model identifies whether tweets incorporate a (false) claim among those considered in our collection. Then, the claim retrieval model matches the tweets with fact-checked information by ranking verified claims according to their relevance with the input tweet. Both models are based on pre-trained language models and fine-tuned to perform a text classification task and an information retrieval task, respectively. In particular, to validate the effectiveness of our methodology, we consider 83 verified false claims that spread on Twitter during the first week of the invasion, and manually annotate 5,872 tweets according to the claim(s) they report. Our experiments show that our proposed methodology outperforms standard baselines for both claim detection and claim retrieval. Overall, our results highlight how social media providers could effectively leverage semi-automated approaches to identify, track, and eventually moderate false information that spreads on their platforms.|如今，社交媒体上的虚假和未经证实的信息在重大地缘政治事件中左右着人们的看法，威胁着整个数字信息生态系统的质量。自从俄罗斯入侵乌克兰以来，几个事实核查组织一直积极参与核实在网上流传的与冲突有关的故事。在本文中，我们利用一个事实核查索赔的公共数据库，建立一个方法框架，自动识别2022年2月在 Twitter 上传播的虚假和未经证实的索赔。我们的框架由两个顺序模型组成: 首先，索赔检测模型确定 tweet 是否在我们的集合中考虑的索赔中包含(虚假)索赔。然后，索赔检索模型根据索赔与输入索赔的相关性对索赔进行排序，从而将索赔与事实核查信息进行匹配。这两种模型都是基于预先训练好的语言模型，经过微调后分别执行文本分类任务和信息检索分类任务。特别是，为了验证我们的方法的有效性，我们考虑了在入侵的第一周在 Twitter 上传播的83个经过验证的虚假声明，并根据他们报告的声明手动注释了5,872条推文。我们的实验表明，我们提出的方法在索赔检测和索赔检索方面都优于标准基线。总的来说，我们的研究结果强调了社交媒体提供商如何有效地利用半自动化方法来识别、跟踪并最终控制在他们的平台上传播的虚假信息。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieving+false+claims+on+Twitter+during+the+Russia-Ukraine+conflict)|0|
|[Enhancing Hierarchy-Aware Graph Networks with Deep Dual Clustering for Session-based Recommendation](https://doi.org/10.1145/3543507.3583247)|Jiajie Su, Chaochao Chen, Weiming Liu, Fei Wu, Xiaolin Zheng, Haoming Lyu|Zhejiang University, China|Session-based Recommendation aims at predicting the next interacted item based on short anonymous behavior sessions. However, existing solutions neglect to model two inherent properties of sequential representing distributions, i.e., hierarchy structures resulted from item popularity and collaborations existing in both intra- and inter-session. Tackling with these two factors at the same time is challenging. On the one hand, traditional Euclidean space utilized in previous studies fails to capture hierarchy structures due to a restricted representation ability. On the other hand, the intuitive apply of hyperbolic geometry could extract hierarchical patterns but more emphasis on degree distribution weakens intra- and inter-session collaborations. To address the challenges, we propose a Hierarchy-Aware Dual Clustering Graph Network (HADCG) model for session-based recommendation. Towards the first challenge, we design the hierarchy-aware graph modeling module which converts sessions into hyperbolic session graphs, adopting hyperbolic geometry in propagation and attention mechanism so as to integrate chronological and hierarchical information. As for the second challenge, we introduce the deep dual clustering module which develops a two-level clustering strategy, i.e., information regularizer for intra-session clustering and contrastive learner for inter-session clustering, to enhance hyperbolic representation learning from collaborative perspectives and further promote recommendation performance. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed HADCG.|基于会话的推荐是基于短的匿名行为会话来预测下一个交互项。然而，现有的解决方案忽视了顺序表示分布的两个固有属性，即由于项目流行和会话内和会话间存在的协作而产生的层次结构。同时处理这两个因素是具有挑战性的。一方面，传统的欧氏空间由于表示能力的限制，无法捕捉层次结构;。另一方面，双曲几何的直观应用可以提取等级模式，但更强调学位分配会削弱会话内部和会话间的协作。针对这一挑战，我们提出了一种基于会话的层次感知双聚类图网络(HADCG)模型。针对第一个挑战，我们设计了层次感知的图形建模模块，它将会话转换为双曲会话图，在传播和注意机制中采用双曲几何，以便整合时间和层次信息。针对第二个挑战，我们引入了深度双聚类模型，提出了一种两级聚类策略，即会话内聚类的信息调整器和会话间聚类的对比学习器，从协作的角度提高双曲表示学习，进一步提高推荐性能。在三个实际数据集上的大量实验证明了所提出的 HADCG 算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Hierarchy-Aware+Graph+Networks+with+Deep+Dual+Clustering+for+Session-based+Recommendation)|0|
|[Intra and Inter Domain HyperGraph Convolutional Network for Cross-Domain Recommendation](https://doi.org/10.1145/3543507.3583402)|Zhongxuan Han, Xiaolin Zheng, Chaochao Chen, Wenjie Cheng, Yang Yao|Zhejiang University, China; Zhejiang Lab, China|Cross-Domain Recommendation (CDR) aims to solve the data sparsity problem by integrating the strengths of different domains. Though researchers have proposed various CDR methods to effectively transfer knowledge across domains, they fail to address the following key issues, i.e., (1) they cannot model high-order correlations among users and items in every single domain to obtain more accurate representations; (2) they cannot model the correlations among items across different domains. To tackle the above issues, we propose a novel Intra and Inter Domain HyperGraph Convolutional Network (II-HGCN) framework, which includes two main layers in the modeling process, i.e., the intra-domain layer and the inter-domain layer. In the intra-domain layer, we design a user hypergraph and an item hypergraph to model high-order correlations inside every single domain. Thus we can address the data sparsity problem better and learn high-quality representations of users and items. In the inter-domain layer, we propose an inter-domain hypergraph structure to explore correlations among items from different domains based on their interactions with common users. Therefore we can not only transfer the knowledge of users but also combine embeddings of items across domains. Comprehensive experiments on three widely used benchmark datasets demonstrate that II-HGCN outperforms other state-of-the-art methods, especially when datasets are extremely sparse.|跨域推荐(CDR)旨在通过整合不同域的优势来解决数据稀疏性问题。尽管研究人员已经提出了各种 CDR 方法来有效地跨领域传递知识，但他们未能解决以下关键问题，即: (1)他们不能模拟每个领域中用户和项目之间的高阶相关性以获得更准确的表示; (2)他们不能模拟不同领域中项目之间的相关性。为了解决上述问题，我们提出了一种新的域内和域间超图卷积网络(II-HGCN)框架，它包括建模过程中的两个主要层次，即域内层和域间层。在域内层，我们设计了一个用户超图和一个项目超图来模拟每个域内的高阶相关性。因此，我们可以更好地解决数据稀疏问题，并学习用户和项目的高质量表示。在域间层，我们提出了一个域间超图结构来探索来自不同领域的项目之间的相关性，基于它们与公共用户的交互。因此，不仅可以实现用户知识的传递，还可以实现跨域嵌入的组合。在三个广泛使用的基准数据集上的综合实验表明，II-HGCN 优于其他最先进的方法，特别是在数据集极其稀疏的情况下。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intra+and+Inter+Domain+HyperGraph+Convolutional+Network+for+Cross-Domain+Recommendation)|0|
|[Generating Counterfactual Hard Negative Samples for Graph Contrastive Learning](https://doi.org/10.1145/3543507.3583499)|Haoran Yang, Hongxu Chen, Sixiao Zhang, Xiangguo Sun, Qian Li, Xiangyu Zhao, Guandong Xu|University of Technology Sydney, Australia; The Chinese University of Hong Kong, Hong Kong; City University of Hong Kong, Hong Kong; Curtin University, Australia|Graph contrastive learning has emerged as a powerful tool for unsupervised graph representation learning. The key to the success of graph contrastive learning is to acquire high-quality positive and negative samples as contrasting pairs for the purpose of learning underlying structural semantics of the input graph. Recent works usually sample negative samples from the same training batch with the positive samples, or from an external irrelevant graph. However, a significant limitation lies in such strategies, which is the unavoidable problem of sampling false negative samples. In this paper, we propose a novel method to utilize \textbf{C}ounterfactual mechanism to generate artificial hard negative samples for \textbf{G}raph \textbf{C}ontrastive learning, namely \textbf{CGC}, which has a different perspective compared to those sampling-based strategies. We utilize counterfactual mechanism to produce hard negative samples, which ensures that the generated samples are similar to, but have labels that different from the positive sample. The proposed method achieves satisfying results on several datasets compared to some traditional unsupervised graph learning methods and some SOTA graph contrastive learning methods. We also conduct some supplementary experiments to give an extensive illustration of the proposed method, including the performances of CGC with different hard negative samples and evaluations for hard negative samples generated with different similarity measurements.|图形对比学习已经成为无监督图形表示学习的有力工具。图形对比学习成功的关键是获取高质量的正负样本作为对比对，从而学习输入图的结构语义。最近的作品通常从同一训练批次的正样本中抽取负样本，或者从一个外部不相关的图中抽取负样本。然而，这种策略存在一个显著的局限性，这就是不可避免的采样假阴性样本的问题。本文提出了一种新的利用 textbf { C }反事实机制生成 textbf { G } raph textbf { C }对比学习人工硬负样本的方法，即 textbf { CGC }。我们利用反事实机制生成硬负样本，确保所生成的样本与正样本相似，但有不同于正样本的标签。与传统的无监督图形学习方法和 SOTA 图形对比学习方法相比，该方法在多个数据集上取得了令人满意的效果。我们还进行了一些补充实验，对所提出的方法进行了广泛的说明，包括对不同硬负样本的 CGC 性能和对不同相似度测量产生的硬负样本的评价。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Counterfactual+Hard+Negative+Samples+for+Graph+Contrastive+Learning)|0|
|[Toward Degree Bias in Embedding-Based Knowledge Graph Completion](https://doi.org/10.1145/3543507.3583544)|Harry Shomer, Wei Jin, Wentao Wang, Jiliang Tang|Computer Science, Michigan State University, USA|A fundamental task for knowledge graphs (KGs) is knowledge graph completion (KGC). It aims to predict unseen edges by learning representations for all the entities and relations in a KG. A common concern when learning representations on traditional graphs is degree bias. It can affect graph algorithms by learning poor representations for lower-degree nodes, often leading to low performance on such nodes. However, there has been limited research on whether there exists degree bias for embedding-based KGC and how such bias affects the performance of KGC. In this paper, we validate the existence of degree bias in embedding-based KGC and identify the key factor to degree bias. We then introduce a novel data augmentation method, KG-Mixup, to generate synthetic triples to mitigate such bias. Extensive experiments have demonstrated that our method can improve various embedding-based KGC methods and outperform other methods tackling the bias problem on multiple benchmark datasets.|知识图的一个基本任务是知识图的完成。它的目的是通过学习 KG 中所有实体和关系的表示来预测看不见的边。学习传统图表示的一个常见问题是度偏差。它通过学习低度节点的差表示来影响图算法，经常导致低度节点的性能下降。然而，关于嵌入式 KGC 是否存在程度偏差以及这种偏差如何影响 KGC 性能的研究还很有限。在本文中，我们验证了基于嵌入的 KGC 中存在程度偏差，并找出了影响程度偏差的关键因素。然后，我们引入一种新的数据增强方法，KG 混合，产生合成三元组，以减轻这种偏差。大量的实验表明，该方法可以改进各种基于嵌入的 KGC 方法，并优于其他处理多基准数据集偏差问题的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Degree+Bias+in+Embedding-Based+Knowledge+Graph+Completion)|0|
|[LINet: A Location and Intention-Aware Neural Network for Hotel Group Recommendation](https://doi.org/10.1145/3543507.3583202)|Ruitao Zhu, Detao Lv, Yao Yu, Ruihao Zhu, Zhenzhe Zheng, Ke Bu, Quan Lu, Fan Wu|Cornell University, USA; Alibaba Group, China; Shanghai Jiao Tong University, China|Motivated by the collaboration with Fliggy1, a leading Online Travel Platform (OTP), we investigate an important but less explored research topic about optimizing the quality of hotel supply, namely selecting potential profitable hotels in advance to build up adequate room inventory. We formulate a WWW problem, i.e., within a specific time period (When) and potential travel area (Where), which hotels should be recommended to a certain group of users with similar travel intentions (Why). We identify three critical challenges in solving the WWW problem: user groups generation, travel data sparsity and utilization of hotel recommendation information (e.g., period, location and intention). To this end, we propose LINet, a Location and Intention-aware neural Network for hotel group recommendation. Specifically, LINet first identifies user travel intentions for user groups generalization, and then characterizes the group preferences by jointly considering historical user-hotel interaction and spatio-temporal features of hotels. For data sparsity, we develop a graph neural network, which employs long-term data, and further design an auxiliary loss function of location that efficiently exploits data within the same and across different locations. Both offline and online experiments demonstrate the effectiveness of LINet when compared with state-of-the-art methods. LINet has been successfully deployed on Fliggy to retrieve high quality hotels for business development, serving hundreds of hotel operation scenarios and thousands of hotel operators.|受到与领先的在线旅游平台(OTP) Fliggy1合作的启发，我们研究了一个重要但探索较少的优化酒店供应质量的研究课题，即提前选择潜在的盈利酒店，以建立足够的客房库存。我们制定了一个 WWW 问题，即在一个特定的时间段(何时)和潜在的旅游区域(何地) ，哪些酒店应该被推荐给具有相似旅游意图的特定用户群体(为什么)。我们确定了解决 WWW 问题的三个关键挑战: 用户群生成、旅游数据稀疏和酒店推荐信息的利用(例如，时间、地点和意图)。为此，我们提出了 LINet，一个位置和意图感知的神经网络，用于酒店集团推荐。具体来说，LINet 首先通过用户群的概括来识别用户的旅游意图，然后联合考虑历史上用户与酒店的交互和酒店的时空特征来表征用户的群体偏好。针对数据稀疏性问题，提出了一种基于长期数据的图形神经网络，并进一步设计了位置辅助损失函数，有效地利用同一位置和不同位置的数据。离线和在线实验都证明了与最先进的方法相比，LINet 的有效性。LINet 已经成功地部署在 Fliggy 上，为业务发展检索高质量的酒店，为数百家酒店运营方案和数千家酒店运营商提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LINet:+A+Location+and+Intention-Aware+Neural+Network+for+Hotel+Group+Recommendation)|0|
|[Distillation from Heterogeneous Models for Top-K Recommendation](https://doi.org/10.1145/3543507.3583209)|SeongKu Kang, Wonbin Kweon, Dongha Lee, Jianxun Lian, Xing Xie, Hwanjo Yu|Microsoft Research Asia, China; Pohang University of Science and Technology, Republic of Korea; Yonsei University, Republic of Korea|Recent recommender systems have shown remarkable performance by using an ensemble of heterogeneous models. However, it is exceedingly costly because it requires resources and inference latency proportional to the number of models, which remains the bottleneck for production. Our work aims to transfer the ensemble knowledge of heterogeneous teachers to a lightweight student model using knowledge distillation (KD), to reduce the huge inference costs while retaining high accuracy. Through an empirical study, we find that the efficacy of distillation severely drops when transferring knowledge from heterogeneous teachers. Nevertheless, we show that an important signal to ease the difficulty can be obtained from the teacher's training trajectory. This paper proposes a new KD framework, named HetComp, that guides the student model by transferring easy-to-hard sequences of knowledge generated from the teachers' trajectories. To provide guidance according to the student's learning state, HetComp uses dynamic knowledge construction to provide progressively difficult ranking knowledge and adaptive knowledge transfer to gradually transfer finer-grained ranking information. Our comprehensive experiments show that HetComp significantly improves the distillation quality and the generalization of the student model.|最近的推荐系统通过使用一系列异构模型显示了显著的性能。然而，它的成本非常高，因为它需要的资源和推理延迟与模型的数量成正比，这仍然是生产的瓶颈。我们的工作旨在利用知识精馏(KD)将异构教师的集成知识转移到一个轻量级的学生模型，以减少庞大的推理成本，同时保持较高的推理精度。通过实证研究发现，异质型教师传授知识时，蒸馏效果严重下降。然而，我们表明，一个重要的信号，缓解困难可以从教师的培训轨迹。提出了一种新的知识发现框架 HetComp，该框架通过传递由教师轨迹生成的易于生成的知识序列来指导学生模型。为了根据学生的学习状态提供指导，HetComp 使用动态知识结构来提供逐步难以排序的知识，并使用自适应知识转移来逐步传递更细粒度的排序信息。我们的综合实验表明，HetComp 显著提高了蒸馏质量和学生模型的推广。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distillation+from+Heterogeneous+Models+for+Top-K+Recommendation)|0|
|[Exploration and Regularization of the Latent Action Space in Recommendation](https://doi.org/10.1145/3543507.3583244)|Shuchang Liu, Qingpeng Cai, Bowen Sun, Yuhao Wang, Ji Jiang, Dong Zheng, Peng Jiang, Kun Gai, Xiangyu Zhao, Yongfeng Zhang|; Rutgers University, USA; City University of Hong Kong, China; Peking University, China; Kuaishou Technology, China|In recommender systems, reinforcement learning solutions have effectively boosted recommendation performance because of their ability to capture long-term user-system interaction. However, the action space of the recommendation policy is a list of items, which could be extremely large with a dynamic candidate item pool. To overcome this challenge, we propose a hyper-actor and critic learning framework where the policy decomposes the item list generation process into a hyper-action inference step and an effect-action selection step. The first step maps the given state space into a vectorized hyper-action space, and the second step selects the item list based on the hyper-action. In order to regulate the discrepancy between the two action spaces, we design an alignment module along with a kernel mapping function for items to ensure inference accuracy and include a supervision module to stabilize the learning process. We build simulated environments on public datasets and empirically show that our framework is superior in recommendation compared to standard RL baselines.|在推荐系统中，强化学习解决方案有效地提高了推荐性能，因为它们能够捕捉长期的用户系统交互。但是，推荐策略的操作空间是一个项目列表，对于动态候选项目池，这个列表可能非常大。为了克服这一挑战，我们提出了一个超行为者和批评者学习框架，其中策略将项目表生成过程分解为一个超行为推理步骤和一个效果-行为选择步骤。第一步将给定的状态空间映射到向量化的超动作空间，第二步根据超动作选择项目列表。为了调节两个动作空间之间的差异，我们设计了一个对齐模块和一个项目的核映射函数来保证推理的准确性，并包括一个监督模块来稳定学习过程。我们在公共数据集上建立了模拟环境，并且经验表明我们的框架在推荐方面优于标准 RL 基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploration+and+Regularization+of+the+Latent+Action+Space+in+Recommendation)|0|
|[Compressed Interaction Graph based Framework for Multi-behavior Recommendation](https://doi.org/10.1145/3543507.3583312)|Wei Guo, Chang Meng, Enming Yuan, Zhicheng He, Huifeng Guo, Yingxue Zhang, Bo Chen, Yaochen Hu, Ruiming Tang, Xiu Li, Rui Zhang|ruizhang.info, China; Huawei Technologies, Canada; Shenzhen International Graduate School, Tsinghua University, China; Huawei Noah's Ark Lab, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, China|Multi-types of user behavior data (e.g., clicking, adding to cart, and purchasing) are recorded in most real-world recommendation scenarios, which can help to learn users' multi-faceted preferences. However, it is challenging to explore multi-behavior data due to the unbalanced data distribution and sparse target behavior, which lead to the inadequate modeling of high-order relations when treating multi-behavior data ''as features'' and gradient conflict in multitask learning when treating multi-behavior data ''as labels''. In this paper, we propose CIGF, a Compressed Interaction Graph based Framework, to overcome the above limitations. Specifically, we design a novel Compressed Interaction Graph Convolution Network (CIGCN) to model instance-level high-order relations explicitly. To alleviate the potential gradient conflict when treating multi-behavior data ''as labels'', we propose a Multi-Expert with Separate Input (MESI) network with separate input on the top of CIGCN for multi-task learning. Comprehensive experiments on three large-scale real-world datasets demonstrate the superiority of CIGF. Ablation studies and in-depth analysis further validate the effectiveness of our proposed model in capturing high-order relations and alleviating gradient conflict. The source code and datasets are available at https://github.com/MC-CV/CIGF.|多种类型的用户行为数据(例如，点击、添加到购物车和购买)记录在大多数真实世界的推荐场景中，这有助于了解用户的多方面偏好。然而，由于多行为数据分布不均衡，目标行为稀疏，导致多任务学习中将多行为数据“作为特征”的高阶关系建模不足，将多行为数据“作为标签”的多任务学习中存在梯度冲突。本文提出了一种基于压缩交互图的 CIGF 框架，以克服上述局限性。具体来说，我们设计了一个新的压缩交互图卷积网络(CIGCN)来显式地建模实例级的高阶关系。为了缓解多行为数据“作为标签”时潜在的梯度冲突，本文提出了一种在 CIGCN 顶部具有独立输入的多专家网络，用于多任务学习。通过对三个大规模实际数据集的综合实验，验证了 CIGF 算法的优越性。烧蚀研究和深入分析进一步验证了我们提出的模型在捕获高阶关系和缓解梯度冲突方面的有效性。源代码和数据集可在 https://github.com/mc-cv/cigf 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compressed+Interaction+Graph+based+Framework+for+Multi-behavior+Recommendation)|0|
|[Correlative Preference Transfer with Hierarchical Hypergraph Network for Multi-Domain Recommendation](https://doi.org/10.1145/3543507.3583331)|Zixuan Xu, Penghui Wei, Shaoguo Liu, Weimin Zhang, Liang Wang, Bo Zheng|Alibaba Group, China|Advanced recommender systems usually involve multiple domains (such as scenarios or categories) for various marketing strategies, and users interact with them to satisfy diverse demands. The goal of multi-domain recommendation (MDR) is to improve the recommendation performance of all domains simultaneously. Conventional graph neural network based methods usually deal with each domain separately, or train a shared model to serve all domains. The former fails to leverage users' cross-domain behaviors, making the behavior sparseness issue a great obstacle. The latter learns shared user representation with respect to all domains, which neglects users' domain-specific preferences. In this paper we propose $\mathsf{H^3Trans}$, a hierarchical hypergraph network based correlative preference transfer framework for MDR, which represents multi-domain user-item interactions into a unified graph to help preference transfer. $\mathsf{H^3Trans}$ incorporates two hyperedge-based modules, namely dynamic item transfer (Hyper-I) and adaptive user aggregation (Hyper-U). Hyper-I extracts correlative information from multi-domain user-item feedbacks for eliminating domain discrepancy of item representations. Hyper-U aggregates users' scattered preferences in multiple domains and further exploits the high-order (not only pair-wise) connections to improve user representations. Experiments on both public and production datasets verify the superiority of $\mathsf{H^3Trans}$ for MDR.|高级推荐系统通常涉及多个领域(如场景或类别)的不同营销策略，用户与他们互动，以满足不同的需求。多域推荐(MDR)的目标是同时提高所有域的推荐性能。传统的基于图神经网络的方法通常分别处理各个领域，或者训练一个共享模型来服务于所有领域。前者未能充分利用用户的跨域行为，使得行为稀疏性问题成为一大障碍。后者学习所有域的共享用户表示，这忽略了用户特定域的首选项。本文提出了一种基于层次超图网络的 MDR 相关偏好传递框架 $mathsf { H ^ 3Trans } $，它将多领域用户-项目交互表示为一个统一的图，以帮助偏好传递。$mathsf { H ^ 3Trans } $包含两个基于超边界的模块，即动态项传输(Hyper-I)和自适应用户聚合(Hyper-U)。Hyper-I 从多领域用户项目反馈中提取相关信息，消除项目表示的领域差异。Hyper-U 聚合用户在多个域中的分散偏好，并进一步利用高阶(不仅仅是成对)连接来改善用户表示。在公共数据集和生产数据集上的实验验证了 $mathsf { H ^ 3Trans } $用于 MDR 的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Correlative+Preference+Transfer+with+Hierarchical+Hypergraph+Network+for+Multi-Domain+Recommendation)|0|
|[User Retention-oriented Recommendation with Decision Transformer](https://doi.org/10.1145/3543507.3583418)|Kesen Zhao, Lixin Zou, Xiangyu Zhao, Maolin Wang, Dawei Yin|Wuhan University, China; City University of Hong Kong, Hong Kong; Baidu Inc., China|Improving user retention with reinforcement learning~(RL) has attracted increasing attention due to its significant importance in boosting user engagement. However, training the RL policy from scratch without hurting users' experience is unavoidable due to the requirement of trial-and-error searches. Furthermore, the offline methods, which aim to optimize the policy without online interactions, suffer from the notorious stability problem in value estimation or unbounded variance in counterfactual policy evaluation. To this end, we propose optimizing user retention with Decision Transformer~(DT), which avoids the offline difficulty by translating the RL as an autoregressive problem. However, deploying the DT in recommendation is a non-trivial problem because of the following challenges: (1) deficiency in modeling the numerical reward value; (2) data discrepancy between the policy learning and recommendation generation; (3) unreliable offline performance evaluation. In this work, we, therefore, contribute a series of strategies for tackling the exposed issues. We first articulate an efficient reward prompt by weighted aggregation of meta embeddings for informative reward embedding. Then, we endow a weighted contrastive learning method to solve the discrepancy between training and inference. Furthermore, we design two robust offline metrics to measure user retention. Finally, the significant improvement in the benchmark datasets demonstrates the superiority of the proposed method.|使用强化学习 ~ (RL)提高用户保持率已经引起了越来越多的关注，因为它在提高用户参与度方面具有重要意义。然而，由于试错检索的要求，在不损害用户体验的情况下从头开始训练 RL 策略是不可避免的。此外，离线方法的目的是优化政策没有在线交互，受到臭名昭著的稳定性问题的价值估计或无界方差的反事实政策评估。为此，我们提出了利用决策转换器 ~ (DT)来优化用户保留，通过将 RL 转换为一个自回归问题来避免离线困难。然而，在推荐中部署 DT 是一个非常重要的问题，因为它面临以下挑战: (1)数值奖励值建模不足; (2)策略学习和推荐生成之间的数据差异; (3)不可靠的离线性能评估。在这项工作中，我们，因此，贡献了一系列的战略，以解决暴露的问题。我们首先通过元嵌入的加权聚合提出了一个有效的信息嵌入奖励提示。然后，我们提出了一种加权对比学习方法来解决训练和推理之间的差异。此外，我们还设计了两个健壮的离线度量来衡量用户保持率。最后，基准数据集的显著改进证明了该方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Retention-oriented+Recommendation+with+Decision+Transformer)|0|
|[Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations](https://doi.org/10.1145/3543507.3583495)|Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu|Peking University, China; University of Chinese Academy of Sciences, China; Beijing Technology and Business University, China; University of California, San Diego, USA|Recommender systems are seen as an effective tool to address information overload, but it is widely known that the presence of various biases makes direct training on large-scale observational data result in sub-optimal prediction performance. In contrast, unbiased ratings obtained from randomized controlled trials or A/B tests are considered to be the golden standard, but are costly and small in scale in reality. To exploit both types of data, recent works proposed to use unbiased ratings to correct the parameters of the propensity or imputation models trained on the biased dataset. However, the existing methods fail to obtain accurate predictions in the presence of unobserved confounding or model misspecification. In this paper, we propose a theoretically guaranteed model-agnostic balancing approach that can be applied to any existing debiasing method with the aim of combating unobserved confounding and model misspecification. The proposed approach makes full use of unbiased data by alternatively correcting model parameters learned with biased data, and adaptively learning balance coefficients of biased samples for further debiasing. Extensive real-world experiments are conducted along with the deployment of our proposal on four representative debiasing methods to demonstrate the effectiveness.|推荐系统被视为解决信息超载问题的有效工具，但众所周知，各种偏差的存在使得对大规模观测数据的直接训练导致次优预测性能。相比之下，通过随机对照试验或 A/B 测试获得的无偏评分被认为是黄金标准，但实际上成本高，规模小。为了利用这两种类型的数据，最近的工作建议使用无偏评级来修正倾向或插补模型的参数训练偏向的数据集。然而，现有的方法不能获得准确的预测存在未观察到的混杂或模型错误说明。本文提出了一种理论保证的模型无关平衡方法，该方法可以应用于任何现有的去偏方法，以消除未观察到的混淆和模型不确定性。该方法充分利用无偏数据，通过交替校正有偏数据学习的模型参数，以及有偏样本的自适应学习平衡系数进一步消除偏差。随着我们的建议在四个有代表性的去偏方法上的部署，广泛的现实世界的实验被进行，以证明有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Unobserved+Confounding+with+a+Few+Unbiased+Ratings+in+Debiased+Recommendations)|0|
|[Denoising and Prompt-Tuning for Multi-Behavior Recommendation](https://doi.org/10.1145/3543507.3583513)|Chi Zhang, Rui Chen, Xiangyu Zhao, Qilong Han, Li Li|Harbin Engineering University, China; City University of Hong Kong, Hong Kong; University of Delaware, USA|In practical recommendation scenarios, users often interact with items under multi-typed behaviors (e.g., click, add-to-cart, and purchase). Traditional collaborative filtering techniques typically assume that users only have a single type of behavior with items, making it insufficient to utilize complex collaborative signals to learn informative representations and infer actual user preferences. Consequently, some pioneer studies explore modeling multi-behavior heterogeneity to learn better representations and boost the performance of recommendations for a target behavior. However, a large number of auxiliary behaviors (i.e., click and add-to-cart) could introduce irrelevant information to recommenders, which could mislead the target behavior (i.e., purchase) recommendation, rendering two critical challenges: (i) denoising auxiliary behaviors and (ii) bridging the semantic gap between auxiliary and target behaviors. Motivated by the above observation, we propose a novel framework-Denoising and Prompt-Tuning (DPT) with a three-stage learning paradigm to solve the aforementioned challenges. In particular, DPT is equipped with a pattern-enhanced graph encoder in the first stage to learn complex patterns as prior knowledge in a data-driven manner to guide learning informative representation and pinpointing reliable noise for subsequent stages. Accordingly, we adopt different lightweight tuning approaches with effectiveness and efficiency in the following stages to further attenuate the influence of noise and alleviate the semantic gap among multi-typed behaviors. Extensive experiments on two real-world datasets demonstrate the superiority of DPT over a wide range of state-of-the-art methods. The implementation code is available online at https://github.com/zc-97/DPT.|在实际的推荐场景中，用户经常在多类型行为下与项目交互(例如，单击、添加到购物车和购买)。传统的协同过滤技术通常假设用户只有单一类型的行为与项目，使其不足以利用复杂的协作信号来学习信息表示和推断实际的用户偏好。因此，一些先驱研究探索建立多行为异质性模型，以学习更好的表示方法，并提高针对目标行为的建议的性能。然而，大量的辅助行为(即点击和添加到购物车)可能会向推荐者引入不相关的信息，这可能会误导目标行为(即购买)推荐，造成两个关键的挑战: (i)去噪辅助行为和(ii)桥接辅助行为和目标行为之间的语义差距。基于上述观察，我们提出了一个新的框架-去噪和及时调整(DPT)与三个阶段的学习范式，以解决上述挑战。特别是，DPT 在第一阶段配备了模式增强图形编码器，以数据驱动的方式学习复杂的模式作为先验知识，以指导学习信息表示和确定后续阶段的可靠噪声。相应地，我们在接下来的阶段采用了不同的轻量化方法，以进一步减小噪声的影响，缓解多类型行为之间的语义鸿沟。在两个实际数据集上的大量实验证明了 DPT 相对于一系列最先进的方法的优越性。实施守则可于网上 https://github.com/zc-97/dpt 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Denoising+and+Prompt-Tuning+for+Multi-Behavior+Recommendation)|0|
|[CAMUS: Attribute-Aware Counterfactual Augmentation for Minority Users in Recommendation](https://doi.org/10.1145/3543507.3583538)|Yuxin Ying, Fuzhen Zhuang, Yongchun Zhu, Deqing Wang, Hongwei Zheng|Institute of Artificial Intelligence, Beihang University, China; Beijing Academy of Blockchain and Edge Computing, China; Institute of Computing Technology, Chinese Academy of Sciences, China; School of Computer Science and Engineering, Beihang University, China|Embedding-based methods currently achieved impressive success in recommender systems. However, such methods are more likely to suffer from bias in data distribution, especially the attribute bias problem. For example, when a certain type of user, like the elderly, occupies the mainstream, the recommendation results of minority users would be seriously affected by the mainstream users’ attributes. To address this problem, most existing methods are proposed from the perspective of fairness, which focuses on eliminating unfairness but deteriorates the recommendation performance. Unlike these methods, in this paper, we focus on improving the recommendation performance for minority users of biased attributes. Along this line, we propose a novel attribute-aware Counterfactual Augmentation framework for Minority Users(CAMUS). Specifically, the CAMUS consists of a counterfactual augmenter, a confidence estimator, and a recommender. The counterfactual augmenter conducts data augmentation for the minority group by utilizing the interactions of mainstream users based on a universal counterfactual assumption. Besides, a tri-training-based confidence estimator is applied to ensure the effectiveness of augmentation. Extensive experiments on three real-world datasets have demonstrated the superior performance of the proposed methods. Further case studies verify the universality of the proposed CAMUS framework on different data sparsity, attributes, and models.|基于嵌入的方法目前在推荐系统中取得了令人印象深刻的成功。然而，这些方法更容易受到数据分布偏差的影响，特别是属性偏差问题。例如，当某种类型的用户，如老年人，占据主流时，少数用户的推荐结果会受到主流用户属性的严重影响。为了解决这个问题，现有的方法大多是从公平的角度出发，着重于消除不公平性，但是会降低推荐性能。与这些方法不同的是，本文主要研究如何提高偏向属性的少数用户的推荐性能。在此基础上，我们提出了一种新的面向少数用户的属性感知反事实增强框架(CAMUS)。具体来说，CAMUS 由一个反事实增强器、一个置信度估计器和一个推荐器组成。反事实增强器利用主流用户基于普遍反事实假设的交互作用对少数群体进行数据增强。此外，采用基于三训练的置信估计来保证增广的有效性。在三个实际数据集上的大量实验证明了该方法的优越性能。进一步的案例研究验证了所提出的 CAMUS 框架在不同的数据稀疏性、属性和模型上的通用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAMUS:+Attribute-Aware+Counterfactual+Augmentation+for+Minority+Users+in+Recommendation)|0|
|[Dynamically Expandable Graph Convolution for Streaming Recommendation](https://doi.org/10.1145/3543507.3583237)|Bowei He, Xu He, Yingxue Zhang, Ruiming Tang, Chen Ma|Huawei Noah's Ark Lab, China; City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; Huawei Noah's Ark Lab Montreal, Canada|Personalized recommender systems have been widely studied and deployed to reduce information overload and satisfy users' diverse needs. However, conventional recommendation models solely conduct a one-time training-test fashion and can hardly adapt to evolving demands, considering user preference shifts and ever-increasing users and items in the real world. To tackle such challenges, the streaming recommendation is proposed and has attracted great attention recently. Among these, continual graph learning is widely regarded as a promising approach for the streaming recommendation by academia and industry. However, existing methods either rely on the historical data replay which is often not practical under increasingly strict data regulations, or can seldom solve the \textit{over-stability} issue. To overcome these difficulties, we propose a novel \textbf{D}ynamically \textbf{E}xpandable \textbf{G}raph \textbf{C}onvolution (DEGC) algorithm from a \textit{model isolation} perspective for the streaming recommendation which is orthogonal to previous methods. Based on the motivation of disentangling outdated short-term preferences from useful long-term preferences, we design a sequence of operations including graph convolution pruning, refining, and expanding to only preserve beneficial long-term preference-related parameters and extract fresh short-term preferences. Moreover, we model the temporal user preference, which is utilized as user embedding initialization, for better capturing the individual-level preference shifts. Extensive experiments on the three most representative GCN-based recommendation models and four industrial datasets demonstrate the effectiveness and robustness of our method.|个性化推荐系统已被广泛研究和部署，以减少信息超载和满足用户的不同需求。然而，考虑到用户偏好的变化以及现实世界中不断增加的用户和项目，传统的推荐模型只能进行一次性的训练测试，很难适应不断变化的需求。为了应对这些挑战，流媒体推荐被提出并引起了人们的广泛关注。其中，连续图学习被学术界和工业界广泛认为是一种很有前途的流推荐方法。然而，现有的方法要么依赖于历史数据的重放，这在日益严格的数据规则下往往是不切实际的，要么很少能解决文本的过稳定性问题。为了克服这些困难，我们从文本{模型隔离}的角度提出了一种新的动态 textbf { D }可扩展 textbf { E } Raph textbf { C }内卷(DEGC)算法用于流式推荐，该算法与以前的方法是正交的。基于将过时的短期偏好与有用的长期偏好分离的动机，我们设计了一系列操作，包括图卷积修剪，细化和扩展，以仅保留有益的长期偏好相关参数并提取新的短期偏好。此外，为了更好地捕获个体层次的偏好变化，我们建立了时态用户偏好模型，并将其用于用户嵌入初始化。在三个最具代表性的基于 GCN 的推荐模型和四个工业数据集上的大量实验证明了该方法的有效性和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamically+Expandable+Graph+Convolution+for+Streaming+Recommendation)|0|
|[CTRLStruct: Dialogue Structure Learning for Open-Domain Response Generation](https://doi.org/10.1145/3543507.3583285)|Congchi Yin, Piji Li, Zhaochun Ren|Shandong University, China; Nanjing University of Aeronautics and Astronautics, China|Dialogue structure discovery is essential in dialogue generation. Well-structured topic flow can leverage background information and predict future topics to help generate controllable and explainable responses. However, most previous work focused on dialogue structure learning in task-oriented dialogue other than open-domain dialogue which is more complicated and challenging. In this paper, we present a new framework CTRLStruct for dialogue structure learning to effectively explore topic-level dialogue clusters as well as their transitions with unlabelled information. Precisely, dialogue utterances encoded by bi-directional Transformer are further trained through a special designed contrastive learning task to improve representation. Then we perform clustering to utterance-level representations and form topic-level clusters that can be considered as vertices in dialogue structure graph. The edges in the graph indicating transition probability between vertices are calculated by mimicking expert behavior in datasets. Finally, dialogue structure graph is integrated into dialogue model to perform controlled response generation. Experiments on two popular open-domain dialogue datasets show our model can generate more coherent responses compared to some excellent dialogue models, as well as outperform some typical sentence embedding methods in dialogue utterance representation. Code is available in GitHub.|对话结构的发现是对话生成的基础。结构良好的主题流可以利用背景信息并预测未来的主题，从而帮助产生可控的和可解释的反应。然而，以往的研究大多侧重于面向任务的对话中的对话结构学习，而开放领域的对话更为复杂和具有挑战性。本文提出了一种新的对话结构学习框架 CTRLstruct，以有效地探索话题层次的对话群及其与未标记信息的过渡。准确地说，双向变压器编码的对话话语通过特别设计的对比学习任务进一步训练，以提高表征能力。然后对话语层面的表征进行聚类，形成话题层面的聚类，这些聚类可以看作是对话结构图中的顶点。通过模拟数据集中的专家行为，计算图中表示顶点间转移概率的边。最后，将对话结构图集成到对话模型中进行受控响应的生成。实验结果表明，与一些优秀的对话模型相比，该模型能够产生更加连贯的对话响应，并且在对话话语表征中优于一些典型的句子嵌入方法。代码可在 GitHub 中获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CTRLStruct:+Dialogue+Structure+Learning+for+Open-Domain+Response+Generation)|0|
|[BlinkViz: Fast and Scalable Approximate Visualization on Very Large Datasets using Neural-Enhanced Mixed Sum-Product Networks](https://doi.org/10.1145/3543507.3583411)|Yimeng Qiao, Yinan Jing, Hanbing Zhang, Zhenying He, Kai Zhang, X. Sean Wang|Shanghai Key Laboratory of Data Science, School of Software, Fudan University, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, China|Web-based online interactive visual analytics enjoys popularity in recent years. Traditionally, visualizations are produced directly from querying the underlying data. However, for a very large dataset, this way is so time-consuming that it cannot meet the low-latency requirements of interactive visual analytics. In this paper, we propose a learning-based visualization approach called BlinkViz, which uses a learned model to produce approximate visualizations by leveraging mixed sum-product networks to learn the distribution of the original data. In such a way, it makes visualization faster and more scalable by decoupling visualization and data. In addition, to improve the accuracy of approximate visualizations, we propose an enhanced model by incorporating a neural network with residual structures, which can refine prediction results, especially for visual requests with low selectivity. Extensive experiments show that BlinkViz is extremely fast even on a large dataset with hundreds of millions of data records (over 30GB), responding in sub-seconds (from 2ms to less than 500ms for different requests) while keeping a low error rate. Furthermore, our approach remains scalable on latency and memory footprint size regardless of data size.|基于 Web 的在线交互式可视化分析近年来很受欢迎。传统上，可视化是通过查询底层数据直接生成的。然而，对于一个非常大的数据集，这种方法非常耗时，不能满足交互式可视化分析的低延迟要求。本文提出了一种基于学习的可视化方法 BlinkViz，该方法利用学习模型，通过混合和积网络来学习原始数据的分布情况，从而产生近似可视化效果。通过这种方式，可视化和数据解耦，使得可视化更快、更具可伸缩性。此外，为了提高近似可视化的准确性，我们提出了一个增强的模型，通过结合残差结构的神经网络，可以细化预测结果，特别是对低选择性的可视化请求。大量的实验表明，BlinkViz 即使在拥有数亿条数据记录(超过30GB)的大型数据集上也是极其快速的，响应时间在亚秒(对于不同的请求，响应时间从2毫秒到不到500毫秒) ，同时保持较低的错误率。此外，无论数据大小如何，我们的方法在延迟和内存占用大小上都是可伸缩的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BlinkViz:+Fast+and+Scalable+Approximate+Visualization+on+Very+Large+Datasets+using+Neural-Enhanced+Mixed+Sum-Product+Networks)|0|
|[Semi-supervised Adversarial Learning for Complementary Item Recommendation](https://doi.org/10.1145/3543507.3583462)|Koby Bibas, Oren Sar Shalom, Dietmar Jannach|Amazon, Israel; Meta, Israel; University of Klagenfurt, Austria|Complementary item recommendations are a ubiquitous feature of modern e-commerce sites. Such recommendations are highly effective when they are based on collaborative signals like co-purchase statistics. In certain online marketplaces, however, e.g., on online auction sites, constantly new items are added to the catalog. In such cases, complementary item recommendations are often based on item side-information due to a lack of interaction data. In this work, we propose a novel approach that can leverage both item side-information and labeled complementary item pairs to generate effective complementary recommendations for cold items, i.e., for items for which no co-purchase statistics yet exist. Given that complementary items typically have to be of a different category than the seed item, we technically maintain a latent space for each item category. Simultaneously, we learn to project distributed item representations into these category spaces to determine suitable recommendations. The main learning process in our architecture utilizes labeled pairs of complementary items. In addition, we adopt ideas from Cycle Generative Adversarial Networks (CycleGAN) to leverage available item information even in case no labeled data exists for a given item and category. Experiments on three e-commerce datasets show that our method is highly effective.|互补商品推荐是现代电子商务网站的一个普遍特征。当这些建议基于合作信号(如共同购买统计数据)时，它们是非常有效的。然而，在某些在线市场，例如在线拍卖网站，不断有新物品被添加到目录中。在这种情况下，由于缺乏交互数据，补充项目推荐通常基于项目侧信息。在这项工作中，我们提出了一个新颖的方法，可以利用项目侧信息和标记的互补项目对，以产生有效的补充建议，冷的项目，即项目，共同购买统计数据尚不存在。鉴于补充项目通常必须是一个与种子项目不同的类别，我们在技术上为每个项目类别保持一个潜在的空间。同时，我们学习将分布式项表示投射到这些类别空间中，以确定合适的建议。在我们的建筑中，主要的学习过程是使用标记成对的互补项目。此外，我们采用循环生成对抗网络(CycleGAN)的思想来利用可用的项目信息，即使在给定的项目和类别没有标记数据存在的情况下。在三个电子商务数据集上的实验表明，该方法是高效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-supervised+Adversarial+Learning+for+Complementary+Item+Recommendation)|0|
|[MaSS: Model-agnostic, Semantic and Stealthy Data Poisoning Attack on Knowledge Graph Embedding](https://doi.org/10.1145/3543507.3583203)|Xiaoyu You, Beina Sheng, Daizong Ding, Mi Zhang, Xudong Pan, Min Yang, Fuli Feng|Fudan University, School of Computer Science, China; University of Science and Technology of China, CCCD Key Lab of Ministry of Culture and Tourism, China|Open-source knowledge graphs are attracting increasing attention. Nevertheless, the openness also raises the concern of data poisoning attacks, that is, the attacker could submit malicious facts to bias the prediction of knowledge graph embedding (KGE) models. Existing studies on such attacks adopt a clear-box setting and neglect the semantic information of the generated facts, making them fail to attack in real-world scenarios. In this work, we consider a more rigorous setting and propose a model-agnostic, semantic, and stealthy data poisoning attack on KGE models from a practical perspective. The main design of our work is to inject indicative paths to make the infected model predict certain malicious facts. With the aid of the proposed opaque-box path injection theory, we theoretically reveal that the attack success rate under the opaque-box setting is determined by the plausibility of triplets on the indicative path. Based on this, we develop a novel and efficient algorithm to search paths that maximize the attack goal, satisfy certain semantic constraints, and preserve certain stealthiness, i.e., the normal functionality of the target KGE will not be influenced although it predicts wrong facts given certain queries. Through extensive evaluation of benchmark datasets and 6 typical knowledge graph embedding models as the victims, we validate the effectiveness in terms of attack success rate (ASR) under opaque-box setting and stealthiness. For example, on FB15k-237, our attack achieves a ASR on DeepPath, with an average ASR over when attacking various KGE models under the opaque-box setting.|开源知识图表越来越受到人们的关注。然而，这种开放性也引起了人们对数据中毒攻击的担忧，即攻击者可能会提交恶意事实来偏向知识图嵌入(KGE)模型的预测。现有的关于此类攻击的研究采用了清晰框设置，忽视了所生成事实的语义信息，使得它们无法在现实世界中进行攻击。在这项工作中，我们考虑了一个更严格的设置，并提出了一个模型无关，语义，隐秘的数据中毒攻击的 KGE 模型从实用的角度。我们工作的主要设计是注入指示性路径，使被感染的模型能够预测某些恶意事实。借助所提出的不透明盒路径注入理论，我们从理论上揭示了在不透明盒设置下的攻击成功率取决于指示路径上三联体的合理性。在此基础上，提出了一种新的高效的路径搜索算法，该算法能够使攻击目标最大化，满足一定的语义约束，并保持一定的隐蔽性。通过对基准数据集和6种典型的知识图嵌入模型作为受害者的广泛评估，验证了在不透明框设置和隐蔽性条件下的攻击成功率(ASR)的有效性。例如，在 FB15k-237上，我们的攻击在 DeepPath 上达到 ASR，在不透明盒子设置下攻击各种 KGE 模型时达到平均 ASR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MaSS:+Model-agnostic,+Semantic+and+Stealthy+Data+Poisoning+Attack+on+Knowledge+Graph+Embedding)|0|
|[TaxoComplete: Self-Supervised Taxonomy Completion Leveraging Position-Enhanced Semantic Matching](https://doi.org/10.1145/3543507.3583342)|Ines Arous, Ljiljana Dolamic, Philippe CudréMauroux|University of Fribourg, Switzerland; armasuisse, Switzerland|Taxonomies are used to organize knowledge in many applications, including recommender systems, content browsing, or web search. With the emergence of new concepts, static taxonomies become obsolete as they fail to capture up-to-date knowledge. Several approaches have been proposed to address the problem of maintaining taxonomies automatically. These approaches typically rely on a limited set of neighbors to represent a given node in the taxonomy. However, considering distant nodes could improve the representation of some portions of the taxonomy, especially for those nodes situated in the periphery or in sparse regions of the taxonomy. In this work, we propose TaxoComplete, a self-supervised taxonomy completion framework that learns the representation of nodes leveraging their position in the taxonomy. TaxoComplete uses a self-supervision generation process that selects some nodes and associates each of them with an anchor set, which is a set composed of nodes in the close and distant neighborhood of the selected node. Using self-supervision data, TaxoComplete learns a position-enhanced node representation using two components: (1) a query-anchor semantic matching mechanism, which encodes pairs of nodes and matches their semantic distance to their graph distance, such that nodes that are close in the taxonomy are placed closely in the shared embedding space while distant nodes are placed further apart; (2) a direction-aware propagation module, which embeds the direction of edges in node representation, such that we discriminate <node, parent> relation from other taxonomic relations. Our approach allows the representation of nodes to encapsulate information from a large neighborhood while being aware of the distance separating pairs of nodes in the taxonomy. Extensive experiments on four real-world and large-scale datasets show that TaxoComplete is substantially more effective than state-of-the-art methods (2x more effective in terms of [email protected] ).|分类法用于在许多应用程序中组织知识，包括推荐系统、内容浏览或网络搜索。随着新概念的出现，静态分类法变得过时，因为它们无法捕获最新的知识。已经提出了几种方法来解决自动维护分类法的问题。这些方法通常依赖于一组有限的邻居来表示分类法中的给定节点。然而，考虑远处的节点可以改善分类学的某些部分的表示，特别是对于那些位于分类学的边缘或稀疏区域的节点。在这项工作中，我们提出了 TaxoComplete，一个自我监督的分类完成框架，它学习利用节点在分类中的位置来表示节点。TaxoComplete 使用一个自我监督的生成过程，它选择一些节点，并将它们与锚集相关联，锚集是由所选节点的近邻和远邻的节点组成的集合。TaxoComplete 利用自我监督数据学习位置增强的节点表示，它使用两个组件: (1)查询锚语义匹配机制，对节点对进行编码，并将它们的语义距离匹配到它们的图形距离上，这样在分类学中相近的节点被紧密地放置在共享嵌入空间中，而远处的节点被放置得更远; (2)方向感知传播模块，这种模块在节点表示中嵌入边的方向，这样我们可以区分 < 节点，父节点 > 关系和其他分类关系。我们的方法允许节点的表示来封装来自大邻居的信息，同时知道分类法中节点对之间的距离。在四个真实世界和大规模数据集上的大量实验表明，TaxoComplete 实质上比最先进的方法更有效(在[ email protected ]方面效率高出2倍)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TaxoComplete:+Self-Supervised+Taxonomy+Completion+Leveraging+Position-Enhanced+Semantic+Matching)|0|
|[Bipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space](https://doi.org/10.1145/3543507.3583219)|Yankai Chen, Yixiang Fang, Yifei Zhang, Irwin King|The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Shenzhen, China|Searching on bipartite graphs is basal and versatile to many real-world Web applications, e.g., online recommendation, database retrieval, and query-document searching. Given a query node, the conventional approaches rely on the similarity matching with the vectorized node embeddings in the continuous Euclidean space. To efficiently manage intensive similarity computation, developing hashing techniques for graph structured data has recently become an emerging research direction. Despite the retrieval efficiency in Hamming space, prior work is however confronted with catastrophic performance decay. In this work, we investigate the problem of hashing with Graph Convolutional Network on bipartite graphs for effective Top-N search. We propose an end-to-end Bipartite Graph Convolutional Hashing approach, namely BGCH, which consists of three novel and effective modules: (1) adaptive graph convolutional hashing, (2) latent feature dispersion, and (3) Fourier serialized gradient estimation. Specifically, the former two modules achieve the substantial retention of the structural information against the inevitable information loss in hash encoding; the last module develops Fourier Series decomposition to the hashing function in the frequency domain mainly for more accurate gradient estimation. The extensive experiments on six real-world datasets not only show the performance superiority over the competing hashing-based counterparts, but also demonstrate the effectiveness of all proposed model components contained therein.|对于许多实际的 Web 应用程序，如在线推荐、数据库检索和查询文档搜索，二部图搜索是基础的和通用的。给定一个查询节点，传统的方法依赖于与连续欧氏空间中向量化节点嵌入的相似性匹配。为了有效地管理密集型相似度计算，开发图结构化数据的哈希技术已成为一个新兴的研究方向。尽管在汉明空间中反演效率很高，但是先前的工作却面临着灾难性的性能衰减。在本文中，我们研究了用图卷积网络对二部图进行散列以获得有效的 Top-N 搜索的问题。提出了一种端到端的二部图卷积哈希方法，即 BGCH，它由三个新颖有效的模块组成: (1)自适应图卷积哈希，(2)潜在特征分散，(3)傅里叶序列化梯度估计。具体来说，前两个模块针对哈希编码中不可避免的信息损失实现了结构信息的实质性保留，最后一个模块对频域中的哈希函数进行了傅里叶级数分解，以便更准确地进行梯度估计。在六个实际数据集上进行的大量实验不仅表明了该模型的性能优于竞争对手的散列模型，而且证明了其中所有模型组件的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bipartite+Graph+Convolutional+Hashing+for+Effective+and+Efficient+Top-N+Search+in+Hamming+Space)|0|
|[LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval](https://doi.org/10.1145/3543507.3583294)|Kai Zhang, Chongyang Tao, Tao Shen, Can Xu, Xiubo Geng, Binxing Jiao, Daxin Jiang|University of Technology Sydney, Australia; Microsoft, China; The Ohio State University, USA|Retrieval models based on dense representations in semantic space have become an indispensable branch for first-stage retrieval. These retrievers benefit from surging advances in representation learning towards compressive global sequence-level embeddings. However, they are prone to overlook local salient phrases and entity mentions in texts, which usually play pivot roles in first-stage retrieval. To mitigate this weakness, we propose to make a dense retriever align a well-performing lexicon-aware representation model. The alignment is achieved by weakened knowledge distillations to enlighten the retriever via two aspects -- 1) a lexicon-augmented contrastive objective to challenge the dense encoder and 2) a pair-wise rank-consistent regularization to make dense model's behavior incline to the other. We evaluate our model on three public benchmarks, which shows that with a comparable lexicon-aware retriever as the teacher, our proposed dense one can bring consistent and significant improvements, and even outdo its teacher. In addition, we found our improvement on the dense retriever is complementary to the standard ranker distillation, which can further lift state-of-the-art performance.|基于语义空间密集表示的检索模型已经成为第一阶段检索不可或缺的分支。这些检索器受益于表示学习向压缩全局序列级嵌入方向的飞速发展。然而，它们往往忽视文本中的局部显著短语和实体提及，而这些短语和实体提及在第一阶段的检索中起着关键作用。为了减轻这个弱点，我们建议使一个密集检索对齐一个良好的表现词典感知表示模型。该方法通过弱化知识提取，从两个方面启发检索者: 1)词典增强对比目标，挑战密集编码器; 2)成对秩一致正则化，使密集模型的行为倾向于另一方。我们在三个公共基准上评估了我们的模型，结果表明，与一个具有可比性的词汇感知检索器作为教师，我们提出的密集型可以带来一致和重大的改进，甚至超过它的老师。此外，我们发现我们对稠密检索器的改进是对标准等级精馏的补充，它可以进一步提高最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LED:+Lexicon-Enlightened+Dense+Retriever+for+Large-Scale+Retrieval)|0|
|[A Passage-Level Reading Behavior Model for Mobile Search](https://doi.org/10.1145/3543507.3583343)|Zhijing Wu, Jiaxin Mao, Kedi Xu, Dandan Song, Heyan Huang|School of Computer Science, Carnegie Mellon University, USA; Gaoling School of Artificial Intelligence, Renmin University of China, China; School of Computer Science and Technology, Beijing Institute of Technology, China|Reading is a vital and complex cognitive activity during users’ information-seeking process. Several studies have focused on understanding users’ reading behavior in desktop search. Their findings greatly contribute to the design of information retrieval models. However, little is known about how users read a result in mobile search, although search currently happens more frequently in mobile scenarios. In this paper, we conduct a lab-based user study to investigate users’ fine-grained reading behavior patterns in mobile search. We find that users’ reading attention allocation is strongly affected by several behavior biases, such as position and selection biases. Inspired by these findings, we propose a probabilistic generative model, the Passage-level Reading behavior Model (PRM), to model users’ reading behavior in mobile search. The PRM utilizes observable passage-level exposure and viewport duration events to infer users’ unobserved skimming event, reading event, and satisfaction perception during the reading process. Besides fitting the passage-level reading behavior, we utilize the fitted parameters of PRM to estimate the passage-level and document-level relevance. Experimental results show that PRM outperforms existing unsupervised relevance estimation models. PRM has strong interpretability and provides valuable insights into the understanding of how users seek and perceive useful information in mobile search.|阅读是用户信息搜索过程中一种重要而复杂的认知活动。一些研究集中在了解用户在桌面搜索中的阅读行为。他们的发现极大地促进了信息检索模型的设计。然而，尽管目前搜索在移动场景中出现的频率更高，但人们对用户在移动搜索中如何阅读结果知之甚少。本文以实验室为基础，对移动搜索中用户的细粒度阅读行为模式进行了研究。研究发现，位置偏差、选择偏差等行为偏差对用户的阅读注意分配有显著影响。受这些发现的启发，我们提出了一个概率生成模型——短文水平阅读行为模型(PRM) ，来模拟用户在移动搜索中的阅读行为。PRM 利用可观察到的文章水平暴露和视窗持续时间事件来推断用户在阅读过程中未观察到的略读事件、阅读事件和满意度感知。除了拟合文章阅读行为外，我们还利用 PRM 的拟合参数来估计文章阅读水平和文档阅读水平的相关性。实验结果表明，PRM 算法的性能优于现有的无监督相关估计模型。PRM 具有很强的可解释性，为理解用户在移动搜索中如何寻找和感知有用信息提供了有价值的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Passage-Level+Reading+Behavior+Model+for+Mobile+Search)|0|
|[PROD: Progressive Distillation for Dense Retrieval](https://doi.org/10.1145/3543507.3583421)|Zhenghao Lin, Yeyun Gong, Xiao Liu, Hang Zhang, Chen Lin, Anlei Dong, Jian Jiao, Jingwen Lu, Daxin Jiang, Rangan Majumder, Nan Duan|School of Informatics, Xiamen University, China; Microsoft, China; Microsoft Research Asia, China; Microsoft, USA|Knowledge distillation is an effective way to transfer knowledge from a strong teacher to an efficient student model. Ideally, we expect the better the teacher is, the better the student. However, this expectation does not always come true. It is common that a better teacher model results in a bad student via distillation due to the nonnegligible gap between teacher and student. To bridge the gap, we propose PROD, a PROgressive Distillation method, for dense retrieval. PROD consists of a teacher progressive distillation and a data progressive distillation to gradually improve the student. We conduct extensive experiments on five widely-used benchmarks, MS MARCO Passage, TREC Passage 19, TREC Document 19, MS MARCO Document and Natural Questions, where PROD achieves the state-of-the-art within the distillation methods for dense retrieval. The code and models will be released.|知识提取是将知识从一个强有力的教师转化为一个有效的学生模型的有效途径。理想情况下，我们期望老师越好，学生越好。然而，这种期望并不总是能够实现。由于教师与学生之间存在着不可忽视的差距，一个较好的教师模型常常通过精馏的方法导致不好的学生。为了填补这一空白，我们提出了一种逐步精馏方法 PROD，用于密集提取。PROD 由一个教师的逐步升华和一个数据的逐步升华组成，以逐步提高学生的素质。我们对五个广泛使用的基准进行了广泛的实验，即 MS MARCO Passage，TREC Passage 19，TREC Document 19，MS MARCO Document and Natural Questions，PROD 在这些基准上实现了用于密集检索的蒸馏方法的最先进水平。代码和模型将被发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PROD:+Progressive+Distillation+for+Dense+Retrieval)|0|
|[Ad Auction Design with Coupon-Dependent Conversion Rate in the Auto-bidding World](https://doi.org/10.1145/3543507.3583230)|Bonan Ni, Xun Wang, Qi Zhang, Pingzhong Tang, Zhourong Chen, Tianjiu Yin, Liangni Lu, Xiaobing Liu, Kewu Sun, Zhe Ma|TuringSense, China and Institute for Interdisciplinary Information Sciences, Tsinghua University, China; ByteDance, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, China; Intelligent Science & Technology Academy of CASIC, China and Scientific Research Key Laboratory of Aerospace Defence Intelligent Systems and Technology, China|Online advertising has become a dominant source of revenue of the Internet. In classic auction theory, only the auctioneer (i.e., the platform) and buyers (i.e., the advertisers) are involved, while the advertising audiences are ignored. For ecommerce advertising, however, the platform can provide coupons for the advertising audiences and nudge them into purchasing more products at lower prices (e.g., 2 dollars off the regular price). Such promotions can lead to an increase in amount and value of purchases. In this paper, we jointly design the coupon value computation, slot allocation, and payment of online advertising in an auto-bidding world. Firstly, we propose the auction mechanism, named CFA-auction (i.e., Coupon-For-the-Audiences-auction), which takes advertising audiences into account in the auction design. We prove the existence of pacing equilibrium, and show that CFA-auction satisfies the IC (incentive compatibility), IR (individual rationality) constraints. Then, we study the optimality of CFA-auction, and prove it can maintain an approximation of the optimal. Finally, experimental evaluation results on both offline dataset as well as online A/B test demonstrate the effectiveness of CFA-auction.|在线广告已成为互联网收入的主要来源。在传统的拍卖理论中，只有拍卖商(即平台)和买家(即广告商)参与，而广告受众被忽略。然而，对于电子商务广告来说，这个平台可以为广告受众提供优惠券，推动他们以更低的价格购买更多的产品(例如，比正常价格低2美元)。此类促销活动可能导致购买数量和价值的增加。在这篇论文中，我们共同设计了自动竞价世界中的优惠券价值计算、时段分配和在线广告支付。首先，我们提出了一种拍卖机制，即 CFA 拍卖(即为受众提供优惠券的拍卖) ，该机制在拍卖设计中考虑了广告受众。我们证明了节奏均衡的存在，并且证明了 CFA 拍卖满足集成激励相容(IC)、个人理性(IR)约束。然后，我们研究了 CFA 拍卖的最优性，并证明了它可以保持最优的近似。最后，通过对离线数据集和在线 A/B 测试的实验结果验证了 CFA 拍卖的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ad+Auction+Design+with+Coupon-Dependent+Conversion+Rate+in+the+Auto-bidding+World)|0|
|[A Reference-Dependent Model for Web Search Evaluation: Understanding and Measuring the Experience of Boundedly Rational Users](https://doi.org/10.1145/3543507.3583551)|Nuo Chen, Jiqun Liu, Tetsuya Sakai|The University of Oklahoma, USA; Waseda University, Japan|Previous researches demonstrate that users’ actions in search interaction are associated with relative gains and losses to reference points, known as the reference dependence effect. However, this widely confirmed effect is not represented in most user models underpinning existing search evaluation metrics. In this study, we propose a new evaluation metric framework, namely Reference Dependent Metric (ReDeM), for assessing query-level search by incorporating the effect of reference dependence into the modelling of user search behavior. To test the overall effectiveness of the proposed framework, (1) we evaluate the performance, in terms of correlation with user satisfaction, of ReDeMs built upon different reference points against that of the widely-used metrics on three search datasets; (2) we examine the performance of ReDeMs under different task states, like task difficulty and task urgency; and (3) we analyze the statistical reliability of ReDeMs in terms of discriminative power. Experimental results indicate that: (1) ReDeMs integrated with a proper reference point achieve better correlations with user satisfaction than most of the existing metrics, like Discounted Cumulative Gain (DCG) and Rank-Biased Precision (RBP), even though their parameters have already been well-tuned; (2) ReDeMs reach relatively better performance compared to existing metrics when the task triggers a high-level cognitive load; (3) the discriminative power of ReDeMs is far stronger than Expected Reciprocal Rank (ERR), slightly stronger than Precision and similar to DCG, RBP and INST. To our knowledge, this study is the first to explicitly incorporate the reference dependence effect into the user browsing model and offline evaluation metrics. Our work illustrates a promising approach to leveraging the insights about user biases from cognitive psychology in better evaluating user search experience and enhancing user models.|以往的研究表明，用户在搜索交互中的行为与参考点的相对收益和相对损失有关，称为参考依赖效应。然而，这种被广泛证实的效果在大多数支持现有搜索评估指标的用户模型中并没有体现出来。在这项研究中，我们提出了一个新的评估度量框架，即参考依赖度量(ReDeM) ，通过将参考依赖的影响纳入用户搜索行为的建模来评估查询级搜索。为了测试提出的框架的整体有效性，(1)我们评估建立在不同参考点上的 ReDeM 与用户满意度的相关性，与三个搜索数据集上广泛使用的指标的相关性; (2)我们检查 ReDeM 在不同任务状态下的表现，如任务难度和任务紧迫性; (3)我们分析 ReDeM 在区分能力方面的统计可靠性。实验结果表明: (1)与合适的参考点相结合的 ReDeMs 与用户满意度的相关性优于大多数现有指标，如 DCG 和 RBP，尽管它们的参数已经得到了很好的调整; (2)当任务触发高水平的认知负荷时，与现有指标相比，ReDeMs 获得了相对更好的性能; (3) ReDeMs 的区分能力远远强于期望互惠秩序(ERR) ，略强于精度，类似于 DCG、 RBP 和 INST。据我们所知，这项研究是第一个明确地将参考依赖效应纳入用户浏览模型和离线评价指标。我们的工作说明了一种有前途的方法，利用认知心理学对用户偏见的洞察力，更好地评估用户搜索体验和增强用户模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Reference-Dependent+Model+for+Web+Search+Evaluation:+Understanding+and+Measuring+the+Experience+of+Boundedly+Rational+Users)|0|
|[Maximizing Submodular Functions for Recommendation in the Presence of Biases](https://doi.org/10.1145/3543507.3583195)|Anay Mehrotra, Nisheeth K. Vishnoi||Subset selection tasks, arise in recommendation systems and search engines and ask to select a subset of items that maximize the value for the user. The values of subsets often display diminishing returns, and hence, submodular functions have been used to model them. If the inputs defining the submodular function are known, then existing algorithms can be used. In many applications, however, inputs have been observed to have social biases that reduce the utility of the output subset. Hence, interventions to improve the utility are desired. Prior works focus on maximizing linear functions -- a special case of submodular functions -- and show that fairness constraint-based interventions can not only ensure proportional representation but also achieve near-optimal utility in the presence of biases. We study the maximization of a family of submodular functions that capture functions arising in the aforementioned applications. Our first result is that, unlike linear functions, constraint-based interventions cannot guarantee any constant fraction of the optimal utility for this family of submodular functions. Our second result is an algorithm for submodular maximization. The algorithm provably outputs subsets that have near-optimal utility for this family under mild assumptions and that proportionally represent items from each group. In empirical evaluation, with both synthetic and real-world data, we observe that this algorithm improves the utility of the output subset for this family of submodular functions over baselines.|子集选择任务，出现在推荐系统和搜索引擎，并要求选择一个子集的项目，最大限度地为用户的价值。子集的值经常显示报酬递减，因此，子模块函数被用来建模它们。如果定义子模函数的输入是已知的，那么可以使用现有的算法。然而，在许多应用中，输入已被观察到具有社会偏差，从而降低了输出子集的效用。因此，需要采取干预措施来改善效用。先前的研究集中在最大化线性函数(次模函数的一个特例) ，并且表明基于公平约束的干预不仅可以确保比例代表制，而且在存在偏差的情况下还可以实现接近最优的效用。我们研究了一类子模函数的最大化问题，这类子模函数捕获上述应用中出现的函数。我们的第一个结果是，与线性函数不同，基于约束的干预不能保证这个子模函数族的最优效用的任何常数部分。我们的第二个结果是一个次模最大化算法。该算法可证明输出的子集具有接近最优的效用为这个家庭在温和的假设和比例代表项目从每组。在实证评价中，我们观察到，无论是合成的还是真实的数据，这个算法都提高了这个子模函数族的输出子集在基线上的效用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Maximizing+Submodular+Functions+for+Recommendation+in+the+Presence+of+Biases)|0|
|[Facility Relocation Search For Good: When Facility Exposure Meets User Convenience](https://doi.org/10.1145/3543507.3583859)|Hui Luo, Zhifeng Bao, J. Shane Culpepper, Mingzhao Li, Yanchang Zhao|CSIRO, Australia; RMIT University, Australia|In this paper, we propose a novel facility relocation problem where facilities (and their services) are portable, which is a combinatorial search problem with many practical applications. Given a set of users, a set of existing facilities, and a set of potential sites, we decide which of the existing facilities to relocate to potential sites, such that two factors are satisfied: (1) facility exposure: facilities after relocation have balanced exposure, namely serving equivalent numbers of users; (2) user convenience: it is convenient for users to access the nearest facility, which provides services with shorter travel distance. This problem is motivated by applications such as dynamically redistributing vaccine resources to align supply with demand for different vaccination centers, and relocating the bike sharing sites daily to improve the transportation efficiency. We first prove that this problem is NP-hard, and then we propose two algorithms: a non-learning best response algorithm () and a reinforcement learning algorithm (). In particular, the best response algorithm finds a Nash equilibrium to balance the facility-related and the user-related goals. To avoid being confined to only one Nash equilibrium, as found in the method, we also propose the reinforcement learning algorithm for long-term benefits, where each facility is an agent and we determine whether a facility needs to be relocated or not. To verify the effectiveness of our methods, we adopt multiple metrics to evaluate not only our objective, but also several other facility exposure equity and user convenience metrics to understand the benefits after facility relocation. Finally, comprehensive experiments using real-world datasets provide insights into the effectiveness of the two algorithms in practice.|在本文中，我们提出了一个新的设施搬迁问题，其中设施(及其服务)是可移植的，这是一个组合搜索问题与许多实际应用。根据一组使用者、一组现有设施及一组可供选择的用地，我们会决定哪些现有设施须迁往可供选择的用地，以满足以下两个因素: (1)设施接触量: 迁移后的设施接触量均衡，即服务相等数目的使用者; (2)使用者方便: 使用者可方便地前往最近的设施，而该设施提供的服务距离较短。这个问题的动机是应用程序，如动态重新分配疫苗资源，以调整供应与不同的疫苗接种中心的需求，并重新安置自行车共享站点，以提高运输效率每天。我们首先证明了这个问题是 NP 难的，然后我们提出了两个算法: 非学习最佳响应算法()和强化学习算法()。特别是，最佳响应算法会找到一个平衡设施相关目标和用户相关目标的纳什均衡点。为了避免只局限于一个纳什均衡点，正如方法中所发现的那样，我们还提出了长期利益的强化学习算法，即每个设施都是一个代理人，我们决定是否需要重新安置一个设施。为了验证我们的方法的有效性，我们不仅采用了多个指标来评估我们的目标，而且还采用了其他一些设施暴露公平性和用户便利性指标来了解设施搬迁后的好处。最后，利用真实世界数据集进行综合实验，验证了这两种算法在实际应用中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Facility+Relocation+Search+For+Good:+When+Facility+Exposure+Meets+User+Convenience)|0|
|[Detecting and Limiting Negative User Experiences in Social Media Platforms](https://doi.org/10.1145/3543507.3583883)|Lluís Garcia Pueyo, Vinodh Kumar Sunkara, Prathyusha Senthil Kumar, Mohit Diwan, Qian Ge, Behrang Javaherian, Vasilis Verroios|Meta Platforms, Inc., USA|Item ranking is important to a social media platform’s success. The order in which posts, videos, messages, comments, ads, used products, notifications are presented to a user greatly affects the time spent on the platform, how often they visit it, how much they interact with each other, and the quantity and quality of the content they post. To this end, item ranking algorithms use models that predict the likelihood of different events, e.g., the user liking, sharing, commenting on a video, clicking/converting on an ad, or opening the platform’s app from a notification. Unfortunately, by solely relying on such event-prediction models, social media platforms tend to over optimize for short-term objectives and ignore the long-term effects. In this paper, we propose an approach that aims at improving item ranking long-term impact. The approach primarily relies on an ML model that predicts negative user experiences. The model utilizes all available UI events: the details of an action can reveal how positive or negative the user experience has been; for example, a user writing a lengthy report asking for a given video to be taken down, likely had a very negative experience. Furthermore, the model takes into account detected integrity (e.g., hostile speech or graphic violence) and quality (e.g., click or engagement bait) issues with the content. Note that those issues can be perceived very differently from different users. Therefore, developing a personalized model, where a prediction refers to a specific user for a specific piece of content at a specific point in time, is a fundamental design choice in our approach. Besides the personalized ML model, our approach consists of two more pieces: (a) the way the personalized model is integrated with an item ranking algorithm and (b) the metrics, methodology, and success criteria for the long term impact of detecting and limiting negative user experiences. Our evaluation process uses extensive A/B testing on the Facebook platform: we compare the impact of our approach in treatment groups against production control groups. The AB test results indicate a 5% to 50% reduction in hides, reports, and submitted feedback. Furthermore, we compare against a baseline that does not include some of the crucial elements of our approach: the comparison shows our approach has a 100x to 30x lower False Positive Ratio than a baseline. Lastly, we present the results from a large scale survey, where we observe a statistically significant improvement of 3 to 6 percent in users’ sentiment regarding content suffering from nudity, clickbait, false / misleading, witnessing-hate, and violence issues.|项目排名对社交媒体平台的成功至关重要。发布、视频、信息、评论、广告、二手产品、通知的顺序对用户在平台上花费的时间、访问频率、互动程度以及发布内容的数量和质量有很大影响。为此，项目排名算法使用模型来预测不同事件的可能性，例如，用户喜欢，分享，评论视频，点击/转换广告，或从通知中打开平台的应用程序。不幸的是，仅仅依靠这种事件预测模型，社交媒体平台往往会过度优化短期目标而忽视长期影响。在本文中，我们提出了一种方法，旨在提高项目排名的长期影响。这种方法主要依靠机器学习模型来预测负面的用户体验。该模型利用了所有可用的 UI 事件: 一个动作的细节可以揭示用户体验的积极或消极程度; 例如，一个用户写了一份长篇报告，要求删除一个给定的视频，很可能有一个非常消极的体验。此外，该模型还考虑了检测到的完整性(例如，敌意言论或暴力画面)和质量(例如，点击或参与诱饵)问题。请注意，这些问题可以从不同的用户看到非常不同。因此，开发个性化的模型，其中预测指的是在特定时间点的特定内容的特定用户，是我们方法中的一个基本设计选择。除了个性化机器学习模型，我们的方法还包括两个部分: (a)个性化模型与项目排序算法的整合方式; (b)检测和限制负面用户体验的长期影响的指标、方法和成功标准。我们的评估过程在 Facebook 平台上使用了广泛的 A/B 测试: 我们比较我们在治疗组和生产控制组中的方法的影响。AB 测试结果表明，皮革、报告和提交的反馈减少了5% 到50% 。此外，我们比较了不包括我们方法的一些关键要素的基线: 比较显示我们的方法比基线低100到30倍的错误阳性率。最后，我们展示了一项大规模调查的结果，我们观察到用户对于遭受裸露、点击诱饵、虚假/误导、目击仇恨和暴力问题的内容的情绪有3% 到6% 的统计显著改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+and+Limiting+Negative+User+Experiences+in+Social+Media+Platforms)|0|
|[On Detecting Policy-Related Political Ads: An Exploratory Analysis of Meta Ads in 2022 French Election](https://doi.org/10.1145/3543507.3583875)|Vera Sosnovik, Romaissa Kessi, Maximin Coavoux, Oana Goga|CNRS, France and LIG, Université Grenoble Alpes, Grenoble INP, France; CNRS, France and LIX, Inria, Ecole Polytechnique, Institut Polytechnique de Paris, France|Online political advertising has become the cornerstone of political campaigns. The budget spent solely on political advertising in the U.S. has increased by more than 100% from \$700 million during the 2017-2018 U.S. election cycle to \$1.6 billion during the 2020 U.S. presidential elections. Naturally, the capacity offered by online platforms to micro-target ads with political content has been worrying lawmakers, journalists, and online platforms, especially after the 2016 U.S. presidential election, where Cambridge Analytica has targeted voters with political ads congruent with their personality   To curb such risks, both online platforms and regulators (through the DSA act proposed by the European Commission) have agreed that researchers, journalists, and civil society need to be able to scrutinize the political ads running on large online platforms. Consequently, online platforms such as Meta and Google have implemented Ad Libraries that contain information about all political ads running on their platforms. This is the first step on a long path. Due to the volume of available data, it is impossible to go through these ads manually, and we now need automated methods and tools to assist in the scrutiny of political ads.   In this paper, we focus on political ads that are related to policy. Understanding which policies politicians or organizations promote and to whom is essential in determining dishonest representations. This paper proposes automated methods based on pre-trained models to classify ads in 14 main policy groups identified by the Comparative Agenda Project (CAP). We discuss several inherent challenges that arise. Finally, we analyze policy-related ads featured on Meta platforms during the 2022 French presidential elections period.|在线政治广告已经成为政治运动的基石。美国政治广告预算从2017-2018年美国大选期间的7亿美元增加到2020年美国总统大选期间的16亿美元，增幅超过100% 。自然，在线平台提供的针对政治内容的微观广告的能力一直令立法者、记者和在线平台感到担忧，尤其是在2016年美国总统大选之后，剑桥分析公司(Cambridge Analytica)针对选民的政治广告符合他们的个性。为了遏制这种风险，在线平台和监管机构(通过欧盟委员会提出的 DSA 法案)已经同意，研究人员、记者和公民社会需要能够审查在大型在线平台上运行的政治广告。因此，像 Meta 和 Google 这样的在线平台已经实现了广告库，其中包含了在其平台上运行的所有政治广告的信息。这是漫长道路上的第一步。由于可获得的数据量很大，手动浏览这些广告是不可能的，我们现在需要自动化的方法和工具来协助审查政治广告。本文主要研究与政策相关的政治广告。了解哪些政治家或组织提倡哪些政策，以及向谁提出这些政策，对于确定不诚实陈述至关重要。本文提出了一种基于预训练模型的广告自动分类方法，用于比较议程项目(CAP)确定的14个主要政策组的广告分类。我们将讨论出现的几个内在挑战。最后，我们分析了2022年法国总统大选期间 Meta 平台上的政策相关广告。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Detecting+Policy-Related+Political+Ads:+An+Exploratory+Analysis+of+Meta+Ads+in+2022+French+Election)|0|
|[A ML-based Approach for HTML-based Style Recommendation](https://doi.org/10.1145/3543873.3587300)|Ryan Aponte, Ryan A. Rossi, Shunan Guo, Jane Hoffswell, Nedim Lipka, Chang Xiao, Gromit YeukYin Chan, Eunyee Koh, Nesreen K. Ahmed|Adobe Research, USA; Intel Labs, USA; Adobe, USA; CMU, USA|Given a large corpus of HTML-based emails (or websites, posters, documents) collected from the web, how can we train a model capable of learning from such rich heterogeneous data for HTML-based style recommendation tasks such as recommending useful design styles or suggesting alternative HTML designs? To address this new learning task, we first decompose each HTML document in the corpus into a sequence of smaller HTML fragments where each fragment may consist of a set of HTML entities such as buttons, images, textual content (titles, paragraphs) and stylistic entities such as background-style, font-style, button-style, among others. From these HTML fragments, we then derive a single large heterogeneous hypergraph that captures the higher-order dependencies between HTML fragments and entities in such fragments, both within the same HTML document as well as across the HTML documents in the corpus. We then formulate this new HTML style recommendation task as a hypergraph representation learning problem and propose an approach to solve it. Our approach is able to learn effective low-dimensional representations of the higher-order fragments that consist of sets of heterogeneous entities as well as low-dimensional representations of the individual entities themselves. We demonstrate the effectiveness of the approach across several design style recommendation tasks. To the best of our knowledge, this work is the first to develop an ML-based model for the task of HTML-based email style recommendation.|鉴于从网上收集的大量基于 HTML 的电子邮件(或网站、海报、文档) ，我们如何才能培养一个模型，使其能够从这些丰富的异构数据中学习基于 HTML 的风格推荐任务，如推荐有用的设计风格或建议替代 HTML 设计？为了解决这个新的学习任务，我们首先将语料库中的每个 HTML 文档分解为一系列较小的 HTML 片段，其中每个片段可能包含一组 HTML 实体，如按钮、图像、文本内容(标题、段落)和风格实体，如背景风格、字体风格、按钮风格等。然后，从这些 HTML 片段中，我们得到一个单一的大型异构超图，它捕获这些片段中 HTML 片段和实体之间的高阶依赖关系，这些依赖关系既存在于同一 HTML 文档中，也存在于语料库中的 HTML 文档之间。然后将这个新的 HTML 风格推荐任务表示为一个超图表示学习问题，并提出了一种解决方法。我们的方法能够学习高阶片段的有效低维表示，这些片段由异构实体集合以及单个实体本身的低维表示组成。我们在几个设计风格的推荐任务中演示了该方法的有效性。据我们所知，这项工作是第一个开发基于机器学习的任务的基于 HTML 的电子邮件样式推荐模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+ML-based+Approach+for+HTML-based+Style+Recommendation)|0|
|[Graph-Level Embedding for Time-Evolving Graphs](https://doi.org/10.1145/3543873.3587299)|Lili Wang, Chenghan Huang, Xinyuan Cao, Weicheng Ma, Soroush Vosoughi|Dartmouth College, USA; Georgia Institute of Technology, USA; Jefferies Financial Group LLC, USA|Graph representation learning (also known as network embedding) has been extensively researched with varying levels of granularity, ranging from nodes to graphs. While most prior work in this area focuses on node-level representation, limited research has been conducted on graph-level embedding, particularly for dynamic or temporal networks. However, learning low-dimensional graph-level representations for dynamic networks is critical for various downstream graph retrieval tasks such as temporal graph similarity ranking, temporal graph isomorphism, and anomaly detection. In this paper, we present a novel method for temporal graph-level embedding that addresses this gap. Our approach involves constructing a multilayer graph and using a modified random walk with temporal backtracking to generate temporal contexts for the graph’s nodes. We then train a “document-level’’ language model on these contexts to generate graph-level embeddings. We evaluate our proposed model on five publicly available datasets for the task of temporal graph similarity ranking, and our model outperforms baseline methods. Our experimental results demonstrate the effectiveness of our method in generating graph-level embeddings for dynamic networks.|图表示学习(也称为网络嵌入)已经被广泛研究与不同的粒度级别，从节点到图。虽然该领域的大多数工作集中在节点级表示，但是对图级嵌入的研究很有限，特别是对于动态或时态网络。然而，学习动态网络的低维图级表示对于各种下游图检索任务(如时间图相似性排序、时间图同构和异常检测)至关重要。在本文中，我们提出了一种新的时间图级嵌入方法来解决这一问题。我们的方法包括构造一个多层图，并使用一个修改过的随机游走和时间回溯来为图的节点生成时间上下文。然后，我们在这些上下文上训练一个“文档级”语言模型来生成图级嵌入。我们评估了我们提出的模型在五个公开可用的数据集的时间图相似性排序的任务，我们的模型优于基线方法。实验结果表明了该方法在动态网络图级嵌入生成中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-Level+Embedding+for+Time-Evolving+Graphs)|0|
|[SpotLight: Visual Insight Recommendation](https://doi.org/10.1145/3543873.3587302)|Camille Harris, Ryan A. Rossi, Sana Malik, Jane Hoffswell, Fan Du, Tak Yeon Lee, Eunyee Koh, Handong Zhao|Georgia Tech, USA; KAIST, Republic of Korea; Adobe Research, USA|Visualization recommendation systems make understanding data more accessible to users of all skill levels by automatically generating visualizations for users to explore. However, most existing visualization recommendation systems focus on ranking all possible visualizations based on the attributes or encodings, which makes it difficult to find the most relevant insights. We therefore introduce a novel class of insight-based visualization recommendation systems that automatically rank and recommend groups of related insights as well as the most important insights within each group. Our approach combines results from different learning-based methods to discover insights automatically and generalizes to a variety of attribute types (e.g., categorical, numerical, and temporal), including non-trivial combinations of these attribute types. To demonstrate the utility of this approach, we implemented a insight-centric visualization recommendation system, SpotLight, and conducted a user study with twelve participants, which showed that users are able to quickly find and understand relevant insights in unfamiliar data.|可视化推荐系统通过自动生成供用户探索的可视化，使所有技能水平的用户更容易理解数据。然而，现有的可视化推荐系统大多侧重于基于属性或编码对所有可能的可视化进行排序，这使得很难找到最相关的见解。因此，我们引入了一类新颖的基于洞察力的可视化推荐系统，该系统可以自动对相关洞察力以及每个组内最重要的洞察力进行排名和推荐。我们的方法结合了来自不同的基于学习的方法的结果，自动发现见解，并推广到各种属性类型(例如，分类，数字和时间) ，包括这些属性类型的非平凡组合。为了证明这种方法的实用性，我们实施了一个以洞察力为中心的可视化推荐系统 SpotLight，并对12名参与者进行了用户研究，结果显示用户能够快速找到并理解不熟悉数据中的相关见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SpotLight:+Visual+Insight+Recommendation)|0|
|[DataExpo: A One-Stop Dataset Service for Open Science Research](https://doi.org/10.1145/3543873.3587305)|Bin Lu, Lyuwen Wu, Lina Yang, Chenxing Sun, Wei Liu, Xiaoying Gan, Shiyu Liang, Luoyi Fu, Xinbing Wang, Chenghu Zhou|Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences, China; Shanghai Jiao Tong University, China|The large volumes of data on the Internet provides new opportunities for scientific discovery, especially promoting data-driven open science research. However, due to lack of accurate semantic markups, finding relevant data is still difficult. To address this problem, we develop a one-stop dataset service called DataExpo and propose a deep learning method for automatic metadata ingestion. In this demo paper, we describe the system architecture, and how DataExpo facilitates dataset discovery, search and recommendation. Up till now, DataExpo has indexed over 960,000 datasets from more than 27,000 repositories in the context of Deep-time Digital Earth Program. Demo visitors can explore our service via https://dataexpo.acemap.info.|互联网上的大量数据为科学发现提供了新的机会，特别是促进了数据驱动的开放科学研究。然而，由于缺乏准确的语义标记，找到相关数据仍然很困难。为了解决这个问题，我们开发了一个名为 DataExpo 的一站式数据集服务，并提出了一种自动元数据摄取的深度学习方法。在本演示文章中，我们描述了系统的体系结构，以及 DataExpo 如何促进数据集的发现、搜索和推荐。到目前为止，数据博览会已经从超过27,000个数据库中索引了超过960,000个数据集。示范观众可透过 https://dataexpo.acemap.info 探索我们的服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DataExpo:+A+One-Stop+Dataset+Service+for+Open+Science+Research)|0|
|[Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization](https://doi.org/10.1145/3543873.3587309)|Canwen Xu, Julian J. McAuley, Penghan Wang|UC San Diego, USA; Cisco, USA|We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data.|我们介绍了一个基于大型语言模型的开源数据探索和分析平台—— Mirror。Mirror 为查询数据库提供了一个直观的自然语言界面，并自动生成可执行的 SQL 命令来检索相关数据并用自然语言对其进行汇总。此外，用户还可以预览和手动编辑生成的 SQL 命令，以确保查询的准确性。Mirror 还生成可视化，以便于理解数据。设计具有灵活性和人工输入的头脑，镜子是适合于有经验的数据分析师和非技术专业人士寻求获得洞察力从他们的数据。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mirror:+A+Natural+Language+Interface+for+Data+Querying,+Summarization,+and+Visualization)|0|
|[Is the Impression Log Beneficial to Effective Model Training in News Recommender Systems? No, It's NOT](https://doi.org/10.1145/3543873.3587312)|Jeewon Ahn, HongKyun Bae, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+the+Impression+Log+Beneficial+to+Effective+Model+Training+in+News+Recommender+Systems?+No,+It's+NOT)|0|
|[Incorporating Embedding to Topic Modeling for More Effective Short Text Analysis](https://doi.org/10.1145/3543873.3587316)|Junaid Rashid, Jungeun Kim, Usman Naseem|Department of Software, Kongju National University, Cheonan, Republic of Korea, Republic of Korea; School of Computer Science, The University of Sydney, Sydney, Australia, Australia; Department of Data Science, Sejong University, Seoul, Republic of Korea, Republic of Korea|With the growing abundance of short text content on websites, analyzing and comprehending these short texts has become a crucial task. Topic modeling is a widely used technique for analyzing short text documents and uncovering the underlying topics. However, traditional topic models face difficulties in accurately extracting topics from short texts due to limited content and their sparse nature. To address these issues, we propose an Embedding-based topic modeling (EmTM) approach that incorporates word embedding and hierarchical clustering to identify significant topics. Experimental results demonstrate the effectiveness of EmTM on two datasets comprising web short texts, Snippet and News. The results indicate a superiority of EmTM over baseline topic models by its exceptional performance in both classification accuracy and topic coherence metrics.|随着网站上短文内容的日益丰富，分析和理解这些短文已经成为一项重要的任务。主题建模是一种广泛使用的分析短文本文档和揭示潜在主题的技术。然而，传统的话题模型由于内容有限和稀疏的特点，很难准确地从短文中提取话题。为了解决这些问题，我们提出了一种基于嵌入的主题建模(EmTM)方法，该方法结合了单词嵌入和层次聚类来识别重要的主题。实验结果表明，该方法能够有效地处理包括网络短文本、片段和新闻在内的两个数据集。结果表明，与基线主题模型相比，EmTM 在分类精度和主题一致性度量方面具有优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Embedding+to+Topic+Modeling+for+More+Effective+Short+Text+Analysis)|0|
|[EnhancE: Enhanced Entity and Relation Embedding for Knowledge Hypergraph Link Prediction](https://doi.org/10.1145/3543873.3587326)|Chenxu Wang, Zhao Li, Xin Wang, Zirui Chen|Tianjin University, China|Knowledge Hypergraphs, as the generalization of knowledge graphs, have attracted increasingly widespread attention due to their friendly compatibility with real-world facts. However, link prediction in knowledge hypergraph is still an underexplored field despite the ubiquity of n-ary facts in the real world. Several recent representative embedding-based knowledge hypergraph link prediction methods have proven to be effective in a series of benchmarks, however, they only consider the position (or role) information, ignoring the neighborhood structure among entities and rich semantic information within each fact. To this end, we propose a model named EnhancE for effective link prediction in knowledge hypergraphs. On the one hand, a more expressive entity representation is obtained with both position and neighborhood information added to the initial embedding. On the other hand, rich semantic information of the involved entities within each tuple is incorporated into relation embedding for enhanced representation. Extensive experimental results over real datasets of both knowledge hypergraph and knowledge graph demonstrate the excellent performance of EnhancE compared with a variety of state-of-the-art baselines.|知识超图作为知识图的一种推广，由于其与现实世界事实的友好兼容性而引起了人们越来越广泛的关注。然而，尽管在现实世界中 n 元事实的普遍存在，知识超图中的链接预测仍然是一个未被充分探索的领域。最近几种有代表性的嵌入式知识超图链接预测方法已经被证明在一系列的基准测试中是有效的，但是它们只考虑位置(或角色)信息，忽略了实体间的邻域结构和每个事实中丰富的语义信息。为此，我们提出了一种基于知识超图的有效链接预测模型——增强 E。一方面，在初始嵌入的基础上加入位置信息和邻域信息，得到更具表现力的实体表示;。另一方面，每个元组中所涉及的实体的丰富语义信息被合并到关系嵌入中以增强表示。在知识超图和知识图的实际数据集上进行的大量实验结果表明，与各种最先进的基线相比，增强 E 具有优异的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EnhancE:+Enhanced+Entity+and+Relation+Embedding+for+Knowledge+Hypergraph+Link+Prediction)|0|
|[An Analogical Reasoning Method Based on Multi-task Learning with Relational Clustering](https://doi.org/10.1145/3543873.3587333)|Shuyi Li, Shaojuan Wu, Xiaowang Zhang, Zhiyong Feng|College of Intelligence and Computing, Tianjin University, China|Analogical QA task is a challenging natural language processing problem. When two word pairs are similar in their relationships, we refer to their relations as analogous. Although the analogy method based on word embedding is well developed, the analogy reasoning is far beyond this scope. At present, the methods based on pre-trained language models have explored only the tip of the iceberg. In this paper, we proposed a multi-task learning method for analogical QA task. First, we obtain word-pair representations by leveraging the output embeddings of the [MASK] token in the pre-trained language model. The representations are prepared for two tasks. The first task aims to train an analogical classifier by supervised learning. The second task is an auxiliary task based on relation clustering to generate relation pseudo-labels for word pairs and train relation classifier. Our method guides the model to analyze the relation similarity in analogical reasoning without relation labels. The experiments show that our method achieve excellent performance on four analogical reasoning datasets without the help of external corpus and knowledge. In the most difficult data set E-KAR, it has increased by at least 4%.|类比 QA 任务是一个具有挑战性的自然语言处理问题。当两个词对在关系上相似时，我们把它们的关系称为相似。基于嵌入词的类比推理方法虽然已经得到了很好的发展，但是类比推理远远超出了这个范围。目前，基于预训练语言模型的方法仅仅探索了冰山一角。本文提出了一种类比 QA 任务的多任务学习方法。首先，我们利用预训练语言模型中[ MASK ]令牌的输出嵌入获得词对表示。这些表示准备用于两个任务。第一个任务是通过监督式学习训练一个类比分类器。第二个任务是一个基于关系聚类的辅助任务，用于生成词对的关系伪标签和训练关系分类器。该方法引导模型分析无关联标签的类比推理中的关联相似性。实验结果表明，该方法在不借助外部语料库和知识的情况下，对四个类比推理数据集取得了良好的性能。在最困难的数据集 E-KAR 中，它至少增加了4% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Analogical+Reasoning+Method+Based+on+Multi-task+Learning+with+Relational+Clustering)|0|
|[Templet: A Collaborative System for Knowledge Graph Question Answering over Wikidata](https://doi.org/10.1145/3543873.3587335)|Francisca Suárez, Aidan Hogan|DCC, Universidad de Chile, Chile and Instituto Milenio Fundamentos de los Datos (IMFD), Chile; DCC, Universidad de Chile, Chile|We present Templet: an online question answering (QA) system for Wikidata. Templet is based on the collaboratively-edited repository QAWiki, which collects questions in multiple natural languages along with their corresponding structured queries. Templet generates templates from question–query pairs on QAWiki by replacing key entities with identifiers. Using autocompletion, the user can type a question in natural language, select a template, and again using autocompletion, select the entities they wish to insert into the template’s placeholders, generating a concrete question, query and results. The main objectives of Templet are: (i) to enable users to answer potentially complex questions over Wikidata using natural language templates and autocompletion; (ii) to encourage users to collaboratively create new templates via QAWiki, which in turn can benefit not only Templet, but other QA systems.|我们提出的模板: 一个在线问题回答(QA)系统的 Wikidata。Templet 基于协作编辑的存储库 QAWiki，该存储库用多种自然语言收集问题以及相应的结构化查询。Templet 通过使用标识符替换关键实体，从 QAWiki 上的问题-查询对生成模板。使用自动补全，用户可以用自然语言键入一个问题，选择一个模板，然后再次使用自动补全，选择他们希望插入到模板占位符中的实体，生成一个具体的问题、查询和结果。Templet 的主要目标是: (i)使用户能够通过使用自然语言模板和自动完成来回答 Wikidata 上潜在的复杂问题; (ii)鼓励用户通过 QAWiki 合作创建新的模板，这反过来不仅可以使 Templet 受益，还可以使其他 QA 系统受益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Templet:+A+Collaborative+System+for+Knowledge+Graph+Question+Answering+over+Wikidata)|0|
|[OptiRef: Query Optimization for Knowledge Bases](https://doi.org/10.1145/3543873.3587342)|Wafaa El Husseini, Cheikh Brahim El Vaigh, François Goasdoué, Hélène Jaudoin|Univ. Bourgogne, France; Univ. Rennes, France|Ontology-mediated query answering (OMQA) consists in asking database queries on a knowledge base (KB); a KB is a set of facts, the KB’s database, described by domain knowledge, the KB’s ontology. FOL-rewritability is the main OMQA technique: it reformulates a query w.r.t. the KB’s ontology so that the evaluation of the reformulated query on the KB’s database computes the correct answers. However, because this technique embeds the domain knowledge relevant to the query into the reformulated query, a reformulated query may be complex and its optimization is the crux of efficiency. We showcase OptiRef that implements a novel, general optimization framework for efficient query answering on datalog ±, description logic, existential rules, OWL and RDF/S KBs. OptiRef optimizes reformulated queries by rapidly computing, based on a KB’s database summary, simpler (contained) queries with the same answers. We demonstrate OptiRef’s effectiveness on well-established benchmarks: performance is significantly improved in general, up to several orders of magnitude in the best cases!|本体介导的查询回答(OMQA)包括在知识库(KB)上询问数据库查询; 知识库是一组事实，知识库的数据库，由领域知识描述，知识库的本体。FOL 可重写性是主要的 OMQA 技术: 它重新规范查询 w.r.t. 知识库的本体，以便在知识库的数据库上计算重新规范查询的正确答案。然而，由于这种技术将与查询相关的领域知识嵌入到重构查询中，因此重构查询可能比较复杂，其优化是提高查询效率的关键。我们展示了 OptiRef，它实现了一个新颖的、通用的优化框架，用于在数据目录 ± 、描述逻辑、存在规则、 OWL 和 RDF/S 知识库上进行有效的查询应答。OptiRef 通过快速计算优化重新配置的查询，基于知识库的数据库摘要，使用具有相同答案的更简单(包含)的查询。我们展示了 OptiRef 在完善的基准测试上的有效性: 性能总体上得到了显著的改善，在最好的情况下达到了几个数量级！|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OptiRef:+Query+Optimization+for+Knowledge+Bases)|0|
|[Learning Topical Structured Interfaces from Medical Research Literature](https://doi.org/10.1145/3543873.3587353)|Maitry Chauhan, Anna Pyayt, Michael N. Gubanov|University of South Florida, USA; Florida State University, USA|Accessing large-scale structured datasets such as WDC or CORD-191 is very challenging. Even if one topic (e.g. COVID-19 vaccine efficacy) is of interest, all topical tables in different sources/papers have hundreds of different schemas, depending on the authors, which significantly complicates both finding and querying them. Here we demonstrate a scalable Meta-profiler system, capable of constructing a structured standardized interface to a topic of interest in large-scale (semi-)structured datasets. This interface, that we call Meta-profile represents a multi-dimensional meta-data summary for a selected topic of interest, accumulating all differently structured representations of the topical tables in the dataset. Such Meta-profiles can be used as a rich visualization as well as a robust structural query interface simplifying access to large-scale (semi-)structured data for different user segments, such as data scientists and end users.|访问大规模的结构化数据集，如 WDC 或 CORD-191是非常具有挑战性的。即使一个主题(例如2019冠状病毒疾病疫苗效力)是有趣的，不同来源/论文中的所有主题表格都有数百种不同的模式，这取决于作者，这使得查找和查询这些模式变得非常复杂。在这里，我们演示了一个可伸缩的元分析器系统，它能够为大规模(半)结构化数据集中感兴趣的主题构建一个结构化的标准化接口。我们称之为 Meta-profile 的这个接口表示一个选定主题的多维元数据摘要，它积累了数据集中主题表的所有不同结构的表示。这样的元概要文件可以用作丰富的可视化以及健壮的结构化查询界面，简化不同用户段(如数据科学家和最终用户)对大规模(半)结构化数据的访问。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Topical+Structured+Interfaces+from+Medical+Research+Literature)|0|
|[DGBCT: A Scalable Distributed Gradient Boosting Causal Tree at Alipay](https://doi.org/10.1145/3543873.3584645)|Jun Zhou, Caizhi Tang, Qing Cui, Yi Ding, Longfei Li, Fei Wu|College of Computer Science and Technology, Zhejiang University, China and Ant Group, China; College of Computer Science and Technology, Zhejiang University, China; Ant Group, China|Causal effect estimation has been increasingly emphasized in the past few years. To handle this problem, tree-based causal methods have been widely used due to their robustness and explainability. However, most of the existing methods are limited to running on a single machine, making it difficult to scale up to hundreds of millions of data in typical industrial scenarios. This paper proposes DGBCT, a Distributed Gradient Boosting Causal Tree to tackle such problem, and the contribution of this paper is three folds. First, we extend the original GBCT method to a multi-treatment setting and take the monotonic constraints into consideration, so that more typical industrial necessities can be resolved with our framework. Moreover, we implement DGBCT based on the ‘Controller-Coordinator-Worker’ framework, in which dual failover mechanism is achieved, and commendable flexibility is ensured. In addition, empirical results show that DGBCT significantly outperforms the state-of-the-art causal trees, and has a near-linear speedup as the number of workers grows. The system is currently deployed in Alipay1 to support the daily business tasks that involve hundreds of millions of users.|因果效应估计在过去的几年中越来越受到重视。为了解决这个问题，基于树的因果关系方法由于其鲁棒性和可解释性而得到了广泛的应用。然而，现有的大多数方法仅限于在单台机器上运行，因此在典型的工业场景中很难扩展到数亿个数据。本文提出了分布式梯度提升因果树 DGBCT 来解决这个问题，本文的贡献有三个方面。首先，我们将原来的 GBCT 方法扩展到一个多处理环境，并且考虑了单调约束，使得我们的框架能够解决更多的典型工业需求。此外，我们在“控制器-协调器-工作者”框架的基础上实现了 DGBCT，实现了双重故障转移机制，并保证了值得称赞的灵活性。此外，实证结果显示，DGBCT 的表现明显优于最先进的因果树，并且随着工作人员数量的增加有近线性的加速效应。该系统目前部署在支付宝1中，以支持涉及数亿用户的日常业务任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DGBCT:+A+Scalable+Distributed+Gradient+Boosting+Causal+Tree+at+Alipay)|0|
|[What Image do You Need? A Two-stage Framework for Image Selection in E-commerce](https://doi.org/10.1145/3543873.3584646)|Sheng You, Chao Wang, Baohua Wu, Jingping Liu, Quan Lu, Guanzhou Han, Yanghua Xiao|Alibaba Group, China; East China University of Science and Technology, China; Fudan University, China; Shanghai University, China|In e-commerce, images are widely used to display more intuitive information about items. Image selection significantly affects the user’s click-through rate (CTR). Most existing work considers the CTR as the target to find an appropriate image. However, these methods are challenging to deploy online efficiently. Also, the selected images may not relate to the item but are profitable to CTR, resulting in the undesirable phenomenon of enticing users to click on the item. To address these issues, we propose a novel two-stage pipeline method with content-based recall model and CTR-based ranking model. The first is realized as a joint method based on the title-image matching model and multi-modal knowledge graph embedding learning model. The second is a CTR-based visually aware scoring model, incorporating the entity textual information and entity images. Experimental results show the effectiveness and efficiency of our method in offline evaluations. After a month of online A/B testing on a travel platform Fliggy, the relative improvement of our method is 5% with respect to seller selection on CTCVR in the searching scenario, and our method further improves pCTR from 3.48% of human pick to 3.53% in the recommendation scenario.|在电子商务中，图像被广泛用于显示更直观的商品信息。图像选择会显著影响用户的点进率。大多数现有的工作都将 CTR 作为寻找合适图像的目标。然而，这些方法在线有效部署是具有挑战性的。此外，所选图像可能与该项目无关，但有利于点击率，导致不良现象的诱惑用户点击该项目。为了解决这些问题，我们提出了一种新的基于内容的召回模型和基于点击率的排序模型的两阶段流水线方法。第一种是基于标题-图像匹配模型和多模态知识图嵌入学习模型的联合方法。第二种是基于 CTR 的视觉感知评分模型，结合了实体文本信息和实体图像。实验结果表明了该方法在离线评估中的有效性和有效性。在旅游平台 Fliggy 上进行了一个月的在线 A/B 测试后，在搜索场景中，我们的方法相对于 CTCVR 上的卖方选择的相对改善为5% ，并且我们的方法进一步将 pCTR 从人类选择的3.48% 提高到推荐场景中的3.53% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+Image+do+You+Need?+A+Two-stage+Framework+for+Image+Selection+in+E-commerce)|0|
|[Learning Geolocation by Accurately Matching Customer Addresses via Graph based Active Learning](https://doi.org/10.1145/3543873.3584647)|Saket Maheshwary, Saurabh Sohoney|Amazon, India|We propose a novel adaptation of graph-based active learning for customer address resolution or de-duplication, with the aim to determine if two addresses represent the same physical building or not. For delivery systems, improving address resolution positively impacts multiple downstream systems such as geocoding, route planning and delivery time estimations, leading to an efficient and reliable delivery experience, both for customers as well as delivery agents. Our proposed approach jointly leverages address text, past delivery information and concepts from graph theory to retrieve informative and diverse record pairs to label. We empirically show the effectiveness of our approach on manually curated dataset across addresses from India (IN) and United Arab Emirates (UAE). We achieved absolute improvement in recall on average across IN and UAE while preserving precision over the existing production system. We also introduce delivery point (DP) geocode learning for cold-start addresses as a downstream application of address resolution. In addition to offline evaluation, we also performed online A/B experiments which show that when the production model is augmented with active learnt record pairs, the delivery precision improved by and delivery defects reduced by on an average across shipments from IN and UAE.|我们提出了一种新的基于图的主动学习的客户地址解析或去重复，目的是确定是否两个地址代表相同的物理建筑物。对于送货系统，提高地址分辨率会对多个下游系统产生积极影响，例如地理编码、路径规划和送货时间估计，从而为客户和送货代理带来高效和可靠的送货体验。我们提出的方法共同利用地址文本，过去的传递信息和概念从图论检索信息和不同的记录对标签。我们通过实验证明了我们的方法在人工管理来自印度(IN)和阿拉伯联合酋长国(UAE)的数据集方面的有效性。在保持现有生产系统精度的同时，我们在 IN 和阿联酋的平均召回率上取得了绝对的提高。我们还介绍了用于冷启动地址的交付点(DP)地理编码学习作为地址解析的下游应用。除了离线评估之外，我们还进行了在线 A/B 实验，结果表明，当生产模型增加了主动学习记录对时，从 IN 和阿联酋发货的交付精度提高了，交付缺陷平均减少了。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Geolocation+by+Accurately+Matching+Customer+Addresses+via+Graph+based+Active+Learning)|0|
|[CAViaR: Context Aware Video Recommendations](https://doi.org/10.1145/3543873.3584658)|Khushhall Chandra Mahajan, Aditya Palnitkar, Ameya Raul, Brad Schumitsch|Meta Inc., USA|Many recommendation systems rely on point-wise models, which score items individually. However, point-wise models generating scores for a video are unable to account for other videos being recommended in a query. Due to this, diversity has to be introduced through the application of heuristic-based rules, which are not able to capture user preferences, or make balanced trade-offs in terms of diversity and item relevance. In this paper, we propose a novel method which introduces diversity by modeling the impact of low diversity on user's engagement on individual items, thus being able to account for both diversity and relevance to adjust item scores. The proposed method is designed to be easily pluggable into existing large-scale recommender systems, while introducing minimal changes in the recommendations stack. Our models show significant improvements in offline metrics based on the normalized cross entropy loss compared to production point-wise models. Our approach also shows a substantial increase of 1.7% in topline engagements coupled with a 1.5% increase in daily active users in an A/B test with live traffic on Facebook Watch, which translates into an increase of millions in the number of daily active users for the product.|许多推荐系统依赖于逐点模型，这种模型对项目进行单独评分。然而，为视频生成分数的点模型无法解释在查询中推荐的其他视频。因此，必须通过应用启发式规则来引入多样性，这些规则不能捕捉用户的偏好，也不能在多样性和项目相关性方面做出平衡的权衡。本文提出了一种引入多样性的新方法，该方法通过建立低多样性对用户参与个别项目的影响模型，从而能够同时考虑多样性和相关性来调整项目得分。所提出的方法被设计成可以很容易地插入到现有的大规模推荐系统中，同时在推荐堆栈中引入最小的变化。与生产点模型相比，我们的模型显示了基于归一化交叉熵损失的离线指标的显著改进。我们的方法还显示，顶线参与度大幅增加了1.7% ，在 Facebook Watch 上的实时流量的 A/B 测试中，每日活跃用户增加了1.5% ，这意味着产品的每日活跃用户数量增加了数百万。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAViaR:+Context+Aware+Video+Recommendations)|0|
|[Towards Building a Mobile App for People on the Spectrum](https://doi.org/10.1145/3543873.3587533)|Victoria Firsanova|Department of Mathematical Linguistics, Saint Petersburg State University, Russian Federation|The inclusion of autistic people can be augmented by a mobile app that provides information without a human mediator making information perception more liberating for people in the spectrum. This paper is an overview of a doctoral work dedicated to the development of a web-based mobile tool for supporting the inclusion of people on the autism spectrum. The work includes UX/UI research conducted with psychiatry experts, web information retrieval study and neural question-answering research. Currently, the study results comprise several mobile app layouts, a retriever-reader model design and fine-tuned neural network for extractive question-answering. Source code and other resources are available at https://github.com/vifirsanova/empi.|自闭症患者的包容性可以通过移动应用程序得到加强，这个程序可以在没有人类中介的情况下提供信息，从而使自闭症患者的信息感知更加自由。这篇文章是一篇博士论文的概述，该论文致力于开发一种基于网络的移动工具，以支持孤独症患者的融入。这项工作包括由精神病学专家进行的用户体验/用户界面研究、网络信息检索研究和神经问答研究。目前，研究结果包括几个移动应用程序的布局，一个检索-阅读器模型设计和微调神经网络提取问题回答。源代码和其他资源可在 https://github.com/vifirsanova/empi 获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Building+a+Mobile+App+for+People+on+the+Spectrum)|0|
|[Multi-turn mediated solutions for Conversational Artificial Intelligent systems leveraging graph-based techniques](https://doi.org/10.1145/3543873.3587540)|Riya Naik|Computer Science & Information Systems, Birla Institute Of Technology And Science, Pilani, India|The current era is dominated by intelligent Question Answering (QA) systems that can instantly answer almost all their questions, saving users search time and increasing the throughput and precision in the applied domain. A vast amount of work is being carried out in QA systems to deliver better content satisfying users’ information needs [2]. Since QA systems are ascending the cycle of emerging technologies, there are potential research gaps that can be explored. QA systems form a significant part of Conversational Artificial Intelligent systems giving rise to a new research pathway, i.e., Conversational Question Answering (CQA) systems [32]. We propose to design and develop a CQA system leveraging Hypergraph-based techniques. The approach focuses on the multi-turn conversation and multi-context to gauge users’ exact information needs and deliver better answers. We further aim to address "supporting evidence-based retrieval" for fact-based responsible answer generation. Since the QA system requires a large amount of data and processing, we also intend to investigate hardware performance for effective system utilization.|当今时代的主流是智能问答(QA)系统，它可以即时回答几乎所有的问题，节省用户搜索时间，提高应用领域的吞吐量和精度。为了提供更好的内容以满足用户的信息需求，QA 系统正在进行大量的工作[2]。由于 QA 系统正在提升新兴技术的周期，因此存在可以探索的潜在研究差距。问答系统构成了会话人工智能系统的重要组成部分，从而产生了一种新的研究途径，即会话问答(CQA)系统[32]。我们建议利用基于 Hypergraph 的技术设计和开发一个 CQA 系统。该方法侧重于多回合会话和多上下文，以衡量用户的确切信息需求和提供更好的答案。我们进一步的目标是解决“支持基于证据的检索”的事实为基础的负责任的答案生成。由于 QA 系统需要大量的数据和处理，因此我们还打算研究硬件性能，以便有效地利用系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-turn+mediated+solutions+for+Conversational+Artificial+Intelligent+systems+leveraging+graph-based+techniques)|0|
|[Graph and Embedding based Approach for Text Clustering: Topic Detection in a Large Multilingual Public Consultation](https://doi.org/10.1145/3543873.3587627)|Nicolas Stefanovitch, Guillaume Jacquet, Bertrand De Longueville|European Commission - Joint Research Centre, Italy|We present a novel algorithm for multilingual text clustering built upon two well studied techniques: multilingual aligned embedding and community detection in graphs. The aim of our algorithm is to discover underlying topics in a multilingual dataset using clustering. We present both a numerical evaluation using silhouette and V-measure metrics, and a qualitative evaluation for which we propose a new systematic approach. Our algorithm presents robust overall performance and its results were empirically evaluated by an analyst. The work we present was done in the context of a large multilingual public consultation, for which our new algorithm was deployed and used on a daily basis.|本文提出了一种新的多语言文本聚类算法，该算法基于两种已经得到广泛研究的技术: 多语言对齐嵌入和图中的社区检测。我们的算法的目的是使用聚类来发现多语言数据集中的基本主题。我们提出了一个数值评估使用轮廓和 V 测量度量，和一个定性的评估，我们提出了一个新的系统方法。我们的算法提出了稳健的整体性能，其结果是经验性的分析评价。我们介绍的工作是在大规模多语种公众协商的背景下完成的，我们的新算法每天都得到部署和使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+and+Embedding+based+Approach+for+Text+Clustering:+Topic+Detection+in+a+Large+Multilingual+Public+Consultation)|0|
|[Dual-grained Text-Image Olfactory Matching Model with Mutual Promotion Stages](https://doi.org/10.1145/3543873.3587649)|Yi Shao, Jiande Sun, Ye Jiang, Jing Li|Shandong Management University, China; Shandong Normal University, China; Qingdao University of Science and Technology, China|Olfactory experience has great advantages in awakening human memories and emotions, which may even surpass vision in some cases. Studies have proved that olfactory scene descriptions in images and text content can also arouse human olfactory imagination, but there are still few studies on solving related problems from the perspective of computer vision and NLP. This paper proposes a multimodal model that can detect similar olfactory experience in paired text-image samples. The model builds two stages, coarse-grained and fine-grained. The model adopts the feature fusion method based on pre-trained CLIP for coarse-grained matching training to obtain a preliminary feature extractor to promote fine-grained matching training, and then uses the similarity calculation method based on stacked cross attention for fine-grained matching training to obtain the final feature extractor which in turn promotes coarse-grained matching training. Finally, we manually build an approximate olfactory nouns list during fine-grained matching training, which not only yields significantly better performance when fed back to the fine-grained matching process, but this noun list can be used for future research. Experiments on the MUSTI task dataset of MediaEval2022 prove that the coarse-grained and fine-grained matching stages in proposed model both perform well, and both F1 measures exceed the existing baseline models.|嗅觉经验在唤醒人类记忆和情感方面有很大的优势，在某些情况下甚至可能超越视觉。研究表明，图像和文本内容中的嗅觉场景描述也能激发人类的嗅觉想象，但从计算机视觉和自然语言处理的角度解决相关问题的研究还很少。本文提出了一个多模态模型，可以检测相似的嗅觉经验配对文本图像样本。该模型分为粗粒度和细粒度两个阶段。该模型采用基于预训练 CLIP 的特征融合方法进行粗粒度匹配训练，得到初步的特征提取器以促进细粒度匹配训练，然后采用基于叠加交叉注意的相似度计算方法进行细粒度匹配训练，得到最终的特征提取器以促进粗粒度匹配训练。最后，我们在细粒度匹配训练过程中手动构建了一个近似的嗅觉名词列表，这不仅在反馈到细粒度匹配过程时产生了明显更好的性能，而且这个名词列表可以用于未来的研究。在 MediaEval2022的 MUSTI 任务数据集上的实验证明，所提出的模型中的粗粒度和细粒度匹配阶段都表现良好，而且两种 F1测度都超过了现有的基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-grained+Text-Image+Olfactory+Matching+Model+with+Mutual+Promotion+Stages)|0|
|[MEMER - Multimodal Encoder for Multi-signal Early-stage Recommendations](https://doi.org/10.1145/3543873.3587679)|Mohit Agarwal, Srijan Saket, Rishabh Mehrotra|ShareChat, India|Millions of content gets created daily on platforms like YouTube, Facebook, TikTok etc. Most of such large scale recommender systems are data demanding, thus taking substantial time for content embedding to mature. This problem is aggravated when there is no behavioral data available for new content. Poor quality recommendation for these items lead to user dissatisfaction and short content shelf-life. In this paper we propose a solution MEMER (Multimodal Encoder for Multi-signal Early-stage Recommendations), that utilises the multimodal semantic information of content and uses it to generate better quality embeddings for early-stage items. We demonstrate the flexibility of the framework by extending it to various explicit and implicit user actions. Using these learnt embeddings, we conduct offline and online experiments to verify its effectiveness. The predicted embeddings show significant gains in online early-stage experiments for both videos and images (videos:  44% relative gain in click through rate,  46% relative gain in explicit engagements,  9% relative gain in successful video play,  20% relative reduction in skips, images:  56% relative gain in explicit engagements). This also compares well against the performance of mature embeddings (83.3% RelaImpr (RI) [18] in Successful Video Play, 97.8% RelaImpr in Clicks).|每天都有数以百万计的内容在 YouTube、 Facebook、 TikTok 等平台上被创造出来。大多数这样的大规模推荐系统都需要大量的数据，因此内容嵌入需要大量的时间才能成熟。当没有可用于新内容的行为数据时，这个问题就更加严重了。这些项目的低质量推荐导致用户不满意和内容保质期短。在本文中，我们提出了一个解决方案 MEMER (多信号早期推荐的多模式编码器) ，利用多模式内容语义信息，并使用它为早期项目产生更好的质量嵌入。我们通过将框架扩展到各种显式和隐式用户操作来演示框架的灵活性。使用这些学习嵌入，我们进行离线和在线实验，以验证其有效性。预测的嵌入在视频和图像的在线早期实验中都显示出显著的增益(视频: 点击率相对增益44% ，显性参与相对增益46% ，成功视频播放相对增益9% ，跳过相对减少20% ，图像: 显性参与相对增益56%)。这也与成熟嵌入的性能相当(83.3% RelaImpr (RI)[18]在成功的视频播放，97.8% RelaImpr 在点击)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MEMER+-+Multimodal+Encoder+for+Multi-signal+Early-stage+Recommendations)|0|
|[Social Re-Identification Assisted RTO Detection for E-Commerce](https://doi.org/10.1145/3543873.3587620)|Hitkul Jangra, Abinaya K, Soham Saha, Satyajit Banerjee, Muthusamy Chelliah, Ponnurangam Kumaraguru|IIIT Delhi, India; Flipkart, India; IIIT Hyderabad, India|E-commerce features like easy cancellations, returns, and refunds can be exploited by bad actors or uninformed customers, leading to revenue loss for organization. One such problem faced by e-commerce platforms is Return To Origin (RTO), where the user cancels an order while it is in transit for delivery. In such a scenario platform faces logistics and opportunity costs. Traditionally, models trained on historical trends are used to predict the propensity of an order becoming RTO. Sociology literature has highlighted clear correlations between socio-economic indicators and users’ tendency to exploit systems to gain financial advantage. Social media profiles have information about location, education, and profession which have been shown to be an estimator of socio-economic condition. We believe combining social media data with e-commerce information can lead to improvements in a variety of tasks like RTO, recommendation, fraud detection, and credit modeling. In our proposed system, we find the public social profile of an e-commerce user and extract socio-economic features. Internal data fused with extracted social features are used to train a RTO order detection model. Our system demonstrates a performance improvement in RTO detection of 3.1% and 19.9% on precision and recall, respectively. Our system directly impacts the bottom line revenue and shows the applicability of social re-identification in e-commerce.|电子商务的特点，如容易取消，退货和退款可以利用不良行为者或不知情的客户，导致收入损失的组织。电子商务平台面临的一个这样的问题是返还原产地(RTO) ，即用户在运输途中取消订单。在这种情况下，平台面临物流和机会成本。传统上，根据历史趋势训练的模型被用来预测订单成为 RTO 的倾向。社会学文献强调了社会经济指标与用户利用系统获取金融优势的倾向之间的明确相关性。社交媒体档案包含有关地理位置、教育和职业的信息，这些信息已被证明是社会经济状况的估计值。我们相信，将社交媒体数据与电子商务信息结合起来，可以改进诸如 RTO、推荐、欺诈检测和信用建模等多种任务。在我们提出的系统中，我们找到电子商务用户的公共社会轮廓，并提取社会经济特征。利用内部数据与提取的社会特征融合，建立了 RTO 订单检测模型。我们的系统在检测准确率召回率方面的性能改善分别为3.1% 和19.9% 。我们的系统直接影响到底线收入，显示了社会再认同在电子商务中的适用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Social+Re-Identification+Assisted+RTO+Detection+for+E-Commerce)|0|
|[Contextual Response Interpretation for Automated Structured Interviews: A Case Study in Market Research](https://doi.org/10.1145/3543873.3587657)|Harshita Sahijwani, Kaustubh D. Dhole, Ankur P. Purwar, Venugopal Vasudevan, Eugene Agichtein|Procter & Gamble, Singapore; Procter & Gamble, USA; Emory University, USA|Structured interviews are used in many settings, importantly in market research on topics such as brand perception, customer habits, or preferences, which are critical to product development, marketing, and e-commerce at large. Such interviews generally consist of a series of questions that are asked to a participant. These interviews are typically conducted by skilled interviewers, who interpret the responses from the participants and can adapt the interview accordingly. Using automated conversational agents to conduct such interviews would enable reaching a much larger and potentially more diverse group of participants than currently possible. However, the technical challenges involved in building such a conversational system are relatively unexplored. To learn more about these challenges, we convert a market research multiple-choice questionnaire to a conversational format and conduct a user study. We address the key task of conducting structured interviews, namely interpreting the participant's response, for example, by matching it to one or more predefined options. Our findings can be applied to improve response interpretation for the information elicitation phase of conversational recommender systems.|结构化访谈用于许多场合，重要的是用于市场调查，如品牌认知、客户习惯或偏好，这些对产品开发、市场营销和电子商务至关重要。这种面试通常包括向参与者提出的一系列问题。这些面试通常由技术熟练的面试官进行，他们解释参与者的回答，并能相应地调整面试。使用自动对话代理进行这种访谈将能够接触到比目前可能的更多、可能更多样化的参与者群体。然而，构建这样一个会话系统所涉及的技术挑战相对而言还没有得到探索。为了更多地了解这些挑战，我们将市场调查多项选择问卷转换为会话形式，并进行用户研究。我们解决的关键任务是进行结构化访谈，即解释参与者的反应，例如，通过匹配一个或多个预先定义的选项。我们的研究结果可以用于改善会话推荐系统中信息激发阶段的响应解释。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contextual+Response+Interpretation+for+Automated+Structured+Interviews:+A+Case+Study+in+Market+Research)|0|
|[Knowledge Graph-Enhanced Neural Query Rewriting](https://doi.org/10.1145/3543873.3587678)|Shahla Farzana, Qunzhi Zhou, Petar Ristoski|eBay Inc, USA; eBay Inc., USA; University of Illinois Chicago, USA|The main task of an e-commerce search engine is to semantically match the user query to the product inventory and retrieve the most relevant items that match the user’s intent. This task is not trivial as often there can be a mismatch between the user’s intent and the product inventory for various reasons, the most prevalent being: (i) the buyers and sellers use different vocabularies, which leads to a mismatch; (ii) the inventory doesn’t contain products that match the user’s intent. To build a successful e-commerce platform it is of paramount importance to be able to address both of these challenges. To do so, query rewriting approaches are used, which try to bridge the semantic gap between the user’s intent and the available product inventory. Such approaches use a combination of query token dropping, replacement and expansion. In this work we introduce a novel Knowledge Graph-enhanced neural query rewriting in the e-commerce domain. We use a relationship-rich product Knowledge Graph to infuse auxiliary knowledge in a transformer-based query rewriting deep neural network. Experiments on two tasks, query pruning and complete query rewriting, show that our proposed approach significantly outperforms a baseline BERT-based query rewriting solution.|电子商务搜索引擎的主要任务是在语义上将用户查询与产品库存相匹配，并检索与用户意图相匹配的最相关项目。这个任务并不是微不足道的，因为在用户的意图和产品库存之间经常会因为各种原因而产生不匹配，最普遍的原因是: (i)买家和卖家使用不同的词汇，这会导致不匹配; (ii)库存不包含符合用户意图的产品。要建立一个成功的电子商务平台，最重要的是能够应对这两个挑战。为此，使用了查询重写方法，这些方法试图弥合用户意图和可用产品目录之间的语义差距。这种方法结合使用查询标记删除、替换和扩展。在这项工作中，我们介绍了一种新的知识图增强神经查询重写在电子商务领域。在基于变压器的查询重写深度神经网络中，我们使用一个关系丰富的产品知识图来注入辅助知识。通过对查询裁剪和完全查询重写两个任务的实验表明，该方法的性能明显优于基于 BERT 的基线查询重写方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph-Enhanced+Neural+Query+Rewriting)|0|
|[Fairness-aware Differentially Private Collaborative Filtering](https://doi.org/10.1145/3543873.3587577)|Zhenhuan Yang, Yingqiang Ge, Congzhe Su, Dingxian Wang, Xiaoting Zhao, Yiming Ying|Etsy, USA; Rutgers University, USA; University at Albany, SUNY, USA|Recently, there has been an increasing adoption of differential privacy guided algorithms for privacy-preserving machine learning tasks. However, the use of such algorithms comes with trade-offs in terms of algorithmic fairness, which has been widely acknowledged. Specifically, we have empirically observed that the classical collaborative filtering method, trained by differentially private stochastic gradient descent (DP-SGD), results in a disparate impact on user groups with respect to different user engagement levels. This, in turn, causes the original unfair model to become even more biased against inactive users. To address the above issues, we propose \textbf{DP-Fair}, a two-stage framework for collaborative filtering based algorithms. Specifically, it combines differential privacy mechanisms with fairness constraints to protect user privacy while ensuring fair recommendations. The experimental results, based on Amazon datasets, and user history logs collected from Etsy, one of the largest e-commerce platforms, demonstrate that our proposed method exhibits superior performance in terms of both overall accuracy and user group fairness on both shallow and deep recommendation models compared to vanilla DP-SGD.|最近，在保护隐私的机器学习任务中越来越多地采用差分隐私指导算法。然而，这种算法的使用伴随着算法公平性方面的权衡，这已经得到了广泛的认可。具体来说，我们已经经验性地观察到，由差异私人协同过滤(DP-sgd)训练的经典随机梯度下降方法，在不同的用户参与水平方面对用户组产生了不同的影响。这反过来又导致原来的不公平模型对非活动用户变得更加有偏见。为了解决上述问题，我们提出 textbf { DP-fair } ，一个基于协同过滤的算法的两阶段框架。具体来说，它结合了差分隐私机制和公平约束，以保护用户隐私，同时确保公平推荐。基于 Amazon 数据集的实验结果，以及从最大的电子商务平台之一 Etsy 收集的用户历史记录表明，与普通的 DP-SGD 相比，我们提出的方法在浅层和深层推荐模型的总体准确性和用户组公平性方面表现出更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness-aware+Differentially+Private+Collaborative+Filtering)|0|
|[Psychotherapy AI Companion with Reinforcement Learning Recommendations and Interpretable Policy Dynamics](https://doi.org/10.1145/3543873.3587623)|Baihan Lin, Guillermo A. Cecchi, Djallel Bouneffouf|Columbia University, USA; IBM TJ Watson Research Center, USA|We introduce a Reinforcement Learning Psychotherapy AI Companion that generates topic recommendations for therapists based on patient responses. The system uses Deep Reinforcement Learning (DRL) to generate multi-objective policies for four different psychiatric conditions: anxiety, depression, schizophrenia, and suicidal cases. We present our experimental results on the accuracy of recommended topics using three different scales of working alliance ratings: task, bond, and goal. We show that the system is able to capture the real data (historical topics discussed by the therapists) relatively well, and that the best performing models vary by disorder and rating scale. To gain interpretable insights into the learned policies, we visualize policy trajectories in a 2D principal component analysis space and transition matrices. These visualizations reveal distinct patterns in the policies trained with different reward signals and trained on different clinical diagnoses. Our system's success in generating DIsorder-Specific Multi-Objective Policies (DISMOP) and interpretable policy dynamics demonstrates the potential of DRL in providing personalized and efficient therapeutic recommendations.|我们介绍一个强化学习的心理治疗 AI 指南，根据患者的反应为治疗师提供主题建议。该系统使用深度强化学习(DRL)为四种不同的精神疾病(焦虑症、抑郁症、精神分裂症和自杀病例)制定多目标政策。我们使用三种不同的工作联盟评分尺度(任务、联系和目标)对推荐话题的准确性进行了实验研究。我们表明，该系统能够相对较好地捕获真实数据(治疗师讨论的历史主题) ，并且表现最好的模型因障碍和评分尺度而异。为了获得对所学政策的可解释的见解，我们在二维主成分分析空间和转换矩阵中可视化政策轨迹。这些可视化显示了不同奖励信号训练和不同临床诊断训练的政策的不同模式。我们的系统在产生疾病特异性多目标政策(DISMOP)和可解释的政策动态方面的成功表明 DRL 在提供个性化和有效的治疗建议方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Psychotherapy+AI+Companion+with+Reinforcement+Learning+Recommendations+and+Interpretable+Policy+Dynamics)|0|
|[Investigating Action-Space Generalization in Reinforcement Learning for Recommendation Systems](https://doi.org/10.1145/3543873.3587661)|Abhishek Naik, Bo Chang, Alexandros Karatzoglou, Martin Mladenov, Ed H. Chi, Minmin Chen|University of Alberta, Canada and Alberta Machine Intelligence Institute (Amii), Canada; Google Research, USA|Recommender systems are used to suggest items to users based on the users’ preferences. Such systems often deal with massive item sets and incredibly sparse user-item interactions, which makes it very challenging to generate high-quality personalized recommendations. Reinforcement learning (RL) is a framework for sequential decision making and naturally formulates recommender-system tasks: recommending items as actions in different user and context states to maximize long-term user experience. We investigate two RL policy parameterizations that generalize sparse user-items interactions by leveraging the relationships between actions: parameterizing the policy over action features as a softmax or Gaussian distribution. Our experiments on synthetic problems suggest that the Gaussian parameterization—which is not commonly used on recommendation tasks—is more robust to the set of action features than the softmax parameterization. Based on these promising results, we propose a more thorough investigation of the theoretical properties and empirical benefits of the Gaussian parameterization for recommender systems.|推荐系统用于根据用户的喜好向用户推荐项目。这样的系统经常处理大量的项目集和难以置信的稀疏的用户-项目交互，这使得生成高质量的个性化推荐非常具有挑战性。推荐强化学习(RL)是一个连续决策的框架，它自然而然地制定了推荐系统的任务: 在不同的用户和上下文状态下，推荐项目作为行动，以最大限度地提高长期用户体验。我们研究了两种 RL 策略参数化，它们通过利用操作之间的关系来推广稀疏的用户-项目交互: 将策略参数化为 softmax 或者正态分布。我们在合成问题上的实验表明，高斯参数化(在推荐任务中并不常用)比 softmax 参量化对动作特征集的鲁棒性更强。基于这些有希望的结果，我们建议对高斯参量化推荐系统的理论特性和经验效益进行更深入的研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Action-Space+Generalization+in+Reinforcement+Learning+for+Recommendation+Systems)|0|
|[Conversion of Legal Agreements into Smart Legal Contracts using NLP](https://doi.org/10.1145/3543873.3587554)|Eason Chen, Niall Roche, YuenHsien Tseng, Walter Hernández, Jiangbo Shangguan, Alastair Moore|National Taiwan Normal University, Taiwan; University College London, United Kingdom; HSBC Business School, Peking University, United Kingdom|A Smart Legal Contract (SLC) is a specialized digital agreement comprising natural language and computable components. The Accord Project provides an open-source SLC framework containing three main modules: Cicero, Concerto, and Ergo. Currently, we need lawyers, programmers, and clients to work together with great effort to create a usable SLC using the Accord Project. This paper proposes a pipeline to automate the SLC creation process with several Natural Language Processing (NLP) models to convert law contracts to the Accord Project's Concerto model. After evaluating the proposed pipeline, we discovered that our NER pipeline accurately detects CiceroMark from Accord Project template text with an accuracy of 0.8. Additionally, our Question Answering method can extract one-third of the Concerto variables from the template text. We also delve into some limitations and possible future research for the proposed pipeline. Finally, we describe a web interface enabling users to build SLCs. This interface leverages the proposed pipeline to convert text documents to Smart Legal Contracts by using NLP models.|智能法律合同(SLC)是一种专门的数字协议，包括自然语言和可计算组件。Accord Project 提供了一个开源的 SLC 框架，其中包含三个主要模块: Cicero、 Concerto 和 Ergo。目前，我们需要律师、程序员和客户共同努力，使用 AccordProject 创建一个可用的 SLC。本文提出了一种使用多种自然语言处理(NLP)模型实现 SLC 创建过程自动化的流水线，将法律合同转换为 Accord Project 的 Concerto 模型。经过评估后，我们发现我们的 NER 流水线能够准确地从雅阁项目模板文本中检测到 CiceroMark，准确率为0.8。此外，我们的问题回答方法可以提取三分之一的协奏曲变量从模板文本。我们还深入探讨了一些局限性和可能的未来研究的建议管道。最后，我们描述了一个允许用户构建 SLC 的 Web 界面。该接口利用拟议的管道，通过使用 NLP 模型将文本文档转换为智能法律合同。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Conversion+of+Legal+Agreements+into+Smart+Legal+Contracts+using+NLP)|0|
|[Query-Driven Knowledge Graph Construction using Question Answering and Multimodal Fusion](https://doi.org/10.1145/3543873.3587567)|Yang Peng|University of Florida, USA|Over recent years, large knowledge bases have been constructed to store massive knowledge graphs. However, these knowledge graphs are highly incomplete. To solve this problem, we propose a web-based question answering system with multimodal fusion of unstructured and structured information, to fill in missing information for knowledge bases. To utilize unstructured information from the Web for knowledge graph construction, we design multimodal features and question templates to extract missing facts, which can achieve good quality with very few questions. The question answering system also employs structured information from knowledge bases, such as entity types and entity-to-entity relatedness, to help improve extraction quality. To improve system efficiency, we utilize a few query-driven techniques for web-based question answering to reduce the runtime and provide fast responses to user queries. Extensive experiments have been conducted to demonstrate the effectiveness and efficiency of our system.|近年来，人们建立了大型知识库来存储海量的知识图表。然而，这些知识图是非常不完整的。为了解决这一问题，我们提出了一种基于网络的非结构化和结构化信息多模态融合的问答系统，以填补知识库中缺失的信息。为了利用 Web 中的非结构化信息进行知识图的构造，我们设计了多模态特征和问题模板来提取缺失的事实，这样可以在很少的问题下获得很好的质量。问答系统还利用知识库中的结构化信息，如实体类型和实体间的相关性，以提高抽取质量。为了提高系统的效率，我们采用了一些基于查询驱动的网络问答技术，以减少运行时间，并提供快速响应用户的查询。通过大量的实验验证了该系统的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query-Driven+Knowledge+Graph+Construction+using+Question+Answering+and+Multimodal+Fusion)|0|
|[Decoding Prompt Syntax: Analysing its Impact on Knowledge Retrieval in Large Language Models](https://doi.org/10.1145/3543873.3587655)|Stephan Linzbach, Tim Tressel, Laura Kallmeyer, Stefan Dietze, Hajira Jabeen|GESIS Leibniz Institute for Social Sciences, Germany and Heinrich Heine University, Germany; Heinrich Heine University, Germany; GESIS Leibniz Institute for Social Sciences, Germany; GESIS Leibniz Institut für Sozialwissenschaften, Germany|Large Language Models (LLMs), with their advanced architectures and training on massive language datasets, contain unexplored knowledge. One method to infer this knowledge is through the use of cloze-style prompts. Typically, these prompts are manually designed because the phrasing of these prompts impacts the knowledge retrieval performance, even if the LLM encodes the desired information. In this paper, we study the impact of prompt syntax on the knowledge retrieval capacity of LLMs. We use a template-based approach to paraphrase simple prompts into prompts with a more complex grammatical structure. We then analyse the LLM performance for these structurally different but semantically equivalent prompts. Our study reveals that simple prompts work better than complex forms of sentences. The performance across the syntactical variations for simple relations (1:1) remains best, with a marginal decrease across different typologies. These results reinforce that simple prompt structures are more effective for knowledge retrieval in LLMs and motivate future research into the impact of prompt syntax on various tasks.|大型语言模型(LLM)具有先进的体系结构和对大量语言数据集的训练，包含了未开发的知识。一种推断这种知识的方法是通过使用完形填空式的提示。通常，这些提示是手动设计的，因为这些提示的措辞会影响知识检索性能，即使 LLM 对所需的信息进行了编码。本文研究了提示语法对 LLM 知识检索能力的影响。我们使用基于模板的方法将简单的提示转述为具有更复杂语法结构的提示。然后，我们分析这些结构不同但语义相等的提示符的 LLM 性能。我们的研究表明，简单的提示语比复杂的句子形式更有效。简单关系(1:1)的句法变化的表现仍然是最好的，不同类型之间的表现略有下降。这些结果强调了简单的提示结构对于 LLM 中的知识检索更有效，并且激发了对提示句法对各种任务的影响的进一步研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoding+Prompt+Syntax:+Analysing+its+Impact+on+Knowledge+Retrieval+in+Large+Language+Models)|0|
|[CS-TGN: Community Search via Temporal Graph Neural Networks](https://doi.org/10.1145/3543873.3587654)|Farnoosh Hashemi, Ali Behrouz, Milad Rezaei Hajidehi|University of British Columbia, Canada|Searching for local communities is an important research challenge that allows for personalized community discovery and supports advanced data analysis in various complex networks, such as the World Wide Web, social networks, and brain networks. The evolution of these networks over time has motivated several recent studies to identify local communities in temporal networks. Given any query nodes, Community Search aims to find a densely connected subgraph containing query nodes. However, existing community search approaches in temporal networks have two main limitations: (1) they adopt pre-defined subgraph patterns to model communities, which cannot find communities that do not conform to these patterns in real-world networks, and (2) they only use the aggregation of disjoint structural information to measure quality, missing the dynamic of connections and temporal properties. In this paper, we propose a query-driven Temporal Graph Convolutional Network (CS-TGN) that can capture flexible community structures by learning from the ground-truth communities in a data-driven manner. CS-TGN first combines the local query-dependent structure and the global graph embedding in each snapshot of the network and then uses a GRU cell with contextual attention to learn the dynamics of interactions and update node embeddings over time. We demonstrate how this model can be used for interactive community search in an online setting, allowing users to evaluate the found communities and provide feedback. Experiments on real-world temporal graphs with ground-truth communities validate the superior quality of the solutions obtained and the efficiency of our model in both temporal and interactive static settings.|搜索当地社区是一个重要的研究挑战，它允许个性化的社区发现，并支持各种复杂网络中的先进数据分析，如万维网、社交网络和大脑网络。随着时间的推移，这些网络的演变促使最近几项研究在时间网络中识别局部群落。给定任何查询节点，Community Search 的目标是找到一个包含查询节点的密集连接子图。然而，现有的时态网络中的社区搜索方法存在两个主要的局限性: (1)它们采用预定义的子图模式来模拟社区，在现实网络中不能找到不符合这些模式的社区; (2)它们只使用不相交的结构信息的聚合来度量质量，缺乏连接的动态性和时态性。本文提出了一种基于查询驱动的时态图卷积网络(CS-TGN) ，该网络通过以数据驱动的方式从地面真相社区中学习知识，可以捕获灵活的社区结构。TGN 首先将本地查询依赖结构和全局图嵌入到网络的每个快照中，然后利用一个具有上下文关注的 GRU 单元来学习交互的动态性，并随着时间的推移更新节点嵌入。我们展示了这个模型如何在在线环境中用于交互式社区搜索，允许用户评估找到的社区并提供反馈。在真实时间图上的实验结果验证了该模型在时间静态和交互静态环境下的优越性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CS-TGN:+Community+Search+via+Temporal+Graph+Neural+Networks)|0|
|[Learned Temporal Aggregations for Fraud Classification on E-Commerce Platforms](https://doi.org/10.1145/3543873.3587632)|Xiao Ling, David Yan, Bilal Alsallakh, Ashutosh Pandey, Manan Bakshi, Pamela Bhattacharya|Voxel AI, USA; North Carolina State University, USA; Meta, USA; Meta, Canada|Fraud and other types of adversarial behavior are serious problems on customer-to-customer (C2C) e-commerce platforms, where harmful behaviors by bad actors erode user trust and safety. Many modern e-commerce integrity systems utilize machine learning (ML) to detect fraud and bad actors. We discuss the practical problems faced by integrity systems which utilize data associated with user interactions with the platform. Specifically, we focus on the challenge of representing the user interaction events, and aggregating their features. We compare the performance of two paradigms to handle the feature temporality when training the ML models: hand-engineered temporal aggregation and a learned aggregation using a sequence encoder. We show that a model which learns a time-aggregation using a sequence encoder outperforms models trained on handcrafted aggregations on the fraud classification task with a real-world dataset.|欺诈和其他类型的对抗行为是 C2C 电子商务平台上的严重问题，不良行为者的有害行为侵蚀了用户的信任和安全。许多现代电子商务完整性系统利用机器学习(ML)来检测欺诈和不良行为者。我们讨论完整性系统所面临的实际问题，这些系统利用与平台的用户交互相关的数据。具体来说，我们关注的挑战是表示用户交互事件，并聚合它们的特性。在训练机器学习模型时，我们比较了两种模式处理特征时间的性能: 手工时间聚合和使用序列编码器的学习聚合。我们展示了一个使用序列编码器学习时间聚合的模型优于使用真实世界数据集进行欺诈分类任务的手工聚合训练的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learned+Temporal+Aggregations+for+Fraud+Classification+on+E-Commerce+Platforms)|0|
|[Decency and Decentralisation: Verifiable Decentralised Knowledge Graph Querying](https://doi.org/10.1145/3543873.3587635)|Aisling Third, John Domingue|Knowledge Media Institute, The Open University, United Kingdom|Increasing interest in decentralisation for data and processing on the Web brings with it the need to re-examine methods for verifying data and behaviour for scalable multi-party interactions. We consider factors relevant to verification of querying activity on knowledge graphs in a Trusted Decentralised Web, and set out ideas for future research in this area.|随着人们对数据地方分权和网络处理的兴趣日益增长，人们需要重新审视可扩展的多方交互的数据和行为验证方法。我们考虑了与可信分布式网络中知识图表查询活动验证相关的因素，并为这一领域的未来研究提出了一些想法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decency+and+Decentralisation:+Verifiable+Decentralised+Knowledge+Graph+Querying)|0|
|[Towards a Decentralized Data Hub and Query System for Federated Dynamic Data Spaces](https://doi.org/10.1145/3543873.3587646)|Danh Le Phuoc, Sonja Schimmler, Anh LeTuan, Uwe A. Kuehn, Manfred Hauswirth|TU Berlin, Germany; Fraunhofer Institute for Open Communication Systems, Berlin, Germany|This position paper proposes a hybrid architecture for secure and efficient data sharing and processing across dynamic data spaces. On the one hand, current centralized approaches are plagued by issues such as lack of privacy and control for users, high costs, and bad performance, making these approaches unsuitable for the decentralized data spaces prevalent in Europe and various industries (decentralized on the conceptual and physical levels while centralized in the underlying implementation). On the other hand, decentralized systems face challenges with limited knowledge of/control over the global system, fair resource utilization, and data provenance. Our proposed Semantic Data Ledger (SDL) approach combines the advantages of both architectures to overcome their limitations. SDL allows users to choose the best combination of centralized and decentralized features, providing a decentralized infrastructure for the publication of structured data with machine-readable semantics. It supports expressive structured queries, secure data sharing, and payment mechanisms based on an underlying autonomous ledger, enabling the implementation of economic models and fair-use strategies.|本文提出了一种跨动态数据空间的安全有效的数据共享和处理的混合体系结构。一方面，当前的集中式方法受到诸如用户缺乏隐私和控制、高成本和性能差等问题的困扰，使得这些方法不适合在欧洲和各种行业盛行的分散式数据空间(在概念和物理层面上分散，而在底层实现中集中)。另一方面，分散系统面临的挑战是对全球系统的了解和控制有限，资源利用不公平，数据来源不明确。我们提出的语义数据分类账(SDL)方法结合了两种体系结构的优点，克服了它们的局限性。SDL 允许用户选择集中和分散特性的最佳组合，为具有机器可读语义的结构化数据的发布提供分散的基础设施。它支持表达式结构化查询、安全数据共享和基于底层自治分类账的支付机制，使经济模型和合理使用策略的实施成为可能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Decentralized+Data+Hub+and+Query+System+for+Federated+Dynamic+Data+Spaces)|0|
|[What are "personal data spaces"?](https://doi.org/10.1145/3543873.3587656)|Viivi Lähteenoja|University of Helsinki, Finland and Aalto University, Finland|While the concept of “data spaces” is no longer new, its specific application to individuals and personal data management is still undeveloped. This short paper presents a vision for “personal data spaces” in the shape of a work-in-progress description of them and some of the conceptual and implementation features envisioned. It is offered for discussion, debate, and improvement by professionals, policymakers, and researchers operating in the intersection of data spaces and personal data management.|虽然“数据空间”的概念不再是新的，但它在个人和个人数据管理方面的具体应用仍然没有得到发展。这篇简短的论文提出了一个“个人数据空间”的愿景，其形式是一个在建的数据空间描述，以及所设想的一些概念和实现特征。它提供了讨论，辩论和改进的专业人士，决策者和研究人员在数据空间和个人数据管理的交叉运作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+are+"personal+data+spaces"?)|0|
|[TAPP: Defining standard provenance information for clinical research data and workflows - Obstacles and opportunities](https://doi.org/10.1145/3543873.3587562)|Kerstin Gierend, Judith A. H. Wodke, Sascha Genehr, Robert Gött, Ron Henkel, Frank Krüger, Markus Mandalka, Lea Michaelis, Alexander Scheuerlein, Max Schröder, Atinkut Zeleke, Dagmar Waltemath|Institute of Communications Engineering, University of Rostock, Germany; Medical Informatics Laboratory, University Medicine Greifswald, Germany; Core Unit Data Integration Center, University Medicine Greifswald, Germany; Rostock University Library, University of Rostock, Germany; Department of Biomedical Informatics, Center for Preventive Medicine and Digital Health, Medical Faculty Mannheim, Heidelberg University, Germany; Faculty of Engineering, Wismar University of Applied Sciences, Germany; Institute for Data Science, University of Greifswald, Germany; Medical Informatics Laboratory, MeDaX Group, University Medicine Greifswald, Germany|Data provenance has raised much attention across disciplines lately, as it has been shown that enrichment of data with provenance information leads to better credibility, renders data more FAIR fostering data reuse. Also, the biomedical domain has recognised the potential of provenance capture. However, several obstacles prevent efficient, automated, and machine-interpretable enrichment of biomedical data with provenance information, such as data heterogeneity, complexity, and sensitivity. Here, we explain how in Germany clinical data are transferred from hospital information systems into a data integration centre to enable secondary use of patient data and how it can be reused as research data. Considering the complex data infrastructures in hospitals, we indicate obstacles and opportunities when collecting provenance information along heterogeneous data processing pipelines. To express provenance data, we indicate the usage of the Fast Healthcare Interoperability Resource (FHIR) provenance resource for healthcare data. In addition, we consider already existing approaches from other research fields and standard communities. As a solution towards high-quality standardised clinical research data, we propose to develop a ’MInimal Requirements for Automated Provenance Information Enrichment’ (MIRAPIE) guideline. As a community project, MIRAPIE should generalise provenance information concepts to allow its world-wide applicability, possibly beyond the health care sector.|数据来源最近引起了跨学科的广泛关注，因为已经表明，用来源信息丰富数据可以提高可信度，使数据更加公平，促进数据重用。此外，生物医学领域已经认识到种源捕获的潜力。然而，一些障碍阻碍了生物医学数据的有效、自动化和机器可解释的来源信息的丰富，例如数据异构性、复杂性和敏感性。在这里，我们解释在德国如何将临床数据从医院信息系统转移到数据集成中心，以便能够对患者数据进行二次使用，以及如何将其重用为研究数据。考虑到医院复杂的数据基础设施，我们指出了沿着异构数据处理管道收集起源信息的障碍和机会。为了表示来源数据，我们指出了 Fast Healthcare Interoperability Resource (FHIR)来源资源对医疗数据的使用。此外，我们还考虑了来自其他研究领域和标准社区的已有方法。作为高质量标准化临床研究数据的解决方案，我们建议制定一个“自动起源信息丰富的最低要求”(MIRAPIE)指南。作为一个社区项目，MIRAPIE 应该推广起源信息的概念，使其在世界范围内适用，可能超出卫生保健部门。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TAPP:+Defining+standard+provenance+information+for+clinical+research+data+and+workflows+-+Obstacles+and+opportunities)|0|
|[ProSA: A provenance system for reproducing query results](https://doi.org/10.1145/3543873.3587563)|Tanja Auge|Faculty of Informatics and Data Science, University of Regensburg, Germany|Good scientific work requires comprehensible, transparent and reproducible research. One way to ensure this is to include all data relevant to a study or evaluation when publishing an article. This data should be at least aggregated or anonymized, at best compact and complete, but always resilient. In this paper we present ProSA, a system for calculating the minimal necessary data set, called sub-database. For this, we combine the Chase — a set of algorithms for transforming databases — with additional provenance information. We display the implementation of provenance guided by the ProSA pipeline and show its use to generate an optimized sub-database. Furhter, we demonstrate how the ProSA GUI looks like and present some applications and extensions.|好的科学工作需要可理解、透明和可重复的研究。确保这一点的一个方法是在发表文章时包括与研究或评估相关的所有数据。这些数据应该至少是聚合或匿名的，充其量是紧凑和完整的，但总是具有弹性。本文介绍了 ProSA，一个计算最小必要数据集的系统，称为子数据库。为此，我们将 Chase (一组转换数据库的算法)与其他来源信息结合起来。我们展示了 ProSA 流水线引导的起源实现，并展示了它用于生成优化的子数据库。进一步，我们将演示 ProSA GUI 的外观，并展示一些应用程序和扩展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ProSA:+A+provenance+system+for+reproducing+query+results)|0|
|[Hybrid Query and Instance Explanations and Repairs](https://doi.org/10.1145/3543873.3587565)|Seokki Lee, Boris Glavic, Adriane Chapman, Bertram Ludäscher|Illinois Institute of Technology, USA; University of Cincinnati, USA; University of Southampton, United Kingdom; University of Illinois at Urbana-Champaign, USA|Prior work on explaining missing (unexpected) query results identifies which parts of the query or data are responsible for the erroneous result or repairs the query or data to fix such errors. The problem of generating repairs is typically expressed as an optimization problem, i.e., a single repair is returned that is optimal wrt. to some criterion such as minimizing the repair’s side effects. However, such an optimization objective may not concretely model a user’s (often hard to formalize) notion of which repair is “correct”. In this paper, we motivate hybrid explanations and repairs, i.e., that fix both the query and the data. Instead of returning one “optimal” repair, we argue for an approach that empowers the user to explore the space of possible repairs effectively. We also present a proof-of-concept implementation and outline open research problems.|先前解释丢失(意外)查询结果的工作确定了查询或数据的哪些部分对错误结果负责，或者修复查询或数据以修复此类错误。产生维修的问题通常表示为一个最佳化问题，也就是说，一个单一的维修被返回，这是最优的书面意见，以某些标准，如最小化维修的副作用。然而，这样的优化目标可能无法具体地模拟用户(通常很难形式化)的哪种修复是“正确的”概念。在本文中，我们激励混合解释和修复，即，修复查询和数据。与返回一个“最佳”修复相反，我们主张采用一种方法，使用户能够有效地探索可能的修复空间。我们还提出了一个概念验证实现，并概述了开放式研究问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hybrid+Query+and+Instance+Explanations+and+Repairs)|0|
|[Querying Container Provenance](https://doi.org/10.1145/3543873.3587568)|Aniket Modi, Moaz Reyad, Tanu Malik, Ashish Gehani|College of Computing and Digital Media, DePaul University, USA and Department of Computer Science and Engineering, IIT Delhi, India; College of Computing and Digital Media, DePaul University, USA; SRI International, USA|Containers are lightweight mechanisms for the isolation of operating system resources. They are realized by activating a set of namespaces. Given the use of containers in scientific computing, tracking and managing provenance within and across containers is becoming essential for debugging and reproducibility. In this work, we examine the properties of container provenance graphs that result from auditing containerized applications. We observe that the generated container provenance graphs are hypergraphs because one resource may belong to one or more namespaces. We examine the hierarchical behavior of PID, mount, and user namespaces, that are more commonly activated and show that even when represented as hypergraphs, the resulting container provenance graphs are acyclic. We experiment with recently published container logs and identify hypergraph properties.|容器是用于隔离操作系统资源的轻量级机制。它们是通过激活一组名称空间来实现的。鉴于容器在科学计算中的使用，跟踪和管理容器内部和跨容器的出处对于调试和再现性变得至关重要。在本文中，我们研究了审计容器化应用程序所产生的容器起源图的属性。我们注意到，生成的容器起源图是超图，因为一个资源可能属于一个或多个名称空间。我们研究了 PID、 mount 和用户名称空间的分层行为，这些名称空间通常被激活，并且表明即使用超图表示，最终的容器起源图也是无环的。我们使用最近发布的容器日志进行实验，并识别超图属性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Querying+Container+Provenance)|0|
|[Graph-less Collaborative Filtering](https://doi.org/10.1145/3543507.3583196)|Lianghao Xia, Chao Huang, Jiao Shi, Yong Xu|The University of Hong Kong, Hong Kong; South China University of Technology, China|Graph neural networks (GNNs) have shown the power in representation learning over graph-structured user-item interaction data for collaborative filtering (CF) task. However, with their inherently recursive message propagation among neighboring nodes, existing GNN-based CF models may generate indistinguishable and inaccurate user (item) representations due to the over-smoothing and noise effect with low-pass Laplacian smoothing operators. In addition, the recursive information propagation with the stacked aggregators in the entire graph structures may result in poor scalability in practical applications. Motivated by these limitations, we propose a simple and effective collaborative filtering model (SimRec) that marries the power of knowledge distillation and contrastive learning. In SimRec, adaptive transferring knowledge is enabled between the teacher GNN model and a lightweight student network, to not only preserve the global collaborative signals, but also address the over-smoothing issue with representation recalibration. Empirical results on public datasets show that SimRec archives better efficiency while maintaining superior recommendation performance compared with various strong baselines. Our implementations are publicly available at: https://github.com/HKUDS/SimRec.|图形神经网络(GNN)已经显示了在表示学习方面的能力，超过了图形结构的用户-项目交互数据的协同过滤(CF)任务。然而，由于现有的基于 GNN 的 CF 模型固有的相邻节点之间的递归消息传播特性，由于低通拉普拉斯平滑算子的过平滑和噪声效应，可能产生难以区分和不准确的用户(项)表示。此外，在整个图结构中，叠加聚合器的递归信息传播可能导致实际应用中的可扩展性较差。基于这些局限性，我们提出了一个简单有效的协同过滤模型(SimRec) ，它将知识提取和对比学习的力量结合在一起。在 SimRec 中，在教师 GNN 模型和轻量级学生网络之间实现了自适应知识传递，不仅保留了全局协作信号，而且通过表示重校正解决了过于平滑的问题。对公共数据集的实证结果表明，与各种强基线相比，SimRec 在保持优异推荐性能的同时提高了存档效率。我们的实施方案可以在以下 https://github.com/hkuds/simrec 公开获得:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-less+Collaborative+Filtering)|0|
|[Collaboration-Aware Graph Convolutional Network for Recommender Systems](https://doi.org/10.1145/3543507.3583229)|Yu Wang, Yuying Zhao, Yi Zhang, Tyler Derr|Vanderbilt university, USA|Graph Neural Networks (GNNs) have been successfully adopted in recommender systems by virtue of the message-passing that implicitly captures collaborative effect. Nevertheless, most of the existing message-passing mechanisms for recommendation are directly inherited from GNNs without scrutinizing whether the captured collaborative effect would benefit the prediction of user preferences. In this paper, we first analyze how message-passing captures the collaborative effect and propose a recommendation-oriented topological metric, Common Interacted Ratio (CIR), which measures the level of interaction between a specific neighbor of a node with the rest of its neighbors. After demonstrating the benefits of leveraging collaborations from neighbors with higher CIR, we propose a recommendation-tailored GNN, Collaboration-Aware Graph Convolutional Network (CAGCN), that goes beyond 1-Weisfeiler-Lehman(1-WL) test in distinguishing non-bipartite-subgraph-isomorphic graphs. Experiments on six benchmark datasets show that the best CAGCN variant outperforms the most representative GNN-based recommendation model, LightGCN, by nearly 10% in Recall@20 and also achieves around 80% speedup. Our code is publicly available at https://github.com/YuWVandy/CAGCN.|图形神经网络(GNN)通过隐式捕捉协作效果的消息传递，已成功地应用于推荐系统中。尽管如此，大多数现有的推荐信息传递机制都是直接从 GNN 继承而来的，没有仔细检查所捕获的协作效应是否有利于预测用户的偏好。在本文中，我们首先分析了消息传递是如何捕获协作效果的，并提出了一个面向推荐的拓扑度量，公共交互比(CIR) ，它测量节点的特定邻居与其他邻居之间的交互水平。在证明了利用具有较高 CIR 的邻居的协作的好处之后，我们提出了一种推荐量身定制的 GNN，协作感知图卷积网络(CAGCN) ，其超越了1-Weisfeiler-Lehman (1-WL)检验在区分非二部子图-同构图。在六个基准数据集上的实验表明，在 Recall@20中，最好的 CAGCN 变体比最具代表性的基于 GNN 的推荐模型 LightGCN 的性能提高了近10% ，并且还实现了约80% 的加速比。我们的代码可以在 https://github.com/yuwvandy/cagcn 上公开获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaboration-Aware+Graph+Convolutional+Network+for+Recommender+Systems)|0|
|[HyConvE: A Novel Embedding Model for Knowledge Hypergraph Link Prediction with Convolutional Neural Networks](https://doi.org/10.1145/3543507.3583256)|Chenxu Wang, Xin Wang, Zhao Li, Zirui Chen, Jianxin Li|Deakin University, Australia; Tianjin University, China|Knowledge hypergraph embedding, which projects entities and n-ary relations into a low-dimensional continuous vector space to predict missing links, remains a challenging area to be explored despite the ubiquity of n-ary relational facts in the real world. Currently, knowledge hypergraph link prediction methods are essentially simple extensions of those used in knowledge graphs, where n-ary relational facts are decomposed into different subelements. Convolutional neural networks have been shown to have remarkable information extraction capabilities in previous work on knowledge graph link prediction. In this paper, we propose a novel embedding-based knowledge hypergraph link prediction model named HyConvE, which exploits the powerful learning ability of convolutional neural networks for effective link prediction. Specifically, we employ 3D convolution to capture the deep interactions of entities and relations to efficiently extract explicit and implicit knowledge in each n-ary relational fact without compromising its translation property. In addition, appropriate relation and position-aware filters are utilized sequentially to perform two-dimensional convolution operations to capture the intrinsic patterns and position information in each n-ary relation, respectively. Extensive experimental results on real datasets of knowledge hypergraphs and knowledge graphs demonstrate the superior performance of HyConvE compared with state-of-the-art baselines.|知识超图嵌入将实体和 n 元关系投影到低维连续向量空间中以预测缺失的链接，尽管 n 元关系事实在现实世界中无处不在，但仍然是一个有待探索的挑战领域。目前，知识超图链接预测方法基本上是知识图的简单扩展，其中 n 元关系事实被分解为不同的子元素。卷积神经网络已被证明具有显著的信息抽取能力在以前的工作中的知识图链接预测。本文提出了一种新的基于嵌入的知识超图链接预测模型 HyConve，该模型利用卷积神经网络强大的学习能力进行有效的链接预测。具体来说，我们使用三维卷积来捕捉实体和关系的深层交互作用，以有效地提取每个 n 元关系事实中的显性和隐性知识，而不损害其翻译性质。此外，还利用合适的关系和位置感知滤波器，分别进行二维卷积运算，捕获每个 n 元关系中的内在模式和位置信息。在知识超图和知识图的实际数据集上进行的大量实验结果表明，与最先进的基线相比，HyConve 方法具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyConvE:+A+Novel+Embedding+Model+for+Knowledge+Hypergraph+Link+Prediction+with+Convolutional+Neural+Networks)|0|
|[Efficient Approximation Algorithms for the Diameter-Bounded Max-Coverage Group Steiner Tree Problem](https://doi.org/10.1145/3543507.3583257)|Ke Zhang, Xiaoqing Wang, Gong Cheng|State Key Laboratory for Novel Software Technology, Nanjing University, China|The Diameter-bounded max-Coverage Group Steiner Tree (DCGST) problem has recently been proposed as an expressive way of formulating keyword-based search and exploration of knowledge graphs. It aims at finding a diameter-bounded tree which covers the most given groups of vertices and has the minimum weight. In contrast to its specialization—the classic Group Steiner Tree (GST) problem which has been extensively studied, the emerging DCGST problem still lacks an efficient algorithm. In this paper, we propose Cba, the first approximation algorithm for the DCGST problem, and we prove its worst-case approximation ratio. Furthermore, we incorporate a best-first search strategy with two pruning methods into PrunedCBA, an improved approximation algorithm. Our extensive experiments on real and synthetic graphs demonstrate the effectiveness and efficiency of PrunedCBA.|直径有界的最大覆盖群 Steiner 树(DCGST)问题是近年来提出的一种基于关键字搜索和知识图探索的表示方法。它的目标是找到一个直径有界的树，它覆盖了最多给定的顶点群，并具有最小的权重。与经典的群 Steiner 树(GST)问题相比，新出现的 DCGST 问题仍然缺乏一种有效的算法。在这篇文章中，我们提出了 Cba，这是 DCGST 问题的第一个近似演算法，并且证明了它的最坏情况逼近比。此外，我们将最佳优先搜索策略和两种修剪方法结合到一个改进的近似演算法 PrunedCBA 中。我们在实图和合成图上的大量实验证明了 PrunedCBA 的有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Approximation+Algorithms+for+the+Diameter-Bounded+Max-Coverage+Group+Steiner+Tree+Problem)|0|
|[ConsRec: Learning Consensus Behind Interactions for Group Recommendation](https://doi.org/10.1145/3543507.3583277)|Xixi Wu, Yun Xiong, Yao Zhang, Yizhu Jiao, Jiawei Zhang, Yangyong Zhu, Philip S. Yu|University of Illinois at Chicago, USA; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, China; IFM Lab, Department of Computer Science, University of California, Davis, USA; University of Illinois at Urbana-Champaign, USA|Since group activities have become very common in daily life, there is an urgent demand for generating recommendations for a group of users, referred to as group recommendation task. Existing group recommendation methods usually infer groups' preferences via aggregating diverse members' interests. Actually, groups' ultimate choice involves compromises between members, and finally, an agreement can be reached. However, existing individual information aggregation lacks a holistic group-level consideration, failing to capture the consensus information. Besides, their specific aggregation strategies either suffer from high computational costs or become too coarse-grained to make precise predictions. To solve the aforementioned limitations, in this paper, we focus on exploring consensus behind group behavior data. To comprehensively capture the group consensus, we innovatively design three distinct views which provide mutually complementary information to enable multi-view learning, including member-level aggregation, item-level tastes, and group-level inherent preferences. To integrate and balance the multi-view information, an adaptive fusion component is further proposed. As to member-level aggregation, different from existing linear or attentive strategies, we design a novel hypergraph neural network that allows for efficient hypergraph convolutional operations to generate expressive member-level aggregation. We evaluate our ConsRec on two real-world datasets and experimental results show that our model outperforms state-of-the-art methods. An extensive case study also verifies the effectiveness of consensus modeling.|由于小组活动在日常生活中已经非常普遍，因此迫切需要为一组用户提供建议，称为小组推荐任务。现有的群体推荐方法通常通过聚合不同成员的兴趣来推断群体的偏好。实际上，团体的最终选择包括成员之间的妥协，最终可以达成协议。然而，现有的个人信息聚合缺乏整体的群体层面的考虑，未能捕获共识信息。此外，他们特定的聚合策略要么计算成本高，要么过于粗粒度，无法做出精确的预测。为了解决上述局限性，本文重点探讨群体行为数据背后的共识。为了全面捕捉群体共识，我们创新性地设计了三种不同的视图，提供相互补充的信息，使多视图学习成为可能，包括成员层面的聚合、项目层面的品味和群体层面的固有偏好。为了对多视点信息进行集成和平衡，进一步提出了一种自适应融合构件。对于成员级聚集，不同于现有的线性或注意策略，我们设计了一种新的超图神经网络，该网络允许有效的超图卷积操作来产生具有表达能力的成员级聚集。我们在两个真实世界的数据集上评估了我们的 ConsRec，实验结果表明我们的模型优于最先进的方法。一个广泛的案例研究也验证了一致性建模的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ConsRec:+Learning+Consensus+Behind+Interactions+for+Group+Recommendation)|0|
|[Graph Neural Networks with Diverse Spectral Filtering](https://doi.org/10.1145/3543507.3583324)|Jingwei Guo, Kaizhu Huang, Xinping Yi, Rui Zhang|The University of Liverpool, United Kingdom; Xi'an Jiaotong-Liverpool University; The University of Liverpool, China; Duke Kunshan University, China; Xi'an Jiaotong-Liverpool University, China|Spectral Graph Neural Networks (GNNs) have achieved tremendous success in graph machine learning, with polynomial filters applied for graph convolutions, where all nodes share the identical filter weights to mine their local contexts. Despite the success, existing spectral GNNs usually fail to deal with complex networks (e.g., WWW) due to such homogeneous spectral filtering setting that ignores the regional heterogeneity as typically seen in real-world networks. To tackle this issue, we propose a novel diverse spectral filtering (DSF) framework, which automatically learns node-specific filter weights to exploit the varying local structure properly. Particularly, the diverse filter weights consist of two components — A global one shared among all nodes, and a local one that varies along network edges to reflect node difference arising from distinct graph parts — to balance between local and global information. As such, not only can the global graph characteristics be captured, but also the diverse local patterns can be mined with awareness of different node positions. Interestingly, we formulate a novel optimization problem to assist in learning diverse filters, which also enables us to enhance any spectral GNNs with our DSF framework. We showcase the proposed framework on three state-of-the-arts including GPR-GNN, BernNet, and JacobiConv. Extensive experiments over 10 benchmark datasets demonstrate that our framework can consistently boost model performance by up to 4.92% in node classification tasks, producing diverse filters with enhanced interpretability.|谱图神经网络(GNN)在图形机器学习中取得了巨大的成功，其中多项式滤波器应用于图卷积，其中所有节点共享相同的滤波器权重来挖掘它们的局部上下文。尽管已有的光谱 GNN 在处理复杂网络(如 WWW)时取得了一定的成功，但由于均匀的光谱滤波设置忽略了现实网络中典型的区域异质性，导致 GNN 无法处理复杂网络(如 WWW)。针对这一问题，我们提出了一种新的多谱段滤波(DSF)框架，该框架能够自动学习节点特定的滤波器权值，以适当地利用变化的局部结构。特别地，不同的滤波器权重由两部分组成: 一部分是所有节点共享的全局权重，另一部分是沿网络边缘变化的局部权重，以反映不同图部分产生的节点差异，从而平衡局部和全局信息。因此，不仅可以捕获全局图的特征，而且可以挖掘不同节点位置的不同局部模式。有趣的是，我们制定了一个新的最佳化问题，以帮助学习不同的过滤器，这也使我们能够增强任何光谱 GNN 与我们的 dSF 框架。我们在 GPR-GNN、 BernNet 和 JacobiConv 这三种最新技术的基础上展示了提议的框架。通过对10个基准数据集的大量实验表明，我们的框架可以在节点分类任务中始终如一地将模型性能提高高达4.92% ，产生具有增强可解释性的多样化过滤器。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks+with+Diverse+Spectral+Filtering)|0|
|[Semi-decentralized Federated Ego Graph Learning for Recommendation](https://doi.org/10.1145/3543507.3583337)|Liang Qu, Ningzhi Tang, Ruiqi Zheng, Quoc Viet Hung Nguyen, Zi Huang, Yuhui Shi, Hongzhi Yin|Griffith University, Australia; Southern University of Science and Technology, China; The University of Queensland, Australia|Collaborative filtering (CF) based recommender systems are typically trained based on personal interaction data (e.g., clicks and purchases) that could be naturally represented as ego graphs. However, most existing recommendation methods collect these ego graphs from all users to compose a global graph to obtain high-order collaborative information between users and items, and these centralized CF recommendation methods inevitably lead to a high risk of user privacy leakage. Although recently proposed federated recommendation systems can mitigate the privacy problem, they either restrict the on-device local training to an isolated ego graph or rely on an additional third-party server to access other ego graphs resulting in a cumbersome pipeline, which is hard to work in practice. In addition, existing federated recommendation systems require resource-limited devices to maintain the entire embedding tables resulting in high communication costs.   In light of this, we propose a semi-decentralized federated ego graph learning framework for on-device recommendations, named SemiDFEGL, which introduces new device-to-device collaborations to improve scalability and reduce communication costs and innovatively utilizes predicted interacted item nodes to connect isolated ego graphs to augment local subgraphs such that the high-order user-item collaborative information could be used in a privacy-preserving manner. Furthermore, the proposed framework is model-agnostic, meaning that it could be seamlessly integrated with existing graph neural network-based recommendation methods and privacy protection techniques. To validate the effectiveness of the proposed SemiDFEGL, extensive experiments are conducted on three public datasets, and the results demonstrate the superiority of the proposed SemiDFEGL compared to other federated recommendation methods.|基于协同过滤(CF)的推荐系统通常基于个人交互数据(例如点击和购买)进行培训，这些数据可以自然地表示为自我图表。然而，现有的大多数推荐方法都是从所有用户中收集这些自我图来构成一个全局图，以获得用户和项目之间的高阶协同信息，而这些集中式的 CF 推荐方法不可避免地会导致用户隐私泄露的高风险。虽然最近提出的联邦推荐系统可以缓解隐私问题，但是它们要么将设备上的本地培训限制在一个孤立的自我图上，要么依赖于另外一个第三方服务器来访问其他自我图，从而产生一个繁琐的管道，这在实践中很难实现。此外，现有的联邦推荐系统需要资源有限的设备来维护整个嵌入表，从而导致高通信成本。鉴于此，我们提出了一个半分散的联邦自我图学习框架 SemiDFEGL，该框架引入了新的设备间协作以提高可扩展性和降低通信成本，并创新地利用预测的交互项节点连接孤立的自我图以增强局部子图，从而可以以保护隐私的方式使用高阶用户项协作信息。此外，提出的框架是模型无关的，这意味着它可以与现有的基于图神经网络的推荐方法和隐私保护技术无缝集成。为了验证半 DFEGL 的有效性，在三个公共数据集上进行了广泛的实验，实验结果表明了半 DFEGL 相对于其他联邦推荐方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-decentralized+Federated+Ego+Graph+Learning+for+Recommendation)|0|
|[SINCERE: Sequential Interaction Networks representation learning on Co-Evolving RiEmannian manifolds](https://doi.org/10.1145/3543507.3583353)|Junda Ye, Zhongbao Zhang, Li Sun, Yang Yan, Feiyang Wang, Fuxin Ren|North China Electric Power University, China; Beijing University of Posts and Telecommunications, China|Sequential interaction networks (SIN) have been commonly adopted in many applications such as recommendation systems, search engines and social networks to describe the mutual influence between users and items/products. Efforts on representing SIN are mainly focused on capturing the dynamics of networks in Euclidean space, and recently plenty of work has extended to hyperbolic geometry for implicit hierarchical learning. Previous approaches which learn the embedding trajectories of users and items achieve promising results. However, there are still a range of fundamental issues remaining open. For example, is it appropriate to place user and item nodes in one identical space regardless of their inherent discrepancy? Instead of residing in a single fixed curvature space, how will the representation spaces evolve when new interaction occurs? To explore these issues for sequential interaction networks, we propose SINCERE, a novel method representing Sequential Interaction Networks on Co-Evolving RiEmannian manifolds. SIN- CERE not only takes the user and item embedding trajectories in respective spaces into account, but also emphasizes on the space evolvement that how curvature changes over time. Specifically, we introduce a fresh cross-geometry aggregation which allows us to propagate information across different Riemannian manifolds without breaking conformal invariance, and a curvature estimator which is delicately designed to predict global curvatures effectively according to current local Ricci curvatures. Extensive experiments on several real-world datasets demonstrate the promising performance of SINCERE over the state-of-the-art sequential interaction prediction methods.|在推荐系统、搜索引擎、社交网络等应用中，用户与产品之间的相互影响通常采用序贯交互网络(SIN)来描述。表示 SIN 的努力主要集中在捕捉欧几里得空间中网络的动态，最近大量的工作已经延伸到了隐含双曲几何的深度学习。以往的方法通过学习用户和项目的嵌入轨迹，取得了良好的效果。然而，仍有一系列基本问题悬而未决。例如，是否应该将用户和项目节点放在一个相同的空间中，而不管它们的固有差异？当发生新的相互作用时，表示空间将如何演化，而不是驻留在一个单一的固定曲率空间中？为了研究序贯相互作用网络的这些问题，我们提出了一种新的方法 SINCARE，它在共进化黎曼流形上表示序贯相互作用网络。SIN-CERE 不仅考虑了用户和项目在各自空间中的嵌入轨迹，而且强调了曲率随时间变化的空间演化。具体地说，我们引入了一个新的交叉几何聚合，它允许我们在不破坏共形不变性的情况下在不同的黎曼流形上传播信息，以及一个精心设计的曲率估计器，它可以根据当前的局部 Ricci 曲率有效地预测全局曲率。在几个真实世界数据集上的大量实验表明，SINCARE 相对于最先进的顺序交互预测方法具有很好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SINCERE:+Sequential+Interaction+Networks+representation+learning+on+Co-Evolving+RiEmannian+manifolds)|0|
|[TIGER: Temporal Interaction Graph Embedding with Restarts](https://doi.org/10.1145/3543507.3583433)|Yao Zhang, Yun Xiong, Yongxiang Liao, Yiheng Sun, Yucheng Jin, Xuehao Zheng, Yangyong Zhu|Tencent Weixin Group, China; Fudan University, China|Temporal interaction graphs (TIGs), consisting of sequences of timestamped interaction events, are prevalent in fields like e-commerce and social networks. To better learn dynamic node embeddings that vary over time, researchers have proposed a series of temporal graph neural networks for TIGs. However, due to the entangled temporal and structural dependencies, existing methods have to process the sequence of events chronologically and consecutively to ensure node representations are up-to-date. This prevents existing models from parallelization and reduces their flexibility in industrial applications. To tackle the above challenge, in this paper, we propose TIGER, a TIG embedding model that can restart at any timestamp. We introduce a restarter module that generates surrogate representations acting as the warm initialization of node representations. By restarting from multiple timestamps simultaneously, we divide the sequence into multiple chunks and naturally enable the parallelization of the model. Moreover, in contrast to previous models that utilize a single memory unit, we introduce a dual memory module to better exploit neighborhood information and alleviate the staleness problem. Extensive experiments on four public datasets and one industrial dataset are conducted, and the results verify both the effectiveness and the efficiency of our work.|时间交互图(TIGs)由时间戳交互事件序列组成，在电子商务和社交网络等领域非常普遍。为了更好地学习随时间变化的动态节点嵌入，研究人员提出了一系列针对 TIG 的时间图神经网络。然而，由于时间和结构的依赖性，现有的方法必须按时间顺序和连续地处理事件序列，以确保节点表示是最新的。这阻止了现有模型的并行化，并降低了它们在工业应用程序中的灵活性。为了应对上述挑战，本文提出了一种 TIG 嵌入模型 TIGER，它可以在任意时间戳重新启动。我们引入了一个 restarter 模块，它生成代理表示作为节点表示的温初始化。通过同时从多个时间戳重新开始，我们将序列划分为多个块，自然而然地实现了模型的并行化。此外，相对于以往的单一存储器模型，我们引入了双存储器模块，以更好地利用邻域信息和缓解过时问题。对四个公共数据集和一个工业数据集进行了广泛的实验，实验结果验证了本文工作的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TIGER:+Temporal+Interaction+Graph+Embedding+with+Restarts)|0|
|[Expressive and Efficient Representation Learning for Ranking Links in Temporal Graphs](https://doi.org/10.1145/3543507.3583476)|Susheel Suresh, Mayank Shrivastava, Arko Mukherjee, Jennifer Neville, Pan Li|Purdue University, USA; Microsoft, USA; Microsoft Research, USA|Temporal graph representation learning (T-GRL) aims to learn representations that model how graph edges evolve over time. While recent works on T-GRL have improved link prediction accuracy in temporal settings, their methods optimize a point-wise loss function independently over future links rather than optimize jointly over a candidate set per node. In applications where resources (e.g., attention) are allocated based on ranking links by likelihood, the use of a ranking loss is preferred. However it is not straightforward to develop a T-GRL method to optimize a ranking loss due to a tradeoff between model expressivity and scalability. In this work, we address these issues and propose a Temporal Graph network for Ranking (TGRank), which significantly improves performance for link prediction tasks by (i) optimizing a list-wise loss for improved ranking, and (ii) incorporating a labeling approach designed to allow for efficient inference over the candidate set jointly, while provably boosting expressivity. We extensively evaluate TGRank over six real networks. TGRank outperforms the state-of-the-art baselines on average by 14.21%↑ (transductive) and 16.25% ↑ (inductive) in ranking metrics while being more efficient (up-to 65 × speed-up) to make inference on large networks.|时态图表示学习(T-GRL)的目的是学习模拟图边如何随时间演化的表示。尽管最近在 T-GRL 上的工作在时间设置上提高了链路预测的精度，但是他们的方法在未来链路上独立优化点损失函数，而不是在每个节点的候选集上联合优化。在应用程序中，资源(如注意力)的分配是基于可能性的排名链接，使用排名损失是首选。然而，由于模型表达性和可伸缩性之间的权衡，开发 T-GRL 方法来优化排名损失并不容易。在这项工作中，我们解决了这些问题，并提出了排名时态图网络(TGRank) ，它通过(i)优化改善排名的列表损失，以及(ii)结合标记方法，以便对候选集合进行有效的推理，同时可证明地提高表现力，从而显着改善链接预测任务的性能。我们广泛评估 TGRank 在六个实际网络。TGRank 在排序指标方面平均比最先进的基线表现出14.21% 惊(转导)和16.25% 惊(归纳)的优势，同时在大型网络上进行推理的效率更高(高达65倍加速)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Expressive+and+Efficient+Representation+Learning+for+Ranking+Links+in+Temporal+Graphs)|0|
|[Semi-Supervised Embedding of Attributed Multiplex Networks](https://doi.org/10.1145/3543507.3583485)|Ylli Sadikaj, Justus Rass, Yllka Velaj, Claudia Plant|Faculty of Computer Science, University of Vienna, Austria; Faculty of Computer Science, University of Vienna, Austria and UniVie Doctoral School Computer Science, University of Vienna, Austria; Faculty of Computer Science, University of Vienna, Austria and ds:Univie, University of Vienna, Austria|Complex information can be represented as networks (graphs) characterized by a large number of nodes, multiple types of nodes, and multiple types of relationships between them, i.e. multiplex networks. Additionally, these networks are enriched with different types of node features. We propose a Semi-supervised Embedding approach for Attributed Multiplex Networks (SSAMN), to jointly embed nodes, node attributes, and node labels of multiplex networks in a low dimensional space. Network embedding techniques have garnered research attention for real-world applications. However, most existing techniques solely focus on learning the node embeddings, and only a few learn class label embeddings. Our method assumes that we have different classes of nodes and that we know the class label of some, very few nodes for every class. Guided by this type of supervision, SSAMN learns a low-dimensional representation incorporating all information in a large labeled multiplex network. SSAMN integrates techniques from Spectral Embedding and Homogeneity Analysis to improve the embedding of nodes, node attributes, and node labels. Our experiments demonstrate that we only need very few labels per class in order to have a final embedding that preservers the information of the graph. To evaluate the performance of SSAMN, we run experiments on four real-world datasets. The results show that our approach outperforms state-of-the-art methods for downstream tasks such as semi-supervised node classification and node clustering.|复杂的信息可以用网络(图形)来表示，拥有属性包括大量的节点、多种类型的节点以及它们之间多种类型的关系，即多路网络。此外，这些网络丰富了不同类型的节点特征。提出了一种基于半监督嵌入的属性化多路网络(SSAMN)方法，在低维空间中联合嵌入多路网络的节点、节点属性和节点标签。网络嵌入技术已经成为现实应用领域的研究热点。然而，大多数现有的技术只关注于学习节点嵌入，只有少数学习类标签嵌入。我们的方法假设我们有不同的节点类，并且我们知道每个类的一些非常少的节点的类标签。在这种类型的监督指导下，SSAMN 学习了一种低维表示，将所有信息整合到一个大的标记多路网络中。SSAMN 集成了谱嵌入和均匀性分析技术，改进了节点、节点属性和节点标签的嵌入。我们的实验表明，我们只需要非常少的标签每个类，以便有一个最终的嵌入，保存图的信息。为了评估 SSAMN 的表现，我们在四个真实世界的数据集上进行了实验。结果表明，该方法在处理半监督节点分类和节点聚类等下游任务时，性能优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-Supervised+Embedding+of+Attributed+Multiplex+Networks)|0|
|[Search to Capture Long-range Dependency with Stacking GNNs for Graph Classification](https://doi.org/10.1145/3543507.3583486)|Lanning Wei, Zhiqiang He, Huan Zhao, Quanming Yao|Institute of Computing Technology, Chinese Academy of Sciences, China and University of Chinese Academy of Sciences, China; Institute of Computing Technology, Chinese Academy of Science, China and Lenovo, China; 4Paradigm. Inc, China; Department of Electronic Engineering, Tsinghua University, China|In recent years, Graph Neural Networks (GNNs) have been popular in the graph classification task. Currently, shallow GNNs are more common due to the well-known over-smoothing problem facing deeper GNNs. However, they are sub-optimal without utilizing the information from distant nodes, i.e., the long-range dependencies. The mainstream methods in the graph classification task can extract the long-range dependencies either by designing the pooling operations or incorporating the higher-order neighbors, while they have evident drawbacks by modifying the original graph structure, which may result in information loss in graph structure learning. In this paper, by justifying the smaller influence of the over-smoothing problem in the graph classification task, we evoke the importance of stacking-based GNNs and then employ them to capture the long-range dependencies without modifying the original graph structure. To achieve this, two design needs are given for stacking-based GNNs, i.e., sufficient model depth and adaptive skip-connection schemes. By transforming the two design needs into designing data-specific inter-layer connections, we propose a novel approach with the help of neural architecture search (NAS), which is dubbed LRGNN (Long-Range Graph Neural Networks). Extensive experiments on five datasets show that the proposed LRGNN can achieve the best performance, and obtained data-specific GNNs with different depth and skip-connection schemes, which can better capture the long-range dependencies.|近年来，图形神经网络(GNN)在图形分类任务中得到了广泛的应用。目前，浅 GNN 更常见，由于众所周知的过度平滑问题所面临的深 GNN。然而，如果没有利用来自远程节点的信息(即远程依赖) ，它们就是次优的。图分类任务中的主流方法可以通过设计合并操作或合并高阶邻居来提取远程依赖关系，但通过修改原有的图结构存在明显的缺陷，可能导致图结构学习中的信息丢失。本文通过证明过平滑问题在图分类任务中的影响较小，引出了基于叠加的 GNN 的重要性，并利用它们在不改变原始图结构的情况下捕获长程依赖关系。为了实现这一目标，给出了基于叠加的 GNN 的两种设计需求，即充分的模型深度和自适应跳跃连接方案。通过将这两种设计需求转化为设计数据特定的层间连接，我们提出了一种神经结构搜索(NAS)的新方法，称为长程图形神经网络(LRGNN)。通过对5个数据集的大量实验表明，本文提出的 LRGNN 能够获得最好的性能，并且能够获得具有不同深度和跳跃连接方案的数据特定 GNN，能够更好地捕获远程依赖关系。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search+to+Capture+Long-range+Dependency+with+Stacking+GNNs+for+Graph+Classification)|0|
|[Cut-matching Games for Generalized Hypergraph Ratio Cuts](https://doi.org/10.1145/3543507.3583539)|Nate Veldt|Texas A&M University, USA|Hypergraph clustering is a basic algorithmic primitive for analyzing complex datasets and systems characterized by multiway interactions, such as group email conversations, groups of co-purchased retail products, and co-authorship data. This paper presents a practical $O(\log n)$-approximation algorithm for a broad class of hypergraph ratio cut clustering objectives. This includes objectives involving generalized hypergraph cut functions, which allow a user to penalize cut hyperedges differently depending on the number of nodes in each cluster. Our method is a generalization of the cut-matching framework for graph ratio cuts, and relies only on solving maximum s-t flow problems in a special reduced graph. It is significantly faster than existing hypergraph ratio cut algorithms, while also solving a more general problem. In numerical experiments on various types of hypergraphs, we show that it quickly finds ratio cut solutions within a small factor of optimality.|Hypergraph 聚类是一种基本的算法原理，用于分析复杂的数据集和多拥有属性交互的系统，比如群组电子邮件对话、共同购买的零售产品组和合著者数据。本文提出了一个实用的 $o (log n) $- 近似演算法，用于一类广泛的超图比率削减聚类目标。这包括涉及广义超图割函数的目标，它允许用户根据每个簇中节点的数量对割超边进行不同的惩罚。该方法是图比割的割匹配框架的推广，仅依赖于求解特殊简化图中的最大 s-t 流问题。它明显快于现有的超图比率割算法，同时也解决了更一般的问题。通过对不同类型超图的数值实验，我们发现它能在一个小的最优性因子内快速找到比率割分解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cut-matching+Games+for+Generalized+Hypergraph+Ratio+Cuts)|0|
|[ApeGNN: Node-Wise Adaptive Aggregation in GNNs for Recommendation](https://doi.org/10.1145/3543507.3583530)|Dan Zhang, Yifan Zhu, Yuxiao Dong, Yuandong Wang, Wenzheng Feng, Evgeny Kharlamov, Jie Tang|Tsinghua University, China; Bosch Center for Artificial Intelligence, Germany|In recent years, graph neural networks (GNNs) have made great progress in recommendation. The core mechanism of GNNs-based recommender system is to iteratively aggregate neighboring information on the user-item interaction graph. However, existing GNNs treat users and items equally and cannot distinguish diverse local patterns of each node, which makes them suboptimal in the recommendation scenario. To resolve this challenge, we present a node-wise adaptive graph neural network framework ApeGNN. ApeGNN develops a node-wise adaptive diffusion mechanism for information aggregation, in which each node is enabled to adaptively decide its diffusion weights based on the local structure (e.g., degree). We perform experiments on six widely-used recommendation datasets. The experimental results show that the proposed ApeGNN is superior to the most advanced GNN-based recommender methods (up to 48.94%), demonstrating the effectiveness of node-wise adaptive aggregation.|近年来，图神经网络在推荐方面取得了很大的进展。基于 GNN 的推荐系统的核心机制是在用户-项目交互图上迭代地聚合相邻信息。然而，现有的 GNN 对用户和项目一视同仁，不能区分每个节点的不同本地模式，这使得它们在推荐场景中处于次优状态。为了解决这一问题，我们提出了一种节点自适应图神经网络框架 ApeGNN。ApeGNN 提出了一种基于节点的自适应信息聚合扩散机制，该机制允许每个节点根据局部结构(如度)自适应确定其扩散权重。我们在六个广泛使用的推荐数据集上进行实验。实验结果表明，该算法优于目前最先进的基于 GNN 的推荐方法(48.94%) ，证明了节点自适应聚集的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ApeGNN:+Node-Wise+Adaptive+Aggregation+in+GNNs+for+Recommendation)|0|
|[Multi-Modal Self-Supervised Learning for Recommendation](https://doi.org/10.1145/3543507.3583206)|Wei Wei, Chao Huang, Lianghao Xia, Chuxu Zhang|The University of Hong Kong, Hong Kong; University of Hong Kong, Hong Kong; Brandeis University, USA|The online emergence of multi-modal sharing platforms (eg, TikTok, Youtube) is powering personalized recommender systems to incorporate various modalities (eg, visual, textual and acoustic) into the latent user representations. While existing works on multi-modal recommendation exploit multimedia content features in enhancing item embeddings, their model representation capability is limited by heavy label reliance and weak robustness on sparse user behavior data. Inspired by the recent progress of self-supervised learning in alleviating label scarcity issue, we explore deriving self-supervision signals with effectively learning of modality-aware user preference and cross-modal dependencies. To this end, we propose a new Multi-Modal Self-Supervised Learning (MMSSL) method which tackles two key challenges. Specifically, to characterize the inter-dependency between the user-item collaborative view and item multi-modal semantic view, we design a modality-aware interactive structure learning paradigm via adversarial perturbations for data augmentation. In addition, to capture the effects that user's modality-aware interaction pattern would interweave with each other, a cross-modal contrastive learning approach is introduced to jointly preserve the inter-modal semantic commonality and user preference diversity. Experiments on real-world datasets verify the superiority of our method in offering great potential for multimedia recommendation over various state-of-the-art baselines. The implementation is released at: https://github.com/HKUDS/MMSSL.|多模式共享平台(如 TikTok、 Youtube)的在线出现为个性化推荐系统提供了动力，将各种模式(如视觉、文本和声学)纳入潜在用户表示。现有的多模态推荐方法利用多媒体内容特征增强项目嵌入，但其模型表示能力受到严重的标签依赖和对稀疏用户行为数据鲁棒性较差的限制。受近年来自我监督学习在缓解标签稀缺问题上的进展的启发，我们探讨了如何通过有效地学习模式感知的用户偏好和跨模式依赖来获得自我监督信号。为此，我们提出了一种新的多模态自主学习(MMSSL)方法，解决了两个关键的挑战。为了刻画用户项目协作视图和项目多模态语义视图之间的相互依赖关系，我们设计了一个基于模态感知的交互式结构学习范式。此外，为了捕捉用户感知情态的交互模式相互交织的影响，引入了一种跨情态对比学习方法，以共同保持多情态语义共性和用户偏好多样性。在现实世界数据集上的实验验证了该方法的优越性，在各种最先进的基线上为多媒体推荐提供了巨大的潜力。实施 https://github.com/hkuds/mmssl 如下:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Modal+Self-Supervised+Learning+for+Recommendation)|0|
|[Bootstrap Latent Representations for Multi-modal Recommendation](https://doi.org/10.1145/3543507.3583251)|Xin Zhou, Hongyu Zhou, Yong Liu, Zhiwei Zeng, Chunyan Miao, Pengwei Wang, Yuan You, Feijun Jiang|Nanyang Technological University, Singapore; Alibaba, China|This paper studies the multi-modal recommendation problem, where the item multi-modality information (e.g., images and textual descriptions) is exploited to improve the recommendation accuracy. Besides the user-item interaction graph, existing state-of-the-art methods usually use auxiliary graphs (e.g., user-user or item-item relation graph) to augment the learned representations of users and/or items. These representations are often propagated and aggregated on auxiliary graphs using graph convolutional networks, which can be prohibitively expensive in computation and memory, especially for large graphs. Moreover, existing multi-modal recommendation methods usually leverage randomly sampled negative examples in Bayesian Personalized Ranking (BPR) loss to guide the learning of user/item representations, which increases the computational cost on large graphs and may also bring noisy supervision signals into the training process. To tackle the above issues, we propose a novel self-supervised multi-modal recommendation model, dubbed BM3, which requires neither augmentations from auxiliary graphs nor negative samples. Specifically, BM3 first bootstraps latent contrastive views from the representations of users and items with a simple dropout augmentation. It then jointly optimizes three multi-modal objectives to learn the representations of users and items by reconstructing the user-item interaction graph and aligning modality features under both inter- and intra-modality perspectives. BM3 alleviates both the need for contrasting with negative examples and the complex graph augmentation from an additional target network for contrastive view generation. We show BM3 outperforms prior recommendation models on three datasets with number of nodes ranging from 20K to 200K, while achieving a 2-9X reduction in training time. Our code is available at https://github.com/enoche/BM3.|本文研究了多模态推荐问题，该问题利用项目的多模态信息(如图像和文本描述)来提高推荐的准确性。除了用户-项目交互图，现有的方法通常使用辅助图(例如，用户-用户或项目-项目关系图)来增强用户和/或项目的学习表示。这些表示通常使用图卷积网络在辅助图上进行传播和聚合，这在计算和存储方面是非常昂贵的，特别是对于大图。此外，现有的多模态推荐方法通常利用贝叶斯个性化排序(BPR)损失中随机抽样的负例子来指导用户/项目表示的学习，这增加了大图上的计算成本，也可能使噪声监督信号进入训练过程。为了解决上述问题，我们提出了一种新的自监督多模态推荐模型，称为 BM3，它不需要辅助图和负样本的增广。具体来说，BM3首先通过简单的辍学增强从用户和项目的表示中引导潜在的对比视图。然后，通过重构用户-项目交互图和在情态间和情态内对齐情态特征，联合优化三个多模态目标来学习用户和项目的表征。BM3减轻了与负面例子对比的需要，也减轻了从一个额外的目标网络生成对比视图的复杂图形增强。我们发现 BM3在三个数据集上的节点数从20K 到200K 不等，优于先前的推荐模型，同时实现了2-9倍的训练时间缩短。我们的代码可以在 https://github.com/enoche/bm3找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bootstrap+Latent+Representations+for+Multi-modal+Recommendation)|0|
|[Recommendation with Causality enhanced Natural Language Explanations](https://doi.org/10.1145/3543507.3583260)|Jingsen Zhang, Xu Chen, Jiakai Tang, Weiqi Shao, Quanyu Dai, Zhenhua Dong, Rui Zhang|Huawei Noah's Ark Lab, China; Renmin University of China, China; www.ruizhang.info, China|Explainable recommendation has recently attracted increasing attention from both academic and industry communities. Among different explainable strategies, generating natural language explanations is an important method, which can deliver more informative, flexible and readable explanations to facilitate better user decisions. Despite the effectiveness, existing models are mostly optimized based on the observed datasets, which can be skewed due to the selection or exposure bias. To alleviate this problem, in this paper, we formulate the task of explainable recommendation with a causal graph, and design a causality enhanced framework to generate unbiased explanations. More specifically, we firstly define an ideal unbiased learning objective, and then derive a tractable loss for the observational data based on the inverse propensity score (IPS), where the key is a sample re-weighting strategy for equalizing the loss and ideal objective in expectation. Considering that the IPS estimated from the sparse and noisy recommendation datasets can be inaccurate, we introduce a fault tolerant mechanism by minimizing the maximum loss induced by the sample weights near the IPS. For more comprehensive modeling, we further analyze and infer the potential latent confounders induced by the complex and diverse user personalities. We conduct extensive experiments by comparing with the state-of-the-art methods based on three real-world datasets to demonstrate the effectiveness of our method.|可解释的建议最近引起了学术界和工业界越来越多的关注。在不同的解释策略中，生成自然语言解释是一种重要的方法，它可以提供更多的信息，灵活和可读的解释，以便于更好的用户决策。尽管有效，现有的模型大多是优化的基础上观察数据集，这可能会由于选择或曝光偏差。为了解决这一问题，本文利用因果图构造了可解释推荐任务，并设计了一个因果增强框架来生成无偏解释。更具体地说，我们首先定义一个理想的无偏学习目标，然后推导出一个基于逆倾向评分(IPS)的观测数据易处理的损失，其中的关键是一个样本重新加权策略来均衡损失和期望的理想目标。针对由稀疏和噪声推荐数据集估计的 IPS 可能不准确的问题，我们引入了一种容错机制，使 IPS 附近的样本权重引起的最大损失最小。为了更全面的建模，我们进一步分析和推断潜在的潜在混杂因素引起的复杂和多样的用户个性。为了验证该方法的有效性，我们在三个实际数据集上进行了广泛的实验，并与现有的方法进行了比较。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommendation+with+Causality+enhanced+Natural+Language+Explanations)|0|
|[Two-Stage Constrained Actor-Critic for Short Video Recommendation](https://doi.org/10.1145/3543507.3583259)|Qingpeng Cai, Zhenghai Xue, Chi Zhang, Wanqi Xue, Shuchang Liu, Ruohan Zhan, Xueliang Wang, Tianyou Zuo, Wentao Xie, Dong Zheng, Peng Jiang, Kun Gai|Kuaishou Technology, China; Hong Kong University of Science and Technology, China; Unaffiliated, China|The wide popularity of short videos on social media poses new opportunities and challenges to optimize recommender systems on the video-sharing platforms. Users sequentially interact with the system and provide complex and multi-faceted responses, including watch time and various types of interactions with multiple videos. One the one hand, the platforms aims at optimizing the users' cumulative watch time (main goal) in long term, which can be effectively optimized by Reinforcement Learning. On the other hand, the platforms also needs to satisfy the constraint of accommodating the responses of multiple user interactions (auxiliary goals) such like, follow, share etc. In this paper, we formulate the problem of short video recommendation as a Constrained Markov Decision Process (CMDP). We find that traditional constrained reinforcement learning algorithms can not work well in this setting. We propose a novel two-stage constrained actor-critic method: At stage one, we learn individual policies to optimize each auxiliary signal. At stage two, we learn a policy to (i) optimize the main signal and (ii) stay close to policies learned at the first stage, which effectively guarantees the performance of this main policy on the auxiliaries. Through extensive offline evaluations, we demonstrate effectiveness of our method over alternatives in both optimizing the main goal as well as balancing the others. We further show the advantage of our method in live experiments of short video recommendations, where it significantly outperforms other baselines in terms of both watch time and interactions. Our approach has been fully launched in the production system to optimize user experiences on the platform.|短视频在社交媒体上的广泛流行为优化视频共享平台上的推荐系统带来了新的机遇和挑战。用户按顺序与系统互动，并提供复杂和多方面的反应，包括观看时间和与多个视频的各种类型的互动。一方面，这些平台旨在长期优化用户的累计观看时间(主要目标) ，这可以通过强化学习有效地优化。另一方面，平台还需要满足适应多用户交互(辅助目标)的响应约束，如跟踪、共享等。在这篇文章中，我们将短视频推荐问题描述为一个约束马可夫决策过程(CMDP)。我们发现传统的约束强化学习算法在这种情况下不能很好地工作。我们提出了一种新的两阶段约束行为者-评论方法: 在第一阶段，我们学习个体策略来优化每个辅助信号。在第二阶段，我们学习了一个策略来(i)优化主信号和(ii)紧跟在第一阶段学到的策略，这有效地保证了这个主策略在辅助系统上的性能。通过广泛的离线评估，我们证明了我们的方法在优化主要目标和平衡其他方面的有效性。我们进一步展示了我们的方法在短视频推荐的现场实验中的优势，在观看时间和交互方面显著优于其他基准。我们的方法已经在生产系统中全面推出，以优化平台上的用户体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Two-Stage+Constrained+Actor-Critic+for+Short+Video+Recommendation)|0|
|[Robust Recommendation with Adversarial Gaussian Data Augmentation](https://doi.org/10.1145/3543507.3583273)|Zhenlei Wang, Xu Chen|Gaoling School of Artificial Intelligence, Renmin university of China, China|Recommender system holds the promise of accurately understanding and estimating the user preferences. However, due to the extremely sparse user-item interactions, the learned recommender models can be less robust and sensitive to the highly dynamic user preferences and easily changed recommendation environments. To alleviate this problem, in this paper, we propose a simple yet effective robust recommender framework by generating additional samples from the Gaussian distributions. In specific, we design two types of data augmentation strategies. For the first one, we directly produce the data based on the original samples, where we simulate the generation process in the latent space. For the second one, we firstly change the original samples towards the direction of maximizing the loss function, and then produce the data based on the altered samples to make more effective explorations. Based on both of the above strategies, we leverage adversarial training to optimize the recommender model with the generated data which can achieve the largest losses. In addition, we theoretically analyze our framework, and find that the above two data augmentation strategies equal to impose a gradient based regularization on the original recommender models. We conduct extensive experiments based on six real-world datasets to demonstrate the effectiveness of our framework.|推荐系统有希望准确理解和估计用户的偏好。然而，由于用户与项目之间的交互非常稀少，所学习的推荐模型可能对高度动态的用户偏好和容易更改的推荐环境不太健壮和敏感。为了解决这个问题，本文提出了一个简单而有效的鲁棒推荐框架，通过从高斯分布生成额外的样本。具体来说，我们设计了两种类型的数据增强策略。对于第一种方法，我们直接在原始样本的基础上生成数据，模拟潜在空间中的生成过程。第二种方法首先将原始样本向损失函数最大化方向改变，然后根据改变后的样本生成数据，进行更有效的探索。基于上述两种策略，我们利用对抗性训练来优化推荐模型，生成的数据可以达到最大的损失。此外，我们还从理论上分析了我们的框架，发现上述两种数据增强策略相当于在原有的推荐模型上加入了基于梯度的正则化。我们基于六个真实世界的数据集进行了广泛的实验，以证明我们的框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Recommendation+with+Adversarial+Gaussian+Data+Augmentation)|0|
|[Anti-FakeU: Defending Shilling Attacks on Graph Neural Network based Recommender Model](https://doi.org/10.1145/3543507.3583289)|Xiaoyu You, Chi Li, Daizong Ding, Mi Zhang, Fuli Feng, Xudong Pan, Min Yang|Fudan University, School of Computer Science, China; University of Science and Technology of China, CCCD Key Lab of Ministry of Culture and Tourism, China|Graph neural network (GNN) based recommendation models are observed to be more vulnerable against carefully-designed malicious records injected into the system, i.e., shilling attacks, which manipulate the recommendation to common users and therefore impair user trust. In this paper, we for the first time conduct a systematic study on the vulnerability of GNN based recommendation model against the shilling attack. With the aid of theoretical analysis, we attribute the root cause of the vulnerability to its neighborhood aggregation mechanism, which could make the negative impact of attacks propagate rapidly in the system. To restore the robustness of GNN based recommendation model, the key factor lies in detecting malicious records in the system and preventing the propagation of misinformation. To this end, we construct a user-user graph to capture the patterns of malicious behaviors and design a novel GNN based detector to identify fake users. Furthermore, we develop a data augmentation strategy and a joint learning paradigm to train the recommender model and the proposed detector. Extensive experiments on benchmark datasets validate the enhanced robustness of the proposed method in resisting various types of shilling attacks and identifying fake users, e.g., our proposed method fully mitigating the impact of popularity attacks on target items up to , and improving the accuracy of detecting fake users on the Gowalla dataset by .|基于图神经网络(GNN)的推荐模型更容易受到注入系统的精心设计的恶意记录(即先令攻击)的攻击，这些恶意记录操纵普通用户的推荐，从而损害用户的信任。本文首次对基于 GNN 的推荐模型在面对先令攻击时的脆弱性进行了系统的研究。在理论分析的基础上，将易受攻击的根本原因归结为其邻域聚合机制，使得攻击的负面影响在系统中迅速传播。要恢复基于 GNN 的推荐模型的鲁棒性，关键在于检测系统中的恶意记录，防止错误信息的传播。为此，我们构造了一个用户-用户图来捕捉恶意行为的模式，并设计了一种新的基于 GNN 的检测器来识别虚假用户。此外，我们发展了一个数据增强策略和一个联合学习范式来训练推荐模型和建议的检测器。基准数据集的大量实验验证了该方法在抵御各种先令攻击和识别假用户方面的增强鲁棒性，例如，我们提出的方法充分减轻了流行攻击对目标项的影响，并通过以下方法提高了 Gowalla 数据集检测假用户的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anti-FakeU:+Defending+Shilling+Attacks+on+Graph+Neural+Network+based+Recommender+Model)|0|
|[Automated Self-Supervised Learning for Recommendation](https://doi.org/10.1145/3543507.3583336)|Lianghao Xia, Chao Huang, Chunzhen Huang, Kangyi Lin, Tao Yu, Ben Kao|Tencent, China; The University of Hong Kong, Hong Kong|Graph neural networks (GNNs) have emerged as the state-of-the-art paradigm for collaborative filtering (CF). To improve the representation quality over limited labeled data, contrastive learning has attracted attention in recommendation and benefited graph-based CF model recently. However, the success of most contrastive methods heavily relies on manually generating effective contrastive views for heuristic-based data augmentation. This does not generalize across different datasets and downstream recommendation tasks, which is difficult to be adaptive for data augmentation and robust to noise perturbation. To fill this crucial gap, this work proposes a unified Automated Collaborative Filtering (AutoCF) to automatically perform data augmentation for recommendation. Specifically, we focus on the generative self-supervised learning framework with a learnable augmentation paradigm that benefits the automated distillation of important self-supervised signals. To enhance the representation discrimination ability, our masked graph autoencoder is designed to aggregate global information during the augmentation via reconstructing the masked subgraph structures. Experiments and ablation studies are performed on several public datasets for recommending products, venues, and locations. Results demonstrate the superiority of AutoCF against various baseline methods. We release the model implementation at https://github.com/HKUDS/AutoCF.|图形神经网络(GNN)已经成为最先进的协同过滤(CF)模式。为了提高有限标记数据的表示质量，对比学习近年来受到推荐界的关注，并受益于基于图的 CF 模型。然而，大多数对比方法的成功在很大程度上依赖于手工生成有效的对比视图，用于基于启发式的数据增强。这不能在不同的数据集和下游推荐任务之间推广，这对于数据增强和抗噪声干扰是很难自适应的。为了填补这个关键的空白，这项工作提出了一个统一的自动化协同过滤(AutoCF)来自动执行数据增强的推荐。具体来说，我们重点研究了具有可学习增强范式的生成式自监督学习框架，该框架有利于自动提取重要的自监督信号。为了提高表示识别能力，我们设计了掩码自动编码器，通过重构掩码子图结构来聚集增强过程中的全局信息。实验和烧蚀研究进行了几个公共数据集推荐产品，场所和地点。结果表明，AutoCF 方法与各种基线方法相比具有优越性。我们在 https://github.com/hkuds/autocf 发布模型实现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Self-Supervised+Learning+for+Recommendation)|0|
|[AutoDenoise: Automatic Data Instance Denoising for Recommendations](https://doi.org/10.1145/3543507.3583339)|Weilin Lin, Xiangyu Zhao, Yejing Wang, Yuanshao Zhu, Wanyu Wang|City University of Hong Kong, Hong Kong; City University of Hong Kong, Hong Kong and Southern University of Science and Technology, China|Historical user-item interaction datasets are essential in training modern recommender systems for predicting user preferences. However, the arbitrary user behaviors in most recommendation scenarios lead to a large volume of noisy data instances being recorded, which cannot fully represent their true interests. While a large number of denoising studies are emerging in the recommender system community, all of them suffer from highly dynamic data distributions. In this paper, we propose a Deep Reinforcement Learning (DRL) based framework, AutoDenoise, with an Instance Denoising Policy Network, for denoising data instances with an instance selection manner in deep recommender systems. To be specific, AutoDenoise serves as an agent in DRL to adaptively select noise-free and predictive data instances, which can then be utilized directly in training representative recommendation models. In addition, we design an alternate two-phase optimization strategy to train and validate the AutoDenoise properly. In the searching phase, we aim to train the policy network with the capacity of instance denoising; in the validation phase, we find out and evaluate the denoised subset of data instances selected by the trained policy network, so as to validate its denoising ability. We conduct extensive experiments to validate the effectiveness of AutoDenoise combined with multiple representative recommender system models.|历史用户项目交互数据集对于培训现代推荐系统来预测用户偏好是必不可少的。然而，在大多数推荐场景中，任意的用户行为会导致大量有噪声的数据实例被记录下来，而这些数据实例并不能完全代表用户的真实兴趣。虽然在推荐系统社区中出现了大量的去噪研究，但所有这些研究都受到高度动态数据分布的影响。在这篇文章中，我们提出了一个基于深度强化学习的框架，AutoDenoise，和一个实例去噪策略网络，用于在深度推荐系统中用实例选择的方式去除数据实例。具体来说，自动去噪作为 DRL 中的一个代理，自适应地选择无噪声和预测数据实例，然后可以直接用于训练代表性的推荐模型。此外，我们还设计了一个交替的两阶段优化策略来训练和验证自动去噪的正确性。在搜索阶段，我们的目标是训练具有实例去噪能力的策略网络，在验证阶段，我们找出并评估训练后的策略网络选择的数据实例的去噪子集，以验证其去噪能力。我们进行了广泛的实验，以验证自动去噪与多个具有代表性的推荐系统模型相结合的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoDenoise:+Automatic+Data+Instance+Denoising+for+Recommendations)|0|
|[AutoS2AE: Automate to Regularize Sparse Shallow Autoencoders for Recommendation](https://doi.org/10.1145/3543507.3583349)|Rui Fan, Yuanhao Pu, Jin Chen, Zhihao Zhu, Defu Lian, Enhong Chen|School of Computer Science, University of Science and Technology of China, China; University of Electronic Science and Technology of China, China; School of Computer Science, School of Data Science, University of Science and Technology of China, China and State Key Laboratory of Cognitive Intelligence, China; School of Data Science, University of Science and Technology of China, China|The Embarrassingly Shallow Autoencoders (EASE and SLIM) are strong recommendation methods based on implicit feedback, compared to competing methods like iALS and VAE-CF. However, EASE suffers from several major shortcomings. First, the training and inference of EASE can not scale with the increasing number of items since it requires storing and inverting a large dense matrix; Second, though its optimization objective – the square loss– can yield a closed-form solution, it is not consistent with recommendation goal – predicting a personalized ranking on a set of items, so that its performance is far from optimal w.r.t ranking-oriented recommendation metrics. Finally, the regularization coefficients are sensitive w.r.t recommendation accuracy and vary a lot across different datasets, so the fine-tuning of these parameters is important yet time-consuming. To improve training and inference efficiency, we propose a Similarity-Structure Aware Shallow Autoencoder on top of three similarity structures, including Co-Occurrence, KNN and NSW. We then optimize the model with a weighted square loss, which is proven effective for ranking-based recommendation but still capable of deriving closed-form solutions. However, the weight in the loss can not be learned in the training set and is similarly sensitive w.r.t the accuracy to regularization coefficients. To automatically tune the hyperparameters, we design two validation losses on the validation set for guidance, and update the hyperparameters with the gradient of the validation losses. We finally evaluate the proposed method on multiple real-world datasets and show that it outperforms seven competing baselines remarkably, and verify the effectiveness of each part in the proposed method.|令人尴尬的浅层自动编码器(EASE 和 SLIM)是基于隐式反馈的强有力的推荐方法，与 iALS 和 VAE-CF 等竞争方法相比。然而，EASE 有几个主要的缺点。首先，EASE 的训练和推理不能随着项目数量的增加而扩展，因为它需要存储和反演一个大的密集矩阵; 其次，虽然它的优化目标-平方损失-可以产生一个封闭形式的解决方案，但它不符合推荐目标-预测一组项目的个性化排名，因此它的性能远远不是最优的面向网络排名的推荐指标。最后，正则化系数对推荐精度非常敏感，并且在不同的数据集上有很大的差异，因此对这些参数进行微调非常重要，但也非常耗时。为了提高训练和推理效率，本文提出了一种基于共现、 KNN 和 NSW 三种相似结构的相似结构感知浅层自动编码器。然后，我们用加权平方损失优化模型，这被证明是有效的排名为基础的推荐，但仍然能够导出闭合形式的解决方案。然而，损失中的权重不能在训练集中学习，并且对正则化系数的精度同样敏感。为了自动调整超参数，我们在验证集上设计了两个验证损失作为指导，并用验证损失的梯度来更新超参数。最后，我们对该方法在多个实际数据集上的性能进行了评估，结果表明该方法明显优于7个竞争基线，并验证了该方法各部分的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoS2AE:+Automate+to+Regularize+Sparse+Shallow+Autoencoders+for+Recommendation)|0|
|[Improving Recommendation Fairness via Data Augmentation](https://doi.org/10.1145/3543507.3583341)|Lei Chen, Le Wu, Kun Zhang, Richang Hong, Defu Lian, Zhiqiang Zhang, Jun Zhou, Meng Wang|Hefei University of Technology, China and Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, China; Hefei University of Technology, China; Ant Group, China; University of Science and Technology of China, China|Collaborative filtering based recommendation learns users' preferences from all users' historical behavior data, and has been popular to facilitate decision making. R Recently, the fairness issue of recommendation has become more and more essential. A recommender system is considered unfair when it does not perform equally well for different user groups according to users' sensitive attributes~(e.g., gender, race). Plenty of methods have been proposed to alleviate unfairness by optimizing a predefined fairness goal or changing the distribution of unbalanced training data. However, they either suffered from the specific fairness optimization metrics or relied on redesigning the current recommendation architecture. In this paper, we study how to improve recommendation fairness from the data augmentation perspective. The recommendation model amplifies the inherent unfairness of imbalanced training data. We augment imbalanced training data towards balanced data distribution to improve fairness. The proposed framework is generally applicable to any embedding-based recommendation, and does not need to pre-define a fairness metric. Extensive experiments on two real-world datasets clearly demonstrate the superiority of our proposed framework. We publish the source code at https://github.com/newlei/FDA.|基于协同过滤的推荐从所有用户的历史行为数据中了解用户的偏好，并且已经流行起来以促进决策制定。近年来，推荐的公平性问题变得越来越重要。根据用户的敏感属性 ~ (如性别、种族) ，一个推荐系统在不同用户组中的表现不尽相同，这被认为是不公平的。通过优化预定义的公平目标或改变不平衡训练数据的分布，已经提出了许多缓解不公平现象的方法。然而，它们要么受到特定公平性优化指标的影响，要么依赖于重新设计当前的推荐体系结构。本文从数据增强的角度研究如何提高推荐公平性。推荐模型放大了不平衡训练数据固有的不公平性。为了提高训练数据的公平性，我们对不平衡的训练数据进行扩充以达到平衡的数据分布。提出的框架通常适用于任何基于嵌入的建议，并且不需要预先定义公平性度量。在两个实际数据集上的大量实验清楚地表明了我们提出的框架的优越性。我们在 https://github.com/newlei/fda 公布源代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Recommendation+Fairness+via+Data+Augmentation)|0|
|[Robust Preference-Guided Denoising for Graph based Social Recommendation](https://doi.org/10.1145/3543507.3583374)|Yuhan Quan, Jingtao Ding, Chen Gao, Lingling Yi, Depeng Jin, Yong Li|Tencent, China; Tsinghua University, China|Graph Neural Network(GNN) based social recommendation models improve the prediction accuracy of user preference by leveraging GNN in exploiting preference similarity contained in social relations. However, in terms of both effectiveness and efficiency of recommendation, a large portion of social relations can be redundant or even noisy, e.g., it is quite normal that friends share no preference in a certain domain. Existing models do not fully solve this problem of relation redundancy and noise, as they directly characterize social influence over the full social network. In this paper, we instead propose to improve graph based social recommendation by only retaining the informative social relations to ensure an efficient and effective influence diffusion, i.e., graph denoising. Our designed denoising method is preference-guided to model social relation confidence and benefits user preference learning in return by providing a denoised but more informative social graph for recommendation models. Moreover, to avoid interference of noisy social relations, it designs a self-correcting curriculum learning module and an adaptive denoising strategy, both favoring highly-confident samples. Experimental results on three public datasets demonstrate its consistent capability of improving two state-of-the-art social recommendation models by robustly removing 10-40% of original relations. We release the source code at https://github.com/tsinghua-fib-lab/Graph-Denoising-SocialRec.|基于图神经网络(GNN)的社会推荐模型通过利用社会关系中包含的偏好相似性来提高用户偏好的预测精度。然而，就推荐的有效性和效率而言，很大一部分社会关系可能是冗余的，甚至是嘈杂的，例如，朋友在某个领域没有共同的偏好是很正常的。现有的模型并没有完全解决关系冗余和噪声的问题，因为它们直接表征了社会对整个社会网络的影响。在本文中，我们提出改进基于图的社会推荐，只保留信息性的社会关系，以确保有效和有效的影响扩散，即图去噪。我们设计的去噪方法是偏好引导的社会关系模型的信心和有益的用户偏好学习的回报，提供了一个去噪，但更多的信息社会图的推荐模型。同时，为了避免社会关系噪声的干扰，设计了自校正课程学习模块和自适应去噪策略，两者都有利于高自信样本。在三个公共数据集上的实验结果表明，该算法能够通过鲁棒地去除10-40% 的原始关系来改进两个最新的社会推荐模型。我们在 https://github.com/tsinghua-fib-lab/graph-denoising-socialrec 公布源代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Preference-Guided+Denoising+for+Graph+based+Social+Recommendation)|0|
|[Few-shot News Recommendation via Cross-lingual Transfer](https://doi.org/10.1145/3543507.3583383)|Taicheng Guo, Lu Yu, Basem Shihada, Xiangliang Zhang||The cold-start problem has been commonly recognized in recommendation systems and studied by following a general idea to leverage the abundant interaction records of warm users to infer the preference of cold users. However, the performance of these solutions is limited by the amount of records available from warm users to use. Thus, building a recommendation system based on few interaction records from a few users still remains a challenging problem for unpopular or early-stage recommendation platforms. This paper focuses on solving the few-shot recommendation problem for news recommendation based on two observations. First, news at diferent platforms (even in diferent languages) may share similar topics.Second, the user preference over these topics is transferable across diferent platforms. Therefore, we propose to solve the few-shot news recommendation problem by transferring the user-news preference from a many-shot source domain to a few-shot target domain. To bridge two domainsthat are even in diferent languages and without any overlapping users and news, we propose a novel unsupervised cross-lingual transfer model as the news encoder that aligns semantically similar news in two domains. A user encoder is constructed on top of the aligned news encoding and transfers the user preference from the source to target domain. Experimental results on two real-world news recommendation datasets show the superior performance of our proposed method on addressing few-shot news recommendation, comparing to the baselines. The source code can be found at https://github.com/taichengguo/Few-shot-NewsRec .|冷启动问题在推荐系统中已经得到了广泛的认可，并且通过利用热用户丰富的交互记录来推断冷用户的偏好这一基本思想进行了研究。但是，这些解决方案的性能受限于可供暖用户使用的记录数量。因此，对于不受欢迎或处于早期阶段的推荐平台来说，建立一个基于少量用户交互记录的推荐系统仍然是一个具有挑战性的问题。本文主要研究基于两个观察值的新闻推荐中的少镜头推荐问题。首先，不同平台的新闻(甚至是不同语言的新闻)可能会有相似的话题。其次，用户对这些主题的偏好可以跨不同的平台传递。因此，我们提出通过将用户新闻偏好从多镜头源域转移到少镜头目标域来解决少镜头新闻推荐问题。为了在两个不同语言的领域之间架起一座桥梁，并且没有任何重叠的用户和新闻，我们提出了一种新的无监督跨语言传输模型作为新闻编码器，它将两个领域中语义相似的新闻进行对齐。用户编码器构造在对齐的新闻编码之上，并将用户首选项从源传输到目标域。在两个实际新闻推荐数据集上的实验结果表明，与基线相比，本文提出的方法在处理少镜头新闻推荐方面具有更好的性能。源代码可以在 https://github.com/taichengguo/few-shot-newsrec 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+News+Recommendation+via+Cross-lingual+Transfer)|0|
|[Show Me The Best Outfit for A Certain Scene: A Scene-aware Fashion Recommender System](https://doi.org/10.1145/3543507.3583435)|Tangwei Ye, Liang Hu, Qi Zhang, Zhong Yuan Lai, Usman Naseem, Dora D. Liu|University of Technology Sydney, Australia and DeepBlue Academy of Sciences, China; DeepBlue Academy of Sciences, China and BirenTech Research, China; University of Sydney, Australia; Tongji University, China and DeepBlue Academy of Sciences, China; DeepBlue Academy of Sciences, China|Fashion recommendation (FR) has received increasing attention in the research of new types of recommender systems. Existing fashion recommender systems (FRSs) typically focus on clothing item suggestions for users in three scenarios: 1) how to best recommend fashion items preferred by users; 2) how to best compose a complete outfit, and 3) how to best complete a clothing ensemble. However, current FRSs often overlook an important aspect when making FR, that is, the compatibility of the clothing item or outfit recommendations is highly dependent on the scene context. To this end, we propose the scene-aware fashion recommender system (SAFRS), which uncovers a hitherto unexplored avenue where scene information is taken into account when constructing the FR model. More specifically, our SAFRS addresses this problem by encoding scene and outfit information in separation attention encoders and then fusing the resulting feature embeddings via a novel scene-aware compatibility score function. Extensive qualitative and quantitative experiments are conducted to show that our SAFRS model outperforms all baselines for every evaluated metric.|时尚推荐(FR)在新型推荐系统的研究中受到越来越多的关注。现有的时尚推荐系统(FRSs)主要集中在三个场景中为用户提供服装项目建议: 1)如何最好地推荐用户喜欢的时尚项目; 2)如何最好地组合一套完整的服装; 3)如何最好地完成一套服装。然而，目前的 FRS 在制作 FR 时往往忽略了一个重要方面，即服装项目或服装的兼容性建议高度依赖于场景上下文。为此，我们提出了场景感知时尚推荐系统(SAFRS) ，它揭示了一个迄今为止尚未探索的途径，在构建 FR 模型时，场景信息被考虑在内。更具体地说，我们的 SAFRS 通过在分离注意力编码器中编码场景和装备信息，然后通过一种新颖的场景感知兼容性评分函数融合所得到的特征嵌入来解决这个问题。广泛的定性和定量实验表明，我们的 SAFRS 模型优于所有基线的每一个评估指标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Show+Me+The+Best+Outfit+for+A+Certain+Scene:+A+Scene-aware+Fashion+Recommender+System)|0|
|[Invariant Collaborative Filtering to Popularity Distribution Shift](https://doi.org/10.1145/3543507.3583461)|An Zhang, Jingnan Zheng, Xiang Wang, Yancheng Yuan, TatSeng Chua|The Hong Kong Polytechnic University, Hong Kong; National University of Singapore, Singapore; Sea-NExT Joint Lab, National University of Singapore, Singapore; University of Science and Technology of China, China and Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, China|Collaborative Filtering (CF) models, despite their great success, suffer from severe performance drops due to popularity distribution shifts, where these changes are ubiquitous and inevitable in real-world scenarios. Unfortunately, most leading popularity debiasing strategies, rather than tackling the vulnerability of CF models to varying popularity distributions, require prior knowledge of the test distribution to identify the degree of bias and further learn the popularity-entangled representations to mitigate the bias. Consequently, these models result in significant performance benefits in the target test set, while dramatically deviating the recommendation from users' true interests without knowing the popularity distribution in advance. In this work, we propose a novel learning framework, Invariant Collaborative Filtering (InvCF), to discover disentangled representations that faithfully reveal the latent preference and popularity semantics without making any assumption about the popularity distribution. At its core is the distillation of unbiased preference representations (i.e., user preference on item property), which are invariant to the change of popularity semantics, while filtering out the popularity feature that is unstable or outdated. Extensive experiments on five benchmark datasets and four evaluation settings (i.e., synthetic long-tail, unbiased, temporal split, and out-of-distribution evaluations) demonstrate that InvCF outperforms the state-of-the-art baselines in terms of popularity generalization ability on real recommendations. Visualization studies shed light on the advantages of InvCF for disentangled representation learning. Our codes are available at https://github.com/anzhang314/InvCF.|协同过滤(CF)模型尽管取得了巨大的成功，但由于受欢迎程度的分布变化，性能严重下降，这些变化在现实世界中无处不在，也是不可避免的。不幸的是，大多数领先的流行去偏策略，而不是解决 CF 模型对不同流行分布的脆弱性，需要事先了解测试分布以确定偏倚程度，并进一步学习流行纠缠表示以减轻偏倚。因此，这些模型在目标测试集中产生了显著的性能效益，同时在不事先知道用户流行度分布的情况下，大大偏离了用户的真实兴趣。在这项工作中，我们提出了一个新的学习框架，不变协同过滤(InvCF) ，发现分离的表征，忠实地揭示潜在的偏好和流行语义，而不作任何假设的流行分布。其核心是无偏好的偏好表示(即，用户对项目属性的偏好)的精华，这些偏好对流行语义的变化是不变的，同时过滤掉不稳定或过时的流行特征。对五个基准数据集和四个评估设置(即合成长尾，无偏见，时间分割和分布外评估)的广泛实验表明，InvCF 在真实推荐的普及概括能力方面优于最先进的基线。可视化研究揭示了 InvCF 在分离表征学习中的优势。我们的密码可以在 https://github.com/anzhang314/invcf 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Invariant+Collaborative+Filtering+to+Popularity+Distribution+Shift)|0|
|[Code Recommendation for Open Source Software Developers](https://doi.org/10.1145/3543507.3583503)|Yiqiao Jin, Yunsheng Bai, Yanqiao Zhu, Yizhou Sun, Wei Wang|Georgia Institute of Technology, USA; University of California, Los Angeles, USA|Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers' interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. Considering the complex interactions among multiple parties within the system, we propose CODER, a novel graph-based code recommendation framework for open source software developers. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect the project hierarchy. Moreover, due to the lack of reliable benchmarks, we construct three large-scale datasets to facilitate future research in this direction. Extensive experiments show that our CODER framework achieves superior performance under various experimental settings, including intra-project, cross-project, and cold-start recommendation. We will release all the datasets, code, and utilities for data retrieval upon the acceptance of this work.|开源软件(OSS)正在形成技术基础设施的脊梁，吸引了数以百万计的人才贡献。值得注意的是，同时考虑开发人员的兴趣和项目代码的语义特性，以便向 OSS 开发人员推荐适当的开发任务，这是一项具有挑战性和关键性的工作。本文提出了一个新的代码推荐问题，其目的是根据开发人员的交互历史、源代码的语义特征以及项目的层次化文件结构来预测开发人员未来的贡献行为。考虑到系统中多方之间的复杂交互，我们提出了一种新的基于图的开源软件开发者代码推荐框架 CODER。CODER 通过异构图联合建模微观用户-代码交互和宏观用户-项目交互，并通过聚合反映项目层次结构的文件结构图进一步桥接两个层次的信息。此外，由于缺乏可靠的基准，我们建立了三个大规模的数据集，以方便未来在这方面的研究。大量的实验表明，我们的 CODER 框架在不同的实验环境下，包括项目内、项目间和冷启动推荐，都取得了较好的性能。我们将发布所有的数据集，代码和实用程序的数据检索后，接受这项工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Code+Recommendation+for+Open+Source+Software+Developers)|0|
|[pFedPrompt: Learning Personalized Prompt for Vision-Language Models in Federated Learning](https://doi.org/10.1145/3543507.3583518)|Tao Guo, Song Guo, Junxiao Wang|The Hong Kong Polytechnic University, Hong Kong|Pre-trained vision-language models like CLIP show great potential in learning representations that capture latent characteristics of users. A recently proposed method called Contextual Optimization (CoOp) introduces the concept of training prompt for adapting pre-trained vision-language models. Given the lightweight nature of this method, researchers have migrated the paradigm from centralized to decentralized system to innovate the collaborative training framework of Federated Learning (FL). However, current prompt training in FL mainly focuses on modeling user consensus and lacks the adaptation to user characteristics, leaving the personalization of prompt largely under-explored. Researches over the past few years have applied personalized FL (pFL) approaches to customizing models for heterogeneous users. Unfortunately, we find that with the variation of modality and training behavior, directly applying the pFL methods to prompt training leads to insufficient personalization and performance. To bridge the gap, we present pFedPrompt, which leverages the unique advantage of multimodality in vision-language models by learning user consensus from linguistic space and adapting to user characteristics in visual space in a non-parametric manner. Through this dual collaboration, the learned prompt will be fully personalized and aligned to the user’s local characteristics. We conduct extensive experiments across various datasets under the FL setting with statistical heterogeneity. The results demonstrate the superiority of our pFedPrompt against the alternative approaches with robust performance.|像 CLIP 这样预先训练好的视觉语言模型在捕捉用户潜在特征的学习表示方面显示出巨大的潜力。最近提出的上下文优化(CoOp)方法引入了训练提示符的概念来适应预先训练好的视觉语言模型。考虑到该方法的轻量级特性，研究人员将该模式从集中式系统迁移到分散式系统，以创新联邦学习(FL)的协同训练框架。然而，目前外语快速教学主要侧重于建立用户共识模型，缺乏对用户特征的适应性，使得个性化快速教学在很大程度上缺乏探索。过去几年的研究已经将个性化 FL (pFL)方法应用于异构用户的定制模型。不幸的是，我们发现，随着模式和训练行为的变化，直接应用 pFL 方法促进训练导致个性化和绩效的不足。为了弥合这一差距，我们提出了 pFedPrompt，它通过从语言空间学习用户共识并以非参数方式适应视觉空间中的用户特征，从而利用了视觉语言模型中多模态的独特优势。通过这种双重协作，学到的提示符将完全个性化，并与用户的本地特征保持一致。我们在统计异质性的 FL 环境下对不同的数据集进行了广泛的实验。实验结果表明，本文提出的 pFedPrompt 算法与其他具有鲁棒性能的方法相比具有优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=pFedPrompt:+Learning+Personalized+Prompt+for+Vision-Language+Models+in+Federated+Learning)|0|
|[Word Sense Disambiguation by Refining Target Word Embedding](https://doi.org/10.1145/3543507.3583191)|Xuefeng Zhang, Richong Zhang, Xiaoyang Li, Fanshuang Kong, Junfan Chen, Samuel Mensah, Yongyi Mao|University of Ottawa, Canada; SKLSDE, School of Computer Science and Engineering, Beihang University, China; The University of Sheffield, United Kingdom|Word Sense Disambiguation (WSD) which aims to identify the correct sense of a target word appearing in a specific context is essential for web text analysis. The use of glosses has been explored as a means for WSD. However, only a few works model the correlation between the target context and gloss. We add to the body of literature by presenting a model that employs a multi-head attention mechanism on deep contextual features of the target word and candidate glosses to refine the target word embedding. Furthermore, to encourage the model to learn the relevant part of target features that align with the correct gloss, we recursively alternate attention on target word features and that of candidate glosses to gradually extract the relevant contextual features of the target word, refining its representation and strengthening the final disambiguation results. Empirical studies on the five most commonly used benchmark datasets show that our proposed model is effective and achieves state-of-the-art results.|词义消歧(WSD)是识别特定语境中目标词的正确意义，是网络文本分析的基础。水务署已研究使用注释作为一种方法。然而，只有少数作品模拟了目标语境和注释之间的相关性。本文提出了一种基于目标词深层语境特征和候选修饰语的多目标注意机制来完善目标词嵌入的模型，并对文献进行了补充。此外，为了鼓励模型学习与正确的注释相一致的目标特征的相关部分，我们递归地交替关注目标词特征和候选注释的特征，以逐渐提取目标词的相关上下文特征，完善其表示并加强最终的消歧结果。对五个最常用的基准数据集的实证研究表明，我们提出的模型是有效的，并取得了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Word+Sense+Disambiguation+by+Refining+Target+Word+Embedding)|0|
|[Dual Policy Learning for Aggregation Optimization in Graph Neural Network-based Recommender Systems](https://doi.org/10.1145/3543507.3583241)|Heesoo Jung, Sangpil Kim, Hogun Park|Dept. of Electrical and Computer Engineering, Sungkyunkwan University, Republic of Korea and Dept. of Artificial Intelligence, Sungkyunkwan University, Republic of Korea; Dept. of Artificial Intelligence, Korea University, Republic of Korea; Dept. of Artificial Intelligence, Sungkyunkwan University, Republic of Korea|Graph Neural Networks (GNNs) provide powerful representations for recommendation tasks. GNN-based recommendation systems capture the complex high-order connectivity between users and items by aggregating information from distant neighbors and can improve the performance of recommender systems. Recently, Knowledge Graphs (KGs) have also been incorporated into the user-item interaction graph to provide more abundant contextual information; they are exploited to address cold-start problems and enable more explainable aggregation in GNN-based recommender systems (GNN-Rs). However, due to the heterogeneous nature of users and items, developing an effective aggregation strategy that works across multiple GNN-Rs, such as LightGCN and KGAT, remains a challenge. In this paper, we propose a novel reinforcement learning-based message passing framework for recommender systems, which we call DPAO (Dual Policy framework for Aggregation Optimization). This framework adaptively determines high-order connectivity to aggregate users and items using dual policy learning. Dual policy learning leverages two Deep-Q-Network models to exploit the user- and item-aware feedback from a GNN-R and boost the performance of the target GNN-R. Our proposed framework was evaluated with both non-KG-based and KG-based GNN-R models on six real-world datasets, and their results show that our proposed framework significantly enhances the recent base model, improving nDCG and Recall by up to 63.7% and 42.9%, respectively. Our implementation code is available at https://github.com/steve30572/DPAO/.|图形神经网络(GNN)为推荐任务提供了强有力的表示。基于 GNN 的推荐系统通过聚合来自远邻的信息来捕获用户和项目之间复杂的高阶连通性，从而提高推荐系统的性能。最近，知识图(KGs)也被纳入到用户项目交互图中，以提供更丰富的上下文信息; 它们被用来解决冷启动问题，并能够在基于 GNN 的推荐系统(GNN-Rs)中实现更可解释的聚合。然而，由于用户和项目的异构性，开发一个跨多个 GNN-R (如 LightGCN 和 KGAT)的有效聚合策略仍然是一个挑战。本文提出了一种新的基于强化学习的推荐系统消息传递框架，称之为聚合优化的双策略框架(DPAO)。该框架使用双策略学习自适应地确定与聚合用户和项目的高阶连通性。双策略学习利用两个 Deep-Q 网络模型来利用来自 GNN-R 的用户和项目感知反馈，提高目标 GNN-R 的性能。我们提出的框架在六个实际数据集上用非 KG 和基于 KG 的 GNN-R 模型进行了评估，结果表明，我们提出的框架显着增强了最近的基础模型，使 nDCG 和 Recall 分别提高了63.7% 和42.9% 。我们的实施守则可于 https://github.com/steve30572/dpao/索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Policy+Learning+for+Aggregation+Optimization+in+Graph+Neural+Network-based+Recommender+Systems)|0|
|[Addressing Heterophily in Graph Anomaly Detection: A Perspective of Graph Spectrum](https://doi.org/10.1145/3543507.3583268)|Yuan Gao, Xiang Wang, Xiangnan He, Zhenguang Liu, Huamin Feng, Yongdong Zhang|Zhejiang University, China; University of Science and Technology of China, China; Beijing Electronic Science And Technology Institute, China|Graph anomaly detection (GAD) suffers from heterophily — abnormal nodes are sparse so that they are connected to vast normal nodes. The current solutions upon Graph Neural Networks (GNNs) blindly smooth the representation of neiboring nodes, thus undermining the discriminative information of the anomalies. To alleviate the issue, recent studies identify and discard inter-class edges through estimating and comparing the node-level representation similarity. However, the representation of a single node can be misleading when the prediction error is high, thus hindering the performance of the edge indicator. In graph signal processing, the smoothness index is a widely adopted metric which plays the role of frequency in classical spectral analysis. Considering the ground truth Y to be a signal on graph, the smoothness index is equivalent to the value of the heterophily ratio. From this perspective, we aim to address the heterophily problem in the spectral domain. First, we point out that heterophily is positively associated with the frequency of a graph. Towards this end, we could prune inter-class edges by simply emphasizing and delineating the high-frequency components of the graph. Recall that graph Laplacian is a high-pass filter, we adopt it to measure the extent of 1-hop label changing of the center node and indicate high-frequency components. As GAD can be formulated as a semi-supervised binary classification problem, only part of the nodes are labeled. As an alternative, we use the prediction of the nodes to estimate it. Through our analysis, we show that prediction errors are less likely to affect the identification process. Extensive empirical evaluations on four benchmarks demonstrate the effectiveness of the indicator over popular homophilic, heterophilic, and tailored fraud detection methods. Our proposed indicator can effectively reduce the heterophily degree of the graph, thus boosting the overall GAD performance. Codes are open-sourced in https://github.com/blacksingular/GHRN.|图形异常检测(GAD)存在异质性ーー异常节点稀疏，因此它们连接到巨大的正常节点。现有的基于图神经网络(GNN)的解决方案盲目地平滑邻近节点的表示，从而破坏了异常的判别信息。为了缓解这一问题，最近的研究通过估计和比较节点级表示相似度来识别和丢弃类间边缘。然而，当预测误差较大时，单个节点的表示可能会产生误导，从而影响边缘指示器的性能。在图形信号处理中，平滑度指数是一个被广泛采用的度量指标，在经典的谱分析中起着频率的作用。考虑到地面真值 Y 是图上的一个信号，光滑度指标等价于异质比的值。从这个角度出发，我们的目标是解决谱域中的异质性问题。首先，我们指出异质性与图的频率成正相关。为了达到这个目的，我们可以通过简单地强调和描述图的高频成分来修剪类间边缘。回想一下，图拉普拉斯是一个高通滤波器，我们采用它来测量中心节点的1跳标签变化的程度，并指示高频分量。由于 GAD 可以表述为一个半监督的二进制分类问题，所以只对部分节点进行标记。作为一种替代方法，我们使用节点的预测来估计它。通过我们的分析，我们表明，预测错误不太可能影响识别过程。对四个基准的广泛的实证评估证明了指标的有效性超过流行的同质性，异质性和量身定制的欺诈检测方法。我们提出的指标可以有效地降低图的异构度，从而提高整体的 GAD 性能。代码在 https://github.com/blacksingular/ghrn 中是开源的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Heterophily+in+Graph+Anomaly+Detection:+A+Perspective+of+Graph+Spectrum)|0|
|[Ginver: Generative Model Inversion Attacks Against Collaborative Inference](https://doi.org/10.1145/3543507.3583306)|Yupeng Yin, Xianglong Zhang, Huanle Zhang, Feng Li, Yue Yu, Xiuzhen Cheng, Pengfei Hu|National University of Defense Technology, China and Peng Cheng Laboratory, China; School of Computer Science and Technology, Shandong University, China|Deep Learning (DL) has been widely adopted in almost all domains, from threat recognition to medical diagnosis. Albeit its supreme model accuracy, DL imposes a heavy burden on devices as it incurs overwhelming system overhead to execute DL models, especially on Internet-of-Things (IoT) and edge devices. Collaborative inference is a promising approach to supporting DL models, by which the data owner (the victim) runs the first layers of the model on her local device and then a cloud provider (the adversary) runs the remaining layers of the model. Compared to offloading the entire model to the cloud, the collaborative inference approach is more data privacy-preserving as the owner’s model input is not exposed to outsiders. However, we show in this paper that the adversary can restore the victim’s model input by exploiting the output of the victim’s local model. Our attack is dubbed Ginver 1: Generative model inversion attacks against collaborative inference. Once trained, Ginver can infer the victim’s unseen model inputs without remaking the inversion attack model and thus has the generative capability. We extensively evaluate Ginver under different settings (e.g., white-box and black-box of the victim’s local model) and applications (e.g., CIFAR10 and FaceScrub datasets). The experimental results show that Ginver recovers high-quality images from the victims.|从威胁识别到医学诊断，深度学习已被广泛应用于几乎所有的领域。尽管 DL 的模型精确度最高，但它对设备造成了沉重的负担，因为它在执行 DL 模型时会产生巨大的系统开销，特别是在物联网(IoT)和边缘设备上。协作推理是支持 DL 模型的一种有前途的方法，通过这种方法，数据所有者(受害者)在其本地设备上运行模型的第一层，然后云提供者(对手)运行模型的其余层。与将整个模型卸载到云中相比，协作推理方法更能保护数据隐私，因为所有者的模型输入不会暴露给外部人员。然而，本文证明了对手可以通过利用被害人局部模型的输出来恢复被害人的模型输入。我们的攻击被称为 Ginver 1: 针对协作推理的生成模型反转攻击。一旦被训练，Ginver 可以推断出受害者看不见的模型输入，而无需重建反转攻击模型，因此具有生成能力。我们在不同的设置(例如，受害者本地模型的白盒和黑盒)和应用程序(例如，CIFAR10和 FaceScrub 数据集)下广泛评估 Ginver。实验结果表明，Ginver 可以从受害者身上恢复出高质量的图像。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ginver:+Generative+Model+Inversion+Attacks+Against+Collaborative+Inference)|0|
|[All Your Shops Are Belong to Us: Security Weaknesses in E-commerce Platforms](https://doi.org/10.1145/3543507.3583319)|Rohan Pagey, Mohammad Mannan, Amr M. Youssef|Concordia Institute for Information Systems Engineering, Concordia University, Canada|Software as a Service (SaaS) e-commerce platforms for merchants allow individual business owners to set up their online stores almost instantly. Prior work has shown that the checkout flows and payment integration of some e-commerce applications are vulnerable to logic bugs with serious financial consequences, e.g., allowing “shopping for free”. Apart from checkout and payment integration, vulnerabilities in other e-commerce operations have remained largely unexplored, even though they can have far more serious consequences, e.g., enabling “store takeover”. In this work, we design and implement a security evaluation framework to uncover security vulnerabilities in e-commerce operations beyond checkout/payment integration. We use this framework to analyze 32 representative e-commerce platforms, including web services of 24 commercial SaaS platforms and 15 associated Android apps, and 8 open source platforms; these platforms host over 10 million stores as approximated through Google dorks. We uncover several new vulnerabilities with serious consequences, e.g., allowing an attacker to take over all stores under a platform, and listing illegal products at a victim’s store—in addition to “shopping for free” bugs, without exploiting the checkout/payment process. We found 12 platforms vulnerable to store takeover (affecting 41000+ stores) and 6 platforms vulnerable to shopping for free (affecting 19000+ stores, approximated via Google dorks on Oct. 8, 2022). We have responsibly disclosed the vulnerabilities to all affected parties, and requested four CVEs (three assigned, and one is pending review).|软件即服务(SaaS)商家电子商务平台允许个体企业主几乎立即建立他们的在线商店。先前的研究已经表明，一些电子商务应用程序的结帐流程和支付集成容易受到逻辑错误的影响，这些逻辑错误会带来严重的财务后果，例如，允许“免费购物”。除了结账和支付集成，其他电子商务操作中的漏洞基本上还没有得到探索，尽管它们可能产生更为严重的后果，例如“商店接管”。在这项工作中，我们设计和实现了一个安全评估框架，以揭示电子商务运作中的安全漏洞超越结帐/支付集成。我们使用这个框架来分析32个具有代表性的电子商务平台，包括24个商业 SaaS 平台和15个相关的 Android 应用程序的网络服务，以及8个开源平台; 这些平台拥有超过1000万个商店，大致相当于 Google 呆子的数量。我们发现了几个具有严重后果的新漏洞，例如，允许攻击者在一个平台下接管所有商店，以及在受害者的商店中列出非法产品ーー除了“免费购物”的漏洞之外，还没有利用结帐/付款过程。我们发现有12个平台容易被商店接管(影响到41000多家商店) ，6个平台容易被免费购物(影响到19000多家商店，大约在2022年10月8日通过谷歌书呆子)。我们已经负责任地向所有受影响的方面披露了漏洞，并要求四个 CVE (三个分配，一个正在等待审查)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=All+Your+Shops+Are+Belong+to+Us:+Security+Weaknesses+in+E-commerce+Platforms)|0|
|[An Empirical Study of the Usage of Checksums for Web Downloads](https://doi.org/10.1145/3543507.3583326)|Gaël Bernard, Rémi Coudert, Bertil Chapuis, Kévin Huguenin|Department of Information Systems, University of Lausanne, Switzerland; EPFL, Switzerland; University of Applied Sciences Western Switzerland, Switzerland|Checksums, typically provided on webpages and generated from cryptographic hash functions (e.g., MD5, SHA256) or signature schemes (e.g., PGP), are commonly used on websites to enable users to verify that the files they download have not been tampered with when stored on possibly untrusted servers. In this paper, we elucidate the current practices regarding the usage of checksums for web downloads (hash functions used, visibility and validity of checksums, type of websites and files, etc.), as this has been mostly overlooked so far. Using a snowball-sampling strategy for the 200000 most popular domains of the Web, we first crawled a dataset of  8.5M webpages, from which we built, through an active-learning approach, a unique dataset of 277 diverse webpages that contain checksums. Our analysis of these webpages reveals interesting findings about the usage of checksums. For instance, it shows that checksums are used mostly to verify program files, that weak hash functions are frequently used, and that a non-negligible proportion of the checksums provided on webpages do not match that of their associated files. Finally, we complement our analysis with a survey of the webmasters of the considered webpages (N = 26), thus shedding light on the reasons behind the checksum-related choices they make.|校验和通常在网页上提供，由加密散列函数(例如 MD5、 SHA256)或签名方案(例如 PGP)产生，通常在网站上使用，使用户能够验证他们下载的文件在存储在可能不受信任的服务器上时没有被篡改。在这篇文章中，我们阐述了目前使用校验和进行网页下载的做法(使用的散列函数，校验和的可见性和有效性，网站和文件的类型等) ，因为这是迄今为止大多数被忽视的。使用滚雪球抽样策略对200000个最流行的网络领域，我们首先抓取了850万个网页的数据集，从中，我们通过一个主动学习的方法，建立了一个包含校验和的277个不同网页的独特数据集。我们对这些网页的分析揭示了校验和使用的有趣发现。例如，它表明校验和主要用于验证程序文件，经常使用弱散列函数，网页上提供的校验和中有不可忽视的比例与相关文件的校验和不匹配。最后，我们通过对所考虑的网页(N = 26)的网站管理员进行调查来补充我们的分析，从而阐明他们做出校验和相关选择背后的原因。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Empirical+Study+of+the+Usage+of+Checksums+for+Web+Downloads)|0|
|[Quantifying and Defending against Privacy Threats on Federated Knowledge Graph Embedding](https://doi.org/10.1145/3543507.3583450)|Yuke Hu, Wei Liang, Ruofan Wu, Kai Xiao, Weiqiang Wang, Xiaochen Li, Jinfei Liu, Zhan Qin|Zhejiang University, China and HIC-ZJU, China; Ant Group, China|Knowledge Graph Embedding (KGE) is a fundamental technique that extracts expressive representation from knowledge graph (KG) to facilitate diverse downstream tasks. The emerging federated KGE (FKGE) collaboratively trains from distributed KGs held among clients while avoiding exchanging clients' sensitive raw KGs, which can still suffer from privacy threats as evidenced in other federated model trainings (e.g., neural networks). However, quantifying and defending against such privacy threats remain unexplored for FKGE which possesses unique properties not shared by previously studied models. In this paper, we conduct the first holistic study of the privacy threat on FKGE from both attack and defense perspectives. For the attack, we quantify the privacy threat by proposing three new inference attacks, which reveal substantial privacy risk by successfully inferring the existence of the KG triple from victim clients. For the defense, we propose DP-Flames, a novel differentially private FKGE with private selection, which offers a better privacy-utility tradeoff by exploiting the entity-binding sparse gradient property of FKGE and comes with a tight privacy accountant by incorporating the state-of-the-art private selection technique. We further propose an adaptive privacy budget allocation policy to dynamically adjust defense magnitude across the training procedure. Comprehensive evaluations demonstrate that the proposed defense can successfully mitigate the privacy threat by effectively reducing the success rate of inference attacks from $83.1\%$ to $59.4\%$ on average with only a modest utility decrease.|知识图嵌入(KGE)是一种从知识图中提取表达式的基本技术，可以方便地完成不同的下游任务。新兴的联邦 KGE (FKGE)协同培训客户之间的分布式幼儿园，同时避免交换客户敏感的原始幼儿园，这些幼儿园仍然可能受到隐私威胁，这在其他联邦模型培训(例如，神经网络)中得到了证明。然而，量化和防御这种隐私威胁仍然没有探索的 FKGE，具有独特的性质没有共享以前的研究模型。本文首次从攻击和防御两个角度对 FKGE 隐私威胁进行了全面的研究。对于这种攻击，我们提出了三种新的推理攻击来量化隐私威胁，通过成功地从受害客户端推断出 KG 三元组的存在，揭示了巨大的隐私风险。对于辩方，我们提出 DP-Flames，一种具有私有选择的新型差异私有 FKGE，它通过利用 FKGE 的实体绑定稀疏梯度特性提供了更好的隐私-效用权衡，并通过结合最先进的私有选择技术提供了一个严密的隐私会计。我们进一步提出了一个自适应的隐私预算分配策略，以动态调整整个训练过程中的防御大小。综合评估表明，提出的防御能够成功地减轻隐私威胁，有效地减少推理攻击的成功率从83.1% $至59.4% $平均只有适度的效用减少。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+and+Defending+against+Privacy+Threats+on+Federated+Knowledge+Graph+Embedding)|0|
|[Sanitizing Sentence Embeddings (and Labels) for Local Differential Privacy](https://doi.org/10.1145/3543507.3583512)|Minxin Du, Xiang Yue, Sherman S. M. Chow, Huan Sun|Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Ohio State University, USA|Differentially private (DP) learning, notably DP stochastic gradient descent (DP-SGD), has limited applicability in fine-tuning gigantic pre-trained language models (LMs) for natural language processing tasks. The culprit is the perturbation of gradients (as gigantic as entire models), leading to significant efficiency and accuracy drops. We show how to achieve metric-based local DP (LDP) by sanitizing (high-dimensional) sentence embedding, extracted by LMs and much smaller than gradients. For potential utility improvement, we impose a consistency constraint on the sanitization. We explore two approaches: One is brand new and can directly output consistent noisy embeddings; the other is an upgradation with post-processing. To further mitigate “the curse of dimensionality,” we introduce two trainable linear maps for mediating dimensions without hurting privacy or utility. Our protection can effectively defend against privacy threats on embeddings. It also naturally extends to inference. Our experiments1 show that we reach the non-private accuracy under properly configured parameters, e.g., 0.92 for SST-2 with a privacy budget ϵ = 10 and the reduced dimension as 16. We also sanitize the label for LDP (with another small privacy budget) with limited accuracy losses to fully protect every sequence-label pair.|差异私有(DP)学习，特别是 DP 随机梯度下降(DP-sgd) ，在为自然语言处理任务微调庞大的预训练语言模型(LMs)方面的适用性有限。罪魁祸首是梯度的扰动(像整个模型一样巨大) ，导致了显著的效率和精度下降。我们展示了如何通过消毒(高维)句子嵌入、利用 LMs 提取和比梯度小得多的方法来实现基于度量的局部 DP (LDP)。对于潜在的效用改进，我们对消毒施加一致性约束。我们探索了两种方法: 一种是全新的，可以直接输出一致的噪声嵌入; 另一种是后处理的升级。为了进一步减轻“维数灾难”，我们引入了两个可训练的线性映射，用于在不损害隐私或效用的情况下调节维度。我们的保护可以有效地防御嵌入式系统的隐私威胁。它也自然地延伸到推理。我们的实验表明，在适当的参数配置下，我们达到了非私有精度，例如，0.92的 SST-2与私有预算 ε = 10和降维为16。我们还消毒的标签为 LDP (与另一个小的隐私预算)与有限的准确性损失，以充分保护每个序列标签对。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sanitizing+Sentence+Embeddings+(and+Labels)+for+Local+Differential+Privacy)|0|
|[Heterogeneous Federated Knowledge Graph Embedding Learning and Unlearning](https://doi.org/10.1145/3543507.3583305)|Xiangrong Zhu, Guangyao Li, Wei Hu|State Key Laboratory for Novel Software Technology, Nanjing University, China and National Institute of Healthcare Data Science, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China|Federated Learning (FL) recently emerges as a paradigm to train a global machine learning model across distributed clients without sharing raw data. Knowledge Graph (KG) embedding represents KGs in a continuous vector space, serving as the backbone of many knowledge-driven applications. As a promising combination, federated KG embedding can fully take advantage of knowledge learned from different clients while preserving the privacy of local data. However, realistic problems such as data heterogeneity and knowledge forgetting still remain to be concerned. In this paper, we propose FedLU, a novel FL framework for heterogeneous KG embedding learning and unlearning. To cope with the drift between local optimization and global convergence caused by data heterogeneity, we propose mutual knowledge distillation to transfer local knowledge to global, and absorb global knowledge back. Moreover, we present an unlearning method based on cognitive neuroscience, which combines retroactive interference and passive decay to erase specific knowledge from local clients and propagate to the global model by reusing knowledge distillation. We construct new datasets for assessing realistic performance of the state-of-the-arts. Extensive experiments show that FedLU achieves superior results in both link prediction and knowledge forgetting.|联邦学习(Federated Learning，FL)最近作为一种模式出现，它可以在不共享原始数据的情况下跨分布式客户机训练全局机器学习模型。知识图(KG)嵌入表示连续向量空间中的 KG，作为许多知识驱动应用程序的骨干。作为一种有前途的组合，联邦 KG 嵌入可以充分利用从不同客户端获得的知识，同时保护本地数据的隐私。然而，数据异构性和知识遗忘等现实问题仍然值得关注。本文提出了一种适用于异构 KG 嵌入学习和非学习的 FL 框架 FedLU。针对数据异构导致的局部优化和全局收敛之间的漂移问题，提出了互知识提取方法，将局部知识转化为全局知识，并将全局知识吸收回来。此外，我们还提出了一种基于认知神经科学的去学习方法，它结合了追溯干扰和被动衰减，从本地客户删除特定的知识，并通过重复使用知识提取传播到全球模型。我们建立了新的数据集来评估现实性能的最新技术。大量实验表明，FedLU 在链路预测和知识遗忘方面都取得了较好的效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+Federated+Knowledge+Graph+Embedding+Learning+and+Unlearning)|0|
|[A Single Vector Is Not Enough: Taxonomy Expansion via Box Embeddings](https://doi.org/10.1145/3543507.3583310)|Song Jiang, Qiyue Yao, Qifan Wang, Yizhou Sun|University of California, Los Angeles, USA; Meta AI, USA|Taxonomies, which organize knowledge hierarchically, support various practical web applications such as product navigation in online shopping and user profile tagging on social platforms. Given the continued and rapid emergence of new entities, maintaining a comprehensive taxonomy in a timely manner through human annotation is prohibitively expensive. Therefore, expanding a taxonomy automatically with new entities is essential. Most existing methods for expanding taxonomies encode entities into vector embeddings (i.e., single points). However, we argue that vectors are insufficient to model the “is-a” hierarchy in taxonomy (asymmetrical relation), because two points can only represent pairwise similarity (symmetrical relation). To this end, we propose to project taxonomy entities into boxes (i.e., hyperrectangles). Two boxes can be "contained", "disjoint" and "intersecting", thus naturally representing an asymmetrical taxonomic hierarchy. Upon box embeddings, we propose a novel model BoxTaxo for taxonomy expansion. The core of BoxTaxo is to learn boxes for entities to capture their child-parent hierarchies. To achieve this, BoxTaxo optimizes the box embeddings from a joint view of geometry and probability. BoxTaxo also offers an easy and natural way for inference: examine whether the box of a given new entity is fully enclosed inside the box of a candidate parent from the existing taxonomy. Extensive experiments on two benchmarks demonstrate the effectiveness of BoxTaxo compared to vector based models.|分类法按层次组织知识，支持各种实际的网络应用程序，如在线购物中的产品导航和社交平台上的用户配置文件标签。鉴于新实体的持续和快速出现，通过人工注释及时维护全面的分类是非常昂贵的。因此，使用新实体自动扩展分类法是必不可少的。大多数现有的分类扩展方法都将实体编码为向量嵌入(即单点)。然而，我们认为向量不足以模拟分类学中的“ is-a”层次结构(非对称关系) ，因为两点只能表示成对的相似性(对称关系)。为此，我们建议将分类实体投影到盒子(即超矩形)中。两个盒子可以“包含”、“不相交”和“交叉”，因此自然地代表了一个不对称的分类层次。在盒子嵌入的基础上，提出了一种新的分类扩展模型 BoxTaxo。BoxTaxo 的核心是为实体学习用于捕获其子-父层次结构的框。为了实现这一点，BoxTaxo 从几何和概率的联合视图优化了盒子嵌入。BoxTaxo 还提供了一种简单而自然的推理方法: 检查给定新实体的框是否完全封闭在现有分类法的候选父类的框中。在两个基准上的大量实验证明了 BoxTaxo 与基于向量的模型相比的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Single+Vector+Is+Not+Enough:+Taxonomy+Expansion+via+Box+Embeddings)|0|
|[Knowledge Graph Question Answering with Ambiguous Query](https://doi.org/10.1145/3543507.3583316)|Lihui Liu, Yuzhong Chen, Mahashweta Das, Hao Yang, Hanghang Tong|Department of Computer Science, University of Illinois at Urbana Champaign, USA; visa research, USA|Knowledge graph question answering aims to identify answers of the query according to the facts in the knowledge graph. In the vast majority of the existing works, the input queries are considered perfect and can precisely express the user’s query intention. However, in reality, input queries might be ambiguous and elusive which only contain a limited amount of information. Directly answering these ambiguous queries may yield unwanted answers and deteriorate user experience. In this paper, we propose PReFNet which focuses on answering ambiguous queries with pseudo relevance feedback on knowledge graphs. In order to leverage the hidden (pseudo) relevance information existed in the results that are initially returned from a given query, PReFNet treats the top-k returned candidate answers as a set of most relevant answers, and uses variational Bayesian inference to infer user’s query intention. To boost the quality of the inferred queries, a neighborhood embedding based VGAE model is used to prune inferior inferred queries. The inferred high quality queries will be returned to the users to help them search with ease. Moreover, all the high-quality candidate nodes will be re-ranked according to the inferred queries. The experiment results show that our proposed method can recommend high-quality query graphs to users and improve the question answering accuracy.|知识图问答的目的是根据知识图中的事实来识别问题的答案。在现有的大多数工作中，输入查询被认为是完美的，可以准确地表达用户的查询意图。然而，在现实中，输入查询可能是模糊和难以捉摸的，只包含有限数量的信息。直接回答这些模棱两可的问题可能会得到不想要的答案，并损害用户体验。在这篇文章中，我们提出了一种基于知识图的伪关联反馈回答模糊查询的方法。为了利用最初从给定查询返回的结果中存在的隐藏(伪)相关信息，prefNet 将返回的候选答案视为一组最相关的答案，并使用变异贝叶斯推断来推断用户的查询意图。为了提高推理查询的质量，提出了一种基于邻域嵌入的 VGAE 模型来裁剪劣质推理查询。推断出的高质量查询将返回给用户，以帮助他们轻松搜索。此外，所有高质量的候选节点将根据推断的查询进行重新排序。实验结果表明，该方法可以向用户推荐高质量的查询图，提高问答的准确率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Question+Answering+with+Ambiguous+Query)|0|
|[Hierarchical Self-Attention Embedding for Temporal Knowledge Graph Completion](https://doi.org/10.1145/3543507.3583397)|Xin Ren, Luyi Bai, Qianwen Xiao, Xiangxi Meng|Northeastern University, China|Temporal Knowledge Graph (TKG) is composed of a series of facts related to timestamps in the real world and has become the basis of many artificial intelligence applications. However, the existing TKG is usually incomplete. It has become a hot research task to infer missing facts based on existing facts in a TKG; namely, Temporal Knowledge Graph Completion (TKGC). The current mainstream TKGC models are embedded models that predict missing facts by representing entities, relations and timestamps as low-dimensional vectors. In order to deal with the TKG structure information, there are some models that try to introduce attention mechanism into the embedding process. But they only consider the structure information of entities or relations, and ignore the structure information of the whole TKG. Moreover, most of them usually treat timestamps as a general feature and cannot take advantage of the potential time series information of the timestamp. To solve these problems, wo propose a new Hierarchical Self-Attention Embedding (HSAE) model which inspired by self-attention mechanism and diachronic embedding technique. For structure information of the whole TKG, we divide the TKG into two layers: entity layer and relation layer, and then apply the self-attention mechanism to the entity layer and relation layer respectively to capture the structure information. For time series information of the timestamp, we capture them by combining positional encoding and diachronic embedding technique into the above two self-attention layers. Finally, we can get the embedded representation vectors of entities, relations and timestamps, which can be combined with other models for better results. We evaluate our model on three TKG datasets: ICEWS14, ICEWS05-15 and GDELT. Experimental results on the TKGC (interpolation) task demonstrate that our model achieves state-of-the-art results.|时间知识图(TKG)由现实世界中与时间戳相关的一系列事实组成，已成为许多人工智能应用的基础。然而，现有的 TKG 通常是不完整的。基于 TKG 中已有事实推断缺失事实，即时态知识图完成(TKGC) ，已成为一个热门的研究课题。目前主流的 TKGC 模型是嵌入式模型，通过将实体、关系和时间戳表示为低维向量来预测缺失事实。为了处理 TKG 的结构信息，有一些模型尝试在嵌入过程中引入注意机制。但他们只考虑实体或关系的结构信息，而忽略了整个 TKG 的结构信息。此外，它们中的大多数通常将时间戳视为一个通用特性，不能利用时间戳的潜在时间序列信息。为了解决这些问题，我们提出了一种新的分层自我注意嵌入(HSAE)模型，该模型受自我注意机制和历时嵌入技术的启发。对于整个 TKG 的结构信息，我们将 TKG 分为实体层和关系层两个层次，然后将自注意机制分别应用于实体层和关系层，以获取 TKG 的结构信息。对于时间戳的时间序列信息，我们将位置编码和历时嵌入技术结合到上述两个自我注意层中来获取它们。最后，我们可以得到实体、关系和时间戳的嵌入式表示向量，这些表示向量可以与其他模型相结合以获得更好的结果。我们在三个 TKG 数据集上评估我们的模型: ICEWS14，ICEWS05-15和 GDELT。在 TKGC (插值)任务上的实验结果表明，我们的模型达到了最先进的效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Self-Attention+Embedding+for+Temporal+Knowledge+Graph+Completion)|0|
|[Link Prediction with Attention Applied on Multiple Knowledge Graph Embedding Models](https://doi.org/10.1145/3543507.3583358)|Cosimo Gregucci, Mojtaba Nayyeri, Daniel Hernández, Steffen Staab|University of Stuttgart, Germany; University of Stuttgart, Germany and University of Southampton, United Kingdom|Predicting missing links between entities in a knowledge graph is a fundamental task to deal with the incompleteness of data on the Web. Knowledge graph embeddings map nodes into a vector space to predict new links, scoring them according to geometric criteria. Relations in the graph may follow patterns that can be learned, e.g., some relations might be symmetric and others might be hierarchical. However, the learning capability of different embedding models varies for each pattern and, so far, no single model can learn all patterns equally well. In this paper, we combine the query representations from several models in a unified one to incorporate patterns that are independently captured by each model. Our combination uses attention to select the most suitable model to answer each query. The models are also mapped onto a non-Euclidean manifold, the Poincar\'e ball, to capture structural patterns, such as hierarchies, besides relational patterns, such as symmetry. We prove that our combination provides a higher expressiveness and inference power than each model on its own. As a result, the combined model can learn relational and structural patterns. We conduct extensive experimental analysis with various link prediction benchmarks showing that the combined model outperforms individual models, including state-of-the-art approaches.|预测知识图中实体之间的缺失链接是处理网络数据不完整性的基本任务。知识图嵌入将节点映射到向量空间中，预测新的链接，并根据几何标准对其进行评分。图中的关系可能遵循可以学习的模式，例如，一些关系可能是对称的，另一些可能是等级的。然而，不同嵌入模型的学习能力因模式的不同而异，到目前为止，还没有一个单独的模型能够同样好地学习所有的模式。在本文中，我们将来自多个模型的查询表示结合在一个统一的模型中，以合并由每个模型独立捕获的模式。我们的组合使用注意力来选择最合适的模型来回答每个查询。这些模型还被映射到一个非欧几里德流形，即 Poincar‘ e 球，以捕获结构模式，如层次结构，以及关系模式，如对称性。我们证明，我们的组合提供了更高的表达能力和推理能力比每个模型本身。因此，组合模型可以学习关系模式和结构模式。我们进行了广泛的实验分析与各种链接预测基准表明，组合模型优于个别模型，包括最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Link+Prediction+with+Attention+Applied+on+Multiple+Knowledge+Graph+Embedding+Models)|0|
|[SeqCare: Sequential Training with External Medical Knowledge Graph for Diagnosis Prediction in Healthcare Data](https://doi.org/10.1145/3543507.3583543)|Yongxin Xu, Xu Chu, Kai Yang, Zhiyuan Wang, Peinie Zou, Hongxin Ding, Junfeng Zhao, Yasha Wang, Bing Xie|Key Laboratory of High Confidence Software Technologies, Ministry of Education, China and Peking University, China; Tsinghua University, China; Zhongguancun Laboratory, China|Deep learning techniques are capable of capturing complex input-output relationships, and have been widely applied to the diagnosis prediction task based on web-based patient electronic health records (EHR) data. To improve the prediction and interpretability of pure data-driven deep learning with only a limited amount of labeled data, a pervasive trend is to assist the model training with knowledge priors from online medical knowledge graphs. However, they marginally investigated the label imbalance and the task-irrelevant noise in the external knowledge graph. The imbalanced label distribution would bias the learning and knowledge extraction towards the majority categories. The task-irrelevant noise introduces extra uncertainty to the model performance. To this end, aiming at by-passing the bias-variance trade-off dilemma, we introduce a new sequential learning framework, dubbed SeqCare, for diagnosis prediction with online medical knowledge graphs. Concretely, in the first step, SeqCare learns a bias-reduced space through a self-supervised graph contrastive learning task. Secondly, SeqCare reduces the learning uncertainty by refining the supervision signal and the graph structure of the knowledge graph simultaneously. Lastly, SeqCare trains the model in the bias-variance reduced space with a self-distillation to further filter out irrelevant information in the data. Experimental evaluations on two real-world datasets show that SeqCare outperforms state-of-the-art approaches. Case studies exemplify the interpretability of SeqCare. Moreover, the medical findings discovered by SeqCare are consistent with experts and medical literature.|深度学习技术能够捕捉复杂的输入输出关系，已广泛应用于基于网络病人电子健康记录(EHR)数据的诊断预测任务中。为了提高纯数据驱动的深度学习的预测性和可解释性，通过在线医学知识图的知识先验来辅助模型训练是一个普遍的趋势。然而，他们对外部知识图中的标签不平衡和任务不相关噪声的研究很少。不均衡的标签分布会使学习和知识抽取偏向于大多数类别。任务无关噪声给模型性能带来额外的不确定性。为此，针对偏差-方差权衡困境，我们引入了一个新的序列学习框架，称为 SeqCare，用于在线医学知识图的诊断预测。具体地说，在第一步中，SeqCare 通过一个自监督的图形对比学习任务学习一个减少偏差的空间。其次，SeqCare 通过同时细化监督信号和知识图的图形结构来降低学习的不确定性。最后，SeqCare 在偏差-方差缩减空间中用自精馏的方法对模型进行训练，以进一步滤除数据中的不相关信息。对两个真实世界数据集的实验评估表明，SeqCare 的性能优于最先进的方法。案例研究例证了 SeqCare 的可解释性。此外，SeqCare 发现的医学发现与专家和医学文献一致。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SeqCare:+Sequential+Training+with+External+Medical+Knowledge+Graph+for+Diagnosis+Prediction+in+Healthcare+Data)|0|
|[The Thin Ideology of Populist Advertising on Facebook during the 2019 EU Elections](https://doi.org/10.1145/3543507.3583267)|Arthur Capozzi, Gianmarco De Francisci Morales, Yelena Mejova, Corrado Monti, André Panisson|Computer Science, Universita' di Torino, Italy; Centai, Italy; ISI Foundation, Italy|Social media has been an important tool in the expansion of the populist message, and it is thought to have contributed to the electoral success of populist parties in the past decade. This study compares how populist parties advertised on Facebook during the 2019 European Parliamentary election. In particular, we examine commonalities and differences in which audiences they reach and on which issues they focus. By using data from Meta (previously Facebook) Ad Library, we analyze 45k ad campaigns by 39 parties, both populist and mainstream, in Germany, United Kingdom, Italy, Spain, and Poland. While populist parties represent just over 20% of the total expenditure on political ads, they account for 40% of the total impressions$\unicode{x2013}$most of which from Eurosceptic and far-right parties$\unicode{x2013}$thus hinting at a competitive advantage for populist parties on Facebook. We further find that ads posted by populist parties are more likely to reach male audiences, and sometimes much older ones. In terms of issues, populist politicians focus on monetary policy, state bureaucracy and reforms, and security, while the focus on EU and Brexit is on par with non-populist, mainstream parties. However, issue preferences are largely country-specific, thus supporting the view in political science that populism is a "thin ideology", that does not have a universal, coherent policy agenda. This study illustrates the usefulness of publicly available advertising data for monitoring the populist outreach to, and engagement with, millions of potential voters, while outlining the limitations of currently available data.|社交媒体一直是传播民粹主义信息的重要工具，据认为它在过去十年中为民粹主义政党在选举中取得成功做出了贡献。这项研究比较了2019年欧洲议会选举期间民粹主义政党在 Facebook 上的广告。特别是，我们研究了它们所接触到的受众以及它们所关注的问题的共性和差异。通过使用来自 Meta (以前的 Facebook)广告库的数据，我们分析了来自德国、英国、意大利、西班牙和波兰的39个民粹主义和主流政党的45000个广告活动。尽管民粹主义政党仅占政治广告总支出的20% 多一点，但他们占了总印象的40% ，其中大部分来自欧洲怀疑论者和极右翼政党，因此暗示了民粹主义政党在 Facebook 上的竞争优势。我们进一步发现，民粹主义政党发布的广告更有可能触及男性受众，有时甚至是年龄更大的受众。就问题而言，民粹主义政客关注的是货币政策、国家官僚机构和改革以及安全，而关注欧盟和 Brexit 的政党，与非民粹主义的主流政党不相上下。然而，问题的偏好在很大程度上是针对具体国家的，因此支持了政治科学中的观点，即民粹主义是一种“薄弱的意识形态”，没有一个普遍的、连贯的政策议程。这项研究说明了公开可用的广告数据在监测民粹主义者与数百万潜在选民的接触和接触方面的有用性，同时概述了目前可用数据的局限性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Thin+Ideology+of+Populist+Advertising+on+Facebook+during+the+2019+EU+Elections)|0|
|[FlexiFed: Personalized Federated Learning for Edge Clients with Heterogeneous Model Architectures](https://doi.org/10.1145/3543507.3583347)|Kaibin Wang, Qiang He, Feifei Chen, Chunyang Chen, Faliang Huang, Hai Jin, Yun Yang|Swinburne University of Technology, Australia; Deakin University, Australia; Monash University, Australia; Nanning Normal University, China; Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China and Swinburne University of Technology, Australia|Mobile and Web-of-Things (WoT) devices at the network edge account for more than half of the world’s web traffic, making a great data source for various machine learning (ML) applications, particularly federated learning (FL) which offers a promising solution to privacy-preserving ML feeding on these data. FL allows edge mobile and WoT devices to train a shared global ML model under the orchestration of a central parameter server. In the real world, due to resource heterogeneity, these edge devices often train different versions of models (e.g., VGG-16 and VGG-19) or different ML models (e.g., VGG and ResNet) for the same ML task (e.g., computer vision and speech recognition). Existing FL schemes have assumed that participating edge devices share a common model architecture, and thus cannot facilitate FL across edge devices with heterogeneous ML model architectures. We explored this architecture heterogeneity challenge and found that FL can and should accommodate these edge devices to improve model accuracy and accelerate model training. This paper presents our findings and FlexiFed, a novel scheme for FL across edge devices with heterogeneous model architectures, and three model aggregation strategies for accommodating architecture heterogeneity under FlexiFed. Experiments with four widely-used ML models on four public datasets demonstrate 1) the usefulness of FlexiFed; and 2) that compared with the state-of-the-art FL scheme, FlexiFed improves model accuracy by 2.6%-9.7% and accelerates model convergence by 1.24 × -4.04 ×.|处于网络边缘的移动和物联网(WoT)设备占据了世界网络流量的一半以上，为各种机器学习(ML)应用提供了一个巨大的数据源，特别是联邦学习(FL) ，它为依靠这些数据保护隐私的机器学习提供了一个有前途的解决方案。FL 允许边缘移动和 WoT 设备在一个中心参数服务器的协调下训练一个共享的全球 ML 模型。在现实世界中，由于资源的异质性，这些边缘设备经常为相同的机器学习任务训练不同版本的模型(例如，VGG-16和 VGG-19)或不同的机器学习模型(例如，VGG 和 ResNet)(例如，计算机视觉和语音识别)。现有的 FL 方案假定参与的边缘设备共享一个共同的模型架构，因此不能促进具有异构机器学习模型架构的边缘设备之间的 FL。我们探讨了这种体系结构异构性的挑战，发现 FL 可以而且应该适应这些边缘设备，以提高模型精度和加速模型训练。本文介绍了我们的研究结果和 FlexiFed，这是一个跨具有异构模型结构的边缘设备的 FL 的新方案，以及在 FlexiFed 下适应结构异构性的三种模型聚合策略。在四个公共数据集上对四个广泛使用的机器学习模型进行的实验表明: 1) FlexiFed 的有用性; 2)与最先进的 FL 方案相比，FlexiFed 将模型精度提高了2.6% -9.7% ，并加速了模型收敛1.24 × -4.04 × 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FlexiFed:+Personalized+Federated+Learning+for+Edge+Clients+with+Heterogeneous+Model+Architectures)|0|
|[PipeEdge: A Trusted Pipelining Collaborative Edge Training based on Blockchain](https://doi.org/10.1145/3543507.3583413)|Liang Yuan, Qiang He, Feifei Chen, Ruihan Dou, Hai Jin, Yun Yang|Swinburne University of Technology, Australia; Deakin University, Australia; Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China and Swinburne University of Technology, Australia; University of Waterloo, Canada|Powered by the massive data generated by the blossom of mobile and Web-of-Things (WoT) devices, Deep Neural Networks (DNNs) have developed both in accuracy and size in recent years. Conventional cloud-based DNN training incurs rapidly-increasing data and model transmission overheads as well as privacy issues. Mobile edge computing (MEC) provides a promising solution by facilitating DNN model training on edge servers at the network edge. However, edge servers often suffer from constrained resources and need to collaborate on DNN training. Unfortunately, managed by different telecoms, edge servers cannot properly collaborate with each other without incentives and trust. In this paper, we introduce PipeEdge, a scheme that promotes collaborative edge training between edge servers by introducing incentives and trust based on blockchain. Under the PipeEdge scheme, edge servers can hire trustworthy workers for pipelined DNN training tasks based on model parallelism. We implement PipeEdge and evaluate it comprehensively with four different DNN models. The results show that it outperforms state-of-the-art schemes by up to 173.98% with negligible overheads.|深度神经网络(DNN)由移动设备和物联网(WoT)设备的蓬勃发展所产生的大量数据所驱动，近年来在精度和规模上都有所发展。传统的基于云的 DNN 培训会带来快速增长的数据和模型传输开销以及隐私问题。移动边缘计算(MEC)为网络边缘服务器上的 DNN 模型训练提供了一种有前途的解决方案。然而，边缘服务器经常受到资源的限制，需要协作进行 DNN 培训。不幸的是，由不同电信公司管理的边缘服务器如果没有激励和信任，就无法正确地相互协作。本文介绍了 PipeEdge 方案，该方案通过引入基于区块链的激励和信任来促进边缘服务器之间的协同边缘训练。在 PipeEdge 方案下，边缘服务器可以雇佣值得信赖的工人，根据模型并行性执行流水线 DNN 培训任务。我们实现了 PipeEdge，并使用四种不同的 DNN 模型对其进行了综合评估。结果表明，该方案的性能优于最先进的方案达173.98% ，开销可以忽略不计。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PipeEdge:+A+Trusted+Pipelining+Collaborative+Edge+Training+based+on+Blockchain)|0|
|[ELASTIC: Edge Workload Forecasting based on Collaborative Cloud-Edge Deep Learning](https://doi.org/10.1145/3543507.3583436)|Yanan Li, Haitao Yuan, Zhe Fu, Xiao Ma, Mengwei Xu, Shangguang Wang|Tsinghua University, China; Beijing University of Posts and Telecommunications, China; Nanyang Technological University, Singapore|With the rapid development of edge computing in the post-COVID19 pandemic period, precise workload forecasting is considered the basis for making full use of the edge limited resources, and both edge service providers (ESPs) and edge service consumers (ESCs) can benefit significantly from it. Existing paradigms of workload forecasting (i.e., edge-only or cloud-only) are improper, due to failing to consider the inter-site correlations and might suffer from significant data transmission delays. With the increasing adoption of edge platforms by web services, it is critical to balance both accuracy and efficiency in workload forecasting. In this paper, we propose ELASTIC, which is the first study that leverages a cloud-edge collaborative paradigm for edge workload forecasting with multi-view graphs. Specifically, at the global stage, we design a learnable aggregation layer on each edge site to reduce the time consumption while capturing the inter-site correlation. Additionally, at the local stage, we design a disaggregation layer combining both the intra-site correlation and inter-site correlation to improve the prediction accuracy. Extensive experiments on realistic edge workload datasets collected from China’s largest edge service provider show that ELASTIC outperforms state-of-the-art methods, decreases time consumption, and reduces communication cost.|随着后 COVID19大流行时期边缘计算的快速发展，精确的工作量预测被认为是充分利用边缘有限资源的基础，边缘服务提供商(ESP)和边缘服务消费者(ESCs)都可以从中受益匪浅。现有的工作量预测模式(即仅边缘预测或仅云预测)是不适当的，因为没有考虑到站点间的相关性，并可能遭受显著的数据传输延迟。随着 Web 服务越来越多地采用边缘平台，在工作负载预测中平衡准确性和效率至关重要。在本文中，我们提出了 ELASTIC，这是第一个利用云端协作范式进行多视图边缘工作负荷预测的研究。具体来说，在全局阶段，我们在每个边缘站点上设计一个可学习的聚合层，以减少时间消耗，同时捕获站点间的相关性。此外，在局部阶段，我们设计了一个解体层，将场内相关性和场间相关性结合起来，以提高预测的准确性。对中国最大的边缘服务提供商收集的真实边缘工作负载数据集进行的大量实验表明，ELASTIC 优于最先进的方法，减少了时间消耗，降低了通信成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELASTIC:+Edge+Workload+Forecasting+based+on+Collaborative+Cloud-Edge+Deep+Learning)|0|
|[DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation Framework for Efficient Device Model Generalization](https://doi.org/10.1145/3543507.3583451)|Zheqi Lv, Wenqiao Zhang, Shengyu Zhang, Kun Kuang, Feng Wang, Yongwei Wang, Zhengyu Chen, Tao Shen, Hongxia Yang, Beng Chin Ooi, Fei Wu|National University of Singapore, Singapore; Zhejiang University, China; Alibaba Group, China|Device Model Generalization (DMG) is a practical yet under-investigated research topic for on-device machine learning applications. It aims to improve the generalization ability of pre-trained models when deployed on resource-constrained devices, such as improving the performance of pre-trained cloud models on smart mobiles. While quite a lot of works have investigated the data distribution shift across clouds and devices, most of them focus on model fine-tuning on personalized data for individual devices to facilitate DMG. Despite their promising, these approaches require on-device re-training, which is practically infeasible due to the overfitting problem and high time delay when performing gradient calculation on real-time data. In this paper, we argue that the computational cost brought by fine-tuning can be rather unnecessary. We consequently present a novel perspective to improving DMG without increasing computational cost, i.e., device-specific parameter generation which directly maps data distribution to parameters. Specifically, we propose an efficient Device-cloUd collaborative parametErs generaTion framework DUET. DUET is deployed on a powerful cloud server that only requires the low cost of forwarding propagation and low time delay of data transmission between the device and the cloud. By doing so, DUET can rehearse the device-specific model weight realizations conditioned on the personalized real-time data for an individual device. Importantly, our DUET elegantly connects the cloud and device as a 'duet' collaboration, frees the DMG from fine-tuning, and enables a faster and more accurate DMG paradigm. We conduct an extensive experimental study of DUET on three public datasets, and the experimental results confirm our framework's effectiveness and generalisability for different DMG tasks.|设备模型综合(DMG)是设备上机器学习应用中一个实用但尚未得到充分研究的课题。它旨在提高预先训练的模型在资源有限的设备上部署时的泛化能力，例如提高预先训练的云模型在智能手机上的性能。虽然许多工作已经研究了跨云和设备的数据分布转移，但大多数工作集中在针对个人设备的个性化数据的模型微调上，以促进 DMG。尽管这些方法很有前景，但是需要在设备上进行再训练，这在实际中是不可行的，因为在对实时数据进行梯度计算时，存在过拟合问题和高时延。在本文中，我们认为微调带来的计算成本可能是相当不必要的。因此，我们提出了一个新的视角来改善 DMG 而不增加计算成本，即，设备特定的参数生成，直接映射数据分布到参数。具体地说，我们提出了一种高效的设备云协同参数生成框架 DUET。DUET 部署在一个强大的云服务器上，只需要较低的转发传播成本和较低的设备与云之间的数据传输延迟。通过这样做，DUET 可以预演设备特定的模型权重实现条件下的个性化实时数据为单个设备。重要的是，我们的 DUET 作为一个“二重奏”协作优雅地连接了云和设备，从微调中解放了 DMG，并支持更快、更准确的 DMG 范例。我们对三个公共数据集上的 DUET 进行了广泛的实验研究，实验结果证实了我们的框架对不同 DMG 任务的有效性和通用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DUET:+A+Tuning-Free+Device-Cloud+Collaborative+Parameters+Generation+Framework+for+Efficient+Device+Model+Generalization)|0|
|[RL-MPCA: A Reinforcement Learning Based Multi-Phase Computation Allocation Approach for Recommender Systems](https://doi.org/10.1145/3543507.3583313)|Jiahong Zhou, Shunhui Mao, Guoliang Yang, Bo Tang, Qianlong Xie, Lebin Lin, Xingxing Wang, Dong Wang|Meituan, China|Recommender systems aim to recommend the most suitable items to users from a large number of candidates. Their computation cost grows as the number of user requests and the complexity of services (or models) increases. Under the limitation of computation resources (CRs), how to make a trade-off between computation cost and business revenue becomes an essential question. The existing studies focus on dynamically allocating CRs in queue truncation scenarios (i.e., allocating the size of candidates), and formulate the CR allocation problem as an optimization problem with constraints. Some of them focus on single-phase CR allocation, and others focus on multi-phase CR allocation but introduce some assumptions about queue truncation scenarios. However, these assumptions do not hold in other scenarios, such as retrieval channel selection and prediction model selection. Moreover, existing studies ignore the state transition process of requests between different phases, limiting the effectiveness of their approaches. This paper proposes a Reinforcement Learning (RL) based Multi-Phase Computation Allocation approach (RL-MPCA), which aims to maximize the total business revenue under the limitation of CRs. RL-MPCA formulates the CR allocation problem as a Weakly Coupled MDP problem and solves it with an RL-based approach. Specifically, RL-MPCA designs a novel deep Q-network to adapt to various CR allocation scenarios, and calibrates the Q-value by introducing multiple adaptive Lagrange multipliers (adaptive-λ) to avoid violating the global CR constraints. Finally, experiments on the offline simulation environment and online real-world recommender system validate the effectiveness of our approach.|推荐系统的目的是从大量的候选人中向用户推荐最合适的项目。它们的计算成本随着用户请求的数量和服务(或模型)的复杂性的增加而增加。在计算资源有限的情况下，如何在计算成本和业务收益之间取得平衡成为一个必须解决的问题。现有的研究集中于在队列截断情况下(即分配候选人的人数)动态分配登记册编号，并将登记册编号分配问题制订为一个有约束的最佳化问题。其中一些关注于单相 CR 分配，另一些关注于多相 CR 分配，但是引入了一些关于队列截断场景的假设。但是，这些假设在其他场景中不成立，例如检索通道选择和预测模型选择。此外，现有的研究忽视了请求在不同阶段之间的状态转换过程，限制了这些方法的有效性。本文提出了一种基于强化学习的多阶段计算分配方法(RL-MPCA) ，其目标是在客户关系的限制下实现企业总收入的最大化。RL-MPCA 将 CR 分配问题表示为弱耦合 MDP 问题，并用基于 RL 的方法求解。具体来说，RL-MPCA 设计了一种新的深层 Q 网络来适应各种 CR 分配场景，并通过引入多个自适应拉格朗日乘子(Adaptive-λ)来校准 Q 值，以避免违反全局 CR 约束。最后，离线仿真环境和在线真实世界推荐系统的实验验证了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RL-MPCA:+A+Reinforcement+Learning+Based+Multi-Phase+Computation+Allocation+Approach+for+Recommender+Systems)|0|
|[Learning To Rank Resources with GNN](https://doi.org/10.1145/3543507.3583360)|Ulugbek Ergashev, Eduard C. Dragut, Weiyi Meng|Computer Science, Binghamton University, USA; Computer and Information Sciences, Temple University, USA|As the content on the Internet continues to grow, many new dynamically changing and heterogeneous sources of data constantly emerge. A conventional search engine cannot crawl and index at the same pace as the expansion of the Internet. Moreover, a large portion of the data on the Internet is not accessible to traditional search engines. Distributed Information Retrieval (DIR) is a viable solution to this as it integrates multiple shards (resources) and provides a unified access to them. Resource selection is a key component of DIR systems. There is a rich body of literature on resource selection approaches for DIR. A key limitation of the existing approaches is that they primarily use term-based statistical features and do not generally model resource-query and resource-resource relationships. In this paper, we propose a graph neural network (GNN) based approach to learning-to-rank that is capable of modeling resource-query and resource-resource relationships. Specifically, we utilize a pre-trained language model (PTLM) to obtain semantic information from queries and resources. Then, we explicitly build a heterogeneous graph to preserve structural information of query-resource relationships and employ GNN to extract structural information. In addition, the heterogeneous graph is enriched with resource-resource type of edges to further enhance the ranking accuracy. Extensive experiments on benchmark datasets show that our proposed approach is highly effective in resource selection. Our method outperforms the state-of-the-art by 6.4% to 42% on various performance metrics.|随着 Internet 上的内容不断增长，许多新的动态变化和异构的数据源不断出现。传统的搜索引擎无法以与互联网扩展同样的速度爬行和索引。此外，互联网上的大部分数据不能被传统的搜索引擎访问。分布式信息检索(DIR)是一个可行的解决方案，因为它集成了多个碎片(资源) ，并提供了对它们的统一访问。资源选择是 DIR 系统的关键组成部分。关于 DIR 的资源选择方法有大量的文献。现有方法的一个主要局限性在于，它们主要使用基于术语的统计特征，并且一般不对资源-查询和资源-资源关系建模。本文提出了一种基于图神经网络(GNN)的排序学习方法，该方法能够对资源-查询和资源-资源关系进行建模。具体来说，我们利用预先训练的语言模型(PTLM)从查询和资源中获取语义信息。然后，我们显式地构建一个异构图来保存查询-资源关系的结构信息，并使用 GNN 来提取结构信息。此外，对异构图进行了资源-资源类型边的丰富，进一步提高了排序的准确性。对基准数据集的大量实验表明，该方法在资源选择方面是非常有效的。在各种性能指标上，我们的方法比最先进的方法表现好6.4% 到42% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+To+Rank+Resources+with+GNN)|0|
|[CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval](https://doi.org/10.1145/3543507.3583369)|Xunguang Wang, Yiqun Lin, Xiaomeng Li|The Hong Kong University of Science and Technology, China; The Hong Kong University of Science and Technology, China and The Hong Kong University of Science and Technology Shenzhen Research Institute, China|Deep hashing has been extensively utilized in massive image retrieval because of its efficiency and effectiveness. However, deep hashing models are vulnerable to adversarial examples, making it essential to develop adversarial defense methods for image retrieval. Existing solutions achieved limited defense performance because of using weak adversarial samples for training and lacking discriminative optimization objectives to learn robust features. In this paper, we present a min-max based Center-guided Adversarial Training, namely CgAT, to improve the robustness of deep hashing networks through worst adversarial examples. Specifically, we first formulate the center code as a semantically-discriminative representative of the input image content, which preserves the semantic similarity with positive samples and dissimilarity with negative examples. We prove that a mathematical formula can calculate the center code immediately. After obtaining the center codes in each optimization iteration of the deep hashing network, they are adopted to guide the adversarial training process. On the one hand, CgAT generates the worst adversarial examples as augmented data by maximizing the Hamming distance between the hash codes of the adversarial examples and the center codes. On the other hand, CgAT learns to mitigate the effects of adversarial samples by minimizing the Hamming distance to the center codes. Extensive experiments on the benchmark datasets demonstrate the effectiveness of our adversarial training algorithm in defending against adversarial attacks for deep hashing-based retrieval. Compared with the current state-of-the-art defense method, we significantly improve the defense performance by an average of 18.61\%, 12.35\%, and 11.56\% on FLICKR-25K, NUS-WIDE, and MS-COCO, respectively. The code is available at https://github.com/xunguangwang/CgAT.|深度散列由于其高效性和有效性，在海量图像检索中得到了广泛的应用。然而，深度散列模型很容易受到敌对实例的影响，因此开发图像检索的敌对防御方法是非常必要的。现有的解决方案由于使用弱对手样本进行训练，缺乏区分性优化目标来学习鲁棒特征，因此防御性能有限。本文提出了一种基于最小-最大中心引导的对抗训练方法，即 CgAT，通过最坏的对抗实例来提高深度哈希网络的鲁棒性。具体来说，我们首先将中心代码表示为输入图像内容的语义识别代表，保留了正样本的语义相似性和负样本的语义不相似性。我们证明了一个数学公式可以立即计算中心码。在深度哈希网络的每次优化迭代中获得中心码后，采用中心码来指导对抗训练过程。一方面，通过最大化对手的散列码和中心代码之间的汉明距离，CgAT 生成最坏的对手的例子作为增强数据。另一方面，CgAT 学会了通过最小化对中心代码的汉明距离来减轻对抗性样本的影响。在基准数据集上的大量实验证明了我们的对抗性训练算法在防御基于深度散列检索的对抗性攻击方面的有效性。与目前最先进的防御方法相比，FLICKR-25K、 NUS-WIDE 和 MS-COCO 的防御性能分别平均提高了18.61% 、12.35% 和11.56% 。密码可在 https://github.com/xunguangwang/cgat 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CgAT:+Center-Guided+Adversarial+Training+for+Deep+Hashing-Based+Retrieval)|0|
|[Algorithmic Vibe in Information Retrieval](https://doi.org/10.1145/3543507.3583384)|Ali Montazeralghaem, Nick Craswell, Ryen W. White, Ahmed Hassan Awadallah, Byungki Byun|Microsoft, USA; University of Massachusetts Amherst, USA|When information retrieval systems return a ranked list of results in response to a query, they may be choosing from a large set of candidate results that are equally useful and relevant. This means we might be able to identify a difference between rankers A and B, where ranker A systematically prefers a certain type of relevant results. Ranker A may have this systematic difference (different “vibe”) without having systematically better or worse results according to standard information retrieval metrics. We first show that a vibe difference can exist, comparing two publicly available rankers, where the one that is trained on health-related queries will systematically prefer health-related results, even for non-health queries. We define a vibe metric that lets us see the words that a ranker prefers. We investigate the vibe of search engine clicks vs. human labels. We perform an initial study into correcting for vibe differences to make ranker A more like ranker B via changes in negative sampling during training.|当信息检索系统对一个查询返回一个排名结果列表时，它们可能会从一大堆同样有用和相关的候选结果中进行选择。这意味着我们可能能够识别排名 A 和 B 之间的差异，其中排名 A 系统地偏好某种类型的相关结果。排名 a 可能有这种系统性差异(不同的“内心感应”) ，而没有根据标准的信息检索指标得出系统性更好或更差的结果。我们首先展示了内心感应差异的存在，比较两个公开可用的排名，其中受过健康相关查询培训的人会系统地偏好与健康相关的结果，即使对于非健康查询也是如此。我们定义一个内心感应度量，让我们看到一个排名喜欢的词。我们调查了搜索引擎点击与人类标签之间的关系。我们进行了一个初步的研究，以纠正内心感应的差异，使排名 A 更像排名 B 通过改变负面抽样在训练期间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Algorithmic+Vibe+in+Information+Retrieval)|0|
|[Geographic Information Retrieval Using Wikipedia Articles](https://doi.org/10.1145/3543507.3583469)|Amir Krause, Sara Cohen|The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University, Israel|Assigning semantically relevant, real-world locations to documents opens new possibilities to perform geographic information retrieval. We propose a novel approach to automatically determine the latitude-longitude coordinates of appropriate Wikipedia articles with high accuracy, leveraging both text and metadata in the corpus. By examining articles whose base-truth coordinates are known, we show that our method attains a substantial improvement over state of the art works. We subsequently demonstrate how our approach could yield two benefits: (1) detecting significant geolocation errors in Wikipedia; and (2) proposing approximated coordinates for hundreds of thousands of articles which are not traditionally considered to be locations (such as events, ideas or people), opening new possibilities for conceptual geographic retrievals over Wikipedia.|为文档分配语义相关的、现实世界中的位置，为执行地理信息检索开辟了新的可能性。我们提出了一种新的方法，利用语料库中的文本和元数据，高精度地自动确定适当 Wikipedia 文章的经纬度坐标。通过检查文章的基础-真理坐标已知，我们表明，我们的方法取得了实质性的改善状态的艺术作品。我们随后展示了我们的方法如何产生两个好处: (1)检测维基百科中的重大地理定位错误; (2)提出几十万个传统上不被认为是地点的文章(如事件、想法或人)的大致坐标，为维基百科的概念地理检索开辟了新的可能性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geographic+Information+Retrieval+Using+Wikipedia+Articles)|0|
|[Optimizing Guided Traversal for Fast Learned Sparse Retrieval](https://doi.org/10.1145/3543507.3583497)|Yifan Qiao, Yingrui Yang, Haixin Lin, Tao Yang|Department of Computer Science, University of California at Santa Barbara, USA; Department of Computer Science, University of California, Santa Barbara, USA|Recent studies show that BM25-driven dynamic index skipping can greatly accelerate MaxScore-based document retrieval based on the learned sparse representation derived by DeepImpact. This paper investigates the effectiveness of such a traversal guidance strategy during top k retrieval when using other models such as SPLADE and uniCOIL, and finds that unconstrained BM25-driven skipping could have a visible relevance degradation when the BM25 model is not well aligned with a learned weight model or when retrieval depth k is small. This paper generalizes the previous work and optimizes the BM25 guided index traversal with a two-level pruning control scheme and model alignment for fast retrieval using a sparse representation. Although there can be a cost of increased latency, the proposed scheme is much faster than the original MaxScore method without BM25 guidance while retaining the relevance effectiveness. This paper analyzes the competitiveness of this two-level pruning scheme, and evaluates its tradeoff in ranking relevance and time efficiency when searching several test datasets.|最近的研究表明，BM25驱动的动态指数跳跃可以大大加快基于深度影响学习稀疏表示的基于 MaxScore 的文献检索。本文研究了使用 SPLADE 和 uniCOIL 等其他模型进行 top k 检索时，这种遍历指导策略的有效性，发现当 BM25模型与学习权重模型不匹配或检索深度 k 较小时，无约束 BM25驱动的跳跃可能具有明显的相关性退化。本文在总结前人工作的基础上，采用两级剪枝控制策略和稀疏表示模型对齐方法对 BM25引导的索引遍历进行了优化，实现了快速检索。虽然可能会增加延迟的代价，提出的方案比原来的 MaxScore 方法快得多没有 BM25的指导，同时保留了相关性的有效性。本文分析了这种两级剪枝方案的竞争力，并在搜索多个测试数据集时，对其在排序相关性和时间效率方面的权衡进行了评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Guided+Traversal+for+Fast+Learned+Sparse+Retrieval)|0|
|[Stability and Efficiency of Personalised Cultural Markets](https://doi.org/10.1145/3543507.3583315)|Haiqing Zhu, Yun Kuen Cheung, Lexing Xie|Australian National University, Australia; Royal Holloway University of London, United Kingdom|This work is concerned with the dynamics of online cultural markets, namely, attention allocation of many users on a set of digital goods with infinite supply. Such dynamic is important in shaping processes and outcomes in society, from trending items in entertainment, collective knowledge creation, to election outcomes. The outcomes of online cultural markets are susceptible to intricate social influence dynamics, particularly so when the community comprises consumers with heterogeneous interests. This has made formal analysis of these markets improbable. In this paper, we remedy this by establishing robust connections between influence dynamics and optimization processes, in trial-offer markets where the consumer preferences are modelled by multinomial logit. Among other results, we show that the proportional-response-esque influence dynamic is equivalent to stochastic mirror descent on a convex objective function, thus leading to a stable and predictable outcome. When all consumers are homogeneous, the objective function has a natural interpretation as a weighted sum of efficiency and diversity of the culture market. In simulations driven by real-world preferences collected from a large-scale recommender system, we observe that ranking strategies aligned with the underlying heterogeneous preferences are more stable, and achieves higher efficiency and diversity. In simulations driven by real-world preferences collected from a large-scale recommender system, we observe that ranking strategies aligned with the underlying heterogeneous preferences are more stable, and achieves higher efficiency and diversity.|本文研究的是在线文化市场的动态变化，即在无限供应的数字商品上，许多用户的注意力分配。这种动态对于塑造社会的进程和结果至关重要，从娱乐的趋势项目、集体知识创造到选举结果。在线文化市场的结果容易受到错综复杂的社会影响力动态的影响，特别是当社区由具有不同兴趣的消费者组成时。这使得对这些市场的正式分析成为不可能。在本文中，我们通过建立影响力动态和最优化过程之间的强有力的联系来纠正这个问题，在试销市场中，消费者的偏好是由多项式 logit 建模的。在其他结果中，我们表明，比例响应方式的影响动态相当于随机镜下降的凸目标函数，从而导致一个稳定和可预测的结果。当所有消费者都是同质的时候，目标函数就自然地被解释为文化市场效率和多样性的加权和。在从大规模推荐系统中收集的现实世界偏好驱动的模拟中，我们观察到与潜在的异质偏好相一致的排序策略更加稳定，并且实现更高的效率和多样性。在从大规模推荐系统中收集的现实世界偏好驱动的模拟中，我们观察到与潜在的异质偏好相一致的排序策略更加稳定，并且实现更高的效率和多样性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stability+and+Efficiency+of+Personalised+Cultural+Markets)|0|
|[Eligibility Mechanisms: Auctions Meet Information Retrieval](https://doi.org/10.1145/3543507.3583478)|Gagan Goel, Renato Paes Leme, Jon Schneider, David Thompson, Hanrui Zhang|Google, USA; Carnegie Mellon University, USA|The design of internet advertisement systems is both an auction design problem and an information retrieval (IR) problem. As an auction, the designer needs to take the participants incentives into account. As an information retrieval problem, it needs to identify the ad that it is the most relevant to a user out of an enormous set of ad candidates. Those aspects are combined by first having an IR system narrow down the initial set of ad candidates to a manageable size followed by an auction that ranks and prices those candidates. If the IR system uses information about bids, agents could in principle manipulate the system by manipulating the IR stage even when the subsequent auction is truthful. In this paper we investigate the design of truthful IR mechanisms, which we term eligibility mechanisms. We model it as a truthful version of the stochastic probing problem. We show that there is a constant gap between the truthful and non-truthful versions of the stochastic probing problem and exhibit a constant approximation algorithm. En route, we also characterize the set of eligibility mechanisms, which provides necessary and sufficient conditions for an IR system to be truthful.|互联网广告系统的设计既是一个拍卖设计问题，也是一个信息检索(IR)问题。作为一种拍卖，设计师需要考虑参与者的激励因素。作为一个信息检索问题，它需要从大量的候选广告中找出与用户最相关的广告。将这些方面结合起来，首先通过投资者关系系统将最初的广告候选人缩小到一个可管理的规模，然后通过拍卖对这些候选人进行排名和定价。如果 IR 系统使用关于出价的信息，即使随后的拍卖是真实的，代理人原则上也可以通过操纵 IR 阶段来操纵系统。本文研究了真实信息检索机制的设计，我们称之为资格机制。我们将其建模为随机探测问题的真实版本。我们证明了随机探测问题的真实版本和非真实版本之间存在一个恒定的差距，并呈现出一个恒定的近似演算法。在此过程中，我们还刻画了一组资格机制，它为 IR 系统的真实性提供了充分的必要条件。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Eligibility+Mechanisms:+Auctions+Meet+Information+Retrieval)|0|
|[Scoping Fairness Objectives and Identifying Fairness Metrics for Recommender Systems: The Practitioners' Perspective](https://doi.org/10.1145/3543507.3583204)|Jessie J. Smith, Lex Beattie, Henriette Cramer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scoping+Fairness+Objectives+and+Identifying+Fairness+Metrics+for+Recommender+Systems:+The+Practitioners'+Perspective)|0|
|[Same Same, But Different: Conditional Multi-Task Learning for Demographic-Specific Toxicity Detection](https://doi.org/10.1145/3543507.3583290)|Soumyajit Gupta, Sooyong Lee, Maria DeArteaga, Matthew Lease||Algorithmic bias often arises as a result of differential subgroup validity, in which predictive relationships vary across groups. For example, in toxic language detection, comments targeting different demographic groups can vary markedly across groups. In such settings, trained models can be dominated by the relationships that best fit the majority group, leading to disparate performance. We propose framing toxicity detection as multi-task learning (MTL), allowing a model to specialize on the relationships that are relevant to each demographic group while also leveraging shared properties across groups. With toxicity detection, each task corresponds to identifying toxicity against a particular demographic group. However, traditional MTL requires labels for all tasks to be present for every data point. To address this, we propose Conditional MTL (CondMTL), wherein only training examples relevant to the given demographic group are considered by the loss function. This lets us learn group specific representations in each branch which are not cross contaminated by irrelevant labels. Results on synthetic and real data show that using CondMTL improves predictive recall over various baselines in general and for the minority demographic group in particular, while having similar overall accuracy.|算法偏差通常由于不同的子群效度而产生，其中预测关系因组而异。例如，在毒性语言检测中，针对不同人口群体的评论可能因群体而有显著差异。在这种情况下，训练有素的模型可以被最适合大多数群体的关系所主导，从而导致不同的表现。我们建议将毒性检测框架为多任务学习(MTL) ，允许模型专门处理与每个人口组相关的关系，同时利用跨组的共享属性。通过毒性检测，每项任务都对应于确定针对特定人口群体的毒性。但是，传统的 MTL 要求为每个数据点显示所有任务的标签。为了解决这个问题，我们提出了条件 MTL (CondMTL) ，其中只有与给定人口组相关的训练实例被损失函数考虑。这使我们能够了解每个分支中不受不相关标签交叉污染的特定分组表示。对合成和真实数据的研究结果表明，使用 CondMTL 提高了对各种基线的预测性回忆，特别是对少数人口群体，同时具有相似的整体准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Same+Same,+But+Different:+Conditional+Multi-Task+Learning+for+Demographic-Specific+Toxicity+Detection)|0|
|[Towards Explainable Collaborative Filtering with Taste Clusters Learning](https://doi.org/10.1145/3543507.3583303)|Yuntao Du, Jianxun Lian, Jing Yao, Xiting Wang, Mingqi Wu, Lu Chen, Yunjun Gao, Xing Xie||Collaborative Filtering (CF) is a widely used and effective technique for recommender systems. In recent decades, there have been significant advancements in latent embedding-based CF methods for improved accuracy, such as matrix factorization, neural collaborative filtering, and LightGCN. However, the explainability of these models has not been fully explored. Adding explainability to recommendation models can not only increase trust in the decisionmaking process, but also have multiple benefits such as providing persuasive explanations for item recommendations, creating explicit profiles for users and items, and assisting item producers in design improvements.   In this paper, we propose a neat and effective Explainable Collaborative Filtering (ECF) model that leverages interpretable cluster learning to achieve the two most demanding objectives: (1) Precise - the model should not compromise accuracy in the pursuit of explainability; and (2) Self-explainable - the model's explanations should truly reflect its decision-making process, not generated from post-hoc methods. The core of ECF is mining taste clusters from user-item interactions and item profiles.We map each user and item to a sparse set of taste clusters, and taste clusters are distinguished by a few representative tags. The user-item preference, users/items' cluster affiliations, and the generation of taste clusters are jointly optimized in an end-to-end manner. Additionally, we introduce a forest mechanism to ensure the model's accuracy, explainability, and diversity. To comprehensively evaluate the explainability quality of taste clusters, we design several quantitative metrics, including in-cluster item coverage, tag utilization, silhouette, and informativeness. Our model's effectiveness is demonstrated through extensive experiments on three real-world datasets.|协同过滤(CF)是推荐系统中广泛使用的有效技术。近几十年来，基于潜在嵌入的 CF 方法在提高准确性方面取得了重大进展，例如矩阵分解、神经协同过滤和 LightGCN。然而，这些模型的可解释性还没有得到充分的探索。为推荐模型增加可解释性不仅可以增加对决策过程的信任，而且还有多种好处，例如为项目推荐提供有说服力的解释，为用户和项目创建明确的配置文件，以及帮助项目生产者改进设计。在本文中，我们提出了一个简洁而有效的可解释协同过滤(ECF)模型，它利用可解释的聚类学习来实现两个最严格的目标: (1)精确——模型在追求可解释性的过程中不应该损害准确性; (2)自我解释——模型的解释应该真实地反映其决策过程，而不是由事后方法产生。ECF 的核心是从用户-项目交互和项目配置文件中挖掘味觉集群。我们将每个用户和项目映射到一个稀疏的味觉集群，味觉集群通过几个代表性的标签来区分。用户项偏好、用户/项目的集群附属关系以及味道集群的生成都以端到端的方式进行了联合优化。此外，我们还引入了森林机制来保证模型的准确性、可解释性和多样性。为了全面评价味觉集群的可解释性质量，我们设计了几个量化指标，包括集群内项目覆盖率、标签利用率、轮廓和信息量。通过对三个实际数据集的大量实验，验证了该模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Explainable+Collaborative+Filtering+with+Taste+Clusters+Learning)|0|
|[Towards Fair Allocation in Social Commerce Platforms](https://doi.org/10.1145/3543507.3583398)|Anjali Gupta, Shreyans J. Nagori, Abhijnan Chakraborty, Rohit Vaish, Sayan Ranu, Prajit Prashant Sinai Nadkarni, Narendra Varma Dasararaju, Muthusamy Chelliah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Allocation+in+Social+Commerce+Platforms)|0|
|[Fairness-Aware Clique-Preserving Spectral Clustering of Temporal Graphs](https://doi.org/10.1145/3543507.3583423)|Dongqi Fu, Dawei Zhou, Ross Maciejewski, Arie Croitoru, Marcus Boyd, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness-Aware+Clique-Preserving+Spectral+Clustering+of+Temporal+Graphs)|0|
|[HybridEval: A Human-AI Collaborative Approach for Evaluating Design Ideas at Scale](https://doi.org/10.1145/3543507.3583496)|Sepideh Mesbah, Ines Arous, Jie Yang, Alessandro Bozzon|University of Fribourg, Switzerland; Booking, Netherlands; Delft University of Technology, Netherlands|Evaluating design ideas is necessary to predict their success and assess their impact early on in the process. Existing methods rely either on metrics computed by systems that are effective but subject to errors and bias, or experts’ ratings, which are accurate but expensive and long to collect. Crowdsourcing offers a compelling way to evaluate a large number of design ideas in a short amount of time while being cost-effective. Workers’ evaluation is, however, less reliable and might substantially differ from experts’ evaluation. In this work, we investigate workers’ rating behavior and compare it with experts. First, we instrument a crowdsourcing study where we asked workers to evaluate design ideas from three innovation challenges. We show that workers share similar insights with experts but tend to rate more generously and weigh certain criteria more importantly. Next, we develop a hybrid human-AI approach that combines a machine learning model with crowdsourcing to evaluate ideas. Our approach models workers’ reliability and bias while leveraging ideas’ textual content to train a machine learning model. It is able to incorporate experts’ ratings whenever available, to supervise the model training and infer worker performance. Results show that our framework outperforms baseline methods and requires significantly less training data from experts, thus providing a viable solution for evaluating ideas at scale.|评估设计想法是必要的，以预测他们的成功和评估他们的影响早在过程中。现有的方法要么依赖于有效但容易出错和偏差的系统计算出的指标，要么依赖于专家的评分，这些评分准确但昂贵，而且需要很长时间才能收集到。众包提供了一个引人注目的方式来评估大量的设计想法在短时间内，同时具有成本效益。然而，工人的评估不太可靠，可能与专家的评估大不相同。在这项工作中，我们调查工人的评分行为，并与专家进行比较。首先，我们进行了一项众包研究，要求工人评估来自三个创新挑战的设计理念。我们的研究表明，员工与专家有着相似的见解，但他们倾向于更慷慨地给出评价，更重视某些标准。接下来，我们开发了一种混合的人工智能方法，它结合了机器学习模型和众包来评估想法。我们的方法模拟工人的可靠性和偏见，同时利用想法的文本内容来训练机器学习模型。它能够在任何时候合并专家的评分，以监督模型培训和推断工人的表现。结果表明，我们的框架优于基线方法，需要的专家培训数据明显减少，从而为大规模评估想法提供了一个可行的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HybridEval:+A+Human-AI+Collaborative+Approach+for+Evaluating+Design+Ideas+at+Scale)|0|
|[A Multi-task Model for Emotion and Offensive Aided Stance Detection of Climate Change Tweets](https://doi.org/10.1145/3543507.3583860)|Apoorva Upadhyaya, Marco Fisichella, Wolfgang Nejdl|L3S Research Center, Leibniz University Hannover, Germany|In this work, we address the United Nations Sustainable Development Goal 13: Climate Action by focusing on identifying public attitudes toward climate change on social media platforms such as Twitter. Climate change is threatening the health of the planet and humanity. Public engagement is critical to address climate change. However, climate change conversations on Twitter tend to polarize beliefs, leading to misinformation and fake news that influence public attitudes, often dividing them into climate change believers and deniers. Our paper proposes an approach to classify the attitude of climate change tweets (believe/deny/ambiguous) to identify denier statements on Twitter. Most existing approaches for detecting stances and classifying climate change tweets either overlook deniers’ tweets or do not have a suitable architecture. The relevant literature suggests that emotions and higher levels of toxicity are prevalent in climate change Twitter conversations, leading to a delay in appropriate climate action. Therefore, our work focuses on learning stance detection (main task) while exploiting the auxiliary tasks of recognizing emotions and offensive utterances. We propose a multimodal multitasking framework MEMOCLiC that captures the input data using different embedding techniques and attention frameworks, and then incorporates the learned emotional and offensive expressions to obtain an overall representation of the features relevant to the stance of the input tweet. Extensive experiments conducted on a novel curated climate change dataset and two benchmark stance detection datasets (SemEval-2016 and ClimateStance-2022) demonstrate the effectiveness of our approach.|在这项工作中，我们致力于实现联合国可持续发展目标13: 气候行动，重点是在 Twitter 等社交媒体平台上确定公众对气候变化的态度。气候变化正威胁着地球和人类的健康。公众参与对应对气候变化至关重要。然而，Twitter 上关于气候变化的讨论往往会导致信仰的两极分化，导致错误信息和假新闻，从而影响公众态度，往往将公众分为气候变化信徒和否认者。我们的论文提出了一种方法来分类气候变化推文的态度(相信/否认/模棱两可) ，以确定否认者的声明在 Twitter 上。大多数现有的检测立场和分类气候变化推文的方法要么忽略否认者的推文，要么没有一个合适的架构。相关文献表明，在气候变化的 Twitter 对话中，情绪和较高的毒性水平普遍存在，导致适当的气候行动出现延误。因此，我们的工作集中在学习姿势检测(主要任务) ，同时利用辅助任务的识别情绪和攻击性话语。我们提出了一个多模式多任务框架 MEMOCLiC，它使用不同的嵌入技术和注意力框架捕获输入数据，然后结合所学到的情绪和攻击性表达来获得与输入 tweet 立场相关的特征的整体表示。在一个新的策划气候变化数据集和两个基准姿态检测数据集(SemEval-2016和 ClimateStance-2022)上进行的大量实验证明了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-task+Model+for+Emotion+and+Offensive+Aided+Stance+Detection+of+Climate+Change+Tweets)|0|
|[Cross-center Early Sepsis Recognition by Medical Knowledge Guided Collaborative Learning for Data-scarce Hospitals](https://doi.org/10.1145/3543507.3583989)|Ruiqing Ding, Fangjie Rong, Xiao Han, Leye Wang|Peking University, China; Shanghai University of Finance and Economics, China|There are significant regional inequities in health resources around the world. It has become one of the most focused topics to improve health services for data-scarce hospitals and promote health equity through knowledge sharing among medical institutions. Because electronic medical records (EMRs) contain sensitive personal information, privacy protection is unavoidable and essential for multi-hospital collaboration. In this paper, for a common disease in ICU patients, sepsis, we propose a novel cross-center collaborative learning framework guided by medical knowledge, SofaNet, to achieve early recognition of this disease. The Sepsis-3 guideline, published in 2016, defines that sepsis can be diagnosed by satisfying both suspicion of infection and Sequential Organ Failure Assessment (SOFA) greater than or equal to 2. Based on this knowledge, SofaNet adopts a multi-channel GRU structure to predict SOFA values of different systems, which can be seen as an auxiliary task to generate better health status representations for sepsis recognition. Moreover, we only achieve feature distribution alignment in the hidden space during cross-center collaborative learning, which ensures secure and compliant knowledge transfer without raw data exchange. Extensive experiments on two open clinical datasets, MIMIC-III and Challenge, demonstrate that SofaNet can benefit early sepsis recognition when hospitals only have limited EMRs.|世界各地在卫生资源方面存在着严重的区域不平等。通过医疗机构之间的知识共享，改善数据稀缺的医院的卫生服务，促进卫生公平，已成为最重点的议题之一。由于电子病历(EMR)包含敏感的个人信息，隐私保护是不可避免的，也是多医院合作的必要条件。在这篇文章中，我们针对 ICU 患者常见的一种疾病，败血症，提出了一种新的跨中心合作学习框架，以医学知识为指导，SofaNet，以实现对这种疾病的早期识别。2016年发布的脓毒症3指南规定，脓毒症可以通过满足感染的怀疑和大于或等于2的序贯性器官衰竭评估(SOFA)来诊断。在此基础上，SofaNet 采用多通道 GRU 结构来预测不同系统的 SOFA 值，这可以看作是一个辅助任务，以产生更好的脓毒症识别健康状态表示。此外，我们只有在跨中心合作学习时才能在隐藏空间中实现特征分布对齐，从而确保在没有原始数据交换的情况下安全和兼容的知识传输。在两个开放的临床数据集 MIMIC-III 和 Challenge 上的大量实验表明，当医院只有有限的 EMR 时，SofaNet 可以有利于早期脓毒症识别。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-center+Early+Sepsis+Recognition+by+Medical+Knowledge+Guided+Collaborative+Learning+for+Data-scarce+Hospitals)|0|
|[Breaking Filter Bubble: A Reinforcement Learning Framework of Controllable Recommender System](https://doi.org/10.1145/3543507.3583856)|Zhenyang Li, Yancheng Dong, Chen Gao, Yizhou Zhao, Dong Li, Jianye Hao, Kai Zhang, Yong Li, Zhi Wang|Tsinghua University, China; Carnegie Mellon University, USA; Tsinghua Shenzhen International Graduate School, Tsinghua University, China and Research Institute of Tsinghua, Pearl River Delta, China; Huawei Noah's Ark Lab, China; Tsinghua University, China and Huawei Noah's Ark Lab, China; Tsinghua-Berkeley Shenzhen Institute, Tsinghua Shenzhen International Graduate School, China and Peng Cheng Laboratory, China|In the information-overloaded era of the Web, recommender systems that provide personalized content filtering are now the mainstream portal for users to access Web information. Recommender systems deploy machine learning models to learn users’ preferences from collected historical data, leading to more centralized recommendation results due to the feedback loop. As a result, it will harm the ranking of content outside the narrowed scope and limit the options seen by users. In this work, we first conduct data analysis from a graph view to observe that the users’ feedback is restricted to limited items, verifying the phenomenon of centralized recommendation. We further develop a general simulation framework to derive the procedure of the recommender system, including data collection, model learning, and item exposure, which forms a loop. To address the filter bubble issue under the feedback loop, we then propose a general and easy-to-use reinforcement learning-based method, which can adaptively select few but effective connections between nodes from different communities as the exposure list. We conduct extensive experiments in the simulation framework based on large-scale real-world datasets. The results demonstrate that our proposed reinforcement learning-based control method can serve as an effective solution to alleviate the filter bubble and the separated communities induced by it. We believe the proposed framework of controllable recommendation in this work can inspire not only the researchers of recommender systems, but also a broader community concerned with artificial intelligence algorithms’ impact on humanity, especially for those vulnerable populations on the Web.|在信息过载的 Web 时代，提供个性化内容过滤的推荐系统现在已经成为用户访问 Web 信息的主流门户。推荐系统部署机器学习模型，从收集的历史数据中了解用户的偏好，由于反馈回路的存在，推荐结果更加集中。因此，它将损害内容在狭窄范围之外的排名，并限制用户看到的选项。本文首先从图的角度进行数据分析，发现用户的反馈仅限于有限的项目，验证了集中推荐的现象。我们进一步开发了一个通用的模拟框架来推导推荐系统的过程，包括数据收集、模型学习和项目曝光，形成一个循环。为了解决反馈回路下的过滤泡问题，提出了一种通用的、易于使用的强化学习方法，该方法可以自适应地选择不同社区节点之间少量但有效的连接作为暴露列表。我们在基于大规模真实世界数据集的仿真框架中进行了广泛的实验。结果表明，本文提出的基于强化学习的控制方法可以作为一种有效的解决方案，以减轻过滤气泡及其引起的社区分离。我们相信，这项工作中提出的可控推荐框架不仅可以激励推荐系统的研究人员，而且可以激励更广泛的社区关注人工智能算法对人类的影响，特别是对那些网络上的弱势群体。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+Filter+Bubble:+A+Reinforcement+Learning+Framework+of+Controllable+Recommender+System)|0|
|[CollabEquality: A Crowd-AI Collaborative Learning Framework to Address Class-wise Inequality in Web-based Disaster Response](https://doi.org/10.1145/3543507.3583871)|Yang Zhang, Lanyu Shang, Ruohan Zong, Huimin Zeng, Zhenrui Yue, Dong Wang|School of Information Sciences, University of Illinois Urbana-Champaign, USA|Web-based disaster response (WebDR) is emerging as a pervasive approach to acquire real-time situation awareness of disaster events by collecting timely observations from the Web (e.g., social media). This paper studies a class-wise inequality problem in WebDR applications where the objective is to address the limitation of current WebDR solutions that often have imbalanced classification performance across different classes. To address such a limitation, this paper explores the collaborative strengths of the diversified yet complementary biases of AI and crowdsourced human intelligence to ensure a more balanced and accurate performance for WebDR applications. However, two critical challenges exist: 1) it is difficult to identify the imbalanced AI results without knowing the ground-truth WebDR labels a priori; ii) it is non-trivial to address the class-wise inequality problem using potentially imperfect crowd labels. To address the above challenges, we develop CollabEquality, an inequality-aware crowd-AI collaborative learning framework that carefully models the inequality bias of both AI and human intelligence from crowdsourcing systems into a principled learning framework. Extensive experiments on two real-world WebDR applications demonstrate that CollabEquality consistently outperforms the state-of-the-art baselines by significantly reducing class-wise inequality while improving the WebDR classification accuracy.|基于 Web 的灾难响应(WebDR)正在成为一种普遍的方法，通过从 Web (例如，社交媒体)收集及时的观察结果来获得对灾难事件的实时情况感知。本文研究了 WebDR 应用程序中的类别不等式问题，其目的是解决目前 WebDR 解决方案的局限性，这些解决方案通常在不同类别之间具有不平衡的分类性能。为了解决这一局限性，本文探讨了人工智能和众包人类智能的多样化但互补的偏见的协作优势，以确保更平衡和准确的 WebDR 应用程序的性能。然而，存在两个关键的挑战: 1)在不知道基本事实 WebDR 标签的情况下很难识别不平衡的 AI 结果; 2)使用潜在不完美的群体标签来解决类别不平等问题是不平凡的。为了应对上述挑战，我们开发了 Collabequity，这是一个意识到不平等的群体人工智能合作学习框架，它仔细地将人工智能和人类智能的不平等偏见从众包系统建模成一个有原则的学习框架。在两个真实世界的 WebDR 应用程序上进行的大量实验表明，CollabEquity 通过显著减少类别不平等，同时提高 WebDR 分类准确性，始终优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CollabEquality:+A+Crowd-AI+Collaborative+Learning+Framework+to+Address+Class-wise+Inequality+in+Web-based+Disaster+Response)|0|
|[MoleRec: Combinatorial Drug Recommendation with Substructure-Aware Molecular Representation Learning](https://doi.org/10.1145/3543507.3583872)|Nianzu Yang, Kaipeng Zeng, Qitian Wu, Junchi Yan|Shanghai Jiao Tong University, China|Combinatorial drug recommendation involves recommending a personalized combination of medication (drugs) to a patient over his/her longitudinal history, which essentially aims at solving a combinatorial optimization problem that pursues high accuracy under the safety constraint. Among existing learning-based approaches, the association between drug substructures (i.e., a sub-graph of the molecule that contributes to certain chemical effect) and the target disease is largely overlooked, though the function of drugs in fact exhibits strong relevance with particular substructures. To address this issue, we propose a molecular substructure-aware encoding method entitled MoleRec that entails a hierarchical architecture aimed at modeling inter-substructure interactions and individual substructures’ impact on patient’s health condition, in order to identify those substructures that really contribute to healing patients. Specifically, MoleRec learns to attentively pooling over substructure representations which will be element-wisely re-scaled by the model’s inferred relevancy with a patient’s health condition to obtain a prior-knowledge-informed drug representation. We further design a weight annealing strategy for drug-drug-interaction (DDI) objective to adaptively control the balance between accuracy and safety criteria throughout training. Experiments on the MIMIC-III dataset demonstrate that our approach achieves new state-of-the-art performance w.r.t. four accuracy and safety metrics. Our source code is publicly available at https://github.com/yangnianzu0515/MoleRec.|组合药物推荐包括在病人的纵向病史中向病人推荐个性化的药物组合(药物) ，其主要目的是解决在安全约束下追求高准确性的组合优化问题。在现有的基于学习的方法中，药物子结构(即有助于某些化学效应的分子的子图)与目标疾病之间的关联在很大程度上被忽视，尽管药物的功能实际上与特定的子结构显示出强烈的相关性。为了解决这个问题，我们提出了一个名为 MoleRec 的分子子结构感知编码方法，它需要一个层次结构，旨在建模子结构间的相互作用和个体子结构对患者健康状况的影响，以确定那些真正有助于治愈患者的子结构。具体而言，MoleRec 学习仔细汇集子结构表示，这些子结构表示将通过模型与患者健康状况的推断相关性进行元素智能重新缩放，以获得事先知情的药物表示。我们进一步设计了药物-药物相互作用(DDI)目标的权重退火策略，以自适应地控制整个训练过程中准确性和安全性标准之间的平衡。在 MIMIC-III 数据集上的实验表明，我们的方法实现了新的最先进的性能和四个准确性和安全性指标。我们的源代码可以在 https://github.com/yangnianzu0515/molerec 上公开。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoleRec:+Combinatorial+Drug+Recommendation+with+Substructure-Aware+Molecular+Representation+Learning)|0|
|[Moral Narratives Around the Vaccination Debate on Facebook](https://doi.org/10.1145/3543507.3583865)|Mariano Gastón Beiró, Jacopo D'Ignazi, Victoria Perez Bustos, Maria Florencia Prado, Kyriaki Kalimeri|Universidad de Buenos Aires. Facultad de Ingeniería, Paseo Colón 850, C1063ACV, Argentina and CONICET, Universidad de Buenos Aires, INTECIN, Paseo Colón 850, C1063ACV, Argentina; ; ISI Foundation, Italy|Vaccine hesitancy is a complex issue with psychological, cultural, and even societal factors entangled in the decision-making process. The narrative around this process is captured in our everyday interactions; social media data offer a direct and spontaneous view of peoples' argumentation. Here, we analysed more than 500,000 public posts and comments from Facebook Pages dedicated to the topic of vaccination to study the role of moral values and, in particular, the understudied role of the Liberty moral foundation from the actual user-generated text. We operationalise morality by employing the Moral Foundations Theory, while our proposed framework is based on recurrent neural network classifiers with a short memory and entity linking information. Our findings show that the principal moral narratives around the vaccination debate focus on the values of Liberty, Care, and Authority. Vaccine advocates urge compliance with the authorities as prosocial behaviour to protect society. On the other hand, vaccine sceptics mainly build their narrative around the value of Liberty, advocating for the right to choose freely whether to adhere or not to the vaccination. We contribute to the automatic understanding of vaccine hesitancy drivers emerging from user-generated text, providing concrete insights into the moral framing around vaccination decision-making. Especially in emergencies such as the Covid-19 pandemic, contrary to traditional surveys, these insights can be provided contemporary to the event, helping policymakers craft communication campaigns that adequately address the concerns of the hesitant population.|疫苗犹豫不决是一个复杂的问题，心理，文化，甚至社会因素纠缠在决策过程中。围绕这一过程的叙述被捕捉在我们日常的互动中; 社交媒体数据提供了人们争论的直接和自发的视角。在这里，我们分析了超过500,000个来自 Facebook 页面的公开帖子和评论，这些帖子和评论专门针对疫苗接种这一主题，研究道德价值观的作用，特别是从实际的用户生成的文本中研究自由道德基础的被忽视的作用。我们运用道德基础理论来操作道德，而我们提出的框架是基于短记忆的递归神经网络分类器和连接信息的实体。我们的研究结果表明，围绕疫苗接种辩论的主要道德叙事集中在自由、关怀和权威的价值观上。疫苗倡导者敦促当局遵守规定，以此作为保护社会的亲社会行为。另一方面，疫苗怀疑论者主要围绕自由的价值建立他们的叙述，倡导自由选择是否坚持接种疫苗的权利。我们有助于自动理解疫苗犹豫驱动程序出现从用户生成的文本，提供具体的见解围绕疫苗接种决策的道德框架。特别是在2019冠状病毒疾病大流行这样的紧急情况下，与传统的调查不同，这些见解可以在事件发生时提供，帮助政策制定者制定沟通运动，充分解决犹豫不决的民众的关切。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Moral+Narratives+Around+the+Vaccination+Debate+on+Facebook)|0|
|[Exploration of Framing Biases in Polarized Online Content Consumption](https://doi.org/10.1145/3543873.3587534)|Markus ReiterHaas|Institute of Interactive Systems and Data Science, Graz University of Technology, Austria|The study of framing bias on the Web is crucial in our digital age, as the framing of information can influence human behavior and decision on critical issues such as health or politics. Traditional frame analysis requires a curated set of frames derived from manual content analysis by domain experts. In this work, we introduce a frame analysis approach based on pretrained Transformer models that let us capture frames in an exploratory manner beyond predefined frames. In our experiments on two public online news and social media datasets, we show that our approach lets us identify underexplored conceptualizations, such as that health-related content is framed in terms of beliefs for conspiracy media, while mainstream media is instead concerned with science. We anticipate our work to be a starting point for further research on exploratory computational framing analysis using pretrained Transformers.|在我们的数字时代，研究网络上的框架偏见是至关重要的，因为信息的框架可以影响人类的行为和决策，如健康或政治等关键问题。传统的框架分析需要一组精心策划的框架，这些框架来自于领域专家的手工内容分析。在这项工作中，我们介绍了一种基于预先训练的变压器模型的帧分析方法，使我们能够以一种探索性的方式捕获超越预先定义的帧。在我们对两个公共在线新闻和社交媒体数据集的实验中，我们表明，我们的方法让我们确定了未被充分探索的概念化，例如，健康相关的内容被框定在阴谋媒体的信念方面，而主流媒体关注的是科学。我们期望我们的工作是一个开始点，进一步研究探索性计算框架分析使用预先训练的变压器。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploration+of+Framing+Biases+in+Polarized+Online+Content+Consumption)|0|
|[On Modeling Long-Term User Engagement from Stochastic Feedback](https://doi.org/10.1145/3543873.3587626)|Guoxi Zhang, Xing Yao, Xuanji Xiao|China Central Depository & Clearing Co., Ltd., China; Graduate School of Informatics, Kyoto University, Japan; Shopee Inc., China|An ultimate goal of recommender systems (RS) is to improve user engagement. Reinforcement learning (RL) is a promising paradigm for this goal, as it directly optimizes overall performance of sequential recommendation. However, many existing RL-based approaches induce huge computational overhead, because they require not only the recommended items but also all other candidate items to be stored. This paper proposes an efficient alternative that does not require the candidate items. The idea is to model the correlation between user engagement and items directly from data. Moreover, the proposed approach consider randomness in user feedback and termination behavior, which are ubiquitous for RS but rarely discussed in RL-based prior work. With online A/B experiments on real-world RS, we confirm the efficacy of the proposed approach and the importance of modeling the two types of randomness.|推荐系统(RS)的最终目标是提高用户参与度。强化学习(RL)是这个目标的一个很有前途的范例，因为它直接优化了顺序推荐的整体性能。然而，许多现有的基于 RL 的方法会产生巨大的计算开销，因为它们不仅需要存储推荐的项，而且还需要存储所有其他候选项。本文提出了一种不需要候选项的有效方案。其思想是直接从数据中建模用户参与度和项目之间的相关性。此外，提出的方法考虑了用户反馈和终止行为的随机性，这在 RS 中是普遍存在的，但在基于 RL 的先前工作中很少讨论。通过在现实世界中的在线 A/B 实验，我们证实了该方法的有效性和建模两种类型的随机性的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Modeling+Long-Term+User+Engagement+from+Stochastic+Feedback)|0|
|[CaML: Carbon Footprinting of Household Products with Zero-Shot Semantic Text Similarity](https://doi.org/10.1145/3543507.3583882)|Bharathan Balaji, Venkata Sai Gargeya Vunnava, Geoffrey Guest, Jared Kramer|Amazon, USA|Products contribute to carbon emissions in each phase of their life cycle, from manufacturing to disposal. Estimating the embodied carbon in products is a key step towards understanding their impact, and undertaking mitigation actions. Precise carbon attribution is challenging at scale, requiring both domain expertise and granular supply chain data. As a first-order approximation, standard reports use Economic Input-Output based Life Cycle Assessment (EIO-LCA) which estimates carbon emissions per dollar at an industry sector level using transactions between different parts of the economy. EIO-LCA models map products to an industry sector, and uses the corresponding carbon per dollar estimates to calculate the embodied carbon footprint of a product. An LCA expert needs to map each product to one of upwards of 1000 potential industry sectors. To reduce the annotation burden, the standard practice is to group products by categories, and map categories to their corresponding industry sector. We present CaML, an algorithm to automate EIO-LCA using semantic text similarity matching by leveraging the text descriptions of the product and the industry sector. CaML uses a pre-trained sentence transformer model to rank the top-5 matches, and asks a human to check if any of them are a good match. We annotated 40K products with non-experts. Our results reveal that pre-defined product categories are heterogeneous with respect to EIO-LCA industry sectors, and lead to a large mean absolute percentage error (MAPE) of 51% in kgCO2e/$. CaML outperforms the previous manually intensive method, yielding a MAPE of 22% with no domain labels (zero-shot). We compared annotations of a small sample of 210 products with LCA experts, and find that CaML accuracy is comparable to that of annotations by non-experts.|产品在其生命周期的每个阶段(从生产到处理)都会造成碳排放。评估产品中的含碳量是了解其影响并采取缓解行动的关键一步。精确的碳归属在规模上具有挑战性，需要领域专业知识和细粒度供应链数据。作为一阶近似，标准报告使用基于经济投入产出的生命周期评估(EIO-LCA) ，该评估利用不同经济部门之间的交易，在行业部门水平上估计每美元的碳排放量。生命周期评估模型将产品映射到一个行业部门，并使用相应的每美元碳排放估计值来计算产品的碳足印。LCA 专家需要将每个产品映射到1000个以上的潜在行业部门之一。为了减少注释负担，标准实践是按类别对产品进行分组，并将类别映射到相应的行业部门。我们提出了 CaML，一种利用产品和工业部门的文本描述，使用语义文本相似性匹配实现 EIO-LCA 自动化的算法。CaML 使用一个预先训练好的句子转换模型对前5个匹配项进行排序，并要求人类检查它们中是否有一个是良好匹配的。我们用非专家注释40K 产品。我们的研究结果表明，预定义的产品类别相对于 EIO-LCA 行业部门是异构的，并导致 kgCO2e/$的大平均绝对百分比误差(MAPE)为51% 。CaML 优于以前的手动密集型方法，产生的 MAPE 为22% ，没有域标签(0-shot)。我们将210个产品的小样本注释与 LCA 专家进行了比较，发现 CaML 的准确性与非专家的注释相当。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CaML:+Carbon+Footprinting+of+Household+Products+with+Zero-Shot+Semantic+Text+Similarity)|0|
|[RDF Playground: An Online Tool for Learning about the Semantic Web](https://doi.org/10.1145/3543873.3587325)|Bastián Inostroza, Raúl Cid, Aidan Hogan|DCC, Universidad de Chile, Chile and Instituto Milenio Fundamentos de los Datos (IMFD), Chile; DCC, Universidad de Chile, Chile|We present RDF Playground: a web-based tool to assist those who wish to learn or teach about the Semantic Web. The tool integrates functionalities relating to the key features of RDF, allowing users to specify an RDF graph in Turtle syntax, visualise it as an interactive graph, query it using SPARQL, reason over it using OWL 2 RL, and to validate it using SHACL or ShEx. The tool further provides the ability to import and explore data from the Web through a graph-based Linked Data browser. We discuss the design and functionality of the tool, its implementation, and the results of a usability study considering students from a Web of Data course that used it for lab assignments. We conclude with a discussion of these results, as well as future directions that we envisage for improving the tool.|我们介绍 RDF Playground: 一个基于 Web 的工具，用于帮助那些希望学习或教授语义 Web 的人。该工具集成了与 RDF 关键特性相关的功能，允许用户用 Turtle 语法指定一个 RDF 图形，将其可视化为一个交互式图形，使用 SPARQL 查询它，使用 OWL 2 RL 推理它，并使用 SHACL 或 ShEx 验证它。该工具还提供了通过基于图形的关联数据浏览器从 Web 导入和探索数据的能力。我们讨论了该工具的设计和功能，它的实现，以及一个可用性研究的结果，该研究考虑了使用它完成实验作业的数据网络课程的学生。最后，我们讨论了这些结果以及我们设想的改进该工具的未来方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RDF+Playground:+An+Online+Tool+for+Learning+about+the+Semantic+Web)|0|
|[Locating Faulty Applications via Semantic and Topology Estimation](https://doi.org/10.1145/3543873.3584660)|Shuyi Niu, Jiawei Jin, Xiutian Huang, Yonggeng Wang, Wenhao Xu, Youyong Kong|Southeast University, China; Ant Group, China|With the explosion of Internet product users, how to locate the faulty ones from numerous back-end applications after a customer complaint has become an essential issue in improving user experience. However, existing solutions mostly rely on manual testing to infer the fault, severely limiting their efficiency. In this paper, we transform the problem of locating faulty applications into two subproblems and propose a fully automated framework. We design a scorecard model in one stage to evaluate the semantic relevance between applications and customer complaints. Then in the other stage, topology graphs that reflect the actual calling relationship and engineering connection relationship between applications are utilized to evaluate the topology relevance between applications. Specifically, we employ a multi-graph co-learning framework constrained by consistency-independence loss and an engineering-theory-driven clustering strategy for the unsupervised learning of graphs. With semantic and topology relevance, we can comprehensively locate relevant faulty applications. Experiments on the Alipay dataset show that our method gains significant improvements in both model performance and efficiency.|随着互联网产品用户的爆炸式增长，如何在用户投诉之后从众多的后端应用程序中定位出故障用户已成为提高用户体验的关键问题。然而，现有的解决方案大多依赖于人工测试来推断故障，这严重限制了它们的效率。本文将故障应用定位问题转化为两个子问题，并提出了一个全自动化的框架。我们在一个阶段中设计了一个记分卡模型来评估应用程序和客户投诉之间的语义相关性。然后在另一个阶段，利用反映实际调用关系和应用间工程连接关系的拓扑图来评估应用间的拓扑相关性。具体来说，我们采用了一个受一致性独立性损失约束的多图协同学习框架和一个工程理论驱动的聚类策略来处理图的非监督式学习。通过语义和拓扑相关性，我们可以全面定位相关的故障应用。在支付宝数据集上的实验表明，该方法在模型性能和效率方面都得到了显著的改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Locating+Faulty+Applications+via+Semantic+and+Topology+Estimation)|0|
|[Analyzing COVID-Related Social Discourse on Twitter using Emotion, Sentiment, Political Bias, Stance, Veracity and Conspiracy Theories](https://doi.org/10.1145/3543873.3587622)|Youri Peskine, Raphaël Troncy, Paolo Papotti|EURECOM, France|Online misinformation has become a major concern in recent years, and it has been further emphasized during the COVID-19 pandemic. Social media platforms, such as Twitter, can be serious vectors of misinformation online. In order to better understand the spread of these fake-news, lies, deceptions, and rumours, we analyze the correlations between the following textual features in tweets: emotion, sentiment, political bias, stance, veracity and conspiracy theories. We train several transformer-based classifiers from multiple datasets to detect these textual features and identify potential correlations using conditional distributions of the labels. Our results show that the online discourse regarding some topics, such as COVID-19 regulations or conspiracy theories, is highly controversial and reflects the actual U.S. political landscape.|近年来，网上虚假信息已成为一个主要问题，在2019冠状病毒疾病大流行期间，这一问题得到了进一步强调。像 Twitter 这样的社交媒体平台可能是网络上错误信息的严重载体。为了更好地理解这些假新闻、谎言、欺骗和谣言的传播，我们分析了以下推文文本特征之间的相关性: 情绪、情绪、政治偏见、立场、真实性和阴谋论。我们训练了多个来自多个数据集的基于转换器的分类器来检测这些文本特征，并使用标签的条件分布来识别潜在的相关性。我们的研究结果表明，网上关于某些话题的讨论，比如2019冠状病毒疾病监管或阴谋论，具有高度的争议性，反映了美国实际的政治环境。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+COVID-Related+Social+Discourse+on+Twitter+using+Emotion,+Sentiment,+Political+Bias,+Stance,+Veracity+and+Conspiracy+Theories)|0|
|[Machine Learning for Streaming Media](https://doi.org/10.1145/3543873.3589751)|Sudarshan Lamkhede, Praveen Chandar, Vladan Radosavljevic, Amit Goyal, Lan Luo|Amazon Music, USA; Spotify, USA; Netflix Research, USA; University of Southern California, USA|Streaming media has become a popular medium for consumers of all ages, with people spending several hours a day streaming videos, games, music, or podcasts across devices. Most global streaming services have introduced Machine Learning (ML) into their operations to personalize consumer experience, improve content, and further enhance the value proposition of streaming services. Despite the rapid growth, there is a need to bridge the gap between academic research and industry requirements and build connections between researchers and practitioners in the field. This workshop aims to provide a unique forum for practitioners and researchers interested in Machine Learning to get together, exchange ideas and get a pulse for the state of the art in research and burning issues in the industry.|流媒体已经成为所有年龄段消费者的流行媒体，人们每天花几个小时在各种设备上观看视频、游戏、音乐或播客。大多数全球流媒体服务已经将机器学习(ML)引入到它们的运营中，以个性化消费者体验、改善内容并进一步提高流媒体服务的价值主张。尽管增长迅速，但仍需要弥合学术研究和行业需求之间的差距，并在该领域的研究人员和从业人员之间建立联系。本研讨会旨在为对机器学习感兴趣的从业人员和研究人员提供一个独特的论坛，让他们聚集在一起，交流思想，了解行业研究的最新进展和热点问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Machine+Learning+for+Streaming+Media)|0|
|[Interleaved Online Testing in Large-Scale Systems](https://doi.org/10.1145/3543873.3587572)|Nan Bi, Bai Li, Ruoyuan Gao, Graham Edge, Sachin Ahuja|Amazon, USA|Online testing is indispensable in decision making for information retrieval systems. Interleaving emerges as an online testing method with orders of magnitude higher sensitivity than the pervading A/B testing. It merges the compared results into a single interleaved result to show to users, and attributes user actions back to the systems being tested. However, its pairwise design also brings practical challenges to real-world systems, in terms of effectively comparing multiple (more than two) systems and interpreting the magnitude of raw interleaving measurement. We present two novel methods to address these challenges that make interleaving practically applicable. The first method infers the ordering of multiple systems based on interleaving pairwise results with false discovery control. The second method estimates A/B effect size based on interleaving results using a weighted linear model that adjust for uncertainties of different measurements. We showcase the effectiveness of our methods in large-scale e-commerce experiments, reporting as many as 75 interleaving results, and provide extensive evaluations of their underlying assumptions.|在线测试对于信息检索系统的决策是不可或缺的。交错测试作为一种在线测试方法出现，其灵敏度数量级高于普遍采用的 A/B 测试。它将比较的结果合并到一个交错的结果中以显示给用户，并将用户操作归结到正在测试的系统。然而，它的成对设计也给现实世界的系统带来了实际的挑战，就有效地比较多个(两个以上)系统和解释原始交错测量的大小而言。我们提出了两种新的方法来解决这些挑战，使交织实际上适用。第一种方法是基于错误发现控制交织成对结果来推断多系统的排序。第二种方法基于交错结果估计 A/B 效应大小，使用加权线性模型来调整不同测量的不确定性。我们展示了我们的方法在大规模电子商务实验中的有效性，报告了多达75个交错的结果，并提供了对其基本假设的广泛评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interleaved+Online+Testing+in+Large-Scale+Systems)|0|
|[Impact of COVID-19 Pandemic on Cultural Products Interests](https://doi.org/10.1145/3543873.3587594)|Ke Li, Zhiwen Yu, Ying Zhang, Bin Guo|School of Computer Science, Northwestern Polytechnical University, China; School of Computer Science, Northwestern Polytechnical University, China and Harbin Engineering University, China|The COVID-19 pandemic has had a significant impact on human behaviors and how it influenced peoples’ interests in cultural products is an unsolved problem. While prior studies mostly adopt subjective surveys to find an answer, these methods are always suffering from high cost, limited size, and subjective bias. Inspired by the rich user-oriented data over the Internet, this work explores the possibility to leverage users’ search logs to reflect humans’ underlying cultural product interests. To further examine how the COVID-19 mobility policy might influence cultural interest changes, we propose a new regression discontinuity design that has the additional potential to predict the recovery phase of peoples’ cultural product interests. By analyzing the 1592 search interest time series in 6 countries, we found different patterns of change in interest in movies, music, and art during the COVID-19 pandemic, but a clear overall incremental increase. Across the six countries we studied, we found that changes in interest in cultural products were found to be strongly correlated with mobility and that as mobility declined, interest in movies, music, and art increased by an average of 35, 27 and 20, respectively, with these changes lasting at least eight weeks.|2019冠状病毒疾病疫情对人类行为产生了重大影响，它如何影响人们对文化产品的兴趣是一个尚未解决的问题。以往的研究大多采用主观调查的方法来寻找答案，但这些方法往往成本高、规模有限、存在主观偏差。受互联网上丰富的以用户为导向的数据的启发，这项工作探索了利用用户的搜索日志来反映人类潜在的文化产品兴趣的可能性。为了进一步研究2019冠状病毒疾病流动政策可能如何影响文化兴趣的变化，我们提出了一种新的回归不连续性设计，它具有额外的潜力来预测人们的文化产品兴趣的恢复阶段。通过分析6个国家1592年的搜索兴趣时间序列，我们发现在2019冠状病毒疾病大流行期间，人们对电影、音乐和艺术的兴趣有不同的变化模式，但总体上有明显的增长。在我们研究的六个国家中，我们发现对文化产品兴趣的变化与流动性密切相关，随着流动性的下降，对电影、音乐和艺术的兴趣分别平均增加了35、27和20，这些变化至少持续了八周。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Impact+of+COVID-19+Pandemic+on+Cultural+Products+Interests)|0|
|[Enhancing Data Space Semantic Interoperability through Machine Learning: a Visionary Perspective](https://doi.org/10.1145/3543873.3587658)|Zeyd Boukhers, Christoph Lange, Oya Beyan|Fraunhofer Institute for Applied Information Technology, Germany and Faculty of Medicine and University Hospital Cologne, University of Cologne, Germany; Faculty of Medicine and University Hospital Cologne, University of Cologne, Germany and Fraunhofer Institute for Applied Information Technology, Germany; Fraunhofer Institute for Applied Information Technology, Germany and RWTH Aachen University, Germany|Our vision paper outlines a plan to improve the future of semantic interoperability in data spaces through the application of machine learning. The use of data spaces, where data is exchanged among members in a self-regulated environment, is becoming increasingly popular. However, the current manual practices of managing metadata and vocabularies in these spaces are time-consuming, prone to errors, and may not meet the needs of all stakeholders. By leveraging the power of machine learning, we believe that semantic interoperability in data spaces can be significantly improved. This involves automatically generating and updating metadata, which results in a more flexible vocabulary that can accommodate the diverse terminologies used by different sub-communities. Our vision for the future of data spaces addresses the limitations of conventional data exchange and makes data more accessible and valuable for all members of the community.|我们的愿景文件概述了一个通过机器学习应用改善数据空间语义互操作性未来的计划。数据空间的使用正变得越来越流行，数据空间是在一个自我管理的环境中在成员之间交换数据的地方。然而，在这些空间中管理元数据和词汇表的当前手工实践非常耗时，容易出错，并且可能不能满足所有涉众的需求。通过利用机器学习的力量，我们相信数据空间的语义互操作性可以得到显著改善。这涉及到自动生成和更新元数据，从而产生更灵活的词汇表，可以适应不同子社区使用的不同术语。我们对数据空间未来的展望解决了传统数据交换的局限性，并使数据对社区的所有成员更容易获得和更有价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Data+Space+Semantic+Interoperability+through+Machine+Learning:+a+Visionary+Perspective)|0|
|[The PLASMA Framework: Laying the Path to Domain-Specific Semantics in Dataspaces](https://doi.org/10.1145/3543873.3587662)|Alexander Paulus, André Pomp, Tobias Meisen|Institute for Technologies and Management of Digital Transformation, University of Wuppertal, Germany|Modern data management is evolving from centralized integration-based solutions to a non-integration-based process of finding, accessing and processing data, as observed within dataspaces. Common reference dataspace architectures assume that sources publish their own domain-specific schema. These schemas, also known as semantic models, can only be partially created automatically and require oversight and refinement by human modellers. Non-expert users, such as mechanical engineers or municipal workers, often have difficulty building models because they are faced with multiple ontologies, classes, and relations, and existing tools are not designed for non-expert users. The PLASMA framework consists of a platform and auxiliary services that focus on providing non-expert users with an accessible way to create and edit semantic models, combining automation approaches and support systems such as a recommendation engine. It also provides data conversion from raw data to RDF. In this paper we highlight the main features, like the modeling interface and the data conversion engine. We discuss how PLASMA as a tool is suitable for building semantic models by non-expert users in the context of dataspaces and show some applications where PLASMA has already been used in data management projects.|现代数据管理正在从基于集中式集成的解决方案演变为基于非集成的查找、访问和处理数据的过程，正如在数据空间中观察到的那样。通用参考数据空间体系结构假设源发布自己的特定于域的模式。这些模式也称为语义模型，只能部分自动创建，需要人类建模者进行监督和细化。非专家用户，如机械工程师或市政工人，往往难以建立模型，因为他们面临着多个本体、类和关系，现有的工具不是为非专家用户设计的。PLASMA 框架由一个平台和辅助服务组成，侧重于为非专家用户提供创建和编辑语义模型的便捷方式，将自动化方法和推荐引擎等支持系统结合起来。它还提供从原始数据到 RDF 的数据转换。本文着重介绍了建模接口和数据转换引擎等主要特性。我们讨论了 PLASMA 作为一种工具是如何适用于非专家用户在数据空间上下文中建立语义模型的，并展示了 PLASMA 已经在数据管理项目中使用的一些应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+PLASMA+Framework:+Laying+the+Path+to+Domain-Specific+Semantics+in+Dataspaces)|0|
|[Pairwise-interactions-based Bayesian Inference of Network Structure from Information Cascades](https://doi.org/10.1145/3543507.3583231)|Chao Gao, Yuchen Wang, Zhen Wang, Xianghua Li, Xuelong Li|Northwestern Polytechnical University, China; School of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University, China|An explicit network structure plays an important role when analyzing and understanding diffusion processes. In many scenarios, however, the interactions between nodes in an underlying network are unavailable. Although many methods for inferring a network structure from observed cascades have been proposed, they did not perceive the relationship between pairwise interactions in a cascade. Therefore, this paper proposes a Pairwise-interactions-based Bayesian Inference method (named PBI) to infer the underlying diffusion network structure. More specifically, to get more accurate inference results, we measure the weights of each candidate pairwise interaction in different cascades and add them to the likelihood of a contagion process. In addition, a pre-pruning work is introduced for candidate edges to further improve the inference efficiency. Experiments on synthetic and real-world networks show that PBI achieves significantly better results.|显式的网络结构在分析和理解扩散过程中起着重要作用。然而，在许多场景中，底层网络中的节点之间的交互是不可用的。虽然已经提出了许多从观察到的级联推断网络结构的方法，但它们没有认识到级联中成对相互作用之间的关系。因此，本文提出了一种基于成对互动的贝叶斯推断方法(称为 PBI)来推断基础扩散网络的结构。更具体地说，为了得到更准确的推断结果，我们测量了不同级联中每个候选者成对相互作用的权重，并将它们加到传染过程的可能性上。此外，为了进一步提高推理效率，引入了候选边缘的预剪枝方法。在合成网络和真实网络上的实验表明，PBI 取得了明显的改善效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pairwise-interactions-based+Bayesian+Inference+of+Network+Structure+from+Information+Cascades)|0|
|[Graph Neural Network with Two Uplift Estimators for Label-Scarcity Individual Uplift Modeling](https://doi.org/10.1145/3543507.3583368)|Dingyuan Zhu, Daixin Wang, Zhiqiang Zhang, Kun Kuang, Yan Zhang, Yulin Kang, Jun Zhou|Zhejiang university, China; Ant Group, China|Uplift modeling aims to measure the incremental effect, which we call uplift, of a strategy or action on the users from randomized experiments or observational data. Most existing uplift methods only use individual data, which are usually not informative enough to capture the unobserved and complex hidden factors regarding the uplift. Furthermore, uplift modeling scenario usually has scarce labeled data, especially for the treatment group, which also poses a great challenge for model training. Considering that the neighbors’ features and the social relationships are very informative to characterize a user’s uplift, we propose a graph neural network-based framework with two uplift estimators, called GNUM, to learn from the social graph for uplift estimation. Specifically, we design the first estimator based on a class-transformed target. The estimator is general for all types of outcomes, and is able to comprehensively model the treatment and control group data together to approach the uplift. When the outcome is discrete, we further design the other uplift estimator based on our defined partial labels, which is able to utilize more labeled data from both the treatment and control groups, to further alleviate the label scarcity problem. Comprehensive experiments on a public dataset and two industrial datasets show a superior performance of our proposed framework over state-of-the-art methods under various evaluation metrics. The proposed algorithms have been deployed online to serve real-world uplift estimation scenarios.|提升模型的目的是通过随机实验或观察数据来衡量策略或行动对用户的增量效应，我们称之为提升。大多数现有的抬升方法只使用单独的数据，这些数据通常不足以获取关于抬升的未观测到的复杂的隐藏因素。此外，抬升模型场景通常缺乏标记数据，特别是对于治疗组，这也对模型训练提出了很大的挑战。考虑到邻居的特征和社会关系对于表征用户的提升是非常有用的，我们提出了一种基于图神经网络的提升估计框架，称为 GNUM，以学习社会图的提升估计。具体地说，我们设计了基于类转换目标的第一个估计器。该估计值对于所有类型的结果都是通用的，并且能够将治疗组和对照组的数据综合建模以接近隆起。当结果是离散的，我们进一步设计其他提升估计的基础上我们定义的部分标签，它能够利用更多的标记数据从治疗组和对照组，以进一步减轻标签稀缺问题。对一个公共数据集和两个工业数据集的综合实验表明，在各种评估指标下，我们提出的框架比最先进的方法具有更好的性能。提出的算法已经在线部署，以服务于真实世界的抬升估计场景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Network+with+Two+Uplift+Estimators+for+Label-Scarcity+Individual+Uplift+Modeling)|0|
|[Multi-head Variational Graph Autoencoder Constrained by Sum-product Networks](https://doi.org/10.1145/3543507.3583517)|Riting Xia, Yan Zhang, Chunxu Zhang, Xueyan Liu, Bo Yang|Jilin University, China|Variational graph autoencoder (VGAE) is a promising deep probabilistic model in graph representation learning. However, most existing VGAEs adopt the mean-field assumption, and cannot characterize the graphs with noise well. In this paper, we propose a novel deep probabilistic model for graph analysis, termed Multi-head Variational Graph Autoencoder Constrained by Sum-product Networks (named SPN-MVGAE), which helps to relax the mean-field assumption and learns better latent representation with fault tolerance. Our proposed model SPN-MVGAE uses conditional sum-product networks as constraints to learn the dependencies between latent factors in an end-to-end manner. Furthermore, we introduce the superposition of the latent representations learned by multiple variational networks to represent the final latent representations of nodes. Our model is the first use sum-product networks for graph representation learning, extending the scope of sum-product networks applications. Experimental results show that compared with other baseline methods, our model has competitive advantages in link prediction, fault tolerance, node classification, and graph visualization on real datasets.|变分图自动编码器(VGAE)是图表示学习中一种很有前途的深度概率模型。然而，现有的 VGAE 大多采用平均场假设，不能很好地刻画有噪声的图。本文提出了一种新的图分析的深度概率模型，称为和积网络约束下的多头变分图自动编码器(SPN-MVGAE)。我们提出的模型 SPN-MVGAE 使用条件和积网络作为约束，以端到端的方式学习潜在因素之间的相关性。此外，我们还引入了多变分网络学习的潜在表征的叠加来表示节点的最终潜在表征。该模型首次将和积网络用于图表示学习，扩展了和积网络的应用范围。实验结果表明，与其他基线方法相比，该模型在实际数据集的链接预测、容错、节点分类和图形可视化等方面具有优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-head+Variational+Graph+Autoencoder+Constrained+by+Sum-product+Networks)|0|
|[Interactive Log Parsing via Light-weight User Feedback](https://doi.org/10.1145/3543507.3583456)|Liming Wang, Hong Xie, Ye Li, Jian Tan, John C. S. Lui|Alibaba, Hong Kong; College of Computer Science, Chongqing University, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Alibaba, China|Template mining is one of the foundational tasks to support log analysis, which supports the diagnosis and troubleshooting of large scale Web applications. This paper develops a human-in-the-loop template mining framework to support interactive log analysis, which is highly desirable in real-world diagnosis or troubleshooting of Web applications but yet previous template mining algorithms fails to support it. We formulate three types of light-weight user feedbacks and based on them we design three atomic human-in-the-loop template mining algorithms. We derive mild conditions under which the outputs of our proposed algorithms are provably correct. We also derive upper bounds on the computational complexity and query complexity of each algorithm. We demonstrate the versatility of our proposed algorithms by combining them to improve the template mining accuracy of five representative algorithms over sixteen widely used benchmark datasets.|模板挖掘是支持日志分析的基本任务之一，它支持大规模 Web 应用程序的诊断和故障排除。本文提出了一种支持交互式日志分析的半人工模板挖掘框架，该框架在 Web 应用程序的实际诊断和故障排除中非常有用，但以往的模板挖掘算法都不支持。我们提出了三种轻量级用户反馈，并在此基础上设计了三种原子人在环模板挖掘算法。我们推导出我们提出的算法输出可证明正确的温和条件。我们还推导了每种算法的计算复杂度和查询复杂度的上界。我们证明了我们提出的算法的通用性，通过结合他们来提高模板挖掘准确性的五个代表性算法超过16个广泛使用的基准数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interactive+Log+Parsing+via+Light-weight+User+Feedback)|0|
|[Misbehavior and Account Suspension in an Online Financial Communication Platform](https://doi.org/10.1145/3543507.3583385)|Taro Tsuchiya, Alejandro Cuevas, Thomas Magelinski, Nicolas Christin|Carnegie Mellon University, USA|The expanding accessibility and appeal of investing have attracted millions of new retail investors. As such, investment discussion boards became the de facto communities where traders create, disseminate, and discuss investing ideas. These communities, which can provide useful information to support investors, have anecdotally also attracted a wide range of misbehavior – toxicity, spam/fraud, and reputation manipulation. This paper is the first comprehensive analysis of online misbehavior in the context of investment communities. We study TradingView, the largest online communication platform for financial trading. We collect 2.76M user profiles with their corresponding social graphs, 4.2M historical article posts, and 5.3M comments, including information on nearly 4 000 suspended accounts and 17 000 removed comments. Price fluctuations seem to drive abuse across the platform and certain types of assets, such as “meme” stocks, attract disproportionate misbehavior. Suspended user accounts tend to form more closely-knit communities than those formed by non-suspended accounts; and paying accounts are less likely to be suspended than free accounts even when posting similar levels of content violating platform policies. We conclude by offering guidelines on how to adapt content moderation efforts to fit the particularities of online investment communities.|投资的可及性和吸引力不断扩大，吸引了数以百万计的新散户投资者。因此，投资讨论委员会事实上成为了交易员创建、传播和讨论投资理念的社区。这些社区可以提供有用的信息来支持投资者，据说也吸引了大量的不良行为——毒性、垃圾邮件/欺诈和声誉操纵。本文首次全面分析了投资社区背景下的网络不良行为。我们研究了 TradingView，这是最大的金融交易在线交流平台。我们收集了276万用户的个人资料及其相应的社交图表，420万篇历史文章和530万条评论，包括近4000个被暂停的账户和17000条被删除的评论。价格波动似乎推动了整个平台的滥用，某些类型的资产，如“模因”股票，吸引了不成比例的不当行为。与非暂停用户账户相比，暂停用户账户往往形成更为紧密的社区; 即使发布了违反平台政策的类似水平的内容，付费账户被暂停的可能性也低于免费账户。最后，我们提供了关于如何调整内容审核工作以适应在线投资社区的特殊性的指导方针。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Misbehavior+and+Account+Suspension+in+an+Online+Financial+Communication+Platform)|0|
|[BiSR: Bidirectionally Optimized Super-Resolution for Mobile Video Streaming](https://doi.org/10.1145/3543507.3583519)|Qian Yu, Qing Li, Rui He, Gareth Tyson, Wanxin Shi, Jianhui Lv, Zhenhui Yuan, Peng Zhang, Yulong Lan, Zhicheng Li|SUSTech, China and Peng Cheng Laboratory, China; Northumbria University, United Kingdom; Tencent, China; International Graduate School, Tsinghua University, China; Peng Cheng Laboratory, China; Hong Kong University of Science and Technology(GZ), China|The user experience of mobile web video streaming is often impacted by insufficient and dynamic network bandwidth. In this paper, we design Bidirectionally Optimized Super-Resolution (BiSR) to improve the quality of experience (QoE) for mobile web users under limited bandwidth. BiSR exploits a deep neural network (DNN)-based model to super-resolve key frames efficiently without changing the inter-frame spatial-temporal information. We then propose a downscaling DNN and a mobile-specific optimized lightweight super-resolution DNN to enhance the performance. Finally, a novel reinforcement learning-based adaptive bitrate (ABR) algorithm is proposed to verify the performance of BiSR on real network traces. Our evaluation, using a full system implementation, shows that BiSR saves 26% of bitrate compared to the traditional H.264 codec and improves the SSIM of video by 3.7% compared to the prior state-of-the-art. Overall, BiSR enhances the user-perceived quality of experience by up to 30.6%.|移动网络视频流的用户体验往往受到网络带宽不足和动态性的影响。本文设计了双向优化超分辨率(BiSR)算法，以提高有限带宽下移动网络用户的体验质量(QoE)。BiSR 利用基于深度神经网络(DNN)的模型，在不改变帧间时空信息的情况下，有效地对关键帧进行超分辨。然后，我们提出了一个缩放 DNN 和一个移动专用的优化轻量级超分辨率 DNN，以提高性能。最后，提出了一种新的基于强化学习的自适应比特率(ABR)算法来验证 BiSR 在实际网络跟踪中的性能。我们的评估，使用一个完整的系统实现，表明 BiSR 节省26% 的比特率相比，传统的 H.264编解码器和提高了3.7% 的 SSIM 的视频相比，以前的最先进的国家。总的来说，BiSR 提高了30.6% 的用户感知体验质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BiSR:+Bidirectionally+Optimized+Super-Resolution+for+Mobile+Video+Streaming)|0|
|[Autobidding Auctions in the Presence of User Costs](https://doi.org/10.1145/3543507.3583234)|Yuan Deng, Jieming Mao, Vahab Mirrokni, Hanrui Zhang, Song Zuo|Google Research, USA; Carnegie Mellon University, USA|We study autobidding ad auctions with user costs, where each bidder is value-maximizing subject to a return-over-investment (ROI) constraint, and the seller aims to maximize the social welfare taking into consideration the user's cost of viewing an ad. We show that in the worst case, the approximation ratio of social welfare by running the vanilla VCG auctions with user costs could as bad as 0. To improve the performance of VCG, We propose a new variant of VCG based on properly chosen cost multipliers, and prove that there exist auction-dependent and bidder-dependent cost multipliers that guarantee approximation ratios of 1/2 and 1/4 respectively in terms of the social welfare.|本文研究了具有用户成本的自动竞价广告拍卖，其中每个竞价者的价值最大化受到投资回报率(ROI)的约束，卖方的目标是最大化社会福利，同时考虑用户观看广告的成本。我们指出，在最坏的情况下，通过运行普通的 VCG 拍卖与用户成本的社会福利的近似比率可能为0。为了提高 VCG 的性能，我们提出了一种新的基于合理选择成本乘数的 VCG 变体，并证明了存在拍卖相关成本乘数和投标人相关成本乘数，它们分别保证在社会福利方面的近似比为1/2和1/4。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Autobidding+Auctions+in+the+Presence+of+User+Costs)|0|
|[Online Bidding Algorithms for Return-on-Spend Constrained Advertisers✱](https://doi.org/10.1145/3543507.3583491)|Zhe Feng, Swati Padmanabhan, Di Wang|University of Washington, Seattle, USA; Google Research, USA|Online advertising has recently grown into a highly competitive and complex multi-billion-dollar industry, with advertisers bidding for ad slots at large scales and high frequencies. This has resulted in a growing need for efficient "auto-bidding" algorithms that determine the bids for incoming queries to maximize advertisers' targets subject to their specified constraints. This work explores efficient online algorithms for a single value-maximizing advertiser under an increasingly popular constraint: Return-on-Spend (RoS). We quantify efficiency in terms of regret relative to the optimal algorithm, which knows all queries a priori.   We contribute a simple online algorithm that achieves near-optimal regret in expectation while always respecting the specified RoS constraint when the input sequence of queries are i.i.d. samples from some distribution. We also integrate our results with the previous work of Balseiro, Lu, and Mirrokni [BLM20] to achieve near-optimal regret while respecting both RoS and fixed budget constraints.   Our algorithm follows the primal-dual framework and uses online mirror descent (OMD) for the dual updates. However, we need to use a non-canonical setup of OMD, and therefore the classic low-regret guarantee of OMD, which is for the adversarial setting in online learning, no longer holds. Nonetheless, in our case and more generally where low-regret dynamics are applied in algorithm design, the gradients encountered by OMD can be far from adversarial but influenced by our algorithmic choices. We exploit this key insight to show our OMD setup achieves low regret in the realm of our algorithm.|最近，在线广告业已发展成为一个竞争激烈、规模高达数十亿美元的复杂行业，广告客户大规模、高频率地竞标广告位置。这就导致了对有效的“自动竞价”算法的需求日益增长，这种算法可以确定收到的查询的出价，从而最大限度地提高广告商的目标，使其受到特定的约束。这项工作探讨了一个单一的价值最大化的广告客户在一个日益流行的约束下有效的在线算法: 支出回报(RoS)。我们量化效率的遗憾相对于优化算法，它知道所有查询的先验。我们提出了一个简单的在线算法，当查询的输入序列是来自某个分布的标识样本时，该算法在期望中达到接近最优的遗憾，同时始终遵守指定的 RoS 约束。我们还将我们的研究结果与 Balseiro、 Lu 和 Mirrokni [ BLM20]的前期工作结合起来，以在尊重 RoS 和固定预算约束的情况下实现近乎最佳的遗憾。我们的算法遵循原始-对偶框架，并使用在线镜像下降(OMD)的双重更新。然而，我们需要使用一个非规范的 OMD 设置，因此 OMD 的经典的低后悔保证，这是在线学习的对抗设置，不再成立。尽管如此，在我们的案例中，以及更一般的低后悔动力学应用于算法设计的情况下，OMD 遇到的梯度可能远不是对手，而是受到我们的算法选择的影响。我们利用这个关键的洞察力来展示我们的 OMD 设置在我们的算法领域实现了低遗憾。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Bidding+Algorithms+for+Return-on-Spend+Constrained+Advertisers✱)|0|
|[EDNet: Attention-Based Multimodal Representation for Classification of Twitter Users Related to Eating Disorders](https://doi.org/10.1145/3543507.3583863)|Mohammad Abuhassan, Tarique Anwar, Chengfei Liu, Hannah K. Jarman, Matthew FullerTyszkiewicz|University of York, United Kingdom; Swinburne University of Technology, Australia; Deakin University, Australia|Social media platforms provide rich data sources in several domains. In mental health, individuals experiencing an Eating Disorder (ED) are often hesitant to seek help through conventional healthcare services. However, many people seek help with diet and body image issues on social media. To better distinguish at-risk users who may need help for an ED from those who are simply commenting on ED in social environments, highly sophisticated approaches are required. Assessment of ED risks in such a situation can be done in various ways, and each has its own strengths and weaknesses. Hence, there is a need for and potential benefit of a more complex multimodal approach. To this end, we collect historical tweets, user biographies, and online behaviours of relevant users from Twitter, and generate a reasonably large labelled benchmark dataset. Thereafter, we develop an advanced multimodal deep learning model called EDNet using these data to identify the different types of users with ED engagement (e.g., potential ED sufferers, healthcare professionals, or communicators) and distinguish them from those not experiencing EDs on Twitter. EDNet consists of five deep neural network layers. With the help of its embedding, representation and behaviour modeling layers, it effectively learns the multimodalities of social media. In our experiments, EDNet consistently outperforms all the baseline techniques by significant margins. It achieves an accuracy of up to 94.32% and F1 score of up to 93.91% F1 score. To the best of our knowledge, this is the first such study to propose a multimodal approach for user-level classification according to their engagement with ED content on social media.|社交媒体平台在多个领域提供丰富的数据源。在心理健康方面，患有饮食失调(ED)的个体往往不愿意通过传统的医疗服务寻求帮助。然而，许多人在社交媒体上寻求关于饮食和身体形象问题的帮助。为了更好地区分那些可能需要急诊帮助的高危患者和那些只是在社会环境中评论急诊的患者，需要高度复杂的方法。在这种情况下，评估教育署的风险有多种方法，每种方法各有优缺点。因此，需要一种更复杂的多模式方法，而且这种方法还有潜在的好处。为此，我们从 Twitter 收集历史推文、用户简历和相关用户的在线行为，并生成一个相当大的带标签的基准数据集。此后，我们开发了一种称为 EDNet 的高级多模式深度学习模型，使用这些数据来确定不同类型的 ED 参与用户(例如，潜在的 ED 患者，医疗保健专业人员或沟通者) ，并将他们与 Twitter 上没有经历 ED 的人区分开来。EDNet 由五个深层神经网络层组成。借助其嵌入层、表征层和行为建模层，它有效地学习了社会媒体的多重形态。在我们的实验中，EDNet 始终以显著的优势优于所有的基线技术。该算法的正确率达到94.32% ，F1得分达到93.91% 。据我们所知，这是第一个这样的研究，提出了一个多模式的方法，用户级别的分类，根据他们的参与，教育署的内容在社交媒体上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EDNet:+Attention-Based+Multimodal+Representation+for+Classification+of+Twitter+Users+Related+to+Eating+Disorders)|0|
|[C-Affinity: A Novel Similarity Measure for Effective Data Clustering](https://doi.org/10.1145/3543873.3587307)|Jiwon Hong, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=C-Affinity:+A+Novel+Similarity+Measure+for+Effective+Data+Clustering)|0|
|[Knowledge Distillation on Cross-Modal Adversarial Reprogramming for Data-Limited Attribute Inference](https://doi.org/10.1145/3543873.3587313)|Quan Li, Lingwei Chen, Shixiong Jing, Dinghao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Distillation+on+Cross-Modal+Adversarial+Reprogramming+for+Data-Limited+Attribute+Inference)|0|
|[Copyright Protection and Accountability of Generative AI: Attack, Watermarking and Attribution](https://doi.org/10.1145/3543873.3587321)|Haonan Zhong, Jiamin Chang, Ziyue Yang, Tingmin Wu, Pathum Chamikara Mahawaga Arachchige, Chehara Pathmabandu, Minhui Xue||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Copyright+Protection+and+Accountability+of+Generative+AI:+Attack,+Watermarking+and+Attribution)|0|
|[How Streaming Can Improve the World (Wide Web)](https://doi.org/10.1145/3543873.3587332)|Lucas Vogel, Thomas Springer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Streaming+Can+Improve+the+World+(Wide+Web))|0|
|[PyPoll: A python library automating mining of networks, discussions and polarization on Twitter](https://doi.org/10.1145/3543873.3587349)|Dimitrios Panteleimon Giakatos, Pavlos Sermpezis, Athena Vakali||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PyPoll:+A+python+library+automating+mining+of+networks,+discussions+and+polarization+on+Twitter)|0|
|[WebSHAP: Towards Explaining Any Machine Learning Models Anywhere](https://doi.org/10.1145/3543873.3587362)|Zijie J. Wang, Duen Horng Chau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WebSHAP:+Towards+Explaining+Any+Machine+Learning+Models+Anywhere)|0|
|[Privacy-Preserving Online Content Moderation: A Federated Learning Use Case](https://doi.org/10.1145/3543873.3587604)|Pantelitsa Leonidou, Nicolas Kourtellis, Nikos Salamanos, Michael Sirivianos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Online+Content+Moderation:+A+Federated+Learning+Use+Case)|0|
|[Intent-based Web Page Summarization with Structure-Aware Chunking and Generative Language Models](https://doi.org/10.1145/3543873.3587372)|HuanYuan Chen, Hong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intent-based+Web+Page+Summarization+with+Structure-Aware+Chunking+and+Generative+Language+Models)|0|
|[Measuring and Detecting Virality on Social Media: The Case of Twitter's Viral Tweets Topic](https://doi.org/10.1145/3543873.3587373)|Tugrulcan Elmas, Stephane Selim, Célia Houssiaux||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+and+Detecting+Virality+on+Social+Media:+The+Case+of+Twitter's+Viral+Tweets+Topic)|0|
|[Anytime-Valid Confidence Sequences in an Enterprise A/B Testing Platform](https://doi.org/10.1145/3543873.3584635)|Akash Maharaj, Ritwik Sinha, David Arbour, Ian WaudbySmith, Simon Z. Liu, Moumita Sinha, Raghavendra Addanki, Aaditya Ramdas, Manas Garg, Viswanathan Swaminathan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anytime-Valid+Confidence+Sequences+in+an+Enterprise+A/B+Testing+Platform)|0|
|[Contrastive Fine-tuning on Few Shot Intent Detection with Topological Intent Tree](https://doi.org/10.1145/3543873.3584648)|Wei Yuan, Martin Dimkovski, Aijun An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Fine-tuning+on+Few+Shot+Intent+Detection+with+Topological+Intent+Tree)|0|
|[Visual Item Selection With Voice Assistants: A systems perspective](https://doi.org/10.1145/3543873.3584655)|Prashan Wanigasekara, Rafid AlHumaimidi, Turan Gojayev, Niloofar Gheissari, Achal Dave, Stephen Rawls, Fan Yang, Kechen Qin, Nalin Gupta, Spurthi Sandiri, Chevanthie Dissanayake, Zeynab Raeesy, Emre Barut, Chengwei Su||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Visual+Item+Selection+With+Voice+Assistants:+A+systems+perspective)|0|
|[Multi-Source Domain Adaptation via Latent Domain Reconstruction](https://doi.org/10.1145/3543873.3584659)|Jun Zhou, Chilin Fu, Xiaolu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Source+Domain+Adaptation+via+Latent+Domain+Reconstruction)|0|
|[Human Dimensions of Animal Exploitation: Towards Understanding the International Wildlife Trade and Selfie-Tourism on Twitter](https://doi.org/10.1145/3543873.3587538)|Sean P. Rogers, Jeremiah Onaolapo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human+Dimensions+of+Animal+Exploitation:+Towards+Understanding+the+International+Wildlife+Trade+and+Selfie-Tourism+on+Twitter)|0|
|[A Bridge over the Troll: Non-Complementary Activism Online](https://doi.org/10.1145/3543873.3587541)|Emyn Dean||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Bridge+over+the+Troll:+Non-Complementary+Activism+Online)|0|
|[The DEEP Sensorium: a multidimensional approach to sensory domain labelling](https://doi.org/10.1145/3543873.3587631)|Simona Corciulo, Livio Bioglio, Valerio Basile, Viviana Patti, Rossana Damiano||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+DEEP+Sensorium:+a+multidimensional+approach+to+sensory+domain+labelling)|0|
|[A Survey of General Ontologies for the Cross-Industry Domain of Circular Economy](https://doi.org/10.1145/3543873.3587613)|Huanyu Li, Mina Abd Nikooie Pour, Ying Li, Mikael Lindecrantz, Eva Blomqvist, Patrick Lambrix||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Survey+of+General+Ontologies+for+the+Cross-Industry+Domain+of+Circular+Economy)|0|
|[Improving Netflix Video Quality with Neural Networks](https://doi.org/10.1145/3543873.3587553)|Christos G. Bampis, LiHeng Chen, Zhi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Netflix+Video+Quality+with+Neural+Networks)|0|
|[Graph2Feat: Inductive Link Prediction via Knowledge Distillation](https://doi.org/10.1145/3543873.3587596)|Ahmed E. Samy, Zekarias T. Kefato, Sarunas Girdzijauskas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph2Feat:+Inductive+Link+Prediction+via+Knowledge+Distillation)|0|
|[Universal Model in Online Customer Service](https://doi.org/10.1145/3543873.3587630)|ShuTing Pi, ChengPing Hsieh, Qun Liu, Yuying Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Universal+Model+in+Online+Customer+Service)|0|
|[Robust Stochastic Multi-Armed Bandits with Historical Data](https://doi.org/10.1145/3543873.3587653)|Sarah Boufelja Yacobi, Djallel Bouneffouf||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Stochastic+Multi-Armed+Bandits+with+Historical+Data)|0|
|[Skill Graph Construction From Semantic Understanding](https://doi.org/10.1145/3543873.3587667)|Shiyong Lin, Yiping Yuan, Carol Jin, Yi Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Skill+Graph+Construction+From+Semantic+Understanding)|0|
|[Cultural Differences in Signed Ego Networks on Twitter: An Investigatory Analysis](https://doi.org/10.1145/3543873.3587641)|Jack Tacchi, Chiara Boldrini, Andrea Passarella, Marco Conti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cultural+Differences+in+Signed+Ego+Networks+on+Twitter:+An+Investigatory+Analysis)|0|
|[Don't Trust, Verify: The Case of Slashing from a Popular Ethereum Explorer](https://doi.org/10.1145/3543873.3587555)|Zhiguo He, Jiasun Li, Zhengxun Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Don't+Trust,+Verify:+The+Case+of+Slashing+from+a+Popular+Ethereum+Explorer)|0|
|[An Exploration on Cryptocurrency Corporations' Fiscal Opportunities](https://doi.org/10.1145/3543873.3587603)|Thomas Charest, Masarah PaquetClouston||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Exploration+on+Cryptocurrency+Corporations'+Fiscal+Opportunities)|0|
|[Improving the Exploration/Exploitation Trade-Off in Web Content Discovery](https://doi.org/10.1145/3543873.3587574)|Peter Schulam, Ion Muslea||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+the+Exploration/Exploitation+Trade-Off+in+Web+Content+Discovery)|0|
|[SoarGraph: Numerical Reasoning over Financial Table-Text Data via Semantic-Oriented Hierarchical Graphs](https://doi.org/10.1145/3543873.3587598)|Fengbin Zhu, Moxin Li, Junbin Xiao, Fuli Feng, Chao Wang, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SoarGraph:+Numerical+Reasoning+over+Financial+Table-Text+Data+via+Semantic-Oriented+Hierarchical+Graphs)|0|
|[Online to Offline Crossover of White Supremacist Propaganda](https://doi.org/10.1145/3543873.3587569)|Ahmad Diab, BolorErdene Jagdagdorj, Lynnette Hui Xian Ng, YuRu Lin, Michael Miller Yoder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+to+Offline+Crossover+of+White+Supremacist+Propaganda)|0|
|[Privacy-Preserving Online Content Moderation with Federated Learning](https://doi.org/10.1145/3543873.3587366)|Pantelitsa Leonidou, Nicolas Kourtellis, Nikos Salamanos, Michael Sirivianos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Online+Content+Moderation+with+Federated+Learning)|0|
|[Graph-based Approach for Studying Spread of Radical Online Sentiment](https://doi.org/10.1145/3543873.3587634)|Le Nguyen, Nidhi Rastogi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-based+Approach+for+Studying+Spread+of+Radical+Online+Sentiment)|0|
|[Swinging in the States: Does disinformation on Twitter mirror the US presidential election system?](https://doi.org/10.1145/3543873.3587638)|Manuel Pratelli, Marinella Petrocchi, Fabio Saracco, Rocco De Nicola||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Swinging+in+the+States:+Does+disinformation+on+Twitter+mirror+the+US+presidential+election+system?)|0|
|[Analyzing Activity and Suspension Patterns of Twitter Bots Attacking Turkish Twitter Trends by a Longitudinal Dataset](https://doi.org/10.1145/3543873.3587650)|Tugrulcan Elmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+Activity+and+Suspension+Patterns+of+Twitter+Bots+Attacking+Turkish+Twitter+Trends+by+a+Longitudinal+Dataset)|0|
|[Socio-Emotional Computational Analysis of Propaganda Campaigns on Social Media Users in the Middle East](https://doi.org/10.1145/3543873.3587677)|Zain A. Halloush, Ahmed Aleroud, Craig Albert||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Socio-Emotional+Computational+Analysis+of+Propaganda+Campaigns+on+Social+Media+Users+in+the+Middle+East)|0|
|[Towards a Semantic Approach for Linked Dataspace, Model and Data Cards](https://doi.org/10.1145/3543873.3587659)|Andy Donald, Apostolos Galanopoulos, Edward Curry, Emir Muñoz, Ihsan Ullah, M. A. Waskow, Maciej Dabrowski, Manan Kalra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Semantic+Approach+for+Linked+Dataspace,+Model+and+Data+Cards)|0|
|[Semantics in Dataspaces: Origin and Future Directions](https://doi.org/10.1145/3543873.3587689)|Johannes TheissenLipp, Max Kocher, Christoph Lange, Stefan Decker, Alexander Paulus, André Pomp, Edward Curry||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantics+in+Dataspaces:+Origin+and+Future+Directions)|0|
|[Efficient Sampling for Big Provenance](https://doi.org/10.1145/3543873.3587556)|Sara Moshtaghi Largani, Seokki Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Sampling+for+Big+Provenance)|0|
|[Provenance Tracking for End-to-End Machine Learning Pipelines](https://doi.org/10.1145/3543873.3587557)|Stefan Grafberger, Paul Groth, Sebastian Schelter||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Provenance+Tracking+for+End-to-End+Machine+Learning+Pipelines)|0|
|[SeeGera: Self-supervised Semi-implicit Graph Variational Auto-encoders with Masking](https://doi.org/10.1145/3543507.3583245)|Xiang Li, Tiandi Ye, Caihua Shan, Dongsheng Li, Ming Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SeeGera:+Self-supervised+Semi-implicit+Graph+Variational+Auto-encoders+with+Masking)|0|
|[Lightweight source localization for large-scale social networks](https://doi.org/10.1145/3543507.3583299)|Zhen Wang, Dongpeng Hou, Chao Gao, Xiaoyu Li, Xuelong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lightweight+source+localization+for+large-scale+social+networks)|0|
|[xGCN: An Extreme Graph Convolutional Network for Large-scale Social Link Prediction](https://doi.org/10.1145/3543507.3583340)|Xiran Song, Jianxun Lian, Hong Huang, Zihan Luo, Wei Zhou, Xue Lin, Mingqi Wu, Chaozhuo Li, Xing Xie, Hai Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=xGCN:+An+Extreme+Graph+Convolutional+Network+for+Large-scale+Social+Link+Prediction)|0|
|[GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks](https://doi.org/10.1145/3543507.3583386)|Zemin Liu, Xingtong Yu, Yuan Fang, Xinming Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphPrompt:+Unifying+Pre-Training+and+Downstream+Tasks+for+Graph+Neural+Networks)|0|
|[FedACK: Federated Adversarial Contrastive Knowledge Distillation for Cross-Lingual and Cross-Model Social Bot Detection](https://doi.org/10.1145/3543507.3583500)|Yingguang Yang, Renyu Yang, Hao Peng, Yangyang Li, Tong Li, Yong Liao, Pengyuan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedACK:+Federated+Adversarial+Contrastive+Knowledge+Distillation+for+Cross-Lingual+and+Cross-Model+Social+Bot+Detection)|0|
|[Self-training through Classifier Disagreement for Cross-Domain Opinion Target Extraction](https://doi.org/10.1145/3543507.3583325)|Kai Sun, Richong Zhang, Samuel Mensah, Nikolaos Aletras, Yongyi Mao, Xudong Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-training+through+Classifier+Disagreement+for+Cross-Domain+Opinion+Target+Extraction)|0|
|[Fast and Multi-aspect Mining of Complex Time-stamped Event Streams](https://doi.org/10.1145/3543507.3583370)|Kota Nakamura, Yasuko Matsubara, Koki Kawabata, Yuhei Umeda, Yuichiro Wada, Yasushi Sakurai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+and+Multi-aspect+Mining+of+Complex+Time-stamped+Event+Streams)|0|
|[PDSum: Prototype-driven Continuous Summarization of Evolving Multi-document Sets Stream](https://doi.org/10.1145/3543507.3583371)|Susik Yoon, Hou Pong Chan, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PDSum:+Prototype-driven+Continuous+Summarization+of+Evolving+Multi-document+Sets+Stream)|0|
|[Learning Disentangled Representation via Domain Adaptation for Dialogue Summarization](https://doi.org/10.1145/3543507.3583389)|Jinpeng Li, Yingce Xia, Xin Cheng, Dongyan Zhao, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Disentangled+Representation+via+Domain+Adaptation+for+Dialogue+Summarization)|0|
|[Towards Understanding Consumer Healthcare Questions on the Web with Semantically Enhanced Contrastive Learning](https://doi.org/10.1145/3543507.3583449)|Shweta Yadav, Stefan Cobeli, Cornelia Caragea||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Understanding+Consumer+Healthcare+Questions+on+the+Web+with+Semantically+Enhanced+Contrastive+Learning)|0|
|[Modeling Dynamic Interactions over Tensor Streams](https://doi.org/10.1145/3543507.3583458)|Koki Kawabata, Yasuko Matsubara, Yasushi Sakurai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Dynamic+Interactions+over+Tensor+Streams)|0|
|[Constrained Subset Selection from Data Streams for Profit Maximization](https://doi.org/10.1145/3543507.3583490)|Shuang Cui, Kai Han, Jing Tang, He Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Constrained+Subset+Selection+from+Data+Streams+for+Profit+Maximization)|0|
|[SCStory: Self-supervised and Continual Online Story Discovery](https://doi.org/10.1145/3543507.3583507)|Susik Yoon, Yu Meng, Dongha Lee, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SCStory:+Self-supervised+and+Continual+Online+Story+Discovery)|0|
|[Know Your Transactions: Real-time and Generic Transaction Semantic Representation on Blockchain & Web3 Ecosystem](https://doi.org/10.1145/3543507.3583537)|Zhiying Wu, Jieli Liu, Jiajing Wu, Zibin Zheng, Xiapu Luo, Ting Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Know+Your+Transactions:+Real-time+and+Generic+Transaction+Semantic+Representation+on+Blockchain+&+Web3+Ecosystem)|0|
|[Toward Open-domain Slot Filling via Self-supervised Co-training](https://doi.org/10.1145/3543507.3583541)|Adib Mosharrof, Moghis Fereidouni, A. B. Siddique||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Open-domain+Slot+Filling+via+Self-supervised+Co-training)|0|
|[Measuring and Evading Turkmenistan's Internet Censorship: A Case Study in Large-Scale Measurements of a Low-Penetration Country](https://doi.org/10.1145/3543507.3583189)|Sadia Nourin, Van Tran, Xi Jiang, Kevin Bock, Nick Feamster, Nguyen Phong Hoang, Dave Levin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+and+Evading+Turkmenistan's+Internet+Censorship:+A+Case+Study+in+Large-Scale+Measurements+of+a+Low-Penetration+Country)|0|
|[NetGuard: Protecting Commercial Web APIs from Model Inversion Attacks using GAN-generated Fake Samples](https://doi.org/10.1145/3543507.3583224)|Xueluan Gong, Ziyao Wang, Yanjiao Chen, Qian Wang, Cong Wang, Chao Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NetGuard:+Protecting+Commercial+Web+APIs+from+Model+Inversion+Attacks+using+GAN-generated+Fake+Samples)|0|
|[Meteor: Improved Secure 3-Party Neural Network Inference with Reducing Online Communication Costs](https://doi.org/10.1145/3543507.3583272)|Ye Dong, Xiaojun Chen, Weizhan Jing, Kaiyun Li, Weiping Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meteor:+Improved+Secure+3-Party+Neural+Network+Inference+with+Reducing+Online+Communication+Costs)|0|
|[IRWArt: Levering Watermarking Performance for Protecting High-quality Artwork Images](https://doi.org/10.1145/3543507.3583489)|Yuanjing Luo, Tongqing Zhou, Fang Liu, Zhiping Cai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IRWArt:+Levering+Watermarking+Performance+for+Protecting+High-quality+Artwork+Images)|0|
|[CapEnrich: Enriching Caption Semantics for Web Images via Cross-modal Pre-trained Knowledge](https://doi.org/10.1145/3543507.3583232)|Linli Yao, Weijing Chen, Qin Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CapEnrich:+Enriching+Caption+Semantics+for+Web+Images+via+Cross-modal+Pre-trained+Knowledge)|0|
|[MLN4KB: an efficient Markov logic network engine for large-scale knowledge bases and structured logic rules](https://doi.org/10.1145/3543507.3583248)|Huang Fang, Yang Liu, Yunfeng Cai, Mingming Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MLN4KB:+an+efficient+Markov+logic+network+engine+for+large-scale+knowledge+bases+and+structured+logic+rules)|0|
|[Learning Long- and Short-term Representations for Temporal Knowledge Graph Reasoning](https://doi.org/10.1145/3543507.3583242)|Mengqi Zhang, Yuwei Xia, Qiang Liu, Shu Wu, Liang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Long-+and+Short-term+Representations+for+Temporal+Knowledge+Graph+Reasoning)|0|
|[Mutually-paced Knowledge Distillation for Cross-lingual Temporal Knowledge Graph Reasoning](https://doi.org/10.1145/3543507.3583407)|Ruijie Wang, Zheng Li, Jingfeng Yang, Tianyu Cao, Chao Zhang, Bing Yin, Tarek F. Abdelzaher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mutually-paced+Knowledge+Distillation+for+Cross-lingual+Temporal+Knowledge+Graph+Reasoning)|0|
|[Large-Scale Analysis of New Employee Network Dynamics](https://doi.org/10.1145/3543507.3583400)|Yulin Yu, Longqi Yang, Siân Lindley, Mengting Wan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large-Scale+Analysis+of+New+Employee+Network+Dynamics)|0|
|[MassNE: Exploring Higher-Order Interactions with Marginal Effect for Massive Battle Outcome Prediction](https://doi.org/10.1145/3543507.3583390)|Yin Gu, Kai Zhang, Qi Liu, Xin Lin, Zhenya Huang, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MassNE:+Exploring+Higher-Order+Interactions+with+Marginal+Effect+for+Massive+Battle+Outcome+Prediction)|0|
|[Online Advertising in Ukraine and Russia During the 2022 Russian Invasion](https://doi.org/10.1145/3543507.3583484)|Christina Yeung, Umar Iqbal, Yekaterina Tsipenyuk O'Neil, Tadayoshi Kohno, Franziska Roesner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Advertising+in+Ukraine+and+Russia+During+the+2022+Russian+Invasion)|0|
|[Understanding the Behaviors of Toxic Accounts on Reddit](https://doi.org/10.1145/3543507.3583522)|Deepak Kumar, Jeff T. Hancock, Kurt Thomas, Zakir Durumeric||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Behaviors+of+Toxic+Accounts+on+Reddit)|0|
|[Online Reviews Are Leading Indicators of Changes in K-12 School Attributes](https://doi.org/10.1145/3543507.3583531)|Linsen Li, Aron Culotta, Douglas N. Harris, Nicholas Mattei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Reviews+Are+Leading+Indicators+of+Changes+in+K-12+School+Attributes)|0|
|[Beyond Fine-Tuning: Efficient and Effective Fed-Tuning for Mobile/Web Users](https://doi.org/10.1145/3543507.3583212)|Bingyan Liu, Yifeng Cai, Hongzhe Bi, Ziqi Zhang, Ding Li, Yao Guo, Xiangqun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Fine-Tuning:+Efficient+and+Effective+Fed-Tuning+for+Mobile/Web+Users)|0|
|[Automated WebAssembly Function Purpose Identification With Semantics-Aware Analysis](https://doi.org/10.1145/3543507.3583235)|Alan Romano, Weihang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+WebAssembly+Function+Purpose+Identification+With+Semantics-Aware+Analysis)|0|
|[SCTAP: Supporting Scenario-Centric Trigger-Action Programming based on Software-Defined Physical Environments](https://doi.org/10.1145/3543507.3583293)|Bingkun Sun, Liwei Shen, Xin Peng, Ziming Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SCTAP:+Supporting+Scenario-Centric+Trigger-Action+Programming+based+on+Software-Defined+Physical+Environments)|0|
|[DeeProphet: Improving HTTP Adaptive Streaming for Low Latency Live Video by Meticulous Bandwidth Prediction](https://doi.org/10.1145/3543507.3583364)|Kefan Chen, Bo Wang, Wufan Wang, Xiaoyu Li, Fengyuan Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeeProphet:+Improving+HTTP+Adaptive+Streaming+for+Low+Latency+Live+Video+by+Meticulous+Bandwidth+Prediction)|0|
|[Is IPFS Ready for Decentralized Video Streaming?](https://doi.org/10.1145/3543507.3583404)|Zhengyu Wu, ChengHao Ryan Yang, Santiago Vargas, Aruna Balasubramanian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+IPFS+Ready+for+Decentralized+Video+Streaming?)|0|
|[SISSI: An Architecture for Semantic Interoperable Self-Sovereign Identity-based Access Control on the Web](https://doi.org/10.1145/3543507.3583409)|Christoph H.J. Braun, Vasil Papanchev, Tobias Käfer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SISSI:+An+Architecture+for+Semantic+Interoperable+Self-Sovereign+Identity-based+Access+Control+on+the+Web)|0|
|[Detecting Socially Abnormal Highway Driving Behaviors via Recurrent Graph Attention Networks](https://doi.org/10.1145/3543507.3583452)|Yue Hu, Yuhang Zhang, Yanbing Wang, Daniel B. Work||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Socially+Abnormal+Highway+Driving+Behaviors+via+Recurrent+Graph+Attention+Networks)|0|
|[GROUP: An End-to-end Multi-step-ahead Workload Prediction Approach Focusing on Workload Group Behavior](https://doi.org/10.1145/3543507.3583460)|Binbin Feng, Zhijun Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GROUP:+An+End-to-end+Multi-step-ahead+Workload+Prediction+Approach+Focusing+on+Workload+Group+Behavior)|0|
|[FANS: Fast Non-Autoregressive Sequence Generation for Item List Continuation](https://doi.org/10.1145/3543507.3583430)|Qijiong Liu, Jieming Zhu, Jiahao Wu, Tiandeng Wu, Zhenhua Dong, XiaoMing Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FANS:+Fast+Non-Autoregressive+Sequence+Generation+for+Item+List+Continuation)|0|
|[DANCE: Learning A Domain Adaptive Framework for Deep Hashing](https://doi.org/10.1145/3543507.3583445)|Haixin Wang, Jinan Sun, Xiang Wei, Shikun Zhang, Chong Chen, XianSheng Hua, Xiao Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DANCE:+Learning+A+Domain+Adaptive+Framework+for+Deep+Hashing)|0|
|[Differentiable Optimized Product Quantization and Beyond](https://doi.org/10.1145/3543507.3583482)|Zepu Lu, Defu Lian, Jin Zhang, Zaixi Zhang, Chao Feng, Hao Wang, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Differentiable+Optimized+Product+Quantization+and+Beyond)|0|
|[Auctions without commitment in the auto-bidding world](https://doi.org/10.1145/3543507.3583416)|Andrés Perlroth, Aranyak Mehta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Auctions+without+commitment+in+the+auto-bidding+world)|0|
|[Online resource allocation in Markov Chains](https://doi.org/10.1145/3543507.3583428)|Jianhao Jia, Hao Li, Kai Liu, Ziqi Liu, Jun Zhou, Nikolai Gravin, Zhihao Gavin Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+resource+allocation+in+Markov+Chains)|0|
|[Worst-Case Welfare of Item Pricing in the Tollbooth Problem](https://doi.org/10.1145/3543507.3583432)|Zihan Tan, Yifeng Teng, Mingfei Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Worst-Case+Welfare+of+Item+Pricing+in+the+Tollbooth+Problem)|0|
|[Learning to Bid in Contextual First Price Auctions✱](https://doi.org/10.1145/3543507.3583427)|Ashwinkumar Badanidiyuru, Zhe Feng, Guru Guruganesh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Bid+in+Contextual+First+Price+Auctions✱)|0|
|[Efficiency of Non-Truthful Auctions in Auto-bidding: The Power of Randomization](https://doi.org/10.1145/3543507.3583492)|Christopher Liaw, Aranyak Mehta, Andrés Perlroth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficiency+of+Non-Truthful+Auctions+in+Auto-bidding:+The+Power+of+Randomization)|0|
|[Platform Behavior under Market Shocks: A Simulation Framework and Reinforcement-Learning Based Study](https://doi.org/10.1145/3543507.3583523)|Xintong Wang, Gary Qiurui Ma, Alon Eden, Clara Li, Alexander Trott, Stephan Zheng, David C. Parkes||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Platform+Behavior+under+Market+Shocks:+A+Simulation+Framework+and+Reinforcement-Learning+Based+Study)|0|
|[Near-Optimal Experimental Design Under the Budget Constraint in Online Platforms](https://doi.org/10.1145/3543507.3583528)|Yongkang Guo, Yuan Yuan, Jinshan Zhang, Yuqing Kong, Zhihua Zhu, Zheng Cai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Near-Optimal+Experimental+Design+Under+the+Budget+Constraint+in+Online+Platforms)|0|
|[A Method to Assess and Explain Disparate Impact in Online Retailing](https://doi.org/10.1145/3543507.3583270)|Rafael BecerrilArreola||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Method+to+Assess+and+Explain+Disparate+Impact+in+Online+Retailing)|0|
|[Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection](https://doi.org/10.1145/3543507.3583214)|Chris Hays, Zachary Schutzman, Manish Raghavan, Erin Walk, Philipp Zimmer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simplistic+Collection+and+Labeling+Practices+Limit+the+Utility+of+Benchmark+Datasets+for+Twitter+Bot+Detection)|0|
|[A Dataset on Malicious Paper Bidding in Peer Review](https://doi.org/10.1145/3543507.3583424)|Steven Jecmen, Minji Yoon, Vincent Conitzer, Nihar B. Shah, Fei Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dataset+on+Malicious+Paper+Bidding+in+Peer+Review)|0|
|[Exploring Social Media for Early Detection of Depression in COVID-19 Patients](https://doi.org/10.1145/3543507.3583867)|Jiageng Wu, Xian Wu, Yining Hua, Shixu Lin, Yefeng Zheng, Jie Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Social+Media+for+Early+Detection+of+Depression+in+COVID-19+Patients)|0|
|[Identifying Checkworthy CURE Claims on Twitter](https://doi.org/10.1145/3543507.3583870)|Sujatha Das Gollapalli, Mingzhe Du, SeeKiong Ng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Checkworthy+CURE+Claims+on+Twitter)|0|
|[The Impact of Covid-19 on Online Discussions: the Case Study of the Sanctioned Suicide Forum](https://doi.org/10.1145/3543507.3583879)|Elisa Sartori, Luca Pajola, Giovanni Da San Martino, Mauro Conti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Impact+of+Covid-19+on+Online+Discussions:+the+Case+Study+of+the+Sanctioned+Suicide+Forum)|0|
|[Learning like human annotators: Cyberbullying detection in lengthy social media sessions](https://doi.org/10.1145/3543507.3583873)|Peiling Yi, Arkaitz Zubiaga||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+like+human+annotators:+Cyberbullying+detection+in+lengthy+social+media+sessions)|0|
|[Vertical Federated Knowledge Transfer via Representation Distillation for Healthcare Collaboration Networks](https://doi.org/10.1145/3543507.3583874)|Chungju Huang, Leye Wang, Xiao Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Vertical+Federated+Knowledge+Transfer+via+Representation+Distillation+for+Healthcare+Collaboration+Networks)|0|
|[On Graph Time-Series Representations for Temporal Networks](https://doi.org/10.1145/3543873.3587301)|Ryan A. Rossi, Nesreen K. Ahmed, Namyong Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Graph+Time-Series+Representations+for+Temporal+Networks)|0|
|[Lower Risks, Better Choices: Stock Correlation Based Portfolio Selection in Stock Markets](https://doi.org/10.1145/3543873.3587298)|Di Luo, Weiheng Liao, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lower+Risks,+Better+Choices:+Stock+Correlation+Based+Portfolio+Selection+in+Stock+Markets)|0|
|[Creation and Analysis of a Corpus of Scam Emails Targeting Universities](https://doi.org/10.1145/3543873.3587303)|Grace Ciambrone, Shomir Wilson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Creation+and+Analysis+of+a+Corpus+of+Scam+Emails+Targeting+Universities)|0|
|[STRUM: Extractive Aspect-Based Contrastive Summarization](https://doi.org/10.1145/3543873.3587304)|Beliz Gunel, Sandeep Tata, Marc Najork||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STRUM:+Extractive+Aspect-Based+Contrastive+Summarization)|0|
|[gDoc: Automatic Generation of Structured API Documentation](https://doi.org/10.1145/3543873.3587310)|Shujun Wang, Yongqiang Tian, Dengcheng He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=gDoc:+Automatic+Generation+of+Structured+API+Documentation)|0|
|[Reduce API Debugging Overhead via Knowledge Prepositioning](https://doi.org/10.1145/3543873.3587311)|Shujun Wang, Yongqiang Tian, Dengcheng He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reduce+API+Debugging+Overhead+via+Knowledge+Prepositioning)|0|
|[Augmenting Visualizations with Predictive and Investigative Insights to Facilitate Decision Making](https://doi.org/10.1145/3543873.3587317)|Md Main Uddin Rony, Fan Du, Ryan A. Rossi, Jane Hoffswell, Niyati Chhaya, Iftikhar Ahamath Burhanuddin, Eunyee Koh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Augmenting+Visualizations+with+Predictive+and+Investigative+Insights+to+Facilitate+Decision+Making)|0|
|[OntoEval: an Automated Ontology Evaluation System](https://doi.org/10.1145/3543873.3587318)|Antonio Zaitoun, Tomer Sagi, Katja Hose||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OntoEval:+an+Automated+Ontology+Evaluation+System)|0|
|[Public Spot Instance Dataset Archive Service](https://doi.org/10.1145/3543873.3587314)|Kyunghwan Kim, Subin Park, Jaeil Hwang, Hyeonyoung Lee, Seokhyeon Kang, Kyungyong Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Public+Spot+Instance+Dataset+Archive+Service)|0|
|[Towards Deeper Graph Neural Networks via Layer-Adaptive](https://doi.org/10.1145/3543873.3587323)|Bingbing Xu, Bin Xie, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Deeper+Graph+Neural+Networks+via+Layer-Adaptive)|0|
|[qEndpoint: A Wikidata SPARQL endpoint on commodity hardware](https://doi.org/10.1145/3543873.3587327)|Antoine Willerval, Angela Bonifati, Dennis Diefenbach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=qEndpoint:+A+Wikidata+SPARQL+endpoint+on+commodity+hardware)|0|
|[Metadatamatic: A Web application to Create a Dataset Description](https://doi.org/10.1145/3543873.3587328)|Pierre Maillot, Olivier Corby, Catherine Faron, Fabien Gandon, Franck Michel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metadatamatic:+A+Web+application+to+Create+a+Dataset+Description)|0|
|[What do LLMs Know about Financial Markets? A Case Study on Reddit Market Sentiment Analysis](https://doi.org/10.1145/3543873.3587324)|Xiang Deng, Vasilisa Bashlovkina, Feng Han, Simon Baumgartner, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+do+LLMs+Know+about+Financial+Markets?+A+Case+Study+on+Reddit+Market+Sentiment+Analysis)|0|
|[GAT-DNS: DNS Multivariate Time Series Prediction Model Based on Graph Attention Network](https://doi.org/10.1145/3543873.3587329)|Xiaofeng Lu, Xiaoyu Zhang, Pietro Lió||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAT-DNS:+DNS+Multivariate+Time+Series+Prediction+Model+Based+on+Graph+Attention+Network)|0|
|[Weedle: Composable Dashboard for Data-Centric NLP in Computational Notebooks](https://doi.org/10.1145/3543873.3587330)|Nahyun Kwon, Hannah Kim, Sajjadur Rahman, Dan Zhang, Estevam Hruschka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weedle:+Composable+Dashboard+for+Data-Centric+NLP+in+Computational+Notebooks)|0|
|[The Web Data Commons Schema.org Data Set Series](https://doi.org/10.1145/3543873.3587331)|Alexander Brinkmann, Anna Primpeli, Christian Bizer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Web+Data+Commons+Schema.org+Data+Set+Series)|0|
|[Class Cardinality Comparison as a Fermi Problem](https://doi.org/10.1145/3543873.3587334)|Shrestha Ghosh, Simon Razniewski, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Class+Cardinality+Comparison+as+a+Fermi+Problem)|0|
|[Towards a Critical Open-Source Software Database](https://doi.org/10.1145/3543873.3587336)|Tobias Dam, Lukas Daniel Klausner, Sebastian Neumaier||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Critical+Open-Source+Software+Database)|0|
|[Task-Specific Data Augmentation for Zero-shot and Few-shot Stance Detection](https://doi.org/10.1145/3543873.3587337)|Jiarui Zhang, Shaojuan Wu, Xiaowang Zhang, Zhiyong Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Specific+Data+Augmentation+for+Zero-shot+and+Few-shot+Stance+Detection)|0|
|[Measuring Potential Performance Gains of Python Web Applications with pyUpgradeSim](https://doi.org/10.1145/3543873.3587338)|Anthony Shaw, Amin Beheshti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Potential+Performance+Gains+of+Python+Web+Applications+with+pyUpgradeSim)|0|
|[mStore: Schema Mining based-RDF Data Storage](https://doi.org/10.1145/3543873.3587339)|Guopeng Zheng, Tenglong Ren, Lulu Yang, Xiaowang Zhang, Zhiyong Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=mStore:+Schema+Mining+based-RDF+Data+Storage)|0|
|[Identifying Topic and Cause for Sarcasm: An Unsupervised Knowledge-enhanced Prompt Method](https://doi.org/10.1145/3543873.3587343)|Minjie Yuan, Qiudan Li, Xue Mao, Daniel Dajun Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Topic+and+Cause+for+Sarcasm:+An+Unsupervised+Knowledge-enhanced+Prompt+Method)|0|
|[The Community Notes Observatory: Can Crowdsourced Fact-Checking be Trusted in Practice?](https://doi.org/10.1145/3543873.3587340)|Luca Righes, Mohammed Saeed, Gianluca Demartini, Paolo Papotti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Community+Notes+Observatory:+Can+Crowdsourced+Fact-Checking+be+Trusted+in+Practice?)|0|
|[EasySpider: A No-Code Visual System for Crawling the Web](https://doi.org/10.1145/3543873.3587345)|Naibo Wang, Wenjie Feng, Jianwei Yin, SeeKiong Ng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EasySpider:+A+No-Code+Visual+System+for+Crawling+the+Web)|0|
|[Persona Consistent Dialogue Generation via Contrastive Learning](https://doi.org/10.1145/3543873.3587346)|Zhenfeng Han, Sai Zhang, Xiaowang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Persona+Consistent+Dialogue+Generation+via+Contrastive+Learning)|0|
|[TML: A Temporal-aware Multitask Learning Framework for Time-sensitive Question Answering](https://doi.org/10.1145/3543873.3587347)|Ziqiang Chen, Shaojuan Wu, Xiaowang Zhang, Zhiyong Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TML:+A+Temporal-aware+Multitask+Learning+Framework+for+Time-sensitive+Question+Answering)|0|
|[Addressing socially destructive disinformation on the web with advanced AI tools: Russia as a case study](https://doi.org/10.1145/3543873.3587348)|Florian Barbaro, Andy Skumanich||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+socially+destructive+disinformation+on+the+web+with+advanced+AI+tools:+Russia+as+a+case+study)|0|
|[Katti: An Extensive and Scalable Tool for Website Analyses](https://doi.org/10.1145/3543873.3587351)|Florian Nettersheim, Stephan Arlt, Michael Rademacher, Florian Dehling||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Katti:+An+Extensive+and+Scalable+Tool+for+Website+Analyses)|0|
|[Graph Induced Transformer Network for Detection of Politeness and Formality in Text](https://doi.org/10.1145/3543873.3587352)|Tirthankar Dasgupta, Manjira Sinha, Chundru Geetha Praveen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Induced+Transformer+Network+for+Detection+of+Politeness+and+Formality+in+Text)|0|
|[Visualizing How-Provenance Explanations for SPARQL Queries](https://doi.org/10.1145/3543873.3587350)|Luis Galárraga, Daniel Hernández, Anas Katim, Katja Hose||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Visualizing+How-Provenance+Explanations+for+SPARQL+Queries)|0|
|[Counterfactual Reasoning for Decision Model Fairness Assessment](https://doi.org/10.1145/3543873.3587354)|Giandomenico Cornacchia, Vito Walter Anelli, Fedelucio Narducci, Azzurra Ragone, Eugenio Di Sciascio||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Reasoning+for+Decision+Model+Fairness+Assessment)|0|
|[Wikidata Atlas: Putting Wikidata on the Map](https://doi.org/10.1145/3543873.3587356)|Benjamín Del Pino, Aidan Hogan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wikidata+Atlas:+Putting+Wikidata+on+the+Map)|0|
|[How Algorithm Awareness Impacts Algospeak Use on TikTok](https://doi.org/10.1145/3543873.3587355)|Daniel Klug, Ella Steen, Kathryn Yurechko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Algorithm+Awareness+Impacts+Algospeak+Use+on+TikTok)|0|
|[Computing and Visualizing Agro-Meteorological Parameters based on an Observational Weather Knowledge Graph](https://doi.org/10.1145/3543873.3587357)|Nadia Yacoubi Ayadi, Catherine Faron, Franck Michel, Fabien Gandon, Olivier Corby||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Computing+and+Visualizing+Agro-Meteorological+Parameters+based+on+an+Observational+Weather+Knowledge+Graph)|0|
|[Injecting data into ODRL privacy policies dynamically with RDF mappings](https://doi.org/10.1145/3543873.3587358)|Juan CanoBenito, Andrea Cimmino, Raúl GarcíaCastro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Injecting+data+into+ODRL+privacy+policies+dynamically+with+RDF+mappings)|0|
|[MediSage: An AI Assistant for Healthcare via Composition of Neural-Symbolic Reasoning Operators](https://doi.org/10.1145/3543873.3587361)|Sutanay Choudhury, Khushbu Agarwal, Colby Ham, Suzanne Tamang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MediSage:+An+AI+Assistant+for+Healthcare+via+Composition+of+Neural-Symbolic+Reasoning+Operators)|0|
|[Depicting Vocabulary Summaries with Devos](https://doi.org/10.1145/3543873.3587359)|Ahmad Alobaid, Jhon Toledo, Óscar Corcho, María PovedaVillalón||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Depicting+Vocabulary+Summaries+with+Devos)|0|
|[Child Sexual Abuse Awareness and Support Seeking on Reddit: A thematic Analysis](https://doi.org/10.1145/3543873.3587363)|Siva Sahitya Simhadri, Tatiana Ringenberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Child+Sexual+Abuse+Awareness+and+Support+Seeking+on+Reddit:+A+thematic+Analysis)|0|
|[Violentometer: measuring violence on the Web in real time](https://doi.org/10.1145/3543873.3587364)|Henrique S. Xavier||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Violentometer:+measuring+violence+on+the+Web+in+real+time)|0|
|[Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech](https://doi.org/10.1145/3543873.3587368)|Fan Huang, Haewoon Kwak, Jisun An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+ChatGPT+better+than+Human+Annotators?+Potential+and+Limitations+of+ChatGPT+in+Explaining+Implicit+Hate+Speech)|0|
|[RealGraph+: A High-Performance Single-Machine-Based Graph Engine that Utilizes IO Bandwidth Effectively](https://doi.org/10.1145/3543873.3587365)|MyungHwan Jang, JeongMin Park, Ikhyeon Jo, DuckHo Bae, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RealGraph+:+A+High-Performance+Single-Machine-Based+Graph+Engine+that+Utilizes+IO+Bandwidth+Effectively)|0|
|[Hierarchical Deep Neural Network Inference for Device-Edge-Cloud Systems](https://doi.org/10.1145/3543873.3587370)|Fatih Ilhan, Selim Furkan Tekin, Sihao Hu, Tiansheng Huang, Ka Ho Chow, Ling Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Deep+Neural+Network+Inference+for+Device-Edge-Cloud+Systems)|0|
|[A Detection System for Comfortable Locations Based on Facial Expression Analysis While Riding Bicycles](https://doi.org/10.1145/3543873.3587371)|Ryuta Yamaguchi, Panote Siriaraya, Tomoki Yoshihisa, Shinji Shimojo, Yukiko Kawai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Detection+System+for+Comfortable+Locations+Based+on+Facial+Expression+Analysis+While+Riding+Bicycles)|0|
|[Efficient Fair Graph Representation Learning Using a Multi-level Framework](https://doi.org/10.1145/3543873.3587369)|Yuntian He, Saket Gurukar, Srinivasan Parthasarathy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Fair+Graph+Representation+Learning+Using+a+Multi-level+Framework)|0|
|[Simple Multi-view Can Bring Powerful Graph Neural Network](https://doi.org/10.1145/3543873.3587375)|Bingbing Xu, Yang Li, Qi Cao, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simple+Multi-view+Can+Bring+Powerful+Graph+Neural+Network)|0|
|[EDITS: An Easy-to-difficult Training Strategy for Cloud Failure Prediction](https://doi.org/10.1145/3543873.3584630)|Qingwei Lin, Tianci Li, Pu Zhao, Yudong Liu, Minghua Ma, Lingling Zheng, Murali Chintalapati, Bo Liu, Paul Wang, Hongyu Zhang, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EDITS:+An+Easy-to-difficult+Training+Strategy+for+Cloud+Failure+Prediction)|0|
|[Multi-Agent Reinforcement Learning with Shared Policy for Cloud Quota Management Problem](https://doi.org/10.1145/3543873.3584634)|Tong Cheng, Hang Dong, Lu Wang, Bo Qiao, Si Qin, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Thomas Moscibroda||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Agent+Reinforcement+Learning+with+Shared+Policy+for+Cloud+Quota+Management+Problem)|0|
|[Job Type Extraction for Service Businesses](https://doi.org/10.1145/3543873.3584636)|Cheng Li, Yaping Qi, Hayk Zakaryan, Mingyang Zhang, Michael Bendersky, Yonghua Wu, Marc Najork||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Job+Type+Extraction+for+Service+Businesses)|0|
|[A Practical Rule Learning Framework for Risk Management](https://doi.org/10.1145/3543873.3584644)|Jun Zhou, Meng Li, Lu Yu, Longfei Li, Fei Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Practical+Rule+Learning+Framework+for+Risk+Management)|0|
|[WAM-studio, a Digital Audio Workstation (DAW) for the Web](https://doi.org/10.1145/3543873.3587987)|Michel Buffa, Antoine VidalMazuy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WAM-studio,+a+Digital+Audio+Workstation+(DAW)+for+the+Web)|0|
|[The Capable Web](https://doi.org/10.1145/3543873.3587988)|Thomas Steiner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Capable+Web)|0|
|[MetaCrimes: Criminal accountability for conducts in the Metaverse](https://doi.org/10.1145/3543873.3587535)|Gian Marco Bovenzi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaCrimes:+Criminal+accountability+for+conducts+in+the+Metaverse)|0|
|[SEKA: Seeking Knowledge Graph Anomalies](https://doi.org/10.1145/3543873.3587536)|Asara Senaratne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEKA:+Seeking+Knowledge+Graph+Anomalies)|0|
|[Detecting Cross-Lingual Information Gaps in Wikipedia](https://doi.org/10.1145/3543873.3587539)|Vahid Ashrafimoghari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Cross-Lingual+Information+Gaps+in+Wikipedia)|0|
|[Caught in the Game: On the History and Evolution of Web Browser Gaming](https://doi.org/10.1145/3543873.3585572)|Naif Mehanna, Walter Rudametkin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Caught+in+the+Game:+On+the+History+and+Evolution+of+Web+Browser+Gaming)|0|
|[Identifying Stable States of Large Signed Graphs](https://doi.org/10.1145/3543873.3587544)|Muhieddine Shebaro, Jelena Tesic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Stable+States+of+Large+Signed+Graphs)|0|
|[Those who are left behind: A chronicle of internet access in Cuba](https://doi.org/10.1145/3543873.3585573)|Brenda Reyes Ayala||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Those+who+are+left+behind:+A+chronicle+of+internet+access+in+Cuba)|0|
|[Reflex-in: Generate Music on the Web with Real-time Brain Wave](https://doi.org/10.1145/3543873.3587315)|Shihong Ren, Michel Buffa, Laurent Pottier, Yang Yu, Gerwin Schalk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reflex-in:+Generate+Music+on+the+Web+with+Real-time+Brain+Wave)|0|
|[Wikidata: The Making Of](https://doi.org/10.1145/3543873.3585579)|Denny Vrandecic, Lydia Pintscher, Markus Krötzsch||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wikidata:+The+Making+Of)|0|
|[A History of Diversity in The Web (Conference)](https://doi.org/10.1145/3543873.3585576)|Siddharth D. Jaiswal, Animesh Mukherjee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+History+of+Diversity+in+The+Web+(Conference))|0|
|[Why are Hyperlinks Blue?: A deep dive into browser hyperlink color history](https://doi.org/10.1145/3543873.3587714)|Elise Blanchard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+are+Hyperlinks+Blue?:+A+deep+dive+into+browser+hyperlink+color+history)|0|
|[The One Hundred Year Web](https://doi.org/10.1145/3543873.3585578)|Steven Pemberton||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+One+Hundred+Year+Web)|0|
|[Followers Tell Who an Influencer Is](https://doi.org/10.1145/3543873.3587576)|Dheeman Saha, Md Rashidul Hasan, Abdullah Mueen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Followers+Tell+Who+an+Influencer+Is)|0|
|[Smart Cities as Hubs: a use case from Biotechnology](https://doi.org/10.1145/3543873.3587582)|Tsapadikou Asteria, Leonidas G. Anthopoulos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Smart+Cities+as+Hubs:+a+use+case+from+Biotechnology)|0|
|[Do bridges dream of water pollutants? Towards DreamsKG, a knowledge graph to make digital access for sustainable environmental assessment come true](https://doi.org/10.1145/3543873.3587590)|Darío Garigliotti, Johannes Bjerva, Finn Årup Nielsen, Annika Butzbach, Ivar Lyhne, Lone Kørnøv, Katja Hose||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+bridges+dream+of+water+pollutants?+Towards+DreamsKG,+a+knowledge+graph+to+make+digital+access+for+sustainable+environmental+assessment+come+true)|0|
|[Towards High Resolution Urban Heat Analysis: Incorporating Thermal Drones to Enhance Satellite Based Urban Heatmaps](https://doi.org/10.1145/3543873.3587682)|Bryan Rickens, Navid Hashemi Tonekaboni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+High+Resolution+Urban+Heat+Analysis:+Incorporating+Thermal+Drones+to+Enhance+Satellite+Based+Urban+Heatmaps)|0|
|[Towards a Sustainability Index Calculator for Smart Cities](https://doi.org/10.1145/3543873.3587683)|Ramesh Gorantla, Srividya Bansal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Sustainability+Index+Calculator+for+Smart+Cities)|0|
|[Sustainable Grain Transportation in Ukraine Amidst War Utilizing KNARM and KnowWhereGraph](https://doi.org/10.1145/3543873.3587618)|Yinglun Zhang, Antonina Broyaka, Jude Kastens, Allen M. Featherstone, Cogan Shimizu, Pascal Hitzler, Hande KüçükMcGinty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sustainable+Grain+Transportation+in+Ukraine+Amidst+War+Utilizing+KNARM+and+KnowWhereGraph)|0|
|[Entity and Event Topic Extraction from Podcast Episode Title and Description Using Entity Linking](https://doi.org/10.1145/3543873.3587648)|Christian Siagian, Amina Shabbeer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity+and+Event+Topic+Extraction+from+Podcast+Episode+Title+and+Description+Using+Entity+Linking)|0|
|[NASA Science Mission Directorate Knowledge Graph Discovery](https://doi.org/10.1145/3543873.3587585)|Roelien C. Timmer, Megan Mark, Fech Scen Khoo, Marcella Scoczynski Ribeiro Martins, Anamaria Berea, Gregory Renard, Kaylin M. Bugbee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NASA+Science+Mission+Directorate+Knowledge+Graph+Discovery)|0|
|[Scientific Data Extraction from Oceanographic Papers](https://doi.org/10.1145/3543873.3587595)|Bartal Eyðfinsson Veyhe, Tomer Sagi, Katja Hose||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scientific+Data+Extraction+from+Oceanographic+Papers)|0|
|[Cross-Team Collaboration and Diversity in the Bridge2AI Project](https://doi.org/10.1145/3543873.3587579)|Huimin Xu, Chitrank Gupta, Zhandos Sembay, Swathi Thaker, Pamela PayneFoster, Jake Chen, Ying Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Team+Collaboration+and+Diversity+in+the+Bridge2AI+Project)|0|
|[A New Annotation Method and Dataset for Layout Analysis of Long Documents](https://doi.org/10.1145/3543873.3587609)|Aman Ahuja, Kevin Dinh, Brian Dinh, William A. Ingram, Edward A. Fox||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Annotation+Method+and+Dataset+for+Layout+Analysis+of+Long+Documents)|0|
|[Towards InnoGraph: A Knowledge Graph for AI Innovation](https://doi.org/10.1145/3543873.3587614)|M. Besher Massri, Blerina Spahiu, Marko Grobelnik, Vladimir Alexiev, Matteo Palmonari, Dumitru Roman||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+InnoGraph:+A+Knowledge+Graph+for+AI+Innovation)|0|
|[Assessing Scientific Contributions in Data Sharing Spaces](https://doi.org/10.1145/3543873.3587608)|Kacy Adams, Fernando Spadea, Conor Flynn, Oshani Seneviratne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Scientific+Contributions+in+Data+Sharing+Spaces)|0|
|[Promoting Inactive Members in Edge-Building Marketplace](https://doi.org/10.1145/3543873.3587647)|Ayan Acharya, Siyuan Gao, Borja Ocejo, Kinjal Basu, Ankan Saha, Sathiya Keerthi Selvaraj, Rahul Mazumder, Parag Agrawal, Aman Gupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Promoting+Inactive+Members+in+Edge-Building+Marketplace)|0|
|[CLIME: Completeness-Constrained LIME](https://doi.org/10.1145/3543873.3587652)|Claudia V. Roberts, Ehtsham Elahi, Ashok Chandrashekar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLIME:+Completeness-Constrained+LIME)|0|
|[DeepPvisit: A Deep Survival Model for Notification Management](https://doi.org/10.1145/3543873.3587666)|Guangyu Yang, Efrem Ghebreab, Jiaxi Xu, Xianen Qiu, Yiping Yuan, Wensheng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeepPvisit:+A+Deep+Survival+Model+for+Notification+Management)|0|
|[Digital Twins for Radiation Oncology](https://doi.org/10.1145/3543873.3587688)|James Jensen, Jun Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Digital+Twins+for+Radiation+Oncology)|0|
|[Graph-Based Hierarchical Attention Network for Suicide Risk Detection on Social Media](https://doi.org/10.1145/3543873.3587587)|Usman Naseem, Jinman Kim, Matloob Khushi, Adam G. Dunn||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-Based+Hierarchical+Attention+Network+for+Suicide+Risk+Detection+on+Social+Media)|0|
|[I'm out of breath from laughing! I think? A dataset of COVID-19 Humor and its toxic variants](https://doi.org/10.1145/3543873.3587591)|Neha Reddy Bogireddy, Smriti Suresh, Sunny Rai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=I'm+out+of+breath+from+laughing!+I+think?+A+dataset+of+COVID-19+Humor+and+its+toxic+variants)|0|
|[LLMs to the Moon? Reddit Market Sentiment Analysis with Large Language Models](https://doi.org/10.1145/3543873.3587605)|Xiang Deng, Vasilisa Bashlovkina, Feng Han, Simon Baumgartner, Michael Bendersky||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLMs+to+the+Moon?+Reddit+Market+Sentiment+Analysis+with+Large+Language+Models)|0|
|[Forecasting COVID-19 Vaccination Rates using Social Media Data](https://doi.org/10.1145/3543873.3587639)|Xintian Li, Aron Culotta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forecasting+COVID-19+Vaccination+Rates+using+Social+Media+Data)|0|
|[A Cross-Modal Study of Pain Across Communities in the United States](https://doi.org/10.1145/3543873.3587642)|Arnav Aggarwal, Sunny Rai, Salvatore Giorgi, Shreya Havaldar, Garrick Sherman, Juhi Mittal, Sharath Chandra Guntuku||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Cross-Modal+Study+of+Pain+Across+Communities+in+the+United+States)|0|
|[Claim Extraction and Dynamic Stance Detection in COVID-19 Tweets](https://doi.org/10.1145/3543873.3587643)|Noushin Salek Faramarzi, Fateme Hashemi Chaleshtori, Hossein Shirazi, Indrakshi Ray, Ritwik Banerjee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Claim+Extraction+and+Dynamic+Stance+Detection+in+COVID-19+Tweets)|0|
|[Self-supervised Pre-training and Semi-supervised Learning for Extractive Dialog Summarization](https://doi.org/10.1145/3543873.3587680)|Yingying Zhuang, Jiecheng Song, Narayanan Sadagopan, Anurag Beniwal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+Pre-training+and+Semi-supervised+Learning+for+Extractive+Dialog+Summarization)|0|
|[Ready, Aim, Snipe! Analysis of Sniper Bots and their Impact on the DeFi Ecosystem](https://doi.org/10.1145/3543873.3587612)|Federico Cernera, Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini, Francesco Sassi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ready,+Aim,+Snipe!+Analysis+of+Sniper+Bots+and+their+Impact+on+the+DeFi+Ecosystem)|0|
|[Regime-based Implied Stochastic Volatility Model for Crypto Option Pricing](https://doi.org/10.1145/3543873.3587621)|Danial Saef, Yuanrong Wang, Tomaso Aste||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regime-based+Implied+Stochastic+Volatility+Model+for+Crypto+Option+Pricing)|0|
|[NLP4KGC: Natural Language Processing for Knowledge Graph Construction](https://doi.org/10.1145/3543873.3589746)|Edlira Vakaj, Sanju Tiwari, Nandana Mihindukulasooriya, Fernando OrtizRodríguez, Ryan McGranaghan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NLP4KGC:+Natural+Language+Processing+for+Knowledge+Graph+Construction)|0|
|[GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering](https://doi.org/10.1145/3543873.3587651)|Dhaval Taunk, Lakshya Khanna, Siri Venkata Pavan Kumar Kandru, Vasudeva Varma, Charu Sharma, Makarand Tapaswi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GrapeQA:+GRaph+Augmentation+and+Pruning+to+Enhance+Question-Answering)|0|
|[Federated Learning for Metaverse: A Survey](https://doi.org/10.1145/3543873.3587584)|Yao Chen, Shan Huang, Wensheng Gan, Gengsen Huang, Yongdong Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Learning+for+Metaverse:+A+Survey)|0|
|[Understanding the Impact of Label Skewness and Optimization on Federated Learning for Text Classification](https://doi.org/10.1145/3543873.3587599)|Sumam Francis, Kanimozhi Uma, MarieFrancine Moens||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Impact+of+Label+Skewness+and+Optimization+on+Federated+Learning+for+Text+Classification)|0|
|[A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness and Privacy](https://doi.org/10.1145/3543873.3587681)|Yifei Zhang, Dun Zeng, Jinglong Luo, Zenglin Xu, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Survey+of+Trustworthy+Federated+Learning+with+Perspectives+on+Security,+Robustness+and+Privacy)|0|
|[A Federated Learning Benchmark for Drug-Target Interaction](https://doi.org/10.1145/3543873.3587687)|Gianluca Mittone, Filip Svoboda, Marco Aldinucci, Nicholas D. Lane, Pietro Lió||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Federated+Learning+Benchmark+for+Drug-Target+Interaction)|0|
|[Towards Timeline Generation with Abstract Meaning Representation](https://doi.org/10.1145/3543873.3587670)|Behrooz Mansouri, Ricardo Campos, Adam Jatowt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Timeline+Generation+with+Abstract+Meaning+Representation)|0|
|[Gone, Gone, but Not Really, and Gone, But Not forgotten: A Typology of Website Recoverability](https://doi.org/10.1145/3543873.3587671)|Brenda Reyes Ayala||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gone,+Gone,+but+Not+Really,+and+Gone,+But+Not+forgotten:+A+Typology+of+Website+Recoverability)|0|
|[Detecting the Hidden Dynamics of Networked Actors Using Temporal Correlations](https://doi.org/10.1145/3543873.3587672)|Keeley Erhardt, Dina Albassam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+the+Hidden+Dynamics+of+Networked+Actors+Using+Temporal+Correlations)|0|
|[The Age of Snippet Programming: Toward Understanding Developer Communities in Stack Overflow and Reddit](https://doi.org/10.1145/3543873.3587673)|Alessia Antelmi, Gennaro Cordasco, Daniele De Vinco, Carmine Spagnuolo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Age+of+Snippet+Programming:+Toward+Understanding+Developer+Communities+in+Stack+Overflow+and+Reddit)|0|
|[Temporal Ordinance Mining for Event-Driven Social Media Reaction Analytics](https://doi.org/10.1145/3543873.3587674)|Aparna S. Varde, Gerard de Melo, Boxiang Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Ordinance+Mining+for+Event-Driven+Social+Media+Reaction+Analytics)|0|
|[A Chinese Fine-grained Financial Event Extraction Dataset](https://doi.org/10.1145/3543873.3587578)|Mengjie Wu, Maofu Liu, Luyao Wang, Huijun Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Chinese+Fine-grained+Financial+Event+Extraction+Dataset)|0|
|[Financial Technology on the Web](https://doi.org/10.1145/3543873.3589738)|ChungChi Chen, HenHsen Huang, Hiroya Takamura, HsinHsi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Financial+Technology+on+the+Web)|0|
|[Aspect-based Summarization of Legal Case Files using Sentence Classification](https://doi.org/10.1145/3543873.3587611)|Nikhil E, Anshul Padhi, Pulkit Parikh, Swati Kanwal, Kamalakar Karlapalem, Natraj Raman||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aspect-based+Summarization+of+Legal+Case+Files+using+Sentence+Classification)|0|
|[Exploiting graph metrics to detect anomalies in cross-country money transfer temporal networks](https://doi.org/10.1145/3543873.3587602)|Salvatore Vilella, Arthur Thomas Edward Capozzi Lupi, Giancarlo Ruffo, Marco Fornasiero, Dario Moncalvo, Valeria Ricci, Silvia Ronchiadin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+graph+metrics+to+detect+anomalies+in+cross-country+money+transfer+temporal+networks)|0|
|[Multiple-Agent Deep Reinforcement Learning for Avatar Migration in Vehicular Metaverses](https://doi.org/10.1145/3543873.3587573)|Junlong Chen, Jiangtian Nie, Minrui Xu, Lingjuan Lyu, Zehui Xiong, Jiawen Kang, Yongju Tong, Wenchao Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiple-Agent+Deep+Reinforcement+Learning+for+Avatar+Migration+in+Vehicular+Metaverses)|0|
|[China's First Natural Language-based AI ChatBot Trader](https://doi.org/10.1145/3543873.3587633)|James Y. Zhang, Zhi Li, Hao Fang, Jun Wu, Zhongnan Shen, Jing Zheng, Wei Chu, Weiping Duan, Peng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=China's+First+Natural+Language-based+AI+ChatBot+Trader)|0|
|[Web 3.0: The Future of Internet](https://doi.org/10.1145/3543873.3587583)|Wensheng Gan, Zhenqiang Ye, Shicheng Wan, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Web+3.0:+The+Future+of+Internet)|0|
|[DSNet: Efficient Lightweight Model for Video Salient Object Detection for IoT and WoT Applications](https://doi.org/10.1145/3543873.3587592)|Hemraj Singh, Mridula Verma, Ramalingaswamy Cheruku||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DSNet:+Efficient+Lightweight+Model+for+Video+Salient+Object+Detection+for+IoT+and+WoT+Applications)|0|
|[Weighted Statistically Significant Pattern Mining](https://doi.org/10.1145/3543873.3587586)|Tingfu Zhou, Zhenlian Qi, Wensheng Gan, Shicheng Wan, Guoting Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weighted+Statistically+Significant+Pattern+Mining)|0|
|[The Human-Centric Metaverse: A Survey](https://doi.org/10.1145/3543873.3587593)|Riyan Yang, Lin Li, Wensheng Gan, Zefeng Chen, Zhenlian Qi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Human-Centric+Metaverse:+A+Survey)|0|
|[Can Deepfakes be created on a whim?](https://doi.org/10.1145/3543873.3587581)|Pulak Mehta, Gauri Jagatap, Kevin Gallagher, Brian Timmerman, Progga Deb, Siddharth Garg, Rachel Greenstadt, Brendan DolanGavitt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Deepfakes+be+created+on+a+whim?)|0|
|[On Cohesively Polarized Communities in Signed Networks](https://doi.org/10.1145/3543873.3587698)|Jason Niu, Ahmet Erdem Sariyüce||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Cohesively+Polarized+Communities+in+Signed+Networks)|0|
|[Towards Automated Detection of Risky Images Shared by Youth on Social Media](https://doi.org/10.1145/3543873.3587607)|Jinkyung Park, Joshua Gracie, Ashwaq Alsoubai, Gianluca Stringhini, Vivek K. Singh, Pamela J. Wisniewski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Automated+Detection+of+Risky+Images+Shared+by+Youth+on+Social+Media)|0|
|[Detecting Social Media Manipulation in Low-Resource Languages](https://doi.org/10.1145/3543873.3587615)|Samar Haider, Luca Luceri, Ashok Deb, Adam Badawy, Nanyun Peng, Emilio Ferrara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Social+Media+Manipulation+in+Low-Resource+Languages)|0|
|[Text Mining-based Social-Psychological Vulnerability Analysis of Potential Victims To Cybergrooming: Insights and Lessons Learned](https://doi.org/10.1145/3543873.3587636)|Zhen Guo, Pei Wang, JinHee Cho, Lifu Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text+Mining-based+Social-Psychological+Vulnerability+Analysis+of+Potential+Victims+To+Cybergrooming:+Insights+and+Lessons+Learned)|0|
|[Evaluating the Emergence of Collective Identity using Socio-Computational Techniques](https://doi.org/10.1145/3543873.3587637)|Billy Spann, Nitin Agarwal, David Stafford, Obianuju Okeke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+the+Emergence+of+Collective+Identity+using+Socio-Computational+Techniques)|0|
|[Trusting Decentralised Knowledge Graphs and Web Data at the Web Conference](https://doi.org/10.1145/3543873.3589756)|John Domingue, Aisling Third, MariaEsther Vidal, Philipp D. Rohde, Juan Cano, Andrea Cimmino, Ruben Verborgh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trusting+Decentralised+Knowledge+Graphs+and+Web+Data+at+the+Web+Conference)|0|
|[A Decentralised Persistent Identification Layer for DCAT Datasets](https://doi.org/10.1145/3543873.3587589)|Fabian Kirstein, Anton Altenbernd, Sonja Schimmler, Manfred Hauswirth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Decentralised+Persistent+Identification+Layer+for+DCAT+Datasets)|0|
|[Practical challenges of ODRL and potential courses of action](https://doi.org/10.1145/3543873.3587628)|Andrea Cimmino, Juan CanoBenito, Raúl GarcíaCastro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+challenges+of+ODRL+and+potential+courses+of+action)|0|
|[The Web and Linked Data as a Solid Foundation for Dataspaces](https://doi.org/10.1145/3543873.3587616)|Sascha Meckler, Rene Dorsch, Daniel Henselmann, Andreas Harth||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Web+and+Linked+Data+as+a+Solid+Foundation+for+Dataspaces)|0|
|[Extending Actor Models in Data Spaces](https://doi.org/10.1145/3543873.3587645)|Hendrik Meyer zum Felde, Maarten Kollenstart, Thomas Bellebaum, Simon Dalmolen, Gerd Brost||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extending+Actor+Models+in+Data+Spaces)|0|
|[Towards Decentralised Learning Analytics (Positioning Paper)](https://doi.org/10.1145/3543873.3587644)|Audrey Ekuban, John Domingue||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Decentralised+Learning+Analytics+(Positioning+Paper))|0|
|[Analyzing Distributed Medical Data in FAIR Data Spaces](https://doi.org/10.1145/3543873.3587663)|Mehrshad Jaberansary, Macedo Maia, Yeliz Ucer Yediel, Oya Beyan, Toralf Kirsten||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+Distributed+Medical+Data+in+FAIR+Data+Spaces)|0|
|[Requirements and Building Blocks for Manufacturing Dataspaces](https://doi.org/10.1145/3543873.3587664)|Rohit A. Deshmukh, Sisay Adugna Chala, Christoph Lange||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Requirements+and+Building+Blocks+for+Manufacturing+Dataspaces)|0|
|[Towards Multimodal Knowledge Graphs for Data Spaces](https://doi.org/10.1145/3543873.3587665)|Atiya Usmani, Muhammad Jaleed Khan, John G. Breslin, Edward Curry||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Multimodal+Knowledge+Graphs+for+Data+Spaces)|0|
|[SPACE_DS: Towards a Circular Economy Data Space](https://doi.org/10.1145/3543873.3587685)|André Pomp, Maike Jansen, Holger Berg, Tobias Meisen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SPACE_DS:+Towards+a+Circular+Economy+Data+Space)|0|
|[Towards a Data Space for Interoperability of Analytic Provenance](https://doi.org/10.1145/3543873.3587686)|Tristan Langer, André Pomp, Tobias Meisen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Data+Space+for+Interoperability+of+Analytic+Provenance)|0|
|[Provenance for Lattice QCD workflows](https://doi.org/10.1145/3543873.3587559)|Tanja Auge, Gunnar Bali, Meike Klettke, Bertram Ludäscher, Wolfgang Söldner, Simon Weishäupl, Tilo Wettig||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Provenance+for+Lattice+QCD+workflows)|0|
|[Implementing an Environmental Management System Using Provenance-By-Design](https://doi.org/10.1145/3543873.3587560)|Luc Moreau, Nicola Hogan, Nick O'Donnell||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Implementing+an+Environmental+Management+System+Using+Provenance-By-Design)|0|
|[Trust the Process: Analyzing Prospective Provenance for Data Cleaning](https://doi.org/10.1145/3543873.3587558)|Nikolaus Nova Parulian, Bertram Ludäscher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trust+the+Process:+Analyzing+Prospective+Provenance+for+Data+Cleaning)|0|
|[Deep Learning Provenance Data Integration: a Practical Approach](https://doi.org/10.1145/3543873.3587561)|Débora B. Pina, Adriane Chapman, Daniel de Oliveira, Marta Mattoso||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning+Provenance+Data+Integration:+a+Practical+Approach)|0|
|[Providing Data on Financial Results of Public Companies Enriched with Provenance for OBInvest](https://doi.org/10.1145/3543873.3587566)|Saulo Almeida, Gilberto Passos, Valquire Jesus, Sérgio Manuel Serra da Cruz, Jorge Zavaleta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Providing+Data+on+Financial+Results+of+Public+Companies+Enriched+with+Provenance+for+OBInvest)|0|
|[Using diversity as a source of scientific innovation for the Web](https://doi.org/10.1145/3543507.3593046)|Barbara Poblete||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+diversity+as+a+source+of+scientific+innovation+for+the+Web)|0|
|[Concept Regulation in the Social Sciences](https://doi.org/10.1145/3543507.3593050)|Zachary Elkins||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Concept+Regulation+in+the+Social+Sciences)|0|
|[GNNs and Graph Generative models for biomedical applications](https://doi.org/10.1145/3543507.3593049)|Michalis Vazirgiannis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GNNs+and+Graph+Generative+models+for+biomedical+applications)|0|
|[Decolonizing Creative Labor in the age of AI](https://doi.org/10.1145/3543507.3593047)|Payal Arora||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decolonizing+Creative+Labor+in+the+age+of+AI)|0|
|[Connectivity](https://doi.org/10.1145/3543507.3593048)|Robert Melancton Metcalfe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Connectivity)|0|
|[Fair Graph Representation Learning via Diverse Mixture-of-Experts](https://doi.org/10.1145/3543507.3583207)|Zheyuan Liu, Chunhui Zhang, Yijun Tian, Erchi Zhang, Chao Huang, Yanfang Ye, Chuxu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Graph+Representation+Learning+via+Diverse+Mixture-of-Experts)|0|
|[Multi-Aspect Heterogeneous Graph Augmentation](https://doi.org/10.1145/3543507.3583208)|Yuchen Zhou, Yanan Cao, Yongchao Liu, Yanmin Shang, Peng Zhang, Zheng Lin, Yun Yue, Baokun Wang, Xing Fu, Weiqiang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Aspect+Heterogeneous+Graph+Augmentation)|0|
|[Testing Cluster Properties of Signed Graphs](https://doi.org/10.1145/3543507.3583213)|Florian Adriaens, Simon Apers||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Testing+Cluster+Properties+of+Signed+Graphs)|0|
|[RSGNN: A Model-agnostic Approach for Enhancing the Robustness of Signed Graph Neural Networks](https://doi.org/10.1145/3543507.3583221)|Zeyu Zhang, Jiamou Liu, Xianda Zheng, Yifei Wang, Pengqian Han, Yupan Wang, Kaiqi Zhao, Zijian Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RSGNN:+A+Model-agnostic+Approach+for+Enhancing+the+Robustness+of+Signed+Graph+Neural+Networks)|0|
|[Multi-aspect Diffusion Network Inference](https://doi.org/10.1145/3543507.3583228)|Hao Huang, Keqi Han, Beicheng Xu, Ting Gan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-aspect+Diffusion+Network+Inference)|0|
|[Encoding Node Diffusion Competence and Role Significance for Network Dismantling](https://doi.org/10.1145/3543507.3583233)|Jiazheng Zhang, Bang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Encoding+Node+Diffusion+Competence+and+Role+Significance+for+Network+Dismantling)|0|
|[Opinion Maximization in Social Networks via Leader Selection](https://doi.org/10.1145/3543507.3583243)|Xiaotian Zhou, Zhongzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Opinion+Maximization+in+Social+Networks+via+Leader+Selection)|0|
|[Graph Self-supervised Learning with Augmentation-aware Contrastive Learning](https://doi.org/10.1145/3543507.3583246)|Dong Chen, Xiang Zhao, Wei Wang, Zhen Tan, Weidong Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Self-supervised+Learning+with+Augmentation-aware+Contrastive+Learning)|0|
|[Unifying and Improving Graph Convolutional Neural Networks with Wavelet Denoising Filters](https://doi.org/10.1145/3543507.3583253)|Liangtian Wan, Xiaona Li, Huijin Han, Xiaoran Yan, Lu Sun, Zhaolong Ning, Feng Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+and+Improving+Graph+Convolutional+Neural+Networks+with+Wavelet+Denoising+Filters)|0|
|[Neighborhood Structure Configuration Models](https://doi.org/10.1145/3543507.3583266)|Felix I. Stamm, Michael Scholkemper, Michael T. Schaub, Markus Strohmaier||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighborhood+Structure+Configuration+Models)|0|
|[CurvDrop: A Ricci Curvature Based Approach to Prevent Graph Neural Networks from Over-Smoothing and Over-Squashing](https://doi.org/10.1145/3543507.3583269)|Yang Liu, Chuan Zhou, Shirui Pan, Jia Wu, Zhao Li, Hongyang Chen, Peng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CurvDrop:+A+Ricci+Curvature+Based+Approach+to+Prevent+Graph+Neural+Networks+from+Over-Smoothing+and+Over-Squashing)|0|
|[A Post-Training Framework for Improving Heterogeneous Graph Neural Networks](https://doi.org/10.1145/3543507.3583282)|Cheng Yang, Xumeng Gong, Chuan Shi, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Post-Training+Framework+for+Improving+Heterogeneous+Graph+Neural+Networks)|0|
|[Link Prediction on Latent Heterogeneous Graphs](https://doi.org/10.1145/3543507.3583284)|TrungKien Nguyen, Zemin Liu, Yuan Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Link+Prediction+on+Latent+Heterogeneous+Graphs)|0|
|[Predicting the Silent Majority on Graphs: Knowledge Transferable Graph Neural Network](https://doi.org/10.1145/3543507.3583287)|Wendong Bi, Bingbing Xu, Xiaoqian Sun, Li Xu, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+the+Silent+Majority+on+Graphs:+Knowledge+Transferable+Graph+Neural+Network)|0|
|[Automated Spatio-Temporal Graph Contrastive Learning](https://doi.org/10.1145/3543507.3583304)|Qianru Zhang, Chao Huang, Lianghao Xia, Zheng Wang, Zhonghang Li, SiuMing Yiu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Spatio-Temporal+Graph+Contrastive+Learning)|0|
|[Robust Mid-Pass Filtering Graph Convolutional Networks](https://doi.org/10.1145/3543507.3583335)|Jincheng Huang, Lun Du, Xu Chen, Qiang Fu, Shi Han, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Mid-Pass+Filtering+Graph+Convolutional+Networks)|0|
|[PARROT: Position-Aware Regularized Optimal Transport for Network Alignment](https://doi.org/10.1145/3543507.3583357)|Zhichen Zeng, Si Zhang, Yinglong Xia, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PARROT:+Position-Aware+Regularized+Optimal+Transport+for+Network+Alignment)|0|
|[Label Information Enhanced Fraud Detection against Low Homophily in Graphs](https://doi.org/10.1145/3543507.3583373)|Yuchen Wang, Jinghui Zhang, Zhengjie Huang, Weibin Li, Shikun Feng, Ziheng Ma, Yu Sun, Dianhai Yu, Fang Dong, Jiahui Jin, Beilun Wang, Junzhou Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Label+Information+Enhanced+Fraud+Detection+against+Low+Homophily+in+Graphs)|0|
|[An Attentional Multi-scale Co-evolving Model for Dynamic Link Prediction](https://doi.org/10.1145/3543507.3583396)|Guozhen Zhang, Tian Ye, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Attentional+Multi-scale+Co-evolving+Model+for+Dynamic+Link+Prediction)|0|
|[Robust Graph Representation Learning for Local Corruption Recovery](https://doi.org/10.1145/3543507.3583399)|Bingxin Zhou, Yuanhong Jiang, Yuguang Wang, Jingwei Liang, Junbin Gao, Shirui Pan, Xiaoqun Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Graph+Representation+Learning+for+Local+Corruption+Recovery)|0|
|[Hyperbolic Geometric Graph Representation Learning for Hierarchy-imbalance Node Classification](https://doi.org/10.1145/3543507.3583403)|Xingcheng Fu, Yuecen Wei, Qingyun Sun, Haonan Yuan, Jia Wu, Hao Peng, Jianxin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperbolic+Geometric+Graph+Representation+Learning+for+Hierarchy-imbalance+Node+Classification)|0|
|[Graph Neural Networks without Propagation](https://doi.org/10.1145/3543507.3583419)|Liang Yang, Qiuliang Zhang, Runjie Shi, Wenmiao Zhou, Bingxin Niu, Chuan Wang, Xiaochun Cao, Dongxiao He, Zhen Wang, Yuanfang Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks+without+Propagation)|0|
|[Self-Supervised Teaching and Learning of Representations on Graphs](https://doi.org/10.1145/3543507.3583441)|Liangtian Wan, Zhenqiang Fu, Lu Sun, Xianpeng Wang, Gang Xu, Xiaoran Yan, Feng Xia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Teaching+and+Learning+of+Representations+on+Graphs)|0|
|[SE-GSL: A General and Effective Graph Structure Learning Framework through Structural Entropy Optimization](https://doi.org/10.1145/3543507.3583453)|Dongcheng Zou, Hao Peng, Xiang Huang, Renyu Yang, Jianxin Li, Jia Wu, Chunyang Liu, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SE-GSL:+A+General+and+Effective+Graph+Structure+Learning+Framework+through+Structural+Entropy+Optimization)|0|
|[Homophily-oriented Heterogeneous Graph Rewiring](https://doi.org/10.1145/3543507.3583454)|Jiayan Guo, Lun Du, Wendong Bi, Qiang Fu, Xiaojun Ma, Xu Chen, Shi Han, Dongmei Zhang, Yan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Homophily-oriented+Heterogeneous+Graph+Rewiring)|0|
|[HGWaveNet: A Hyperbolic Graph Neural Network for Temporal Link Prediction](https://doi.org/10.1145/3543507.3583455)|Qijie Bai, Changli Nie, Haiwei Zhang, Dongming Zhao, Xiaojie Yuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HGWaveNet:+A+Hyperbolic+Graph+Neural+Network+for+Temporal+Link+Prediction)|0|
|[Rethinking Structural Encodings: Adaptive Graph Transformer for Node Classification Task](https://doi.org/10.1145/3543507.3583464)|Xiaojun Ma, Qin Chen, Yi Wu, Guojie Song, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Structural+Encodings:+Adaptive+Graph+Transformer+for+Node+Classification+Task)|0|
|[Federated Node Classification over Graphs with Latent Link-type Heterogeneity](https://doi.org/10.1145/3543507.3583471)|Han Xie, Li Xiong, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Node+Classification+over+Graphs+with+Latent+Link-type+Heterogeneity)|0|
|[CMINet: a Graph Learning Framework for Content-aware Multi-channel Influence Diffusion](https://doi.org/10.1145/3543507.3583465)|HsiWen Chen, DeNian Yang, WangChien Lee, Philip S. Yu, MingSyan Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CMINet:+a+Graph+Learning+Framework+for+Content-aware+Multi-channel+Influence+Diffusion)|0|
|[Auto-HeG: Automated Graph Neural Network on Heterophilic Graphs](https://doi.org/10.1145/3543507.3583498)|Xin Zheng, Miao Zhang, Chunyang Chen, Qin Zhang, Chuan Zhou, Shirui Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Auto-HeG:+Automated+Graph+Neural+Network+on+Heterophilic+Graphs)|0|
|[HINormer: Representation Learning On Heterogeneous Information Networks with Graph Transformer](https://doi.org/10.1145/3543507.3583493)|Qiheng Mao, Zemin Liu, Chenghao Liu, Jianling Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HINormer:+Representation+Learning+On+Heterogeneous+Information+Networks+with+Graph+Transformer)|0|
|[Minimum Topology Attacks for Graph Neural Networks](https://doi.org/10.1145/3543507.3583509)|Mengmei Zhang, Xiao Wang, Chuan Shi, Lingjuan Lyu, Tianchi Yang, Junping Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Minimum+Topology+Attacks+for+Graph+Neural+Networks)|0|
|[Learning Mixtures of Markov Chains with Quality Guarantees](https://doi.org/10.1145/3543507.3583524)|Fabian Spaeh, Charalampos E. Tsourakakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Mixtures+of+Markov+Chains+with+Quality+Guarantees)|0|
|[GIF: A General Graph Unlearning Strategy via Influence Function](https://doi.org/10.1145/3543507.3583521)|Jiancan Wu, Yi Yang, Yuchun Qian, Yongduo Sui, Xiang Wang, Xiangnan He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GIF:+A+General+Graph+Unlearning+Strategy+via+Influence+Function)|0|
|[INCREASE: Inductive Graph Representation Learning for Spatio-Temporal Kriging](https://doi.org/10.1145/3543507.3583525)|Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, Jianzhong Qi, Chaochao Chen, Longbiao Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=INCREASE:+Inductive+Graph+Representation+Learning+for+Spatio-Temporal+Kriging)|0|
|[Unlearning Graph Classifiers with Limited Data Resources](https://doi.org/10.1145/3543507.3583547)|Chao Pan, Eli Chien, Olgica Milenkovic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlearning+Graph+Classifiers+with+Limited+Data+Resources)|0|
|[GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner](https://doi.org/10.1145/3543507.3583379)|Zhenyu Hou, Yufei He, Yukuo Cen, Xiao Liu, Yuxiao Dong, Evgeny Kharlamov, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphMAE2:+A+Decoding-Enhanced+Masked+Self-Supervised+Graph+Learner)|0|
|[KGTrust: Evaluating Trustworthiness of SIoT via Knowledge Enhanced Graph Neural Networks](https://doi.org/10.1145/3543507.3583549)|Zhizhi Yu, Di Jin, Cuiying Huo, Zhiqiang Wang, Xiulong Liu, Heng Qi, Jia Wu, Lingfei Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGTrust:+Evaluating+Trustworthiness+of+SIoT+via+Knowledge+Enhanced+Graph+Neural+Networks)|0|
|[CogDL: A Comprehensive Library for Graph Deep Learning](https://doi.org/10.1145/3543507.3583472)|Yukuo Cen, Zhenyu Hou, Yan Wang, Qibin Chen, Yizhen Luo, Zhongming Yu, Hengrui Zhang, Xingcheng Yao, Aohan Zeng, Shiguang Guo, Yuxiao Dong, Yang Yang, Peng Zhang, Guohao Dai, Yu Wang, Chang Zhou, Hongxia Yang, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CogDL:+A+Comprehensive+Library+for+Graph+Deep+Learning)|0|
|[Tracing Knowledge Instead of Patterns: Stable Knowledge Tracing with Diagnostic Transformer](https://doi.org/10.1145/3543507.3583255)|Yu Yin, Le Dai, Zhenya Huang, Shuanghong Shen, Fei Wang, Qi Liu, Enhong Chen, Xin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tracing+Knowledge+Instead+of+Patterns:+Stable+Knowledge+Tracing+with+Diagnostic+Transformer)|0|
|[Learning to Simulate Daily Activities via Modeling Dynamic Human Needs](https://doi.org/10.1145/3543507.3583276)|Yuan Yuan, Huandong Wang, Jingtao Ding, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Simulate+Daily+Activities+via+Modeling+Dynamic+Human+Needs)|0|
|[Controllable Universal Fair Representation Learning](https://doi.org/10.1145/3543507.3583307)|Yue Cui, Ma Chen, Kai Zheng, Lei Chen, Xiaofang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Controllable+Universal+Fair+Representation+Learning)|0|
|[Response-act Guided Reinforced Dialogue Generation for Mental Health Counseling](https://doi.org/10.1145/3543507.3583380)|Aseem Srivastava, Ishan Pandey, Md. Shad Akhtar, Tanmoy Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Response-act+Guided+Reinforced+Dialogue+Generation+for+Mental+Health+Counseling)|0|
|[Offline Policy Evaluation in Large Action Spaces via Outcome-Oriented Action Grouping](https://doi.org/10.1145/3543507.3583448)|Jie Peng, Hao Zou, Jiashuo Liu, Shaoming Li, Yibao Jiang, Jian Pei, Peng Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Offline+Policy+Evaluation+in+Large+Action+Spaces+via+Outcome-Oriented+Action+Grouping)|0|
|[Web Table Formatting Affects Readability on Mobile Devices](https://doi.org/10.1145/3543507.3583506)|Christopher Tensmeyer, Zoya Bylinskii, Tianyuan Cai, Dave Miller, Ani Nenkova, Aleena Gertrudes Niklaus, Shaun Wallace||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Web+Table+Formatting+Affects+Readability+on+Mobile+Devices)|0|
|[Web Structure Derived Clustering for Optimised Web Accessibility Evaluation](https://doi.org/10.1145/3543507.3583508)|Alexander Hambley, Yeliz Yesilada, Markel Vigo, Simon Harper||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Web+Structure+Derived+Clustering+for+Optimised+Web+Accessibility+Evaluation)|0|
|[Hashtag-Guided Low-Resource Tweet Classification](https://doi.org/10.1145/3543507.3583194)|Shizhe Diao, Sedrick Scott Keh, Liangming Pan, Zhiliang Tian, Yan Song, Tong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hashtag-Guided+Low-Resource+Tweet+Classification)|0|
|[FormerTime: Hierarchical Multi-Scale Representations for Multivariate Time Series Classification](https://doi.org/10.1145/3543507.3583205)|Mingyue Cheng, Qi Liu, Zhiding Liu, Zhi Li, Yucong Luo, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FormerTime:+Hierarchical+Multi-Scale+Representations+for+Multivariate+Time+Series+Classification)|0|
|[HISum: Hyperbolic Interaction Model for Extractive Multi-Document Summarization](https://doi.org/10.1145/3543507.3583197)|Mingyang Song, Yi Feng, Liping Jing||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HISum:+Hyperbolic+Interaction+Model+for+Extractive+Multi-Document+Summarization)|0|
|[Descartes: Generating Short Descriptions of Wikipedia Articles](https://doi.org/10.1145/3543507.3583220)|Marija Sakota, Maxime Peyrard, Robert West||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Descartes:+Generating+Short+Descriptions+of+Wikipedia+Articles)|0|
|[A Dual Prompt Learning Framework for Few-Shot Dialogue State Tracking](https://doi.org/10.1145/3543507.3583238)|Yuting Yang, Wenqiang Lei, Pei Huang, Juan Cao, Jintao Li, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dual+Prompt+Learning+Framework+for+Few-Shot+Dialogue+State+Tracking)|0|
|[TTS: A Target-based Teacher-Student Framework for Zero-Shot Stance Detection](https://doi.org/10.1145/3543507.3583250)|Yingjie Li, Chenye Zhao, Cornelia Caragea||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TTS:+A+Target-based+Teacher-Student+Framework+for+Zero-Shot+Stance+Detection)|0|
|[CL-WSTC: Continual Learning for Weakly Supervised Text Classification on the Internet](https://doi.org/10.1145/3543507.3583249)|Miaomiao Li, Jiaqi Zhu, Xin Yang, Yi Yang, Qiang Gao, Hongan Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CL-WSTC:+Continual+Learning+for+Weakly+Supervised+Text+Classification+on+the+Internet)|0|
|[Learning Robust Multi-Modal Representation for Multi-Label Emotion Recognition via Adversarial Masking and Perturbation](https://doi.org/10.1145/3543507.3583258)|Shiping Ge, Zhiwei Jiang, Zifeng Cheng, Cong Wang, Yafeng Yin, Qing Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Robust+Multi-Modal+Representation+for+Multi-Label+Emotion+Recognition+via+Adversarial+Masking+and+Perturbation)|0|
|[Continual Few-shot Learning with Transformer Adaptation and Knowledge Regularization](https://doi.org/10.1145/3543507.3583262)|Xin Wang, Yue Liu, Jiapei Fan, Weigao Wen, Hui Xue, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Few-shot+Learning+with+Transformer+Adaptation+and+Knowledge+Regularization)|0|
|[Open-World Social Event Classification](https://doi.org/10.1145/3543507.3583291)|Shengsheng Qian, Hong Chen, Dizhan Xue, Quan Fang, Changsheng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Open-World+Social+Event+Classification)|0|
|[KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate Political Stance Prediction](https://doi.org/10.1145/3543507.3583300)|YunYong Ko, Seongeun Ryu, Soeun Han, Youngseung Jeon, Jaehoon Kim, Sohyun Park, Kyungsik Han, Hanghang Tong, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KHAN:+Knowledge-Aware+Hierarchical+Attention+Networks+for+Accurate+Political+Stance+Prediction)|0|
|[Improving (Dis)agreement Detection with Inductive Social Relation Information From Comment-Reply Interactions](https://doi.org/10.1145/3543507.3583314)|Yun Luo, Zihan Liu, Stan Z. Li, Yue Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+(Dis)agreement+Detection+with+Inductive+Social+Relation+Information+From+Comment-Reply+Interactions)|0|
|[Dynalogue: A Transformer-Based Dialogue System with Dynamic Attention](https://doi.org/10.1145/3543507.3583330)|Rongjunchen Zhang, Tingmin Wu, Xiao Chen, Sheng Wen, Surya Nepal, Cécile Paris, Yang Xiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynalogue:+A+Transformer-Based+Dialogue+System+with+Dynamic+Attention)|0|
|[Active Learning from the Web](https://doi.org/10.1145/3543507.3583346)|Ryoma Sato||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Active+Learning+from+the+Web)|0|
|[The Effect of Metadata on Scientific Literature Tagging: A Cross-Field Cross-Model Study](https://doi.org/10.1145/3543507.3583354)|Yu Zhang, Bowen Jin, Qi Zhu, Yu Meng, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Effect+of+Metadata+on+Scientific+Literature+Tagging:+A+Cross-Field+Cross-Model+Study)|0|
|["Why is this misleading?": Detecting News Headline Hallucinations with Explanations](https://doi.org/10.1145/3543507.3583375)|Jiaming Shen, Jialu Liu, Daniel Finnie, Negar Rahmati, Mike Bendersky, Marc Najork||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="Why+is+this+misleading?":+Detecting+News+Headline+Hallucinations+with+Explanations)|0|
|[DIWIFT: Discovering Instance-wise Influential Features for Tabular Data](https://doi.org/10.1145/3543507.3583382)|Dugang Liu, Pengxiang Cheng, Hong Zhu, Xing Tang, Yanyu Chen, Xiaoting Wang, Weike Pan, Zhong Ming, Xiuqiang He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIWIFT:+Discovering+Instance-wise+Influential+Features+for+Tabular+Data)|0|
|[XWikiGen: Cross-lingual Summarization for Encyclopedic Text Generation in Low Resource Languages](https://doi.org/10.1145/3543507.3583405)|Dhaval Taunk, Shivprasad Sagare, Anupam Patil, Shivansh Subramanian, Manish Gupta, Vasudeva Varma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XWikiGen:+Cross-lingual+Summarization+for+Encyclopedic+Text+Generation+in+Low+Resource+Languages)|0|
|[Learning Structural Co-occurrences for Structured Web Data Extraction in Low-Resource Settings](https://doi.org/10.1145/3543507.3583387)|Zhenyu Zhang, Bowen Yu, Tingwen Liu, Tianyun Liu, Yubin Wang, Li Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Structural+Co-occurrences+for+Structured+Web+Data+Extraction+in+Low-Resource+Settings)|0|
|[TMMDA: A New Token Mixup Multimodal Data Augmentation for Multimodal Sentiment Analysis](https://doi.org/10.1145/3543507.3583406)|Xianbing Zhao, Yixin Chen, Sicen Liu, Xuan Zang, Yang Xiang, Buzhou Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TMMDA:+A+New+Token+Mixup+Multimodal+Data+Augmentation+for+Multimodal+Sentiment+Analysis)|0|
|[Node-wise Diffusion for Scalable Graph Learning](https://doi.org/10.1145/3543507.3583408)|Keke Huang, Jing Tang, Juncheng Liu, Renchi Yang, Xiaokui Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Node-wise+Diffusion+for+Scalable+Graph+Learning)|0|
|[MetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters](https://doi.org/10.1145/3543507.3583417)|Lin Tian, Xiuzhen Zhang, Jey Han Lau||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaTroll:+Few-shot+Detection+of+State-Sponsored+Trolls+with+Transformer+Adapters)|0|
|[EmpMFF: A Multi-factor Sequence Fusion Framework for Empathetic Response Generation](https://doi.org/10.1145/3543507.3583438)|Xiaobing Pang, Yequan Wang, Siqi Fan, Lisi Chen, Shuo Shang, Peng Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EmpMFF:+A+Multi-factor+Sequence+Fusion+Framework+for+Empathetic+Response+Generation)|0|
|[CEIL: A General Classification-Enhanced Iterative Learning Framework for Text Clustering](https://doi.org/10.1145/3543507.3583457)|Mingjun Zhao, Mengzhen Wang, Yinglong Ma, Di Niu, Haijiang Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CEIL:+A+General+Classification-Enhanced+Iterative+Learning+Framework+for+Text+Clustering)|0|
|[Interval-censored Transformer Hawkes: Detecting Information Operations using the Reaction of Social Systems](https://doi.org/10.1145/3543507.3583481)|Quyu Kong, Pio Calderon, Rohit Ram, Olga Boichak, MarianAndrei Rizoiu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interval-censored+Transformer+Hawkes:+Detecting+Information+Operations+using+the+Reaction+of+Social+Systems)|0|
|[Towards Model Robustness: Generating Contextual Counterfactuals for Entities in Relation Extraction](https://doi.org/10.1145/3543507.3583504)|Mi Zhang, Tieyun Qian, Ting Zhang, Xin Miao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Model+Robustness:+Generating+Contextual+Counterfactuals+for+Entities+in+Relation+Extraction)|0|
|[CitationSum: Citation-aware Graph Contrastive Learning for Scientific Paper Summarization](https://doi.org/10.1145/3543507.3583505)|Zheheng Luo, Qianqian Xie, Sophia Ananiadou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CitationSum:+Citation-aware+Graph+Contrastive+Learning+for+Scientific+Paper+Summarization)|0|
|[Set in Stone: Analysis of an Immutable Web3 Social Media Platform](https://doi.org/10.1145/3543507.3583510)|Wenrui Zuo, Aravindh Raman, Raul J. Mondragón, Gareth Tyson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Set+in+Stone:+Analysis+of+an+Immutable+Web3+Social+Media+Platform)|0|
|[Show me your NFT and I tell you how it will perform: Multimodal representation learning for NFT selling price prediction](https://doi.org/10.1145/3543507.3583520)|Davide Costa, Lucio La Cava, Andrea Tagarelli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Show+me+your+NFT+and+I+tell+you+how+it+will+perform:+Multimodal+representation+learning+for+NFT+selling+price+prediction)|0|
|[CoTel: Ontology-Neural Co-Enhanced Text Labeling](https://doi.org/10.1145/3543507.3583533)|MiaoHui Song, Lan Zhang, Mu Yuan, Zichong Li, Qi Song, Yijun Liu, Guidong Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoTel:+Ontology-Neural+Co-Enhanced+Text+Labeling)|0|
|[Extracting Cultural Commonsense Knowledge at Scale](https://doi.org/10.1145/3543507.3583535)|TuanPhong Nguyen, Simon Razniewski, Aparna S. Varde, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extracting+Cultural+Commonsense+Knowledge+at+Scale)|0|
|[Unsupervised Event Chain Mining from Multiple Documents](https://doi.org/10.1145/3543507.3583295)|Yizhu Jiao, Ming Zhong, Jiaming Shen, Yunyi Zhang, Chao Zhang, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Event+Chain+Mining+from+Multiple+Documents)|0|
|[A Multi-view Meta-learning Approach for Multi-modal Response Generation](https://doi.org/10.1145/3543507.3583548)|Zhiliang Tian, Zheng Xie, Fuqiang Lin, Yiping Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-view+Meta-learning+Approach+for+Multi-modal+Response+Generation)|0|
|[Provenance of Training without Training Data: Towards Privacy-Preserving DNN Model Ownership Verification](https://doi.org/10.1145/3543507.3583198)|Yunpeng Liu, Kexin Li, Zhuotao Liu, Bihan Wen, Ke Xu, Weiqiang Wang, Wenbiao Zhao, Qi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Provenance+of+Training+without+Training+Data:+Towards+Privacy-Preserving+DNN+Model+Ownership+Verification)|0|
|[Efficient and Low Overhead Website Fingerprinting Attacks and Defenses based on TCP/IP Traffic](https://doi.org/10.1145/3543507.3583200)|Guodong Huang, Chuan Ma, Ming Ding, Yuwen Qian, Chunpeng Ge, Liming Fang, Zhe Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Low+Overhead+Website+Fingerprinting+Attacks+and+Defenses+based+on+TCP/IP+Traffic)|0|
|[Curriculum Graph Poisoning](https://doi.org/10.1145/3543507.3583211)|Hanwen Liu, Peilin Zhao, Tingyang Xu, Yatao Bian, Junzhou Huang, Yuesheng Zhu, Yadong Mu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curriculum+Graph+Poisoning)|0|
|[Transferring Audio Deepfake Detection Capability across Languages](https://doi.org/10.1145/3543507.3583222)|Zhongjie Ba, Qing Wen, Peng Cheng, Yuwei Wang, Feng Lin, Li Lu, Zhenguang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transferring+Audio+Deepfake+Detection+Capability+across+Languages)|0|
|[Web Photo Source Identification based on Neural Enhanced Camera Fingerprint](https://doi.org/10.1145/3543507.3583225)|Feng Qian, Sifeng He, Honghao Huang, Huanyu Ma, Xiaobo Zhang, Lei Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Web+Photo+Source+Identification+based+on+Neural+Enhanced+Camera+Fingerprint)|0|
|[TFE-GNN: A Temporal Fusion Encoder Using Graph Neural Networks for Fine-grained Encrypted Traffic Classification](https://doi.org/10.1145/3543507.3583227)|Haozhen Zhang, Le Yu, Xi Xiao, Qing Li, Francesco Mercaldo, Xiapu Luo, Qixu Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TFE-GNN:+A+Temporal+Fusion+Encoder+Using+Graph+Neural+Networks+for+Fine-grained+Encrypted+Traffic+Classification)|0|
|[Time-manipulation Attack: Breaking Fairness against Proof of Authority Aura](https://doi.org/10.1145/3543507.3583252)|Xinrui Zhang, Rujia Li, Qin Wang, Qi Wang, Sisi Duan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-manipulation+Attack:+Breaking+Fairness+against+Proof+of+Authority+Aura)|0|
|[Do NFTs' Owners Really Possess their Assets? A First Look at the NFT-to-Asset Connection Fragility](https://doi.org/10.1145/3543507.3583281)|Ziwei Wang, Jiashi Gao, Xuetao Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+NFTs'+Owners+Really+Possess+their+Assets?+A+First+Look+at+the+NFT-to-Asset+Connection+Fragility)|0|
|[Preserving Missing Data Distribution in Synthetic Data](https://doi.org/10.1145/3543507.3583297)|Xinyue Wang, Hafiz Salman Asif, Jaideep Vaidya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preserving+Missing+Data+Distribution+in+Synthetic+Data)|0|
|[Not Seen, Not Heard in the Digital World! Measuring Privacy Practices in Children's Apps](https://doi.org/10.1145/3543507.3583327)|Ruoxi Sun, Minhui Xue, Gareth Tyson, Shuo Wang, Seyit Camtepe, Surya Nepal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+Seen,+Not+Heard+in+the+Digital+World!+Measuring+Privacy+Practices+in+Children's+Apps)|0|
|[Automatic Discovery of Emerging Browser Fingerprinting Techniques](https://doi.org/10.1145/3543507.3583333)|Junhua Su, Alexandros Kapravelos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Discovery+of+Emerging+Browser+Fingerprinting+Techniques)|0|
|[BERT4ETH: A Pre-trained Transformer for Ethereum Fraud Detection](https://doi.org/10.1145/3543507.3583345)|Sihao Hu, Zhen Zhang, Bingqiao Luo, Shengliang Lu, Bingsheng He, Ling Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BERT4ETH:+A+Pre-trained+Transformer+for+Ethereum+Fraud+Detection)|0|
|[Training-free Lexical Backdoor Attacks on Language Models](https://doi.org/10.1145/3543507.3583348)|Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Training-free+Lexical+Backdoor+Attacks+on+Language+Models)|0|
|[The Benefits of Vulnerability Discovery and Bug Bounty Programs: Case Studies of Chromium and Firefox](https://doi.org/10.1145/3543507.3583352)|Soodeh Atefi, Amutheezan Sivagnanam, Afiya Ayman, Jens Grossklags, Aron Laszka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Benefits+of+Vulnerability+Discovery+and+Bug+Bounty+Programs:+Case+Studies+of+Chromium+and+Firefox)|0|
|[Net-track: Generic Web Tracking Detection Using Packet Metadata](https://doi.org/10.1145/3543507.3583372)|Dongkeun Lee, Minwoo Joo, Wonjun Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Net-track:+Generic+Web+Tracking+Detection+Using+Packet+Metadata)|0|
|[Cross-Modality Mutual Learning for Enhancing Smart Contract Vulnerability Detection on Bytecode](https://doi.org/10.1145/3543507.3583367)|Peng Qian, Zhenguang Liu, Yifang Yin, Qinming He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Modality+Mutual+Learning+for+Enhancing+Smart+Contract+Vulnerability+Detection+on+Bytecode)|0|
|[The Chameleon on the Web: an Empirical Study of the Insidious Proactive Web Defacements](https://doi.org/10.1145/3543507.3583377)|Rui Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Chameleon+on+the+Web:+an+Empirical+Study+of+the+Insidious+Proactive+Web+Defacements)|0|
|[Shield: Secure Allegation Escrow System with Stronger Guarantees](https://doi.org/10.1145/3543507.3583391)|Nishat Koti, Varsha Bhat Kukkala, Arpita Patra, Bhavish Raj Gopal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shield:+Secure+Allegation+Escrow+System+with+Stronger+Guarantees)|0|
|[Unnoticeable Backdoor Attacks on Graph Neural Networks](https://doi.org/10.1145/3543507.3583392)|Enyan Dai, Minhua Lin, Xiang Zhang, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unnoticeable+Backdoor+Attacks+on+Graph+Neural+Networks)|0|
|[Bad Apples: Understanding the Centralized Security Risks in Decentralized Ecosystems](https://doi.org/10.1145/3543507.3583393)|Kailun Yan, Jilian Zhang, Xiangyu Liu, Wenrui Diao, Shanqing Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bad+Apples:+Understanding+the+Centralized+Security+Risks+in+Decentralized+Ecosystems)|0|
|[Scan Me If You Can: Understanding and Detecting Unwanted Vulnerability Scanning](https://doi.org/10.1145/3543507.3583394)|Xigao Li, Babak Amin Azad, Amir Rahmati, Nick Nikiforakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scan+Me+If+You+Can:+Understanding+and+Detecting+Unwanted+Vulnerability+Scanning)|0|
|[The More Things Change, the More They Stay the Same: Integrity of Modern JavaScript](https://doi.org/10.1145/3543507.3583395)|Johnny So, Michael Ferdman, Nick Nikiforakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+More+Things+Change,+the+More+They+Stay+the+Same:+Integrity+of+Modern+JavaScript)|0|
|[AppSniffer: Towards Robust Mobile App Fingerprinting Against VPN](https://doi.org/10.1145/3543507.3583473)|Sanghak Oh, Minwook Lee, Hyunwoo Lee, Elisa Bertino, Hyoungshick Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AppSniffer:+Towards+Robust+Mobile+App+Fingerprinting+Against+VPN)|0|
|[RICC: Robust Collective Classification of Sybil Accounts](https://doi.org/10.1145/3543507.3583475)|Dongwon Shin, Suyoung Lee, Sooel Son||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RICC:+Robust+Collective+Classification+of+Sybil+Accounts)|0|
|[ZTLS: A DNS-based Approach to Zero Round Trip Delay in TLS handshake](https://doi.org/10.1145/3543507.3583516)|Sangwon Lim, Hyeonmin Lee, Hyunsoo Kim, Hyunwoo Lee, Ted Taekyoung Kwon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ZTLS:+A+DNS-based+Approach+to+Zero+Round+Trip+Delay+in+TLS+handshake)|0|
|[AgrEvader: Poisoning Membership Inference against Byzantine-robust Federated Learning](https://doi.org/10.1145/3543507.3583542)|Yanjun Zhang, Guangdong Bai, Mahawaga Arachchige Pathum Chamikara, Mengyao Ma, Liyue Shen, Jingwei Wang, Surya Nepal, Minhui Xue, Long Wang, Joseph K. Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AgrEvader:+Poisoning+Membership+Inference+against+Byzantine-robust+Federated+Learning)|0|
|[Event Prediction using Case-Based Reasoning over Knowledge Graphs](https://doi.org/10.1145/3543507.3583201)|Sola Shirai, Debarun Bhattacharjya, Oktie Hassanzadeh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Event+Prediction+using+Case-Based+Reasoning+over+Knowledge+Graphs)|0|
|[Wikidata as a seed for Web Extraction](https://doi.org/10.1145/3543507.3583236)|Kunpeng Guo, Dennis Diefenbach, Antoine Gourru, Christophe Gravier||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wikidata+as+a+seed+for+Web+Extraction)|0|
|[Meta-Learning Based Knowledge Extrapolation for Temporal Knowledge Graph](https://doi.org/10.1145/3543507.3583279)|Zhongwu Chen, Chengjin Xu, Fenglong Su, Zhen Huang, Yong Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Learning+Based+Knowledge+Extrapolation+for+Temporal+Knowledge+Graph)|0|
|[Can Persistent Homology provide an efficient alternative for Evaluation of Knowledge Graph Completion Methods?](https://doi.org/10.1145/3543507.3583308)|Anson Bastos, Kuldeep Singh, Abhishek Nadgeri, Johannes Hoffart, Manish Singh, Toyotaro Suzumura||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Persistent+Homology+provide+an+efficient+alternative+for+Evaluation+of+Knowledge+Graph+Completion+Methods?)|0|
|[Attribute-Consistent Knowledge Graph Representation Learning for Multi-Modal Entity Alignment](https://doi.org/10.1145/3543507.3583328)|Qian Li, Shu Guo, Yangyifei Luo, Cheng Ji, Lihong Wang, Jiawei Sheng, Jianxin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attribute-Consistent+Knowledge+Graph+Representation+Learning+for+Multi-Modal+Entity+Alignment)|0|
|[Hierarchy-Aware Multi-Hop Question Answering over Knowledge Graphs](https://doi.org/10.1145/3543507.3583376)|Junnan Dong, Qinggang Zhang, Xiao Huang, Keyu Duan, Qiaoyu Tan, Zhimeng Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchy-Aware+Multi-Hop+Question+Answering+over+Knowledge+Graphs)|0|
|[Unsupervised Entity Alignment for Temporal Knowledge Graphs](https://doi.org/10.1145/3543507.3583381)|Xiaoze Liu, Junyang Wu, Tianyi Li, Lu Chen, Yunjun Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Entity+Alignment+for+Temporal+Knowledge+Graphs)|0|
|[IMF: Interactive Multimodal Fusion Model for Link Prediction](https://doi.org/10.1145/3543507.3583554)|Xinhang Li, Xiangyu Zhao, Jiaxing Xu, Yong Zhang, Chunxiao Xing||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IMF:+Interactive+Multimodal+Fusion+Model+for+Link+Prediction)|0|
|[Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer](https://doi.org/10.1145/3543507.3583301)|Wen Zhang, Yushan Zhu, Mingyang Chen, Yuxia Geng, Yufeng Huang, Yajing Xu, Wenting Song, Huajun Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structure+Pretraining+and+Prompt+Tuning+for+Knowledge+Graph+Transfer)|0|
|[TEA: Time-aware Entity Alignment in Knowledge Graphs](https://doi.org/10.1145/3543507.3583317)|Yu Liu, Wen Hua, Kexuan Xin, Saeid Hosseini, Xiaofang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TEA:+Time-aware+Entity+Alignment+in+Knowledge+Graphs)|0|
|[Knowledge Graph Completion with Counterfactual Augmentation](https://doi.org/10.1145/3543507.3583401)|Heng Chang, Jie Cai, Jia Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Completion+with+Counterfactual+Augmentation)|0|
|[Learning Social Meta-knowledge for Nowcasting Human Mobility in Disaster](https://doi.org/10.1145/3543507.3583991)|Renhe Jiang, Zhaonan Wang, Yudong Tao, Chuang Yang, Xuan Song, Ryosuke Shibasaki, ShuChing Chen, MeiLing Shyu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Social+Meta-knowledge+for+Nowcasting+Human+Mobility+in+Disaster)|0|
|[Cashing in on Contacts: Characterizing the OnlyFans Ecosystem](https://doi.org/10.1145/3543507.3583210)|Pelayo Vallina, Ignacio Castro, Gareth Tyson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cashing+in+on+Contacts:+Characterizing+the+OnlyFans+Ecosystem)|0|
|[Automated Content Moderation Increases Adherence to Community Guidelines](https://doi.org/10.1145/3543507.3583275)|Manoel Horta Ribeiro, Justin Cheng, Robert West||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Content+Moderation+Increases+Adherence+to+Community+Guidelines)|0|
|[Mental Health Coping Stories on Social Media: A Causal-Inference Study of Papageno Effect](https://doi.org/10.1145/3543507.3583350)|Yunhao Yuan, Koustuv Saha, Barbara Keller, Erkki Tapio Isometsä, Talayeh Aledavood||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mental+Health+Coping+Stories+on+Social+Media:+A+Causal-Inference+Study+of+Papageno+Effect)|0|
|[A First Look at Public Service Websites from the Affordability Lens](https://doi.org/10.1145/3543507.3583415)|Rumaisa Habib, Aimen Inam, Ayesha Ali, Ihsan Ayyub Qazi, Zafar Ayyub Qazi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+First+Look+at+Public+Service+Websites+from+the+Affordability+Lens)|0|
|[Who Funds Misinformation? A Systematic Analysis of the Ad-related Profit Routines of Fake News Sites](https://doi.org/10.1145/3543507.3583443)|Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos P. Markatos, Nicolas Kourtellis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Who+Funds+Misinformation?+A+Systematic+Analysis+of+the+Ad-related+Profit+Routines+of+Fake+News+Sites)|0|
|[Evidence of Demographic rather than Ideological Segregation in News Discussion on Reddit](https://doi.org/10.1145/3543507.3583468)|Corrado Monti, Jacopo D'Ignazi, Michele Starnini, Gianmarco De Francisci Morales||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evidence+of+Demographic+rather+than+Ideological+Segregation+in+News+Discussion+on+Reddit)|0|
|[Longitudinal Assessment of Reference Quality on Wikipedia](https://doi.org/10.1145/3543507.3583218)|Aitolkyn Baigutanova, Jaehyeon Myung, Diego SáezTrumper, AiJou Chou, Miriam Redi, Changwook Jung, Meeyoung Cha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Longitudinal+Assessment+of+Reference+Quality+on+Wikipedia)|0|
|[Gateway Entities in Problematic Trajectories](https://doi.org/10.1145/3543507.3583283)|Xi Leslie Chen, Abhratanu Dutta, Sindhu Ernala, Stratis Ioannidis, Shankar Kalyanaraman, Israel Nir, Udi Weinsberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gateway+Entities+in+Problematic+Trajectories)|0|
|[Unsupervised Anomaly Detection on Microservice Traces through Graph VAE](https://doi.org/10.1145/3543507.3583215)|Zhe Xie, Haowen Xu, Wenxiao Chen, Wanxue Li, Huai Jiang, Liangfei Su, Hanzhang Wang, Dan Pei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Anomaly+Detection+on+Microservice+Traces+through+Graph+VAE)|0|
|[FedEdge: Accelerating Edge-Assisted Federated Learning](https://doi.org/10.1145/3543507.3583264)|Kaibin Wang, Qiang He, Feifei Chen, Hai Jin, Yun Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedEdge:+Accelerating+Edge-Assisted+Federated+Learning)|0|
|[CausIL: Causal Graph for Instance Level Microservice Data](https://doi.org/10.1145/3543507.3583274)|Sarthak Chakraborty, Shaddy Garg, Shubham Agarwal, Ayush Chauhan, Shiv Kumar Saini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CausIL:+Causal+Graph+for+Instance+Level+Microservice+Data)|0|
|[Learning Cooperative Oversubscription for Cloud by Chance-Constrained Multi-Agent Reinforcement Learning](https://doi.org/10.1145/3543507.3583298)|Junjie Sheng, Lu Wang, Fangkai Yang, Bo Qiao, Hang Dong, Xiangfeng Wang, Bo Jin, Jun Wang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Cooperative+Oversubscription+for+Cloud+by+Chance-Constrained+Multi-Agent+Reinforcement+Learning)|0|
|[CMDiagnostor: An Ambiguity-Aware Root Cause Localization Approach Based on Call Metric Data](https://doi.org/10.1145/3543507.3583302)|Qingyang Yu, Changhua Pei, Bowen Hao, Mingjie Li, Zeyan Li, Shenglin Zhang, Xianglin Lu, Rui Wang, Jiaqi Li, Zhenyu Wu, Dan Pei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CMDiagnostor:+An+Ambiguity-Aware+Root+Cause+Localization+Approach+Based+on+Call+Metric+Data)|0|
|[Visual-Aware Testing and Debugging for Web Performance Optimization](https://doi.org/10.1145/3543507.3583323)|Xinlei Yang, Wei Liu, Hao Lin, Zhenhua Li, Feng Qian, Xianlong Wang, Yunhao Liu, Tianyin Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Visual-Aware+Testing+and+Debugging+for+Web+Performance+Optimization)|0|
|[Demystifying Mobile Extended Reality in Web Browsers: How Far Can We Go?](https://doi.org/10.1145/3543507.3583329)|Weichen Bi, Yun Ma, Deyu Tian, Qi Yang, Mingtao Zhang, Xiang Jing||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demystifying+Mobile+Extended+Reality+in+Web+Browsers:+How+Far+Can+We+Go?)|0|
|[Look Deep into the Microservice System Anomaly through Very Sparse Logs](https://doi.org/10.1145/3543507.3583338)|Xinrui Jiang, Yicheng Pan, Meng Ma, Ping Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Look+Deep+into+the+Microservice+System+Anomaly+through+Very+Sparse+Logs)|0|
|[Analyzing the Communication Clusters in Datacenters✱](https://doi.org/10.1145/3543507.3583410)|KlausTycho Foerster, Thibault Marette, Stefan Neumann, Claudia Plant, Ylli Sadikaj, Stefan Schmid, Yllka Velaj||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+the+Communication+Clusters+in+Datacenters✱)|0|
|[DDPC: Automated Data-Driven Power-Performance Controller Design on-the-fly for Latency-sensitive Web Services](https://doi.org/10.1145/3543507.3583437)|Mehmet Savasci, Ahmed AliEldin, Johan Eker, Anders Robertsson, Prashant J. Shenoy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DDPC:+Automated+Data-Driven+Power-Performance+Controller+Design+on-the-fly+for+Latency-sensitive+Web+Services)|0|
|[Will Admins Cope? Decentralized Moderation in the Fediverse](https://doi.org/10.1145/3543507.3583487)|Ishaku Hassan Anaobi, Aravindh Raman, Ignacio Castro, Haris Bin Zia, Damilola Ibosiola, Gareth Tyson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Will+Admins+Cope?+Decentralized+Moderation+in+the+Fediverse)|0|
|[Are Mobile Advertisements in Compliance with App's Age Group?](https://doi.org/10.1145/3543507.3583534)|Yanjie Zhao, Tianming Liu, Haoyu Wang, Yepang Liu, John C. Grundy, Li Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+Mobile+Advertisements+in+Compliance+with+App's+Age+Group?)|0|
|[EdgeMove: Pipelining Device-Edge Model Training for Mobile Intelligence](https://doi.org/10.1145/3543507.3583540)|Zeqian Dong, Qiang He, Feifei Chen, Hai Jin, Tao Gu, Yun Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EdgeMove:+Pipelining+Device-Edge+Model+Training+for+Mobile+Intelligence)|0|
|[HTTP Steady Connections for Robust Web Acceleration](https://doi.org/10.1145/3543507.3583550)|Sunjae Kim, Wonjun Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HTTP+Steady+Connections+for+Robust+Web+Acceleration)|0|
|[Dynamic Interventions for Networked Contagions](https://doi.org/10.1145/3543507.3583470)|Marios Papachristou, Siddhartha Banerjee, Jon M. Kleinberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Interventions+for+Networked+Contagions)|0|
|[Randomized Pricing with Deferred Acceptance for Revenue Maximization with Submodular Objectives](https://doi.org/10.1145/3543507.3583477)|He Huang, Kai Han, Shuang Cui, Jing Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Randomized+Pricing+with+Deferred+Acceptance+for+Revenue+Maximization+with+Submodular+Objectives)|0|
|[Fairness-aware Guaranteed Display Advertising Allocation under Traffic Cost Constraint](https://doi.org/10.1145/3543507.3583501)|Liang Dai, Zhonglin Zu, Hao Wu, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness-aware+Guaranteed+Display+Advertising+Allocation+under+Traffic+Cost+Constraint)|0|
|[Is your digital neighbor a reliable investment advisor?](https://doi.org/10.1145/3543507.3583502)|Daisuke Kawai, Alejandro Cuevas, Bryan R. Routledge, Kyle Soska, Ariel ZetlinJones, Nicolas Christin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+your+digital+neighbor+a+reliable+investment+advisor?)|0|
|[Impartial Selection with Prior Information](https://doi.org/10.1145/3543507.3583553)|Ioannis Caragiannis, George Christodoulou, Nicos Protopapas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Impartial+Selection+with+Prior+Information)|0|
|[Do Language Models Plagiarize?](https://doi.org/10.1145/3543507.3583199)|Jooyoung Lee, Thai Le, Jinghui Chen, Dongwon Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+Language+Models+Plagiarize?)|0|
|[Path-specific Causal Fair Prediction via Auxiliary Graph Structure Learning](https://doi.org/10.1145/3543507.3583280)|Liuyi Yao, Yaliang Li, Bolin Ding, Jingren Zhou, Jinduo Liu, Mengdi Huai, Jing Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Path-specific+Causal+Fair+Prediction+via+Auxiliary+Graph+Structure+Learning)|0|
|[HateProof: Are Hateful Meme Detection Systems really Robust?](https://doi.org/10.1145/3543507.3583356)|Piush Aggarwal, Pranit Chawla, Mithun Das, Punyajoy Saha, Binny Mathew, Torsten Zesch, Animesh Mukherjee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HateProof:+Are+Hateful+Meme+Detection+Systems+really+Robust?)|0|
|[DualFair: Fair Representation Learning at Both Group and Individual Levels via Contrastive Self-supervision](https://doi.org/10.1145/3543507.3583480)|Sungwon Han, SeungEon Lee, Fangzhao Wu, Sundong Kim, Chuhan Wu, Xiting Wang, Xing Xie, Meeyoung Cha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DualFair:+Fair+Representation+Learning+at+Both+Group+and+Individual+Levels+via+Contrastive+Self-supervision)|0|
|[PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous Link Prediction](https://doi.org/10.1145/3543507.3583511)|Shichang Zhang, Jiani Zhang, Xiang Song, Soji Adeshina, Da Zheng, Christos Faloutsos, Yizhou Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PaGE-Link:+Path-based+Graph+Neural+Network+Explanation+for+Heterogeneous+Link+Prediction)|0|
|[Fairness in model-sharing games](https://doi.org/10.1145/3543507.3583483)|Kate Donahue, Jon M. Kleinberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+in+model-sharing+games)|0|
|[Combining Worker Factors for Heterogeneous Crowd Task Assignment](https://doi.org/10.1145/3543507.3583190)|Senuri Wijenayake, Danula Hettiachchi, Jorge Gonçalves||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combining+Worker+Factors+for+Heterogeneous+Crowd+Task+Assignment)|0|
|[Hidden Indicators of Collective Intelligence in Crowdfunding](https://doi.org/10.1145/3543507.3583414)|EmokeÁgnes Horvát, Henry Kudzanai Dambanemuya, Jayaram Uparna, Brian Uzzi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hidden+Indicators+of+Collective+Intelligence+in+Crowdfunding)|0|
|[Multiview Representation Learning from Crowdsourced Triplet Comparisons](https://doi.org/10.1145/3543507.3583431)|Xiaotian Lu, Jiyi Li, Koh Takeuchi, Hisashi Kashima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiview+Representation+Learning+from+Crowdsourced+Triplet+Comparisons)|0|
|[Sedition Hunters: A Quantitative Study of the Crowdsourced Investigation into the 2021 U.S. Capitol Attack](https://doi.org/10.1145/3543507.3583514)|Tianjiao Yu, Sukrit Venkatagiri, Ismini Lourentzou, Kurt Luther||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sedition+Hunters:+A+Quantitative+Study+of+the+Crowdsourced+Investigation+into+the+2021+U.S.+Capitol+Attack)|0|
|[Human-in-the-loop Regular Expression Extraction for Single Column Format Inconsistency](https://doi.org/10.1145/3543507.3583515)|Shaochen Yu, Lei Han, Marta Indulska, Shazia W. Sadiq, Gianluca Demartini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human-in-the-loop+Regular+Expression+Extraction+for+Single+Column+Format+Inconsistency)|0|
|[Identifying Creative Harmful Memes via Prompt based Approach](https://doi.org/10.1145/3543507.3587427)|Junhui Ji, Wei Ren, Usman Naseem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Creative+Harmful+Memes+via+Prompt+based+Approach)|0|
|[SA-Fusion: Multimodal Fusion Approach for Web-based Human-Computer Interaction in the Wild](https://doi.org/10.1145/3543507.3587429)|Xingyu Liu, Pengfei Ren, Yuchen Chen, Cong Liu, Jing Wang, Haifeng Sun, Qi Qi, Jingyu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SA-Fusion:+Multimodal+Fusion+Approach+for+Web-based+Human-Computer+Interaction+in+the+Wild)|0|
|[The Harmonic Memory: a Knowledge Graph of harmonic patterns as a trustworthy framework for computational creativity](https://doi.org/10.1145/3543507.3587428)|Jacopo de Berardinis, Albert MeroñoPeñuela, Andrea Poltronieri, Valentina Presutti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Harmonic+Memory:+a+Knowledge+Graph+of+harmonic+patterns+as+a+trustworthy+framework+for+computational+creativity)|0|
|[A Prompt Log Analysis of Text-to-Image Generation Systems](https://doi.org/10.1145/3543507.3587430)|Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, Qiaozhu Mei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Prompt+Log+Analysis+of+Text-to-Image+Generation+Systems)|0|
|[CAM: A Large Language Model-based Creative Analogy Mining Framework](https://doi.org/10.1145/3543507.3587431)|Bhavya, Jinjun Xiong, Chengxiang Zhai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAM:+A+Large+Language+Model-based+Creative+Analogy+Mining+Framework)|0|
|[Tangible Web: An Interactive Immersion Virtual Reality Creativity System that Travels Across Reality](https://doi.org/10.1145/3543507.3587432)|Simin Yang, Ze Gao, Reza Hadi Mogavi, Pan Hui, Tristan Braud||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tangible+Web:+An+Interactive+Immersion+Virtual+Reality+Creativity+System+that+Travels+Across+Reality)|0|
|[Coherent Topic Modeling for Creative Multimodal Data on Social Media](https://doi.org/10.1145/3543507.3587433)|Junaid Rashid, Jungeun Kim, Usman Naseem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Coherent+Topic+Modeling+for+Creative+Multimodal+Data+on+Social+Media)|0|
|[Improving Health Mention Classification Through Emphasising Literal Meanings: A Study Towards Diversity and Generalisation for Public Health Surveillance](https://doi.org/10.1145/3543507.3583877)|Olanrewaju Tahir Aduragba, Jialin Yu, Alexandra I. Cristea, Yang Long||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Health+Mention+Classification+Through+Emphasising+Literal+Meanings:+A+Study+Towards+Diversity+and+Generalisation+for+Public+Health+Surveillance)|0|
|[Learning Faithful Attention for Interpretable Classification of Crisis-Related Microblogs under Constrained Human Budget](https://doi.org/10.1145/3543507.3583861)|Thi Huyen Nguyen, Koustav Rudra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Faithful+Attention+for+Interpretable+Classification+of+Crisis-Related+Microblogs+under+Constrained+Human+Budget)|0|
|[Attacking Fake News Detectors via Manipulating News Social Engagement](https://doi.org/10.1145/3543507.3583868)|Haoran Wang, Yingtong Dou, Canyu Chen, Lichao Sun, Philip S. Yu, Kai Shu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attacking+Fake+News+Detectors+via+Manipulating+News+Social+Engagement)|0|
|[ContrastFaux: Sparse Semi-supervised Fauxtography Detection on the Web using Multi-view Contrastive Learning](https://doi.org/10.1145/3543507.3583869)|Ruohan Zong, Yang Zhang, Lanyu Shang, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ContrastFaux:+Sparse+Semi-supervised+Fauxtography+Detection+on+the+Web+using+Multi-view+Contrastive+Learning)|0|
|[Interpreting wealth distribution via poverty map inference using multimodal data](https://doi.org/10.1145/3543507.3583862)|Lisette EspínNoboa, János Kertész, Márton Karsai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpreting+wealth+distribution+via+poverty+map+inference+using+multimodal+data)|0|
|[MSQ-BioBERT: Ambiguity Resolution to Enhance BioBERT Medical Question-Answering](https://doi.org/10.1145/3543507.3583878)|Muzhe Guo, Muhao Guo, Edward T. Dougherty, Fang Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSQ-BioBERT:+Ambiguity+Resolution+to+Enhance+BioBERT+Medical+Question-Answering)|0|
|[Graph-based Village Level Poverty Identification](https://doi.org/10.1145/3543507.3583864)|Jing Ma, Liangwei Yang, Qiong Feng, Weizhi Zhang, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-based+Village+Level+Poverty+Identification)|0|
|[Mapping Flood Exposure, Damage, and Population Needs Using Remote and Social Sensing: A Case Study of 2022 Pakistan Floods](https://doi.org/10.1145/3543507.3583881)|Zainab Akhtar, Umair Qazi, Rizwan Sadiq, Aya ElSakka, Muhammad Sajjad, Ferda Ofli, Muhammad Imran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mapping+Flood+Exposure,+Damage,+and+Population+Needs+Using+Remote+and+Social+Sensing:+A+Case+Study+of+2022+Pakistan+Floods)|0|
|[Web Information Extraction for Social Good: Food Pantry Answering As an Example](https://doi.org/10.1145/3543507.3583880)|HuanYuan Chen, Hong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Web+Information+Extraction+for+Social+Good:+Food+Pantry+Answering+As+an+Example)|0|
|[Gender Pay Gap in Sports on a Fan-Request Celebrity Video Site](https://doi.org/10.1145/3543507.3583884)|Nazanin Sabri, Stephen Reysen, Ingmar Weber||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gender+Pay+Gap+in+Sports+on+a+Fan-Request+Celebrity+Video+Site)|0|
|[Leveraging Existing Literature on the Web and Deep Neural Models to Build a Knowledge Graph Focused on Water Quality and Health Risks](https://doi.org/10.1145/3543507.3584185)|Nikita Gautam, David Shumway, Megan Kowalcyk, Sarthak Khanal, Doina Caragea, Cornelia Caragea, Hande Mcginty, Samuel Dorevitch||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Existing+Literature+on+the+Web+and+Deep+Neural+Models+to+Build+a+Knowledge+Graph+Focused+on+Water+Quality+and+Health+Risks)|0|
|[Believability and Harmfulness Shape the Virality of Misleading Social Media Posts](https://doi.org/10.1145/3543507.3583857)|Chiara Patricia Drolsbach, Nicolas Pröllochs||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Believability+and+Harmfulness+Shape+the+Virality+of+Misleading+Social+Media+Posts)|0|
|[Enhancing Deep Knowledge Tracing with Auxiliary Tasks](https://doi.org/10.1145/3543507.3583866)|Zitao Liu, Qiongqiong Liu, Jiahao Chen, Shuyan Huang, Boyu Gao, Weiqi Luo, Jian Weng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Deep+Knowledge+Tracing+with+Auxiliary+Tasks)|0|
|[Learning to Simulate Crowd Trajectories with Graph Networks](https://doi.org/10.1145/3543507.3583858)|Hongzhi Shi, Quanming Yao, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Simulate+Crowd+Trajectories+with+Graph+Networks)|0|
